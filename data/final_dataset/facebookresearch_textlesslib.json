{"home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_dense_model": [[23, 27], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "model_class"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["def", "dispatch_dense_model", "(", "name", ":", "str", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_class", "=", "DENSE_MODELS", "[", "name", "]", "\n", "checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "name", ")", "\n", "return", "model_class", "(", "checkpoint_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer": [[29, 34], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["", "def", "dispatch_quantizer", "(", "dense_model_name", ":", "str", ",", "quantizer_name", ":", "str", ",", "vocab_size", ":", "int", ")", ":", "\n", "    ", "quantizer_checkpoint_name", "=", "f\"{dense_model_name}-{quantizer_name}-{vocab_size}\"", "\n", "checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "quantizer_checkpoint_name", ")", "\n", "quantizer", "=", "QUANTIZER_MODELS", "[", "quantizer_name", "]", "(", "checkpoint_path", ")", "\n", "return", "quantizer", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_vocoder": [[36, 51], ["textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["", "def", "dispatch_vocoder", "(", "\n", "dense_model_name", ":", "str", ",", "\n", "quantizer_name", ":", "str", ",", "\n", "vocoder_name", ":", "str", ",", "\n", "vocab_size", ":", "int", ",", "\n", ")", ":", "\n", "    ", "if", "vocoder_name", "==", "\"tacotron\"", ":", "\n", "        ", "vocoder", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", ",", "\n", "quantizer_name", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Unsupported vocoder name\"", "\n", "", "return", "vocoder", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.__init__": [[22, 28], ["pathlib.Path().expanduser().resolve", "manager.CheckpointManager.disk_root.exists", "manager.CheckpointManager.disk_root.mkdir", "pathlib.Path().expanduser", "pathlib.Path"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "disk_root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", "=", "\"~/.textless/\"", ")", ":", "\n", "        ", "self", ".", "disk_root", "=", "pathlib", ".", "Path", "(", "disk_root", ")", ".", "expanduser", "(", ")", ".", "resolve", "(", ")", "\n", "if", "not", "self", ".", "disk_root", ".", "exists", "(", ")", ":", "\n", "            ", "self", ".", "disk_root", ".", "mkdir", "(", ")", "\n", "\n", "", "self", ".", "storage", ":", "dict", "[", "str", ",", "Checkpoint", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.add_checkpoint": [[29, 33], ["None"], "methods", ["None"], ["", "def", "add_checkpoint", "(", "self", ",", "checkpoint", ":", "Checkpoint", ")", "->", "None", ":", "\n", "        ", "name", "=", "checkpoint", ".", "name", "\n", "assert", "name", "not", "in", "self", ".", "storage", "\n", "self", ".", "storage", "[", "name", "]", "=", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.download_by_name": [[34, 42], ["torchaudio.datasets.utils.download_url"], "methods", ["None"], ["", "def", "download_by_name", "(", "self", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "checkpoint", "=", "self", ".", "storage", "[", "name", "]", "\n", "download_url", "(", "\n", "checkpoint", ".", "remote_path", ",", "\n", "self", ".", "disk_root", ",", "\n", "hash_value", "=", "checkpoint", ".", "sha256", ",", "\n", "hash_type", "=", "\"sha256\"", ",", "\n", "filename", "=", "checkpoint", ".", "fname", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name": [[44, 56], ["disk_name.exists", "manager.CheckpointManager.download_by_name", "FileNotFoundError"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.download_by_name"], ["", "def", "get_by_name", "(", "self", ",", "name", ":", "str", ",", "download_if_needed", ":", "bool", "=", "True", ")", "->", "pathlib", ".", "Path", ":", "\n", "        ", "checkpoint", "=", "self", ".", "storage", "[", "name", "]", "\n", "disk_name", "=", "self", ".", "disk_root", "/", "checkpoint", ".", "fname", "\n", "\n", "if", "not", "disk_name", ".", "exists", "(", ")", ":", "\n", "            ", "if", "download_if_needed", ":", "\n", "                ", "self", ".", "download_by_name", "(", "name", ")", "\n", "", "else", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\n", "f\"Checkpoint {checkpoint} was not found locally at {disk_name}, please set `allow_download` flag\"", "\n", ")", "\n", "", "", "return", "disk_name", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.set_root": [[57, 59], ["pathlib.Path"], "methods", ["None"], ["", "def", "set_root", "(", "self", ",", "new_root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ")", "->", "None", ":", "\n", "        ", "self", ".", "disk_root", "=", "pathlib", ".", "Path", "(", "new_root", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.__init__.populate_checkpoints": [[13, 188], ["manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "manager.Checkpoint", "CHECKPOINT_MANAGER.add_checkpoint"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.add_checkpoint"], ["\"hubert-base-ls960\"", ":", "HubertFeatureReader", ",", "\n", "\"cpc-big-ll6k\"", ":", "CpcFeatureReader", ",", "\n", "}", "\n", "\n", "QUANTIZER_MODELS", "=", "{", "\n", "\"kmeans\"", ":", "KMeansQuantizer", ",", "\n", "}", "\n", "\n", "\n", "# TODO: add kwargs everywhere", "\n", "def", "dispatch_dense_model", "(", "name", ":", "str", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_class", "=", "DENSE_MODELS", "[", "name", "]", "\n", "checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "name", ")", "\n", "return", "model_class", "(", "checkpoint_path", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "def", "dispatch_quantizer", "(", "dense_model_name", ":", "str", ",", "quantizer_name", ":", "str", ",", "vocab_size", ":", "int", ")", ":", "\n", "    ", "quantizer_checkpoint_name", "=", "f\"{dense_model_name}-{quantizer_name}-{vocab_size}\"", "\n", "checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "quantizer_checkpoint_name", ")", "\n", "quantizer", "=", "QUANTIZER_MODELS", "[", "quantizer_name", "]", "(", "checkpoint_path", ")", "\n", "return", "quantizer", "\n", "\n", "\n", "", "def", "dispatch_vocoder", "(", "\n", "dense_model_name", ":", "str", ",", "\n", "quantizer_name", ":", "str", ",", "\n", "vocoder_name", ":", "str", ",", "\n", "vocab_size", ":", "int", ",", "\n", ")", ":", "\n", "    ", "if", "vocoder_name", "==", "\"tacotron\"", ":", "\n", "        ", "vocoder", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", ",", "\n", "quantizer_name", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Unsupported vocoder name\"", "\n", "", "return", "vocoder", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.__init__": [[60, 105], ["super().__init__", "speech_encoder.SpeechEncoder.register_buffer", "speech_encoder.SpeechEncoder.register_buffer", "speech_encoder.SpeechEncoder.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dense_model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "quantizer_model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "deduplicate", ":", "bool", ",", "\n", "add_bos_eos", ":", "bool", "=", "False", ",", "\n", "need_f0", ":", "bool", "=", "True", ",", "\n", "f0_normalizer", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "f0_quantizer", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Builds a SpeechEncoder instance. SpeechEncoder encodes speech into streams of (pseudo-)units, unit durations,\n        and, optionally, F0.\n\n        Args:\n            dense_model (torch.nn.Module): Dense module used to represent the audio\n            quantizer_model (torch.nn.Module): Quantize module that converts dense representation into discrete tokens\n            deduplicate (bool): if set, run-length encoding is applied so that repeated tokens are deduplicated\n                and duration channel contains the number of repeats of the token.\n            add_bos_eos (bool, optional): if set, each token sequences will be prepended with a special token (bos)\n                and appended with another special token (eos).\n            need_f0 (bool, optional): whether F0 stream should be returned. Estimating F0 is computationally heavy,\n                consider disabling it if not needed.\n            f0_normalizer (Optional[Callable], optional): A callback that allows F0 normalization (e.g., per-speaker)\n            f0_quantizer (Optional[Callable], optional): F0 quantization module\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_model", "=", "dense_model", "\n", "self", ".", "quantizer_model", "=", "quantizer_model", "\n", "\n", "self", ".", "deduplicate", "=", "deduplicate", "\n", "self", ".", "add_bos_eos", "=", "add_bos_eos", "\n", "self", ".", "need_f0", "=", "need_f0", "\n", "self", ".", "f0_normalizer", "=", "f0_normalizer", "\n", "self", ".", "f0_quantizer", "=", "f0_quantizer", "\n", "\n", "self", ".", "unit_vocab_size", "=", "self", ".", "quantizer_model", ".", "vocab_size", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "\"bos\"", ",", "torch", ".", "tensor", "(", "[", "self", ".", "unit_vocab_size", "]", ",", "dtype", "=", "torch", ".", "int", ")", "\n", ")", "\n", "self", ".", "register_buffer", "(", "\n", "\"eos\"", ",", "torch", ".", "tensor", "(", "[", "self", ".", "unit_vocab_size", "+", "1", "]", ",", "dtype", "=", "torch", ".", "int", ")", "\n", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.by_name": [[106, 147], ["textless.dispatch_dense_model", "textless.dispatch_quantizer", "cls"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_dense_model", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer"], ["", "@", "classmethod", "\n", "def", "by_name", "(", "\n", "cls", ",", "\n", "dense_model_name", ":", "str", ",", "\n", "quantizer_model_name", ":", "str", ",", "\n", "vocab_size", ":", "int", ",", "\n", "deduplicate", ":", "bool", ",", "\n", "add_bos_eos", ":", "bool", "=", "False", ",", "\n", "need_f0", ":", "bool", "=", "True", ",", "\n", "f0_normalizer", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "f0_quantizer", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", ")", "->", "\"SpeechEncoder\"", ":", "\n", "        ", "\"\"\"Builds a SpeechEncoder instance by retrieving pre-trained dense and quantizer models specified by their parameters\n        (names and vocabulary size).\n\n        Args:\n            dense_model_name (str): Name of the dense module used to represent the audio\n            quantizer_model_name (str): Name of the quantizer module that converts dense representation into discrete tokens\n            vocab_size (int): Specifies the codebook size\n            deduplicate (bool): if set, run-length encoding is applied so that repeated tokens are deduplicated\n                and duration channel contains the number of repeats of the token.\n            add_bos_eos (bool, optional): if set, each token sequences will be prepended with a special token (bos)\n                and appended with another special token (eos).\n            need_f0 (bool, optional): whether F0 stream should be returned. Estimating F0 is computationally heavy,\n                consider disabling it if not needed.\n            f0_normalizer (Optional[Callable], optional): A callback that allows F0 normalization (e.g., per-speaker)\n            f0_quantizer (Optional[Callable], optional): F0 quantization module\n        \"\"\"", "\n", "dense_model", "=", "dispatch_dense_model", "(", "dense_model_name", ")", "\n", "quantizer_model", "=", "dispatch_quantizer", "(", "\n", "dense_model_name", ",", "quantizer_model_name", ",", "vocab_size", "\n", ")", "\n", "\n", "return", "cls", "(", "\n", "dense_model", ",", "\n", "quantizer_model", ",", "\n", "deduplicate", ",", "\n", "add_bos_eos", ",", "\n", "need_f0", ",", "\n", "f0_normalizer", ",", "\n", "f0_quantizer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.device": [[149, 156], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "\"\"\"\n        Returns:\n            torch.device: device where the speech encoder resides\n        \"\"\"", "\n", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.vocab_size": [[157, 164], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns:\n            int: vocabulary size used for the unit stream (NB: not counting bos/eos/pad tokens)\n        \"\"\"", "\n", "return", "self", ".", "quantizer_model", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.f0_code_ratio": [[165, 172], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "f0_code_ratio", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Returns:\n            float: F0 frames per unit frame\n        \"\"\"", "\n", "return", "self", ".", "code_hop_size", "/", "self", ".", "expected_sample_rate", "/", "F0_FRAME_SPACE", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.code_hop_size": [[173, 180], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "code_hop_size", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns:\n            int: hop step size of the dense model\n        \"\"\"", "\n", "return", "self", ".", "dense_model", ".", "code_hop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.expected_sample_rate": [[181, 187], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "expected_sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        int: sample rate expected by the underlying dense model\n        \"\"\"", "\n", "return", "self", ".", "dense_model", ".", "expected_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.maybe_resample": [[188, 207], ["torchaudio.functional.resample"], "methods", ["None"], ["", "def", "maybe_resample", "(", "\n", "self", ",", "waveform", ":", "torch", ".", "Tensor", ",", "input_sample_rate", ":", "int", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Takes a waveform and input rate and resamples it into the\n        sample rate expected by the encoder (and underlying dense model). Does nothing\n        if the sample rates coincide.\n        Args:\n            waveform (torch.Tensor): audio stream\n            input_sample_rate (int): sample rate of the original audio\n\n        Returns:\n            torch.Tensor: audio, potentially resampled to match the expected\n            sample rate of the encoder\n        \"\"\"", "\n", "if", "input_sample_rate", "==", "self", ".", "expected_sample_rate", ":", "\n", "            ", "return", "waveform", "\n", "", "return", "torchaudio", ".", "functional", ".", "resample", "(", "\n", "waveform", ",", "input_sample_rate", ",", "self", ".", "expected_sample_rate", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.forward": [[209, 255], ["speech_encoder.get_streams", "collater_utils.wrap_bos_eos", "units.to", "durations.to"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.get_streams", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.wrap_bos_eos"], ["", "def", "forward", "(", "\n", "self", ",", "waveform", ":", "torch", ".", "Tensor", ",", "speaker", ":", "Optional", "[", "str", "]", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Encodes a raw waveform tensor into two or three aligned & synchronised streams: pseudo-unit (token),\n        duration, and pitch aka F0 streams. F0 is only provided if the SpeechEncoder instance\n        was initialized with `requires_f0=True`.\n\n        Args:\n            waveform (torch.Tensor): audio to be encoded\n            speaker (Optional[str], optional): speaker id to be passed to the F0 normalizer.\n            Can be safely ignored if no F0 stream is requested or no per-speaker F0 normalizer\n            provided.\n\n        Returns:\n            Dict[str, torch.Tensor]: dictionary with the following keys:\n             * \"units\": contains an int tensor with the unit stream,\n             * \"durations\": duration of each unit, measured in frames,\n             * \"dense\": dense encoding of the audio, as provided by the underlying dense model,\n             * \"f0\": F0 stream - only returned if `requires_f0=True` was set in the constructor.\n        \"\"\"", "\n", "units", ",", "durations", ",", "f0", ",", "dense_features", "=", "get_streams", "(", "\n", "waveform", ",", "\n", "speaker", ",", "\n", "self", ".", "dense_model", ",", "\n", "self", ".", "quantizer_model", ",", "\n", "self", ".", "f0_normalizer", ",", "\n", "self", ".", "f0_quantizer", ",", "\n", "self", ".", "need_f0", ",", "\n", "self", ".", "deduplicate", ",", "\n", "self", ".", "f0_code_ratio", ",", "\n", ")", "\n", "\n", "if", "self", ".", "add_bos_eos", ":", "\n", "            ", "units", ",", "durations", ",", "f0", ",", "dense_features", "=", "wrap_bos_eos", "(", "\n", "units", ",", "durations", ",", "f0", ",", "dense_features", ",", "self", ".", "bos", ",", "self", ".", "eos", "\n", ")", "\n", "\n", "", "item", "=", "{", "\n", "\"units\"", ":", "units", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "\"durations\"", ":", "durations", ".", "to", "(", "self", ".", "device", ")", ",", "\n", "\"dense\"", ":", "dense_features", ",", "\n", "}", "\n", "if", "f0", "is", "not", "None", ":", "\n", "            ", "item", "[", "\"f0\"", "]", "=", "f0", "\n", "\n", "", "return", "item", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.get_streams": [[17, 53], ["dense_model", "quantizer_model", "waveform.mean.mean", "torch.unique_consecutive", "torch.unique_consecutive", "torch.ones_like", "torch.ones_like", "textless.data.f0_preprocess.get_f0", "torch.from_numpy().float", "torch.from_numpy().float", "textless.data.f0_preprocess.align_f0_to_durations", "waveform.mean.cpu().numpy", "f0_normalizer", "f0_quantizer", "torch.from_numpy", "torch.from_numpy", "waveform.mean.cpu"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.get_f0", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.align_f0_to_durations"], ["def", "get_streams", "(", "\n", "waveform", ",", "\n", "speaker", ",", "\n", "dense_model", ",", "\n", "quantizer_model", ",", "\n", "f0_normalizer", ",", "\n", "f0_quantizer", ",", "\n", "need_f0", ",", "\n", "deduplicate", ",", "\n", "f0_code_ratio", ",", "\n", ")", ":", "\n", "    ", "if", "waveform", ".", "ndim", ">", "1", ":", "\n", "        ", "waveform", "=", "waveform", ".", "mean", "(", "0", ")", "\n", "\n", "", "dense_features", "=", "dense_model", "(", "waveform", ")", "\n", "units", "=", "quantizer_model", "(", "dense_features", ")", "\n", "\n", "if", "deduplicate", ":", "\n", "        ", "units", ",", "durations", "=", "torch", ".", "unique_consecutive", "(", "units", ",", "return_counts", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "durations", "=", "torch", ".", "ones_like", "(", "units", ")", "\n", "\n", "", "if", "need_f0", ":", "\n", "        ", "f0", "=", "get_f0", "(", "waveform", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "f0", "=", "torch", ".", "from_numpy", "(", "f0", ")", ".", "float", "(", ")", "\n", "\n", "if", "f0_normalizer", ":", "\n", "            ", "f0", "=", "f0_normalizer", "(", "f0", ",", "speaker", ")", "\n", "", "tol", "=", "5", "*", "f0_code_ratio", "\n", "f0", "=", "align_f0_to_durations", "(", "f0", ",", "durations", ",", "f0_code_ratio", ",", "tol", ")", "\n", "if", "f0_quantizer", ":", "\n", "            ", "f0", "=", "f0_quantizer", "(", "f0", ")", "\n", "", "", "else", ":", "\n", "        ", "f0", "=", "None", "\n", "\n", "", "return", "units", ",", "durations", ",", "f0", ",", "dense_features", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.SpeakerMeanNormalize.__init__": [[66, 71], ["torch.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path_to_stats", ",", "center", "=", "True", ",", "scale", "=", "False", ",", "log", "=", "True", ")", ":", "\n", "        ", "self", ".", "stats", "=", "torch", ".", "load", "(", "path_to_stats", ")", "\n", "self", ".", "center", "=", "center", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "log", "=", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.SpeakerMeanNormalize.__call__": [[72, 95], ["f0.clone.clone.clone", "f0[].log"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "f0", ",", "speaker", ")", ":", "\n", "        ", "f0", "=", "f0", ".", "clone", "(", ")", "\n", "mask", "=", "f0", "!=", "0.0", "\n", "if", "self", ".", "log", ":", "\n", "            ", "f0", "[", "mask", "]", "=", "f0", "[", "mask", "]", ".", "log", "(", ")", "\n", "\n", "", "mean", "=", "(", "\n", "self", ".", "stats", "[", "speaker", "]", "[", "\"logf0_mean\"", "]", "\n", "if", "self", ".", "log", "\n", "else", "self", ".", "stats", "[", "speaker", "]", "[", "\"f0_mean\"", "]", "\n", ")", "\n", "std", "=", "(", "\n", "self", ".", "stats", "[", "speaker", "]", "[", "\"logf0_std\"", "]", "\n", "if", "self", ".", "log", "\n", "else", "self", ".", "stats", "[", "speaker", "]", "[", "\"f0_std\"", "]", "\n", ")", "\n", "\n", "if", "self", ".", "center", ":", "\n", "            ", "f0", "[", "mask", "]", "-=", "mean", "\n", "", "if", "self", ".", "scale", ":", "\n", "            ", "f0", "[", "mask", "]", "/=", "std", "\n", "\n", "", "return", "f0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.PromptNormalize.__init__": [[98, 102], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "center", "=", "True", ",", "scale", "=", "False", ",", "log", "=", "True", ")", ":", "\n", "        ", "self", ".", "center", "=", "center", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "log", "=", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.PromptNormalize.__call__": [[103, 115], ["f0.clone.clone.clone", "f0[].log", "f0[].mean", "f0[].std"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "f0", ",", "_speaker", "=", "None", ")", ":", "\n", "        ", "f0", "=", "f0", ".", "clone", "(", ")", "\n", "mask", "=", "f0", "!=", "0.0", "\n", "if", "self", ".", "log", ":", "\n", "            ", "f0", "[", "mask", "]", "=", "f0", "[", "mask", "]", ".", "log", "(", ")", "\n", "\n", "", "if", "self", ".", "center", ":", "\n", "            ", "f0", "[", "mask", "]", "-=", "f0", "[", "mask", "]", ".", "mean", "(", ")", "\n", "", "if", "self", ".", "scale", ":", "\n", "            ", "f0", "[", "mask", "]", "/=", "f0", "[", "mask", "]", ".", "std", "(", ")", "\n", "\n", "", "return", "f0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.F0BinQuantizer.__init__": [[118, 120], ["torch.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "bins_path", ")", ":", "\n", "        ", "self", ".", "bins", "=", "torch", ".", "load", "(", "bins_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.F0BinQuantizer.__call__": [[121, 124], ["f0.view", "f0_preprocess.F0BinQuantizer.bins.view"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "f0", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "bin_idx", "=", "(", "f0", ".", "view", "(", "-", "1", ",", "1", ")", ">", "self", ".", "bins", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "bin_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.get_f0": [[16, 33], ["numpy.pad", "amfm_decompy.SignalObj", "amfm_decompy.yaapt", "int", "librosa.util.normalize"], "function", ["None"], ["def", "get_f0", "(", "audio", ",", "rate", "=", "16_000", ")", ":", "\n", "    ", "assert", "audio", ".", "ndim", "==", "1", "\n", "frame_length", "=", "20.0", "# ms", "\n", "to_pad", "=", "int", "(", "frame_length", "/", "1000", "*", "rate", ")", "//", "2", "\n", "\n", "audio", "=", "normalize", "(", "audio", ")", "*", "0.95", "\n", "audio", "=", "np", ".", "pad", "(", "audio", ",", "(", "to_pad", ",", "to_pad", ")", ",", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "audio", "=", "basic", ".", "SignalObj", "(", "audio", ",", "rate", ")", "\n", "pitch", "=", "pYAAPT", ".", "yaapt", "(", "\n", "audio", ",", "\n", "frame_length", "=", "frame_length", ",", "\n", "frame_space", "=", "F0_FRAME_SPACE", "*", "1000", ",", "\n", "nccf_thresh1", "=", "0.25", ",", "\n", "tda_frame_length", "=", "25.0", ",", "\n", ")", "\n", "f0", "=", "pitch", ".", "samp_values", "\n", "return", "f0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.align_f0_to_durations": [[35, 63], ["durations.sum", "int", "torch.tensor", "torch.cat.size", "abs", "seg_f0s.append", "int", "torch.cat.size", "torch.cat.size", "torch.cat", "dur.item", "len", "torch.tensor().type", "seg_f0.mean.mean", "torch.cat.size", "durations.sum", "int", "int", "seg_f0.mean.type", "torch.cat.new_full", "torch.tensor"], "function", ["None"], ["", "def", "align_f0_to_durations", "(", "f0", ",", "durations", ",", "f0_code_ratio", ",", "tol", "=", "1", ")", ":", "\n", "    ", "code_len", "=", "durations", ".", "sum", "(", ")", "\n", "targ_len", "=", "int", "(", "f0_code_ratio", "*", "code_len", ")", "\n", "diff", "=", "f0", ".", "size", "(", "0", ")", "-", "targ_len", "\n", "assert", "abs", "(", "diff", ")", "<=", "tol", ",", "(", "\n", "f\"Cannot subsample F0: |{f0.size(0)} - {f0_code_ratio}*{code_len}|\"", "\n", "f\" > {tol} (dur=\\n{durations})\"", "\n", ")", "\n", "if", "diff", ">", "0", ":", "\n", "        ", "f0", "=", "f0", "[", ":", "targ_len", "]", "\n", "", "elif", "diff", "<", "0", ":", "\n", "        ", "f0", "=", "torch", ".", "cat", "(", "(", "f0", ",", "f0", ".", "new_full", "(", "(", "-", "diff", ",", ")", ",", "f0", "[", "-", "1", "]", ")", ")", ",", "0", ")", "\n", "\n", "", "f0_offset", "=", "0.0", "\n", "seg_f0s", "=", "[", "]", "\n", "for", "dur", "in", "durations", ":", "\n", "        ", "f0_dur", "=", "dur", ".", "item", "(", ")", "*", "f0_code_ratio", "\n", "seg_f0", "=", "f0", "[", "int", "(", "f0_offset", ")", ":", "int", "(", "f0_offset", "+", "f0_dur", ")", "]", "\n", "seg_f0", "=", "seg_f0", "[", "seg_f0", "!=", "0", "]", "\n", "if", "len", "(", "seg_f0", ")", "==", "0", ":", "\n", "            ", "seg_f0", "=", "torch", ".", "tensor", "(", "0", ")", ".", "type", "(", "seg_f0", ".", "type", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "seg_f0", "=", "seg_f0", ".", "mean", "(", ")", "\n", "", "seg_f0s", ".", "append", "(", "seg_f0", ")", "\n", "f0_offset", "+=", "f0_dur", "\n", "\n", "", "assert", "int", "(", "f0_offset", ")", "==", "f0", ".", "size", "(", "0", ")", ",", "f\"{f0_offset} {f0.size()} {durations.sum()}\"", "\n", "return", "torch", ".", "tensor", "(", "seg_f0s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.trailing_silence_mask": [[126, 135], ["f0.flip"], "function", ["None"], ["", "", "def", "trailing_silence_mask", "(", "f0", ")", ":", "\n", "    ", "\"\"\"\n    >>> f0 = torch.tensor([1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0])\n    >>> trailing_silence_mask(f0)\n    tensor([False, False, False, False,  True,  True,  True])\n    \"\"\"", "\n", "assert", "f0", ".", "ndim", "==", "1", "\n", "mask", "=", "(", "(", "f0", ".", "flip", "(", "0", ")", "!=", "0.0", ")", ".", "cumsum", "(", "0", ")", "==", "0", ")", ".", "flip", "(", "0", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.f0_preprocess.interpolate_f0": [[137, 147], ["numpy.arange", "ii.sum", "scipy.interpolate.interp1d"], "function", ["None"], ["", "def", "interpolate_f0", "(", "f0", ")", ":", "\n", "    ", "orig_t", "=", "np", ".", "arange", "(", "f0", ".", "shape", "[", "0", "]", ")", "\n", "f0_interp", "=", "f0", "[", ":", "]", "\n", "ii", "=", "f0_interp", "!=", "0", "\n", "if", "ii", ".", "sum", "(", ")", ">", "1", ":", "\n", "        ", "f0_interp", "=", "interp1d", "(", "\n", "orig_t", "[", "ii", "]", ",", "f0_interp", "[", "ii", "]", ",", "bounds_error", "=", "False", ",", "kind", "=", "\"linear\"", ",", "fill_value", "=", "0", "\n", ")", "(", "orig_t", ")", "\n", "# f0_interp = torch.Tensor(f0_interp).type_as(f0).to(f0.device)", "\n", "", "return", "f0_interp", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.collate_tensors": [[10, 29], ["max", "len", "stream[].new_full", "enumerate", "len", "v.size", "v.size"], "function", ["None"], ["def", "collate_tensors", "(", "stream", ",", "pad", ")", ":", "\n", "    ", "\"\"\"\n    >>> tensors = [torch.tensor(x) for x in [[1,2,3], [1]]]\n    >>> pad = 0\n    >>> collate_tensors(tensors, pad)\n    tensor([[1, 2, 3],\n        [1, 0, 0]])\n    \"\"\"", "\n", "assert", "len", "(", "stream", ")", ">", "0", "\n", "\n", "length", "=", "max", "(", "v", ".", "size", "(", "0", ")", "for", "v", "in", "stream", ")", "\n", "n_samples", "=", "len", "(", "stream", ")", "\n", "\n", "collated", "=", "stream", "[", "0", "]", ".", "new_full", "(", "(", "n_samples", ",", "length", ")", ",", "pad", ")", "\n", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "stream", ")", ":", "\n", "        ", "collated", "[", "i", ",", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", "\n", "\n", "", "return", "collated", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.wrap_bos_eos": [[31, 46], ["torch.cat", "torch.zeros_like", "torch.cat", "torch.zeros_like", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros_like", "torch.cat", "torch.cat.size", "torch.cat.size"], "function", ["None"], ["", "def", "wrap_bos_eos", "(", "units", ",", "durations", ",", "f0", ",", "dense", ",", "bos", ",", "eos", ")", ":", "\n", "    ", "assert", "units", ".", "size", "(", "0", ")", "==", "durations", ".", "size", "(", "0", ")", "==", "dense", ".", "size", "(", "0", ")", "\n", "if", "f0", "is", "not", "None", ":", "\n", "        ", "assert", "units", ".", "size", "(", "0", ")", "==", "f0", ".", "size", "(", "0", ")", "\n", "\n", "", "units", "=", "torch", ".", "cat", "(", "[", "bos", ",", "units", ",", "eos", "]", ")", "\n", "z", "=", "torch", ".", "zeros_like", "(", "durations", "[", "0", ":", "1", "]", ")", "\n", "durations", "=", "torch", ".", "cat", "(", "[", "z", ",", "durations", ",", "z", "]", ")", "\n", "if", "f0", "is", "not", "None", ":", "\n", "        ", "z", "=", "torch", ".", "zeros_like", "(", "f0", "[", "0", ":", "1", "]", ")", "\n", "f0", "=", "torch", ".", "cat", "(", "[", "z", ",", "f0", ",", "z", "]", ")", "\n", "", "z", "=", "torch", ".", "zeros_like", "(", "dense", "[", "0", ":", "1", ",", ":", "]", ")", "\n", "dense", "=", "torch", ".", "cat", "(", "[", "z", ",", "dense", ",", "z", "]", ")", "\n", "\n", "return", "units", ",", "durations", ",", "f0", ",", "dense", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.__init__": [[13, 28], ["super().__init__", "str", "hubert_feature_reader.HubertFeatureReader.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "hubert_feature_reader.HubertFeatureReader.load_checkpoint_"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.load_checkpoint_"], ["    ", "def", "__init__", "(", "\n", "self", ",", "checkpoint_path", ",", "layer", "=", "6", ",", "max_chunk", "=", "100", "*", "16_000", ",", "lazy_load", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# NB: fairseq doesn't support pathlib.Path", "\n", "self", ".", "checkpoint_path", "=", "str", "(", "checkpoint_path", ")", "\n", "self", ".", "should_normalize", "=", "False", "\n", "self", ".", "lazy_load", "=", "lazy_load", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "layer", "=", "layer", "\n", "self", ".", "max_chunk", "=", "max_chunk", "\n", "# this is useful for determining the device", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "if", "not", "self", ".", "lazy_load", ":", "\n", "            ", "self", ".", "load_checkpoint_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.load_checkpoint_": [[29, 40], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fairseq.checkpoint_utils.load_model_ensemble_and_task", "model[].eval", "hubert_feature_reader.HubertFeatureReader.model.to", "hubert_feature_reader.HubertFeatureReader.model.parameters", "parameter.requires_grad_"], "methods", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "# otherwise some non-leaf nodes appear which breaks serialization", "\n", "def", "load_checkpoint_", "(", "self", ")", ":", "\n", "        ", "model", ",", "_", ",", "task", "=", "fairseq", ".", "checkpoint_utils", ".", "load_model_ensemble_and_task", "(", "\n", "[", "self", ".", "checkpoint_path", "]", "\n", ")", "\n", "self", ".", "model", "=", "model", "[", "0", "]", ".", "eval", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "parameter", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "", "self", ".", "should_normalize", "=", "task", ".", "cfg", ".", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.device": [[41, 44], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.code_hop_size": [[45, 48], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "code_hop_size", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "320", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.expected_sample_rate": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "expected_sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "16_000", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.forward": [[53, 58], ["hubert_feature_reader.HubertFeatureReader.get_features", "hubert_feature_reader.HubertFeatureReader.load_checkpoint_"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.get_features", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.load_checkpoint_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "lazy_load", "and", "self", ".", "model", "is", "None", ":", "\n", "            ", "self", ".", "load_checkpoint_", "(", ")", "\n", "\n", "", "return", "self", ".", "get_features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.hubert_feature_reader.HubertFeatureReader.get_features": [[59, 77], ["torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.layer_norm.to", "torch.layer_norm.view", "range", "torch.cat().squeeze().cpu", "torch.cat().squeeze().cpu", "torch.cat().squeeze().cpu", "torch.cat().squeeze().cpu", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm.size", "hubert_feature_reader.HubertFeatureReader.model.extract_features", "feat.append", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.extract_features"], ["", "@", "torch", ".", "inference_mode", "(", ")", "\n", "def", "get_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "self", ".", "should_normalize", ":", "\n", "            ", "x", "=", "F", ".", "layer_norm", "(", "x", ",", "x", ".", "shape", ")", "\n", "", "x", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "feat", "=", "[", "]", "\n", "for", "start", "in", "range", "(", "0", ",", "x", ".", "size", "(", "1", ")", ",", "self", ".", "max_chunk", ")", ":", "\n", "            ", "x_chunk", "=", "x", "[", ":", ",", "start", ":", "start", "+", "self", ".", "max_chunk", "]", "\n", "feat_chunk", ",", "_", "=", "self", ".", "model", ".", "extract_features", "(", "\n", "source", "=", "x_chunk", ",", "\n", "padding_mask", "=", "None", ",", "\n", "mask", "=", "False", ",", "\n", "output_layer", "=", "self", ".", "layer", ",", "\n", ")", "\n", "feat", ".", "append", "(", "feat_chunk", ")", "\n", "", "return", "torch", ".", "cat", "(", "feat", ",", "1", ")", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.__init__": [[118, 170], ["torch.tensor", "max", "torch.cuda.current_device", "quantized_datasets.QuantizeDataset.speech_encoder.to", "torch.device", "quantized_datasets.QuantizeDataset.speech_encoder.to", "quantized_datasets.QuantizeDataset.speech_encoder.bos.item", "quantized_datasets.QuantizeDataset.speech_encoder.eos.item"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ":", "Dataset", ",", "\n", "speech_encoder", ":", "Callable", ",", "\n", "device", ":", "Optional", "[", "Union", "[", "str", ",", "torch", ".", "torch", ".", "device", "]", "]", "=", "None", ",", "\n", "speaker_extractor", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Wraps an arbitrary index-style PyTorch dataset and provides a \"textless\" quantized view of it.\n        It makes the following assumptions about `dataset[i]`:\n        * it returns a tuple where the first element is a raw waveform,\n        * all waveforms have the same sample rate as speech_encoder expects.\n\n        Args:\n            dataset (Dataset): Dataset to be wrapped\n            speech_encoder (Callable): SpeechEncoder to encode the audio\n            device (Optional[Union[str, torch.torch.device]], optional):\n                Sets a device to be used for encoding speech. If is set to None, torch.cuda.current_device() will be used.\n                When used in a dataloader with multiple workers, it might be useful to set `device` to \"auto\".\n                This way, on the first call of __getitem__(), the QuantizeDataset checks if it runs in a dataloader\n                worker. If this is the case, it will grab one of the available GPUs and place its copy of\n                SpeechEncoder there. This could be useful as SpeechEncoder is typically GPU-intensive and it is a good idea to parallelize\n                across multiple GPUs. Defaults to None.\n            speaker_extractor (Optional[Callable], optional): An optional callable that extracts speaker id from the\n            dataset[i] output. Only needed if speech_encoder uses per-speaker F0 normalization. Defaults to None.\n        \"\"\"", "\n", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "speech_encoder", "=", "speech_encoder", "\n", "\n", "self", ".", "randomize_device_on_next_call", "=", "False", "\n", "# TODO: allow specifying a list of allowed devices", "\n", "# this way we can preprocess and train a model on different GPUs.", "\n", "if", "device", "==", "\"auto\"", ":", "\n", "            ", "self", ".", "device", "=", "None", "\n", "self", ".", "randomize_device_on_next_call", "=", "True", "\n", "", "elif", "device", "is", "None", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "self", ".", "speech_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "speech_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "speaker_extractor", "=", "(", "\n", "speaker_extractor", "if", "speaker_extractor", "is", "not", "None", "else", "default_speaker_ls", "\n", ")", "\n", "\n", "self", ".", "unit_vocab_size", "=", "torch", ".", "tensor", "(", "[", "self", ".", "speech_encoder", ".", "vocab_size", "]", ")", "\n", "\n", "self", ".", "unit_pad", "=", "1", "+", "max", "(", "\n", "self", ".", "unit_vocab_size", "-", "1", ",", "\n", "self", ".", "speech_encoder", ".", "bos", ".", "item", "(", ")", ",", "\n", "self", ".", "speech_encoder", ".", "eos", ".", "item", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.__len__": [[172, 174], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.select_worker_gpu": [[175, 188], ["torch.utils.data.get_worker_info", "torch.cuda.current_device", "quantized_datasets.QuantizeDataset.speech_encoder.to", "torch.cuda.set_device", "torch.cuda.current_device", "quantized_datasets.QuantizeDataset.speech_encoder.cuda", "torch.cuda.device_count"], "methods", ["None"], ["", "def", "select_worker_gpu", "(", "self", ")", ":", "\n", "        ", "worker_info", "=", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "# not a worker process", "\n", "            ", "self", ".", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "self", ".", "speech_encoder", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "# we are in a worker process, we'll assign ourselves", "\n", "# to a random GPU among available", "\n", "            ", "worker_id", "=", "worker_info", ".", "id", "\n", "device_id", "=", "worker_id", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "self", ".", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "self", ".", "speech_encoder", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.__getitem__": [[189, 215], ["quantized_datasets.QuantizeDataset.speaker_extractor", "quantized_datasets.QuantizeDataset.speech_encoder", "quantized_datasets.QuantizeDataset.items", "quantized_datasets.QuantizeDataset.select_worker_gpu", "waveform.to", "isinstance", "v.cpu"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.select_worker_gpu"], ["", "", "def", "__getitem__", "(", "self", ",", "k", ":", "int", ")", "->", "Dict", "[", "str", ",", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"Returns \"texless\" representation of the k-th element of the wrapped dataset in\n        a form of aligned unit, durarion, and (optionally) F0 streams.\n        Args:\n            k (int): example index.\n        Returns:\n            Dict[str, Union[torch.Tensor, Any]]: A dict that has contains\n            speech_encoder(waveform) outputs and the remainder of what\n            the underlying dataset returned under the \"rest\" key.\n            All tensors are placed on CPU.\n        \"\"\"", "\n", "waveform", ",", "*", "rest", "=", "self", ".", "dataset", "[", "k", "]", "\n", "\n", "if", "self", ".", "randomize_device_on_next_call", "and", "self", ".", "device", "is", "None", ":", "\n", "            ", "self", ".", "select_worker_gpu", "(", ")", "\n", "self", ".", "randomize_device_on_next_call", "=", "False", "\n", "\n", "", "speaker", "=", "self", ".", "speaker_extractor", "(", "rest", ")", "\n", "encoded", "=", "self", ".", "speech_encoder", "(", "waveform", ".", "to", "(", "self", ".", "device", ")", ",", "speaker", ")", "\n", "# dataset", "\n", "for", "k", ",", "v", "in", "encoded", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "encoded", "[", "k", "]", "=", "v", ".", "cpu", "(", ")", "\n", "", "", "encoded", "[", "\"rest\"", "]", "=", "rest", "\n", "\n", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizeDataset.collater": [[216, 257], ["textless.data.collater_utils.collate_tensors", "textless.data.collater_utils.collate_tensors", "len", "[].size", "max", "torch.zeros", "enumerate", "len", "textless.data.collater_utils.collate_tensors", "s[].size", "_slice", "torch.zeros_like", "s[].size", "range", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.collate_tensors", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.collate_tensors", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.collater_utils.collate_tensors"], ["", "def", "collater", "(", "self", ",", "samples", ":", "List", "[", "Any", "]", ")", ":", "\n", "        ", "\"\"\"Collater utility for using QuantizeDataset within a DataLoader.\n        Args:\n            samples (_type_): Samples to collate.\n\n        Returns:\n            Dict[str, Union[Any, torch.Tensor]: Per-stream collated samples.\n            The unit stream is padded with QuantizeDataset.unit_pad while other streams are padded\n            with zeros. The non-audio parts of the samples (i.e. those that are in\n            sample[\"rest\"]) are not collated and are returned as-is under the \"rest\" key.\n        \"\"\"", "\n", "units", "=", "collate_tensors", "(", "[", "s", "[", "\"units\"", "]", "for", "s", "in", "samples", "]", ",", "pad", "=", "self", ".", "unit_pad", ")", "\n", "if", "\"f0\"", "in", "samples", "[", "0", "]", ":", "\n", "            ", "f0", "=", "collate_tensors", "(", "\n", "[", "s", "[", "\"f0\"", "]", "for", "s", "in", "samples", "]", ",", "pad", "=", "torch", ".", "zeros_like", "(", "samples", "[", "0", "]", "[", "\"f0\"", "]", "[", "0", "]", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "f0", "=", "None", "\n", "", "durations", "=", "collate_tensors", "(", "\n", "[", "s", "[", "\"durations\"", "]", "for", "s", "in", "samples", "]", ",", "\n", "pad", "=", "torch", ".", "zeros_like", "(", "samples", "[", "0", "]", "[", "\"durations\"", "]", "[", "0", "]", ")", ",", "\n", ")", "\n", "\n", "bsz", "=", "len", "(", "samples", ")", "\n", "dense_dim", "=", "samples", "[", "0", "]", "[", "\"dense\"", "]", ".", "size", "(", "1", ")", "\n", "max_len", "=", "max", "(", "s", "[", "\"dense\"", "]", ".", "size", "(", "0", ")", "for", "s", "in", "samples", ")", "\n", "\n", "dense", "=", "torch", ".", "zeros", "(", "(", "bsz", ",", "max_len", ",", "dense_dim", ")", ")", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "l", "=", "s", "[", "\"dense\"", "]", ".", "size", "(", "0", ")", "\n", "dense", "[", "i", ",", ":", "l", ",", ":", "]", "=", "s", "[", "\"dense\"", "]", "\n", "\n", "", "n_rest", "=", "len", "(", "samples", "[", "0", "]", "[", "\"rest\"", "]", ")", "\n", "_slice", "=", "lambda", "i", ":", "[", "s", "[", "\"rest\"", "]", "[", "i", "]", "for", "s", "in", "samples", "]", "\n", "\n", "rest", "=", "[", "_slice", "(", "i", ")", "for", "i", "in", "range", "(", "n_rest", ")", "]", "\n", "\n", "result", "=", "{", "\"units\"", ":", "units", ",", "\"durations\"", ":", "durations", ",", "\"dense\"", ":", "dense", ",", "\"rest\"", ":", "rest", "}", "\n", "if", "f0", "is", "not", "None", ":", "\n", "            ", "result", "[", "\"f0\"", "]", "=", "(", "f0", ",", ")", "\n", "", "return", "result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedLibriSpeech": [[26, 37], ["torchaudio.datasets.LIBRISPEECH", "quantized_datasets.QuantizeDataset"], "function", ["None"], ["def", "QuantizedLibriSpeech", "(", "\n", "speech_encoder", ":", "Callable", ",", "\n", "root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "\n", "url", ":", "str", "=", "\"train-clean-100\"", ",", "\n", "folder_in_archive", ":", "str", "=", "\"LibriSpeech\"", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "LIBRISPEECH", "(", "root", ",", "url", ",", "folder_in_archive", ",", "download", ")", "\n", "return", "QuantizeDataset", "(", "\n", "dataset", ",", "speech_encoder", ",", "device", ",", "speaker_extractor", "=", "default_speaker_ls", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.default_speaker_ls": [[40, 42], ["str"], "function", ["None"], ["", "def", "default_speaker_ls", "(", "rest", ")", ":", "\n", "    ", "return", "str", "(", "rest", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedLjSpeech": [[44, 54], ["torchaudio.datasets.LJSPEECH", "quantized_datasets.QuantizeDataset"], "function", ["None"], ["", "def", "QuantizedLjSpeech", "(", "\n", "speech_encoder", ":", "Callable", ",", "\n", "root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "\n", "url", ":", "str", "=", "\"https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\"", ",", "\n", "folder_in_archive", ":", "str", "=", "\"wavs\"", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "LJSPEECH", "(", "root", ",", "url", ",", "folder_in_archive", ",", "download", ")", "\n", "return", "QuantizeDataset", "(", "dataset", ",", "speech_encoder", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedCommonVoice": [[57, 66], ["torchaudio.datasets.COMMONVOICE", "quantized_datasets.QuantizeDataset"], "function", ["None"], ["", "def", "QuantizedCommonVoice", "(", "\n", "speech_encoder", ":", "Callable", ",", "\n", "root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "\n", "tsv", ":", "Optional", "[", "str", "]", "=", "\"train.tsv\"", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "COMMONVOICE", "(", "root", ",", "tsv", ")", "\n", "return", "QuantizeDataset", "(", "\n", "dataset", ",", "speech_encoder", ",", "device", ",", "speaker_extractor", "=", "default_speaker_commonvoice", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.default_speaker_commonvoice": [[69, 71], ["None"], "function", ["None"], ["", "def", "default_speaker_commonvoice", "(", "rest", ")", ":", "\n", "    ", "return", "rest", "[", "\"client_id\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedVCTK_092": [[73, 87], ["torchaudio.datasets.VCTK_092", "quantized_datasets.QuantizeDataset"], "function", ["None"], ["", "def", "QuantizedVCTK_092", "(", "\n", "speech_encoder", ":", "Callable", ",", "\n", "root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "\n", "mic_id", ":", "Optional", "[", "str", "]", "=", "\"mic2\"", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", "url", ":", "Optional", "[", "\n", "str", "\n", "]", "=", "\"https://datashare.is.ed.ac.uk/bitstream/handle/10283/3443/VCTK-Corpus-0.92.zip\"", ",", "\n", "audio_ext", "=", "\".flac\"", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "VCTK_092", "(", "root", ",", "mic_id", ",", "download", ",", "url", ",", "audio_ext", ")", "\n", "return", "QuantizeDataset", "(", "\n", "dataset", ",", "speech_encoder", ",", "device", ",", "speaker_extractor", "=", "default_speaker_vctk", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.default_speaker_vctk": [[90, 92], ["None"], "function", ["None"], ["", "def", "default_speaker_vctk", "(", "rest", ")", ":", "\n", "    ", "return", "rest", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedYesNo": [[94, 105], ["torchaudio.datasets.YESNO", "quantized_datasets.QuantizeDataset"], "function", ["None"], ["", "def", "QuantizedYesNo", "(", "\n", "speech_encoder", ":", "Callable", ",", "\n", "root", ":", "Union", "[", "str", ",", "pathlib", ".", "Path", "]", ",", "\n", "url", ":", "str", "=", "\"http://www.openslr.org/resources/1/waves_yesno.tar.gz\"", ",", "\n", "folder_in_archive", ":", "str", "=", "\"waves_yesno\"", ",", "\n", "download", ":", "bool", "=", "False", ",", "\n", "device", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "YESNO", "(", "root", ",", "url", ",", "folder_in_archive", ",", "download", ")", "\n", "return", "QuantizeDataset", "(", "\n", "dataset", ",", "speech_encoder", ",", "device", ",", "speaker_extractor", "=", "no_speaker", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.no_speaker": [[108, 115], ["None"], "function", ["None"], ["", "def", "no_speaker", "(", "_", ")", ":", "\n", "    ", "\"\"\"\n    The dataset doesn't provide speaker information; please\n    use speaker-independent F0 normalization.\n    \"\"\"", "\n", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.__init__": [[12, 27], ["super().__init__", "cpc_feature_reader.CpcFeatureReader.load_cpc_model().eval", "cpc_feature_reader.CpcFeatureReader.load_cpc_model"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.load_cpc_model"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "checkpoint_path", ",", "\n", "layer", "=", "2", ",", "\n", "use_encoder_layer", "=", "False", ",", "\n", "norm_features", "=", "False", ",", "\n", "max_chunk", "=", "64000", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "self", ".", "load_cpc_model", "(", "checkpoint_path", ",", "layer", ")", ".", "eval", "(", ")", "\n", "self", ".", "max_chunk", "=", "max_chunk", "\n", "self", ".", "norm_features", "=", "norm_features", "\n", "self", ".", "use_encoder_layer", "=", "use_encoder_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.forward": [[28, 30], ["cpc_feature_reader.CpcFeatureReader.get_features"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.get_features"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "get_features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.get_features": [[31, 60], ["torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "torch.inference_mode", "x.view.view.view", "x.view.view.size", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "cpc_feature_reader.CpcFeatureReader.model.extract_features", "feat.append", "cpc_feature_reader.CpcFeatureReader.model.extract_features", "feat.append", "x_chunk.size", "cpc_feature_reader.CpcFeatureReader.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.extract_features", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.extract_features"], ["", "@", "torch", ".", "inference_mode", "(", ")", "\n", "def", "get_features", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "size", "=", "x", ".", "size", "(", "2", ")", "\n", "feat", "=", "[", "]", "\n", "start", "=", "0", "\n", "while", "start", "<", "size", ":", "\n", "            ", "if", "start", "+", "self", ".", "max_chunk", ">", "size", ":", "\n", "                ", "break", "\n", "", "x_chunk", "=", "x", "[", "...", ",", "start", ":", "start", "+", "self", ".", "max_chunk", "]", "\n", "feat_chunk", "=", "self", ".", "model", ".", "extract_features", "(", "\n", "source", "=", "x_chunk", ",", "\n", "get_encoded", "=", "self", ".", "use_encoder_layer", ",", "\n", "norm_output", "=", "self", ".", "norm_features", ",", "\n", ")", "\n", "feat", ".", "append", "(", "feat_chunk", ")", "\n", "start", "+=", "self", ".", "max_chunk", "\n", "\n", "", "if", "start", "<", "size", ":", "\n", "            ", "x_chunk", "=", "x", "[", ":", ",", "-", "self", ".", "max_chunk", ":", "]", "\n", "feat_chunk", "=", "self", ".", "model", ".", "extract_features", "(", "\n", "source", "=", "x_chunk", ",", "\n", "get_encoded", "=", "self", ".", "use_encoder_layer", ",", "\n", "norm_output", "=", "self", ".", "norm_features", ",", "\n", ")", "\n", "df", "=", "x_chunk", ".", "size", "(", "2", ")", "//", "feat_chunk", ".", "size", "(", "1", ")", "\n", "delta", "=", "(", "size", "-", "start", ")", "//", "df", "\n", "feat", ".", "append", "(", "feat_chunk", "[", ":", ",", "-", "delta", ":", "]", ")", "\n", "", "return", "torch", ".", "cat", "(", "feat", ",", "1", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.code_hop_size": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "code_hop_size", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "160", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.expected_sample_rate": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "expected_sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "16_000", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CpcFeatureReader.load_cpc_model": [[69, 87], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "cpc_feature_reader.CPCEncoder", "cpc_feature_reader.CPCAR", "cpc_feature_reader.CPCModel", "CPCModel.load_state_dict"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_cpc_model", "(", "checkpoint_path", ":", "str", ",", "layer", ":", "int", "=", "2", ")", "->", "torch", ".", "nn", ".", "Module", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "weights", "=", "state_dict", "[", "\"weights\"", "]", "\n", "config", "=", "state_dict", "[", "\"config\"", "]", "\n", "if", "layer", "is", "not", "None", ":", "\n", "            ", "config", "[", "\"nLevelsGRU\"", "]", "=", "layer", "\n", "\n", "", "encoder", "=", "CPCEncoder", "(", "config", "[", "\"hiddenEncoder\"", "]", ")", "\n", "ar_net", "=", "CPCAR", "(", "\n", "config", "[", "\"hiddenEncoder\"", "]", ",", "config", "[", "\"hiddenGar\"", "]", ",", "False", ",", "config", "[", "\"nLevelsGRU\"", "]", "\n", ")", "\n", "\n", "model", "=", "CPCModel", "(", "encoder", ",", "ar_net", ")", "\n", "model", ".", "load_state_dict", "(", "weights", ",", "strict", "=", "False", ")", "\n", "model", ".", "config", "=", "config", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.ChannelNorm.__init__": [[90, 102], ["torch.Module.__init__", "cpc_feature_reader.ChannelNorm.reset_parameters", "torch.parameter.Parameter", "torch.parameter.Parameter", "torch.parameter.Parameter", "torch.parameter.Parameter", "torch.parameter.Parameter", "torch.parameter.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.ChannelNorm.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "epsilon", "=", "1e-05", ",", "affine", "=", "True", ")", ":", "\n", "        ", "super", "(", "ChannelNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "affine", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "parameter", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "num_features", ",", "1", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "parameter", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "num_features", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight", "=", "None", "\n", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "p", "=", "0", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.ChannelNorm.reset_parameters": [[103, 107], ["torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "affine", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.ChannelNorm.forward": [[108, 115], ["x.mean", "x.var", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "cum_mean", "=", "x", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "cum_var", "=", "x", ".", "var", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "cum_mean", ")", "*", "torch", ".", "rsqrt", "(", "cum_var", "+", "self", ".", "epsilon", ")", "\n", "if", "self", ".", "weight", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "*", "self", ".", "weight", "+", "self", ".", "bias", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCEncoder.__init__": [[118, 131], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cpc_feature_reader.ChannelNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cpc_feature_reader.ChannelNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cpc_feature_reader.ChannelNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cpc_feature_reader.ChannelNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "cpc_feature_reader.ChannelNorm"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_dim", "=", "512", ")", ":", "\n", "        ", "super", "(", "CPCEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv0", "=", "nn", ".", "Conv1d", "(", "1", ",", "hidden_dim", ",", "10", ",", "stride", "=", "5", ",", "padding", "=", "3", ")", "\n", "self", ".", "batchNorm0", "=", "ChannelNorm", "(", "hidden_dim", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "hidden_dim", ",", "hidden_dim", ",", "8", ",", "stride", "=", "4", ",", "padding", "=", "2", ")", "\n", "self", ".", "batchNorm1", "=", "ChannelNorm", "(", "hidden_dim", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "hidden_dim", ",", "hidden_dim", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "batchNorm2", "=", "ChannelNorm", "(", "hidden_dim", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv1d", "(", "hidden_dim", ",", "hidden_dim", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "batchNorm3", "=", "ChannelNorm", "(", "hidden_dim", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv1d", "(", "hidden_dim", ",", "hidden_dim", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "batchNorm4", "=", "ChannelNorm", "(", "hidden_dim", ")", "\n", "self", ".", "DOWNSAMPLING", "=", "160", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCEncoder.get_output_dim": [[132, 134], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "conv4", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCEncoder.forward": [[135, 142], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "cpc_feature_reader.CPCEncoder.batchNorm0", "cpc_feature_reader.CPCEncoder.batchNorm1", "cpc_feature_reader.CPCEncoder.batchNorm2", "cpc_feature_reader.CPCEncoder.batchNorm3", "cpc_feature_reader.CPCEncoder.batchNorm4", "cpc_feature_reader.CPCEncoder.conv0", "cpc_feature_reader.CPCEncoder.conv1", "cpc_feature_reader.CPCEncoder.conv2", "cpc_feature_reader.CPCEncoder.conv3", "cpc_feature_reader.CPCEncoder.conv4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "batchNorm0", "(", "self", ".", "conv0", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "batchNorm1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "batchNorm2", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "batchNorm3", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "batchNorm4", "(", "self", ".", "conv4", "(", "x", ")", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCAR.__init__": [[145, 152], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim_encoded", ",", "dim_output", ",", "keep_hidden", ",", "num_layers", ")", ":", "\n", "        ", "super", "(", "CPCAR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "baseNet", "=", "nn", ".", "LSTM", "(", "\n", "dim_encoded", ",", "dim_output", ",", "num_layers", "=", "num_layers", ",", "batch_first", "=", "True", "\n", ")", "\n", "self", ".", "hidden", "=", "None", "\n", "self", ".", "keep_hidden", "=", "keep_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCAR.get_output_dim": [[153, 155], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "baseNet", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCAR.forward": [[156, 168], ["cpc_feature_reader.CPCAR.baseNet", "cpc_feature_reader.CPCAR.baseNet.flatten_parameters", "isinstance", "tuple", "h.detach", "x.detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "baseNet", ".", "flatten_parameters", "(", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "pass", "\n", "", "x", ",", "h", "=", "self", ".", "baseNet", "(", "x", ",", "self", ".", "hidden", ")", "\n", "if", "self", ".", "keep_hidden", ":", "\n", "            ", "if", "isinstance", "(", "h", ",", "tuple", ")", ":", "\n", "                ", "self", ".", "hidden", "=", "tuple", "(", "x", ".", "detach", "(", ")", "for", "x", "in", "h", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "hidden", "=", "h", ".", "detach", "(", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.__init__": [[171, 176], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "ar_net", ")", ":", "\n", "        ", "super", "(", "CPCModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gEncoder", "=", "encoder", "\n", "self", ".", "gAR", "=", "ar_net", "\n", "self", ".", "config", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.forward": [[177, 181], ["cpc_feature_reader.CPCModel.gEncoder().permute", "cpc_feature_reader.CPCModel.gAR", "cpc_feature_reader.CPCModel.gEncoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "label", ")", ":", "\n", "        ", "encoded", "=", "self", ".", "gEncoder", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "cpc_feature", "=", "self", ".", "gAR", "(", "encoded", ")", "\n", "return", "cpc_feature", ",", "encoded", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.cpc_feature_reader.CPCModel.extract_features": [[182, 191], ["cpc_feature_reader.CPCModel.forward", "cpc_feature.mean", "cpc_feature.var", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.forward"], ["", "def", "extract_features", "(", "self", ",", "source", ",", "get_encoded", "=", "False", ",", "norm_output", "=", "False", ")", ":", "\n", "        ", "cpc_feature", ",", "encoded", ",", "_", "=", "self", ".", "forward", "(", "source", ",", "None", ")", "\n", "if", "get_encoded", ":", "\n", "            ", "cpc_feature", "=", "encoded", "\n", "", "if", "norm_output", ":", "\n", "            ", "mean", "=", "cpc_feature", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "var", "=", "cpc_feature", ".", "var", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "cpc_feature", "=", "(", "cpc_feature", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "var", "+", "1e-08", ")", "\n", "", "return", "cpc_feature", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.__init__": [[12, 16], ["super().__init__", "kmeans_quantizer.KMeansQuantizer.register_buffer", "kmeans_quantizer.KMeansQuantizer.load_kmeans_model", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.load_kmeans_model"], ["    ", "def", "__init__", "(", "self", ",", "checkpoint_path", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "self", ".", "kmeans_model", "=", "self", ".", "load_kmeans_model", "(", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.forward": [[17, 20], ["torch.from_numpy().to", "torch.from_numpy", "kmeans_quantizer.KMeansQuantizer.kmeans_model.predict", "x.cpu().numpy", "x.cpu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "from_numpy", "(", "self", ".", "kmeans_model", ".", "predict", "(", "x", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ".", "to", "(", "\n", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.vocab_size": [[22, 25], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "kmeans_model", ".", "n_clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.device": [[26, 29], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.kmeans_quantizer.KMeansQuantizer.load_kmeans_model": [[30, 43], ["open", "warnings.catch_warnings", "warnings.simplefilter", "joblib.load", "hasattr"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_kmeans_model", "(", "checkpoint_path", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "checkpoint_path", ",", "\"rb\"", ")", "as", "fd", ":", "\n", "            ", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "# produces lots of version warnings which can be annoying when we have many workers", "\n", "                ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ")", "\n", "kmeans_model", "=", "joblib", ".", "load", "(", "fd", ")", "\n", "# some of the GSLM checkpoints (CPC) were saved under a different scikit version", "\n", "if", "not", "hasattr", "(", "kmeans_model", ",", "\"_n_threads\"", ")", ":", "\n", "                    ", "kmeans_model", ".", "_n_threads", "=", "40", "\n", "\n", "", "", "", "kmeans_model", ".", "verbose", "=", "False", "\n", "return", "kmeans_model", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.expand_abbreviations": [[65, 69], ["re.sub"], "function", ["None"], ["def", "expand_abbreviations", "(", "text", ")", ":", "\n", "  ", "for", "regex", ",", "replacement", "in", "_abbreviations", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "regex", ",", "replacement", ",", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.expand_numbers": [[71, 73], ["numbers.normalize_numbers"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers.normalize_numbers"], ["", "def", "expand_numbers", "(", "text", ")", ":", "\n", "  ", "return", "normalize_numbers", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.lowercase": [[75, 77], ["text.lower"], "function", ["None"], ["", "def", "lowercase", "(", "text", ")", ":", "\n", "  ", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.collapse_whitespace": [[79, 81], ["re.sub"], "function", ["None"], ["", "def", "collapse_whitespace", "(", "text", ")", ":", "\n", "  ", "return", "re", ".", "sub", "(", "_whitespace_re", ",", "' '", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.convert_to_ascii": [[83, 85], ["unidecode.unidecode"], "function", ["None"], ["", "def", "convert_to_ascii", "(", "text", ")", ":", "\n", "  ", "return", "unidecode", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.basic_cleaners": [[87, 92], ["cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.lowercase", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.collapse_whitespace"], ["", "def", "basic_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Basic pipeline that lowercases and collapses whitespace without transliteration.'''", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.transliteration_cleaners": [[94, 100], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.lowercase", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.collapse_whitespace"], ["", "def", "transliteration_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Pipeline for non-English text that transliterates to ASCII.'''", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.english_cleaners": [[102, 110], ["cleaners.convert_to_ascii", "cleaners.lowercase", "cleaners.expand_numbers", "cleaners.expand_abbreviations", "cleaners.collapse_whitespace"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.convert_to_ascii", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.lowercase", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.expand_numbers", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.expand_abbreviations", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cleaners.collapse_whitespace"], ["", "def", "english_cleaners", "(", "text", ")", ":", "\n", "  ", "'''Pipeline for English text, including number and abbreviation expansion.'''", "\n", "text", "=", "convert_to_ascii", "(", "text", ")", "\n", "text", "=", "lowercase", "(", "text", ")", "\n", "text", "=", "expand_numbers", "(", "text", ")", "\n", "text", "=", "expand_abbreviations", "(", "text", ")", "\n", "text", "=", "collapse_whitespace", "(", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.__init__": [[19, 44], ["torch.Module.__init__", "vocoder.load_tacotron", "vocoder.load_waveglow_standalone", "tts_data.TacotronInputDataset", "vocoder.TacotronVocoder.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.__init__.load_tacotron", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.load_waveglow_standalone"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tacotron_model_path", ":", "str", ",", "\n", "tacotron_dict_path", ":", "str", ",", "\n", "waveglow_path", ":", "str", ",", "\n", "max_decoder_steps", ":", "int", "=", "2000", ",", "\n", "denoiser_strength", ":", "float", "=", "0.1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_decoder_steps", "=", "max_decoder_steps", "\n", "self", ".", "denoiser_strength", "=", "denoiser_strength", "\n", "(", "\n", "self", ".", "tacotron_model", ",", "\n", "self", ".", "tacotron_sample_rate", ",", "\n", "self", ".", "tacotron_hparams", ",", "\n", ")", "=", "load_tacotron", "(", "\n", "tacotron_model_path", "=", "tacotron_model_path", ",", "\n", "code_dict_path", "=", "tacotron_dict_path", ",", "\n", "max_decoder_steps", "=", "self", ".", "max_decoder_steps", ",", "\n", ")", "\n", "self", ".", "waveglow_model", ",", "self", ".", "denoiser_model", "=", "load_waveglow_standalone", "(", "\n", "waveglow_path", "=", "waveglow_path", ",", "\n", ")", "\n", "self", ".", "tts_dataset", "=", "TacotronInputDataset", "(", "self", ".", "tacotron_hparams", ")", "\n", "self", ".", "register_buffer", "(", "\"_float_tensor\"", ",", "torch", ".", "tensor", "(", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.forward": [[45, 61], ["isinstance", "vocoder.TacotronVocoder.tts_dataset.get_tensor", "tts_input.to.to.to", "vocoder.synthesize_audio", "tts_input.to.to.unsqueeze", "str", "units.cpu().tolist", "units.cpu"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.get_tensor", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.__init__.synthesize_audio"], ["", "def", "forward", "(", "self", ",", "units", ":", "Union", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "isinstance", "(", "units", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "units_str", "=", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "units", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "units_str", "=", "units", "\n", "", "tts_input", "=", "self", ".", "tts_dataset", ".", "get_tensor", "(", "units_str", ")", "\n", "tts_input", "=", "tts_input", ".", "to", "(", "self", ".", "device", ")", "\n", "_", ",", "_", ",", "aud_dn", ",", "_", "=", "synthesize_audio", "(", "\n", "self", ".", "tacotron_model", ",", "\n", "self", ".", "waveglow_model", ",", "\n", "self", ".", "denoiser_model", ",", "\n", "tts_input", ".", "unsqueeze", "(", "0", ")", ",", "\n", "strength", "=", "self", ".", "denoiser_strength", ",", "\n", ")", "\n", "out_audio", "=", "aud_dn", "[", "0", "]", "\n", "return", "out_audio", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name": [[62, 89], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "cls"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["", "@", "classmethod", "\n", "def", "by_name", "(", "\n", "cls", ",", "\n", "dense_model_name", ":", "str", ",", "\n", "quantizer_model_name", ":", "str", ",", "\n", "vocab_size", ":", "int", ",", "\n", "max_decoder_steps", ":", "int", "=", "2000", ",", "\n", "denoiser_strength", ":", "float", "=", "0.1", ",", "\n", ")", ":", "\n", "        ", "waveglow_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "\"waveglow\"", ")", "\n", "\n", "tacotron_checkpoint_name", "=", "(", "\n", "f\"{dense_model_name}-{quantizer_model_name}-{vocab_size}-tacotron\"", "\n", ")", "\n", "tacotron_checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "\n", "tacotron_checkpoint_name", "\n", ")", "\n", "\n", "checkpoint_codes_name", "=", "f\"{tacotron_checkpoint_name}-codes\"", "\n", "tacotron_codes_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "checkpoint_codes_name", ")", "\n", "\n", "return", "cls", "(", "\n", "tacotron_checkpoint_path", ",", "\n", "tacotron_codes_path", ",", "\n", "waveglow_path", ",", "\n", "max_decoder_steps", ",", "\n", "denoiser_strength", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device": [[91, 94], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "device", "(", "self", ")", "->", "torch", ".", "device", ":", "\n", "        ", "return", "self", ".", "_float_tensor", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.output_sample_rate": [[95, 98], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tacotron_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.synthesize_audio": [[100, 115], ["inp.size", "torch.LongTensor().fill_", "torch.LongTensor().fill_", "torch.inference_mode", "torch.inference_mode", "model.inference", "waveglow.infer", "denoiser().squeeze", "next", "inp.to", "mel.float", "torch.LongTensor", "torch.LongTensor", "model.parameters", "torch.LongTensor().fill_.to", "denoiser", "waveglow.infer.half"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.inference", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.infer"], ["", "", "def", "synthesize_audio", "(", "model", ",", "waveglow", ",", "denoiser", ",", "inp", ",", "lab", "=", "None", ",", "strength", "=", "0.0", ")", ":", "\n", "    ", "assert", "inp", ".", "size", "(", "0", ")", "==", "1", "\n", "if", "lab", "is", "not", "None", ":", "\n", "        ", "lab", "=", "torch", ".", "LongTensor", "(", "1", ")", ".", "fill_", "(", "lab", ")", "\n", "\n", "", "with", "torch", ".", "inference_mode", "(", ")", ":", "\n", "        ", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "_", ",", "mel", ",", "_", ",", "ali", ",", "has_eos", "=", "model", ".", "inference", "(", "\n", "inp", ".", "to", "(", "model_device", ")", ",", "\n", "lab", ".", "to", "(", "model_device", ")", "if", "lab", "is", "not", "None", "else", "None", ",", "\n", "ret_has_eos", "=", "True", ",", "\n", ")", "\n", "aud", "=", "waveglow", ".", "infer", "(", "mel", ".", "float", "(", ")", ",", "sigma", "=", "0.666", ")", "\n", "aud_dn", "=", "denoiser", "(", "aud", ".", "half", "(", ")", ",", "strength", "=", "strength", ")", ".", "squeeze", "(", "1", ")", "\n", "", "return", "mel", ",", "aud", ",", "aud_dn", ",", "has_eos", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.load_tacotron": [[117, 128], ["torch.load", "torch.load", "model.Tacotron2", "model.eval.load_state_dict", "model.eval.half", "model.eval.eval", "torch.device", "torch.device"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device"], ["", "def", "load_tacotron", "(", "tacotron_model_path", ",", "code_dict_path", ",", "max_decoder_steps", ")", ":", "\n", "    ", "ckpt_dict", "=", "torch", ".", "load", "(", "tacotron_model_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "hparams", "=", "ckpt_dict", "[", "\"hparams\"", "]", "\n", "hparams", ".", "code_dict", "=", "code_dict_path", "\n", "hparams", ".", "max_decoder_steps", "=", "max_decoder_steps", "\n", "sr", "=", "hparams", ".", "sampling_rate", "\n", "model", "=", "Tacotron2", "(", "hparams", ")", "\n", "model", ".", "load_state_dict", "(", "ckpt_dict", "[", "\"model_dict\"", "]", ")", "\n", "model", "=", "model", ".", "half", "(", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "return", "model", ",", "sr", ",", "hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.load_waveglow_standalone": [[130, 140], ["torch.load", "torch.load", "glow.WaveGlow", "waveglow.to.load_state_dict", "waveglow.to.eval", "waveglow.to.to", "waveglow_denoiser.Denoiser", "denoiser.eval.eval", "torch.device", "torch.device"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device"], ["", "def", "load_waveglow_standalone", "(", "waveglow_path", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "ckpt_dict", "=", "torch", ".", "load", "(", "waveglow_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "hparams", "=", "ckpt_dict", "[", "\"hparams\"", "]", "\n", "waveglow", "=", "WaveGlow", "(", "**", "hparams", ")", "\n", "waveglow", ".", "load_state_dict", "(", "ckpt_dict", "[", "\"model_dict\"", "]", ")", "\n", "waveglow", "=", "waveglow", ".", "eval", "(", ")", "\n", "waveglow", "=", "waveglow", ".", "to", "(", "device", ")", "\n", "denoiser", "=", "Denoiser", "(", "waveglow", ")", "\n", "denoiser", "=", "denoiser", ".", "eval", "(", ")", "\n", "return", "waveglow", ",", "denoiser", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.text_to_sequence": [[39, 65], ["len", "_curly_re.match", "text._symbols_to_sequence", "text._arpabet_to_sequence", "_curly_re.match.group", "text._symbols_to_sequence", "text._clean_text", "_curly_re.match.group", "text._clean_text", "_curly_re.match.group"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._symbols_to_sequence", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._arpabet_to_sequence", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._symbols_to_sequence", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._clean_text", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._clean_text"], ["def", "text_to_sequence", "(", "text", ",", "cleaner_names", ")", ":", "\n", "  ", "'''Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\n\n    The text can optionally have ARPAbet sequences enclosed in curly braces embedded\n    in it. For example, \"Turn left on {HH AW1 S S T AH0 N} Street.\"\n\n    Args:\n      text: string to convert to a sequence\n      cleaner_names: names of the cleaner functions to run the text through\n\n    Returns:\n      List of integers corresponding to the symbols in the text\n  '''", "\n", "sequence", "=", "[", "]", "\n", "\n", "# Check for curly braces and treat their contents as ARPAbet:", "\n", "while", "len", "(", "text", ")", ":", "\n", "    ", "m", "=", "_curly_re", ".", "match", "(", "text", ")", "\n", "if", "not", "m", ":", "\n", "      ", "sequence", "+=", "_symbols_to_sequence", "(", "_clean_text", "(", "text", ",", "cleaner_names", ")", ")", "\n", "break", "\n", "", "sequence", "+=", "_symbols_to_sequence", "(", "_clean_text", "(", "m", ".", "group", "(", "1", ")", ",", "cleaner_names", ")", ")", "\n", "sequence", "+=", "_arpabet_to_sequence", "(", "m", ".", "group", "(", "2", ")", ")", "\n", "text", "=", "m", ".", "group", "(", "3", ")", "\n", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.sample_code_chunk": [[67, 72], ["numpy.random.randint", "len", "len"], "function", ["None"], ["", "def", "sample_code_chunk", "(", "code", ",", "size", ")", ":", "\n", "    ", "assert", "(", "size", ">", "0", "and", "size", "<=", "len", "(", "code", ")", ")", "\n", "start", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "code", ")", "-", "size", "+", "1", ")", "\n", "end", "=", "start", "+", "size", "\n", "return", "code", "[", "start", ":", "end", "]", ",", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.code_to_sequence": [[74, 88], ["len", "print", "sequence.append", "len"], "function", ["None"], ["", "def", "code_to_sequence", "(", "code", ",", "code_dict", ",", "collapse_code", ")", ":", "\n", "    ", "if", "collapse_code", ":", "\n", "        ", "prev_c", "=", "None", "\n", "sequence", "=", "[", "]", "\n", "for", "c", "in", "code", ":", "\n", "            ", "if", "c", "in", "code_dict", "and", "c", "!=", "prev_c", ":", "\n", "                ", "sequence", ".", "append", "(", "code_dict", "[", "c", "]", ")", "\n", "prev_c", "=", "c", "\n", "", "", "", "else", ":", "\n", "        ", "sequence", "=", "[", "code_dict", "[", "c", "]", "for", "c", "in", "code", "if", "c", "in", "code_dict", "]", "\n", "if", "len", "(", "sequence", ")", "<", "0.95", "*", "len", "(", "code", ")", ":", "\n", "            ", "print", "(", "'WARNING : over 5%% codes are OOV'", ")", "\n", "\n", "", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.sequence_to_text": [[90, 101], ["result.replace", "len"], "function", ["None"], ["", "def", "sequence_to_text", "(", "sequence", ")", ":", "\n", "  ", "'''Converts a sequence of IDs back to a string'''", "\n", "result", "=", "''", "\n", "for", "symbol_id", "in", "sequence", ":", "\n", "    ", "if", "symbol_id", "in", "_id_to_symbol", ":", "\n", "      ", "s", "=", "_id_to_symbol", "[", "symbol_id", "]", "\n", "# Enclose ARPAbet back in curly braces:", "\n", "if", "len", "(", "s", ")", ">", "1", "and", "s", "[", "0", "]", "==", "'@'", ":", "\n", "        ", "s", "=", "'{%s}'", "%", "s", "[", "1", ":", "]", "\n", "", "result", "+=", "s", "\n", "", "", "return", "result", ".", "replace", "(", "'}{'", ",", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.sequence_to_code": [[103, 107], ["code_dict.items"], "function", ["None"], ["", "def", "sequence_to_code", "(", "sequence", ",", "code_dict", ")", ":", "\n", "    ", "'''Analogous to sequence_to_text'''", "\n", "id_to_code", "=", "{", "i", ":", "c", "for", "c", ",", "i", "in", "code_dict", ".", "items", "(", ")", "}", "\n", "return", "' '", ".", "join", "(", "[", "id_to_code", "[", "i", "]", "for", "i", "in", "sequence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._clean_text": [[109, 116], ["getattr", "getattr.", "Exception"], "function", ["None"], ["", "def", "_clean_text", "(", "text", ",", "cleaner_names", ")", ":", "\n", "  ", "for", "name", "in", "cleaner_names", ":", "\n", "    ", "cleaner", "=", "getattr", "(", "cleaners", ",", "name", ")", "\n", "if", "not", "cleaner", ":", "\n", "      ", "raise", "Exception", "(", "'Unknown cleaner: %s'", "%", "name", ")", "\n", "", "text", "=", "cleaner", "(", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._symbols_to_sequence": [[118, 120], ["text._should_keep_symbol"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._should_keep_symbol"], ["", "def", "_symbols_to_sequence", "(", "symbols", ")", ":", "\n", "  ", "return", "[", "_symbol_to_id", "[", "s", "]", "for", "s", "in", "symbols", "if", "_should_keep_symbol", "(", "s", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._arpabet_to_sequence": [[122, 124], ["text._symbols_to_sequence", "text.split"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._symbols_to_sequence"], ["", "def", "_arpabet_to_sequence", "(", "text", ")", ":", "\n", "  ", "return", "_symbols_to_sequence", "(", "[", "'@'", "+", "s", "for", "s", "in", "text", ".", "split", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text._should_keep_symbol": [[126, 128], ["None"], "function", ["None"], ["", "def", "_should_keep_symbol", "(", "s", ")", ":", "\n", "  ", "return", "s", "in", "_symbol_to_id", "and", "s", "!=", "'_'", "and", "s", "!=", "'~'", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers._remove_commas": [[36, 38], ["m.group().replace", "m.group"], "function", ["None"], ["def", "_remove_commas", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "','", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers._expand_decimal_point": [[40, 42], ["m.group().replace", "m.group"], "function", ["None"], ["", "def", "_expand_decimal_point", "(", "m", ")", ":", "\n", "  ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "'.'", ",", "' point '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers._expand_dollars": [[44, 63], ["m.group", "m.group.split", "len", "int", "int", "len"], "function", ["None"], ["", "def", "_expand_dollars", "(", "m", ")", ":", "\n", "  ", "match", "=", "m", ".", "group", "(", "1", ")", "\n", "parts", "=", "match", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "parts", ")", ">", "2", ":", "\n", "    ", "return", "match", "+", "' dollars'", "# Unexpected format", "\n", "", "dollars", "=", "int", "(", "parts", "[", "0", "]", ")", "if", "parts", "[", "0", "]", "else", "0", "\n", "cents", "=", "int", "(", "parts", "[", "1", "]", ")", "if", "len", "(", "parts", ")", ">", "1", "and", "parts", "[", "1", "]", "else", "0", "\n", "if", "dollars", "and", "cents", ":", "\n", "    ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s, %s %s'", "%", "(", "dollars", ",", "dollar_unit", ",", "cents", ",", "cent_unit", ")", "\n", "", "elif", "dollars", ":", "\n", "    ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "return", "'%s %s'", "%", "(", "dollars", ",", "dollar_unit", ")", "\n", "", "elif", "cents", ":", "\n", "    ", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s'", "%", "(", "cents", ",", "cent_unit", ")", "\n", "", "else", ":", "\n", "    ", "return", "'zero dollars'", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers._expand_ordinal": [[65, 67], ["_inflect.number_to_words", "m.group"], "function", ["None"], ["", "", "def", "_expand_ordinal", "(", "m", ")", ":", "\n", "  ", "return", "_inflect", ".", "number_to_words", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers._expand_number": [[69, 82], ["int", "m.group", "_inflect.number_to_words", "_inflect.number_to_words", "_inflect.number_to_words().replace", "_inflect.number_to_words", "_inflect.number_to_words"], "function", ["None"], ["", "def", "_expand_number", "(", "m", ")", ":", "\n", "  ", "num", "=", "int", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "if", "num", ">", "1000", "and", "num", "<", "3000", ":", "\n", "    ", "if", "num", "==", "2000", ":", "\n", "      ", "return", "'two thousand'", "\n", "", "elif", "num", ">", "2000", "and", "num", "<", "2010", ":", "\n", "      ", "return", "'two thousand '", "+", "_inflect", ".", "number_to_words", "(", "num", "%", "100", ")", "\n", "", "elif", "num", "%", "100", "==", "0", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", "//", "100", ")", "+", "' hundred'", "\n", "", "else", ":", "\n", "      ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ",", "zero", "=", "'oh'", ",", "group", "=", "2", ")", ".", "replace", "(", "', '", ",", "' '", ")", "\n", "", "", "else", ":", "\n", "    ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.numbers.normalize_numbers": [[84, 92], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["None"], ["", "", "def", "normalize_numbers", "(", "text", ")", ":", "\n", "  ", "text", "=", "re", ".", "sub", "(", "_comma_number_re", ",", "_remove_commas", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_pounds_re", ",", "r'\\1 pounds'", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_dollars_re", ",", "_expand_dollars", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_decimal_number_re", ",", "_expand_decimal_point", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_ordinal_re", ",", "_expand_ordinal", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_number_re", ",", "_expand_number", ",", "text", ")", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlowLoss.__init__": [[44, 47], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sigma", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "WaveGlowLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlowLoss.forward": [[48, 60], ["enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "z.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "z.size", "z.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "model_output", ")", ":", "\n", "        ", "z", ",", "log_s_list", ",", "log_det_W_list", "=", "model_output", "\n", "for", "i", ",", "log_s", "in", "enumerate", "(", "log_s_list", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "log_s_total", "=", "torch", ".", "sum", "(", "log_s", ")", "\n", "log_det_W_total", "=", "log_det_W_list", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "log_s_total", "=", "log_s_total", "+", "torch", ".", "sum", "(", "log_s", ")", "\n", "log_det_W_total", "+=", "log_det_W_list", "[", "i", "]", "\n", "\n", "", "", "loss", "=", "torch", ".", "sum", "(", "z", "*", "z", ")", "/", "(", "2", "*", "self", ".", "sigma", "*", "self", ".", "sigma", ")", "-", "log_s_total", "-", "log_det_W_total", "\n", "return", "loss", "/", "(", "z", ".", "size", "(", "0", ")", "*", "z", ".", "size", "(", "1", ")", "*", "z", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.Invertible1x1Conv.__init__": [[68, 81], ["super().__init__", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "W.view.view.view", "torch.linalg.qr", "torch.linalg.qr", "torch.linalg.qr", "torch.linalg.qr", "torch.det", "torch.det", "torch.det", "torch.det", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "c", ")", ":", "\n", "        ", "super", "(", "Invertible1x1Conv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Conv1d", "(", "c", ",", "c", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", "\n", "\n", "# Sample a random orthonormal matrix to initialize weights", "\n", "W", "=", "torch", ".", "linalg", ".", "qr", "(", "torch", ".", "FloatTensor", "(", "c", ",", "c", ")", ".", "normal_", "(", ")", ")", "[", "0", "]", "\n", "\n", "# Ensure determinant is 1.0 not -1.0", "\n", "if", "torch", ".", "det", "(", "W", ")", "<", "0", ":", "\n", "            ", "W", "[", ":", ",", "0", "]", "=", "-", "1", "*", "W", "[", ":", ",", "0", "]", "\n", "", "W", "=", "W", ".", "view", "(", "c", ",", "c", ",", "1", ")", "\n", "self", ".", "conv", ".", "weight", ".", "data", "=", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.Invertible1x1Conv.forward": [[82, 103], ["glow.Invertible1x1Conv.size", "glow.Invertible1x1Conv.conv.weight.squeeze", "torch.conv1d", "torch.conv1d", "glow.Invertible1x1Conv.conv", "hasattr", "glow.Invertible1x1Conv.float().inverse", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.logdet", "torch.logdet", "torch.logdet", "torch.logdet", "glow.Invertible1x1Conv.type", "W_inverse.half.half.half", "W_inverse.half.half.detach", "glow.Invertible1x1Conv.float"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse"], ["", "def", "forward", "(", "self", ",", "z", ",", "reverse", "=", "False", ")", ":", "\n", "# shape", "\n", "        ", "batch_size", ",", "group_size", ",", "n_of_groups", "=", "z", ".", "size", "(", ")", "\n", "\n", "W", "=", "self", ".", "conv", ".", "weight", ".", "squeeze", "(", ")", "\n", "\n", "if", "reverse", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ",", "'W_inverse'", ")", ":", "\n", "# Reverse computation", "\n", "                ", "W_inverse", "=", "W", ".", "float", "(", ")", ".", "inverse", "(", ")", "\n", "W_inverse", "=", "Variable", "(", "W_inverse", "[", "...", ",", "None", "]", ")", "\n", "if", "z", ".", "type", "(", ")", "==", "'torch.cuda.HalfTensor'", ":", "\n", "                    ", "W_inverse", "=", "W_inverse", ".", "half", "(", ")", "\n", "", "self", ".", "W_inverse", "=", "torch", ".", "nn", ".", "Parameter", "(", "W_inverse", ".", "detach", "(", ")", ")", "\n", "", "z", "=", "F", ".", "conv1d", "(", "z", ",", "self", ".", "W_inverse", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "return", "z", "\n", "", "else", ":", "\n", "# Forward computation", "\n", "            ", "log_det_W", "=", "batch_size", "*", "n_of_groups", "*", "torch", ".", "logdet", "(", "W", ")", "\n", "z", "=", "self", ".", "conv", "(", "z", ")", "\n", "return", "z", ",", "log_det_W", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WN.__init__": [[111, 152], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d.weight.data.zero_", "torch.nn.Conv1d.weight.data.zero_", "torch.nn.Conv1d.bias.data.zero_", "torch.nn.Conv1d.bias.data.zero_", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "range", "int", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "glow.WN.in_layers.append", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "torch.nn.utils.weight_norm", "glow.WN.res_skip_layers.append"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "n_in_channels", ",", "n_mel_channels", ",", "n_layers", ",", "n_channels", ",", "\n", "kernel_size", ")", ":", "\n", "        ", "super", "(", "WN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "kernel_size", "%", "2", "==", "1", ")", "\n", "assert", "(", "n_channels", "%", "2", "==", "0", ")", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "in_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "res_skip_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "start", "=", "torch", ".", "nn", ".", "Conv1d", "(", "n_in_channels", ",", "n_channels", ",", "1", ")", "\n", "start", "=", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "start", ",", "name", "=", "'weight'", ")", "\n", "self", ".", "start", "=", "start", "\n", "\n", "# Initializing last layer to 0 makes the affine coupling layers", "\n", "# do nothing at first.  This helps with training stability", "\n", "end", "=", "torch", ".", "nn", ".", "Conv1d", "(", "n_channels", ",", "2", "*", "n_in_channels", ",", "1", ")", "\n", "end", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "end", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "end", "=", "end", "\n", "\n", "cond_layer", "=", "torch", ".", "nn", ".", "Conv1d", "(", "n_mel_channels", ",", "2", "*", "n_channels", "*", "n_layers", ",", "1", ")", "\n", "self", ".", "cond_layer", "=", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "cond_layer", ",", "name", "=", "'weight'", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "i", "\n", "padding", "=", "int", "(", "(", "kernel_size", "*", "dilation", "-", "dilation", ")", "/", "2", ")", "\n", "in_layer", "=", "torch", ".", "nn", ".", "Conv1d", "(", "n_channels", ",", "2", "*", "n_channels", ",", "kernel_size", ",", "\n", "dilation", "=", "dilation", ",", "padding", "=", "padding", ")", "\n", "in_layer", "=", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "in_layer", ",", "name", "=", "'weight'", ")", "\n", "self", ".", "in_layers", ".", "append", "(", "in_layer", ")", "\n", "\n", "\n", "# last one is not necessary", "\n", "if", "i", "<", "n_layers", "-", "1", ":", "\n", "                ", "res_skip_channels", "=", "2", "*", "n_channels", "\n", "", "else", ":", "\n", "                ", "res_skip_channels", "=", "n_channels", "\n", "", "res_skip_layer", "=", "torch", ".", "nn", ".", "Conv1d", "(", "n_channels", ",", "res_skip_channels", ",", "1", ")", "\n", "res_skip_layer", "=", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "res_skip_layer", ",", "name", "=", "'weight'", ")", "\n", "self", ".", "res_skip_layers", ".", "append", "(", "res_skip_layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WN.forward": [[153, 176], ["glow.WN.start", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.IntTensor", "torch.IntTensor", "torch.IntTensor", "torch.IntTensor", "glow.WN.cond_layer", "range", "glow.WN.end", "glow.fused_add_tanh_sigmoid_multiply"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.start", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.fused_add_tanh_sigmoid_multiply"], ["", "", "def", "forward", "(", "self", ",", "forward_input", ")", ":", "\n", "        ", "audio", ",", "spect", "=", "forward_input", "\n", "audio", "=", "self", ".", "start", "(", "audio", ")", "\n", "output", "=", "torch", ".", "zeros_like", "(", "audio", ")", "\n", "n_channels_tensor", "=", "torch", ".", "IntTensor", "(", "[", "self", ".", "n_channels", "]", ")", "\n", "\n", "spect", "=", "self", ".", "cond_layer", "(", "spect", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "spect_offset", "=", "i", "*", "2", "*", "self", ".", "n_channels", "\n", "acts", "=", "fused_add_tanh_sigmoid_multiply", "(", "\n", "self", ".", "in_layers", "[", "i", "]", "(", "audio", ")", ",", "\n", "spect", "[", ":", ",", "spect_offset", ":", "spect_offset", "+", "2", "*", "self", ".", "n_channels", ",", ":", "]", ",", "\n", "n_channels_tensor", ")", "\n", "\n", "res_skip_acts", "=", "self", ".", "res_skip_layers", "[", "i", "]", "(", "acts", ")", "\n", "if", "i", "<", "self", ".", "n_layers", "-", "1", ":", "\n", "                ", "audio", "=", "audio", "+", "res_skip_acts", "[", ":", ",", ":", "self", ".", "n_channels", ",", ":", "]", "\n", "output", "=", "output", "+", "res_skip_acts", "[", ":", ",", "self", ".", "n_channels", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "output", "=", "output", "+", "res_skip_acts", "\n", "\n", "", "", "return", "self", ".", "end", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.__init__": [[179, 206], ["super().__init__", "torch.nn.ConvTranspose1d", "torch.nn.ConvTranspose1d", "torch.nn.ConvTranspose1d", "torch.nn.ConvTranspose1d", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "int", "range", "glow.WaveGlow.convinv.append", "glow.WaveGlow.WN.append", "glow.Invertible1x1Conv", "glow.WN", "int"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_mel_channels", ",", "n_flows", ",", "n_group", ",", "n_early_every", ",", "\n", "n_early_size", ",", "WN_config", ")", ":", "\n", "        ", "super", "(", "WaveGlow", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "upsample", "=", "torch", ".", "nn", ".", "ConvTranspose1d", "(", "n_mel_channels", ",", "\n", "n_mel_channels", ",", "\n", "1024", ",", "stride", "=", "256", ")", "\n", "assert", "(", "n_group", "%", "2", "==", "0", ")", "\n", "self", ".", "n_flows", "=", "n_flows", "\n", "self", ".", "n_group", "=", "n_group", "\n", "self", ".", "n_early_every", "=", "n_early_every", "\n", "self", ".", "n_early_size", "=", "n_early_size", "\n", "self", ".", "WN", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "convinv", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "n_half", "=", "int", "(", "n_group", "/", "2", ")", "\n", "\n", "# Set up layers with the right sizes based on how many dimensions", "\n", "# have been output already", "\n", "n_remaining_channels", "=", "n_group", "\n", "for", "k", "in", "range", "(", "n_flows", ")", ":", "\n", "            ", "if", "k", "%", "self", ".", "n_early_every", "==", "0", "and", "k", ">", "0", ":", "\n", "                ", "n_half", "=", "n_half", "-", "int", "(", "self", ".", "n_early_size", "/", "2", ")", "\n", "n_remaining_channels", "=", "n_remaining_channels", "-", "self", ".", "n_early_size", "\n", "", "self", ".", "convinv", ".", "append", "(", "Invertible1x1Conv", "(", "n_remaining_channels", ")", ")", "\n", "self", ".", "WN", ".", "append", "(", "WN", "(", "n_half", ",", "n_mel_channels", "*", "n_group", ",", "**", "WN_config", ")", ")", "\n", "", "self", ".", "n_remaining_channels", "=", "n_remaining_channels", "# Useful during inference", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.forward": [[207, 250], ["glow.WaveGlow.upsample", "spect.contiguous().view().permute.contiguous().view().permute.unfold().permute", "spect.contiguous().view().permute.contiguous().view().permute.contiguous().view().permute", "torch.cat.unfold().permute", "torch.cat.unfold().permute", "range", "output_audio.append", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.cat.size", "torch.cat.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.cat.size", "torch.cat.size", "log_det_W_list.append", "int", "log_s_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "spect.contiguous().view().permute.contiguous().view().permute.unfold", "spect.contiguous().view().permute.contiguous().view().permute.contiguous().view", "torch.cat.unfold", "torch.cat.unfold", "output_audio.append", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.cat.size", "torch.cat.size", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat.size", "torch.cat.size", "spect.contiguous().view().permute.contiguous().view().permute.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "forward_input", ")", ":", "\n", "        ", "\"\"\"\n        forward_input[0] = mel_spectrogram:  batch x n_mel_channels x frames\n        forward_input[1] = audio: batch x time\n        \"\"\"", "\n", "spect", ",", "audio", "=", "forward_input", "\n", "\n", "#  Upsample spectrogram to size of audio", "\n", "spect", "=", "self", ".", "upsample", "(", "spect", ")", "\n", "assert", "(", "spect", ".", "size", "(", "2", ")", ">=", "audio", ".", "size", "(", "1", ")", ")", "\n", "if", "spect", ".", "size", "(", "2", ")", ">", "audio", ".", "size", "(", "1", ")", ":", "\n", "            ", "spect", "=", "spect", "[", ":", ",", ":", ",", ":", "audio", ".", "size", "(", "1", ")", "]", "\n", "\n", "", "spect", "=", "spect", ".", "unfold", "(", "2", ",", "self", ".", "n_group", ",", "self", ".", "n_group", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "spect", "=", "spect", ".", "contiguous", "(", ")", ".", "view", "(", "spect", ".", "size", "(", "0", ")", ",", "spect", ".", "size", "(", "1", ")", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "audio", "=", "audio", ".", "unfold", "(", "1", ",", "self", ".", "n_group", ",", "self", ".", "n_group", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output_audio", "=", "[", "]", "\n", "log_s_list", "=", "[", "]", "\n", "log_det_W_list", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "self", ".", "n_flows", ")", ":", "\n", "            ", "if", "k", "%", "self", ".", "n_early_every", "==", "0", "and", "k", ">", "0", ":", "\n", "                ", "output_audio", ".", "append", "(", "audio", "[", ":", ",", ":", "self", ".", "n_early_size", ",", ":", "]", ")", "\n", "audio", "=", "audio", "[", ":", ",", "self", ".", "n_early_size", ":", ",", ":", "]", "\n", "\n", "", "audio", ",", "log_det_W", "=", "self", ".", "convinv", "[", "k", "]", "(", "audio", ")", "\n", "log_det_W_list", ".", "append", "(", "log_det_W", ")", "\n", "\n", "n_half", "=", "int", "(", "audio", ".", "size", "(", "1", ")", "/", "2", ")", "\n", "audio_0", "=", "audio", "[", ":", ",", ":", "n_half", ",", ":", "]", "\n", "audio_1", "=", "audio", "[", ":", ",", "n_half", ":", ",", ":", "]", "\n", "\n", "output", "=", "self", ".", "WN", "[", "k", "]", "(", "(", "audio_0", ",", "spect", ")", ")", "\n", "log_s", "=", "output", "[", ":", ",", "n_half", ":", ",", ":", "]", "\n", "b", "=", "output", "[", ":", ",", ":", "n_half", ",", ":", "]", "\n", "audio_1", "=", "torch", ".", "exp", "(", "log_s", ")", "*", "audio_1", "+", "b", "\n", "log_s_list", ".", "append", "(", "log_s", ")", "\n", "\n", "audio", "=", "torch", ".", "cat", "(", "[", "audio_0", ",", "audio_1", "]", ",", "1", ")", "\n", "\n", "", "output_audio", ".", "append", "(", "audio", ")", "\n", "return", "torch", ".", "cat", "(", "output_audio", ",", "1", ")", ",", "log_s_list", ",", "log_det_W_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.infer": [[251, 300], ["glow.WaveGlow.upsample", "spect.contiguous().view().permute.contiguous().view().permute.unfold().permute", "spect.contiguous().view().permute.contiguous().view().permute.contiguous().view().permute", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "reversed", "spect.contiguous().view().permute.contiguous().view().permute.type", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "range", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.permute().contiguous().view", "torch.cat.permute().contiguous().view", "spect.contiguous().view().permute.contiguous().view().permute.unfold", "spect.contiguous().view().permute.contiguous().view().permute.contiguous().view", "spect.contiguous().view().permute.contiguous().view().permute.type", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cat.size", "torch.cat.size", "spect.contiguous().view().permute.contiguous().view().permute.type", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "spect.contiguous().view().permute.contiguous().view().permute.contiguous", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "spect.contiguous().view().permute.contiguous().view().permute.type", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.HalfTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cat.permute", "torch.cat.permute", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.HalfTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size", "spect.contiguous().view().permute.contiguous().view().permute.size"], "methods", ["None"], ["", "def", "infer", "(", "self", ",", "spect", ",", "sigma", "=", "1.0", ")", ":", "\n", "        ", "spect", "=", "self", ".", "upsample", "(", "spect", ")", "\n", "# trim conv artifacts. maybe pad spec to kernel multiple", "\n", "time_cutoff", "=", "self", ".", "upsample", ".", "kernel_size", "[", "0", "]", "-", "self", ".", "upsample", ".", "stride", "[", "0", "]", "\n", "spect", "=", "spect", "[", ":", ",", ":", ",", ":", "-", "time_cutoff", "]", "\n", "\n", "spect", "=", "spect", ".", "unfold", "(", "2", ",", "self", ".", "n_group", ",", "self", ".", "n_group", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "spect", "=", "spect", ".", "contiguous", "(", ")", ".", "view", "(", "spect", ".", "size", "(", "0", ")", ",", "spect", ".", "size", "(", "1", ")", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "if", "spect", ".", "type", "(", ")", "==", "'torch.FloatTensor'", ":", "\n", "            ", "audio", "=", "torch", ".", "FloatTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "n_remaining_channels", ",", "\n", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "", "elif", "spect", ".", "type", "(", ")", "==", "'torch.cuda.HalfTensor'", ":", "\n", "            ", "audio", "=", "torch", ".", "cuda", ".", "HalfTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "n_remaining_channels", ",", "\n", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "", "else", ":", "\n", "            ", "audio", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "n_remaining_channels", ",", "\n", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "\n", "", "audio", "=", "torch", ".", "autograd", ".", "Variable", "(", "sigma", "*", "audio", ")", "\n", "\n", "for", "k", "in", "reversed", "(", "range", "(", "self", ".", "n_flows", ")", ")", ":", "\n", "            ", "n_half", "=", "int", "(", "audio", ".", "size", "(", "1", ")", "/", "2", ")", "\n", "audio_0", "=", "audio", "[", ":", ",", ":", "n_half", ",", ":", "]", "\n", "audio_1", "=", "audio", "[", ":", ",", "n_half", ":", ",", ":", "]", "\n", "\n", "output", "=", "self", ".", "WN", "[", "k", "]", "(", "(", "audio_0", ",", "spect", ")", ")", "\n", "\n", "s", "=", "output", "[", ":", ",", "n_half", ":", ",", ":", "]", "\n", "b", "=", "output", "[", ":", ",", ":", "n_half", ",", ":", "]", "\n", "audio_1", "=", "(", "audio_1", "-", "b", ")", "/", "torch", ".", "exp", "(", "s", ")", "\n", "audio", "=", "torch", ".", "cat", "(", "[", "audio_0", ",", "audio_1", "]", ",", "1", ")", "\n", "\n", "audio", "=", "self", ".", "convinv", "[", "k", "]", "(", "audio", ",", "reverse", "=", "True", ")", "\n", "\n", "if", "k", "%", "self", ".", "n_early_every", "==", "0", "and", "k", ">", "0", ":", "\n", "                ", "if", "spect", ".", "type", "(", ")", "==", "'torch.FloatTensor'", ":", "\n", "                    ", "z", "=", "torch", ".", "FloatTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "self", ".", "n_early_size", ",", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "", "elif", "spect", ".", "type", "(", ")", "==", "'torch.cuda.HalfTensor'", ":", "\n", "                    ", "z", "=", "torch", ".", "cuda", ".", "HalfTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "self", ".", "n_early_size", ",", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "spect", ".", "size", "(", "0", ")", ",", "self", ".", "n_early_size", ",", "spect", ".", "size", "(", "2", ")", ")", ".", "normal_", "(", ")", "\n", "", "audio", "=", "torch", ".", "cat", "(", "(", "sigma", "*", "z", ",", "audio", ")", ",", "1", ")", "\n", "\n", "", "", "audio", "=", "audio", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "audio", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "data", "\n", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.remove_weightnorm": [[301, 310], ["torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "glow.remove", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "glow.remove"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.remove", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.remove"], ["", "@", "staticmethod", "\n", "def", "remove_weightnorm", "(", "model", ")", ":", "\n", "        ", "waveglow", "=", "model", "\n", "for", "WN", "in", "waveglow", ".", "WN", ":", "\n", "            ", "WN", ".", "start", "=", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "WN", ".", "start", ")", "\n", "WN", ".", "in_layers", "=", "remove", "(", "WN", ".", "in_layers", ")", "\n", "WN", ".", "cond_layer", "=", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "WN", ".", "cond_layer", ")", "\n", "WN", ".", "res_skip_layers", "=", "remove", "(", "WN", ".", "res_skip_layers", ")", "\n", "", "return", "waveglow", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.fused_add_tanh_sigmoid_multiply": [[33, 41], ["torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["@", "torch", ".", "jit", ".", "script", "\n", "def", "fused_add_tanh_sigmoid_multiply", "(", "input_a", ",", "input_b", ",", "n_channels", ")", ":", "\n", "    ", "n_channels_int", "=", "n_channels", "[", "0", "]", "\n", "in_act", "=", "input_a", "+", "input_b", "\n", "t_act", "=", "torch", ".", "tanh", "(", "in_act", "[", ":", ",", ":", "n_channels_int", ",", ":", "]", ")", "\n", "s_act", "=", "torch", ".", "sigmoid", "(", "in_act", "[", ":", ",", "n_channels_int", ":", ",", ":", "]", ")", "\n", "acts", "=", "t_act", "*", "s_act", "\n", "return", "acts", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.remove": [[312, 318], ["torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.utils.remove_weight_norm", "torch.nn.utils.remove_weight_norm", "torch.nn.ModuleList.append"], "function", ["None"], ["", "", "def", "remove", "(", "conv_list", ")", ":", "\n", "    ", "new_conv_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "old_conv", "in", "conv_list", ":", "\n", "        ", "old_conv", "=", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "old_conv", ")", "\n", "new_conv_list", ".", "append", "(", "old_conv", ")", "\n", "", "return", "new_conv_list", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.LinearNorm.__init__": [[42, 49], ["super().__init__", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.calculate_gain"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "bias", "=", "True", ",", "w_init_gain", "=", "'linear'", ")", ":", "\n", "        ", "super", "(", "LinearNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "self", ".", "linear_layer", ".", "weight", ",", "\n", "gain", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "w_init_gain", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.LinearNorm.forward": [[50, 52], ["layers.LinearNorm.linear_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "linear_layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.ConvNorm.__init__": [[55, 69], ["super().__init__", "torch.nn.Conv1d", "torch.nn.init.xavier_uniform_", "int", "torch.nn.init.calculate_gain"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "None", ",", "dilation", "=", "1", ",", "bias", "=", "True", ",", "w_init_gain", "=", "'linear'", ")", ":", "\n", "        ", "super", "(", "ConvNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "padding", "is", "None", ":", "\n", "            ", "assert", "(", "kernel_size", "%", "2", "==", "1", ")", "\n", "padding", "=", "int", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", "/", "2", ")", "\n", "\n", "", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "self", ".", "conv", ".", "weight", ",", "gain", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "w_init_gain", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.ConvNorm.forward": [[70, 73], ["layers.ConvNorm.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "signal", ")", ":", "\n", "        ", "conv_signal", "=", "self", ".", "conv", "(", "signal", ")", "\n", "return", "conv_signal", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.GlobalAvgPool.__init__": [[76, 78], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "GlobalAvgPool", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.GlobalAvgPool.forward": [[79, 95], ["x.mean", "utils.get_mask_from_lengths().type().to", "mask.reshape.reshape.reshape", "mask.reshape.reshape.sum", "list", "utils.get_mask_from_lengths().type", "mask.reshape.reshape.size", "x.type", "range", "utils.get_mask_from_lengths", "x.ndimension"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.get_mask_from_lengths"], ["", "def", "forward", "(", "self", ",", "x", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"Average pooling across time steps (dim=1) with optionally lengths.\n        Args:\n            x: torch.Tensor of shape (N, T, ...)\n            lengths: None or torch.Tensor of shape (N,)\n            dim: dimension to pool\n        \"\"\"", "\n", "if", "lengths", "is", "None", ":", "\n", "            ", "return", "x", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "get_mask_from_lengths", "(", "lengths", ")", ".", "type", "(", "x", ".", "type", "(", ")", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "mask_shape", "=", "list", "(", "mask", ".", "size", "(", ")", ")", "+", "[", "1", "for", "_", "in", "range", "(", "x", ".", "ndimension", "(", ")", "-", "2", ")", "]", "\n", "mask", "=", "mask", ".", "reshape", "(", "*", "mask_shape", ")", "\n", "numer", "=", "(", "x", "*", "mask", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "denom", "=", "mask", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "numer", "/", "denom", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.TacotronSTFT.__init__": [[98, 109], ["super().__init__", "stft.STFT", "librosa.filters.mel", "torch.from_numpy().float", "layers.TacotronSTFT.register_buffer", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "filter_length", "=", "1024", ",", "hop_length", "=", "256", ",", "win_length", "=", "1024", ",", "\n", "n_mel_channels", "=", "80", ",", "sampling_rate", "=", "22050", ",", "mel_fmin", "=", "0.0", ",", "\n", "mel_fmax", "=", "8000.0", ")", ":", "\n", "        ", "super", "(", "TacotronSTFT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_mel_channels", "=", "n_mel_channels", "\n", "self", ".", "sampling_rate", "=", "sampling_rate", "\n", "self", ".", "stft_fn", "=", "STFT", "(", "filter_length", ",", "hop_length", ",", "win_length", ")", "\n", "mel_basis", "=", "librosa_mel_fn", "(", "\n", "sampling_rate", ",", "filter_length", ",", "n_mel_channels", ",", "mel_fmin", ",", "mel_fmax", ")", "\n", "mel_basis", "=", "torch", ".", "from_numpy", "(", "mel_basis", ")", ".", "float", "(", ")", "\n", "self", ".", "register_buffer", "(", "'mel_basis'", ",", "mel_basis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.TacotronSTFT.spectral_normalize": [[110, 113], ["audio_processing.dynamic_range_compression"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.dynamic_range_compression"], ["", "def", "spectral_normalize", "(", "self", ",", "magnitudes", ")", ":", "\n", "        ", "output", "=", "dynamic_range_compression", "(", "magnitudes", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.TacotronSTFT.spectral_de_normalize": [[114, 117], ["audio_processing.dynamic_range_decompression"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.dynamic_range_decompression"], ["", "def", "spectral_de_normalize", "(", "self", ",", "magnitudes", ")", ":", "\n", "        ", "output", "=", "dynamic_range_decompression", "(", "magnitudes", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.TacotronSTFT.mel_spectrogram": [[118, 136], ["layers.TacotronSTFT.stft_fn.transform", "torch.matmul", "layers.TacotronSTFT.spectral_normalize", "torch.min", "torch.max"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.layers.TacotronSTFT.spectral_normalize"], ["", "def", "mel_spectrogram", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"Computes mel-spectrograms from a batch of waves\n        PARAMS\n        ------\n        y: Variable(torch.FloatTensor) with shape (B, T) in range [-1, 1]\n\n        RETURNS\n        -------\n        mel_output: torch.FloatTensor of shape (B, n_mel_channels, T)\n        \"\"\"", "\n", "assert", "(", "torch", ".", "min", "(", "y", ".", "data", ")", ">=", "-", "1", ")", "\n", "assert", "(", "torch", ".", "max", "(", "y", ".", "data", ")", "<=", "1", ")", "\n", "\n", "magnitudes", ",", "phases", "=", "self", ".", "stft_fn", ".", "transform", "(", "y", ")", "\n", "magnitudes", "=", "magnitudes", ".", "data", "\n", "mel_output", "=", "torch", ".", "matmul", "(", "self", ".", "mel_basis", ",", "magnitudes", ")", "\n", "mel_output", "=", "self", ".", "spectral_normalize", "(", "mel_output", ")", "\n", "return", "mel_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.waveglow_denoiser.Denoiser.__init__": [[35, 59], ["super().__init__", "layers.STFT", "waveglow_denoiser.Denoiser.register_buffer", "torch.zeros", "torch.no_grad", "waveglow.infer().float", "waveglow_denoiser.Denoiser.stft.transform", "int", "torch.randn", "Exception", "waveglow.infer"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.infer"], ["def", "__init__", "(", "self", ",", "waveglow", ",", "filter_length", "=", "1024", ",", "n_overlap", "=", "4", ",", "\n", "win_length", "=", "1024", ",", "mode", "=", "'zeros'", ")", ":", "\n", "        ", "super", "(", "Denoiser", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stft", "=", "STFT", "(", "filter_length", "=", "filter_length", ",", "\n", "hop_length", "=", "int", "(", "filter_length", "/", "n_overlap", ")", ",", "\n", "win_length", "=", "win_length", ")", "\n", "if", "mode", "==", "'zeros'", ":", "\n", "            ", "mel_input", "=", "torch", ".", "zeros", "(", "\n", "(", "1", ",", "80", ",", "88", ")", ",", "\n", "dtype", "=", "waveglow", ".", "upsample", ".", "weight", ".", "dtype", ",", "\n", "device", "=", "waveglow", ".", "upsample", ".", "weight", ".", "device", ")", "\n", "", "elif", "mode", "==", "'normal'", ":", "\n", "            ", "mel_input", "=", "torch", ".", "randn", "(", "\n", "(", "1", ",", "80", ",", "88", ")", ",", "\n", "dtype", "=", "waveglow", ".", "upsample", ".", "weight", ".", "dtype", ",", "\n", "device", "=", "waveglow", ".", "upsample", ".", "weight", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Mode {} if not supported\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "bias_audio", "=", "waveglow", ".", "infer", "(", "mel_input", ",", "sigma", "=", "0.0", ")", ".", "float", "(", ")", "\n", "bias_spec", ",", "_", "=", "self", ".", "stft", ".", "transform", "(", "bias_audio", ")", "\n", "\n", "", "self", ".", "register_buffer", "(", "'bias_spec'", ",", "bias_spec", "[", ":", ",", ":", ",", "0", "]", "[", ":", ",", ":", ",", "None", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.waveglow_denoiser.Denoiser.forward": [[60, 66], ["waveglow_denoiser.Denoiser.stft.transform", "torch.clamp", "waveglow_denoiser.Denoiser.stft.inverse", "audio.cuda().float", "audio.cuda"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse"], ["", "def", "forward", "(", "self", ",", "audio", ",", "strength", "=", "0.1", ")", ":", "\n", "        ", "audio_spec", ",", "audio_angles", "=", "self", ".", "stft", ".", "transform", "(", "audio", ".", "cuda", "(", ")", ".", "float", "(", ")", ")", "\n", "audio_spec_denoised", "=", "audio_spec", "-", "self", ".", "bias_spec", "*", "strength", "\n", "audio_spec_denoised", "=", "torch", ".", "clamp", "(", "audio_spec_denoised", ",", "0.0", ")", "\n", "audio_denoised", "=", "self", ".", "stft", ".", "inverse", "(", "audio_spec_denoised", ",", "audio_angles", ")", "\n", "return", "audio_denoised", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.LocationLayer.__init__": [[44, 54], ["torch.nn.Module.__init__", "int", "layers.ConvNorm", "layers.LinearNorm"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_n_filters", ",", "attention_kernel_size", ",", "\n", "attention_dim", ")", ":", "\n", "        ", "super", "(", "LocationLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "int", "(", "(", "attention_kernel_size", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "location_conv", "=", "ConvNorm", "(", "2", ",", "attention_n_filters", ",", "\n", "kernel_size", "=", "attention_kernel_size", ",", "\n", "padding", "=", "padding", ",", "bias", "=", "False", ",", "stride", "=", "1", ",", "\n", "dilation", "=", "1", ")", "\n", "self", ".", "location_dense", "=", "LinearNorm", "(", "attention_n_filters", ",", "attention_dim", ",", "\n", "bias", "=", "False", ",", "w_init_gain", "=", "'tanh'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.LocationLayer.forward": [[55, 60], ["model.LocationLayer.location_conv", "model.LocationLayer.transpose", "model.LocationLayer.location_dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "attention_weights_cat", ")", ":", "\n", "        ", "processed_attention", "=", "self", ".", "location_conv", "(", "attention_weights_cat", ")", "\n", "processed_attention", "=", "processed_attention", ".", "transpose", "(", "1", ",", "2", ")", "\n", "processed_attention", "=", "self", ".", "location_dense", "(", "processed_attention", ")", "\n", "return", "processed_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Attention.__init__": [[63, 75], ["torch.nn.Module.__init__", "layers.LinearNorm", "layers.LinearNorm", "layers.LinearNorm", "model.LocationLayer", "float"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention_rnn_dim", ",", "embedding_dim", ",", "attention_dim", ",", "\n", "attention_location_n_filters", ",", "attention_location_kernel_size", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "query_layer", "=", "LinearNorm", "(", "attention_rnn_dim", ",", "attention_dim", ",", "\n", "bias", "=", "False", ",", "w_init_gain", "=", "'tanh'", ")", "\n", "self", ".", "memory_layer", "=", "LinearNorm", "(", "embedding_dim", ",", "attention_dim", ",", "bias", "=", "False", ",", "\n", "w_init_gain", "=", "'tanh'", ")", "\n", "self", ".", "v", "=", "LinearNorm", "(", "attention_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "location_layer", "=", "LocationLayer", "(", "attention_location_n_filters", ",", "\n", "attention_location_kernel_size", ",", "\n", "attention_dim", ")", "\n", "self", ".", "score_mask_value", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Attention.get_alignment_energies": [[76, 97], ["model.Attention.query_layer", "model.Attention.location_layer", "model.Attention.v", "energies.squeeze.squeeze.squeeze", "query.unsqueeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "get_alignment_energies", "(", "self", ",", "query", ",", "processed_memory", ",", "\n", "attention_weights_cat", ")", ":", "\n", "        ", "\"\"\"\n        PARAMS\n        ------\n        query: decoder output (batch, n_mel_channels * n_frames_per_step)\n        processed_memory: processed encoder outputs (B, T_in, attention_dim)\n        attention_weights_cat: cumulative and prev. att weights (B, 2, max_time)\n\n        RETURNS\n        -------\n        alignment (batch, max_time)\n        \"\"\"", "\n", "\n", "processed_query", "=", "self", ".", "query_layer", "(", "query", ".", "unsqueeze", "(", "1", ")", ")", "\n", "processed_attention_weights", "=", "self", ".", "location_layer", "(", "attention_weights_cat", ")", "\n", "energies", "=", "self", ".", "v", "(", "torch", ".", "tanh", "(", "\n", "processed_query", "+", "processed_attention_weights", "+", "processed_memory", ")", ")", "\n", "\n", "energies", "=", "energies", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "energies", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Attention.forward": [[98, 120], ["model.Attention.get_alignment_energies", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "attention_context.squeeze.squeeze.squeeze", "model.Attention.data.masked_fill_", "torch.nn.functional.softmax.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Attention.get_alignment_energies"], ["", "def", "forward", "(", "self", ",", "attention_hidden_state", ",", "memory", ",", "processed_memory", ",", "\n", "attention_weights_cat", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        PARAMS\n        ------\n        attention_hidden_state: attention rnn last output\n        memory: encoder outputs\n        processed_memory: processed encoder outputs\n        attention_weights_cat: previous and cummulative attention weights\n        mask: binary mask for padded data\n        \"\"\"", "\n", "alignment", "=", "self", ".", "get_alignment_energies", "(", "\n", "attention_hidden_state", ",", "processed_memory", ",", "attention_weights_cat", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "alignment", ".", "data", ".", "masked_fill_", "(", "mask", ",", "self", ".", "score_mask_value", ")", "\n", "\n", "", "attention_weights", "=", "F", ".", "softmax", "(", "alignment", ",", "dim", "=", "1", ")", "\n", "attention_context", "=", "torch", ".", "bmm", "(", "attention_weights", ".", "unsqueeze", "(", "1", ")", ",", "memory", ")", "\n", "attention_context", "=", "attention_context", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "attention_context", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Prenet.__init__": [[123, 129], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "layers.LinearNorm", "zip"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "sizes", ")", ":", "\n", "        ", "super", "(", "Prenet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "in_sizes", "=", "[", "in_dim", "]", "+", "sizes", "[", ":", "-", "1", "]", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "LinearNorm", "(", "in_size", ",", "out_size", ",", "bias", "=", "False", ")", "\n", "for", "(", "in_size", ",", "out_size", ")", "in", "zip", "(", "in_sizes", ",", "sizes", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Prenet.forward": [[130, 134], ["torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.relu", "torch.nn.functional.relu", "linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "linear", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "F", ".", "relu", "(", "linear", "(", "x", ")", ")", ",", "p", "=", "0.5", ",", "training", "=", "True", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Postnet.__init__": [[141, 172], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "model.Postnet.convolutions.append", "range", "model.Postnet.convolutions.append", "torch.nn.Sequential", "torch.nn.Sequential", "model.Postnet.convolutions.append", "torch.nn.Sequential", "torch.nn.Sequential", "layers.ConvNorm", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Sequential", "torch.nn.Sequential", "layers.ConvNorm", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "layers.ConvNorm", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "Postnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "hparams", ".", "n_mel_channels", ",", "hparams", ".", "postnet_embedding_dim", ",", "\n", "kernel_size", "=", "hparams", ".", "postnet_kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "hparams", ".", "postnet_kernel_size", "-", "1", ")", "/", "2", ")", ",", "\n", "dilation", "=", "1", ",", "w_init_gain", "=", "'tanh'", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hparams", ".", "postnet_embedding_dim", ")", ")", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "hparams", ".", "postnet_n_convolutions", "-", "1", ")", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "hparams", ".", "postnet_embedding_dim", ",", "\n", "hparams", ".", "postnet_embedding_dim", ",", "\n", "kernel_size", "=", "hparams", ".", "postnet_kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "hparams", ".", "postnet_kernel_size", "-", "1", ")", "/", "2", ")", ",", "\n", "dilation", "=", "1", ",", "w_init_gain", "=", "'tanh'", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hparams", ".", "postnet_embedding_dim", ")", ")", "\n", ")", "\n", "\n", "", "self", ".", "convolutions", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "hparams", ".", "postnet_embedding_dim", ",", "hparams", ".", "n_mel_channels", ",", "\n", "kernel_size", "=", "hparams", ".", "postnet_kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "hparams", ".", "postnet_kernel_size", "-", "1", ")", "/", "2", ")", ",", "\n", "dilation", "=", "1", ",", "w_init_gain", "=", "'linear'", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hparams", ".", "n_mel_channels", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Postnet.forward": [[174, 180], ["range", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "len", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "convolutions", ")", "-", "1", ")", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "torch", ".", "tanh", "(", "self", ".", "convolutions", "[", "i", "]", "(", "x", ")", ")", ",", "0.5", ",", "self", ".", "training", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "self", ".", "convolutions", "[", "-", "1", "]", "(", "x", ")", ",", "0.5", ",", "self", ".", "training", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Encoder.__init__": [[187, 205], ["torch.nn.Module.__init__", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Sequential", "torch.nn.Sequential", "convolutions.append", "int", "layers.ConvNorm", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "int"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "convolutions", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "hparams", ".", "encoder_n_convolutions", ")", ":", "\n", "            ", "conv_layer", "=", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "hparams", ".", "encoder_embedding_dim", ",", "\n", "hparams", ".", "encoder_embedding_dim", ",", "\n", "kernel_size", "=", "hparams", ".", "encoder_kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "hparams", ".", "encoder_kernel_size", "-", "1", ")", "/", "2", ")", ",", "\n", "dilation", "=", "1", ",", "w_init_gain", "=", "'relu'", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hparams", ".", "encoder_embedding_dim", ")", ")", "\n", "convolutions", ".", "append", "(", "conv_layer", ")", "\n", "", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", "convolutions", ")", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "hparams", ".", "encoder_embedding_dim", ",", "\n", "int", "(", "hparams", ".", "encoder_embedding_dim", "/", "2", ")", ",", "1", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Encoder.forward": [[206, 224], ["torch.nn.functional.dropout.transpose", "input_lengths.cpu().numpy.cpu().numpy.cpu().numpy", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.Encoder.lstm.flatten_parameters", "model.Encoder.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.relu", "torch.nn.functional.relu", "input_lengths.cpu().numpy.cpu().numpy.cpu", "conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "input_lengths", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "convolutions", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "F", ".", "relu", "(", "conv", "(", "x", ")", ")", ",", "0.5", ",", "self", ".", "training", ")", "\n", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# pytorch tensor are not reversible, hence the conversion", "\n", "input_lengths", "=", "input_lengths", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "x", ",", "input_lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "outputs", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "\n", "outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "outputs", ",", "batch_first", "=", "True", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Encoder.inference": [[225, 235], ["torch.nn.functional.dropout.transpose", "model.Encoder.lstm.flatten_parameters", "model.Encoder.lstm", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.nn.functional.relu", "torch.nn.functional.relu", "conv"], "methods", ["None"], ["", "def", "inference", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "convolutions", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "F", ".", "relu", "(", "conv", "(", "x", ")", ")", ",", "0.5", ",", "self", ".", "training", ")", "\n", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "outputs", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.AudioEncoder.__init__": [[238, 265], ["torch.nn.Module.__init__", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.LSTM", "torch.nn.LSTM", "layers.GlobalAvgPool", "layers.LinearNorm", "layers.LinearNorm", "torch.nn.Sequential", "torch.nn.Sequential", "convolutions.append", "int", "layers.ConvNorm", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "int"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "AudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "hparams", ".", "lat_dim", ">", "0", "\n", "\n", "convolutions", "=", "[", "]", "\n", "inp_dim", "=", "hparams", ".", "n_mel_channels", "\n", "for", "_", "in", "range", "(", "hparams", ".", "lat_n_convolutions", ")", ":", "\n", "            ", "conv_layer", "=", "nn", ".", "Sequential", "(", "\n", "ConvNorm", "(", "inp_dim", ",", "hparams", ".", "lat_n_filters", ",", "\n", "kernel_size", "=", "hparams", ".", "lat_kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "hparams", ".", "lat_kernel_size", "-", "1", ")", "/", "2", ")", ",", "\n", "dilation", "=", "1", ",", "w_init_gain", "=", "'tanh'", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "hparams", ".", "lat_n_filters", ")", ")", "\n", "inp_dim", "=", "hparams", ".", "lat_n_filters", "\n", "convolutions", ".", "append", "(", "conv_layer", ")", "\n", "", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", "convolutions", ")", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "hparams", ".", "lat_n_filters", ",", "\n", "int", "(", "hparams", ".", "lat_n_filters", "/", "2", ")", ",", "\n", "hparams", ".", "lat_n_blstms", ",", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", ")", "\n", "self", ".", "pool", "=", "GlobalAvgPool", "(", ")", "\n", "\n", "self", ".", "mu_proj", "=", "LinearNorm", "(", "hparams", ".", "lat_n_filters", ",", "hparams", ".", "lat_dim", ")", "\n", "self", ".", "logvar_proj", "=", "LinearNorm", "(", "hparams", ".", "lat_n_filters", ",", "hparams", ".", "lat_dim", ")", "\n", "self", ".", "lat_dim", "=", "hparams", ".", "lat_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.AudioEncoder.forward": [[266, 299], ["torch.nn.functional.dropout.transpose", "torch.nn.functional.dropout.size", "lengths.sort", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.AudioEncoder.lstm.flatten_parameters", "model.AudioEncoder.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "perm_idx.sort", "model.AudioEncoder.pool", "model.AudioEncoder.mu_proj", "model.AudioEncoder.logvar_proj", "torch.Normal().rsample", "torch.Normal().rsample", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.nn.functional.tanh", "torch.nn.functional.tanh", "torch.Normal", "torch.Normal", "conv", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "lengths", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (torch.Tensor): (B, F, T)\n        \"\"\"", "\n", "\n", "for", "conv", "in", "self", ".", "convolutions", ":", "\n", "            ", "x", "=", "F", ".", "dropout", "(", "F", ".", "tanh", "(", "conv", "(", "x", ")", ")", ",", "0.5", ",", "self", ".", "training", ")", "\n", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "# (B, T, D)", "\n", "\n", "# x may not be sorted by length. Sort->process->unsort", "\n", "max_len", "=", "x", ".", "size", "(", "1", ")", "\n", "assert", "max_len", "==", "torch", ".", "max", "(", "lengths", ")", ".", "item", "(", ")", "\n", "\n", "lengths", ",", "perm_idx", "=", "lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "x", "=", "x", "[", "perm_idx", "]", "\n", "x", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "outputs", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "outputs", ",", "batch_first", "=", "True", ")", "\n", "\n", "_", ",", "unperm_idx", "=", "perm_idx", ".", "sort", "(", "0", ")", "\n", "outputs", "=", "outputs", "[", "unperm_idx", "]", "# (B, T, D)", "\n", "lengths", "=", "lengths", "[", "unperm_idx", "]", "# (B, T, D)", "\n", "\n", "outputs", "=", "self", ".", "pool", "(", "outputs", ",", "lengths", ")", "# (B, D)", "\n", "\n", "mu", "=", "self", ".", "mu_proj", "(", "outputs", ")", "\n", "logvar", "=", "self", ".", "logvar_proj", "(", "outputs", ")", "\n", "z", "=", "distr", ".", "Normal", "(", "mu", ",", "logvar", ")", ".", "rsample", "(", ")", "\n", "return", "z", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.__init__": [[302, 343], ["torch.nn.Module.__init__", "model.Prenet", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "model.Attention", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "layers.LinearNorm", "layers.LinearNorm"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_mel_channels", "=", "hparams", ".", "n_mel_channels", "\n", "self", ".", "n_frames_per_step", "=", "hparams", ".", "n_frames_per_step", "\n", "self", ".", "encoder_embedding_dim", "=", "hparams", ".", "encoder_embedding_dim", "\n", "self", ".", "obs_dim", "=", "hparams", ".", "obs_dim", "\n", "self", ".", "lat_dim", "=", "hparams", ".", "lat_dim", "\n", "self", ".", "attention_rnn_dim", "=", "hparams", ".", "attention_rnn_dim", "\n", "self", ".", "decoder_rnn_dim", "=", "hparams", ".", "decoder_rnn_dim", "\n", "self", ".", "prenet_dim", "=", "hparams", ".", "prenet_dim", "\n", "self", ".", "max_decoder_steps", "=", "hparams", ".", "max_decoder_steps", "\n", "self", ".", "gate_threshold", "=", "hparams", ".", "gate_threshold", "\n", "self", ".", "p_attention_dropout", "=", "hparams", ".", "p_attention_dropout", "\n", "self", ".", "p_decoder_dropout", "=", "hparams", ".", "p_decoder_dropout", "\n", "\n", "self", ".", "prenet", "=", "Prenet", "(", "\n", "hparams", ".", "n_mel_channels", "*", "hparams", ".", "n_frames_per_step", ",", "\n", "[", "hparams", ".", "prenet_dim", ",", "hparams", ".", "prenet_dim", "]", ")", "\n", "\n", "self", ".", "attention_rnn", "=", "nn", ".", "LSTMCell", "(", "\n", "hparams", ".", "prenet_dim", "+", "hparams", ".", "encoder_embedding_dim", ",", "\n", "hparams", ".", "attention_rnn_dim", ")", "\n", "\n", "self", ".", "attention_layer", "=", "Attention", "(", "\n", "hparams", ".", "attention_rnn_dim", ",", "hparams", ".", "encoder_embedding_dim", ",", "\n", "hparams", ".", "attention_dim", ",", "hparams", ".", "attention_location_n_filters", ",", "\n", "hparams", ".", "attention_location_kernel_size", ")", "\n", "\n", "encoder_tot_dim", "=", "(", "hparams", ".", "encoder_embedding_dim", "+", "hparams", ".", "lat_dim", "+", "hparams", ".", "obs_dim", ")", "\n", "self", ".", "decoder_rnn", "=", "nn", ".", "LSTMCell", "(", "\n", "hparams", ".", "attention_rnn_dim", "+", "encoder_tot_dim", ",", "\n", "hparams", ".", "decoder_rnn_dim", ",", "1", ")", "\n", "\n", "self", ".", "linear_projection", "=", "LinearNorm", "(", "\n", "hparams", ".", "decoder_rnn_dim", "+", "encoder_tot_dim", ",", "\n", "hparams", ".", "n_mel_channels", "*", "hparams", ".", "n_frames_per_step", ")", "\n", "\n", "self", ".", "gate_layer", "=", "LinearNorm", "(", "\n", "hparams", ".", "decoder_rnn_dim", "+", "encoder_tot_dim", ",", "1", ",", "\n", "bias", "=", "True", ",", "w_init_gain", "=", "'sigmoid'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.get_go_frame": [[344, 358], ["memory.size", "torch.autograd.Variable", "torch.autograd.Variable", "memory.data.new().zero_", "memory.data.new"], "methods", ["None"], ["", "def", "get_go_frame", "(", "self", ",", "memory", ")", ":", "\n", "        ", "\"\"\" Gets all zeros frames to use as first decoder input\n        PARAMS\n        ------\n        memory: decoder outputs\n\n        RETURNS\n        -------\n        decoder_input: all zeros frames\n        \"\"\"", "\n", "B", "=", "memory", ".", "size", "(", "0", ")", "\n", "decoder_input", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "n_mel_channels", "*", "self", ".", "n_frames_per_step", ")", ".", "zero_", "(", ")", ")", "\n", "return", "decoder_input", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.initialize_decoder_states": [[359, 393], ["memory.size", "memory.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model.Decoder.attention_layer.memory_layer", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new().zero_", "memory.data.new", "memory.data.new", "memory.data.new", "memory.data.new", "memory.data.new", "memory.data.new", "memory.data.new"], "methods", ["None"], ["", "def", "initialize_decoder_states", "(", "self", ",", "memory", ",", "obs_and_lat", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Initializes attention rnn states, decoder rnn states, attention\n        weights, attention cumulative weights, attention context, stores memory\n        and stores processed memory\n        PARAMS\n        ------\n        memory: Encoder outputs\n        obs_and_lat: Observed and latent attribute embeddings\n        mask: Mask for padded data if training, expects None for inference\n        \"\"\"", "\n", "B", "=", "memory", ".", "size", "(", "0", ")", "\n", "MAX_TIME", "=", "memory", ".", "size", "(", "1", ")", "\n", "\n", "self", ".", "attention_hidden", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "attention_rnn_dim", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "attention_cell", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "attention_rnn_dim", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "self", ".", "decoder_hidden", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "decoder_rnn_dim", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "decoder_cell", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "decoder_rnn_dim", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "self", ".", "attention_weights", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "MAX_TIME", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "attention_weights_cum", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "MAX_TIME", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "attention_context", "=", "Variable", "(", "memory", ".", "data", ".", "new", "(", "\n", "B", ",", "self", ".", "encoder_embedding_dim", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "processed_memory", "=", "self", ".", "attention_layer", ".", "memory_layer", "(", "memory", ")", "\n", "self", ".", "obs_and_lat", "=", "obs_and_lat", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.parse_decoder_inputs": [[394, 413], ["decoder_inputs.transpose.transpose.transpose", "decoder_inputs.transpose.transpose.view", "decoder_inputs.transpose.transpose.transpose", "decoder_inputs.transpose.transpose.size", "int", "decoder_inputs.transpose.transpose.size"], "methods", ["None"], ["", "def", "parse_decoder_inputs", "(", "self", ",", "decoder_inputs", ")", ":", "\n", "        ", "\"\"\" Prepares decoder inputs, i.e. mel outputs\n        PARAMS\n        ------\n        decoder_inputs: inputs used for teacher-forced training, i.e. mel-specs\n\n        RETURNS\n        -------\n        inputs: processed decoder inputs\n\n        \"\"\"", "\n", "# (B, n_mel_channels, T_out) -> (B, T_out, n_mel_channels)", "\n", "decoder_inputs", "=", "decoder_inputs", ".", "transpose", "(", "1", ",", "2", ")", "\n", "decoder_inputs", "=", "decoder_inputs", ".", "view", "(", "\n", "decoder_inputs", ".", "size", "(", "0", ")", ",", "\n", "int", "(", "decoder_inputs", ".", "size", "(", "1", ")", "/", "self", ".", "n_frames_per_step", ")", ",", "-", "1", ")", "\n", "# (B, T_out, n_mel_channels) -> (T_out, B, n_mel_channels)", "\n", "decoder_inputs", "=", "decoder_inputs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "decoder_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.parse_decoder_outputs": [[414, 442], ["torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "gate_outputs.contiguous.contiguous.contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "torch.stack().transpose().contiguous", "mel_outputs.transpose.transpose.view", "mel_outputs.transpose.transpose.transpose", "mel_outputs.transpose.transpose.size", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "parse_decoder_outputs", "(", "self", ",", "mel_outputs", ",", "gate_outputs", ",", "alignments", ")", ":", "\n", "        ", "\"\"\" Prepares decoder outputs for output\n        PARAMS\n        ------\n        mel_outputs:\n        gate_outputs: gate output energies\n        alignments:\n\n        RETURNS\n        -------\n        mel_outputs:\n        gate_outpust: gate output energies\n        alignments:\n        \"\"\"", "\n", "# (T_out, B) -> (B, T_out)", "\n", "alignments", "=", "torch", ".", "stack", "(", "alignments", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# (T_out, B) -> (B, T_out)", "\n", "gate_outputs", "=", "torch", ".", "stack", "(", "gate_outputs", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "gate_outputs", "=", "gate_outputs", ".", "contiguous", "(", ")", "\n", "# (T_out, B, n_mel_channels) -> (B, T_out, n_mel_channels)", "\n", "mel_outputs", "=", "torch", ".", "stack", "(", "mel_outputs", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# decouple frames per step", "\n", "mel_outputs", "=", "mel_outputs", ".", "view", "(", "\n", "mel_outputs", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "n_mel_channels", ")", "\n", "# (B, T_out, n_mel_channels) -> (B, n_mel_channels, T_out)", "\n", "mel_outputs", "=", "mel_outputs", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "mel_outputs", ",", "gate_outputs", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.decode": [[443, 488], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.attention_rnn", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.attention_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.decoder_rnn", "torch.nn.functional.dropout", "torch.nn.functional.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.linear_projection", "model.Decoder.gate_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.attention_weights.unsqueeze", "model.Decoder.attention_weights_cum.unsqueeze"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "decoder_input", ")", ":", "\n", "        ", "\"\"\" Decoder step using stored states, attention and memory\n        PARAMS\n        ------\n        decoder_input: previous mel output\n\n        RETURNS\n        -------\n        mel_output:\n        gate_output: gate output energies\n        attention_weights:\n        \"\"\"", "\n", "cell_input", "=", "torch", ".", "cat", "(", "(", "decoder_input", ",", "self", ".", "attention_context", ")", ",", "-", "1", ")", "\n", "self", ".", "attention_hidden", ",", "self", ".", "attention_cell", "=", "self", ".", "attention_rnn", "(", "\n", "cell_input", ",", "(", "self", ".", "attention_hidden", ",", "self", ".", "attention_cell", ")", ")", "\n", "self", ".", "attention_hidden", "=", "F", ".", "dropout", "(", "\n", "self", ".", "attention_hidden", ",", "self", ".", "p_attention_dropout", ",", "self", ".", "training", ")", "\n", "\n", "attention_weights_cat", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "attention_weights", ".", "unsqueeze", "(", "1", ")", ",", "\n", "self", ".", "attention_weights_cum", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "self", ".", "attention_context", ",", "self", ".", "attention_weights", "=", "self", ".", "attention_layer", "(", "\n", "self", ".", "attention_hidden", ",", "self", ".", "memory", ",", "self", ".", "processed_memory", ",", "\n", "attention_weights_cat", ",", "self", ".", "mask", ")", "\n", "\n", "self", ".", "attention_weights_cum", "+=", "self", ".", "attention_weights", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "attention_hidden", ",", "self", ".", "attention_context", ")", ",", "-", "1", ")", "\n", "if", "self", ".", "obs_and_lat", "is", "not", "None", ":", "\n", "            ", "decoder_input", "=", "torch", ".", "cat", "(", "(", "decoder_input", ",", "self", ".", "obs_and_lat", ")", ",", "-", "1", ")", "\n", "", "self", ".", "decoder_hidden", ",", "self", ".", "decoder_cell", "=", "self", ".", "decoder_rnn", "(", "\n", "decoder_input", ",", "(", "self", ".", "decoder_hidden", ",", "self", ".", "decoder_cell", ")", ")", "\n", "self", ".", "decoder_hidden", "=", "F", ".", "dropout", "(", "\n", "self", ".", "decoder_hidden", ",", "self", ".", "p_decoder_dropout", ",", "self", ".", "training", ")", "\n", "\n", "decoder_hidden_attention_context", "=", "torch", ".", "cat", "(", "\n", "(", "self", ".", "decoder_hidden", ",", "self", ".", "attention_context", ")", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "obs_and_lat", "is", "not", "None", ":", "\n", "            ", "decoder_hidden_attention_context", "=", "torch", ".", "cat", "(", "\n", "(", "decoder_hidden_attention_context", ",", "self", ".", "obs_and_lat", ")", ",", "dim", "=", "1", ")", "\n", "", "decoder_output", "=", "self", ".", "linear_projection", "(", "\n", "decoder_hidden_attention_context", ")", "\n", "\n", "gate_prediction", "=", "self", ".", "gate_layer", "(", "decoder_hidden_attention_context", ")", "\n", "return", "decoder_output", ",", "gate_prediction", ",", "self", ".", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.forward": [[489, 526], ["model.Decoder.get_go_frame().unsqueeze", "model.Decoder.parse_decoder_inputs", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Decoder.prenet", "model.Decoder.initialize_decoder_states", "model.Decoder.parse_decoder_outputs", "len", "model.Decoder.decode", "model.Decoder.get_go_frame", "model.Decoder.size", "mel_output.squeeze", "gate_output.squeeze", "utils.get_mask_from_lengths", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.parse_decoder_inputs", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.initialize_decoder_states", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.parse_decoder_outputs", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.decode", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.get_go_frame", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.get_mask_from_lengths"], ["", "def", "forward", "(", "self", ",", "memory", ",", "obs_and_lat", ",", "decoder_inputs", ",", "memory_lengths", ")", ":", "\n", "        ", "\"\"\" Decoder forward pass for training\n        PARAMS\n        ------\n        memory: Encoder outputs\n        obs_and_lat: Observed and latent attribute embeddings\n        decoder_inputs: Decoder inputs for teacher forcing. i.e. mel-specs\n        memory_lengths: Encoder output lengths for attention masking.\n\n        RETURNS\n        -------\n        mel_outputs: mel outputs from the decoder\n        gate_outputs: gate outputs from the decoder\n        alignments: sequence of attention weights from the decoder\n        \"\"\"", "\n", "\n", "decoder_input", "=", "self", ".", "get_go_frame", "(", "memory", ")", ".", "unsqueeze", "(", "0", ")", "\n", "decoder_inputs", "=", "self", ".", "parse_decoder_inputs", "(", "decoder_inputs", ")", "\n", "decoder_inputs", "=", "torch", ".", "cat", "(", "(", "decoder_input", ",", "decoder_inputs", ")", ",", "dim", "=", "0", ")", "\n", "decoder_inputs", "=", "self", ".", "prenet", "(", "decoder_inputs", ")", "\n", "\n", "self", ".", "initialize_decoder_states", "(", "\n", "memory", ",", "obs_and_lat", ",", "mask", "=", "~", "get_mask_from_lengths", "(", "memory_lengths", ")", ")", "\n", "\n", "mel_outputs", ",", "gate_outputs", ",", "alignments", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "while", "len", "(", "mel_outputs", ")", "<", "decoder_inputs", ".", "size", "(", "0", ")", "-", "1", ":", "\n", "            ", "decoder_input", "=", "decoder_inputs", "[", "len", "(", "mel_outputs", ")", "]", "\n", "mel_output", ",", "gate_output", ",", "attention_weights", "=", "self", ".", "decode", "(", "\n", "decoder_input", ")", "\n", "mel_outputs", "+=", "[", "mel_output", ".", "squeeze", "(", "1", ")", "]", "\n", "gate_outputs", "+=", "[", "gate_output", ".", "squeeze", "(", ")", "]", "\n", "alignments", "+=", "[", "attention_weights", "]", "\n", "\n", "", "mel_outputs", ",", "gate_outputs", ",", "alignments", "=", "self", ".", "parse_decoder_outputs", "(", "\n", "mel_outputs", ",", "gate_outputs", ",", "alignments", ")", "\n", "\n", "return", "mel_outputs", ",", "gate_outputs", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.inference": [[527, 570], ["model.Decoder.get_go_frame", "model.Decoder.initialize_decoder_states", "model.Decoder.parse_decoder_outputs", "model.Decoder.prenet", "model.Decoder.decode", "mel_output.squeeze", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.get_go_frame", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.initialize_decoder_states", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.parse_decoder_outputs", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.decode"], ["", "def", "inference", "(", "self", ",", "memory", ",", "obs_and_lat", ",", "ret_has_eos", "=", "False", ")", ":", "\n", "        ", "\"\"\" Decoder inference\n        PARAMS\n        ------\n        memory: Encoder outputs\n        obs_and_lat: Observed and latent attribute embeddings\n\n        RETURNS\n        -------\n        mel_outputs: mel outputs from the decoder\n        gate_outputs: gate outputs from the decoder\n        alignments: sequence of attention weights from the decoder\n        \"\"\"", "\n", "decoder_input", "=", "self", ".", "get_go_frame", "(", "memory", ")", "\n", "\n", "self", ".", "initialize_decoder_states", "(", "memory", ",", "obs_and_lat", ",", "mask", "=", "None", ")", "\n", "\n", "mel_outputs", ",", "gate_outputs", ",", "alignments", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "has_eos", "=", "False", "\n", "while", "True", ":", "\n", "            ", "decoder_input", "=", "self", ".", "prenet", "(", "decoder_input", ")", "\n", "mel_output", ",", "gate_output", ",", "alignment", "=", "self", ".", "decode", "(", "decoder_input", ")", "\n", "\n", "mel_outputs", "+=", "[", "mel_output", ".", "squeeze", "(", "1", ")", "]", "\n", "gate_outputs", "+=", "[", "gate_output", "]", "\n", "alignments", "+=", "[", "alignment", "]", "\n", "\n", "if", "torch", ".", "sigmoid", "(", "gate_output", ".", "data", ")", ">", "self", ".", "gate_threshold", ":", "\n", "                ", "has_eos", "=", "True", "\n", "break", "\n", "", "elif", "len", "(", "mel_outputs", ")", "==", "self", ".", "max_decoder_steps", ":", "\n", "# print(\"Warning! Reached max decoder steps\")", "\n", "                ", "break", "\n", "\n", "", "decoder_input", "=", "mel_output", "\n", "\n", "", "mel_outputs", ",", "gate_outputs", ",", "alignments", "=", "self", ".", "parse_decoder_outputs", "(", "\n", "mel_outputs", ",", "gate_outputs", ",", "alignments", ")", "\n", "\n", "if", "ret_has_eos", ":", "\n", "            ", "return", "mel_outputs", ",", "gate_outputs", ",", "alignments", ",", "has_eos", "\n", "", "else", ":", "\n", "            ", "return", "mel_outputs", ",", "gate_outputs", ",", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.__init__": [[573, 603], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "math.sqrt", "model.Tacotron2.embedding.weight.data.uniform_", "model.Encoder", "model.Decoder", "model.Postnet", "math.sqrt", "torch.nn.Embedding", "torch.nn.Embedding", "math.sqrt", "model.Tacotron2.obs_embedding.weight.data.uniform_", "model.AudioEncoder", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "Tacotron2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask_padding", "=", "hparams", ".", "mask_padding", "\n", "self", ".", "fp16_run", "=", "hparams", ".", "fp16_run", "\n", "self", ".", "n_mel_channels", "=", "hparams", ".", "n_mel_channels", "\n", "self", ".", "n_frames_per_step", "=", "hparams", ".", "n_frames_per_step", "\n", "\n", "# initialize text encoder embedding", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "\n", "hparams", ".", "n_symbols", ",", "hparams", ".", "symbols_embedding_dim", ")", "\n", "std", "=", "sqrt", "(", "2.0", "/", "(", "hparams", ".", "n_symbols", "+", "hparams", ".", "symbols_embedding_dim", ")", ")", "\n", "val", "=", "sqrt", "(", "3.0", ")", "*", "std", "# uniform bounds for std", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val", ",", "val", ")", "\n", "\n", "# initialize observed attribute embedding", "\n", "self", ".", "obs_embedding", "=", "None", "\n", "if", "hparams", ".", "obs_dim", ">", "0", ":", "\n", "            ", "self", ".", "obs_embedding", "=", "nn", ".", "Embedding", "(", "\n", "hparams", ".", "obs_n_class", ",", "hparams", ".", "obs_dim", ")", "\n", "std", "=", "sqrt", "(", "2.0", "/", "(", "hparams", ".", "obs_n_class", "+", "hparams", ".", "obs_dim", ")", ")", "\n", "val", "=", "sqrt", "(", "3.0", ")", "*", "std", "# uniform bounds for std", "\n", "self", ".", "obs_embedding", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val", ",", "val", ")", "\n", "\n", "", "self", ".", "encoder", "=", "Encoder", "(", "hparams", ")", "\n", "self", ".", "decoder", "=", "Decoder", "(", "hparams", ")", "\n", "self", ".", "postnet", "=", "Postnet", "(", "hparams", ")", "\n", "\n", "self", ".", "lat_encoder", "=", "None", "\n", "if", "hparams", ".", "lat_dim", ">", "0", ":", "\n", "            ", "self", ".", "lat_encoder", "=", "AudioEncoder", "(", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.parse_batch": [[604, 619], ["utils.to_gpu().long", "utils.to_gpu().long", "utils.to_gpu().long", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "utils.to_gpu().float", "utils.to_gpu().float", "utils.to_gpu().long", "utils.to_gpu", "utils.to_gpu", "utils.to_gpu", "torch.max", "torch.max", "torch.max", "torch.max", "utils.to_gpu", "utils.to_gpu", "utils.to_gpu"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu"], ["", "", "def", "parse_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "(", "text_padded", ",", "input_lengths", ",", "obs_labels", ",", "\n", "mel_padded", ",", "gate_padded", ",", "output_lengths", ")", "=", "batch", "\n", "text_padded", "=", "to_gpu", "(", "text_padded", ")", ".", "long", "(", ")", "\n", "input_lengths", "=", "to_gpu", "(", "input_lengths", ")", ".", "long", "(", ")", "\n", "obs_labels", "=", "to_gpu", "(", "obs_labels", ")", ".", "long", "(", ")", "\n", "max_len", "=", "torch", ".", "max", "(", "input_lengths", ".", "data", ")", ".", "item", "(", ")", "\n", "mel_padded", "=", "to_gpu", "(", "mel_padded", ")", ".", "float", "(", ")", "\n", "gate_padded", "=", "to_gpu", "(", "gate_padded", ")", ".", "float", "(", ")", "\n", "output_lengths", "=", "to_gpu", "(", "output_lengths", ")", ".", "long", "(", ")", "\n", "\n", "return", "(", "\n", "(", "text_padded", ",", "input_lengths", ",", "obs_labels", ",", "\n", "mel_padded", ",", "max_len", ",", "output_lengths", ")", ",", "\n", "(", "mel_padded", ",", "gate_padded", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.parse_output": [[620, 631], ["mask.permute.permute.expand", "mask.permute.permute.permute", "outputs[].data.masked_fill_", "outputs[].data.masked_fill_", "outputs[].data.masked_fill_", "utils.get_mask_from_lengths", "mask.permute.permute.size", "mask.permute.permute.size"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.get_mask_from_lengths"], ["", "def", "parse_output", "(", "self", ",", "outputs", ",", "output_lengths", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "mask_padding", "and", "output_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "~", "get_mask_from_lengths", "(", "output_lengths", ")", "\n", "mask", "=", "mask", ".", "expand", "(", "self", ".", "n_mel_channels", ",", "mask", ".", "size", "(", "0", ")", ",", "mask", ".", "size", "(", "1", ")", ")", "\n", "mask", "=", "mask", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "outputs", "[", "0", "]", ".", "data", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "outputs", "[", "1", "]", ".", "data", ".", "masked_fill_", "(", "mask", ",", "0.0", ")", "\n", "outputs", "[", "2", "]", ".", "data", ".", "masked_fill_", "(", "mask", "[", ":", ",", "0", ",", ":", "]", ",", "1e3", ")", "# gate energies", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.forward": [[632, 665], ["model.Tacotron2.embedding().transpose", "model.Tacotron2.encoder", "bool", "model.Tacotron2.decoder", "model.Tacotron2.postnet", "model.Tacotron2.parse_output", "model.Tacotron2.obs_embedding", "model.Tacotron2.lat_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Tacotron2.embedding"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.parse_output"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "(", "text_inputs", ",", "text_lengths", ",", "obs_labels", ",", "\n", "mels", ",", "max_len", ",", "output_lengths", ")", "=", "inputs", "\n", "text_lengths", ",", "output_lengths", "=", "text_lengths", ".", "data", ",", "output_lengths", ".", "data", "\n", "\n", "embedded_inputs", "=", "self", ".", "embedding", "(", "text_inputs", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedded_inputs", ",", "text_lengths", ")", "\n", "\n", "obs", "=", "None", "\n", "if", "self", ".", "obs_embedding", "is", "not", "None", ":", "\n", "            ", "obs", "=", "self", ".", "obs_embedding", "(", "obs_labels", ")", "\n", "\n", "", "lat", ",", "lat_mu", ",", "lat_logvar", "=", "None", ",", "None", ",", "None", "\n", "if", "self", ".", "lat_encoder", "is", "not", "None", ":", "\n", "            ", "(", "lat", ",", "lat_mu", ",", "lat_logvar", ")", "=", "self", ".", "lat_encoder", "(", "mels", ",", "output_lengths", ")", "\n", "\n", "", "obs_and_lat", "=", "[", "x", "for", "x", "in", "[", "obs", ",", "lat", "]", "if", "x", "is", "not", "None", "]", "\n", "if", "bool", "(", "obs_and_lat", ")", ":", "\n", "            ", "obs_and_lat", "=", "torch", ".", "cat", "(", "obs_and_lat", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "obs_and_lat", "=", "None", "\n", "\n", "", "mel_outputs", ",", "gate_outputs", ",", "alignments", "=", "self", ".", "decoder", "(", "\n", "encoder_outputs", ",", "obs_and_lat", ",", "mels", ",", "memory_lengths", "=", "text_lengths", ")", "\n", "\n", "mel_outputs_postnet", "=", "self", ".", "postnet", "(", "mel_outputs", ")", "\n", "mel_outputs_postnet", "=", "mel_outputs", "+", "mel_outputs_postnet", "\n", "\n", "return", "self", ".", "parse_output", "(", "\n", "[", "mel_outputs", ",", "mel_outputs_postnet", ",", "gate_outputs", ",", "alignments", ",", "\n", "lat_mu", ",", "lat_logvar", "]", ",", "\n", "output_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.inference": [[666, 702], ["model.Tacotron2.embedding().transpose", "model.Tacotron2.encoder.inference", "bool", "model.Tacotron2.decoder.inference", "model.Tacotron2.postnet", "model.Tacotron2.parse_output", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "obs_labels.to().zero_.to().zero_.to().zero_", "model.Tacotron2.obs_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Tacotron2.embedding", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "lat.to().zero_().type.to().zero_().type.to().zero_().type", "obs_labels.to().zero_.to().zero_.to", "len", "model.Tacotron2.type", "lat.to().zero_().type.to().zero_().type.to().zero_", "lat.to().zero_().type.to().zero_().type.to"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.inference", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.inference", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.parse_output"], ["", "def", "inference", "(", "self", ",", "inputs", ",", "obs_labels", "=", "None", ",", "lat", "=", "None", ",", "ret_has_eos", "=", "False", ")", ":", "\n", "        ", "embedded_inputs", "=", "self", ".", "embedding", "(", "inputs", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", ".", "inference", "(", "embedded_inputs", ")", "\n", "\n", "if", "obs_labels", "is", "None", ":", "\n", "            ", "obs_labels", "=", "torch", ".", "LongTensor", "(", "len", "(", "inputs", ")", ")", "\n", "obs_labels", "=", "obs_labels", ".", "to", "(", "inputs", ".", "device", ")", ".", "zero_", "(", ")", "\n", "\n", "", "obs", "=", "None", "\n", "if", "self", ".", "obs_embedding", "is", "not", "None", ":", "\n", "            ", "obs", "=", "self", ".", "obs_embedding", "(", "obs_labels", ")", "\n", "\n", "", "if", "self", ".", "lat_encoder", "is", "not", "None", ":", "\n", "            ", "if", "lat", "is", "None", ":", "\n", "                ", "lat", "=", "torch", ".", "FloatTensor", "(", "len", "(", "inputs", ")", ",", "self", ".", "lat_encoder", ".", "lat_dim", ")", "\n", "lat", "=", "lat", ".", "to", "(", "inputs", ".", "device", ")", ".", "zero_", "(", ")", ".", "type", "(", "encoder_outputs", ".", "type", "(", ")", ")", "\n", "\n", "", "", "obs_and_lat", "=", "[", "x", "for", "x", "in", "[", "obs", ",", "lat", "]", "if", "x", "is", "not", "None", "]", "\n", "if", "bool", "(", "obs_and_lat", ")", ":", "\n", "            ", "obs_and_lat", "=", "torch", ".", "cat", "(", "obs_and_lat", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "obs_and_lat", "=", "None", "\n", "\n", "", "mel_outputs", ",", "gate_outputs", ",", "alignments", ",", "has_eos", "=", "self", ".", "decoder", ".", "inference", "(", "\n", "encoder_outputs", ",", "obs_and_lat", ",", "ret_has_eos", "=", "True", ")", "\n", "\n", "mel_outputs_postnet", "=", "self", ".", "postnet", "(", "mel_outputs", ")", "\n", "mel_outputs_postnet", "=", "mel_outputs", "+", "mel_outputs_postnet", "\n", "\n", "outputs", "=", "self", ".", "parse_output", "(", "\n", "[", "mel_outputs", ",", "mel_outputs_postnet", ",", "gate_outputs", ",", "alignments", "]", ")", "\n", "\n", "if", "ret_has_eos", ":", "\n", "            ", "return", "outputs", "+", "[", "has_eos", "]", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.window_sumsquare": [[39, 89], ["numpy.zeros", "scipy.signal.get_window", "librosa.pad_center", "range", "librosa.normalize", "min", "max", "min"], "function", ["None"], ["def", "window_sumsquare", "(", "window", ",", "n_frames", ",", "hop_length", "=", "200", ",", "win_length", "=", "800", ",", "\n", "n_fft", "=", "800", ",", "dtype", "=", "np", ".", "float32", ",", "norm", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    # from librosa 0.6\n    Compute the sum-square envelope of a window function at a given hop length.\n\n    This is used to estimate modulation effects induced by windowing\n    observations in short-time fourier transforms.\n\n    Parameters\n    ----------\n    window : string, tuple, number, callable, or list-like\n        Window specification, as in `get_window`\n\n    n_frames : int > 0\n        The number of analysis frames\n\n    hop_length : int > 0\n        The number of samples to advance between frames\n\n    win_length : [optional]\n        The length of the window function.  By default, this matches `n_fft`.\n\n    n_fft : int > 0\n        The length of each analysis frame.\n\n    dtype : np.dtype\n        The data type of the output\n\n    Returns\n    -------\n    wss : np.ndarray, shape=`(n_fft + hop_length * (n_frames - 1))`\n        The sum-squared envelope of the window function\n    \"\"\"", "\n", "if", "win_length", "is", "None", ":", "\n", "        ", "win_length", "=", "n_fft", "\n", "\n", "", "n", "=", "n_fft", "+", "hop_length", "*", "(", "n_frames", "-", "1", ")", "\n", "x", "=", "np", ".", "zeros", "(", "n", ",", "dtype", "=", "dtype", ")", "\n", "\n", "# Compute the squared window at the desired length", "\n", "win_sq", "=", "get_window", "(", "window", ",", "win_length", ",", "fftbins", "=", "True", ")", "\n", "win_sq", "=", "librosa_util", ".", "normalize", "(", "win_sq", ",", "norm", "=", "norm", ")", "**", "2", "\n", "win_sq", "=", "librosa_util", ".", "pad_center", "(", "win_sq", ",", "n_fft", ")", "\n", "\n", "# Fill the envelope", "\n", "for", "i", "in", "range", "(", "n_frames", ")", ":", "\n", "        ", "sample", "=", "i", "*", "hop_length", "\n", "x", "[", "sample", ":", "min", "(", "n", ",", "sample", "+", "n_fft", ")", "]", "+=", "win_sq", "[", ":", "max", "(", "0", ",", "min", "(", "n_fft", ",", "n", "-", "sample", ")", ")", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.griffin_lim": [[91, 108], ["numpy.angle", "torch.autograd.Variable.astype", "torch.autograd.Variable", "stft_fn.inverse().squeeze", "range", "numpy.exp", "torch.from_numpy", "stft_fn.transform", "stft_fn.inverse().squeeze", "stft_fn.inverse", "numpy.random.rand", "stft_fn.inverse", "magnitudes.size"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse"], ["", "def", "griffin_lim", "(", "magnitudes", ",", "stft_fn", ",", "n_iters", "=", "30", ")", ":", "\n", "    ", "\"\"\"\n    PARAMS\n    ------\n    magnitudes: spectrogram magnitudes\n    stft_fn: STFT class with transform (STFT) and inverse (ISTFT) methods\n    \"\"\"", "\n", "\n", "angles", "=", "np", ".", "angle", "(", "np", ".", "exp", "(", "2j", "*", "np", ".", "pi", "*", "np", ".", "random", ".", "rand", "(", "*", "magnitudes", ".", "size", "(", ")", ")", ")", ")", "\n", "angles", "=", "angles", ".", "astype", "(", "np", ".", "float32", ")", "\n", "angles", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "from_numpy", "(", "angles", ")", ")", "\n", "signal", "=", "stft_fn", ".", "inverse", "(", "magnitudes", ",", "angles", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_iters", ")", ":", "\n", "        ", "_", ",", "angles", "=", "stft_fn", ".", "transform", "(", "signal", ")", "\n", "signal", "=", "stft_fn", ".", "inverse", "(", "magnitudes", ",", "angles", ")", ".", "squeeze", "(", "1", ")", "\n", "", "return", "signal", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.dynamic_range_compression": [[110, 117], ["torch.log", "torch.clamp"], "function", ["None"], ["", "def", "dynamic_range_compression", "(", "x", ",", "C", "=", "1", ",", "clip_val", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"\n    PARAMS\n    ------\n    C: compression factor\n    \"\"\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "x", ",", "min", "=", "clip_val", ")", "*", "C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.dynamic_range_decompression": [[119, 126], ["torch.exp"], "function", ["None"], ["", "def", "dynamic_range_decompression", "(", "x", ",", "C", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    PARAMS\n    ------\n    C: compression factor used to compress\n    \"\"\"", "\n", "return", "torch", ".", "exp", "(", "x", ")", "/", "C", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict.CMUDict.__init__": [[41, 50], ["isinstance", "cmudict._parse_cmudict", "open", "cmudict._parse_cmudict", "_parse_cmudict.items", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict._parse_cmudict", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict._parse_cmudict"], ["def", "__init__", "(", "self", ",", "file_or_path", ",", "keep_ambiguous", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "file_or_path", ",", "str", ")", ":", "\n", "      ", "with", "open", "(", "file_or_path", ",", "encoding", "=", "'latin-1'", ")", "as", "f", ":", "\n", "        ", "entries", "=", "_parse_cmudict", "(", "f", ")", "\n", "", "", "else", ":", "\n", "      ", "entries", "=", "_parse_cmudict", "(", "file_or_path", ")", "\n", "", "if", "not", "keep_ambiguous", ":", "\n", "      ", "entries", "=", "{", "word", ":", "pron", "for", "word", ",", "pron", "in", "entries", ".", "items", "(", ")", "if", "len", "(", "pron", ")", "==", "1", "}", "\n", "", "self", ".", "_entries", "=", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict.CMUDict.__len__": [[52, 54], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_entries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict.CMUDict.lookup": [[56, 59], ["cmudict.CMUDict._entries.get", "word.upper"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "word", ")", ":", "\n", "    ", "'''Returns list of ARPAbet pronunciations of the given word.'''", "\n", "return", "self", ".", "_entries", ".", "get", "(", "word", ".", "upper", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict._parse_cmudict": [[65, 78], ["len", "line.split", "re.sub", "cmudict._get_pronunciation", "cmudict[].append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict._get_pronunciation"], ["def", "_parse_cmudict", "(", "file", ")", ":", "\n", "  ", "cmudict", "=", "{", "}", "\n", "for", "line", "in", "file", ":", "\n", "    ", "if", "len", "(", "line", ")", "and", "(", "line", "[", "0", "]", ">=", "'A'", "and", "line", "[", "0", "]", "<=", "'Z'", "or", "line", "[", "0", "]", "==", "\"'\"", ")", ":", "\n", "      ", "parts", "=", "line", ".", "split", "(", "'  '", ")", "\n", "word", "=", "re", ".", "sub", "(", "_alt_re", ",", "''", ",", "parts", "[", "0", "]", ")", "\n", "pronunciation", "=", "_get_pronunciation", "(", "parts", "[", "1", "]", ")", "\n", "if", "pronunciation", ":", "\n", "        ", "if", "word", "in", "cmudict", ":", "\n", "          ", "cmudict", "[", "word", "]", ".", "append", "(", "pronunciation", ")", "\n", "", "else", ":", "\n", "          ", "cmudict", "[", "word", "]", "=", "[", "pronunciation", "]", "\n", "", "", "", "", "return", "cmudict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.cmudict._get_pronunciation": [[80, 86], ["s.strip().split", "s.strip"], "function", ["None"], ["", "def", "_get_pronunciation", "(", "s", ")", ":", "\n", "  ", "parts", "=", "s", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "part", "in", "parts", ":", "\n", "    ", "if", "part", "not", "in", "_valid_symbol_set", ":", "\n", "      ", "return", "None", "\n", "", "", "return", "' '", ".", "join", "(", "parts", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.__init__": [[21, 30], ["getattr", "utils.load_code_dict"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.load_code_dict"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "append_str", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "is_text", "=", "getattr", "(", "hparams", ",", "\"text_or_code\"", ",", "\"text\"", ")", "==", "\"text\"", "\n", "if", "not", "self", ".", "is_text", ":", "\n", "            ", "self", ".", "code_dict", "=", "load_code_dict", "(", "hparams", ".", "code_dict", ")", "\n", "self", ".", "code_key", "=", "hparams", ".", "code_key", "\n", "", "self", ".", "add_sos", "=", "hparams", ".", "add_sos", "\n", "self", ".", "add_eos", "=", "hparams", ".", "add_eos", "\n", "self", ".", "collapse_code", "=", "hparams", ".", "collapse_code", "\n", "self", ".", "append_str", "=", "append_str", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.process_code": [[31, 38], ["inp_str.split", "text.code_to_sequence"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.code_to_sequence"], ["", "def", "process_code", "(", "self", ",", "inp_str", ")", ":", "\n", "        ", "inp_toks", "=", "inp_str", ".", "split", "(", ")", "\n", "if", "self", ".", "add_sos", ":", "\n", "            ", "inp_toks", "=", "[", "SOS_TOK", "]", "+", "inp_toks", "\n", "", "if", "self", ".", "add_eos", ":", "\n", "            ", "inp_toks", "=", "inp_toks", "+", "[", "EOS_TOK", "]", "\n", "", "return", "code_to_sequence", "(", "inp_toks", ",", "self", ".", "code_dict", ",", "self", ".", "collapse_code", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.process_text": [[39, 41], ["text.text_to_sequence"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.text.text_to_sequence"], ["", "def", "process_text", "(", "self", ",", "inp_str", ")", ":", "\n", "        ", "return", "text_to_sequence", "(", "inp_str", ",", "[", "\"english_cleaners\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.get_tensor": [[42, 50], ["torch.from_numpy().long", "tts_data.TacotronInputDataset.process_text", "tts_data.TacotronInputDataset.process_code", "torch.from_numpy", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.process_text", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.process_code"], ["", "def", "get_tensor", "(", "self", ",", "inp_str", ")", ":", "\n", "# uid, txt, inp_str = self._get_data(idx)", "\n", "        ", "inp_str", "=", "inp_str", "+", "self", ".", "append_str", "\n", "if", "self", ".", "is_text", ":", "\n", "            ", "inp_toks", "=", "self", ".", "process_text", "(", "inp_str", ")", "\n", "", "else", ":", "\n", "            ", "inp_toks", "=", "self", ".", "process_code", "(", "inp_str", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "inp_toks", ")", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.__len__": [[51, 53], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.__init__.get_waveglow": [[16, 29], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "sys.path.append", "sys.path.pop", "waveglow.cuda().eval.cuda().eval", "waveglow_denoiser.Denoiser", "torch.load", "waveglow.cuda().eval.cuda"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["\n", "QUANTIZER_MODELS", "=", "{", "\n", "\"kmeans\"", ":", "KMeansQuantizer", ",", "\n", "}", "\n", "\n", "\n", "# TODO: add kwargs everywhere", "\n", "def", "dispatch_dense_model", "(", "name", ":", "str", ",", "**", "kwargs", ")", ":", "\n", "    ", "model_class", "=", "DENSE_MODELS", "[", "name", "]", "\n", "checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "name", ")", "\n", "return", "model_class", "(", "checkpoint_path", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "def", "dispatch_quantizer", "(", "dense_model_name", ":", "str", ",", "quantizer_name", ":", "str", ",", "vocab_size", ":", "int", ")", ":", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.__init__.load_tacotron": [[31, 51], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "torch.load", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "model.Tacotron2", "model.cuda().eval().half.load_state_dict", "model.cuda().eval().half.cuda().eval().half", "tts_data.TacotronInputDataset", "model.cuda().eval().half.cuda().eval", "model.cuda().eval().half.cuda"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["checkpoint_path", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "quantizer_checkpoint_name", ")", "\n", "quantizer", "=", "QUANTIZER_MODELS", "[", "quantizer_name", "]", "(", "checkpoint_path", ")", "\n", "return", "quantizer", "\n", "\n", "\n", "", "def", "dispatch_vocoder", "(", "\n", "dense_model_name", ":", "str", ",", "\n", "quantizer_name", ":", "str", ",", "\n", "vocoder_name", ":", "str", ",", "\n", "vocab_size", ":", "int", ",", "\n", ")", ":", "\n", "    ", "if", "vocoder_name", "==", "\"tacotron\"", ":", "\n", "        ", "vocoder", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", ",", "\n", "quantizer_name", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"Unsupported vocoder name\"", "\n", "", "return", "vocoder", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.__init__.synthesize_audio": [[53, 68], ["tts_dataset.get_tensor().cuda().unsqueeze", "map", "torch.LongTensor().cuda().fill_", "torch.no_grad", "model.inference", "mel.float.float", "waveglow.infer", "denoiser().squeeze", "units.tolist", "tts_dataset.get_tensor().cuda", "torch.LongTensor().cuda", "denoiser", "tts_dataset.get_tensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Tacotron2.inference", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.glow.WaveGlow.infer", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.tts_data.TacotronInputDataset.get_tensor"], []], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer.__init__": [[120, 123], ["utils.CudaTimer.reset"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.reset"], ["    ", "def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer.start": [[124, 129], ["torch.cuda.Event", "torch.cuda.Event.record", "utils.CudaTimer.start_events[].append"], "methods", ["None"], ["", "def", "start", "(", "self", ",", "key", ")", ":", "\n", "        ", "s", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "s", ".", "record", "(", ")", "\n", "self", ".", "start_events", "[", "key", "]", ".", "append", "(", "s", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer.stop": [[130, 135], ["torch.cuda.Event", "torch.cuda.Event.record", "utils.CudaTimer.end_events[].append"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "key", ")", ":", "\n", "        ", "e", "=", "torch", ".", "cuda", ".", "Event", "(", "enable_timing", "=", "True", ")", "\n", "e", ".", "record", "(", ")", "\n", "self", ".", "end_events", "[", "key", "]", ".", "append", "(", "e", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer.reset": [[136, 142], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_events", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "self", ".", "end_events", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "self", ".", "running_times", "=", "collections", ".", "defaultdict", "(", "float", ")", "\n", "self", ".", "n", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer.value": [[143, 146], ["utils.CudaTimer._synchronize"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer._synchronize"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "self", ".", "_synchronize", "(", ")", "\n", "return", "{", "k", ":", "self", ".", "running_times", "[", "k", "]", "/", "self", ".", "n", "[", "k", "]", "for", "k", "in", "self", ".", "keys", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.CudaTimer._synchronize": [[147, 163], ["torch.cuda.synchronize", "collections.defaultdict", "collections.defaultdict", "zip", "len", "len", "ValueError", "len", "len", "ValueError", "start.elapsed_time"], "methods", ["None"], ["", "def", "_synchronize", "(", "self", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "for", "k", "in", "self", ".", "keys", ":", "\n", "            ", "starts", "=", "self", ".", "start_events", "[", "k", "]", "\n", "ends", "=", "self", ".", "end_events", "[", "k", "]", "\n", "if", "len", "(", "starts", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"Trying to divide by zero in TimeMeter\"", ")", "\n", "", "if", "len", "(", "ends", ")", "!=", "len", "(", "starts", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Call stop before checking value!\"", ")", "\n", "", "time", "=", "0", "\n", "for", "start", ",", "end", "in", "zip", "(", "starts", ",", "ends", ")", ":", "\n", "                ", "time", "+=", "start", ".", "elapsed_time", "(", "end", ")", "\n", "", "self", ".", "running_times", "[", "k", "]", "+=", "time", "*", "1e-3", "\n", "self", ".", "n", "[", "k", "]", "+=", "len", "(", "starts", ")", "\n", "", "self", ".", "start_events", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "self", ".", "end_events", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.__init__": [[167, 173], ["utils.Timer.reset"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.reset"], ["    ", "def", "__init__", "(", "self", ",", "keys", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keys", "\n", "self", ".", "n", "=", "{", "}", "\n", "self", ".", "running_time", "=", "{", "}", "\n", "self", ".", "total_time", "=", "{", "}", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.start": [[174, 177], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ",", "key", ")", ":", "\n", "        ", "self", ".", "running_time", "[", "key", "]", "=", "time", ".", "time", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.stop": [[178, 183], ["time.time"], "methods", ["None"], ["", "def", "stop", "(", "self", ",", "key", ")", ":", "\n", "        ", "self", ".", "total_time", "[", "key", "]", "=", "time", ".", "time", "(", ")", "-", "self", ".", "running_time", "[", "key", "]", "\n", "self", ".", "n", "[", "key", "]", "+=", "1", "\n", "self", ".", "running_time", "[", "key", "]", "=", "None", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.reset": [[184, 190], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "k", "in", "self", ".", "keys", ":", "\n", "            ", "self", ".", "total_time", "[", "k", "]", "=", "0", "\n", "self", ".", "running_time", "[", "k", "]", "=", "None", "\n", "self", ".", "n", "[", "k", "]", "=", "0", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.Timer.value": [[191, 199], ["ValueError"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "vals", "=", "{", "}", "\n", "for", "k", "in", "self", ".", "keys", ":", "\n", "            ", "if", "self", ".", "n", "[", "k", "]", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\"Trying to divide by zero in TimeMeter\"", ")", "\n", "", "else", ":", "\n", "                ", "vals", "[", "k", "]", "=", "self", ".", "total_time", "[", "k", "]", "/", "self", ".", "n", "[", "k", "]", "\n", "", "", "return", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.get_mask_from_lengths": [[45, 50], ["torch.max().item", "torch.arange", "lengths.unsqueeze", "torch.max", "torch.cuda.LongTensor"], "function", ["None"], ["def", "get_mask_from_lengths", "(", "lengths", ")", ":", "\n", "    ", "max_len", "=", "torch", ".", "max", "(", "lengths", ")", ".", "item", "(", ")", "\n", "ids", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "out", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "max_len", ")", ")", "\n", "mask", "=", "(", "ids", "<", "lengths", ".", "unsqueeze", "(", "1", ")", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.load_wav_to_torch": [[52, 57], ["librosa.load", "numpy.clip", "torch.FloatTensor", "np.clip.astype"], "function", ["None"], ["", "def", "load_wav_to_torch", "(", "full_path", ",", "sr", "=", "None", ")", ":", "\n", "    ", "data", ",", "sr", "=", "librosa", ".", "load", "(", "full_path", ",", "sr", "=", "sr", ")", "\n", "data", "=", "np", ".", "clip", "(", "data", ",", "-", "1", ",", "1", ")", "# potentially out of [-1, 1] due to resampling", "\n", "data", "=", "data", "*", "32768.0", "# match values loaded by scipy", "\n", "return", "torch", ".", "FloatTensor", "(", "data", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "sr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.read_binary_audio": [[59, 77], ["soundfile.read", "numpy.clip", "io.BytesIO", "librosa.resample", "torch.FloatTensor", "librosa.resample.astype"], "function", ["None"], ["", "def", "read_binary_audio", "(", "bin_data", ",", "tar_sr", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    read binary audio (`bytes` or `uint8` `numpy.ndarray`) to `float32`\n    `numpy.ndarray`\n\n    RETURNS:\n        data (np.ndarray) : audio of shape (n,) or (2, n)\n        tar_sr (int) : sample rate\n    \"\"\"", "\n", "data", ",", "ori_sr", "=", "sf", ".", "read", "(", "io", ".", "BytesIO", "(", "bin_data", ")", ",", "dtype", "=", "'float32'", ")", "\n", "data", "=", "data", ".", "T", "\n", "if", "(", "tar_sr", "is", "not", "None", ")", "and", "(", "ori_sr", "!=", "tar_sr", ")", ":", "\n", "        ", "data", "=", "librosa", ".", "resample", "(", "data", ",", "ori_sr", ",", "tar_sr", ")", "\n", "", "else", ":", "\n", "        ", "tar_sr", "=", "ori_sr", "\n", "", "data", "=", "np", ".", "clip", "(", "data", ",", "-", "1", ",", "1", ")", "\n", "data", "=", "data", "*", "32768.0", "\n", "return", "torch", ".", "FloatTensor", "(", "data", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "tar_sr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.load_filepaths_and_text": [[79, 83], ["open", "json.loads", "line.rstrip"], "function", ["None"], ["", "def", "load_filepaths_and_text", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "data", "=", "[", "json", ".", "loads", "(", "line", ".", "rstrip", "(", ")", ")", "for", "line", "in", "f", "]", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.to_gpu": [[85, 91], ["x.cuda.contiguous", "torch.cuda.is_available", "torch.autograd.Variable", "x.cuda.cuda"], "function", ["None"], ["", "def", "to_gpu", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "x", "=", "x", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "", "return", "torch", ".", "autograd", ".", "Variable", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.load_code_dict": [[93, 108], ["open", "len", "len", "set", "set", "enumerate", "code_dict.values", "range", "line.rstrip", "len"], "function", ["None"], ["", "def", "load_code_dict", "(", "path", ",", "add_sos", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "    ", "if", "not", "path", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "codes", "=", "[", "'_'", "]", "+", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", "]", "# '_' for pad", "\n", "", "code_dict", "=", "{", "c", ":", "i", "for", "i", ",", "c", "in", "enumerate", "(", "codes", ")", "}", "\n", "\n", "if", "add_sos", ":", "\n", "        ", "code_dict", "[", "SOS_TOK", "]", "=", "len", "(", "code_dict", ")", "\n", "", "if", "add_eos", ":", "\n", "        ", "code_dict", "[", "EOS_TOK", "]", "=", "len", "(", "code_dict", ")", "\n", "", "assert", "(", "set", "(", "code_dict", ".", "values", "(", ")", ")", "==", "set", "(", "range", "(", "len", "(", "code_dict", ")", ")", ")", ")", "\n", "\n", "return", "code_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.utils.load_obs_label_dict": [[110, 116], ["open", "line.rstrip", "enumerate"], "function", ["None"], ["", "def", "load_obs_label_dict", "(", "path", ")", ":", "\n", "    ", "if", "not", "path", ":", "\n", "        ", "return", "{", "}", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "obs_labels", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", "]", "\n", "", "return", "{", "c", ":", "i", "for", "i", ",", "c", "in", "enumerate", "(", "obs_labels", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.__init__": [[44, 76], ["super().__init__", "numpy.fft.fft", "int", "numpy.vstack", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "stft.STFT.register_buffer", "stft.STFT.register_buffer", "numpy.eye", "scipy.signal.get_window", "librosa.util.pad_center", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.FloatTensor.float", "torch.FloatTensor.float", "torch.FloatTensor.float", "torch.FloatTensor.float", "numpy.real", "numpy.imag", "numpy.linalg.pinv", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "filter_length", "=", "800", ",", "hop_length", "=", "200", ",", "win_length", "=", "800", ",", "\n", "window", "=", "'hann'", ")", ":", "\n", "        ", "super", "(", "STFT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filter_length", "=", "filter_length", "\n", "self", ".", "hop_length", "=", "hop_length", "\n", "self", ".", "win_length", "=", "win_length", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "forward_transform", "=", "None", "\n", "scale", "=", "self", ".", "filter_length", "/", "self", ".", "hop_length", "\n", "fourier_basis", "=", "np", ".", "fft", ".", "fft", "(", "np", ".", "eye", "(", "self", ".", "filter_length", ")", ")", "\n", "\n", "cutoff", "=", "int", "(", "(", "self", ".", "filter_length", "/", "2", "+", "1", ")", ")", "\n", "fourier_basis", "=", "np", ".", "vstack", "(", "[", "np", ".", "real", "(", "fourier_basis", "[", ":", "cutoff", ",", ":", "]", ")", ",", "\n", "np", ".", "imag", "(", "fourier_basis", "[", ":", "cutoff", ",", ":", "]", ")", "]", ")", "\n", "\n", "forward_basis", "=", "torch", ".", "FloatTensor", "(", "fourier_basis", "[", ":", ",", "None", ",", ":", "]", ")", "\n", "inverse_basis", "=", "torch", ".", "FloatTensor", "(", "\n", "np", ".", "linalg", ".", "pinv", "(", "scale", "*", "fourier_basis", ")", ".", "T", "[", ":", ",", "None", ",", ":", "]", ")", "\n", "\n", "if", "window", "is", "not", "None", ":", "\n", "            ", "assert", "(", "filter_length", ">=", "win_length", ")", "\n", "# get window and zero center pad it to filter_length", "\n", "fft_window", "=", "get_window", "(", "window", ",", "win_length", ",", "fftbins", "=", "True", ")", "\n", "fft_window", "=", "pad_center", "(", "fft_window", ",", "filter_length", ")", "\n", "fft_window", "=", "torch", ".", "from_numpy", "(", "fft_window", ")", ".", "float", "(", ")", "\n", "\n", "# window the bases", "\n", "forward_basis", "*=", "fft_window", "\n", "inverse_basis", "*=", "fft_window", "\n", "\n", "", "self", ".", "register_buffer", "(", "'forward_basis'", ",", "forward_basis", ".", "float", "(", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inverse_basis'", ",", "inverse_basis", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform": [[77, 106], ["input_data.squeeze.squeeze.size", "input_data.squeeze.squeeze.size", "input_data.squeeze.squeeze.view", "torch.pad", "torch.pad", "input_data.squeeze.squeeze.squeeze", "torch.conv1d", "torch.conv1d", "int", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "input_data.squeeze.squeeze.unsqueeze", "torch.autograd.Variable", "torch.autograd.Variable", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "int", "int"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "num_batches", "=", "input_data", ".", "size", "(", "0", ")", "\n", "num_samples", "=", "input_data", ".", "size", "(", "1", ")", "\n", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "\n", "# similar to librosa, reflect-pad the input", "\n", "input_data", "=", "input_data", ".", "view", "(", "num_batches", ",", "1", ",", "num_samples", ")", "\n", "input_data", "=", "F", ".", "pad", "(", "\n", "input_data", ".", "unsqueeze", "(", "1", ")", ",", "\n", "(", "int", "(", "self", ".", "filter_length", "/", "2", ")", ",", "int", "(", "self", ".", "filter_length", "/", "2", ")", ",", "0", ",", "0", ")", ",", "\n", "mode", "=", "'reflect'", ")", "\n", "input_data", "=", "input_data", ".", "squeeze", "(", "1", ")", "\n", "\n", "forward_transform", "=", "F", ".", "conv1d", "(", "\n", "input_data", ",", "\n", "Variable", "(", "self", ".", "forward_basis", ",", "requires_grad", "=", "False", ")", ",", "\n", "stride", "=", "self", ".", "hop_length", ",", "\n", "padding", "=", "0", ")", "\n", "\n", "cutoff", "=", "int", "(", "(", "self", ".", "filter_length", "/", "2", ")", "+", "1", ")", "\n", "real_part", "=", "forward_transform", "[", ":", ",", ":", "cutoff", ",", ":", "]", "\n", "imag_part", "=", "forward_transform", "[", ":", ",", "cutoff", ":", ",", ":", "]", "\n", "\n", "magnitude", "=", "torch", ".", "sqrt", "(", "real_part", "**", "2", "+", "imag_part", "**", "2", ")", "\n", "phase", "=", "torch", ".", "autograd", ".", "Variable", "(", "\n", "torch", ".", "atan2", "(", "imag_part", ".", "data", ",", "real_part", ".", "data", ")", ")", "\n", "\n", "return", "magnitude", ",", "phase", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse": [[107, 137], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.conv_transpose1d", "torch.conv_transpose1d", "torch.autograd.Variable", "torch.autograd.Variable", "audio_processing.window_sumsquare", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "magnitude.size", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "float", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "numpy.where", "int", "int", "librosa.util.tiny"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.audio_processing.window_sumsquare"], ["", "def", "inverse", "(", "self", ",", "magnitude", ",", "phase", ")", ":", "\n", "        ", "recombine_magnitude_phase", "=", "torch", ".", "cat", "(", "\n", "[", "magnitude", "*", "torch", ".", "cos", "(", "phase", ")", ",", "magnitude", "*", "torch", ".", "sin", "(", "phase", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "inverse_transform", "=", "F", ".", "conv_transpose1d", "(", "\n", "recombine_magnitude_phase", ",", "\n", "Variable", "(", "self", ".", "inverse_basis", ",", "requires_grad", "=", "False", ")", ",", "\n", "stride", "=", "self", ".", "hop_length", ",", "\n", "padding", "=", "0", ")", "\n", "\n", "if", "self", ".", "window", "is", "not", "None", ":", "\n", "            ", "window_sum", "=", "window_sumsquare", "(", "\n", "self", ".", "window", ",", "magnitude", ".", "size", "(", "-", "1", ")", ",", "hop_length", "=", "self", ".", "hop_length", ",", "\n", "win_length", "=", "self", ".", "win_length", ",", "n_fft", "=", "self", ".", "filter_length", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "# remove modulation effects", "\n", "approx_nonzero_indices", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "where", "(", "window_sum", ">", "tiny", "(", "window_sum", ")", ")", "[", "0", "]", ")", "\n", "window_sum", "=", "torch", ".", "autograd", ".", "Variable", "(", "\n", "torch", ".", "from_numpy", "(", "window_sum", ")", ",", "requires_grad", "=", "False", ")", "\n", "window_sum", "=", "window_sum", ".", "cuda", "(", ")", "if", "magnitude", ".", "is_cuda", "else", "window_sum", "\n", "inverse_transform", "[", ":", ",", ":", ",", "approx_nonzero_indices", "]", "/=", "window_sum", "[", "approx_nonzero_indices", "]", "\n", "\n", "# scale by hop ratio", "\n", "inverse_transform", "*=", "float", "(", "self", ".", "filter_length", ")", "/", "self", ".", "hop_length", "\n", "\n", "", "inverse_transform", "=", "inverse_transform", "[", ":", ",", ":", ",", "int", "(", "self", ".", "filter_length", "/", "2", ")", ":", "]", "\n", "inverse_transform", "=", "inverse_transform", "[", ":", ",", ":", ",", ":", "-", "int", "(", "self", ".", "filter_length", "/", "2", ")", ":", "]", "\n", "\n", "return", "inverse_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.forward": [[138, 142], ["stft.STFT.transform", "stft.STFT.inverse"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.transform", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.stft.STFT.inverse"], ["", "def", "forward", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "self", ".", "magnitude", ",", "self", ".", "phase", "=", "self", ".", "transform", "(", "input_data", ")", "\n", "reconstruction", "=", "self", ".", "inverse", "(", "self", ".", "magnitude", ",", "self", ".", "phase", ")", "\n", "return", "reconstruction", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.get_args": [[22, 80], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logger.info"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vocab_size\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Quantization codebook vocabulary size\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dense_model\"", ",", "default", "=", "\"hubert-base-ls960\"", ",", "help", "=", "\"Dense model to be used\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--quantizer_model\"", ",", "default", "=", "\"kmeans\"", ",", "help", "=", "\"Quantizer model to be used\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--manifest\"", ",", "required", "=", "True", ",", "help", "=", "\"Path to the dataset manifest file\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the output files. Pseudo-units and duration (if requested) streams will be stored in files with .units and .durations suffixes, respectively\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--deduplicate\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, consecutive repeats of the same pseudo-unit are collapsed ('1 2 2 2 3' becomes '1 2 3')\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--durations\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, the token durations stream is produced\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--f0s\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"if set, the F0 stream is produced\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--preserve_name\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If set, the transcript contains names of the audio files\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--separator\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\" \"", ",", "\n", "help", "=", "\"Separator between pseudo-unit tokens\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--distributed_port\"", ",", "type", "=", "int", ",", "default", "=", "58554", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "logger", ".", "info", "(", "f\"Launched with args: {args}\"", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.worker_shard_path": [[82, 84], ["pathlib.Path().with_suffix", "pathlib.Path"], "function", ["None"], ["", "def", "worker_shard_path", "(", "fname", ",", "suffix", ",", "worker_id", ")", "->", "pathlib", ".", "Path", ":", "\n", "    ", "return", "pathlib", ".", "Path", "(", "fname", ")", ".", "with_suffix", "(", "f\".{suffix}_partial_{worker_id}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.transcribe": [[86, 128], ["data_handler.ManifestDataset", "textless.data.speech_encoder.SpeechEncoder.by_name().cuda", "range", "output_files.values", "open", "len", "SpeechEncoder.by_name().cuda.", "textless.data.speech_encoder.SpeechEncoder.by_name", "transcribe.worker_shard_path", "open", "open", "args.separator.join", "print", "fout.close", "transcribe.worker_shard_path", "transcribe.worker_shard_path", "str", "int", "args.separator.join.tolist"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.worker_shard_path", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.worker_shard_path", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.worker_shard_path"], ["", "def", "transcribe", "(", "args", ",", "rank", ",", "world_size", ")", ":", "\n", "    ", "dataset", "=", "ManifestDataset", "(", "args", ".", "manifest", ")", "\n", "\n", "speech_encoder", "=", "SpeechEncoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "args", ".", "dense_model", ",", "\n", "quantizer_model_name", "=", "args", ".", "quantizer_model", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "deduplicate", "=", "args", ".", "deduplicate", ",", "\n", "need_f0", "=", "args", ".", "f0s", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "output_files", "=", "{", "\n", "\"units\"", ":", "open", "(", "worker_shard_path", "(", "args", ".", "output", ",", "\"units\"", ",", "rank", ")", ",", "\"w\"", ")", ",", "\n", "\"durations\"", ":", "None", "\n", "if", "not", "args", ".", "durations", "\n", "else", "open", "(", "worker_shard_path", "(", "args", ".", "output", ",", "\"durations\"", ",", "rank", ")", ",", "\"w\"", ")", ",", "\n", "\"f0s\"", ":", "None", "\n", "if", "not", "args", ".", "f0s", "\n", "else", "open", "(", "worker_shard_path", "(", "args", ".", "output", ",", "\"f0s\"", ",", "rank", ")", ",", "\"w\"", ")", ",", "\n", "}", "\n", "\n", "# DistributedSampler will pad the dataloader to be divisible", "\n", "# by the number of workers, which we do not want so we iterate directly", "\n", "for", "i", "in", "range", "(", "rank", ",", "len", "(", "dataset", ")", ",", "world_size", ")", ":", "\n", "        ", "waveform", ",", "name", "=", "dataset", "[", "i", "]", "\n", "encoded", "=", "speech_encoder", "(", "waveform", ")", "\n", "\n", "stream_names", "=", "[", "\"units\"", ",", "\"durations\"", "]", "\n", "if", "args", ".", "f0s", ":", "\n", "            ", "stream_names", "+=", "[", "\"f0s\"", "]", "\n", "\n", "", "for", "stream_name", "in", "stream_names", ":", "\n", "            ", "stream", "=", "encoded", "[", "stream_name", "]", "\n", "stream", "=", "[", "str", "(", "int", "(", "x", ")", ")", "for", "x", "in", "stream", ".", "tolist", "(", ")", "]", "\n", "stream", "=", "args", ".", "separator", ".", "join", "(", "stream", ")", "\n", "\n", "stream", "=", "f\"{name}\\t{stream}\"", "if", "args", ".", "preserve_name", "else", "stream", "\n", "print", "(", "stream", ",", "file", "=", "output_files", "[", "stream_name", "]", ")", "\n", "\n", "", "", "for", "fout", "in", "output_files", ".", "values", "(", ")", ":", "\n", "        ", "if", "fout", ":", "\n", "            ", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.main": [[130, 150], ["distributed.init_distributed_context", "logger.info", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device", "torch.cuda.device", "transcribe.transcribe", "torch.barrier", "transcribe.merge_files"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.distributed.init_distributed_context", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.transcribe", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.merge_files"], ["", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "context", "=", "init_distributed_context", "(", "args", ".", "distributed_port", ")", "\n", "logger", ".", "info", "(", "f\"Distributed context {context}\"", ")", "\n", "\n", "n_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "with", "torch", ".", "cuda", ".", "device", "(", "context", ".", "local_rank", "%", "n_gpus", ")", ":", "\n", "        ", "transcribe", "(", "args", ",", "context", ".", "rank", ",", "context", ".", "world_size", ")", "\n", "\n", "", "if", "context", ".", "world_size", ">", "1", ":", "\n", "        ", "distr", ".", "barrier", "(", ")", "\n", "\n", "", "if", "context", ".", "is_leader", ":", "\n", "        ", "generated_streams", "=", "[", "\"units\"", "]", "\n", "if", "args", ".", "durations", ":", "\n", "            ", "generated_streams", "+=", "[", "\"durations\"", "]", "\n", "", "if", "args", ".", "f0s", ":", "\n", "            ", "generated_streams", "+=", "[", "\"f0s\"", "]", "\n", "\n", "", "for", "stream_name", "in", "generated_streams", ":", "\n", "            ", "merge_files", "(", "args", ".", "output", ",", "stream_name", ",", "context", ".", "world_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.merge_files": [[152, 161], ["open", "range", "transcribe.worker_shard_path", "open", "worker_shard_path.unlink", "print", "line.strip"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.transcribe.worker_shard_path"], ["", "", "", "def", "merge_files", "(", "full_output", ",", "suffix", ",", "n_workers", ")", ":", "\n", "    ", "output", "=", "full_output", "+", "f\".{suffix}\"", "\n", "with", "open", "(", "output", ",", "\"w\"", ")", "as", "full", ":", "\n", "        ", "for", "worker_id", "in", "range", "(", "n_workers", ")", ":", "\n", "            ", "partial_path", "=", "worker_shard_path", "(", "full_output", ",", "suffix", ",", "worker_id", ")", "\n", "partial", "=", "open", "(", "partial_path", ",", "\"r\"", ")", "\n", "for", "line", "in", "partial", ":", "\n", "                ", "print", "(", "line", ".", "strip", "(", ")", ",", "file", "=", "full", ")", "\n", "", "partial_path", ".", "unlink", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.distributed.DistributedContext.is_leader": [[20, 23], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "is_leader", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "self", ".", "rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.distributed.init_distributed_context": [[25, 92], ["distributed.DistributedContext", "all", "int", "int", "int", "distributed.DistributedContext", "torch.init_process_group", "all", "int", "int", "int", "subprocess.check_output", "[].decode", "str", "str", "str", "distributed.DistributedContext", "torch.init_process_group", "subprocess.check_output.split"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.model.Decoder.decode"], ["", "", "def", "init_distributed_context", "(", "port", ":", "int", ")", "->", "DistributedContext", ":", "\n", "# Sometimes the nccl backend hangs on the barrier op (https://github.com/pytorch/pytorch/issues/53658).", "\n", "# Since it is the only op we care about here, we'd use the gloo backend.", "\n", "    ", "BACKEND", "=", "\"gloo\"", "\n", "\n", "# default, non-distributed context", "\n", "context", "=", "DistributedContext", "(", "\n", "is_distributed", "=", "False", ",", "rank", "=", "0", ",", "local_rank", "=", "0", ",", "world_size", "=", "1", ",", "mode", "=", "\"none\"", "\n", ")", "\n", "\n", "launch_keys", "=", "[", "\"MASTER_ADDR\"", ",", "\"MASTER_PORT\"", ",", "\"WORLD_SIZE\"", ",", "\"RANK\"", ",", "\"LOCAL_RANK\"", "]", "\n", "slurm_keys", "=", "[", "\n", "\"SLURM_LOCALID\"", ",", "\n", "\"SLURM_PROCID\"", ",", "\n", "\"SLURM_NTASKS\"", ",", "\n", "\"SLURM_NODEID\"", ",", "\n", "\"SLURM_JOB_NODELIST\"", ",", "\n", "]", "\n", "\n", "# is it torch.distributed.launch?", "\n", "if", "all", "(", "key", "in", "os", ".", "environ", "for", "key", "in", "launch_keys", ")", ":", "\n", "        ", "init_method", "=", "\"env://\"", "\n", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "\"LOCAL_RANK\"", "]", ")", "\n", "context", "=", "DistributedContext", "(", "\n", "is_distributed", "=", "True", ",", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", "local_rank", "=", "local_rank", ",", "\n", "mode", "=", "\"launch\"", ",", "\n", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "BACKEND", ",", "init_method", "=", "init_method", ",", "world_size", "=", "world_size", ",", "rank", "=", "rank", "\n", ")", "\n", "# is it slurm?", "\n", "", "elif", "all", "(", "key", "in", "os", ".", "environ", "for", "key", "in", "slurm_keys", ")", ":", "\n", "        ", "init_method", "=", "\"env://\"", "\n", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "\"SLURM_LOCALID\"", "]", ")", "\n", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"SLURM_PROCID\"", "]", ")", "\n", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"SLURM_NTASKS\"", "]", ")", "\n", "\n", "hostnames", "=", "subprocess", ".", "check_output", "(", "\n", "[", "\"scontrol\"", ",", "\"show\"", ",", "\"hostnames\"", ",", "os", ".", "environ", "[", "\"SLURM_JOB_NODELIST\"", "]", "]", "\n", ")", "\n", "leader_addr", "=", "hostnames", ".", "split", "(", ")", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "os", ".", "environ", "[", "\"MASTER_ADDR\"", "]", "=", "leader_addr", "\n", "os", ".", "environ", "[", "\"MASTER_PORT\"", "]", "=", "str", "(", "port", ")", "\n", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", "=", "str", "(", "world_size", ")", "\n", "os", ".", "environ", "[", "\"RANK\"", "]", "=", "str", "(", "rank", ")", "\n", "\n", "context", "=", "DistributedContext", "(", "\n", "is_distributed", "=", "True", ",", "\n", "rank", "=", "rank", ",", "\n", "local_rank", "=", "local_rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", "mode", "=", "\"slurm\"", ",", "\n", ")", "\n", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "BACKEND", ",", "\n", "init_method", "=", "init_method", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", ")", "\n", "\n", "", "return", "context", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.data_handler.ManifestDataset.__init__": [[16, 23], ["logger.info", "open", "pathlib.Path", "fin.readline().strip", "x.strip().split", "fin.readlines", "len", "fin.readline", "x.strip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "manifest", ")", ":", "\n", "        ", "with", "open", "(", "manifest", ",", "\"r\"", ")", "as", "fin", ":", "\n", "            ", "self", ".", "root", "=", "pathlib", ".", "Path", "(", "fin", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "files", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "for", "x", "in", "fin", ".", "readlines", "(", ")", "]", "\n", "\n", "", "logger", ".", "info", "(", "\n", "f\"Init dataset with root in {self.root}, containing {len(self.files)} files\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.data_handler.ManifestDataset.__len__": [[25, 27], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.distributed_transcribe.data_handler.ManifestDataset.__getitem__": [[28, 34], ["torchaudio.load", "str", "data.squeeze", "path.with_suffix"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "k", ")", ":", "\n", "        ", "path", "=", "self", ".", "root", "/", "self", ".", "files", "[", "k", "]", "\n", "data", ",", "sr", "=", "torchaudio", ".", "load", "(", "str", "(", "path", ")", ")", "\n", "\n", "assert", "sr", "==", "16_000", "\n", "return", "data", ".", "squeeze", "(", "0", ")", ",", "path", ".", "with_suffix", "(", "\"\"", ")", ".", "name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sample.GslmPipeline.__init__": [[25, 72], ["logger.info", "torch.device", "logger.info", "sampler.UnitLanguageModelSampler.from_pretrained", "logger.info", "logger.info", "textless.data.speech_encoder.SpeechEncoder.by_name().cuda", "logger.info", "logger.info", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name().cuda", "logger.info", "logger.info", "random.seed", "numpy.random.seed", "fairseq.utils.set_torch_seed", "textless.data.speech_encoder.SpeechEncoder.by_name", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.device", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.from_pretrained", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Initializing the GSLM pipeline.\"", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "            ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "utils", ".", "set_torch_seed", "(", "args", ".", "seed", ")", "\n", "\n", "", "self", ".", "temperature", "=", "args", ".", "temperature", "\n", "self", ".", "tokens_framerate", "=", "0.02", "# HuBERT framerate", "\n", "self", ".", "max_length", "=", "1000", "\n", "self", ".", "trim_trailing_audio_frames", "=", "200", "\n", "self", ".", "sampling_kwargs", "=", "{", "\n", "\"temperature\"", ":", "self", ".", "temperature", ",", "\n", "\"sampling\"", ":", "True", ",", "\n", "\"beam\"", ":", "1", ",", "\n", "\"prefix_size\"", ":", "-", "1", ",", "\n", "\"max_len_a\"", ":", "0.0", ",", "\n", "\"max_len_b\"", ":", "self", ".", "max_length", ",", "\n", "}", "\n", "logger", ".", "info", "(", "\"... Loading the language model\"", ")", "\n", "self", ".", "sampler", "=", "UnitLanguageModelSampler", ".", "from_pretrained", "(", "\n", "args", ".", "language_model_data_dir", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"=> Done!\"", ")", "\n", "logger", ".", "info", "(", "\"... Loading the encoder\"", ")", "\n", "\n", "self", ".", "speech_encoder", "=", "SpeechEncoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "\"hubert-base-ls960\"", ",", "\n", "quantizer_model_name", "=", "\"kmeans\"", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "need_f0", "=", "False", ",", "\n", "deduplicate", "=", "True", ",", "\n", "f0_normalizer", "=", "None", ",", "\n", "f0_quantizer", "=", "None", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"=> Done!\"", ")", "\n", "logger", ".", "info", "(", "\"... Loading the vocoder\"", ")", "\n", "self", ".", "resynthesizer", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "\"hubert-base-ls960\"", ",", "\n", "quantizer_model_name", "=", "\"kmeans\"", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"=> Done!\"", ")", "\n", "logger", ".", "info", "(", "\"Pipeline initialized!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sample.GslmPipeline.__call__": [[73, 96], ["sample.GslmPipeline.GslmPipeline.speech_encoder.maybe_resample", "sample.GslmPipeline.GslmPipeline.speech_encoder", "sample[].sum().item", "sample.GslmPipeline.GslmPipeline.resynthesizer", "list", "sample.GslmPipeline.GslmPipeline.sampler.sample", "sample[].sum", "map", "int", "units.tolist"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.maybe_resample", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.sample"], ["", "def", "__call__", "(", "self", ",", "raw_audio", ",", "sample_rate", ")", ":", "\n", "        ", "raw_audio", "=", "self", ".", "speech_encoder", ".", "maybe_resample", "(", "raw_audio", ",", "sample_rate", ")", "\n", "\n", "sample", "=", "self", ".", "speech_encoder", "(", "raw_audio", ")", "\n", "units", "=", "sample", "[", "\"units\"", "]", "\n", "duration", "=", "sample", "[", "\"durations\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "prefix_duration", "=", "self", ".", "tokens_framerate", "*", "duration", "\n", "target_duration", "=", "self", ".", "tokens_framerate", "*", "(", "\n", "self", ".", "max_length", "-", "self", ".", "trim_trailing_audio_frames", "\n", ")", "\n", "\n", "unit_str", "=", "\" \"", ".", "join", "(", "list", "(", "map", "(", "str", ",", "units", ".", "tolist", "(", ")", ")", ")", ")", "\n", "sampled_unit_str", "=", "self", ".", "sampler", ".", "sample", "(", "[", "unit_str", "]", ",", "**", "self", ".", "sampling_kwargs", ")", "[", "0", "]", "\n", "\n", "audio", "=", "self", ".", "resynthesizer", "(", "sampled_unit_str", ")", "\n", "audio", "=", "audio", "[", "\n", ":", "int", "(", "\n", "self", ".", "resynthesizer", ".", "output_sample_rate", "\n", "*", "(", "prefix_duration", "+", "target_duration", ")", "\n", ")", "\n", "]", "\n", "\n", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sample.GslmPipeline.output_sample_rate": [[97, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "resynthesizer", ".", "output_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sample.main": [[102, 120], ["sample.GslmPipeline", "torchaudio.load", "GslmPipeline.", "torchaudio.save", "audio.mean.mean", "int", "pipeline.cpu().unsqueeze", "pipeline.cpu"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "pipeline", "=", "GslmPipeline", "(", "args", ")", "\n", "\n", "audio", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "args", ".", "input_file", ")", "\n", "\n", "if", "audio", ".", "ndim", "==", "2", ":", "\n", "        ", "audio", "=", "audio", ".", "mean", "(", "0", ")", "\n", "\n", "", "if", "args", ".", "prompt_duration_sec", ":", "\n", "        ", "prompt", "=", "int", "(", "args", ".", "prompt_duration_sec", "*", "sample_rate", ")", "\n", "audio", "=", "audio", "[", ":", "prompt", "]", "\n", "\n", "", "generated_audio", "=", "pipeline", "(", "audio", ",", "sample_rate", ")", "\n", "\n", "torchaudio", ".", "save", "(", "\n", "args", ".", "output_file", ",", "\n", "generated_audio", ".", "cpu", "(", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "pipeline", ".", "output_sample_rate", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sample.cli_main": [[123, 166], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "sample.main"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.main"], ["", "def", "cli_main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input-file\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Input filepath\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--language-model-data-dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to language model dataset config path\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.7", ",", "\n", "help", "=", "\"Temperature: should be above 0.0\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--prompt-duration-sec\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Cutting prompts to a maximum duration\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output-file\"", ",", "type", "=", "str", ",", "help", "=", "\"Path where generated metadata is saved\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vocab-size\"", ",", "\n", "type", "=", "int", ",", "\n", "choices", "=", "[", "50", ",", "100", ",", "200", "]", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"Vocabulary size used\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.__init__": [[17, 21], ["fairseq.hub_utils.GeneratorHubInterface.__init__", "sampler.UnitLanguageModelSampler.model.eval"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__"], ["def", "__init__", "(", "self", ",", "cfg", ",", "task", ",", "models", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", ",", "task", ",", "models", ")", "\n", "self", ".", "model", "=", "self", ".", "models", "[", "0", "]", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.encode": [[22, 27], ["sampler.UnitLanguageModelSampler.task.source_dictionary.encode_line().long", "sampler.UnitLanguageModelSampler.task.source_dictionary.encode_line"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "unit_str", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "task", ".", "source_dictionary", ".", "encode_line", "(", "\n", "unit_str", ",", "add_if_not_exist", "=", "False", "\n", ")", ".", "long", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.get_prefix_size": [[28, 30], ["None"], "methods", ["None"], ["", "def", "get_prefix_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cfg", ".", "generation", ".", "prefix_size", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.post_process_predictions": [[31, 48], ["fairseq.utils.strip_pad", "sampler.UnitLanguageModelSampler.tgt_dict.pad", "sampler.UnitLanguageModelSampler.task.source_dictionary.string", "fairseq.utils.post_process_prediction", "hypo[].int().cpu", "hypo[].int"], "methods", ["None"], ["", "def", "post_process_predictions", "(", "self", ",", "src_tokens", ",", "hypos", ")", ":", "\n", "        ", "src_tokens", "=", "utils", ".", "strip_pad", "(", "src_tokens", ",", "self", ".", "tgt_dict", ".", "pad", "(", ")", ")", "\n", "src_str", "=", "None", "\n", "if", "self", ".", "task", ".", "source_dictionary", "is", "not", "None", ":", "\n", "            ", "src_str", "=", "self", ".", "task", ".", "source_dictionary", ".", "string", "(", "\n", "src_tokens", ",", "self", ".", "cfg", ".", "common_eval", ".", "post_process", "\n", ")", "\n", "", "return", "[", "\n", "utils", ".", "post_process_prediction", "(", "\n", "hypo_tokens", "=", "hypo", "[", "\"tokens\"", "]", ".", "int", "(", ")", ".", "cpu", "(", ")", ",", "\n", "src_str", "=", "src_str", ",", "\n", "alignment", "=", "hypo", "[", "\"alignment\"", "]", ",", "\n", "align_dict", "=", "self", ".", "align_dict", ",", "\n", "tgt_dict", "=", "self", ".", "tgt_dict", ",", "\n", "remove_bpe", "=", "self", ".", "cfg", ".", "common_eval", ".", "post_process", ",", "\n", ")", "[", "1", "]", "\n", "for", "hypo", "in", "hypos", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.sample": [[50, 55], ["sampler.UnitLanguageModelSampler.sample_top_hypotheses"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.sample_top_hypotheses"], ["", "def", "sample", "(", "\n", "self", ",", "sentences", ":", "tp", ".", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "hypotheses", "=", "self", ".", "sample_top_hypotheses", "(", "sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "return", "[", "hypos", "[", "0", "]", "for", "hypos", "in", "hypotheses", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.sample_top_hypotheses": [[56, 69], ["isinstance", "sampler.UnitLanguageModelSampler.generate", "sampler.UnitLanguageModelSampler.encode", "sampler.UnitLanguageModelSampler.post_process_predictions", "sampler.UnitLanguageModelSampler.sample_top_hypotheses", "zip"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.encode", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.post_process_predictions", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.sample_top_hypotheses"], ["", "def", "sample_top_hypotheses", "(", "\n", "self", ",", "sentences", ":", "tp", ".", "List", "[", "str", "]", ",", "beam", ":", "int", "=", "1", ",", "verbose", ":", "bool", "=", "False", ",", "**", "kwargs", "\n", ")", "->", "tp", ".", "List", "[", "str", "]", ":", "\n", "        ", "if", "isinstance", "(", "sentences", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "sample_top_hypotheses", "(", "\n", "[", "sentences", "]", ",", "beam", "=", "beam", ",", "verbose", "=", "verbose", ",", "**", "kwargs", "\n", ")", "[", "0", "]", "\n", "", "tokenized_sentences", "=", "[", "self", ".", "encode", "(", "sentence", ")", "for", "sentence", "in", "sentences", "]", "\n", "batched_hypos", "=", "self", ".", "generate", "(", "tokenized_sentences", ",", "beam", ",", "verbose", ",", "**", "kwargs", ")", "\n", "\n", "return", "[", "\n", "self", ".", "post_process_predictions", "(", "src_tokens", ",", "hypos", ")", "\n", "for", "src_tokens", ",", "hypos", "in", "zip", "(", "tokenized_sentences", ",", "batched_hypos", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.from_pretrained": [[71, 90], ["fairseq.hub_utils.from_pretrained", "cls"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.gslm.sampler.UnitLanguageModelSampler.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", "=", "\"checkpoint_best.pt\"", ",", "\n", "data_name_or_path", "=", "\".\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "x", "=", "hub_utils", ".", "from_pretrained", "(", "\n", "model_name_or_path", ",", "\n", "checkpoint_file", ",", "\n", "data_name_or_path", ",", "\n", "archive_map", "=", "None", ",", "\n", "bpe", "=", "None", ",", "\n", "load_checkpoint_heads", "=", "True", ",", "\n", "sample_break_mode", "=", "\"eos\"", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "cls", "(", "x", "[", "\"args\"", "]", ",", "x", "[", "\"task\"", "]", ",", "x", "[", "\"models\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.resynthesis.resynth.get_args": [[12, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dense_model_name\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"hubert-base-ls960\"", ",", "\n", "choices", "=", "[", "\"hubert-base-ls960\"", ",", "\"cpc-big-ll6k\"", "]", ",", "\n", "help", "=", "\"Dense representation model\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--vocab_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "50", ",", "\n", "help", "=", "\"Vocabulary size used for resynthesis\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--input\"", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the input audio file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output\"", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the output audio file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"Maximal number of decoder steps\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.resynthesis.resynth.get_compression_rate": [[50, 77], ["np.log2", "wave.numel", "units.size", "units.size"], "function", ["None"], ["", "def", "get_compression_rate", "(", "dense_model", ",", "units", ",", "wave", ",", "vocab_size", ",", "sample_rate", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "\n", "assert", "units", ".", "ndim", "==", "1", "\n", "assert", "wave", ".", "ndim", "==", "1", "\n", "\n", "time_in_seconds", "=", "wave", ".", "numel", "(", ")", "/", "sample_rate", "\n", "\n", "uniform_token_entropy", "=", "np", ".", "log2", "(", "vocab_size", ")", "\n", "# calculated on LL-6k train", "\n", "unigram_token_entropy", "=", "{", "\n", "\"hubert-base-ls960\"", ":", "{", "\n", "50", ":", "5.458528917634601", ",", "\n", "100", ":", "6.44513268276806", ",", "\n", "200", ":", "7.477069233162813", ",", "\n", "}", ",", "\n", "\"cpc-big-ll6k\"", ":", "{", "\n", "50", ":", "5.428271158461133", ",", "\n", "100", ":", "6.413083187885448", ",", "\n", "200", ":", "7.44253841579776", ",", "\n", "}", ",", "\n", "}", "[", "dense_model", "]", "[", "vocab_size", "]", "\n", "\n", "uniform_bps", "=", "uniform_token_entropy", "*", "units", ".", "size", "(", "0", ")", "/", "time_in_seconds", "\n", "unigram_entropy", "=", "unigram_token_entropy", "*", "units", ".", "size", "(", "0", ")", "/", "time_in_seconds", "\n", "\n", "return", "uniform_bps", ",", "unigram_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.resynthesis.resynth.main": [[79, 158], ["textless.data.speech_encoder.SpeechEncoder.by_name().cuda", "textless.dispatch_dense_model", "textless.dispatch_quantizer", "textless.data.speech_encoder.SpeechEncoder().cuda", "torchaudio.load", "SpeechEncoder().cuda.maybe_resample", "SpeechEncoder().cuda.", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name().cuda", "TacotronVocoder.by_name().cuda.", "torchaudio.save", "resynth.get_compression_rate", "print", "print", "print", "waveform.mean.mean", "waveform.mean.cuda", "vocoder.cpu().float().unsqueeze", "textless.data.speech_encoder.SpeechEncoder.by_name", "textless.data.speech_encoder.SpeechEncoder", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name", "vocoder.cpu().float", "round", "units.numel", "round", "round", "vocoder.cpu", "waveform.mean.size"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_dense_model", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.speech_encoder.SpeechEncoder.maybe_resample", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.resynthesis.resynth.get_compression_rate", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "dense_model_name", "=", "args", ".", "dense_model_name", "\n", "quantizer_name", "=", "\"kmeans\"", "\n", "\n", "# We can build a speech encoder module using names of pre-trained dense and quantizer models.", "\n", "# The call below will download appropriate checkpoints as needed behind the scenes", "\n", "encoder", "=", "SpeechEncoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "dense_model_name", ",", "\n", "quantizer_model_name", "=", "quantizer_name", ",", "\n", "vocab_size", "=", "args", ".", "vocab_size", ",", "\n", "need_f0", "=", "False", ",", "\n", "deduplicate", "=", "True", ",", "\n", "f0_normalizer", "=", "None", ",", "\n", "f0_quantizer", "=", "None", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "# Alternatively, we can pass dense/quantizer models directly.", "\n", "# Here, we'll look up the same models as above, but generally those", "\n", "# could be any other models.", "\n", "dense_model", "=", "dispatch_dense_model", "(", "dense_model_name", ")", "\n", "quantizer_model", "=", "dispatch_quantizer", "(", "\n", "dense_model_name", ",", "quantizer_name", ",", "args", ".", "vocab_size", "\n", ")", "\n", "\n", "# .. and use them when initializing the encoder. Same constructor can be used to when we want", "\n", "# to use models other than pre-defined.", "\n", "encoder", "=", "SpeechEncoder", "(", "\n", "dense_model", "=", "dense_model", ",", "\n", "quantizer_model", "=", "quantizer_model", ",", "\n", "need_f0", "=", "False", ",", "\n", "deduplicate", "=", "True", ",", "\n", "f0_normalizer", "=", "None", ",", "\n", "f0_quantizer", "=", "None", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "# now let's load an audio example", "\n", "waveform", ",", "input_sample_rate", "=", "torchaudio", ".", "load", "(", "args", ".", "input", ")", "\n", "if", "waveform", ".", "ndim", "==", "2", ":", "\n", "        ", "waveform", "=", "waveform", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "", "waveform", "=", "encoder", ".", "maybe_resample", "(", "waveform", ",", "input_sample_rate", ")", "\n", "\n", "# now and convert it in a stream of deduplicated units (as in GSLM)", "\n", "encoded", "=", "encoder", "(", "waveform", ".", "cuda", "(", ")", ")", "\n", "# encoded is a dict with keys ('dense', 'units', 'durations'). It can also contain 'f0' if SpeechEncoder", "\n", "# was initialized with need_f0=True flag.", "\n", "units", "=", "encoded", "[", "\n", "\"units\"", "\n", "]", "# tensor([71, 12, 57, 12, 57, 12, 57, 12, ...], device='cuda:0', dtype=torch.int32)", "\n", "\n", "# as with encoder, we can setup vocoder by specifying names of pretrained models", "\n", "# or by passing checkpoint paths directly. The dense/quantizer models are not invokes,", "\n", "# we just use their names as an index.", "\n", "vocoder", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", ",", "\n", "quantizer_name", ",", "\n", "args", ".", "vocab_size", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "# now we turn those units back into the audio.", "\n", "audio", "=", "vocoder", "(", "units", ")", "\n", "\n", "# save the audio", "\n", "torchaudio", ".", "save", "(", "\n", "args", ".", "output", ",", "audio", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "0", ")", ",", "vocoder", ".", "output_sample_rate", "\n", ")", "\n", "\n", "uniform_bps", ",", "learned_bps", "=", "get_compression_rate", "(", "\n", "dense_model_name", ",", "units", ",", "waveform", ",", "args", ".", "vocab_size", ",", "encoder", ".", "expected_sample_rate", "\n", ")", "\n", "\n", "print", "(", "\n", "f\"Audio of length {round(waveform.size(0) / 16_000, 1)} seconds represented as {units.numel()} tokens\"", "\n", ")", "\n", "print", "(", "\n", "f\"\\tAssuming uniform token distribution: {round(uniform_bps, 1)} bits per second\"", "\n", ")", "\n", "print", "(", "\n", "f\"\\tAssuming unigram token distribution estimated on LL-6K train: {round(learned_bps, 1)} bits per second\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__init__": [[115, 125], ["train.SpeakerDatasetWrapper.get_speaker_ids"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.get_speaker_ids"], ["    ", "def", "__init__", "(", "self", ",", "quantized_data", ",", "speaker_mapping", "=", "None", ")", ":", "\n", "        ", "self", ".", "quantized_data", "=", "quantized_data", "\n", "self", ".", "speaker_mapping", "=", "(", "\n", "speaker_mapping", "\n", "if", "speaker_mapping", "is", "not", "None", "\n", "else", "self", ".", "get_speaker_ids", "(", "quantized_data", ".", "dataset", ".", "_walker", ")", "\n", ")", "\n", "self", ".", "collater", "=", "self", ".", "quantized_data", ".", "collater", "\n", "self", ".", "max_length", "=", "(", "\n", "10", "*", "16_000", "//", "self", ".", "quantized_data", ".", "speech_encoder", ".", "code_hop_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.get_speaker_ids": [[127, 136], ["fileid.split", "int", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_speaker_ids", "(", "walker", ")", ":", "\n", "        ", "speaker_mapping", "=", "{", "}", "\n", "for", "fileid", "in", "walker", ":", "\n", "            ", "speaker_id", ",", "*", "_", "=", "fileid", ".", "split", "(", "\"-\"", ")", "\n", "speaker_id", "=", "int", "(", "speaker_id", ")", "\n", "if", "speaker_id", "not", "in", "speaker_mapping", ":", "\n", "                ", "speaker_mapping", "[", "speaker_id", "]", "=", "len", "(", "speaker_mapping", ")", "\n", "", "", "return", "speaker_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__getitem__": [[137, 148], ["item[].size"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "k", ")", ":", "\n", "        ", "item", "=", "self", ".", "quantized_data", "[", "k", "]", "\n", "speaker", "=", "item", "[", "\"rest\"", "]", "[", "2", "]", "\n", "item", "[", "\"rest\"", "]", "[", "2", "]", "=", "self", ".", "speaker_mapping", "[", "speaker", "]", "\n", "\n", "if", "self", ".", "max_length", "<", "item", "[", "\"dense\"", "]", ".", "size", "(", "0", ")", ":", "\n", "            ", "item", "[", "\"dense\"", "]", "=", "item", "[", "\"dense\"", "]", "[", ":", "self", ".", "max_length", ",", ":", "]", "\n", "item", "[", "\"units\"", "]", "=", "item", "[", "\"units\"", "]", "[", ":", "self", ".", "max_length", "]", "\n", "item", "[", "\"durations\"", "]", "=", "item", "[", "\"durations\"", "]", "[", ":", "self", ".", "max_length", "]", "\n", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.__len__": [[149, 151], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "quantized_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.set_seed_": [[17, 20], ["torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["def", "set_seed_", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.move_to": [[22, 30], ["hasattr", "isinstance", "x.to", "isinstance", "isinstance", "train.move_to", "train.move_to", "x.items"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.move_to", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.move_to"], ["", "def", "move_to", "(", "x", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "    ", "if", "hasattr", "(", "x", ",", "\"to\"", ")", ":", "\n", "        ", "return", "x", ".", "to", "(", "device", ")", "\n", "", "if", "isinstance", "(", "x", ",", "list", ")", "or", "isinstance", "(", "x", ",", "tuple", ")", ":", "\n", "        ", "return", "[", "move_to", "(", "i", ",", "device", ")", "for", "i", "in", "x", "]", "\n", "", "if", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "        ", "return", "{", "k", ":", "move_to", "(", "v", ",", "device", ")", "for", "k", ",", "v", "in", "x", ".", "items", "(", ")", "}", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.get_args": [[32, 56], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dense_model_name\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Dense model to be used\"", ",", "\n", "default", "=", "\"hubert-base-ls960\"", ",", "\n", "choices", "=", "[", "\"hubert-base-ls960\"", ",", "\"cpc-big-ll6k\"", "]", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab_size\"", ",", "type", "=", "int", ",", "help", "=", "\"Unit vocab size\"", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "150", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch_size\"", ",", "type", "=", "int", ",", "help", "=", "\"Batch size for K-means training\"", ",", "default", "=", "32", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "13", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "choices", "=", "[", "\"baseline\"", ",", "\"discrete\"", ",", "\"continuous\"", "]", ",", "\n", "default", "=", "\"baseline\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train": [[58, 65], ["model.train", "torch.optim.Adam", "torch.optim.Adam", "range", "model.parameters", "train.train_epoch", "train.evaluate_model"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train_epoch", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.evaluate_model"], ["", "def", "train", "(", "model", ",", "train_dataloader", ",", "valid_dataloader", ",", "args", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "train_epoch", "(", "model", ",", "train_dataloader", ",", "optimizer", ",", "epoch", ")", "\n", "evaluate_model", "(", "model", ",", "valid_dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train_epoch": [[67, 88], ["model.train", "torch.zeros().cuda", "torch.zeros().cuda", "print", "train.move_to", "torch.tensor().cuda", "torch.tensor().cuda", "model", "torch.nll_loss", "optimizer.zero_grad", "F.nll_loss.backward", "optimizer.step", "F.nll_loss.detach().sum", "torch.tensor().cuda.size", "torch.zeros", "torch.zeros", "torch.cuda.current_device", "torch.cuda.current_device", "torch.tensor", "torch.tensor", "F.nll_loss.detach"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.move_to"], ["", "", "def", "train_epoch", "(", "model", ",", "dataloader", ",", "optimizer", ",", "e", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "n_examples", "=", "0.0", "\n", "accumulated", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "move_to", "(", "batch", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "speakers", "=", "torch", ".", "tensor", "(", "batch", "[", "\"rest\"", "]", "[", "2", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "speaker_logprobs", "=", "model", "(", "batch", ")", "\n", "loss", "=", "F", ".", "nll_loss", "(", "speaker_logprobs", ",", "speakers", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "accumulated", "+=", "loss", ".", "detach", "(", ")", ".", "sum", "(", ")", "\n", "n_examples", "+=", "speakers", ".", "size", "(", "0", ")", "\n", "\n", "", "train_loss", "=", "(", "accumulated", "/", "n_examples", ")", ".", "item", "(", ")", "\n", "print", "(", "f\"Epoch {e} | sliding mean train loss {train_loss}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.evaluate_model": [[90, 112], ["torch.no_grad", "torch.no_grad", "model.eval", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "print", "train.move_to", "torch.tensor().cuda", "torch.tensor().cuda", "model", "torch.nll_loss", "torch.tensor().cuda.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cuda.current_device", "torch.cuda.current_device", "torch.tensor", "torch.tensor", "torch.zeros().cuda.item", "torch.zeros().cuda.item", "model.argmax"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.move_to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate_model", "(", "model", ",", "dataloader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "n_examples", "=", "0", "\n", "accumulated_loss", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "cuda", "(", ")", "\n", "accuracy", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float64", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "batch", "=", "move_to", "(", "batch", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "speakers", "=", "torch", ".", "tensor", "(", "batch", "[", "\"rest\"", "]", "[", "2", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "speaker_logprobs", "=", "model", "(", "batch", ")", "\n", "loss", "=", "F", ".", "nll_loss", "(", "speaker_logprobs", ",", "speakers", ")", "\n", "accumulated_loss", "+=", "loss", "\n", "\n", "accuracy", "+=", "(", "speaker_logprobs", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "speakers", ")", ".", "sum", "(", ")", "\n", "n_examples", "+=", "speakers", ".", "size", "(", "0", ")", "\n", "\n", "", "accumulated_loss", "/=", "n_examples", "\n", "accuracy", "/=", "n_examples", "\n", "\n", "print", "(", "f\"Valid loss: {accumulated_loss.item()}, accuracy: {accuracy.item()}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.main": [[153, 250], ["train.get_args", "train.set_seed_", "textless.dispatch_dense_model", "textless.dispatch_quantizer", "textless.data.speech_encoder.SpeechEncoder", "textless.data.quantized_datasets.QuantizedLibriSpeech", "train.SpeakerDatasetWrapper.get_speaker_ids", "max", "train.SpeakerDatasetWrapper", "int", "torch.utils.data.random_split", "torch.utils.data.random_split", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "probes.ContinuousClassifier.cuda", "train.train", "SpeakerDatasetWrapper.get_speaker_ids.values", "len", "probes.ConstantBaseline", "len", "torch.Generator().manual_seed", "torch.Generator().manual_seed", "probes.DiscreteClassifier", "probes.ContinuousClassifier", "torch.Generator", "torch.Generator"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.get_args", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.set_seed_", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_dense_model", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedLibriSpeech", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.SpeakerDatasetWrapper.get_speaker_ids", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.speaker_probing.train.train"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "set_seed_", "(", "args", ".", "seed", ")", "\n", "\n", "dense_model_name", "=", "args", ".", "dense_model_name", "\n", "quantizer_model_name", "=", "\"kmeans\"", "\n", "vocab_size", "=", "args", ".", "vocab_size", "\n", "\n", "# NB: Hubert is not serializable as-is, so to have a multi-worker dataloader", "\n", "# we have a worker-around: load the actual checkpoint on the first call - which", "\n", "# will happen in a worker process already. This behavior is enabled with", "\n", "# the `lazy_load` flag.", "\n", "dense_model", "=", "dispatch_dense_model", "(", "dense_model_name", ",", "lazy_load", "=", "True", ")", "\n", "quantizer_model", "=", "dispatch_quantizer", "(", "\n", "dense_model_name", ",", "quantizer_model_name", ",", "vocab_size", "\n", ")", "\n", "\n", "speech_encoder", "=", "SpeechEncoder", "(", "\n", "dense_model", ",", "\n", "quantizer_model", ",", "\n", "deduplicate", "=", "False", ",", "\n", "need_f0", "=", "False", ",", "\n", "add_bos_eos", "=", "True", ",", "\n", ")", "\n", "\n", "dataset", "=", "QuantizedLibriSpeech", "(", "\n", "speech_encoder", ",", "\n", "root", "=", "\"datasets\"", ",", "\n", "url", "=", "\"dev-clean\"", ",", "\n", "download", "=", "True", ",", "\n", "device", "=", "\"auto\"", "\n", "# when we set `device` to auto, the dataset instance will check if it is", "\n", "# running within a worker process of a dataloader. If it is the case,", "\n", "# it will move SpeechEncoder to one of the available GPUs, depending on the", "\n", "# worker id. This way we can pack quite a few (GPU-hungry) Hubert instances running across", "\n", "# all GPUs in parallel, within the same standard DataLoader.", "\n", ")", "\n", "\n", "speaker_mapping", "=", "SpeakerDatasetWrapper", ".", "get_speaker_ids", "(", "dataset", ".", "dataset", ".", "_walker", ")", "\n", "max_speaker_id", "=", "max", "(", "speaker_mapping", ".", "values", "(", ")", ")", "\n", "dataset", "=", "SpeakerDatasetWrapper", "(", "dataset", ",", "speaker_mapping", ")", "\n", "\n", "valid_size", "=", "int", "(", "0.1", "*", "len", "(", "dataset", ")", ")", "\n", "train_size", "=", "len", "(", "dataset", ")", "-", "valid_size", "\n", "train_data", ",", "valid_data", "=", "torch", ".", "utils", ".", "data", ".", "random_split", "(", "\n", "dataset", ",", "[", "train_size", ",", "valid_size", "]", ",", "generator", "=", "torch", ".", "Generator", "(", ")", ".", "manual_seed", "(", "42", ")", "\n", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "num_workers", "=", "4", ",", "\n", ")", "\n", "valid_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "dataset", ".", "collater", ",", "\n", "num_workers", "=", "4", ",", "\n", ")", "\n", "\n", "if", "args", ".", "model_type", "==", "\"baseline\"", ":", "\n", "        ", "model", "=", "ConstantBaseline", "(", "total_speakers", "=", "max_speaker_id", "+", "1", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"discrete\"", ":", "\n", "        ", "model", "=", "DiscreteClassifier", "(", "\n", "vocab_size", "=", "args", ".", "vocab_size", "+", "3", ",", "# accounting for bos, pad, eos", "\n", "embedding_size", "=", "32", ",", "\n", "n_heads", "=", "4", ",", "\n", "hidden_size", "=", "128", ",", "\n", "n_layers", "=", "2", ",", "\n", "dropout", "=", "0.1", ",", "\n", "pad_value", "=", "dataset", ".", "quantized_data", ".", "unit_pad", ",", "\n", "total_speakers", "=", "max_speaker_id", "+", "1", ",", "\n", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"continuous\"", ":", "\n", "        ", "input_size", "=", "{", "\n", "\"hubert-base-ls960\"", ":", "768", ",", "\n", "\"cpc-big-ll6k\"", ":", "512", ",", "\n", "}", "[", "dense_model_name", "]", "\n", "\n", "model", "=", "ContinuousClassifier", "(", "\n", "embedding_size", "=", "32", ",", "\n", "input_size", "=", "input_size", ",", "\n", "n_heads", "=", "4", ",", "\n", "hidden_size", "=", "128", ",", "\n", "n_layers", "=", "2", ",", "\n", "dropout", "=", "0.1", ",", "\n", "pad_value", "=", "dataset", ".", "quantized_data", ".", "unit_pad", ",", "\n", "total_speakers", "=", "max_speaker_id", "+", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "\"unknown model type\"", "\n", "\n", "", "model", ".", "cuda", "(", ")", "\n", "train", "(", "model", ",", "train_loader", ",", "valid_loader", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_checkpoint_manager.test_checkpoint_manager": [[12, 20], ["textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "pathlib.Path().exists", "pytest.raises", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["def", "test_checkpoint_manager", "(", ")", ":", "\n", "    ", "codes", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "\n", "\"hubert-base-ls960-kmeans-50-tacotron-codes\"", ",", "download_if_needed", "=", "True", "\n", ")", "\n", "assert", "pathlib", ".", "Path", "(", "codes", ")", ".", "exists", "(", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "        ", "codes", "=", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "\"123\"", ",", "download_if_needed", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_checkpoint_manager.test_changing_root": [[22, 32], ["tempfile.TemporaryDirectory", "textless.checkpoint_manager.CHECKPOINT_MANAGER.set_root", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "pytest.raises", "textless.checkpoint_manager.CHECKPOINT_MANAGER.get_by_name", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.set_root", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.checkpoint_manager.manager.CheckpointManager.get_by_name"], ["", "", "def", "test_changing_root", "(", ")", ":", "\n", "    ", "name", "=", "\"hubert-base-ls960-kmeans-50-tacotron-codes\"", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "        ", "CHECKPOINT_MANAGER", ".", "set_root", "(", "tmpdir", ")", "\n", "with", "pytest", ".", "raises", "(", "FileNotFoundError", ")", ":", "\n", "            ", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "name", ",", "download_if_needed", "=", "False", ")", "\n", "\n", "", "CHECKPOINT_MANAGER", ".", "get_by_name", "(", "name", ",", "download_if_needed", "=", "True", ")", "\n", "assert", "(", "pathlib", ".", "Path", "(", "tmpdir", ")", "/", "CHECKPOINT_MANAGER", ".", "storage", "[", "name", "]", ".", "fname", ")", ".", "exists", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_model_handling.test_model_dispatch": [[15, 41], ["textless.dispatch_dense_model", "isinstance", "textless.dispatch_quantizer", "pytest.raises", "textless.dispatch_quantizer", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_dense_model", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.textless.__init__.dispatch_quantizer", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["def", "test_model_dispatch", "(", ")", ":", "\n", "    ", "dense_model_name", "=", "\"hubert-base-ls960\"", "\n", "quantizer_name", "=", "\"kmeans\"", "\n", "vocab_size", "=", "100", "\n", "\n", "# getting dense model", "\n", "dense_model", "=", "dispatch_dense_model", "(", "dense_model_name", ")", "\n", "assert", "isinstance", "(", "dense_model", ",", "torch", ".", "nn", ".", "Module", ")", "\n", "\n", "# getting a quantizer for it", "\n", "assert", "(", "\n", "dispatch_quantizer", "(", "dense_model_name", ",", "quantizer_name", ",", "vocab_size", "=", "vocab_size", ")", "\n", "is", "not", "None", "\n", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "KeyError", ")", ":", "\n", "        ", "assert", "dispatch_quantizer", "(", "dense_model_name", ",", "quantizer_name", ",", "vocab_size", "=", "101", ")", "\n", "\n", "# getting a vocoder for it", "\n", "", "assert", "(", "\n", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "dense_model_name", ",", "\n", "quantizer_model_name", "=", "quantizer_name", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", ")", "\n", "is", "not", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_model_handling.test_speech_encoder": [[47, 68], ["pytest.mark.parametrize", "textless.data.speech_encoder.SpeechEncoder.by_name", "torch.zeros", "SpeechEncoder.by_name."], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dense_name,vocab_size\"", ",", "densename_vocabsize", ")", "\n", "def", "test_speech_encoder", "(", "dense_name", ",", "vocab_size", ")", ":", "\n", "    ", "quantizer_name", "=", "\"kmeans\"", "\n", "\n", "encoder", "=", "SpeechEncoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "dense_name", ",", "\n", "quantizer_model_name", "=", "quantizer_name", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "need_f0", "=", "False", ",", "\n", "deduplicate", "=", "True", ",", "\n", "f0_normalizer", "=", "None", ",", "\n", "f0_quantizer", "=", "None", ",", "\n", ")", "\n", "\n", "assert", "encoder", "is", "not", "None", "\n", "\n", "# let's pass 0.5s of silence thru it", "\n", "waveform", "=", "torch", ".", "zeros", "(", "encoder", ".", "expected_sample_rate", "//", "2", ")", "\n", "encoded", "=", "encoder", "(", "waveform", ")", "\n", "\n", "assert", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_model_handling.test_vocoder_lookup": [[70, 80], ["pytest.mark.parametrize", "textless.vocoders.tacotron2.vocoder.TacotronVocoder.by_name"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dense_name,vocab_size\"", ",", "densename_vocabsize", ")", "\n", "def", "test_vocoder_lookup", "(", "dense_name", ",", "vocab_size", ")", ":", "\n", "    ", "quantizer_name", "=", "\"kmeans\"", "\n", "\n", "vocoder", "=", "TacotronVocoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "dense_name", ",", "\n", "quantizer_model_name", "=", "quantizer_name", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", ")", "\n", "assert", "vocoder", "is", "not", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_textlesslib.tests.test_quantized_dataset.test_quantized_librispeech": [[11, 39], ["pathlib.Path().mkdir", "textless.data.speech_encoder.SpeechEncoder.by_name", "textless.data.quantized_datasets.QuantizedLibriSpeech", "item[].size", "item[].size", "item[].size", "item[].sum().item", "item[].size", "pathlib.Path", "item[].sum"], "function", ["home.repos.pwc.inspect_result.facebookresearch_textlesslib.tacotron2.vocoder.TacotronVocoder.by_name", "home.repos.pwc.inspect_result.facebookresearch_textlesslib.data.quantized_datasets.QuantizedLibriSpeech"], ["def", "test_quantized_librispeech", "(", ")", ":", "\n", "    ", "url", "=", "\"dev-clean\"", "\n", "root", "=", "\"./data\"", "\n", "\n", "pathlib", ".", "Path", "(", "root", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "dense_model_name", "=", "\"hubert-base-ls960\"", "\n", "quantizer_name", "=", "\"kmeans\"", "\n", "vocab_size", "=", "100", "\n", "\n", "encoder", "=", "SpeechEncoder", ".", "by_name", "(", "\n", "dense_model_name", "=", "dense_model_name", ",", "\n", "quantizer_model_name", "=", "quantizer_name", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "need_f0", "=", "True", ",", "\n", "deduplicate", "=", "True", ",", "\n", "f0_normalizer", "=", "None", ",", "\n", "f0_quantizer", "=", "None", ",", "\n", ")", "\n", "\n", "quantized_dataset", "=", "QuantizedLibriSpeech", "(", "\n", "root", "=", "root", ",", "speech_encoder", "=", "encoder", ",", "url", "=", "url", ",", "download", "=", "True", "\n", ")", "\n", "item", "=", "quantized_dataset", "[", "0", "]", "\n", "\n", "# checking a few invariants", "\n", "assert", "item", "[", "\"units\"", "]", ".", "size", "(", "0", ")", "==", "item", "[", "\"durations\"", "]", ".", "size", "(", "0", ")", "==", "item", "[", "\"f0\"", "]", ".", "size", "(", "0", ")", "\n", "assert", "item", "[", "\"durations\"", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "item", "[", "\"dense\"", "]", ".", "size", "(", "0", ")", "\n", "", ""]]}