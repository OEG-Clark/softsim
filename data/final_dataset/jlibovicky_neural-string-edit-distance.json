{"home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.__init__": [[13, 34], ["models.EditDistBase.__init__", "torch.tensor", "torch.log", "enumerate", "torch.tensor", "range", "range", "statistical_model.EditDistStatModel._substitute_id"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["def", "__init__", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "start_symbol", "=", "\"<s>\"", ",", "\n", "end_symbol", "=", "\"</s>\"", ",", "pad_symbol", "=", "\"<pad>\"", ",", "\n", "identitiy_initialize", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "src_vocab", ",", "tgt_vocab", ",", "start_symbol", ",", "end_symbol", ",", "pad_symbol", ")", "\n", "\n", "weights", "=", "torch", ".", "tensor", "(", "[", "\n", "1", "/", "self", ".", "n_target_classes", "for", "_", "in", "range", "(", "self", ".", "n_target_classes", ")", "]", ")", "\n", "\n", "if", "identitiy_initialize", ":", "\n", "            ", "idenity_weight", "=", "[", "0.", "for", "_", "in", "range", "(", "self", ".", "n_target_classes", ")", "]", "\n", "id_count", "=", "0", "\n", "for", "idx", ",", "symbol", "in", "enumerate", "(", "self", ".", "src_vocab", ".", "itos", ")", ":", "\n", "                ", "if", "symbol", "in", "self", ".", "tgt_vocab", ".", "stoi", ":", "\n", "                    ", "idenity_weight", "[", "self", ".", "_substitute_id", "(", "\n", "idx", ",", "self", ".", "tgt_vocab", "[", "symbol", "]", ")", "]", "=", "1.", "\n", "id_count", "+=", "1", "\n", "", "", "idenity_weight_tensor", "=", "torch", ".", "tensor", "(", "idenity_weight", ")", "/", "id_count", "\n", "weights", "=", "(", "weights", "+", "idenity_weight_tensor", ")", "/", "2", "\n", "\n", "", "self", ".", "weights", "=", "torch", ".", "log", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel._forward_evaluation": [[36, 60], ["enumerate", "src_sent.size", "tgt_sent.size", "torch.zeros", "enumerate", "statistical_model.EditDistStatModel._deletion_id", "statistical_model.EditDistStatModel._insertion_id", "statistical_model.EditDistStatModel._substitute_id", "torch.logsumexp", "to_sum.append", "to_sum.append", "to_sum.append", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "def", "_forward_evaluation", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "src_len", ",", "tgt_len", "=", "src_sent", ".", "size", "(", "1", ")", ",", "tgt_sent", ".", "size", "(", "1", ")", "\n", "alpha", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "+", "MINF", "\n", "alpha", "[", "0", ",", "0", "]", "=", "0", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", "[", "0", "]", ")", ":", "\n", "            ", "for", "v", ",", "tgt_char", "in", "enumerate", "(", "tgt_sent", "[", "0", "]", ")", ":", "\n", "                ", "if", "t", "==", "0", "and", "v", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "insertion_id", "=", "self", ".", "_insertion_id", "(", "tgt_char", ")", "\n", "subsitute_id", "=", "self", ".", "_substitute_id", "(", "src_char", ",", "tgt_char", ")", "\n", "\n", "to_sum", "=", "[", "alpha", "[", "t", ",", "v", "]", "]", "\n", "if", "v", ">=", "1", ":", "\n", "                    ", "to_sum", ".", "append", "(", "self", ".", "weights", "[", "insertion_id", "]", "+", "alpha", "[", "t", ",", "v", "-", "1", "]", ")", "\n", "", "if", "t", ">=", "1", ":", "\n", "                    ", "to_sum", ".", "append", "(", "self", ".", "weights", "[", "deletion_id", "]", "+", "alpha", "[", "t", "-", "1", ",", "v", "]", ")", "\n", "", "if", "v", ">=", "1", "and", "t", ">=", "1", ":", "\n", "                    ", "to_sum", ".", "append", "(", "\n", "self", ".", "weights", "[", "subsitute_id", "]", "+", "alpha", "[", "t", "-", "1", ",", "v", "-", "1", "]", ")", "\n", "\n", "", "alpha", "[", "t", ",", "v", "]", "=", "torch", ".", "logsumexp", "(", "torch", ".", "tensor", "(", "to_sum", ")", ",", "dim", "=", "0", ")", "\n", "", "", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.forward": [[61, 120], ["statistical_model.EditDistStatModel._forward_evaluation", "reversed", "statistical_model.EditDistStatModel.weights.unsqueeze().unsqueeze", "torch.cat", "torch.cat.logsumexp", "src_sent.size", "tgt_sent.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "reversed", "beta[].unsqueeze", "beta[].unsqueeze", "beta[].unsqueeze", "range", "torch.logsumexp", "statistical_model.EditDistStatModel.weights.unsqueeze", "expected_deletions.reshape", "expected_insertions.reshape", "expected_substitutions.reshape", "statistical_model.EditDistStatModel._insertion_id", "to_sum.append", "statistical_model.EditDistStatModel._deletion_id", "to_sum.append", "statistical_model.EditDistStatModel._substitute_id", "to_sum.append", "torch.tensor", "alpha[].unsqueeze", "alpha[].unsqueeze", "alpha[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "def", "forward", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "src_len", ",", "tgt_len", "=", "src_sent", ".", "size", "(", "1", ")", ",", "tgt_sent", ".", "size", "(", "1", ")", "\n", "table_shape", "=", "(", "(", "src_len", ",", "tgt_len", ",", "self", ".", "n_target_classes", ")", ")", "\n", "\n", "alpha", "=", "self", ".", "_forward_evaluation", "(", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "plausible_deletions", "=", "torch", ".", "zeros", "(", "table_shape", ")", "+", "MINF", "\n", "plausible_insertions", "=", "torch", ".", "zeros", "(", "table_shape", ")", "+", "MINF", "\n", "plausible_substitutions", "=", "torch", ".", "zeros", "(", "table_shape", ")", "+", "MINF", "\n", "\n", "beta", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "+", "MINF", "\n", "beta", "[", "-", "1", ",", "-", "1", "]", "=", "0.0", "\n", "\n", "for", "t", "in", "reversed", "(", "range", "(", "src_len", ")", ")", ":", "\n", "            ", "for", "v", "in", "reversed", "(", "range", "(", "tgt_len", ")", ")", ":", "\n", "                ", "to_sum", "=", "[", "beta", "[", "t", ",", "v", "]", "]", "\n", "if", "v", "<", "tgt_len", "-", "1", ":", "\n", "                    ", "insertion_id", "=", "self", ".", "_insertion_id", "(", "tgt_sent", "[", "0", ",", "v", "+", "1", "]", ")", "\n", "plausible_insertions", "[", "t", ",", "v", ",", "insertion_id", "]", "=", "0", "\n", "to_sum", ".", "append", "(", "\n", "self", ".", "weights", "[", "insertion_id", "]", "+", "beta", "[", "t", ",", "v", "+", "1", "]", ")", "\n", "", "if", "t", "<", "src_len", "-", "1", ":", "\n", "                    ", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_sent", "[", "0", ",", "t", "+", "1", "]", ")", "\n", "plausible_deletions", "[", "t", ",", "v", ",", "deletion_id", "]", "=", "0", "\n", "to_sum", ".", "append", "(", "\n", "self", ".", "weights", "[", "deletion_id", "]", "+", "beta", "[", "t", "+", "1", ",", "v", "]", ")", "\n", "", "if", "v", "<", "tgt_len", "-", "1", "and", "t", "<", "src_len", "-", "1", ":", "\n", "                    ", "subsitute_id", "=", "self", ".", "_substitute_id", "(", "\n", "src_sent", "[", "0", ",", "t", "+", "1", "]", ",", "tgt_sent", "[", "0", ",", "v", "+", "1", "]", ")", "\n", "plausible_substitutions", "[", "t", ",", "v", ",", "subsitute_id", "]", "=", "0", "\n", "to_sum", ".", "append", "(", "\n", "self", ".", "weights", "[", "subsitute_id", "]", "+", "beta", "[", "t", "+", "1", ",", "v", "+", "1", "]", ")", "\n", "", "beta", "[", "t", ",", "v", "]", "=", "torch", ".", "logsumexp", "(", "torch", ".", "tensor", "(", "to_sum", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "expand_weights", "=", "self", ".", "weights", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# deletion expectation", "\n", "expected_deletions", "=", "(", "\n", "alpha", "[", ":", "-", "1", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", "+", "\n", "expand_weights", "+", "plausible_deletions", "[", "1", ":", ",", ":", "]", "+", "\n", "beta", "[", "1", ":", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", ")", "\n", "# insertoin expectation", "\n", "expected_insertions", "=", "(", "\n", "alpha", "[", ":", ",", ":", "-", "1", "]", ".", "unsqueeze", "(", "2", ")", "+", "\n", "expand_weights", "+", "plausible_insertions", "[", ":", ",", "1", ":", "]", "+", "\n", "beta", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "2", ")", ")", "\n", "# substitution expectation", "\n", "expected_substitutions", "=", "(", "\n", "alpha", "[", ":", "-", "1", ",", ":", "-", "1", "]", ".", "unsqueeze", "(", "2", ")", "+", "\n", "expand_weights", "+", "plausible_substitutions", "[", "1", ":", ",", "1", ":", "]", "+", "\n", "beta", "[", "1", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "2", ")", ")", "\n", "\n", "all_counts", "=", "torch", ".", "cat", "(", "[", "\n", "expected_deletions", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "n_target_classes", ")", ")", ",", "\n", "expected_insertions", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "n_target_classes", ")", ")", ",", "\n", "expected_substitutions", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "n_target_classes", ")", ")", "]", ",", "\n", "dim", "=", "0", ")", "\n", "\n", "expected_counts", "=", "all_counts", ".", "logsumexp", "(", "0", ")", "\n", "return", "expected_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.viterbi": [[121, 158], ["torch.zeros", "enumerate", "torch.exp", "src_sent.size", "tgt_sent.size", "torch.zeros", "enumerate", "statistical_model.EditDistStatModel._deletion_id", "statistical_model.EditDistStatModel._insertion_id", "statistical_model.EditDistStatModel._substitute_id", "max", "possible_actions.append", "possible_actions.append", "possible_actions.append"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "def", "viterbi", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "src_len", ",", "tgt_len", "=", "src_sent", ".", "size", "(", "1", ")", ",", "tgt_sent", ".", "size", "(", "1", ")", "\n", "\n", "action_count", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "\n", "alpha", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "-", "MINF", "\n", "alpha", "[", "0", ",", "0", "]", "=", "0", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", "[", "0", "]", ")", ":", "\n", "            ", "for", "v", ",", "tgt_char", "in", "enumerate", "(", "tgt_sent", "[", "0", "]", ")", ":", "\n", "                ", "if", "t", "==", "0", "and", "v", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "insertion_id", "=", "self", ".", "_insertion_id", "(", "tgt_char", ")", "\n", "subsitute_id", "=", "self", ".", "_substitute_id", "(", "src_char", ",", "tgt_char", ")", "\n", "\n", "possible_actions", "=", "[", "]", "\n", "\n", "if", "v", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "self", ".", "weights", "[", "insertion_id", "]", "+", "alpha", "[", "t", ",", "v", "-", "1", "]", ",", "\n", "action_count", "[", "t", ",", "v", "-", "1", "]", "+", "1", ")", ")", "\n", "", "if", "t", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "self", ".", "weights", "[", "deletion_id", "]", "+", "alpha", "[", "t", "-", "1", ",", "v", "]", ",", "\n", "action_count", "[", "t", "-", "1", ",", "v", "]", "+", "1", ")", ")", "\n", "", "if", "v", ">=", "1", "and", "t", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "self", ".", "weights", "[", "subsitute_id", "]", "+", "alpha", "[", "t", "-", "1", ",", "v", "-", "1", "]", ",", "\n", "action_count", "[", "t", "-", "1", ",", "v", "-", "1", "]", "+", "1", ")", ")", "\n", "\n", "", "best_action_cost", ",", "best_action_count", "=", "max", "(", "\n", "possible_actions", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", "/", "x", "[", "1", "]", ")", "\n", "\n", "alpha", "[", "t", ",", "v", "]", "=", "best_action_cost", "\n", "action_count", "[", "t", ",", "v", "]", "=", "best_action_count", "\n", "\n", "", "", "return", "torch", ".", "exp", "(", "alpha", "[", "-", "1", ",", "-", "1", "]", "/", "action_count", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.maximize_expectation": [[159, 170], ["torch.stack().logsumexp", "torch.stack().logsumexp", "torch.log", "torch.zeros_like", "torch.stack().logsumexp.logsumexp", "torch.tensor", "torch.stack", "torch.stack", "torch.log", "torch.log", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "maximize_expectation", "(", "self", ",", "expectations", ",", "learning_rate", "=", "0.1", ")", ":", "\n", "        ", "assert", "0", "<", "learning_rate", "<=", "1.0", "\n", "epsilon", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "1e-16", ")", ")", "+", "torch", ".", "zeros_like", "(", "self", ".", "weights", ")", "\n", "expecation_sum", "=", "torch", ".", "stack", "(", "[", "epsilon", "]", "+", "expectations", ")", ".", "logsumexp", "(", "0", ")", "\n", "distribution", "=", "(", "\n", "expecation_sum", "-", "expecation_sum", ".", "logsumexp", "(", "0", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "self", ".", "weights", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "1", "-", "learning_rate", ")", ")", "+", "self", ".", "weights", ",", "\n", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "learning_rate", ")", ")", "+", "distribution", "]", ")", ".", "logsumexp", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.decode": [[171, 228], ["range", "range", "torch.tensor().exp", "torch.tensor().exp.sum", "tgt_sent.append", "statistical_model.EditDistStatModel._forward_evaluation", "torch.tensor", "src_sent.size", "range", "range", "torch.tensor", "torch.multinomial", "statistical_model.EditDistStatModel._insertion_id", "statistical_model.EditDistStatModel._deletion_id", "statistical_model.EditDistStatModel._substitute_id"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "def", "decode", "(", "self", ",", "src_sent", ",", "max_len", "=", "100", ",", "samples", "=", "10", ")", ":", "\n", "        ", "assert", "samples", ">", "0", ",", "\"With zero samples nothing can be decoded.\"", "\n", "best_tgt_sent", "=", "[", "]", "\n", "best_tgt_sent_score", "=", "MINF", "\n", "\n", "for", "_", "in", "range", "(", "samples", ")", ":", "\n", "            ", "tgt_sent", "=", "[", "]", "\n", "src_pos", "=", "1", "\n", "src_char", "=", "src_sent", "[", "0", ",", "src_pos", "]", "\n", "\n", "op_count", "=", "0", "\n", "for", "_", "in", "range", "(", "max_len", ")", ":", "\n", "                ", "if", "src_pos", "==", "src_sent", ".", "size", "(", "1", ")", "-", "1", ":", "\n", "                    ", "break", "\n", "\n", "", "src_char", "=", "src_sent", "[", "0", ",", "src_pos", "]", "\n", "insert_weights", "=", "[", "\n", "self", ".", "weights", "[", "self", ".", "_insertion_id", "(", "i", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "tgt_symbol_count", ")", "]", "\n", "delete_weight", "=", "[", "self", ".", "weights", "[", "self", ".", "_deletion_id", "(", "src_char", ")", "]", "]", "\n", "substitute_weight", "=", "[", "\n", "self", ".", "weights", "[", "self", ".", "_substitute_id", "(", "src_char", ",", "i", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "tgt_symbol_count", ")", "]", "\n", "\n", "distr", "=", "torch", ".", "tensor", "(", "insert_weights", "+", "substitute_weight", "+", "delete_weight", ")", ".", "exp", "(", ")", "\n", "distr", "/=", "distr", ".", "sum", "(", ")", "\n", "\n", "next_symb", "=", "self", ".", "tgt_pad", "\n", "while", "next_symb", "in", "[", "self", ".", "tgt_pad", ",", "self", ".", "tgt_bos", ",", "self", ".", "tgt_vocab", "[", "\"<unk>\"", "]", "]", ":", "\n", "                    ", "next_op", "=", "torch", ".", "multinomial", "(", "distr", ",", "1", ")", "[", "0", "]", "\n", "# If it is delete, we are done", "\n", "if", "next_op", "==", "2", "*", "self", ".", "tgt_symbol_count", ":", "\n", "                        ", "break", "\n", "# Tgt symbol candidate", "\n", "", "next_symb", "=", "next_op", "%", "self", ".", "tgt_symbol_count", "\n", "", "op_count", "+=", "1", "\n", "\n", "if", "next_op", "==", "2", "*", "self", ".", "tgt_symbol_count", ":", "\n", "                    ", "src_pos", "+=", "1", "# DELETE OP", "\n", "continue", "\n", "\n", "", "if", "next_symb", "==", "self", ".", "tgt_eos", ":", "\n", "                    ", "break", "\n", "", "tgt_sent", ".", "append", "(", "next_op", "%", "self", ".", "tgt_symbol_count", ")", "\n", "if", "next_op", ">", "self", ".", "tgt_symbol_count", ":", "\n", "                    ", "src_pos", "+=", "1", "# IT WAS A SUBSTITUTION", "\n", "\n", "", "", "if", "not", "tgt_sent", ":", "\n", "                ", "continue", "\n", "\n", "", "score", "=", "self", ".", "_forward_evaluation", "(", "\n", "src_sent", ",", "torch", ".", "tensor", "(", "[", "tgt_sent", "]", ")", ")", "[", "-", "1", ",", "-", "1", "]", "# / op_count", "\n", "if", "score", ">", "best_tgt_sent_score", ":", "\n", "                ", "best_tgt_sent_score", "=", "score", "\n", "best_tgt_sent", "=", "tgt_sent", "\n", "\n", "", "", "return", "tgt_sent", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_cmudict.main": [[18, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "transliteration_utils.load_vocab", "transliteration_utils.load_vocab", "logging.info", "logging.info", "parser.parse_args.test_set.close", "logging.info", "enumerate", "logging.info", "logging.info", "print", "print", "line.strip().split", "test_data.items", "torch.tensor().cuda", "transliteration_utils.decode_ids", "min", "cers.append", "sum", "len", "sum", "len", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "test_data[].append", "torch.load.decode", "transliteration_utils.char_error_rate", "logging.info", "line.strip", "list", "torch.tensor", "torch.load.beam_search", "len", "float", "torch.load.operation_decoding", "len", "torch.load.operation_beam_search", "ValueError"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.decode", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_decoding", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_beam_search"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"test_set\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoding\"", ",", "default", "=", "\"beam_search\"", ",", "\n", "choices", "=", "[", "\"greedy\"", ",", "\"beam_search\"", ",", "\"operations\"", ",", "\"operations_beam\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam-size\"", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "\"--len-norm\"", ",", "type", "=", "float", ",", "default", "=", "1.6", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "src_vocab", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "logging", ".", "info", "(", "\"Collecting test data.\"", ")", "\n", "test_data", "=", "{", "}", "\n", "for", "line", "in", "args", ".", "test_set", ":", "\n", "        ", "src", ",", "tgt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "src", "not", "in", "test_data", ":", "\n", "            ", "test_data", "[", "src", "]", "=", "[", "tgt", "]", "\n", "", "else", ":", "\n", "            ", "test_data", "[", "src", "]", ".", "append", "(", "tgt", ")", "\n", "", "", "args", ".", "test_set", ".", "close", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Generate transcriptions.\"", ")", "\n", "cers", "=", "[", "]", "\n", "for", "i", ",", "(", "src", ",", "tgts", ")", "in", "enumerate", "(", "test_data", ".", "items", "(", ")", ")", ":", "\n", "        ", "src_tok", "=", "[", "\"<s>\"", "]", "+", "list", "(", "src", ")", "+", "[", "\"</s>\"", "]", "\n", "\n", "src_idx", "=", "torch", ".", "tensor", "(", "\n", "[", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "src_tok", "]", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "args", ".", "decoding", "==", "\"greedy\"", ":", "\n", "            ", "output", "=", "model", ".", "decode", "(", "src_idx", ")", "\n", "", "elif", "args", ".", "decoding", "==", "\"beam_search\"", ":", "\n", "            ", "output", "=", "model", ".", "beam_search", "(", "src_idx", ",", "args", ".", "beam_size", ",", "len_norm", "=", "args", ".", "len_norm", ")", "\n", "", "elif", "args", ".", "decoding", "==", "\"operations\"", ":", "\n", "            ", "output", "=", "model", ".", "operation_decoding", "(", "src_idx", ")", "#, args.beam_size)", "\n", "", "elif", "args", ".", "decoding", "==", "\"operations_beam\"", ":", "\n", "            ", "output", "=", "model", ".", "operation_beam_search", "(", "src_idx", ",", "args", ".", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unknown type of decoding: {args.decoding}\"", ")", "\n", "\n", "", "output_str", "=", "decode_ids", "(", "output", "[", "0", "]", ",", "tgt_vocab", ",", "tokenized", "=", "True", ")", "\n", "\n", "cer", "=", "min", "(", "char_error_rate", "(", "\n", "[", "output_str", "]", "*", "len", "(", "tgts", ")", ",", "tgts", ",", "tokenized", "=", "True", ",", "average", "=", "False", ")", ")", "\n", "cers", ".", "append", "(", "cer", ")", "\n", "\n", "if", "i", "%", "100", "==", "99", ":", "\n", "            ", "logging", ".", "info", "(", "\"Processed %d / %d strings.\"", ",", "i", "+", "1", ",", "len", "(", "test_data", ")", ")", "\n", "\n", "", "", "final_acc", "=", "sum", "(", "float", "(", "cer", "==", "0", ")", "for", "cer", "in", "cers", ")", "/", "len", "(", "cers", ")", "\n", "final_cer", "=", "sum", "(", "cers", ")", "/", "len", "(", "cers", ")", "\n", "logging", ".", "info", "(", "\"WER: %.3g\"", ",", "1", "-", "final_acc", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3g\"", ",", "final_cer", ")", "\n", "print", "(", "1", "-", "final_acc", ")", "\n", "print", "(", "final_cer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.RNNEncoder.__init__": [[19, 42], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Embedding", "torch.nn.ModuleList", "torch.nn.GRU", "torch.nn.ModuleList", "len", "torch.nn.LayerNorm", "torch.nn.GRU", "range", "range"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "hidden_size", ",", "embedding_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic network params", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embedding_size", "=", "embedding_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "vocab", ")", ",", "embedding_size", ")", "\n", "\n", "self", ".", "norms", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "LayerNorm", "(", "hidden_size", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "self", ".", "first_gru", "=", "nn", ".", "GRU", "(", "embedding_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "\n", "self", ".", "other_grus", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "GRU", "(", "hidden_size", ",", "hidden_size", ",", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "num_layers", "-", "1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.RNNEncoder.forward": [[43, 72], ["attention_mask.sum", "rnn.RNNEncoder.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "rnn.RNNEncoder.first_gru", "torch.nn.utils.rnn.pad_packed_sequence", "zip", "rnn.RNNEncoder.embeddings", "attention_mask.sum.cpu", "rnn.RNNEncoder.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "gru", "torch.nn.utils.rnn.pad_packed_sequence", "norm", "attention_mask.sum.cpu", "rnn.RNNEncoder.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_sequence", ",", "attention_mask", ")", ":", "\n", "        ", "input_lengths", "=", "attention_mask", ".", "sum", "(", "1", ")", "\n", "\n", "word_embeddings", "=", "self", ".", "dropout", "(", "self", ".", "embeddings", "(", "input_sequence", ")", ")", "\n", "packed_embeddings", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "word_embeddings", ",", "input_lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "\n", "# Run the packed embeddings through the GRU, and then unpack the", "\n", "# sequences", "\n", "outputs", ",", "_", "=", "self", ".", "first_gru", "(", "packed_embeddings", ")", "\n", "outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "outputs", ",", "batch_first", "=", "True", ")", "\n", "outputs", "=", "self", ".", "norms", "[", "0", "]", "(", "self", ".", "dropout", "(", "\n", "outputs", "[", ":", ",", ":", ",", ":", "self", ".", "hidden_size", "]", "+", "\n", "outputs", "[", ":", ",", ":", ",", "self", ".", "hidden_size", ":", "]", ")", ")", "\n", "\n", "for", "gru", ",", "norm", "in", "zip", "(", "self", ".", "other_grus", ",", "self", ".", "norms", "[", "1", ":", "]", ")", ":", "\n", "            ", "packed_outputs", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "outputs", ",", "input_lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "next_outputs", ",", "_", "=", "gru", "(", "packed_outputs", ")", "\n", "next_outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "next_outputs", ",", "batch_first", "=", "True", ")", "\n", "next_outputs", "=", "(", "next_outputs", "[", ":", ",", ":", ",", ":", "self", ".", "hidden_size", "]", "+", "\n", "next_outputs", "[", ":", ",", ":", ",", "self", ".", "hidden_size", ":", "]", ")", "\n", "outputs", "=", "norm", "(", "outputs", "+", "self", ".", "dropout", "(", "next_outputs", ")", ")", "\n", "\n", "", "return", "outputs", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.Attention.__init__": [[79, 82], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.Attention.forward": [[83, 92], ["rnn.dot_score", "attn_scores.masked_fill.masked_fill.masked_fill", "torch.functional.F.softmax().unsqueeze", "mask.unsqueeze", "torch.functional.F.softmax", "values.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.dot_score"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "keys", ",", "values", ",", "mask", ")", ":", "\n", "        ", "attn_scores", "=", "dot_score", "(", "hidden", ",", "keys", ")", "\n", "# Apply mask so network does not attend <pad> tokens", "\n", "attn_scores", "=", "attn_scores", ".", "masked_fill", "(", "mask", ".", "unsqueeze", "(", "1", ")", "==", "0", ",", "-", "1e10", ")", "\n", "\n", "attention_weights", "=", "F", ".", "softmax", "(", "attn_scores", ",", "dim", "=", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "\n", "context", "=", "(", "values", ".", "unsqueeze", "(", "1", ")", "*", "attention_weights", ")", ".", "sum", "(", "2", ")", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.RNNDecoder.__init__": [[95, 139], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Embedding", "torch.nn.GRU", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "len", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "range", "torch.nn.ModuleList", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "range", "range", "rnn.Attention", "range", "range", "transformers.modeling_bert.BertSelfAttention", "AttConfig", "range"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "hidden_size", ",", "embedding_size", ",", "\n", "num_layers", "=", "2", ",", "attention_heads", "=", "4", ",", "dropout", "=", "0.0", ",", "\n", "use_attention", "=", "True", ",", "\n", "output_proj", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic network params", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embedding_size", "=", "embedding_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "use_attention", "=", "use_attention", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "vocab", ")", ",", "embedding_size", ")", "\n", "\n", "self", ".", "first_gru", "=", "nn", ".", "GRU", "(", "embedding_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "rnn_norms", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "LayerNorm", "(", "hidden_size", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "self", ".", "ctx_norms", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "LayerNorm", "(", "hidden_size", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "self", ".", "attn", "=", "[", "None", "for", "_", "in", "range", "(", "num_layers", ")", "]", "\n", "if", "use_attention", "and", "attention_heads", "==", "1", ":", "\n", "            ", "self", ".", "attn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "Attention", "(", "hidden_size", ")", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "", "elif", "use_attention", ":", "\n", "            ", "self", ".", "attn", "=", "nn", ".", "ModuleList", "(", "[", "\n", "BertSelfAttention", "(", "AttConfig", "(", "\n", "hidden_size", ",", "attention_heads", ",", "True", ",", "0.1", ")", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "", "self", ".", "other_grus", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "GRU", "(", "hidden_size", ",", "hidden_size", ",", "batch_first", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "num_layers", "-", "1", ")", "]", ")", "\n", "\n", "self", ".", "output_proj", "=", "None", "\n", "if", "output_proj", ":", "\n", "            ", "self", ".", "output_proj", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.RNNDecoder.forward": [[140, 194], ["attention_mask.sum", "rnn.RNNDecoder.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "rnn.RNNDecoder.first_gru", "torch.nn.utils.rnn.pad_packed_sequence", "zip", "rnn.RNNDecoder.embeddings", "attention_mask.sum.cpu", "rnn.RNNDecoder.dropout", "encoder_attention_mask.unsqueeze().unsqueeze", "attentions.append", "torch.nn.utils.rnn.pack_padded_sequence", "gru", "torch.nn.utils.rnn.pad_packed_sequence", "rnn_norm", "rnn.RNNDecoder.output_proj", "attention_mask.sum.cpu", "encoder_attention_mask.unsqueeze().unsqueeze", "att", "ctx_norm", "attentions.append", "encoder_attention_mask.unsqueeze", "len", "rnn.RNNDecoder.dropout", "rnn.RNNDecoder.dropout", "encoder_attention_mask.unsqueeze", "len", "rnn.RNNDecoder.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ")", ":", "\n", "        ", "input_lengths", "=", "attention_mask", ".", "sum", "(", "1", ")", "\n", "\n", "word_embeddings", "=", "self", ".", "dropout", "(", "self", ".", "embeddings", "(", "input_ids", ")", ")", "\n", "packed_embeddings", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "word_embeddings", ",", "input_lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "\n", "# Run the packed embeddings through the GRU, and then unpack", "\n", "# the sequences", "\n", "outputs", ",", "_", "=", "self", ".", "first_gru", "(", "packed_embeddings", ")", "\n", "outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "outputs", ",", "batch_first", "=", "True", ")", "\n", "outputs", "=", "self", ".", "rnn_norms", "[", "0", "]", "(", "self", ".", "dropout", "(", "outputs", ")", ")", "\n", "\n", "attentions", "=", "[", "]", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "unsq_enc_att_mask", "=", "(", "\n", "encoder_attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "att_output", "=", "self", ".", "attn", "[", "0", "]", "(", "\n", "outputs", ",", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "unsq_enc_att_mask", ")", "\n", "context", "=", "att_output", "[", "0", "]", "\n", "att_dist", "=", "att_output", "[", "1", "]", "if", "len", "(", "att_output", ")", ">", "1", "else", "None", "\n", "outputs", "=", "self", ".", "ctx_norms", "[", "0", "]", "(", "outputs", "+", "self", ".", "dropout", "(", "context", ")", ")", "\n", "attentions", ".", "append", "(", "(", "None", ",", "att_dist", ")", ")", "\n", "\n", "", "for", "gru", ",", "att", ",", "rnn_norm", ",", "ctx_norm", "in", "zip", "(", "\n", "self", ".", "other_grus", ",", "self", ".", "attn", "[", "1", ":", "]", ",", "\n", "self", ".", "rnn_norms", "[", "1", ":", "]", ",", "self", ".", "ctx_norms", "[", "1", ":", "]", ")", ":", "\n", "            ", "packed_outputs", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "outputs", ",", "input_lengths", ".", "cpu", "(", ")", ",", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "next_outputs", ",", "_", "=", "gru", "(", "packed_outputs", ")", "\n", "next_outputs", ",", "_", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "\n", "next_outputs", ",", "batch_first", "=", "True", ")", "\n", "outputs", "=", "rnn_norm", "(", "outputs", "+", "self", ".", "dropout", "(", "next_outputs", ")", ")", "\n", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                ", "unsq_enc_att_mask", "=", "(", "\n", "encoder_attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "att_output", "=", "att", "(", "\n", "outputs", ",", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "unsq_enc_att_mask", ")", "\n", "context", "=", "att_output", "[", "0", "]", "\n", "att_dist", "=", "att_output", "[", "1", "]", "if", "len", "(", "att_output", ")", ">", "1", "else", "None", "\n", "outputs", "=", "ctx_norm", "(", "outputs", "+", "self", ".", "dropout", "(", "context", ")", ")", "\n", "attentions", ".", "append", "(", "(", "None", ",", "att_dist", ")", ")", "\n", "\n", "", "", "if", "self", ".", "output_proj", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "self", ".", "output_proj", "(", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "None", ",", "attentions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.rnn.dot_score": [[74, 76], ["hidden_state.unsqueeze", "encoder_states.unsqueeze"], "function", ["None"], ["", "", "def", "dot_score", "(", "hidden_state", ",", "encoder_states", ")", ":", "\n", "    ", "return", "(", "hidden_state", ".", "unsqueeze", "(", "2", ")", "*", "encoder_states", ".", "unsqueeze", "(", "1", ")", ")", ".", "sum", "(", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase.__init__": [[30, 72], ["torch.nn.Module.__init__", "len", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "start_symbol", ",", "\n", "end_symbol", ",", "pad_symbol", ",", "table_type", "=", "\"full\"", ",", "extra_classes", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "src_vocab", "=", "src_vocab", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "\n", "self", ".", "src_bos", "=", "src_vocab", "[", "start_symbol", "]", "\n", "self", ".", "src_eos", "=", "src_vocab", "[", "end_symbol", "]", "\n", "self", ".", "src_pad", "=", "src_vocab", "[", "pad_symbol", "]", "\n", "self", ".", "tgt_bos", "=", "tgt_vocab", "[", "start_symbol", "]", "\n", "self", ".", "tgt_eos", "=", "tgt_vocab", "[", "end_symbol", "]", "\n", "self", ".", "tgt_pad", "=", "tgt_vocab", "[", "pad_symbol", "]", "\n", "\n", "self", ".", "extra_classes", "=", "extra_classes", "\n", "self", ".", "src_symbol_count", "=", "len", "(", "src_vocab", ")", "\n", "self", ".", "tgt_symbol_count", "=", "len", "(", "tgt_vocab", ")", "\n", "\n", "self", ".", "table_type", "=", "table_type", "\n", "\n", "if", "table_type", "==", "\"full\"", ":", "\n", "            ", "self", ".", "deletion_classes", "=", "self", ".", "src_symbol_count", "\n", "self", ".", "insertion_classes", "=", "self", ".", "tgt_symbol_count", "\n", "self", ".", "subs_classes", "=", "self", ".", "src_symbol_count", "*", "self", ".", "tgt_symbol_count", "\n", "self", ".", "n_target_classes", "=", "(", "\n", "self", ".", "extra_classes", "+", "\n", "self", ".", "src_symbol_count", "+", "# delete source", "\n", "self", ".", "tgt_symbol_count", "+", "# insert target", "\n", "self", ".", "src_symbol_count", "*", "self", ".", "tgt_symbol_count", ")", "# substitute", "\n", "", "elif", "table_type", "==", "\"tiny\"", ":", "\n", "            ", "self", ".", "deletion_classes", "=", "1", "\n", "self", ".", "insertion_classes", "=", "1", "\n", "self", ".", "subs_classes", "=", "1", "\n", "self", ".", "n_target_classes", "=", "self", ".", "extra_classes", "+", "3", "\n", "", "elif", "table_type", "==", "\"vocab\"", ":", "\n", "            ", "self", ".", "deletion_classes", "=", "1", "\n", "self", ".", "insertion_classes", "=", "self", ".", "tgt_symbol_count", "\n", "self", ".", "subs_classes", "=", "self", ".", "tgt_symbol_count", "\n", "self", ".", "n_target_classes", "=", "(", "\n", "self", ".", "extra_classes", "+", "1", "+", "2", "*", "self", ".", "tgt_symbol_count", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown table type.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id": [[73, 77], ["torch.zeros_like"], "methods", ["None"], ["", "", "def", "_deletion_id", "(", "self", ",", "src_char", ")", ":", "\n", "        ", "if", "self", ".", "table_type", "==", "\"full\"", ":", "\n", "            ", "return", "src_char", "\n", "", "return", "torch", ".", "zeros_like", "(", "src_char", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id": [[78, 86], ["RuntimeError", "torch.ones_like"], "methods", ["None"], ["", "def", "_insertion_id", "(", "self", ",", "tgt_char", ")", ":", "\n", "        ", "if", "self", ".", "table_type", "==", "\"full\"", ":", "\n", "            ", "return", "self", ".", "src_symbol_count", "+", "tgt_char", "\n", "", "if", "self", ".", "table_type", "==", "\"tiny\"", ":", "\n", "            ", "return", "torch", ".", "ones_like", "(", "tgt_char", ")", "\n", "", "if", "self", ".", "table_type", "==", "\"vocab\"", ":", "\n", "            ", "return", "1", "+", "tgt_char", "\n", "", "raise", "RuntimeError", "(", "\"Unknown table type.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id": [[87, 98], ["RuntimeError", "torch.full_like"], "methods", ["None"], ["", "def", "_substitute_id", "(", "self", ",", "src_char", ",", "tgt_char", ")", ":", "\n", "        ", "if", "self", ".", "table_type", "==", "\"full\"", ":", "\n", "            ", "subs_id", "=", "(", "self", ".", "src_symbol_count", "+", "self", ".", "tgt_symbol_count", "+", "\n", "self", ".", "tgt_symbol_count", "*", "src_char", "+", "tgt_char", ")", "\n", "assert", "subs_id", "<", "self", ".", "n_target_classes", "\n", "return", "subs_id", "\n", "", "if", "self", ".", "table_type", "==", "\"tiny\"", ":", "\n", "            ", "return", "torch", ".", "full_like", "(", "src_char", ",", "2", ")", "\n", "", "if", "self", ".", "table_type", "==", "\"vocab\"", ":", "\n", "            ", "return", "1", "+", "self", ".", "tgt_symbol_count", "+", "tgt_char", "\n", "", "raise", "RuntimeError", "(", "\"Unknown table type.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.__init__": [[124, 184], ["models.EditDistBase.__init__", "models.NeuralEditDistBase._encoder_for_vocab", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "get_distortion_mask().to", "ValueError", "models.NeuralEditDistBase._encoder_for_vocab", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.LayerNorm", "transformers.modeling_bert.BertSelfAttention", "ValueError", "AttConfig", "models.get_distortion_mask"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encoder_for_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encoder_for_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.get_distortion_mask"], ["def", "__init__", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "device", ",", "directed", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", "share_encoders", "=", "False", ",", "\n", "table_type", "=", "\"vocab\"", ",", "extra_classes", "=", "0", ",", "\n", "window", "=", "3", ",", "\n", "hidden_dim", "=", "32", ",", "hidden_layers", "=", "2", ",", "attention_heads", "=", "4", ",", "\n", "model_type", "=", "\"transformer\"", ",", "\n", "start_symbol", "=", "\"<s>\"", ",", "end_symbol", "=", "\"</s>\"", ",", "pad_symbol", "=", "\"<pad>\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "src_vocab", ",", "tgt_vocab", ",", "start_symbol", ",", "end_symbol", ",", "pad_symbol", ",", "\n", "table_type", "=", "table_type", ",", "extra_classes", "=", "extra_classes", ")", "\n", "\n", "if", "directed", "and", "share_encoders", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You cannot share encoder if one of them is decoder.\"", ")", "\n", "", "if", "share_encoders", ":", "\n", "            ", "if", "src_vocab", "!=", "tgt_vocab", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"When sharing encoders, vocabularies must be the same.\"", ")", "\n", "\n", "", "", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "directed", "=", "directed", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "window", "=", "window", "\n", "if", "self", ".", "model_type", "==", "\"bert\"", ":", "\n", "            ", "self", ".", "hidden_dim", "=", "768", "\n", "", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "attention_heads", "=", "attention_heads", "\n", "self", ".", "src_encoder", "=", "self", ".", "_encoder_for_vocab", "(", "src_vocab", ")", "\n", "if", "model_type", "==", "\"bert\"", "or", "share_encoders", ":", "\n", "            ", "self", ".", "tgt_encoder", "=", "self", ".", "src_encoder", "\n", "", "else", ":", "\n", "            ", "self", ".", "tgt_encoder", "=", "self", ".", "_encoder_for_vocab", "(", "\n", "tgt_vocab", ",", "directed", "=", "directed", ")", "\n", "\n", "", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "nn", ".", "LayerNorm", "(", "self", ".", "hidden_dim", ")", ")", "\n", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "proj_source", "=", "4", "*", "self", ".", "hidden_dim", "if", "self", ".", "directed", "else", "self", ".", "hidden_dim", "\n", "\n", "if", "self", ".", "directed", ":", "\n", "            ", "self", ".", "attention", "=", "BertSelfAttention", "(", "AttConfig", "(", "\n", "self", ".", "hidden_dim", ",", "4", ",", "True", ",", "0.1", ")", ")", "\n", "\n", "", "self", ".", "deletion_logit_proj", "=", "nn", ".", "Linear", "(", "\n", "proj_source", ",", "self", ".", "deletion_classes", ")", "\n", "self", ".", "insertion_proj", "=", "nn", ".", "Linear", "(", "\n", "proj_source", ",", "self", ".", "insertion_classes", ")", "\n", "self", ".", "substitution_proj", "=", "nn", ".", "Linear", "(", "\n", "proj_source", ",", "self", ".", "subs_classes", ")", "\n", "self", ".", "extra_proj", "=", "nn", ".", "Linear", "(", "proj_source", ",", "self", ".", "extra_classes", ")", "\n", "\n", "self", ".", "distortion_mask", "=", "get_distortion_mask", "(", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encoder_for_vocab": [[185, 197], ["ValueError", "models.NeuralEditDistBase._transformer_for_vocab", "models.NeuralEditDistBase._rnn_for_vocab", "transformers.BertModel.from_pretrained", "models.NeuralEditDistBase._cnn_for_vocab", "models.NeuralEditDistBase._cnn_for_vocab"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._transformer_for_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._rnn_for_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._cnn_for_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._cnn_for_vocab"], ["", "def", "_encoder_for_vocab", "(", "self", ",", "vocab", ",", "directed", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "model_type", "==", "\"transformer\"", ":", "\n", "            ", "return", "self", ".", "_transformer_for_vocab", "(", "vocab", ",", "directed", ")", "\n", "", "if", "self", ".", "model_type", "==", "\"rnn\"", ":", "\n", "            ", "return", "self", ".", "_rnn_for_vocab", "(", "vocab", ",", "directed", ")", "\n", "", "if", "self", ".", "model_type", "==", "\"bert\"", ":", "\n", "            ", "return", "BertModel", ".", "from_pretrained", "(", "\"bert-base-cased\"", ")", "\n", "", "if", "self", ".", "model_type", "==", "\"embeddings\"", ":", "\n", "            ", "return", "self", ".", "_cnn_for_vocab", "(", "vocab", ",", "directed", ",", "hidden", "=", "False", ")", "\n", "", "if", "self", ".", "model_type", "==", "\"cnn\"", ":", "\n", "            ", "return", "self", ".", "_cnn_for_vocab", "(", "vocab", ",", "directed", ",", "hidden", "=", "True", ")", "\n", "", "raise", "ValueError", "(", "f\"Uknown model type {self.model_type}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._transformer_for_vocab": [[198, 211], ["transformers.BertConfig", "transformers.BertModel", "len"], "methods", ["None"], ["", "def", "_transformer_for_vocab", "(", "self", ",", "vocab", ",", "directed", "=", "False", ")", ":", "\n", "        ", "config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "len", "(", "vocab", ")", ",", "\n", "is_decoder", "=", "directed", ",", "\n", "hidden_size", "=", "self", ".", "hidden_dim", ",", "\n", "num_hidden_layers", "=", "self", ".", "hidden_layers", ",", "\n", "num_attention_heads", "=", "self", ".", "attention_heads", ",", "\n", "intermediate_size", "=", "2", "*", "self", ".", "hidden_dim", ",", "\n", "hidden_act", "=", "'relu'", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ")", "\n", "\n", "return", "BertModel", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._rnn_for_vocab": [[212, 221], ["rnn.RNNDecoder", "rnn.RNNEncoder"], "methods", ["None"], ["", "def", "_rnn_for_vocab", "(", "self", ",", "vocab", ",", "directed", "=", "False", ")", ":", "\n", "        ", "if", "not", "directed", ":", "\n", "            ", "return", "RNNEncoder", "(", "\n", "vocab", ",", "self", ".", "hidden_dim", ",", "\n", "self", ".", "hidden_dim", ",", "self", ".", "hidden_layers", ",", "dropout", "=", "0.1", ")", "\n", "", "return", "RNNDecoder", "(", "\n", "vocab", ",", "self", ".", "hidden_dim", ",", "\n", "self", ".", "hidden_dim", ",", "self", ".", "hidden_layers", ",", "self", ".", "attention_heads", ",", "\n", "output_proj", "=", "False", ",", "dropout", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._cnn_for_vocab": [[222, 237], ["cnn.CNNDecoder", "cnn.CNNEncoder"], "methods", ["None"], ["", "def", "_cnn_for_vocab", "(", "self", ",", "vocab", ",", "directed", "=", "False", ",", "hidden", "=", "True", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "layers", "=", "self", ".", "hidden_layers", "if", "hidden", "else", "0", "\n", "\n", "if", "not", "directed", ":", "\n", "            ", "return", "CNNEncoder", "(", "\n", "vocab", ",", "self", ".", "hidden_dim", ",", "\n", "self", ".", "hidden_dim", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "layers", "=", "layers", ",", "dropout", "=", "dropout", ")", "\n", "", "return", "CNNDecoder", "(", "\n", "vocab", ",", "self", ".", "hidden_dim", ",", "\n", "self", ".", "hidden_dim", ",", "layers", "=", "layers", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "attention_heads", "=", "self", ".", "attention_heads", ",", "\n", "output_proj", "=", "False", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encode_src": [[238, 240], ["models.NeuralEditDistBase.src_encoder"], "methods", ["None"], ["", "def", "_encode_src", "(", "self", ",", "inputs", ",", "mask", ")", ":", "\n", "        ", "return", "self", ".", "src_encoder", "(", "inputs", ",", "attention_mask", "=", "mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encode_tgt": [[241, 249], ["models.NeuralEditDistBase.tgt_encoder", "models.NeuralEditDistBase.tgt_encoder"], "methods", ["None"], ["", "def", "_encode_tgt", "(", "self", ",", "inputs", ",", "mask", ",", "src_vectors", ",", "src_mask", ")", ":", "\n", "        ", "if", "self", ".", "encoder_decoder_attention", ":", "\n", "            ", "return", "self", ".", "tgt_encoder", "(", "\n", "inputs", ",", "attention_mask", "=", "mask", ",", "\n", "encoder_hidden_states", "=", "src_vectors", ",", "\n", "encoder_attention_mask", "=", "src_mask", ")", "[", "0", "]", "\n", "", "return", "self", ".", "tgt_encoder", "(", "\n", "inputs", ",", "attention_mask", "=", "mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._target_class_ids": [[250, 267], ["models.NeuralEditDistBase._deletion_id", "models.NeuralEditDistBase._insertion_id", "models.NeuralEditDistBase._substitute_id", "src_sent.unsqueeze().repeat", "tgt_sent.unsqueeze().repeat", "tgt_sent.size", "src_sent.size", "src_sent.unsqueeze", "tgt_sent.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "def", "_target_class_ids", "(", "\n", "self", ",", "src_sent", ":", "Tensor", ",", "tgt_sent", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"Output classes for input string pair.\n\n        This function computes what target classes correspond to deleting\n        source symbols, inserting target symbols and subsitituting source\n        symbols for target symbols. The vocabulary indices cannot be used\n        directly because they are different on source and target side and there\n        is a different number of possible edit operations than the vocabulary\n        sizes.\n        \"\"\"", "\n", "all_deletion_ids", "=", "self", ".", "_deletion_id", "(", "src_sent", ")", "\n", "all_insertion_ids", "=", "self", ".", "_insertion_id", "(", "tgt_sent", ")", "\n", "all_subs_ids", "=", "self", ".", "_substitute_id", "(", "\n", "src_sent", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "tgt_sent", ".", "size", "(", "1", ")", ")", ",", "\n", "tgt_sent", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src_sent", ".", "size", "(", "1", ")", ",", "1", ")", ")", "\n", "return", "(", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores": [[268, 340], ["models.NeuralEditDistBase._encode_src", "models.NeuralEditDistBase._encode_tgt", "models.NeuralEditDistBase.projection", "models.NeuralEditDistBase.deletion_logit_proj", "torch.full_like", "torch.cat", "models.NeuralEditDistBase.insertion_proj", "torch.full().to", "torch.cat", "models.NeuralEditDistBase.substitution_proj", "torch.full_like", "torch.cat", "torch.full().to", "torch.cat", "torch.functional.F.log_softmax", "src_sent.size", "tgt_sent.size", "torch.cat", "src_mask.unsqueeze().unsqueeze", "torch.cat", "models.NeuralEditDistBase.extra_proj", "actions_to_concat.append", "torch.cat", "torch.functional.F.log_softmax.size", "torch.functional.F.log_softmax.size", "torch.functional.F.log_softmax.size", "models.NeuralEditDistBase.attention", "torch.full", "torch.full", "models.NeuralEditDistBase.unsqueeze().repeat", "models.NeuralEditDistBase.unsqueeze().repeat", "src_mask.unsqueeze", "models.NeuralEditDistBase.unsqueeze().repeat", "models.NeuralEditDistBase.unsqueeze().repeat", "att_output.unsqueeze().repeat", "models.NeuralEditDistBase.size", "models.NeuralEditDistBase.size", "models.NeuralEditDistBase.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "models.NeuralEditDistBase.unsqueeze", "models.NeuralEditDistBase.unsqueeze", "models.NeuralEditDistBase.unsqueeze", "models.NeuralEditDistBase.unsqueeze", "att_output.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encode_src", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._encode_tgt"], ["", "def", "_action_scores", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "\"\"\"Compute possible action probabilities (Eq. 3 and 4).\"\"\"", "\n", "src_len", ",", "tgt_len", "=", "src_sent", ".", "size", "(", "1", ")", ",", "tgt_sent", ".", "size", "(", "1", ")", "\n", "src_mask", "=", "src_sent", "!=", "self", ".", "src_pad", "\n", "tgt_mask", "=", "tgt_sent", "!=", "self", ".", "tgt_pad", "\n", "src_vectors", "=", "self", ".", "_encode_src", "(", "src_sent", ",", "src_mask", ")", "\n", "tgt_vectors", "=", "self", ".", "_encode_tgt", "(", "tgt_sent", ",", "tgt_mask", ",", "src_vectors", ",", "src_mask", ")", "\n", "\n", "# TODO: do the sort of residual connection I had in Munich", "\n", "feature_table", "=", "self", ".", "projection", "(", "torch", ".", "cat", "(", "(", "\n", "src_vectors", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "tgt_len", ",", "1", ")", ",", "\n", "tgt_vectors", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src_len", ",", "1", ",", "1", ")", ")", ",", "dim", "=", "3", ")", ")", "\n", "\n", "if", "self", ".", "directed", ":", "\n", "            ", "unsq_enc_att_mask", "=", "(", "\n", "src_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "att_output", "=", "self", ".", "attention", "(", "\n", "tgt_vectors", ",", "encoder_hidden_states", "=", "src_vectors", ",", "\n", "encoder_attention_mask", "=", "unsq_enc_att_mask", ")", "[", "0", "]", "\n", "\n", "feature_table", "=", "torch", ".", "cat", "(", "\n", "(", "feature_table", ",", "\n", "src_vectors", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "tgt_len", ",", "1", ")", ",", "\n", "tgt_vectors", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src_len", ",", "1", ",", "1", ")", ",", "\n", "att_output", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src_len", ",", "1", ",", "1", ")", ")", ",", "\n", "dim", "=", "3", ")", "\n", "\n", "# DELETION <<<", "\n", "", "valid_deletion_logits", "=", "self", ".", "deletion_logit_proj", "(", "feature_table", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "deletion_padding", "=", "torch", ".", "full_like", "(", "valid_deletion_logits", "[", ":", ",", ":", "1", "]", ",", "MINF", ")", "\n", "padded_deletion_logits", "=", "torch", ".", "cat", "(", "\n", "(", "deletion_padding", ",", "valid_deletion_logits", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# INSERTIONS <<<", "\n", "valid_insertion_logits", "=", "self", ".", "insertion_proj", "(", "feature_table", "[", ":", ",", ":", ",", ":", "-", "1", "]", ")", "\n", "insertion_padding", "=", "torch", ".", "full", "(", "(", "\n", "valid_insertion_logits", ".", "size", "(", "0", ")", ",", "\n", "valid_insertion_logits", ".", "size", "(", "1", ")", ",", "1", ",", "\n", "valid_insertion_logits", ".", "size", "(", "3", ")", ")", ",", "MINF", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "padded_insertion_logits", "=", "torch", ".", "cat", "(", "\n", "(", "insertion_padding", ",", "valid_insertion_logits", ")", ",", "dim", "=", "2", ")", "\n", "\n", "# SUBSITUTION <<<", "\n", "valid_subs_logits", "=", "self", ".", "substitution_proj", "(", "feature_table", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ")", "\n", "src_subs_padding", "=", "torch", ".", "full_like", "(", "valid_subs_logits", "[", ":", ",", ":", "1", "]", ",", "MINF", ")", "\n", "src_padded_subs_logits", "=", "torch", ".", "cat", "(", "\n", "(", "src_subs_padding", ",", "valid_subs_logits", ")", ",", "dim", "=", "1", ")", "\n", "tgt_subs_padding", "=", "torch", ".", "full", "(", "(", "\n", "src_padded_subs_logits", ".", "size", "(", "0", ")", ",", "\n", "src_padded_subs_logits", ".", "size", "(", "1", ")", ",", "1", ",", "\n", "src_padded_subs_logits", ".", "size", "(", "3", ")", ")", ",", "MINF", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "padded_subs_logits", "=", "torch", ".", "cat", "(", "\n", "(", "tgt_subs_padding", ",", "src_padded_subs_logits", ")", ",", "dim", "=", "2", ")", "\n", "\n", "actions_to_concat", "=", "[", "\n", "padded_deletion_logits", ",", "padded_insertion_logits", ",", "\n", "padded_subs_logits", "]", "\n", "\n", "if", "self", ".", "extra_classes", ">", "0", ":", "\n", "            ", "extra_logits", "=", "self", ".", "extra_proj", "(", "feature_table", ")", "\n", "actions_to_concat", ".", "append", "(", "extra_logits", ")", "\n", "\n", "", "action_scores", "=", "F", ".", "log_softmax", "(", "torch", ".", "cat", "(", "\n", "actions_to_concat", ",", "dim", "=", "3", ")", ",", "dim", "=", "3", ")", "\n", "\n", "assert", "action_scores", ".", "size", "(", "1", ")", "==", "src_len", "\n", "assert", "action_scores", ".", "size", "(", "2", ")", "==", "tgt_len", "\n", "assert", "action_scores", ".", "size", "(", "3", ")", "==", "self", ".", "n_target_classes", "\n", "\n", "return", "(", "src_len", ",", "tgt_len", ",", "feature_table", ",", "action_scores", ",", "\n", "valid_insertion_logits", ",", "\n", "valid_subs_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation": [[341, 359], ["models._torchscript_forward_evaluation", "models.NeuralEditDistBase._target_class_ids"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models._torchscript_forward_evaluation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._target_class_ids"], ["", "def", "_forward_evaluation", "(", "\n", "self", ",", "\n", "src_sent", ":", "Tensor", ",", "\n", "tgt_sent", ":", "Tensor", ",", "\n", "action_scores", ":", "Tensor", ",", "\n", "all_deletion_ids", ":", "Tensor", "=", "None", ",", "\n", "all_insertion_ids", ":", "Tensor", "=", "None", ",", "\n", "all_subs_ids", ":", "Tensor", "=", "None", ")", ":", "\n", "        ", "\"\"\"Differentiable forward pass through the model. Algorithm 1.\"\"\"", "\n", "\n", "if", "all_deletion_ids", "is", "None", ":", "\n", "            ", "(", "all_deletion_ids", ",", "\n", "all_insertion_ids", ",", "\n", "all_subs_ids", ")", "=", "self", ".", "_target_class_ids", "(", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "", "return", "_torchscript_forward_evaluation", "(", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ",", "\n", "action_scores", ",", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._backward_evalatuion_and_expectation": [[360, 387], ["torch.no_grad", "models._torchscript_backward_evaluation"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models._torchscript_backward_evaluation"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_backward_evalatuion_and_expectation", "(", "\n", "self", ",", "\n", "src_len", ":", "int", ",", "\n", "tgt_len", ":", "int", ",", "\n", "src_sent", ":", "Tensor", ",", "\n", "tgt_sent", ":", "Tensor", ",", "\n", "all_deletion_ids", ":", "Tensor", ",", "\n", "all_insertion_ids", ":", "Tensor", ",", "\n", "all_subs_ids", ":", "Tensor", ",", "\n", "alpha", ":", "Tensor", ",", "\n", "action_scores", ":", "Tensor", ")", ":", "\n", "        ", "\"\"\"The backward pass through the edit distance table. Algorithm 2.\n\n        Unlike, the forward pass it does not have to be differentiable, because\n        it is only used to compute the expected distribution that is as a\n        \"target\" in the EM loss.\n        \"\"\"", "\n", "\n", "src_lengths", "=", "(", "src_sent", "!=", "self", ".", "src_pad", ")", ".", "sum", "(", "1", ")", "\n", "tgt_lengths", "=", "(", "tgt_sent", "!=", "self", ".", "tgt_pad", ")", ".", "sum", "(", "1", ")", "\n", "\n", "return", "_torchscript_backward_evaluation", "(", "\n", "src_len", ",", "tgt_len", ",", "\n", "src_lengths", ",", "tgt_lengths", ",", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ",", "\n", "alpha", ",", "action_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._alpha_distortion_penalty": [[388, 392], ["alpha_table.exp"], "methods", ["None"], ["", "def", "_alpha_distortion_penalty", "(", "self", ",", "src_len", ",", "tgt_len", ",", "alpha_table", ")", ":", "\n", "        ", "\"\"\"Penalty for the alphas being too high outside from the diagonal.\"\"\"", "\n", "penalties", "=", "self", ".", "distortion_mask", "[", ":", ",", ":", "src_len", ",", ":", "tgt_len", "]", "\n", "return", "alpha_table", ".", "exp", "(", ")", "*", "penalties", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.viterbi": [[393, 467], ["torch.no_grad", "models.NeuralEditDistBase._action_scores", "action_scores.squeeze.squeeze.squeeze", "torch.zeros", "torch.zeros", "enumerate", "operations.reverse", "src_sent.size", "torch.zeros", "enumerate", "torch.exp", "models.NeuralEditDistBase._deletion_id", "models.NeuralEditDistBase._insertion_id", "models.NeuralEditDistBase._substitute_id", "max", "operations.append", "possible_actions.append", "possible_actions.append", "possible_actions.append", "possible_actions.append", "possible_actions.append", "possible_actions.append", "operations.append", "src_sent[].cpu().numpy", "operations.append", "tgt_sent[].cpu().numpy", "src_sent[].cpu", "tgt_sent[].cpu", "src_sent[].cpu().numpy", "tgt_sent[].cpu().numpy", "src_sent[].cpu", "tgt_sent[].cpu"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "viterbi", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "\"\"\"Get a single best sequence of edit ops for a string pair.\"\"\"", "\n", "assert", "src_sent", ".", "size", "(", "0", ")", "==", "1", "\n", "src_len", ",", "tgt_len", ",", "_", ",", "action_scores", ",", "_", ",", "_", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "action_scores", "=", "action_scores", ".", "squeeze", "(", "0", ")", "\n", "\n", "action_count", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "\n", "actions", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "\n", "alpha", "=", "torch", ".", "zeros", "(", "(", "src_len", ",", "tgt_len", ")", ")", "+", "MINF", "\n", "alpha", "[", "0", ",", "0", "]", "=", "0", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", "[", "0", "]", ")", ":", "\n", "            ", "for", "v", ",", "tgt_char", "in", "enumerate", "(", "tgt_sent", "[", "0", "]", ")", ":", "\n", "                ", "if", "t", "==", "0", "and", "v", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "insertion_id", "=", "self", ".", "_insertion_id", "(", "tgt_char", ")", "\n", "subsitute_id", "=", "self", ".", "_substitute_id", "(", "src_char", ",", "tgt_char", ")", "\n", "\n", "possible_actions", "=", "[", "]", "\n", "\n", "if", "v", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "action_scores", "[", "t", ",", "v", ",", "insertion_id", "]", "+", "alpha", "[", "t", ",", "v", "-", "1", "]", ",", "\n", "action_count", "[", "t", ",", "v", "-", "1", "]", "+", "1", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "(", "-", "1e12", ",", "1.0", ",", "0", ")", ")", "\n", "", "if", "t", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "action_scores", "[", "t", ",", "v", ",", "deletion_id", "]", "+", "alpha", "[", "t", "-", "1", ",", "v", "]", ",", "\n", "action_count", "[", "t", "-", "1", ",", "v", "]", "+", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "(", "-", "1e12", ",", "1.0", ",", "1", ")", ")", "\n", "", "if", "v", ">=", "1", "and", "t", ">=", "1", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "\n", "(", "(", "action_scores", "[", "t", ",", "v", ",", "subsitute_id", "]", "+", "\n", "alpha", "[", "t", "-", "1", ",", "v", "-", "1", "]", ")", ",", "\n", "action_count", "[", "t", "-", "1", ",", "v", "-", "1", "]", "+", "1", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "possible_actions", ".", "append", "(", "(", "-", "1e12", ",", "1.0", ",", "2", ")", ")", "\n", "\n", "", "best_action_cost", ",", "best_action_count", ",", "best_action_id", "=", "max", "(", "\n", "possible_actions", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "\n", "alpha", "[", "t", ",", "v", "]", "=", "best_action_cost", "\n", "action_count", "[", "t", ",", "v", "]", "=", "best_action_count", "\n", "actions", "[", "t", ",", "v", "]", "=", "best_action_id", "\n", "\n", "", "", "operations", "=", "[", "]", "\n", "t", "=", "src_len", "-", "1", "\n", "v", "=", "tgt_len", "-", "1", "\n", "while", "t", ">", "0", "or", "v", ">", "0", ":", "\n", "            ", "if", "actions", "[", "t", ",", "v", "]", "==", "1", ":", "\n", "                ", "operations", ".", "append", "(", "\n", "(", "\"delete\"", ",", "src_sent", "[", "0", ",", "t", "-", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "t", "-", "1", ")", ")", "\n", "t", "-=", "1", "\n", "", "elif", "actions", "[", "t", ",", "v", "]", "==", "0", ":", "\n", "                ", "operations", ".", "append", "(", "\n", "(", "\"insert\"", ",", "tgt_sent", "[", "0", ",", "v", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "v", ")", ")", "\n", "v", "-=", "1", "\n", "", "elif", "actions", "[", "t", ",", "v", "]", "==", "2", ":", "\n", "                ", "operations", ".", "append", "(", "\n", "(", "\"subs\"", ",", "\n", "(", "src_sent", "[", "0", ",", "t", "-", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "tgt_sent", "[", "0", ",", "v", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "(", "t", "-", "1", ",", "v", ")", ")", ")", "\n", "v", "-=", "1", "\n", "t", "-=", "1", "\n", "", "", "operations", ".", "reverse", "(", ")", "\n", "\n", "return", "(", "torch", ".", "exp", "(", "alpha", "[", "-", "1", ",", "-", "1", "]", "/", "action_count", "[", "-", "1", ",", "-", "1", "]", ")", ",", "\n", "operations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.alpha": [[468, 477], ["torch.no_grad", "src_sent.size", "models.NeuralEditDistBase._action_scores", "models.NeuralEditDistBase._forward_evaluation"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "alpha", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "batch_size", "=", "src_sent", ".", "size", "(", "0", ")", "\n", "_", ",", "_", ",", "_", ",", "action_scores", ",", "_", ",", "_", "=", "(", "\n", "self", ".", "_action_scores", "(", "src_sent", ",", "tgt_sent", ")", ")", "\n", "\n", "alphas", "=", "self", ".", "_forward_evaluation", "(", "src_sent", ",", "tgt_sent", ",", "action_scores", ")", "\n", "\n", "return", "alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelConcurrent.__init__": [[481, 495], ["models.NeuralEditDistBase.__init__"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "device", ",", "directed", "=", "False", ",", "\n", "hidden_dim", "=", "32", ",", "hidden_layers", "=", "2", ",", "attention_heads", "=", "4", ",", "\n", "share_encoders", "=", "False", ",", "\n", "model_type", "=", "\"transformer\"", ",", "\n", "start_symbol", "=", "\"<s>\"", ",", "end_symbol", "=", "\"</s>\"", ",", "pad_symbol", "=", "\"<pad>\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "src_vocab", ",", "tgt_vocab", ",", "device", ",", "directed", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "\n", "share_encoders", "=", "share_encoders", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "hidden_layers", "=", "hidden_layers", ",", "\n", "attention_heads", "=", "attention_heads", ",", "\n", "table_type", "=", "\"tiny\"", ",", "extra_classes", "=", "1", ",", "\n", "start_symbol", "=", "start_symbol", ",", "end_symbol", "=", "end_symbol", ",", "\n", "pad_symbol", "=", "pad_symbol", ",", "model_type", "=", "model_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelConcurrent.forward": [[496, 521], ["src_sent.size", "torch.arange", "models.EditDistNeuralModelConcurrent._action_scores", "models.EditDistNeuralModelConcurrent._target_class_ids", "models.EditDistNeuralModelConcurrent._forward_evaluation", "models.EditDistNeuralModelConcurrent._backward_evalatuion_and_expectation", "models.EditDistNeuralModelConcurrent._alpha_distortion_penalty", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._target_class_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._backward_evalatuion_and_expectation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._alpha_distortion_penalty"], ["", "def", "forward", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "batch_size", "=", "src_sent", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", "\n", "src_lengths", "=", "(", "src_sent", "!=", "self", ".", "src_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "tgt_lengths", "=", "(", "tgt_sent", "!=", "self", ".", "tgt_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "src_len", ",", "tgt_len", ",", "_", ",", "action_scores", ",", "_", ",", "_", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "(", "all_deletion_ids", ",", "\n", "all_insertion_ids", ",", "\n", "all_subs_ids", ")", "=", "self", ".", "_target_class_ids", "(", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "alpha", "=", "self", ".", "_forward_evaluation", "(", "\n", "src_sent", ",", "tgt_sent", ",", "action_scores", ",", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ")", "\n", "_", ",", "expected_counts", "=", "self", ".", "_backward_evalatuion_and_expectation", "(", "\n", "src_len", ",", "tgt_len", ",", "src_sent", ",", "tgt_sent", ",", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ",", "\n", "alpha", ",", "action_scores", ")", "\n", "\n", "distorted_probs", "=", "self", ".", "_alpha_distortion_penalty", "(", "\n", "src_len", ",", "tgt_len", ",", "alpha", ")", "\n", "\n", "return", "(", "action_scores", ",", "torch", ".", "exp", "(", "expected_counts", ")", ",", "\n", "alpha", "[", "b_range", ",", "src_lengths", ",", "tgt_lengths", "]", ",", "distorted_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelConcurrent.probabilities": [[522, 537], ["torch.no_grad", "src_sent.size", "torch.arange", "models.EditDistNeuralModelConcurrent._action_scores", "models.EditDistNeuralModelConcurrent._forward_evaluation", "torch.max().float", "log_probs.exp", "torch.max", "torch.arange.to"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "probabilities", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "batch_size", "=", "src_sent", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", "\n", "src_lengths", "=", "(", "src_sent", "!=", "self", ".", "src_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "tgt_lengths", "=", "(", "tgt_sent", "!=", "self", ".", "tgt_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "_", ",", "_", ",", "_", ",", "action_scores", ",", "_", ",", "_", "=", "(", "\n", "self", ".", "_action_scores", "(", "src_sent", ",", "tgt_sent", ")", ")", "\n", "\n", "alpha", "=", "self", ".", "_forward_evaluation", "(", "src_sent", ",", "tgt_sent", ",", "action_scores", ")", "\n", "\n", "max_lens", "=", "torch", ".", "max", "(", "src_lengths", ",", "tgt_lengths", ")", ".", "float", "(", ")", "\n", "log_probs", "=", "alpha", "[", "b_range", ".", "to", "(", "self", ".", "device", ")", ",", "src_lengths", ",", "tgt_lengths", "]", "\n", "\n", "return", "log_probs", ".", "exp", "(", ")", ",", "(", "log_probs", "/", "max_lens", ")", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.__init__": [[541, 554], ["models.NeuralEditDistBase.__init__"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "device", ",", "directed", "=", "True", ",", "\n", "hidden_dim", "=", "32", ",", "hidden_layers", "=", "2", ",", "attention_heads", "=", "4", ",", "\n", "window", "=", "3", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "model_type", "=", "\"transformer\"", ",", "\n", "start_symbol", "=", "\"<s>\"", ",", "end_symbol", "=", "\"</s>\"", ",", "pad_symbol", "=", "\"<pad>\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "src_vocab", ",", "tgt_vocab", ",", "device", ",", "directed", ",", "table_type", "=", "\"vocab\"", ",", "\n", "model_type", "=", "model_type", ",", "\n", "encoder_decoder_attention", "=", "encoder_decoder_attention", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "hidden_layers", "=", "hidden_layers", ",", "\n", "attention_heads", "=", "attention_heads", ",", "window", "=", "window", ",", "\n", "start_symbol", "=", "start_symbol", ",", "end_symbol", "=", "end_symbol", ",", "\n", "pad_symbol", "=", "pad_symbol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.forward": [[555, 594], ["torch.arange", "models.EditDistNeuralModelProgressive._action_scores", "models.EditDistNeuralModelProgressive._target_class_ids", "models.EditDistNeuralModelProgressive._forward_evaluation", "models.EditDistNeuralModelProgressive._backward_evalatuion_and_expectation", "torch.cat().logsumexp", "models.EditDistNeuralModelProgressive._alpha_distortion_penalty", "src_sent.size", "torch.functional.F.log_softmax", "alpha[].unsqueeze", "torch.functional.F.log_softmax", "alpha[].unsqueeze", "torch.cat().logsumexp.logsumexp", "torch.exp", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._target_class_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._forward_evaluation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._backward_evalatuion_and_expectation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._alpha_distortion_penalty"], ["", "def", "forward", "(", "self", ",", "src_sent", ",", "tgt_sent", ")", ":", "\n", "        ", "b_range", "=", "torch", ".", "arange", "(", "src_sent", ".", "size", "(", "0", ")", ")", "\n", "src_lengths", "=", "(", "src_sent", "!=", "self", ".", "src_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "tgt_lengths", "=", "(", "tgt_sent", "!=", "self", ".", "tgt_pad", ")", ".", "int", "(", ")", ".", "sum", "(", "1", ")", "-", "1", "\n", "(", "src_len", ",", "tgt_len", ",", "_", ",", "action_scores", ",", "\n", "insertion_logits", ",", "subs_logits", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "(", "all_deletion_ids", ",", "\n", "all_insertion_ids", ",", "\n", "all_subs_ids", ")", "=", "self", ".", "_target_class_ids", "(", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "alpha", "=", "self", ".", "_forward_evaluation", "(", "\n", "src_sent", ",", "tgt_sent", ",", "action_scores", ",", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ")", "\n", "_", ",", "expected_counts", "=", "self", ".", "_backward_evalatuion_and_expectation", "(", "\n", "src_len", ",", "tgt_len", ",", "src_sent", ",", "tgt_sent", ",", "\n", "all_deletion_ids", ",", "all_insertion_ids", ",", "all_subs_ids", ",", "\n", "alpha", ",", "action_scores", ")", "\n", "\n", "insertion_log_dist", "=", "(", "\n", "F", ".", "log_softmax", "(", "insertion_logits", ",", "dim", "=", "3", ")", "\n", "+", "alpha", "[", ":", ",", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "subs_log_dist", "=", "(", "\n", "F", ".", "log_softmax", "(", "subs_logits", ",", "dim", "=", "3", ")", "\n", "+", "alpha", "[", ":", ",", "1", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "\n", "next_symbol_logprobs_sum", "=", "torch", ".", "cat", "(", "\n", "(", "insertion_log_dist", ",", "subs_log_dist", ")", ",", "dim", "=", "1", ")", ".", "logsumexp", "(", "1", ")", "\n", "next_symbol_logprobs", "=", "(", "\n", "next_symbol_logprobs_sum", "-", "\n", "next_symbol_logprobs_sum", ".", "logsumexp", "(", "2", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "distorted_probs", "=", "self", ".", "_alpha_distortion_penalty", "(", "\n", "src_len", ",", "tgt_len", ",", "alpha", ")", "\n", "\n", "return", "(", "action_scores", ",", "torch", ".", "exp", "(", "expected_counts", ")", ",", "\n", "alpha", "[", "b_range", ",", "src_lengths", ",", "tgt_lengths", "]", ",", "\n", "next_symbol_logprobs", ",", "distorted_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._scores_for_next_step": [[595, 632], ["torch.no_grad", "torch.cat().logsumexp", "alpha[].unsqueeze", "alpha[].unsqueeze", "torch.functional.F.log_softmax", "log_src_mask.unsqueeze().unsqueeze", "torch.functional.F.log_softmax", "log_src_mask[].unsqueeze().unsqueeze", "torch.cat", "models.EditDistNeuralModelProgressive.insertion_proj", "models.EditDistNeuralModelProgressive.substitution_proj", "log_src_mask.unsqueeze", "log_src_mask[].unsqueeze"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_scores_for_next_step", "(", "\n", "self", ",", "b_range", ",", "v", ",", "feature_table", ",", "log_src_mask", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Predict scores of next symbol, given the decoding history.\n\n        The decoding history is already in the feature table that contains also\n        the most recently decoded symbol.\n\n        Args:\n            b_range: Technical thing: tensor 0..batch_size\n            v: Position in the decoding.\n            feature_table: Representation of symbol pairs.\n            log_src_mask: Position maks for the input in the log domain.\n            alpha: Table with state probabilties.\n\n        Returns:\n            Logits for the next symbols.\n        \"\"\"", "\n", "\n", "insertion_scores", "=", "(", "\n", "F", ".", "log_softmax", "(", "\n", "self", ".", "insertion_proj", "(", "feature_table", "[", "b_range", ",", ":", ",", "v", "-", "1", ":", "v", "]", ")", ",", "\n", "dim", "=", "-", "1", ")", "\n", "+", "log_src_mask", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "+", "alpha", "[", ":", ",", ":", ",", "v", "-", "1", ":", "v", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "\n", "subs_scores", "=", "(", "\n", "F", ".", "log_softmax", "(", "\n", "self", ".", "substitution_proj", "(", "feature_table", "[", "b_range", ",", "1", ":", ",", "v", "-", "1", ":", "v", "]", ")", ",", "\n", "dim", "=", "-", "1", ")", "\n", "+", "log_src_mask", "[", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", "\n", "+", "alpha", "[", ":", ",", "1", ":", ",", "v", "-", "1", ":", "v", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "\n", "next_symb_scores", "=", "torch", ".", "cat", "(", "\n", "(", "insertion_scores", ",", "subs_scores", ")", ",", "dim", "=", "1", ")", ".", "logsumexp", "(", "1", ")", "\n", "\n", "return", "next_symb_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._update_alpha_with_new_row": [[633, 682], ["torch.no_grad", "torch.cat", "enumerate", "src_sent.transpose", "models.EditDistNeuralModelProgressive._deletion_id", "models.EditDistNeuralModelProgressive._insertion_id", "models.EditDistNeuralModelProgressive._substitute_id", "torch.full().to", "to_sum.append", "to_sum.append", "len", "torch.stack().logsumexp", "torch.full", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._insertion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._substitute_id"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_alpha_with_new_row", "(", "\n", "self", ",", "batch_size", ",", "b_range", ",", "v", ",", "alpha", ",", "action_scores", ",", "src_sent", ",", "\n", "tgt_sent", ",", "src_len", ")", ":", "\n", "        ", "\"\"\"Update the probabilities table for newly decoded characters.\n\n        Here, we add a row to the alpha table (probabilities of edit states)\n        for the recently added symbol during decoding. It assumes the feature\n        table already contains representations for the most recent symbol.\n\n        Args:\n            b_range: Technical thing: tensor 0..batch_size\n            v: Position in the decoding.\n            alpha: Alpha table from previous step.\n            action_scores: Table with scores for particular edit actions.\n            src_sent: Source sequence.\n            tgt_sent: Prefix of so far decoded target sequence.\n            src_len: Max lenght of the source sequences.\n\n        Return:\n            Updated alpha table.\n        \"\"\"", "\n", "alpha", "=", "torch", ".", "cat", "(", "\n", "(", "alpha", ",", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "src_len", ",", "1", ")", ",", "MINF", ")", ".", "to", "(", "self", ".", "device", ")", ")", ",", "dim", "=", "2", ")", "\n", "\n", "# TODO masking!", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "            ", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "insertion_id", "=", "self", ".", "_insertion_id", "(", "tgt_sent", "[", ":", ",", "v", "]", ")", "\n", "subsitute_id", "=", "self", ".", "_substitute_id", "(", "src_char", ",", "tgt_sent", "[", ":", ",", "v", "]", ")", "\n", "\n", "to_sum", "=", "[", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "insertion_id", "]", "+", "\n", "alpha", "[", ":", ",", "t", ",", "v", "-", "1", "]", "]", "\n", "if", "t", ">=", "1", ":", "\n", "                ", "to_sum", ".", "append", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "deletion_id", "]", "+", "\n", "alpha", "[", ":", ",", "t", "-", "1", ",", "v", "]", ")", "\n", "to_sum", ".", "append", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "subsitute_id", "]", "+", "\n", "alpha", "[", ":", ",", "t", "-", "1", ",", "v", "-", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "to_sum", ")", "==", "1", ":", "\n", "                ", "alpha", "[", ":", ",", "t", ",", "v", "]", "=", "to_sum", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "alpha", "[", ":", ",", "t", ",", "v", "]", "=", "torch", ".", "stack", "(", "to_sum", ")", ".", "logsumexp", "(", "0", ")", "\n", "\n", "", "", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.decode": [[683, 735], ["torch.no_grad", "src_sent.size", "torch.arange", "torch.tensor().to", "models.EditDistNeuralModelProgressive._action_scores", "torch.where", "torch.full().to", "enumerate", "torch.full().to", "range", "torch.full_like", "torch.zeros_like", "src_sent.transpose", "models.EditDistNeuralModelProgressive._deletion_id", "models.EditDistNeuralModelProgressive._scores_for_next_step", "models.EditDistNeuralModelProgressive.argmax", "torch.where", "torch.cat", "models.EditDistNeuralModelProgressive._action_scores", "models.EditDistNeuralModelProgressive._update_alpha_with_new_row", "torch.all", "torch.tensor", "torch.full", "torch.full", "src_sent.size", "torch.full().to.unsqueeze", "torch.full_like", "torch.where.squeeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._scores_for_next_step", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._update_alpha_with_new_row"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "decode", "(", "self", ",", "src_sent", ")", ":", "\n", "        ", "batch_size", "=", "src_sent", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", "\n", "\n", "tgt_sent", "=", "torch", ".", "tensor", "(", "[", "[", "self", ".", "tgt_bos", "]", "]", "*", "batch_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "(", "src_len", ",", "_", ",", "feature_table", ",", "\n", "action_scores", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "src_sent", ",", "tgt_sent", ")", "\n", "log_src_mask", "=", "torch", ".", "where", "(", "\n", "src_sent", "==", "self", ".", "src_pad", ",", "\n", "torch", ".", "full_like", "(", "src_sent", ",", "MINF", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "torch", ".", "zeros_like", "(", "src_sent", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "# special case, v = 0", "\n", "alpha", "=", "torch", ".", "full", "(", "(", "batch_size", ",", "src_len", ",", "1", ")", ",", "MINF", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "alpha", "[", ":", ",", ":", ",", "0", "]", "=", "log_src_mask", "\n", "continue", "\n", "", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "alpha", "[", ":", ",", "t", ",", "0", "]", "=", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "0", ",", "deletion_id", "]", "+", "alpha", "[", ":", ",", "t", "-", "1", ",", "0", "]", ")", "\n", "\n", "", "finished", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "]", ",", "False", ",", "dtype", "=", "torch", ".", "bool", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "v", "in", "range", "(", "1", ",", "2", "*", "src_sent", ".", "size", "(", "1", ")", ")", ":", "\n", "\n", "            ", "next_symb_scores", "=", "self", ".", "_scores_for_next_step", "(", "\n", "b_range", ",", "v", ",", "feature_table", ",", "log_src_mask", ",", "alpha", ")", "\n", "\n", "next_symbol_candidate", "=", "next_symb_scores", ".", "argmax", "(", "2", ")", "\n", "next_symbol", "=", "torch", ".", "where", "(", "\n", "finished", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "full_like", "(", "next_symbol_candidate", ",", "self", ".", "tgt_pad", ")", ",", "\n", "next_symbol_candidate", ")", "\n", "\n", "tgt_sent", "=", "torch", ".", "cat", "(", "(", "tgt_sent", ",", "next_symbol", ")", ",", "dim", "=", "1", ")", "\n", "\n", "(", "src_len", ",", "tgt_len", ",", "feature_table", ",", "\n", "action_scores", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "finished", "+=", "next_symbol", ".", "squeeze", "(", "1", ")", "==", "self", ".", "tgt_eos", "\n", "\n", "alpha", "=", "self", ".", "_update_alpha_with_new_row", "(", "\n", "batch_size", ",", "b_range", ",", "v", ",", "alpha", ",", "action_scores", ",", "\n", "src_sent", ",", "tgt_sent", ",", "src_len", ")", "\n", "\n", "# expand the target sequence", "\n", "if", "torch", ".", "all", "(", "finished", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "tgt_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.beam_search": [[736, 847], ["torch.no_grad", "src_sent.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.size", "torch.arange", "torch.where", "torch.full().to", "models.EditDistNeuralModelProgressive._action_scores", "torch.full().to", "enumerate", "torch.full().to", "torch.zeros().to", "torch.cat.reshape", "torch.cat().reshape.reshape", "torch.full().to.reshape", "torch.full_like", "torch.zeros_like", "torch.cat.squeeze", "src_sent.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.transpose", "models.EditDistNeuralModelProgressive._deletion_id", "models.EditDistNeuralModelProgressive._scores_for_next_step", "torch.pow", "normed_scores.reshape().topk", "torch.arange", "torch.cat", "torch.cat().reshape.reshape.index_select", "torch.cat().reshape", "models.EditDistNeuralModelProgressive.index_select", "finished_now.all", "candidate_scores.reshape().gather", "torch.cat.reshape", "torch.cat().reshape.reshape", "models.EditDistNeuralModelProgressive._action_scores", "models.EditDistNeuralModelProgressive._update_alpha_with_new_row", "torch.full", "torch.full", "torch.full", "torch.zeros", "candidate_scores.reshape().gather.unsqueeze", "models.EditDistNeuralModelProgressive.reshape", "src_sent.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "log_src_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "torch.arange().to", "torch.cat.reshape.size", "normed_scores.reshape", "torch.cat.reshape.index_select().reshape", "next_symbol_ids.unsqueeze", "next_symbol_ids.view", "torch.cat", "candidate_scores.reshape", "torch.arange.unsqueeze", "src_sent.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "log_src_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "torch.arange", "torch.cat.reshape.index_select", "torch.cat().reshape.float", "src_sent.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze", "log_src_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistBase._deletion_id", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._scores_for_next_step", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive._update_alpha_with_new_row"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "beam_search", "(", "self", ",", "src_sent", ",", "beam_size", "=", "10", ",", "len_norm", "=", "1.0", ")", ":", "\n", "        ", "batch_size", "=", "src_sent", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", "\n", "\n", "log_src_mask", "=", "torch", ".", "where", "(", "\n", "src_sent", "==", "self", ".", "src_pad", ",", "\n", "torch", ".", "full_like", "(", "src_sent", ",", "MINF", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "torch", ".", "zeros_like", "(", "src_sent", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "\n", "# special case, v = 0 - intitialize first row of alpha table", "\n", "decoded", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ",", "1", ")", ",", "self", ".", "tgt_bos", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "(", "src_len", ",", "_", ",", "feature_table", ",", "\n", "action_scores", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "decoded", ".", "squeeze", "(", "1", ")", ")", "\n", "\n", "alpha", "=", "torch", ".", "full", "(", "(", "batch_size", ",", "1", ",", "src_len", ",", "1", ")", ",", "MINF", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "t", ",", "src_char", "in", "enumerate", "(", "src_sent", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "alpha", "[", ":", ",", "0", ",", ":", ",", "0", "]", "=", "log_src_mask", "\n", "continue", "\n", "", "deletion_id", "=", "self", ".", "_deletion_id", "(", "src_char", ")", "\n", "alpha", "[", ":", ",", "0", ",", "t", ",", "0", "]", "=", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "0", ",", "deletion_id", "]", "\n", "+", "alpha", "[", ":", ",", "0", ",", "t", "-", "1", ",", "0", "]", ")", "\n", "\n", "# INITIALIZE THE BEAM SEARCH", "\n", "", "cur_len", "=", "1", "\n", "current_beam", "=", "1", "\n", "finished", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ",", "1", ")", ",", "False", ",", "dtype", "=", "torch", ".", "bool", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "flat_decoded", "=", "decoded", ".", "reshape", "(", "batch_size", ",", "cur_len", ")", "\n", "flat_finished", "=", "finished", ".", "reshape", "(", "batch_size", ",", "cur_len", ")", "\n", "flat_alpha", "=", "alpha", ".", "reshape", "(", "batch_size", ",", "src_len", ",", "1", ")", "\n", "while", "cur_len", "<", "2", "*", "src_len", ":", "\n", "            ", "next_symb_scores", "=", "self", ".", "_scores_for_next_step", "(", "\n", "b_range", ",", "cur_len", ",", "feature_table", ",", "log_src_mask", ",", "flat_alpha", ")", "\n", "\n", "# get scores of all expanded hypotheses", "\n", "candidate_scores", "=", "(", "\n", "scores", ".", "unsqueeze", "(", "2", ")", "+", "\n", "next_symb_scores", ".", "reshape", "(", "batch_size", ",", "current_beam", ",", "-", "1", ")", ")", "\n", "norm_factor", "=", "torch", ".", "pow", "(", "\n", "(", "1", "-", "finished", ".", "float", "(", ")", ")", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", "+", "1", ",", "len_norm", ")", "\n", "normed_scores", "=", "candidate_scores", "/", "norm_factor", "\n", "\n", "# reshape for beam members and get top k", "\n", "_", ",", "best_indices", "=", "normed_scores", ".", "reshape", "(", "\n", "batch_size", ",", "-", "1", ")", ".", "topk", "(", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "next_symbol_ids", "=", "best_indices", "%", "self", ".", "tgt_symbol_count", "\n", "hypothesis_ids", "=", "best_indices", "//", "self", ".", "tgt_symbol_count", "\n", "\n", "# numbering elements in the extended batch, i.e. beam size copies", "\n", "# of each batch element", "\n", "beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "batch_size", "*", "current_beam", ",", "step", "=", "current_beam", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "global_best_indices", "=", "(", "\n", "beam_offset", ".", "unsqueeze", "(", "1", ")", "+", "hypothesis_ids", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# now select appropriate histories", "\n", "decoded", "=", "torch", ".", "cat", "(", "(", "\n", "flat_decoded", ".", "index_select", "(", "\n", "0", ",", "global_best_indices", ")", ".", "reshape", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ",", "\n", "next_symbol_ids", ".", "unsqueeze", "(", "-", "1", ")", ")", ",", "dim", "=", "2", ")", "\n", "reordered_finished", "=", "flat_finished", ".", "index_select", "(", "\n", "0", ",", "global_best_indices", ")", "\n", "finished_now", "=", "(", "\n", "(", "next_symbol_ids", ".", "view", "(", "-", "1", ",", "1", ")", "==", "self", ".", "tgt_eos", ")", "\n", "+", "reordered_finished", "[", ":", ",", "-", "1", ":", "]", ")", "\n", "finished", "=", "torch", ".", "cat", "(", "(", "\n", "reordered_finished", ",", "\n", "finished_now", ")", ",", "dim", "=", "1", ")", ".", "reshape", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "flat_alpha", "=", "flat_alpha", ".", "index_select", "(", "0", ",", "global_best_indices", ")", "\n", "\n", "if", "finished_now", ".", "all", "(", ")", ":", "\n", "                ", "break", "\n", "\n", "# re-order scores", "\n", "", "scores", "=", "candidate_scores", ".", "reshape", "(", "\n", "batch_size", ",", "-", "1", ")", ".", "gather", "(", "-", "1", ",", "best_indices", ")", "\n", "\n", "# TODO need to be done better fi we want lenght normalization", "\n", "\n", "# tile encoder after first step", "\n", "if", "cur_len", "==", "1", ":", "\n", "                ", "src_sent", "=", "src_sent", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "beam_size", ",", "1", ")", ".", "reshape", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "log_src_mask", "=", "log_src_mask", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "beam_size", ",", "1", ")", ".", "reshape", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", "*", "beam_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# prepare feature and alpha for the next step", "\n", "", "flat_decoded", "=", "decoded", ".", "reshape", "(", "-", "1", ",", "cur_len", "+", "1", ")", "\n", "flat_finished", "=", "finished", ".", "reshape", "(", "-", "1", ",", "cur_len", "+", "1", ")", "\n", "(", "src_len", ",", "_", ",", "feature_table", ",", "\n", "action_scores", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "flat_decoded", ")", "\n", "flat_alpha", "=", "self", ".", "_update_alpha_with_new_row", "(", "\n", "flat_decoded", ".", "size", "(", "0", ")", ",", "b_range", ",", "cur_len", ",", "flat_alpha", ",", "\n", "action_scores", ",", "src_sent", ",", "flat_decoded", ",", "src_len", ")", "\n", "\n", "# in the first iteration, beam size is 1, in the later ones,", "\n", "# it is the real beam size", "\n", "current_beam", "=", "beam_size", "\n", "cur_len", "+=", "1", "\n", "\n", "", "return", "decoded", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_decoding": [[848, 908], ["torch.no_grad", "torch.tensor().to", "models.EditDistNeuralModelProgressive._action_scores", "range", "src_sent.size", "ValueError", "models.EditDistNeuralModelProgressive.insertion_proj", "torch.cat", "torch.cat.argmax", "torch.cat", "models.EditDistNeuralModelProgressive._action_scores", "torch.tensor", "src_sent.size", "MINF.unsqueeze().to", "models.EditDistNeuralModelProgressive.deletion_logit_proj", "torch.full_like", "models.EditDistNeuralModelProgressive.substitution_proj", "next_symbol.unsqueeze().unsqueeze", "MINF.unsqueeze", "next_symbol.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "operation_decoding", "(", "self", ",", "src_sent", ")", ":", "\n", "        ", "\"\"\"Decode sequeence by operation sampling.\n\n        Instead of sampling from symbol distributions, it samples directly\n        operations.\n\n        Args:\n            at_sent: Source sequence.\n\n        Returns:\n            Decoded target string.\n\n        \"\"\"", "\n", "if", "src_sent", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only works with batch size 1.\"", ")", "\n", "\n", "", "tgt_sent", "=", "torch", ".", "tensor", "(", "[", "[", "self", ".", "tgt_bos", "]", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "(", "src_len", ",", "_", ",", "feature_table", ",", "_", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "\n", "v", "=", "0", "\n", "t", "=", "0", "\n", "for", "_", "in", "range", "(", "1", ",", "2", "*", "src_sent", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "state", "=", "feature_table", "[", "0", ",", "t", ",", "v", "]", "\n", "\n", "if", "t", ">=", "src_len", "-", "1", ":", "\n", "                ", "deletion_score", "=", "MINF", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "deletion_score", "=", "self", ".", "deletion_logit_proj", "(", "state", ")", "\n", "", "insertion_scores", "=", "self", ".", "insertion_proj", "(", "state", ")", "\n", "if", "t", ">=", "src_len", "-", "1", ":", "\n", "                ", "subs_scores", "=", "torch", ".", "full_like", "(", "insertion_scores", ",", "MINF", ")", "\n", "", "else", ":", "\n", "                ", "subs_scores", "=", "self", ".", "substitution_proj", "(", "state", ")", "\n", "\n", "", "all_scores", "=", "torch", ".", "cat", "(", "[", "\n", "deletion_score", ",", "insertion_scores", ",", "subs_scores", "]", ",", "dim", "=", "0", ")", "\n", "best_operation", "=", "all_scores", ".", "argmax", "(", ")", "\n", "\n", "# Delete source symbol and move in the source sequence", "\n", "if", "best_operation", "==", "0", ":", "\n", "                ", "t", "+=", "1", "\n", "continue", "\n", "\n", "# We are adding a new symbol => increase target sequnece index", "\n", "", "next_symbol", "=", "(", "best_operation", "-", "1", ")", "%", "self", ".", "tgt_symbol_count", "\n", "v", "+=", "1", "\n", "\n", "if", "best_operation", ">", "self", ".", "tgt_symbol_count", ":", "\n", "                ", "t", "+=", "1", "\n", "\n", "", "tgt_sent", "=", "torch", ".", "cat", "(", "(", "\n", "tgt_sent", ",", "next_symbol", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "(", "src_len", ",", "_", ",", "feature_table", ",", "_", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "if", "next_symbol", "==", "self", ".", "tgt_eos", ":", "\n", "                ", "break", "\n", "", "", "return", "tgt_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_beam_search": [[909, 984], ["torch.no_grad", "range", "src_sent.size", "ValueError", "heapq.nlargest", "all", "max", "torch.tensor().to", "src_sent.size", "models.EditDistNeuralModelProgressive._action_scores", "models.EditDistNeuralModelProgressive.insertion_proj", "torch.functional.F.log_softmax", "torch.functional.F.log_softmax.topk", "zip", "next_candidates.append", "MINF.unsqueeze().to", "models.EditDistNeuralModelProgressive.deletion_logit_proj", "torch.full_like", "models.EditDistNeuralModelProgressive.substitution_proj", "torch.cat", "torch.cat", "next_candidates.append", "torch.tensor", "next_candidates.append", "MINF.unsqueeze", "next_symbol.unsqueeze().unsqueeze", "next_symbol.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase._action_scores"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "operation_beam_search", "(", "self", ",", "src_sent", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\"Decode sequeence by operation sampling.\n\n        Instead of sampling from symbol distributions, it samples directly\n        operations.\n\n        Args:\n            at_sent: Source sequence.\n\n        Returns:\n            Decoded target string.\n        \"\"\"", "\n", "if", "src_sent", ".", "size", "(", "0", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only works with batch size 1.\"", ")", "\n", "\n", "# State is a tuple: target sequence, t, v, finished, score", "\n", "", "beam", "=", "[", "(", "torch", ".", "tensor", "(", "[", "[", "self", ".", "tgt_bos", "]", "]", ")", ".", "to", "(", "self", ".", "device", ")", ",", "0", ",", "0", ",", "False", ",", "0", ")", "]", "\n", "next_candidates", "=", "[", "]", "\n", "\n", "def", "score_fn", "(", "hypothesis", ")", ":", "\n", "            ", "_", ",", "_", ",", "tgt_pos", ",", "_", ",", "score_sum", "=", "hypothesis", "\n", "return", "score_sum", "/", "(", "tgt_pos", "+", "1", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "1", ",", "2", "*", "src_sent", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "for", "tgt_sent", ",", "t", ",", "v", ",", "finished", ",", "score", "in", "beam", ":", "\n", "                ", "if", "finished", ":", "\n", "                    ", "next_candidates", ".", "append", "(", "(", "tgt_sent", ",", "t", ",", "v", ",", "finished", ",", "score", ")", ")", "\n", "continue", "\n", "\n", "", "(", "src_len", ",", "_", ",", "feature_table", ",", "_", ",", "_", ",", "_", ")", "=", "self", ".", "_action_scores", "(", "\n", "src_sent", ",", "tgt_sent", ")", "\n", "state", "=", "feature_table", "[", "0", ",", "t", ",", "v", "]", "\n", "\n", "if", "t", ">=", "src_len", "-", "1", ":", "\n", "                    ", "deletion_score", "=", "MINF", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                    ", "deletion_score", "=", "self", ".", "deletion_logit_proj", "(", "state", ")", "\n", "", "insertion_scores", "=", "self", ".", "insertion_proj", "(", "state", ")", "\n", "if", "t", ">=", "src_len", "-", "1", ":", "\n", "                    ", "subs_scores", "=", "torch", ".", "full_like", "(", "insertion_scores", ",", "MINF", ")", "\n", "", "else", ":", "\n", "                    ", "subs_scores", "=", "self", ".", "substitution_proj", "(", "state", ")", "\n", "\n", "", "all_scores", "=", "F", ".", "log_softmax", "(", "torch", ".", "cat", "(", "[", "\n", "deletion_score", ",", "insertion_scores", ",", "subs_scores", "]", ",", "dim", "=", "0", ")", ",", "\n", "dim", "=", "0", ")", "\n", "best_scores", ",", "best_indices", "=", "all_scores", ".", "topk", "(", "2", "*", "beam_size", ")", "\n", "\n", "for", "op_score", ",", "op_idx", "in", "zip", "(", "best_scores", ",", "best_indices", ")", ":", "\n", "# Delete source symbol and move in the source sequence", "\n", "                    ", "if", "op_idx", "==", "0", ":", "\n", "                        ", "next_candidates", ".", "append", "(", "(", "\n", "tgt_sent", ",", "t", "+", "1", ",", "v", ",", "False", ",", "score", "+", "op_score", ")", ")", "\n", "continue", "\n", "\n", "# Adding a new symbol => increase target sequnece index", "\n", "", "next_symbol", "=", "(", "op_idx", "-", "1", ")", "%", "self", ".", "tgt_symbol_count", "\n", "new_tgt_sent", "=", "torch", ".", "cat", "(", "(", "\n", "tgt_sent", ",", "next_symbol", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "next_candidates", ".", "append", "(", "(", "\n", "new_tgt_sent", ",", "\n", "t", "+", "(", "op_idx", ">", "self", ".", "tgt_symbol_count", ")", ",", "\n", "v", "+", "1", ",", "\n", "next_symbol", "==", "self", ".", "tgt_eos", ",", "\n", "score", "+", "op_score", ")", ")", "\n", "\n", "", "", "beam", "=", "heapq", ".", "nlargest", "(", "\n", "beam_size", ",", "next_candidates", ",", "key", "=", "score_fn", ")", "\n", "next_candidates", "=", "[", "]", "\n", "if", "all", "(", "hyp", "[", "3", "]", "for", "hyp", "in", "beam", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "max", "(", "beam", ",", "key", "=", "score_fn", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.get_distortion_mask": [[100, 116], ["range", "torch.tensor().float().unsqueeze", "range", "mask.append", "row.append", "torch.tensor().float", "max", "torch.tensor", "abs"], "function", ["None"], ["", "", "def", "get_distortion_mask", "(", "max_size", "=", "512", ")", ":", "\n", "    ", "\"\"\"Mask to be applied on alpha during training.\n\n    The purpose of the distrotion maks is to dicourage the model from making\n    states far from diagonal too probable. In other words, discourage the model\n    from considering: delete everything and then insert everything to be a good\n    output.\n    \"\"\"", "\n", "\n", "mask", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_size", ")", ":", "\n", "        ", "row", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "max_size", ")", ":", "\n", "            ", "row", ".", "append", "(", "max", "(", "0", ",", "abs", "(", "i", "-", "j", ")", "-", "1", ")", ")", "\n", "", "mask", ".", "append", "(", "row", ")", "\n", "", "return", "torch", ".", "tensor", "(", "mask", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models._torchscript_forward_evaluation": [[986, 1039], ["torch.log", "all_deletion_ids.size", "torch.arange().to", "enumerate", "torch.stack().permute", "torch.tensor", "all_deletion_ids.transpose", "alpha.append", "enumerate", "torch.arange", "all_insertion_ids.transpose", "torch.stack", "alpha[].append", "to_sum.append", "to_sum.append", "to_sum.append", "alpha[].append", "len", "alpha[].append", "alpha[].append", "torch.zeros().to", "torch.full().to", "torch.stack().logsumexp", "torch.stack", "torch.zeros", "torch.full", "torch.stack"], "function", ["None"], ["", "", "@", "torch", ".", "jit", ".", "script", "\n", "def", "_torchscript_forward_evaluation", "(", "\n", "all_deletion_ids", ":", "Tensor", ",", "\n", "all_insertion_ids", ":", "Tensor", ",", "\n", "all_subs_ids", ":", "Tensor", ",", "\n", "action_scores", ":", "Tensor", ",", "\n", "device", ":", "torch", ".", "device", ")", "->", "Tensor", ":", "\n", "\n", "    ", "\"\"\"Differentiable forward pass through the model. Algorithm 1.\n\n    Here, the input and otput sequence is no longer represented by vocabulary\n    indices (they are necessary to get input embeddings), but by indices that\n    corresponding to target classes of the edit operations.\n    \"\"\"", "\n", "minf", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "0.", ")", ")", "\n", "alpha", ":", "List", "[", "List", "[", "Tensor", "]", "]", "=", "[", "]", "\n", "batch_size", "=", "all_deletion_ids", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "to", "(", "device", ")", "\n", "for", "t", ",", "deletion_id", "in", "enumerate", "(", "all_deletion_ids", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "        ", "alpha", ".", "append", "(", "[", "]", ")", "\n", "for", "v", ",", "insertion_id", "in", "enumerate", "(", "all_insertion_ids", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "            ", "if", "t", "==", "0", "and", "v", "==", "0", ":", "\n", "                ", "alpha", "[", "0", "]", ".", "append", "(", "torch", ".", "zeros", "(", "(", "batch_size", ",", ")", ")", ".", "to", "(", "device", ")", ")", "\n", "continue", "\n", "\n", "", "subsitute_id", "=", "all_subs_ids", "[", ":", ",", "t", ",", "v", "]", "\n", "\n", "to_sum", "=", "[", "]", "\n", "if", "v", ">=", "1", ":", "# INSERTION", "\n", "                ", "to_sum", ".", "append", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "insertion_id", "]", "+", "\n", "alpha", "[", "t", "]", "[", "v", "-", "1", "]", ")", "\n", "", "if", "t", ">=", "1", ":", "# DELETION", "\n", "                ", "to_sum", ".", "append", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "deletion_id", "]", "+", "\n", "alpha", "[", "t", "-", "1", "]", "[", "v", "]", ")", "\n", "", "if", "v", ">=", "1", "and", "t", ">=", "1", ":", "# SUBSTITUTION", "\n", "                ", "to_sum", ".", "append", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "subsitute_id", "]", "+", "\n", "alpha", "[", "t", "-", "1", "]", "[", "v", "-", "1", "]", ")", "\n", "\n", "", "if", "not", "to_sum", ":", "\n", "                ", "alpha", "[", "t", "]", ".", "append", "(", "\n", "torch", ".", "full", "(", "[", "batch_size", "]", ",", "minf", ")", ".", "to", "(", "device", ")", ")", "\n", "", "if", "len", "(", "to_sum", ")", "==", "1", ":", "\n", "                ", "alpha", "[", "t", "]", ".", "append", "(", "to_sum", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "alpha", "[", "t", "]", ".", "append", "(", "\n", "torch", ".", "stack", "(", "to_sum", ")", ".", "logsumexp", "(", "0", ")", ")", "\n", "\n", "", "", "", "alpha_tensor", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "stack", "(", "v", ")", "for", "v", "in", "alpha", "]", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "return", "alpha_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models._torchscript_backward_evaluation": [[1041, 1151], ["torch.log", "torch.full_like", "torch.full_like", "torch.full_like", "all_deletion_ids.size", "torch.arange", "torch.full_like", "torch.arange().to().flip", "torch.stack().logsumexp", "torch.stack().logsumexp.logsumexp", "torch.tensor", "torch.arange().to().flip", "torch.zeros_like", "beta[].unsqueeze", "torch.zeros_like", "beta[].unsqueeze", "torch.zeros_like", "beta[].unsqueeze", "torch.arange().to", "torch.stack().logsumexp", "torch.where", "torch.stack", "torch.arange().to", "to_sum.append", "torch.zeros", "to_sum.append", "to_sum.append", "torch.zeros_like", "torch.where", "alpha[].unsqueeze", "alpha[].unsqueeze", "alpha[].unsqueeze", "torch.arange", "torch.where", "torch.where", "torch.where", "torch.stack", "torch.full_like", "torch.arange", "torch.full_like", "torch.full_like", "torch.full_like"], "function", ["None"], ["", "@", "torch", ".", "jit", ".", "script", "\n", "def", "_torchscript_backward_evaluation", "(", "\n", "src_len", ":", "int", ",", "\n", "tgt_len", ":", "int", ",", "\n", "src_lengths", ":", "Tensor", ",", "\n", "tgt_lengths", ":", "Tensor", ",", "\n", "all_deletion_ids", ":", "Tensor", ",", "\n", "all_insertion_ids", ":", "Tensor", ",", "\n", "all_subs_ids", ":", "Tensor", ",", "\n", "alpha", ":", "Tensor", ",", "\n", "action_scores", ":", "Tensor", ")", "->", "Tuple", "[", "Tensor", ",", "Tensor", "]", ":", "\n", "    ", "\"\"\"The backward pass through the edit distance table.\n\n    Compilable as a TorchScript function.\n    \"\"\"", "\n", "\n", "minf", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "0.", ")", ")", "\n", "plausible_deletions", "=", "torch", ".", "full_like", "(", "action_scores", ",", "minf", ")", "\n", "plausible_insertions", "=", "torch", ".", "full_like", "(", "action_scores", ",", "minf", ")", "\n", "plausible_substitutions", "=", "torch", ".", "full_like", "(", "action_scores", ",", "minf", ")", "\n", "\n", "batch_size", "=", "all_deletion_ids", ".", "size", "(", "0", ")", "\n", "b_range", "=", "torch", ".", "arange", "(", "batch_size", ")", "\n", "\n", "beta", "=", "torch", ".", "full_like", "(", "alpha", ",", "minf", ")", "\n", "beta", "[", ":", ",", "-", "1", ",", "-", "1", "]", "=", "0.0", "\n", "\n", "for", "t", "in", "torch", ".", "arange", "(", "src_len", ")", ".", "to", "(", "alpha", ".", "device", ")", ".", "flip", "(", "0", ")", ":", "\n", "        ", "for", "v", "in", "torch", ".", "arange", "(", "tgt_len", ")", ".", "to", "(", "alpha", ".", "device", ")", ".", "flip", "(", "0", ")", ":", "\n", "# Bool mask: when we are in the table inside both words", "\n", "            ", "is_valid", "=", "(", "v", "<=", "(", "tgt_lengths", "-", "1", ")", ")", "*", "(", "t", "<=", "(", "src_lengths", "-", "1", ")", ")", "\n", "# Bool mask: true for end state of word pairs", "\n", "is_corner", "=", "(", "v", "==", "(", "tgt_lengths", "-", "1", ")", ")", "*", "(", "t", "==", "(", "src_lengths", "-", "1", ")", ")", "\n", "\n", "to_sum", "=", "[", "beta", "[", ":", ",", "t", ",", "v", "]", "]", "\n", "if", "v", "<", "tgt_len", "-", "1", ":", "\n", "                ", "insertion_id", "=", "all_insertion_ids", "[", ":", ",", "v", "]", "\n", "plausible_insertions", "[", "b_range", ",", "t", ",", "v", ",", "insertion_id", "]", "=", "0", "\n", "\n", "# What would be the insertion score look like if there", "\n", "# were anything to insert", "\n", "insertion_score_candidate", "=", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "insertion_id", "]", "+", "\n", "beta", "[", ":", ",", "t", ",", "v", "+", "1", "]", ")", "\n", "\n", "# This keeps MINF before we get inside the words", "\n", "to_sum", ".", "append", "(", "torch", ".", "where", "(", "\n", "is_valid", ",", "\n", "insertion_score_candidate", ",", "\n", "torch", ".", "full_like", "(", "insertion_score_candidate", ",", "minf", ")", ")", ")", "\n", "", "else", ":", "\n", "# This is here, so that TorchScript compiler does not complain.", "\n", "                ", "insertion_score_candidate", "=", "torch", ".", "zeros", "(", "[", "batch_size", "]", ")", "\n", "", "if", "t", "<", "src_len", "-", "1", ":", "\n", "                ", "deletion_id", "=", "all_deletion_ids", "[", ":", ",", "t", "]", "\n", "plausible_deletions", "[", "b_range", ",", "t", ",", "v", ",", "deletion_id", "]", "=", "0", "\n", "\n", "deletion_score_candidate", "=", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "deletion_id", "]", "+", "\n", "beta", "[", ":", ",", "t", "+", "1", ",", "v", "]", ")", "\n", "\n", "to_sum", ".", "append", "(", "torch", ".", "where", "(", "\n", "is_valid", ",", "\n", "deletion_score_candidate", ",", "\n", "torch", ".", "full_like", "(", "deletion_score_candidate", ",", "minf", ")", ")", ")", "\n", "", "if", "v", "<", "tgt_len", "-", "1", "and", "t", "<", "src_len", "-", "1", ":", "\n", "                ", "subsitute_id", "=", "all_subs_ids", "[", ":", ",", "t", ",", "v", "]", "\n", "plausible_substitutions", "[", "\n", "b_range", ",", "t", ",", "v", ",", "subsitute_id", "]", "=", "0", "\n", "\n", "substitution_score_candidate", "=", "(", "\n", "action_scores", "[", "b_range", ",", "t", ",", "v", ",", "subsitute_id", "]", "+", "\n", "beta", "[", ":", ",", "t", "+", "1", ",", "v", "+", "1", "]", ")", "\n", "\n", "to_sum", ".", "append", "(", "torch", ".", "where", "(", "\n", "is_valid", ",", "\n", "substitution_score_candidate", ",", "\n", "torch", ".", "full_like", "(", "insertion_score_candidate", ",", "minf", ")", ")", ")", "\n", "\n", "", "beta_candidate", "=", "torch", ".", "stack", "(", "to_sum", ")", ".", "logsumexp", "(", "0", ")", "\n", "\n", "beta", "[", ":", ",", "t", ",", "v", "]", "=", "torch", ".", "where", "(", "\n", "is_corner", ",", "torch", ".", "zeros_like", "(", "beta_candidate", ")", ",", "\n", "torch", ".", "where", "(", "is_valid", ",", "beta_candidate", ",", "\n", "torch", ".", "full_like", "(", "beta_candidate", ",", "minf", ")", ")", ")", "\n", "\n", "# deletion expectation", "\n", "", "", "expected_deletions", "=", "torch", ".", "zeros_like", "(", "action_scores", ")", "+", "minf", "\n", "expected_deletions", "[", ":", ",", "1", ":", ",", ":", "]", "=", "(", "\n", "alpha", "[", ":", ",", ":", "-", "1", ",", ":", "]", ".", "unsqueeze", "(", "3", ")", "+", "\n", "action_scores", "[", ":", ",", "1", ":", ",", ":", "]", "+", "plausible_deletions", "[", ":", ",", "1", ":", ",", ":", "]", "+", "\n", "beta", "[", ":", ",", "1", ":", ",", ":", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "# insertions expectation", "\n", "expected_insertions", "=", "torch", ".", "zeros_like", "(", "action_scores", ")", "+", "minf", "\n", "expected_insertions", "[", ":", ",", ":", ",", "1", ":", "]", "=", "(", "\n", "alpha", "[", ":", ",", ":", ",", ":", "-", "1", "]", ".", "unsqueeze", "(", "3", ")", "+", "\n", "action_scores", "[", ":", ",", ":", ",", "1", ":", "]", "+", "plausible_insertions", "[", ":", ",", ":", ",", "1", ":", "]", "+", "\n", "beta", "[", ":", ",", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "# substitution expectation", "\n", "expected_substitutions", "=", "torch", ".", "zeros_like", "(", "action_scores", ")", "+", "minf", "\n", "expected_substitutions", "[", ":", ",", "1", ":", ",", "1", ":", "]", "=", "(", "\n", "alpha", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "unsqueeze", "(", "3", ")", "+", "\n", "action_scores", "[", ":", ",", "1", ":", ",", "1", ":", "]", "+", "plausible_substitutions", "[", ":", ",", "1", ":", ",", "1", ":", "]", "+", "\n", "beta", "[", ":", ",", "1", ":", ",", "1", ":", "]", ".", "unsqueeze", "(", "3", ")", ")", "\n", "\n", "expected_counts", "=", "torch", ".", "stack", "(", "[", "\n", "expected_deletions", ",", "expected_insertions", ",", "\n", "expected_substitutions", "]", ",", "dim", "=", "4", ")", ".", "logsumexp", "(", "4", ")", "\n", "expected_counts", "-=", "expected_counts", ".", "logsumexp", "(", "3", ",", "keepdim", "=", "True", ")", "\n", "return", "beta", ",", "expected_counts", "\n", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.visualize_alpha.load_vocab": [[23, 32], ["fh.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "fh", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "fh", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "fh", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.visualize_alpha.draw": [[34, 48], ["matplotlib.subplots", "ax.matshow", "ax.tick_params", "ax.tick_params", "ax.set_xlim", "ax.set_ylim", "ax.set_xticks", "ax.set_yticks", "ax.set_xticklabels", "ax.set_yticklabels", "matplotlib.savefig", "numpy.exp", "numpy.arange", "numpy.arange", "len", "len", "len", "len"], "function", ["None"], ["", "def", "draw", "(", "matrix", ",", "src", ",", "tgt", ",", "fig_file", ")", ":", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "matshow", "(", "np", ".", "exp", "(", "matrix", ")", ",", "cmap", "=", "'cividis'", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'major'", ",", "labelsize", "=", "16", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'minor'", ",", "labelsize", "=", "16", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "-", "0.5", ",", "len", "(", "tgt", ")", "-", "0.5", ")", "\n", "ax", ".", "set_ylim", "(", "len", "(", "src", ")", "-", "0.5", ",", "-", "0.5", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "len", "(", "tgt", ")", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "len", "(", "src", ")", ")", ")", "\n", "ax", ".", "set_xticklabels", "(", "tgt", ")", "\n", "ax", ".", "set_yticklabels", "(", "src", ")", "\n", "plt", ".", "savefig", "(", "f\"{fig_file}.pdf\"", ",", "bbox_inches", "=", "'tight'", ",", "\n", "pad_inches", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.visualize_alpha.main": [[50, 92], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "visualize_alpha.load_vocab", "visualize_alpha.load_vocab", "logging.info", "enumerate", "logging.info", "line.strip().split", "logging.info", "visualize_alpha.draw", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "torch.load.alpha", "alpha.cpu().numpy", "line.strip", "torch.tensor().cuda", "torch.tensor().cuda", "string_1.split", "list", "string_2.split", "list", "alpha.cpu", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.visualize_alpha.draw", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.alpha"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"prefix\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Prefix of the path of the generated files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "_", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "_", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "input", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Inference for example %d\"", ",", "i", "+", "1", ")", "\n", "string_1", ",", "string_2", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "string_1_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_1", ".", "split", "(", ")", "if", "args", ".", "src_tokenized", "else", "list", "(", "string_1", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "string_2_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_2", ".", "split", "(", ")", "if", "args", ".", "tgt_tokenized", "else", "list", "(", "string_2", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "\n", "string_1_idx", "=", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "string_1_tok", "]", "\n", "string_2_idx", "=", "[", "tgt_stoi", "[", "s", "]", "for", "s", "in", "string_2_tok", "]", "\n", "\n", "alpha", "=", "model", ".", "alpha", "(", "\n", "torch", ".", "tensor", "(", "[", "string_1_idx", "]", ")", ".", "cuda", "(", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "string_2_idx", "]", ")", ".", "cuda", "(", ")", ")", "[", "0", "]", "\n", "\n", "logging", ".", "info", "(", "\"Generating image.\"", ")", "\n", "draw", "(", "\n", "alpha", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "string_1_tok", ",", "string_2_tok", ",", "\n", "f\"{args.prefix}{i}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.load_vocab": [[32, 39], ["fh.close", "collections.defaultdict", "enumerate", "line.strip"], "function", ["None"], ["def", "load_vocab", "(", "fh", ")", ":", "\n", "    ", "vocab_itos", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "fh", "]", "\n", "fh", ".", "close", "(", ")", "\n", "vocab_stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "sym", "in", "enumerate", "(", "vocab_itos", ")", ":", "\n", "        ", "vocab_stoi", "[", "sym", "]", "=", "i", "\n", "", "return", "vocab_itos", ",", "vocab_stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.word_to_tensor": [[41, 43], ["torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "word_to_tensor", "(", "word", ",", "vocab_stoi", ")", ":", "\n", "    ", "return", "torch", ".", "tensor", "(", "[", "[", "vocab_stoi", "[", "tok", "]", "for", "tok", "in", "f\"<s> {word} </s>\"", ".", "split", "(", ")", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.get_grouping": [[45, 62], ["infomap.Infomap", "enumerate", "all_scores.items", "infomap.Infomap.run", "infomap.Infomap.add_node", "infomap.Infomap.add_link", "set"], "function", ["None"], ["", "def", "get_grouping", "(", "all_scores", ",", "words", ",", "threshold", ")", ":", "\n", "    ", "im", "=", "infomap", ".", "Infomap", "(", "\"--two-level\"", ")", "\n", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "words", ")", ":", "\n", "        ", "im", ".", "add_node", "(", "i", ")", "\n", "\n", "", "for", "(", "i", ",", "j", ")", ",", "score", "in", "all_scores", ".", "items", "(", ")", ":", "\n", "        ", "if", "score", ">", "threshold", ":", "\n", "            ", "im", ".", "add_link", "(", "i", ",", "j", ",", "score", ")", "\n", "", "", "im", ".", "run", "(", ")", "\n", "learned_grouping", "=", "{", "}", "\n", "for", "node", "in", "im", ".", "tree", ":", "\n", "        ", "if", "node", ".", "is_leaf", ":", "\n", "            ", "word", "=", "words", "[", "node", ".", "node_id", "]", "[", "0", "]", "\n", "learned_grouping", "[", "word", "]", "=", "set", "(", "[", "f\"cluster_{node.module_id}\"", "]", ")", "\n", "\n", "", "", "return", "learned_grouping", ",", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.main": [[64, 165], ["torch.no_grad", "torch.no_grad", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluate_cognates.load_vocab", "evaluate_cognates.load_vocab", "logging.info", "torch.set_num_threads", "torch.set_num_threads", "torch.load", "torch.load", "logging.info", "csv.DictReader", "parser.parse_args.test_data.close", "logging.info", "progress.bar.Bar", "enumerate", "evaluate_cognates.main.score_batch"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"test_data\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch\"", ",", "type", "=", "int", ",", "default", "=", "30000", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "src_vocab_itos", ",", "src_vocab_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab_itos", ",", "tgt_vocab_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Loaded vocabulary.\"", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "20", ")", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Loaded model.\"", ")", "\n", "\n", "words", "=", "[", "]", "\n", "reader", "=", "csv", ".", "DictReader", "(", "args", ".", "test_data", ",", "dialect", "=", "'excel-tab'", ")", "\n", "for", "item", "in", "reader", ":", "\n", "        ", "words", ".", "append", "(", "(", "item", "[", "'TOKENS'", "]", ",", "set", "(", "[", "item", "[", "\"COGNATE_CLASS\"", "]", "]", ")", ")", ")", "\n", "", "args", ".", "test_data", ".", "close", "(", ")", "\n", "words", "=", "words", "[", ":", "2000", "]", "\n", "logging", ".", "info", "(", "\"Loaded test data, computing scores.\"", ")", "\n", "\n", "bar", "=", "Bar", "(", "\n", "'Scoring'", ",", "max", "=", "(", "len", "(", "words", ")", "**", "2", "-", "len", "(", "words", ")", ")", "/", "2", "/", "args", ".", "batch", ",", "\n", "suffix", "=", "'%(index)d/%(max)d %(percent).1f%% - %(eta)ds'", ")", "\n", "batch", "=", "[", "]", "\n", "all_scores", "=", "{", "}", "\n", "\n", "def", "score_batch", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "EditDistStatModel", ")", ":", "\n", "            ", "def", "run_batch", "(", "batch", ")", ":", "\n", "                ", "out_scores", "=", "[", "]", "\n", "for", "_", ",", "_", ",", "w1", ",", "w2", "in", "batch", ":", "\n", "                    ", "out_scores", ".", "append", "(", "model", ".", "viterbi", "(", "w1", ",", "w2", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "return", "out_scores", "\n", "\n", "", "ps", "=", "len", "(", "batch", ")", "//", "2", "\n", "batched_data", "=", "[", "batch", "[", "i", "*", "ps", ":", "(", "i", "+", "1", ")", "*", "ps", "]", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "batch_scores", "=", "parmap", "(", "run_batch", ",", "batched_data", ",", "2", ")", "\n", "scores", "=", "[", "]", "\n", "for", "b", "in", "batch_scores", ":", "\n", "                ", "for", "s", "in", "b", ":", "\n", "                    ", "scores", ".", "append", "(", "s", ")", "\n", "", "", "", "elif", "isinstance", "(", "model", ",", "BertForSequenceClassification", ")", ":", "\n", "            ", "padded", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "\n", "[", "torch", ".", "cat", "(", "(", "x", "[", "2", "]", "[", "0", "]", ",", "x", "[", "3", "]", "[", "0", "]", ")", ",", "dim", "=", "0", ")", "for", "x", "in", "batch", "]", ",", "batch_first", "=", "True", ")", "\n", "scores", "=", "F", ".", "softmax", "(", "model", "(", "padded", ".", "cuda", "(", ")", ")", "[", "0", "]", ",", "dim", "=", "1", ")", "[", ":", ",", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "src_padded", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "\n", "[", "x", "[", "2", "]", "[", "0", "]", "for", "x", "in", "batch", "]", ",", "batch_first", "=", "True", ")", "\n", "tgt_padded", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "\n", "[", "x", "[", "3", "]", "[", "0", "]", "for", "x", "in", "batch", "]", ",", "batch_first", "=", "True", ")", "\n", "raise", "NotImplemented", "(", ")", "\n", "\n", "", "for", "(", "ii", ",", "jj", ",", "_", ",", "_", ")", ",", "score", "in", "zip", "(", "batch", ",", "scores", ")", ":", "\n", "            ", "all_scores", "[", "(", "ii", ",", "jj", ")", "]", "=", "score", "\n", "\n", "", "", "for", "i", ",", "(", "word_i", ",", "_", ")", "in", "enumerate", "(", "words", ")", ":", "\n", "        ", "for", "j", ",", "(", "word_j", ",", "_", ")", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "if", "i", ">=", "j", ":", "\n", "                ", "continue", "\n", "", "word_i_tensor", "=", "word_to_tensor", "(", "word_i", ",", "src_vocab_stoi", ")", "\n", "word_j_tensor", "=", "word_to_tensor", "(", "word_j", ",", "tgt_vocab_stoi", ")", "\n", "batch", ".", "append", "(", "(", "i", ",", "j", ",", "word_i_tensor", ",", "word_j_tensor", ")", ")", "\n", "\n", "if", "len", "(", "batch", ")", ">=", "args", ".", "batch", ":", "\n", "                ", "score_batch", "(", ")", "\n", "batch", "=", "[", "]", "\n", "\n", "bar", ".", "next", "(", ")", "\n", "", "", "", "score_batch", "(", ")", "\n", "bar", ".", "next", "(", ")", "\n", "bar", ".", "finish", "(", ")", "\n", "\n", "ground_truh_grouping", "=", "dict", "(", "words", ")", "\n", "learned_groupings", "=", "[", "]", "\n", "ims", "=", "[", "]", "\n", "\n", "thresholds", "=", "[", ".1", ",", ".2", ",", ".3", ",", ".4", ",", ".5", ",", ".6", ",", ".7", ",", ".8", ",", ".9", "]", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Threshold {threshold}\"", ")", "\n", "logging", ".", "info", "(", "\"Running InfoMap.\"", ")", "\n", "grouping", ",", "im", "=", "get_grouping", "(", "all_scores", ",", "words", ",", "threshold", ")", "\n", "learned_groupings", ".", "append", "(", "grouping", ")", "\n", "ims", ".", "append", "(", "im", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Evaluating.\"", ")", "\n", "for", "thres", ",", "learned_grouping", "in", "zip", "(", "thresholds", ",", "learned_groupings", ")", ":", "\n", "        ", "precision", "=", "bcubed", ".", "precision", "(", "ground_truh_grouping", ",", "learned_grouping", ")", "\n", "recall", "=", "bcubed", ".", "recall", "(", "ground_truh_grouping", ",", "learned_grouping", ")", "\n", "fscore", "=", "bcubed", ".", "fscore", "(", "precision", ",", "recall", ")", "\n", "\n", "logging", ".", "info", "(", "f\"Threshold {thres}\"", ")", "\n", "logging", ".", "info", "(", "f\"Precision:  {100 * precision:.3f}\"", ")", "\n", "logging", ".", "info", "(", "f\"Recall:     {100 * recall:.3f}\"", ")", "\n", "logging", ".", "info", "(", "f\"F-Score:    {100 * fscore:.3f}\"", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.fun": [[170, 176], ["q_in.get", "q_out.put", "f"], "function", ["None"], ["", "", "def", "fun", "(", "f", ",", "q_in", ",", "q_out", ",", "total_size", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "i", ",", "x", "=", "q_in", ".", "get", "(", ")", "\n", "if", "i", "is", "None", ":", "\n", "            ", "break", "\n", "", "q_out", ".", "put", "(", "(", "i", ",", "f", "(", "x", ")", ")", ")", "\n", "#print(f\"Progress: {q_out.qsize()} / {total_size} \"", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.evaluate_cognates.parmap": [[181, 200], ["multiprocessing.Queue", "multiprocessing.Queue", "multiprocessing.Process", "p.start", "multiprocessing.Queue.put", "multiprocessing.Queue.put", "multiprocessing.Queue.get", "p.join", "range", "enumerate", "range", "range", "len", "sorted", "len"], "function", ["None"], ["", "", "def", "parmap", "(", "f", ",", "X", ",", "nprocs", ",", "keep_order", "=", "True", ")", ":", "\n", "    ", "q_in", "=", "multiprocessing", ".", "Queue", "(", "1", ")", "\n", "q_out", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "\n", "proc", "=", "[", "multiprocessing", ".", "Process", "(", "target", "=", "fun", ",", "args", "=", "(", "f", ",", "q_in", ",", "q_out", ",", "len", "(", "X", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "nprocs", ")", "]", "\n", "for", "p", "in", "proc", ":", "\n", "        ", "p", ".", "daemon", "=", "True", "\n", "p", ".", "start", "(", ")", "\n", "\n", "", "sent", "=", "[", "q_in", ".", "put", "(", "(", "i", ",", "x", ")", ")", "for", "i", ",", "x", "in", "enumerate", "(", "X", ")", "]", "\n", "[", "q_in", ".", "put", "(", "(", "None", ",", "None", ")", ")", "for", "_", "in", "range", "(", "nprocs", ")", "]", "\n", "res", "=", "[", "q_out", ".", "get", "(", ")", "for", "_", "in", "range", "(", "len", "(", "sent", ")", ")", "]", "\n", "\n", "[", "p", ".", "join", "(", ")", "for", "p", "in", "proc", "]", "\n", "\n", "if", "keep_order", ":", "\n", "        ", "return", "[", "x", "for", "i", ",", "x", "in", "sorted", "(", "res", ")", "]", "\n", "", "return", "[", "x", "for", "i", ",", "x", "in", "res", "]", "\n", "# END OF STACKOVERFLOW COPY-PASTE", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.test_transliteration_generation.load_vocab": [[20, 29], ["file.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "file", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "file", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.test_transliteration_generation.main": [[31, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "hasattr", "logging.info", "test_transliteration_generation.load_vocab", "test_transliteration_generation.load_vocab", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "isinstance", "line.strip().split", "tgt_references.append", "torch.load.beam_search", "isinstance", "transliteration_utils.decode_ids", "tgt_hypotheses.append", "parser.parse_args.output.close", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "isinstance", "hasattr", "torch.tensor().cuda", "print", "sum", "len", "line.strip", "string_1.split", "list", "torch.tensor", "float", "zip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam-size\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Beam size for test data decoding.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--len-norm\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"Length normalization factor.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"w\"", ")", ",", "default", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "\n", "if", "hasattr", "(", "model", ",", "'ar_pad'", ")", ":", "\n", "        ", "model", ".", "src_pad", "=", "model", ".", "ar_pad", "\n", "model", ".", "tgt_pad", "=", "model", ".", "en_pad", "\n", "model", ".", "tgt_bos", "=", "model", ".", "en_bos", "\n", "model", ".", "tgt_eos", "=", "model", ".", "en_eos", "\n", "model", ".", "src_encoder", "=", "model", ".", "ar_encoder", "\n", "model", ".", "tgt_encoder", "=", "model", ".", "en_encoder", "\n", "model", ".", "tgt_symbol_count", "=", "model", ".", "en_symbol_count", "\n", "\n", "", "if", "(", "not", "isinstance", "(", "model", ",", "Seq2SeqModel", ")", "and", "\n", "isinstance", "(", "model", ".", "src_encoder", ",", "CNNEncoder", ")", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "model", ".", "src_encoder", ",", "\"layers\"", ")", ":", "\n", "            ", "pass", "\n", "# model.encoder.", "\n", "\n", "", "", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "_", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "_", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "tgt_references", "=", "[", "]", "\n", "tgt_hypotheses", "=", "[", "]", "\n", "for", "line", "in", "args", ".", "input", ":", "\n", "        ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "string_1", ",", "string_2", "=", "line_split", "[", "0", "]", ",", "line_split", "[", "1", "]", "\n", "tgt_references", ".", "append", "(", "string_2", ")", "\n", "\n", "string_1_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_1", ".", "split", "(", ")", "if", "args", ".", "src_tokenized", "else", "list", "(", "string_1", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "\n", "string_1_idx", "=", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "string_1_tok", "]", "\n", "\n", "decoded", "=", "model", ".", "beam_search", "(", "\n", "# pylint: disable=not-callable", "\n", "torch", ".", "tensor", "(", "[", "string_1_idx", "]", ")", ".", "cuda", "(", ")", ",", "\n", "# pylint: enable=not-callable", "\n", "beam_size", "=", "args", ".", "beam_size", ",", "\n", "len_norm", "=", "args", ".", "len_norm", ")", "\n", "\n", "if", "isinstance", "(", "decoded", ",", "tuple", ")", ":", "\n", "            ", "decoded", "=", "decoded", "[", "0", "]", "\n", "\n", "", "tgt_string", "=", "decode_ids", "(", "decoded", "[", "0", "]", ",", "tgt_vocab", ",", "args", ".", "tgt_tokenized", ")", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "            ", "print", "(", "tgt_string", ",", "file", "=", "args", ".", "output", ")", "\n", "", "tgt_hypotheses", ".", "append", "(", "tgt_string", ")", "\n", "\n", "", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "args", ".", "output", ".", "close", "(", ")", "\n", "\n", "", "wer", "=", "1", "-", "sum", "(", "\n", "float", "(", "gt", "==", "hyp", ")", "for", "gt", ",", "hyp", "\n", "in", "zip", "(", "tgt_references", ",", "tgt_hypotheses", ")", ")", "/", "len", "(", "tgt_hypotheses", ")", "\n", "cer", "=", "char_error_rate", "(", "\n", "tgt_hypotheses", ",", "tgt_references", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "logging", ".", "info", "(", "\"WER: %.10g\"", ",", "wer", ")", "\n", "logging", ".", "info", "(", "\"CER: %.10g\"", ",", "cer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.__init__": [[29, 48], ["torch.nn.Module.__init__", "isinstance", "isinstance", "decoder.embeddings.weight.t", "decoder.embeddings.word_embeddings.weight.t"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "encoder", ",", "decoder", ",", "src_pad_token_id", ",", "tgt_bos_token_id", ",", "\n", "tgt_eos_token_id", ",", "tgt_pad_token_id", ",", "device", ")", ":", "\n", "        ", "super", "(", "Seq2SeqModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n", "if", "isinstance", "(", "decoder", ",", "RNNDecoder", ")", "or", "isinstance", "(", "decoder", ",", "CNNDecoder", ")", ":", "\n", "            ", "self", ".", "transposed_embeddings", "=", "decoder", ".", "embeddings", ".", "weight", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "transposed_embeddings", "=", "decoder", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "t", "(", ")", "\n", "\n", "", "self", ".", "tgt_bos_token_id", "=", "tgt_bos_token_id", "\n", "self", ".", "tgt_eos_token_id", "=", "tgt_eos_token_id", "\n", "self", ".", "tgt_pad_token_id", "=", "tgt_pad_token_id", "\n", "self", ".", "src_pad_token_id", "=", "src_pad_token_id", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.forward": [[49, 69], ["train_transliteration_s2s.Seq2SeqModel.decoder", "torch.matmul", "train_transliteration_s2s.Seq2SeqModel.encoder", "sum", "len", "att[].mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_batch", ",", "tgt_batch", ")", ":", "\n", "        ", "encoder_mask", "=", "src_batch", "!=", "self", ".", "src_pad_token_id", "\n", "encoder_states", "=", "self", ".", "encoder", "(", "\n", "src_batch", ",", "\n", "attention_mask", "=", "encoder_mask", ")", "[", "0", "]", "\n", "decoder_output", "=", "self", ".", "decoder", "(", "\n", "tgt_batch", "[", ":", ",", ":", "-", "1", "]", ",", "\n", "attention_mask", "=", "tgt_batch", "[", ":", ",", ":", "-", "1", "]", "!=", "self", ".", "tgt_pad_token_id", ",", "\n", "encoder_hidden_states", "=", "encoder_states", ",", "\n", "encoder_attention_mask", "=", "encoder_mask", ")", "#[0]", "\n", "decoder_states", "=", "decoder_output", "[", "0", "]", "\n", "logits", "=", "torch", ".", "matmul", "(", "\n", "decoder_states", ",", "\n", "self", ".", "transposed_embeddings", ")", "\n", "\n", "attentions", "=", "sum", "(", "\n", "att", "[", "1", "]", ".", "mean", "(", "1", ")", "for", "att", "in", "decoder_output", "[", "2", "]", ")", "/", "len", "(", "\n", "decoder_output", "[", "2", "]", ")", "\n", "\n", "return", "logits", ",", "attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.greedy_decode": [[70, 102], ["torch.no_grad", "encoded.size", "range", "train_transliteration_s2s.Seq2SeqModel.encoder", "torch.tensor().to", "torch.tensor().to", "torch.stack", "torch.matmul", "logits[].argmax", "decoded.append", "finished.append", "all", "torch.stack", "torch.stack().logical_not", "train_transliteration_s2s.Seq2SeqModel.decoder", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "range", "range"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "greedy_decode", "(", "self", ",", "src_batch", ",", "max_len", "=", "100", ")", ":", "\n", "        ", "input_mask", "=", "src_batch", "!=", "self", ".", "src_pad_token_id", "\n", "encoded", "=", "self", ".", "encoder", "(", "src_batch", ",", "attention_mask", "=", "input_mask", ")", "[", "0", "]", "\n", "batch_size", "=", "encoded", ".", "size", "(", "0", ")", "\n", "\n", "finished", "=", "[", "\n", "torch", ".", "tensor", "(", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", ")", ".", "to", "(", "self", ".", "device", ")", "]", "\n", "decoded", "=", "[", "torch", ".", "tensor", "(", "[", "\n", "self", ".", "tgt_bos_token_id", "for", "_", "in", "range", "(", "batch_size", ")", "]", ")", ".", "to", "(", "self", ".", "device", ")", "]", "\n", "\n", "for", "_", "in", "range", "(", "max_len", ")", ":", "\n", "            ", "decoder_input", "=", "torch", ".", "stack", "(", "decoded", ",", "dim", "=", "1", ")", "\n", "decoder_states", "=", "self", ".", "decoder", "(", "\n", "decoder_input", ",", "\n", "attention_mask", "=", "~", "torch", ".", "stack", "(", "finished", ",", "dim", "=", "1", ")", ",", "\n", "encoder_hidden_states", "=", "encoded", ",", "\n", "encoder_attention_mask", "=", "input_mask", ")", "[", "0", "]", "\n", "logits", "=", "torch", ".", "matmul", "(", "\n", "decoder_states", ",", "\n", "self", ".", "transposed_embeddings", ")", "\n", "next_symbol", "=", "logits", "[", ":", ",", "-", "1", "]", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "decoded", ".", "append", "(", "next_symbol", ")", "\n", "\n", "finished_now", "=", "next_symbol", "==", "self", ".", "tgt_eos_token_id", "+", "finished", "[", "-", "1", "]", "\n", "finished", ".", "append", "(", "finished_now", ")", "\n", "\n", "if", "all", "(", "finished_now", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "(", "torch", ".", "stack", "(", "decoded", ",", "dim", "=", "1", ")", ",", "\n", "torch", ".", "stack", "(", "finished", ",", "dim", "=", "1", ")", ".", "logical_not", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search": [[103, 190], ["torch.no_grad", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.size", "torch.full().to", "torch.full().to", "torch.zeros().to", "train_transliteration_s2s.Seq2SeqModel.encoder", "torch.cat.reshape", "torch.cat.reshape", "torch.functional.F.log_softmax", "torch.functional.F.log_softmax.size", "torch.pow", "normed_scores.reshape().topk", "torch.arange", "torch.cat", "torch.cat.reshape.index_select().reshape", "torch.cat", "finished_now.all", "candidate_scores.reshape().gather", "finished[].logical_not", "torch.full", "torch.full", "torch.zeros", "train_transliteration_s2s.Seq2SeqModel.decoder", "torch.matmul", "candidate_scores.reshape().gather.unsqueeze", "torch.functional.F.log_softmax.reshape", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "input_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "normed_scores.reshape", "torch.cat.reshape.index_select().reshape", "next_symbol_ids.unsqueeze", "torch.cat.reshape.index_select", "finished_now.unsqueeze", "candidate_scores.reshape", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.size", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.size", "torch.arange.unsqueeze", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "input_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "torch.cat.reshape.index_select", "torch.cat.float", "encoded.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze", "input_mask.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "beam_search", "(", "self", ",", "src_batch", ",", "beam_size", "=", "10", ",", "max_len", "=", "100", ",", "len_norm", "=", "1.0", ")", ":", "\n", "        ", "input_mask", "=", "src_batch", "!=", "self", ".", "src_pad_token_id", "\n", "encoded", "=", "self", ".", "encoder", "(", "src_batch", ",", "attention_mask", "=", "input_mask", ")", "[", "0", "]", "\n", "batch_size", "=", "encoded", ".", "size", "(", "0", ")", "\n", "\n", "cur_len", "=", "1", "\n", "current_beam", "=", "1", "\n", "\n", "decoded", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ",", "1", ")", ",", "self", ".", "tgt_bos_token_id", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "finished", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ",", "1", ")", ",", "False", ",", "dtype", "=", "torch", ".", "bool", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "while", "cur_len", "<", "max_len", ":", "\n", "            ", "flat_decoded", "=", "decoded", ".", "reshape", "(", "-", "1", ",", "cur_len", ")", "\n", "flat_finished", "=", "finished", ".", "reshape", "(", "-", "1", ",", "cur_len", ")", "\n", "\n", "outputs", "=", "self", ".", "decoder", "(", "\n", "input_ids", "=", "flat_decoded", ",", "\n", "attention_mask", "=", "~", "flat_finished", ",", "\n", "encoder_hidden_states", "=", "encoded", ",", "\n", "encoder_attention_mask", "=", "input_mask", ")", "[", "0", "]", "\n", "next_token_logprobs", "=", "F", ".", "log_softmax", "(", "torch", ".", "matmul", "(", "\n", "outputs", "[", ":", ",", "-", "1", ",", ":", "]", ",", "\n", "self", ".", "transposed_embeddings", ")", ",", "dim", "=", "1", ")", "\n", "vocab_size", "=", "next_token_logprobs", ".", "size", "(", "1", ")", "\n", "\n", "# get scores of all expanded hypotheses", "\n", "candidate_scores", "=", "(", "\n", "scores", ".", "unsqueeze", "(", "2", ")", "+", "\n", "next_token_logprobs", ".", "reshape", "(", "batch_size", ",", "current_beam", ",", "-", "1", ")", ")", "\n", "norm_factor", "=", "torch", ".", "pow", "(", "\n", "(", "1", "-", "finished", ".", "float", "(", ")", ")", ".", "sum", "(", "2", ",", "keepdim", "=", "True", ")", "+", "1", ",", "len_norm", ")", "\n", "normed_scores", "=", "candidate_scores", "/", "norm_factor", "\n", "\n", "# reshape for beam members and get top k", "\n", "_", ",", "best_indices", "=", "normed_scores", ".", "reshape", "(", "\n", "batch_size", ",", "-", "1", ")", ".", "topk", "(", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "next_symbol_ids", "=", "best_indices", "%", "vocab_size", "\n", "hypothesis_ids", "=", "best_indices", "//", "vocab_size", "\n", "\n", "# numbering elements in the extended batch, i.e. beam size copies", "\n", "# of each batch element", "\n", "beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "batch_size", "*", "current_beam", ",", "step", "=", "current_beam", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "global_best_indices", "=", "(", "\n", "beam_offset", ".", "unsqueeze", "(", "1", ")", "+", "hypothesis_ids", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# now select appropriate histories", "\n", "decoded", "=", "torch", ".", "cat", "(", "(", "\n", "flat_decoded", ".", "index_select", "(", "\n", "0", ",", "global_best_indices", ")", ".", "reshape", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", ",", "\n", "next_symbol_ids", ".", "unsqueeze", "(", "-", "1", ")", ")", ",", "dim", "=", "2", ")", "\n", "reordered_finished", "=", "flat_finished", ".", "index_select", "(", "\n", "0", ",", "global_best_indices", ")", ".", "reshape", "(", "batch_size", ",", "beam_size", ",", "-", "1", ")", "\n", "finished_now", "=", "(", "\n", "(", "next_symbol_ids", "==", "self", ".", "tgt_eos_token_id", ")", "+", "\n", "reordered_finished", "[", ":", ",", ":", ",", "-", "1", "]", ")", "\n", "finished", "=", "torch", ".", "cat", "(", "(", "\n", "reordered_finished", ",", "\n", "finished_now", ".", "unsqueeze", "(", "-", "1", ")", ")", ",", "dim", "=", "2", ")", "\n", "if", "finished_now", ".", "all", "(", ")", ":", "\n", "                ", "break", "\n", "\n", "# re-order scores", "\n", "", "scores", "=", "candidate_scores", ".", "reshape", "(", "\n", "batch_size", ",", "-", "1", ")", ".", "gather", "(", "-", "1", ",", "best_indices", ")", "\n", "\n", "# tile encoder after first step", "\n", "if", "cur_len", "==", "1", ":", "\n", "                ", "encoded", "=", "encoded", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "beam_size", ",", "1", ",", "1", ")", ".", "reshape", "(", "\n", "batch_size", "*", "beam_size", ",", "encoded", ".", "size", "(", "1", ")", ",", "\n", "encoded", ".", "size", "(", "2", ")", ")", "\n", "input_mask", "=", "input_mask", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "beam_size", ",", "1", ")", ".", "reshape", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "\n", "# in the first iteration, beam size is 1, in the later ones,", "\n", "# it is the real beam size", "\n", "", "current_beam", "=", "beam_size", "\n", "cur_len", "+=", "1", "\n", "\n", "", "return", "(", "decoded", "[", ":", ",", "0", "]", ",", "finished", "[", ":", ",", "0", "]", ".", "logical_not", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.main": [[192, 510], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "tensorboardX.SummaryWriter", "torch.device", "transliteration_utils.load_transliteration_data", "experiment.save_vocab", "experiment.save_vocab", "train_transliteration_s2s.Seq2SeqModel", "logging.info", "torch.nn.CrossEntropyLoss().to", "torch.optim.Adam", "open", "open", "logging.info", "time.time", "range", "logging.info", "logging.info", "logging.info", "torch.load", "torch.load.eval", "range", "logging.info", "enumerate", "logging.info", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "os.path.join", "os.path.join", "transformers.BertConfig", "transformers.BertModel().to", "len", "transformers.BertModel().to", "torch.load.parameters", "os.path.join", "os.path.join", "beam_exploration.append", "logging.info", "open", "print", "torch.cuda.is_available", "rnn.RNNEncoder().to", "rnn.RNNDecoder().to", "sum", "torch.nn.CrossEntropyLoss", "nn.CrossEntropyLoss().to.", "nll.backward", "torch.nn.utils.clip_grad_norm_", "optim.Adam.step", "optim.Adam.zero_grad", "print", "len", "enumerate", "transliteration_utils.char_error_rate", "beam_performance.append", "os.path.join", "torch.no_grad", "torch.load.beam_search", "ground_truth.extend", "all_hypotheses.extend", "sum", "len", "experiment.get_timestamp", "len", "transformers.BertModel", "transformers.BertModel", "cnn.CNNEncoder().to", "cnn.CNNDecoder().to", "RuntimeError", "torch.load.", "logits.reshape", "train_batch.en[].reshape", "logging.info", "torch.load.parameters", "tensorboardX.SummaryWriter.add_scalar", "torch.load.eval", "enumerate", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "print", "logging.info", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.flush", "torch.load.train", "range", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "rnn.RNNEncoder", "rnn.RNNDecoder", "x.reshape().size", "logging.info", "torch.save", "time.time", "torch.no_grad", "torch.load.beam_search", "ground_truth.extend", "all_hypotheses.extend", "float", "cnn.CNNEncoder", "cnn.CNNDecoder", "torch.load.parameters", "len", "torch.no_grad", "torch.load.greedy_decode", "ground_truth.extend", "all_hypotheses.extend", "sum", "len", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "test_batch.ar.size", "zip", "x.reshape", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "range", "parser.parse_args.data_prefix.replace", "logging.info", "logging.info", "float", "val_batch.ar.size", "val_batch.ar.size", "zip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.load_transliteration_data", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.greedy_decode", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-type\"", ",", "default", "=", "'transformer'", ",", "\n", "choices", "=", "[", "\"transformer\"", ",", "\"rnn\"", ",", "\"cnn\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden-size\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention-heads\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--window\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "\"CNN window width.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, source side are space separated tokens.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, target side are space separated tokens.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--patience\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of validations witout improvement before finishing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning-rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-frequency\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "f\"_{args.model_type}\"", "+", "\n", "f\"_hidden{args.hidden_size}\"", "+", "\n", "f\"_attheads{args.attention_heads}\"", "+", "\n", "f\"_layers{args.layers}\"", "+", "\n", "f\"_batch{args.batch_size}\"", "+", "\n", "f\"_lr{args.learning_rate}\"", "+", "\n", "f\"_patence{args.patience}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"s2s_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "tb_writer", "=", "SummaryWriter", "(", "experiment_dir", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "src_text_field", ",", "tgt_text_field", ",", "train_iter", ",", "val_iter", ",", "test_iter", "=", "load_transliteration_data", "(", "\n", "args", ".", "data_prefix", ",", "args", ".", "batch_size", ",", "device", ",", "\n", "src_tokenized", "=", "args", ".", "src_tokenized", ",", "\n", "tgt_tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "\n", "save_vocab", "(", "\n", "src_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "tgt_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "\n", "if", "args", ".", "model_type", "==", "\"transformer\"", ":", "\n", "        ", "transformer_config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "len", "(", "src_text_field", ".", "vocab", ")", ",", "\n", "is_decoder", "=", "False", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_hidden_layers", "=", "args", ".", "layers", ",", "\n", "num_attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "intermediate_size", "=", "2", "*", "args", ".", "hidden_size", ",", "\n", "hidden_act", "=", "'relu'", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "output_attentions", "=", "True", ")", "\n", "encoder", "=", "BertModel", "(", "transformer_config", ")", ".", "to", "(", "device", ")", "\n", "\n", "transformer_config", ".", "is_decoder", "=", "True", "\n", "transformer_config", ".", "vocab_size", "=", "len", "(", "tgt_text_field", ".", "vocab", ")", "\n", "decoder", "=", "BertModel", "(", "transformer_config", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"rnn\"", ":", "\n", "        ", "encoder", "=", "RNNEncoder", "(", "\n", "src_text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "args", ".", "hidden_size", ",", "\n", "args", ".", "layers", ",", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "decoder", "=", "RNNDecoder", "(", "\n", "tgt_text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "args", ".", "hidden_size", ",", "\n", "args", ".", "layers", ",", "attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "dropout", "=", "0.1", ",", "output_proj", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"cnn\"", ":", "\n", "        ", "encoder", "=", "CNNEncoder", "(", "\n", "src_text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "args", ".", "hidden_size", ",", "\n", "layers", "=", "args", ".", "layers", ",", "window", "=", "args", ".", "window", ",", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "decoder", "=", "CNNDecoder", "(", "\n", "tgt_text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "args", ".", "hidden_size", ",", "\n", "layers", "=", "args", ".", "layers", ",", "window", "=", "args", ".", "window", ",", "\n", "attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "dropout", "=", "0.1", ",", "use_attention", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Unknown model type.\"", ")", "\n", "\n", "", "model", "=", "Seq2SeqModel", "(", "\n", "encoder", ",", "decoder", ",", "\n", "src_pad_token_id", "=", "src_text_field", ".", "vocab", ".", "stoi", "[", "src_text_field", ".", "pad_token", "]", ",", "\n", "tgt_bos_token_id", "=", "tgt_text_field", ".", "vocab", ".", "stoi", "[", "tgt_text_field", ".", "init_token", "]", ",", "\n", "tgt_eos_token_id", "=", "tgt_text_field", ".", "vocab", ".", "stoi", "[", "tgt_text_field", ".", "eos_token", "]", ",", "\n", "tgt_pad_token_id", "=", "tgt_text_field", ".", "vocab", ".", "stoi", "[", "tgt_text_field", ".", "pad_token", "]", ",", "\n", "device", "=", "device", ")", "\n", "logging", ".", "info", "(", "\n", "\"Model parameters: %dk\"", ",", "\n", "sum", "(", "[", "x", ".", "reshape", "(", "-", "1", ")", ".", "size", "(", "0", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", "]", ")", "/", "1000", ")", "\n", "\n", "nll", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "\n", "train_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"train_loss.tsv\"", ")", ",", "\"w\"", ")", "\n", "valid_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"valid_cer.tsv\"", ")", ",", "\"w\"", ")", "\n", "\n", "step", "=", "0", "\n", "best_wer", "=", "1e9", "\n", "best_wer_step", "=", "0", "\n", "best_cer", "=", "1e9", "\n", "best_cer_step", "=", "0", "\n", "stalled", "=", "0", "\n", "last_save_time", "=", "0", "\n", "\n", "logging", ".", "info", "(", "\"Start training.\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "            ", "break", "\n", "", "for", "train_batch", "in", "train_iter", ":", "\n", "            ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "                ", "break", "\n", "", "step", "+=", "1", "\n", "\n", "logits", "=", "model", "(", "train_batch", ".", "ar", ",", "train_batch", ".", "en", ")", "[", "0", "]", "\n", "\n", "loss", "=", "nll", "(", "\n", "logits", ".", "reshape", "(", "[", "-", "1", ",", "len", "(", "tgt_text_field", ".", "vocab", ")", "]", ")", ",", "\n", "train_batch", ".", "en", "[", ":", ",", "1", ":", "]", ".", "reshape", "(", "[", "-", "1", "]", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "step", "%", "50", "==", "49", ":", "\n", "                ", "logging", ".", "info", "(", "\"step: %d, train loss = %.3g\"", ",", "step", ",", "loss", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "print", "(", "f\"{step:d}\\t{loss:.3g}\"", ",", "file", "=", "train_curve_file", ")", "\n", "\n", "if", "step", "%", "args", ".", "validation_frequency", "==", "args", ".", "validation_frequency", "-", "1", ":", "\n", "                ", "tb_writer", ".", "add_scalar", "(", "'train/nll'", ",", "loss", ",", "step", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "ground_truth", "=", "[", "]", "\n", "all_hypotheses", "=", "[", "]", "\n", "\n", "for", "j", ",", "val_batch", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "src_string", "=", "[", "\n", "decode_ids", "(", "\n", "val_ex", ",", "src_text_field", ",", "\n", "tokenized", "=", "args", ".", "src_tokenized", ")", "\n", "for", "val_ex", "in", "val_batch", ".", "ar", "]", "\n", "tgt_string", "=", "[", "\n", "decode_ids", "(", "\n", "val_ex", ",", "tgt_text_field", ",", "\n", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "val_ex", "in", "val_batch", ".", "en", "]", "\n", "\n", "decoded_val", "=", "model", ".", "greedy_decode", "(", "\n", "val_batch", ".", "ar", ",", "\n", "max_len", "=", "2", "*", "val_batch", ".", "ar", ".", "size", "(", "1", ")", ")", "\n", "\n", "hypotheses", "=", "[", "\n", "decode_ids", "(", "out", ",", "tgt_text_field", ",", "\n", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "out", "in", "decoded_val", "[", "0", "]", "]", "\n", "\n", "ground_truth", ".", "extend", "(", "tgt_string", ")", "\n", "all_hypotheses", ".", "extend", "(", "hypotheses", ")", "\n", "\n", "if", "j", "==", "0", ":", "\n", "                            ", "for", "k", "in", "range", "(", "10", ")", ":", "\n", "                                ", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"'%s' -> '%s' (%s)\"", ",", "\n", "src_string", "[", "k", "]", ",", "hypotheses", "[", "k", "]", ",", "\n", "tgt_string", "[", "k", "]", ")", "\n", "\n", "", "", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "wer", "=", "1", "-", "sum", "(", "\n", "float", "(", "gt", "==", "hyp", ")", "for", "gt", ",", "hyp", "\n", "in", "zip", "(", "ground_truth", ",", "all_hypotheses", ")", ")", "/", "len", "(", "ground_truth", ")", "\n", "cer", "=", "char_error_rate", "(", "\n", "all_hypotheses", ",", "ground_truth", ",", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "\n", "stalled", "+=", "1", "\n", "if", "wer", "<", "best_wer", ":", "\n", "                    ", "best_wer", "=", "wer", "\n", "best_wer_step", "=", "step", "\n", "stalled", "=", "0", "\n", "", "if", "cer", "<", "best_cer", ":", "\n", "                    ", "best_cer", "=", "cer", "\n", "best_cer_step", "=", "step", "\n", "stalled", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "\"WER: %.3g   (best %.3g, step %d)\"", ",", "\n", "wer", ",", "best_wer", ",", "best_wer_step", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3g   (best %.3g, step %d)\"", ",", "\n", "cer", ",", "best_cer", ",", "best_cer_step", ")", "\n", "if", "stalled", ">", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "\"Stalled %d times.\"", ",", "stalled", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "print", "(", "f\"{step:d}\\t{cer:.3g}\"", ",", "file", "=", "valid_curve_file", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "tb_writer", ".", "add_scalar", "(", "'val/cer'", ",", "cer", ",", "step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'val/wer'", ",", "wer", ",", "step", ")", "\n", "tb_writer", ".", "flush", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "\"TRAINING FINISHED.\"", ")", "\n", "logging", ".", "info", "(", "\n", "\"The training took %d seconds.\"", ",", "last_save_time", "-", "start_time", ")", "\n", "logging", ".", "info", "(", "\"Find best beam serch parameters.\"", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_eval_beam", "=", "1", "\n", "best_eval_len_norm", "=", "0.0", "\n", "best_eval_cer", "=", "10.", "\n", "\n", "beam_exploration", "=", "[", "]", "\n", "\n", "for", "beam", "in", "range", "(", "1", ",", "40", ")", ":", "\n", "        ", "if", "beam", ">=", "len", "(", "tgt_text_field", ".", "vocab", ")", ":", "\n", "            ", "break", "\n", "\n", "", "beam_performance", "=", "[", "]", "\n", "for", "len_norm", "in", "[", "0.2", "*", "x", "for", "x", "in", "range", "(", "9", ")", "]", ":", "\n", "            ", "ground_truth", "=", "[", "]", "\n", "hypotheses", "=", "[", "]", "\n", "for", "j", ",", "val_batch", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "src_string", "=", "[", "\n", "decode_ids", "(", "val_ex", ",", "src_text_field", ",", "\n", "tokenized", "=", "args", ".", "src_tokenized", ")", "\n", "for", "val_ex", "in", "val_batch", ".", "ar", "]", "\n", "tgt_string", "=", "[", "\n", "decode_ids", "(", "val_ex", ",", "tgt_text_field", ",", "\n", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "val_ex", "in", "val_batch", ".", "en", "]", "\n", "\n", "decoded_val", "=", "model", ".", "beam_search", "(", "\n", "val_batch", ".", "ar", ",", "\n", "beam_size", "=", "beam", ",", "\n", "len_norm", "=", "len_norm", ",", "\n", "max_len", "=", "2", "*", "val_batch", ".", "ar", ".", "size", "(", "1", ")", ")", "\n", "\n", "hypotheses", "=", "[", "\n", "decode_ids", "(", "out", ",", "tgt_text_field", ",", "\n", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "out", "in", "decoded_val", "[", "0", "]", "]", "\n", "\n", "ground_truth", ".", "extend", "(", "tgt_string", ")", "\n", "all_hypotheses", ".", "extend", "(", "hypotheses", ")", "\n", "\n", "", "", "cer", "=", "char_error_rate", "(", "\n", "all_hypotheses", ",", "ground_truth", ",", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "if", "cer", "<", "best_eval_cer", ":", "\n", "                ", "best_eval_beam", "=", "beam", "\n", "best_eval_len_norm", "=", "len_norm", "\n", "best_eval_cer", "=", "cer", "\n", "", "beam_performance", ".", "append", "(", "cer", ")", "\n", "\n", "", "beam_exploration", ".", "append", "(", "beam_performance", ")", "\n", "logging", ".", "info", "(", "\"Beam %d, so far best CER %f.\"", ",", "beam", ",", "best_cer", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "experiment_dir", ",", "\"beam_exploration.txt\"", ")", ",", "\"w\"", ")", "as", "f_beam", ":", "\n", "        ", "print", "(", "beam_exploration", ",", "file", "=", "f_beam", ")", "\n", "\n", "", "logging", ".", "info", "(", "\n", "\"Best beam size: %d, best len norm: %f\"", ",", "\n", "best_eval_beam", ",", "best_eval_len_norm", ")", "\n", "\n", "for", "j", ",", "test_batch", "in", "enumerate", "(", "test_iter", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "src_string", "=", "[", "\n", "decode_ids", "(", "test_ex", ",", "src_text_field", ",", "\n", "tokenized", "=", "args", ".", "src_tokenized", ")", "\n", "for", "test_ex", "in", "test_batch", ".", "ar", "]", "\n", "tgt_string", "=", "[", "\n", "decode_ids", "(", "test_ex", ",", "tgt_text_field", ",", "\n", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "test_ex", "in", "test_batch", ".", "en", "]", "\n", "\n", "decoded_val", "=", "model", ".", "beam_search", "(", "\n", "test_batch", ".", "ar", ",", "\n", "beam_size", "=", "best_eval_beam", ",", "\n", "len_norm", "=", "best_eval_len_norm", ",", "\n", "max_len", "=", "2", "*", "test_batch", ".", "ar", ".", "size", "(", "1", ")", ")", "\n", "\n", "hypotheses", "=", "[", "\n", "decode_ids", "(", "out", ",", "tgt_text_field", ",", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "for", "out", "in", "decoded_val", "[", "0", "]", "]", "\n", "\n", "ground_truth", ".", "extend", "(", "tgt_string", ")", "\n", "all_hypotheses", ".", "extend", "(", "hypotheses", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "wer", "=", "1", "-", "sum", "(", "\n", "float", "(", "gt", "==", "hyp", ")", "for", "gt", ",", "hyp", "\n", "in", "zip", "(", "ground_truth", ",", "all_hypotheses", ")", ")", "/", "len", "(", "ground_truth", ")", "\n", "logging", ".", "info", "(", "\"WER: %.3g\"", ",", "wer", ")", "\n", "\n", "cer", "=", "char_error_rate", "(", "\n", "all_hypotheses", ",", "ground_truth", ",", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3g\"", ",", "cer", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_generation.main": [[24, 402], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "tensorboardX.SummaryWriter", "torch.device", "logging.info", "transliteration_utils.load_transliteration_data", "logging.info", "experiment.save_vocab", "experiment.save_vocab", "logging.info", "models.EditDistNeuralModelProgressive().to", "logging.info", "torch.nn.KLDivLoss().to", "torch.nn.NLLLoss().to", "torch.nn.CrossEntropyLoss().to", "torch.nn.BCELoss", "torch.optim.Adam", "logging.info", "open", "open", "logging.info", "time.time", "range", "logging.info", "logging.info", "logging.info", "open.close", "open.close", "torch.load", "torch.load.eval", "range", "logging.info", "enumerate", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "argparse.ArgumentParser.error", "os.path.join", "os.path.join", "torch.load.parameters", "os.path.join", "os.path.join", "beam_exploration.append", "logging.info", "open", "print", "torch.cuda.is_available", "models.EditDistNeuralModelProgressive", "sum", "torch.nn.KLDivLoss", "torch.nn.NLLLoss", "torch.nn.CrossEntropyLoss", "torch.load.", "torch.tensor().to", "torch.tensor().to.backward", "len", "enumerate", "transliteration_utils.char_error_rate", "beam_performance.append", "os.path.join", "torch.no_grad", "torch.load.beam_search", "zip", "sum", "len", "experiment.get_timestamp", "logging.info", "action_scores.size", "nn.KLDivLoss().to.sum", "action_scores.size", "expected_counts.argmax", "nn.CrossEntropyLoss().to.", "next_symbol_score.size", "nn.NLLLoss().to.", "nn.BCELoss.", "logging.info", "torch.nn.utils.clip_grad_norm_", "optim.Adam.step", "optim.Adam.zero_grad", "print", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "torch.load.eval", "enumerate", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "print", "logging.info", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.flush", "torch.load.train", "range", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "sources.append", "ground_truth.append", "hypotheses.append", "zip", "x.reshape().size", "torch.tensor", "table_mask.sum", "action_scores[].reshape", "sampled_actions[].reshape", "table_mask.sum", "next_symbol_score.reshape", "train_ex.en[].reshape", "tgt_mask[].sum", "table_mask.sum", "logprob.exp", "torch.ones_like", "torch.load.parameters", "logging.info", "torch.save", "time.time", "torch.no_grad", "torch.load.beam_search", "zip", "logging.info", "logging.info", "float", "torch.load.parameters", "src_mask.unsqueeze", "tgt_mask.unsqueeze", "nn.KLDivLoss().to.", "torch.no_grad", "torch.load.beam_search", "zip", "sum", "len", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "sources.append", "ground_truth.append", "hypotheses.append", "zip", "x.reshape", "action_scores.reshape", "expected_counts.reshape", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "sources.append", "ground_truth.append", "hypotheses.append", "zip", "table_mask.reshape", "table_mask[].reshape", "tgt_mask[].reshape", "logging.info", "logging.info", "float", "zip", "parser.parse_args.data_prefix.replace"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.load_transliteration_data", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--em-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--sampled-em-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--nll-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--distortion-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--final-state-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-type\"", ",", "default", "=", "'transformer'", ",", "\n", "choices", "=", "[", "\"transformer\"", ",", "\"rnn\"", ",", "\"embeddings\"", ",", "\"cnn\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--embedding-dim\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--window\"", ",", "default", "=", "3", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden-size\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention-heads\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-enc-dec-att\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam-size\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Beam size for test data decoding.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--delay-update\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Update model every N steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, source side is space-separated.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, target side is space-separated.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--patience\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of validations witout improvement before \"", "\n", "\"decreasing the learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-decrease-count\"", ",", "default", "=", "6", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number learning rate decays before \"", "\n", "\"early stopping.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-decrease-ratio\"", ",", "default", "=", "0.7", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Factor by which the learning rate is decayed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning-rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Initial learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-frequency\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--len-norm\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Length normalization during decoding.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "args", ".", "nll_loss", "is", "None", "and", "\n", "args", ".", "em_loss", "is", "None", "and", "args", ".", "sampled_em_loss", "is", "None", ")", ":", "\n", "        ", "parser", ".", "error", "(", "\"No loss was specified.\"", ")", "\n", "\n", "", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "f\"_model{args.model_type}\"", "+", "\n", "f\"_hidden{args.hidden_size}\"", "+", "\n", "f\"_attheads{args.attention_heads}\"", "+", "\n", "f\"_layers{args.layers}\"", "+", "\n", "f\"_encdecatt{not args.no_enc_dec_att}\"", "+", "\n", "f\"_window{args.window}\"", "+", "\n", "f\"_batch{args.batch_size}\"", "+", "\n", "f\"_dealy{args.delay_update}\"", "+", "\n", "f\"_patence{args.patience}\"", "+", "\n", "f\"_nll{args.nll_loss}\"", "+", "\n", "f\"_EMloss{args.em_loss}\"", "+", "\n", "f\"_sampledEMloss{args.sampled_em_loss}\"", "+", "\n", "f\"_finalStateLoss{args.final_state_loss}\"", "+", "\n", "f\"_distortion{args.distortion_loss}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"edit_gen_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "tb_writer", "=", "SummaryWriter", "(", "experiment_dir", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "logging", ".", "info", "(", "\"Load data.\"", ")", "\n", "src_text_field", ",", "tgt_text_field", ",", "train_iter", ",", "val_iter", ",", "test_iter", "=", "load_transliteration_data", "(", "\n", "args", ".", "data_prefix", ",", "args", ".", "batch_size", ",", "device", ",", "\n", "src_tokenized", "=", "args", ".", "src_tokenized", ",", "\n", "tgt_tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "\n", "logging", ".", "info", "(", "\"Save vocabularies.\"", ")", "\n", "save_vocab", "(", "\n", "src_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "tgt_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initialize model on device %s\"", ",", "device", ")", "\n", "model", "=", "EditDistNeuralModelProgressive", "(", "\n", "src_text_field", ".", "vocab", ",", "tgt_text_field", ".", "vocab", ",", "device", ",", "directed", "=", "True", ",", "\n", "model_type", "=", "args", ".", "model_type", ",", "\n", "hidden_dim", "=", "args", ".", "hidden_size", ",", "\n", "hidden_layers", "=", "args", ".", "layers", ",", "\n", "attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "window", "=", "args", ".", "window", ",", "\n", "encoder_decoder_attention", "=", "not", "args", ".", "no_enc_dec_att", ")", ".", "to", "(", "device", ")", "\n", "logging", ".", "info", "(", "\n", "\"Model parameters: %dk\"", ",", "\n", "sum", "(", "[", "x", ".", "reshape", "(", "-", "1", ")", ".", "size", "(", "0", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", "]", ")", "/", "1000", ")", "\n", "\n", "kl_div", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'none'", ")", ".", "to", "(", "device", ")", "\n", "nll", "=", "nn", ".", "NLLLoss", "(", "reduction", "=", "'none'", ")", ".", "to", "(", "device", ")", "\n", "xent", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", ".", "to", "(", "device", ")", "\n", "bce", "=", "nn", ".", "BCELoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "logging", ".", "info", "(", "\"Model initialized.\"", ")", "\n", "\n", "train_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"train_loss.tsv\"", ")", ",", "\"w\"", ")", "\n", "valid_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"valid_cer.tsv\"", ")", ",", "\"w\"", ")", "\n", "\n", "step", "=", "0", "\n", "best_wer", "=", "1e9", "\n", "best_wer_step", "=", "0", "\n", "best_cer", "=", "1e9", "\n", "best_cer_step", "=", "0", "\n", "stalled", "=", "0", "\n", "last_save_time", "=", "0", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "remaining_decrease", "=", "args", ".", "lr_decrease_count", "\n", "\n", "logging", ".", "info", "(", "\"Start training.\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "remaining_decrease", "<=", "0", ":", "\n", "            ", "break", "\n", "\n", "", "for", "train_ex", "in", "train_iter", ":", "\n", "            ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "                ", "learning_rate", "*=", "args", ".", "lr_decrease_ratio", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "learning_rate", "\n", "", "remaining_decrease", "-=", "1", "\n", "stalled", "=", "0", "\n", "logging", ".", "info", "(", "\"Decreasing learning rate to %f.\"", ",", "learning_rate", ")", "\n", "", "if", "remaining_decrease", "<=", "0", ":", "\n", "                ", "break", "\n", "", "step", "+=", "1", "\n", "\n", "(", "action_scores", ",", "expected_counts", ",", "\n", "logprob", ",", "next_symbol_score", ",", "distorted_probs", ")", "=", "model", "(", "\n", "train_ex", ".", "ar", ",", "train_ex", ".", "en", ")", "\n", "\n", "tgt_mask", "=", "(", "train_ex", ".", "en", "!=", "model", ".", "tgt_pad", ")", ".", "float", "(", ")", "\n", "src_mask", "=", "(", "train_ex", ".", "ar", "!=", "model", ".", "src_pad", ")", ".", "float", "(", ")", "\n", "table_mask", "=", "(", "\n", "src_mask", ".", "unsqueeze", "(", "2", ")", "*", "tgt_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "float", "(", ")", "\n", "\n", "loss", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "device", ")", "\n", "kl_loss", "=", "0", "\n", "if", "args", ".", "em_loss", "is", "not", "None", ":", "\n", "                ", "tgt_dim", "=", "action_scores", ".", "size", "(", "-", "1", ")", "\n", "kl_loss_raw", "=", "kl_div", "(", "\n", "action_scores", ".", "reshape", "(", "-", "1", ",", "tgt_dim", ")", ",", "\n", "expected_counts", ".", "reshape", "(", "-", "1", ",", "tgt_dim", ")", ")", ".", "sum", "(", "1", ")", "\n", "kl_loss", "=", "(", "\n", "(", "kl_loss_raw", "*", "table_mask", ".", "reshape", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "/", "\n", "table_mask", ".", "sum", "(", ")", ")", "\n", "loss", "+=", "args", ".", "em_loss", "*", "kl_loss", "\n", "\n", "", "sampled_em_loss", "=", "0", "\n", "if", "args", ".", "sampled_em_loss", "is", "not", "None", ":", "\n", "                ", "tgt_dim", "=", "action_scores", ".", "size", "(", "-", "1", ")", "\n", "# TODO do real sampling instead of argmax", "\n", "sampled_actions", "=", "expected_counts", ".", "argmax", "(", "3", ")", "\n", "# sampled_actions = torch.multinomial(", "\n", "#   expected_counts[:, 1:, 1:].reshape(-1, tgt_dim), 1)", "\n", "sampled_em_loss_raw", "=", "xent", "(", "\n", "action_scores", "[", ":", ",", "1", ":", ",", "1", ":", "]", ".", "reshape", "(", "-", "1", ",", "tgt_dim", ")", ",", "\n", "sampled_actions", "[", ":", ",", "1", ":", ",", "1", ":", "]", ".", "reshape", "(", "-", "1", ")", ")", "\n", "sampled_em_loss", "=", "(", "\n", "(", "sampled_em_loss_raw", "*", "\n", "table_mask", "[", ":", ",", "1", ":", ",", "1", ":", "]", ".", "reshape", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "/", "\n", "table_mask", ".", "sum", "(", ")", ")", "\n", "loss", "+=", "args", ".", "sampled_em_loss", "*", "sampled_em_loss", "\n", "\n", "", "nll_loss", "=", "0", "\n", "if", "args", ".", "nll_loss", "is", "not", "None", ":", "\n", "                ", "tgt_dim", "=", "next_symbol_score", ".", "size", "(", "-", "1", ")", "\n", "nll_loss_raw", "=", "nll", "(", "\n", "next_symbol_score", ".", "reshape", "(", "-", "1", ",", "tgt_dim", ")", ",", "\n", "train_ex", ".", "en", "[", ":", ",", "1", ":", "]", ".", "reshape", "(", "-", "1", ")", ")", "\n", "nll_loss", "=", "(", "\n", "(", "tgt_mask", "[", ":", ",", "1", ":", "]", ".", "reshape", "(", "-", "1", ")", "*", "nll_loss_raw", ")", ".", "sum", "(", ")", "/", "\n", "tgt_mask", "[", ":", ",", "1", ":", "]", ".", "sum", "(", ")", ")", "\n", "loss", "+=", "args", ".", "nll_loss", "*", "nll_loss", "\n", "\n", "", "distortion_loss", "=", "0", "\n", "if", "args", ".", "distortion_loss", "is", "not", "None", ":", "\n", "                ", "distortion_loss", "=", "(", "\n", "(", "table_mask", "*", "distorted_probs", ")", ".", "sum", "(", ")", "/", "table_mask", ".", "sum", "(", ")", ")", "\n", "loss", "+=", "args", ".", "distortion_loss", "*", "distortion_loss", "\n", "\n", "", "final_state_loss", "=", "0", "\n", "if", "args", ".", "final_state_loss", "is", "not", "None", ":", "\n", "                ", "final_state_loss", "=", "bce", "(", "logprob", ".", "exp", "(", ")", ",", "torch", ".", "ones_like", "(", "logprob", ")", ")", "\n", "loss", "+=", "args", ".", "final_state_loss", "*", "final_state_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "step", "%", "args", ".", "delay_update", "==", "args", ".", "delay_update", "-", "1", ":", "\n", "                ", "logging", ".", "info", "(", "\n", "\"step: %d, train loss = %.3g \"", "\n", "\"(NLL %.3g, distortion: %.3g, \"", "\n", "\"final state NLL: %.3g, \"", "\n", "\"EM: %.3g, sampled EM: %.3g)\"", ",", "\n", "step", ",", "loss", ",", "nll_loss", ",", "distortion_loss", ",", "final_state_loss", ",", "\n", "kl_loss", ",", "sampled_em_loss", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "print", "(", "f\"{step:d}\\t{nll_loss:.3g}\"", ",", "file", "=", "train_curve_file", ")", "\n", "\n", "", "if", "(", "step", "%", "(", "args", ".", "delay_update", "*", "args", ".", "validation_frequency", ")", "==", "\n", "args", ".", "delay_update", "*", "args", ".", "validation_frequency", "-", "1", ")", ":", "\n", "                ", "tb_writer", ".", "add_scalar", "(", "'train/loss'", ",", "loss", ",", "step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'train/nll'", ",", "nll_loss", ",", "step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'train/em_kl_div'", ",", "kl_loss", ",", "step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "'train/sampled_em_nll'", ",", "sampled_em_loss", ",", "step", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "sources", "=", "[", "]", "\n", "ground_truth", "=", "[", "]", "\n", "hypotheses", "=", "[", "]", "\n", "\n", "for", "j", ",", "val_ex", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "decoded_val", "=", "model", ".", "beam_search", "(", "\n", "val_ex", ".", "ar", ",", "beam_size", "=", "3", ",", "len_norm", "=", "0.0", ")", "\n", "\n", "for", "ar", ",", "en", ",", "hyp", "in", "zip", "(", "\n", "val_ex", ".", "ar", ",", "val_ex", ".", "en", ",", "decoded_val", ")", ":", "\n", "                            ", "src_string", "=", "decode_ids", "(", "\n", "ar", ",", "src_text_field", ",", "args", ".", "src_tokenized", ")", "\n", "tgt_string", "=", "decode_ids", "(", "\n", "en", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "hypothesis", "=", "decode_ids", "(", "\n", "hyp", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "sources", ".", "append", "(", "src_string", ")", "\n", "ground_truth", ".", "append", "(", "tgt_string", ")", "\n", "hypotheses", ".", "append", "(", "hypothesis", ")", "\n", "\n", "", "if", "j", "==", "0", ":", "\n", "                            ", "for", "src", ",", "hyp", ",", "tgt", "in", "zip", "(", "\n", "sources", "[", ":", "10", "]", ",", "hypotheses", ",", "ground_truth", ")", ":", "\n", "                                ", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\n", "\"'%s' -> '%s' (%s)\"", ",", "src", ",", "hyp", ",", "tgt", ")", "\n", "\n", "", "", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "wer", "=", "1", "-", "sum", "(", "\n", "float", "(", "gt", "==", "hyp", ")", "for", "gt", ",", "hyp", "\n", "in", "zip", "(", "ground_truth", ",", "hypotheses", ")", ")", "/", "len", "(", "ground_truth", ")", "\n", "cer", "=", "char_error_rate", "(", "\n", "hypotheses", ",", "ground_truth", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "stalled", "+=", "1", "\n", "if", "wer", "<", "best_wer", ":", "\n", "                    ", "best_wer", "=", "wer", "\n", "best_wer_step", "=", "step", "\n", "stalled", "=", "0", "\n", "", "if", "cer", "<", "best_cer", ":", "\n", "                    ", "best_cer", "=", "cer", "\n", "best_cer_step", "=", "step", "\n", "stalled", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "\n", "\"WER: %.3g   (best %.3g, step %d)\"", ",", "\n", "wer", ",", "best_wer", ",", "best_wer_step", ")", "\n", "logging", ".", "info", "(", "\n", "\"CER: %.3g   (best %.3g, step %d)\"", ",", "\n", "cer", ",", "best_cer", ",", "best_cer_step", ")", "\n", "if", "stalled", ">", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "\"Stalled %d times.\"", ",", "stalled", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "print", "(", "f\"{step:d}\\t{cer:.3g}\"", ",", "file", "=", "valid_curve_file", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "tb_writer", ".", "add_scalar", "(", "'val/cer'", ",", "cer", ",", "step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'val/wer'", ",", "wer", ",", "step", ")", "\n", "tb_writer", ".", "flush", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "\"TRAINING FINISHED.\"", ")", "\n", "logging", ".", "info", "(", "\n", "\"The training took %d seconds.\"", ",", "last_save_time", "-", "start_time", ")", "\n", "logging", ".", "info", "(", "\"Find best beam serch parameters.\"", ")", "\n", "\n", "train_curve_file", ".", "close", "(", ")", "\n", "valid_curve_file", ".", "close", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_eval_beam", "=", "1", "\n", "best_eval_len_norm", "=", "0.0", "\n", "best_eval_cer", "=", "10.", "\n", "\n", "beam_exploration", "=", "[", "]", "\n", "\n", "for", "beam", "in", "range", "(", "1", ",", "40", ")", ":", "\n", "        ", "if", "beam", ">=", "len", "(", "tgt_text_field", ".", "vocab", ")", ":", "\n", "            ", "break", "\n", "\n", "", "beam_performance", "=", "[", "]", "\n", "for", "len_norm", "in", "[", "0.2", "*", "x", "for", "x", "in", "range", "(", "14", ")", "]", ":", "\n", "            ", "sources", "=", "[", "]", "\n", "ground_truth", "=", "[", "]", "\n", "hypotheses", "=", "[", "]", "\n", "\n", "for", "j", ",", "val_ex", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "decoded_val", "=", "model", ".", "beam_search", "(", "\n", "val_ex", ".", "ar", ",", "beam_size", "=", "beam", ",", "len_norm", "=", "len_norm", ")", "\n", "for", "ar", ",", "en", ",", "hyp", "in", "zip", "(", "val_ex", ".", "ar", ",", "val_ex", ".", "en", ",", "decoded_val", ")", ":", "\n", "                        ", "src_string", "=", "decode_ids", "(", "\n", "ar", ",", "src_text_field", ",", "args", ".", "src_tokenized", ")", "\n", "tgt_string", "=", "decode_ids", "(", "\n", "en", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "hypothesis", "=", "decode_ids", "(", "\n", "hyp", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "sources", ".", "append", "(", "src_string", ")", "\n", "ground_truth", ".", "append", "(", "tgt_string", ")", "\n", "hypotheses", ".", "append", "(", "hypothesis", ")", "\n", "\n", "", "", "", "cer", "=", "char_error_rate", "(", "hypotheses", ",", "ground_truth", ",", "args", ".", "tgt_tokenized", ")", "\n", "if", "cer", "<", "best_eval_cer", ":", "\n", "                ", "best_eval_beam", "=", "beam", "\n", "best_eval_len_norm", "=", "len_norm", "\n", "best_eval_cer", "=", "cer", "\n", "", "beam_performance", ".", "append", "(", "cer", ")", "\n", "", "beam_exploration", ".", "append", "(", "beam_performance", ")", "\n", "logging", ".", "info", "(", "\"Beam %d, so far best CER %f.\"", ",", "beam", ",", "best_eval_cer", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "experiment_dir", ",", "\"beam_exploration.txt\"", ")", ",", "\"w\"", ")", "as", "f_beam", ":", "\n", "        ", "print", "(", "beam_exploration", ",", "file", "=", "f_beam", ")", "\n", "\n", "", "logging", ".", "info", "(", "\n", "\"Best beam size: %d, best len norm: %f\"", ",", "\n", "best_eval_beam", ",", "best_eval_len_norm", ")", "\n", "\n", "for", "j", ",", "test_ex", "in", "enumerate", "(", "test_iter", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "decoded_val", "=", "model", ".", "beam_search", "(", "\n", "test_ex", ".", "ar", ",", "\n", "beam_size", "=", "best_eval_beam", ",", "\n", "len_norm", "=", "best_eval_len_norm", ")", "\n", "for", "ar", ",", "en", ",", "hyp", "in", "zip", "(", "test_ex", ".", "ar", ",", "test_ex", ".", "en", ",", "decoded_val", ")", ":", "\n", "                ", "src_string", "=", "decode_ids", "(", "ar", ",", "src_text_field", ",", "args", ".", "src_tokenized", ")", "\n", "tgt_string", "=", "decode_ids", "(", "en", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "hypothesis", "=", "decode_ids", "(", "hyp", ",", "tgt_text_field", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "sources", ".", "append", "(", "src_string", ")", "\n", "ground_truth", ".", "append", "(", "tgt_string", ")", "\n", "hypotheses", ".", "append", "(", "hypothesis", ")", "\n", "\n", "", "if", "j", "==", "0", ":", "\n", "                ", "for", "src", ",", "hyp", ",", "tgt", "in", "zip", "(", "\n", "sources", "[", ":", "10", "]", ",", "hypotheses", ",", "ground_truth", ")", ":", "\n", "                    ", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"'%s' -> '%s' (%s)\"", ",", "src", ",", "hyp", ",", "tgt", ")", "\n", "", "", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "wer", "=", "1", "-", "sum", "(", "\n", "float", "(", "gt", "==", "hyp", ")", "for", "gt", ",", "hyp", "\n", "in", "zip", "(", "ground_truth", ",", "hypotheses", ")", ")", "/", "len", "(", "ground_truth", ")", "\n", "cer", "=", "char_error_rate", "(", "hypotheses", ",", "ground_truth", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "logging", ".", "info", "(", "\"WER: %.3g\"", ",", "wer", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3g\"", ",", "cer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliterate.main": [[18, 84], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "transliteration_utils.load_vocab", "transliteration_utils.load_vocab", "logging.info", "enumerate", "transliteration_utils.char_error_rate", "logging.info", "logging.info", "torch.tensor().cuda", "transliteration_utils.decode_ids", "print", "sum", "len", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "line.strip().split", "targets.append", "line.strip", "torch.load.decode", "outputs.append", "logging.info", "torch.tensor", "torch.load.beam_search", "float", "line.strip", "line.strip.split", "list", "torch.load.operation_decoding", "zip", "torch.load.operation_beam_search", "ValueError"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.decode", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_s2s.Seq2SeqModel.beam_search", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_decoding", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.operation_beam_search"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoding\"", ",", "default", "=", "\"greedy\"", ",", "\n", "choices", "=", "[", "\"greedy\"", ",", "\"beam_search\"", ",", "\"operations\"", ",", "\"operations_beam\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--beam-size\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "src_vocab", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "input", ")", ":", "\n", "        ", "if", "args", ".", "evaluate", ":", "\n", "            ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "string_1", ",", "string_2", "=", "line_split", "[", "0", "]", ",", "line_split", "[", "1", "]", "\n", "targets", ".", "append", "(", "string_2", ")", "\n", "", "else", ":", "\n", "            ", "string_1", "=", "line", ".", "strip", "(", ")", "\n", "string_2", "=", "None", "\n", "\n", "", "string_1_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_1", ".", "split", "(", ")", "if", "args", ".", "src_tokenized", "else", "list", "(", "string_1", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "\n", "string_1_idx", "=", "torch", ".", "tensor", "(", "\n", "[", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "string_1_tok", "]", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "args", ".", "decoding", "==", "\"greedy\"", ":", "\n", "            ", "output", "=", "model", ".", "decode", "(", "string_1_idx", ")", "\n", "", "elif", "args", ".", "decoding", "==", "\"beam_search\"", ":", "\n", "            ", "output", "=", "model", ".", "beam_search", "(", "string_1_idx", ",", "args", ".", "beam_size", ")", "\n", "", "elif", "args", ".", "decoding", "==", "\"operations\"", ":", "\n", "            ", "output", "=", "model", ".", "operation_decoding", "(", "string_1_idx", ")", "#, args.beam_size)", "\n", "", "elif", "args", ".", "decoding", "==", "\"operations_beam\"", ":", "\n", "            ", "output", "=", "model", ".", "operation_beam_search", "(", "string_1_idx", ",", "args", ".", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unknown type of decoding: {args.decoding}\"", ")", "\n", "\n", "", "output_str", "=", "decode_ids", "(", "output", "[", "0", "]", ",", "tgt_vocab", ",", "args", ".", "tgt_tokenized", ")", "\n", "if", "args", ".", "evaluate", ":", "\n", "            ", "outputs", ".", "append", "(", "output_str", ")", "\n", "", "print", "(", "output_str", ")", "\n", "\n", "if", "i", "%", "100", "==", "99", ":", "\n", "            ", "logging", ".", "info", "(", "\"Processed %d strings.\"", ",", "i", "+", "1", ")", "\n", "\n", "", "", "acc", "=", "sum", "(", "\n", "float", "(", "o", "==", "t", ")", "for", "o", ",", "t", "in", "zip", "(", "outputs", ",", "targets", ")", ")", "/", "len", "(", "outputs", ")", "\n", "cer", "=", "char_error_rate", "(", "outputs", ",", "targets", ",", "args", ".", "tgt_tokenized", ")", "\n", "logging", ".", "info", "(", "\"WER: %.3g\"", ",", "1", "-", "acc", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3g\"", ",", "cer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.load_vocab": [[19, 28], ["file.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "file", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "file", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.str_to_vec": [[29, 34], ["torch.tensor", "string.split", "list"], "function", ["None"], ["", "def", "str_to_vec", "(", "stoi", ",", "string", ",", "tokenized", ")", ":", "\n", "    ", "tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "(", "string", ".", "split", "(", ")", "if", "tokenized", "else", "list", "(", "string", ")", ")", "+", "[", "\"</s>\"", "]", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "[", "[", "stoi", "[", "s", "]", "for", "s", "in", "tok", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.main": [[36, 127], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "eval_classifier_statistical.load_vocab", "eval_classifier_statistical.load_vocab", "logging.info", "logging.info", "enumerate", "logging.info", "sum", "sum", "logging.info", "logging.info", "logging.info", "print", "exit", "enumerate", "logging.info", "logging.info", "logging.info", "print", "line.strip().split", "eval_classifier_statistical.str_to_vec", "eval_classifier_statistical.str_to_vec", "torch.load.viterbi", "len", "line.strip().split", "eval_classifier_statistical.str_to_vec", "eval_classifier_statistical.str_to_vec", "torch.load.viterbi", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "neg_scores.append", "pos_scores.append", "line.strip", "sum", "len", "sum", "len", "line.strip"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.str_to_vec", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.str_to_vec", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.viterbi", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.str_to_vec", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_classifier_statistical.str_to_vec", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.viterbi"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"eval_data\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"test_data\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "src_vocab", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "\n", "pos_scores", "=", "[", "]", "\n", "neg_scores", "=", "[", "]", "\n", "\n", "logging", ".", "info", "(", "\"Estimate threshold on validation data.\"", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "eval_data", ")", ":", "\n", "        ", "src", ",", "tgt", ",", "clazz", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "src_idx", "=", "str_to_vec", "(", "src_stoi", ",", "src", ",", "args", ".", "src_tokenized", ")", "\n", "tgt_idx", "=", "str_to_vec", "(", "tgt_stoi", ",", "tgt", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "score", "=", "model", ".", "viterbi", "(", "src_idx", ",", "tgt_idx", ")", "\n", "if", "clazz", "==", "\"0\"", ":", "\n", "            ", "neg_scores", ".", "append", "(", "score", ")", "\n", "", "if", "clazz", "==", "\"1\"", ":", "\n", "            ", "pos_scores", ".", "append", "(", "score", ")", "\n", "\n", "", "", "threshold", "=", "(", "\n", "sum", "(", "pos_scores", ")", "/", "len", "(", "pos_scores", ")", "+", "\n", "sum", "(", "neg_scores", ")", "/", "len", "(", "neg_scores", ")", ")", "/", "2", "\n", "logging", ".", "info", "(", "\"Threshold set to %f.\"", ",", "threshold", ")", "\n", "\n", "val_true_positives", "=", "sum", "(", "1.0", "for", "x", "in", "pos_scores", "if", "x", ">", "threshold", ")", "\n", "val_false_positives", "=", "sum", "(", "1.0", "for", "x", "in", "neg_scores", "if", "x", ">", "threshold", ")", "\n", "\n", "if", "val_true_positives", "+", "val_false_positives", ">", "0", ":", "\n", "        ", "val_precision", "=", "(", "\n", "val_true_positives", "/", "(", "val_true_positives", "+", "val_false_positives", ")", ")", "\n", "", "else", ":", "\n", "        ", "val_precision", "=", "0", "\n", "", "val_recall", "=", "val_true_positives", "/", "len", "(", "pos_scores", ")", "\n", "if", "val_precision", "+", "val_recall", ">", "0", ":", "\n", "        ", "val_f_score", "=", "2", "*", "val_precision", "*", "val_recall", "/", "(", "val_precision", "+", "val_recall", ")", "\n", "", "else", ":", "\n", "        ", "val_f_score", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "\"Validation precision: %f\"", ",", "val_precision", ")", "\n", "logging", ".", "info", "(", "\"Validation recall:    %f\"", ",", "val_recall", ")", "\n", "logging", ".", "info", "(", "\"Validation F-Score:   %f\"", ",", "val_f_score", ")", "\n", "\n", "print", "(", "val_f_score", ")", "\n", "exit", "(", ")", "\n", "\n", "true_possitive", "=", "0", "\n", "real_positives", "=", "0", "\n", "all_positives", "=", "0", "\n", "all_count", "=", "0", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "test_data", ")", ":", "\n", "        ", "src", ",", "tgt", ",", "clazz", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "src_idx", "=", "str_to_vec", "(", "src_stoi", ",", "src", ",", "args", ".", "src_tokenized", ")", "\n", "tgt_idx", "=", "str_to_vec", "(", "tgt_stoi", ",", "tgt", ",", "args", ".", "tgt_tokenized", ")", "\n", "\n", "score", "=", "model", ".", "viterbi", "(", "src_idx", ",", "tgt_idx", ")", "\n", "\n", "if", "score", ">", "threshold", ":", "\n", "            ", "all_positives", "+=", "1", "\n", "if", "clazz", "==", "\"1\"", ":", "\n", "                ", "true_possitive", "+=", "1", "\n", "", "", "if", "clazz", "==", "\"1\"", ":", "\n", "            ", "real_positives", "+=", "1", "\n", "\n", "", "", "if", "all_positives", ">", "0", ":", "\n", "        ", "precision", "=", "true_possitive", "/", "all_positives", "\n", "", "else", ":", "\n", "        ", "precision", "=", "0", "\n", "", "recall", "=", "true_possitive", "/", "real_positives", "\n", "if", "recall", ">", "0", "and", "precision", ">", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "", "else", ":", "\n", "        ", "f_score", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "\"Test precision: %f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Test recall:    %f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"Test F-Score:   %f\"", ",", "f_score", ")", "\n", "print", "(", "f_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_git_info": [[14, 26], ["os.path.dirname", "os.path.realpath", "open", "subprocess.run", "open", "subprocess.run"], "function", ["None"], ["def", "save_git_info", "(", "git_commit_file", ":", "str", ",", "git_diff_file", ":", "str", ",", "\n", "branch", ":", "str", "=", "\"HEAD\"", ")", "->", "None", ":", "\n", "    ", "repo_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "\n", "with", "open", "(", "git_commit_file", ",", "\"wb\"", ")", "as", "file", ":", "\n", "        ", "subprocess", ".", "run", "(", "[", "\"git\"", ",", "\"log\"", ",", "\"-1\"", ",", "\"--format=%H\"", ",", "branch", "]", ",", "\n", "cwd", "=", "repo_dir", ",", "stdout", "=", "file", ",", "check", "=", "False", ")", "\n", "\n", "", "with", "open", "(", "git_diff_file", ",", "\"wb\"", ")", "as", "file", ":", "\n", "        ", "subprocess", ".", "run", "(", "\n", "[", "\"git\"", ",", "\"--no-pager\"", ",", "\"diff\"", ",", "\"--color=always\"", ",", "branch", "]", ",", "\n", "cwd", "=", "repo_dir", ",", "stdout", "=", "file", ",", "check", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging": [[28, 45], ["os.path.join", "os.mkdir", "experiment.save_git_info", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger().addHandler", "os.path.join", "os.path.join", "open", "print", "os.path.join", "logging.Formatter", "os.path.join", "yaml.dump", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_git_info"], ["", "", "def", "experiment_logging", "(", "root", ":", "str", ",", "experiment_id", ":", "str", ",", "args", ")", "->", "str", ":", "\n", "    ", "experiment_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "experiment_id", ")", "\n", "os", ".", "mkdir", "(", "experiment_dir", ")", "\n", "\n", "save_git_info", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"git_commit\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"git_diff\"", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"args\"", ")", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "print", "(", "yaml", ".", "dump", "(", "args", ".", "__dict__", ")", ",", "file", "=", "file", ")", "\n", "\n", "", "log_handler", "=", "logging", ".", "FileHandler", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"train.log\"", ")", ")", "\n", "log_handler", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "'%(asctime)s %(message)s'", ")", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "log_handler", ")", "\n", "\n", "return", "experiment_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp": [[47, 49], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "get_timestamp", "(", ")", "->", "str", ":", "\n", "    ", "return", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S-%f\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab": [[51, 55], ["open", "print"], "function", ["None"], ["", "def", "save_vocab", "(", "itos_list", ":", "List", "[", "str", "]", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "file", ":", "\n", "        ", "for", "item", "in", "itos_list", ":", "\n", "            ", "print", "(", "item", ",", "file", "=", "file", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.alignment_from_s2s_model.preprocess_input": [[19, 25], ["string.split", "list"], "function", ["None"], ["def", "preprocess_input", "(", "\n", "string", ":", "str", ",", "tokenized", ":", "bool", ",", "stoi", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "    ", "string_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "(", "string", ".", "split", "(", ")", "if", "tokenized", "else", "list", "(", "string", ")", ")", "+", "[", "\"</s>\"", "]", ")", "\n", "string_idx", "=", "[", "stoi", "[", "s", "]", "for", "s", "in", "string_tok", "]", "\n", "return", "string_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.alignment_from_s2s_model.main": [[27, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "transliteration_utils.load_vocab", "transliteration_utils.load_vocab", "logging.info", "enumerate", "line.strip().split", "alignment_from_s2s_model.preprocess_input", "alignment_from_s2s_model.preprocess_input", "attentions[].t", "enumerate", "print", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "torch.no_grad", "torch.load.", "enumerate", "logging.info", "line.strip", "torch.tensor().cuda", "torch.tensor().cuda", "links.append", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.alignment_from_s2s_model.preprocess_input", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.alignment_from_s2s_model.preprocess_input"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--threshold\"", ",", "default", "=", "0.15", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Threshold for considering attention as an alignment link.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "_", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "_", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "input", ")", ":", "\n", "        ", "string_1", ",", "string_2", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "\n", "string_1_idx", "=", "preprocess_input", "(", "string_1", ",", "args", ".", "src_tokenized", ",", "src_stoi", ")", "\n", "string_2_idx", "=", "preprocess_input", "(", "string_2", ",", "args", ".", "tgt_tokenized", ",", "tgt_stoi", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "_", ",", "attentions", "=", "model", "(", "\n", "# pylint: disable=not-callable", "\n", "torch", ".", "tensor", "(", "[", "string_1_idx", "]", ")", ".", "cuda", "(", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "string_2_idx", "]", ")", ".", "cuda", "(", ")", ")", "\n", "# pylint: enable=not-callable", "\n", "\n", "", "links", "=", "[", "]", "\n", "soft_alignment", "=", "attentions", "[", "0", ",", ":", "-", "1", ",", "1", ":", "-", "1", "]", ".", "t", "(", ")", "\n", "for", "src_idx", ",", "row", "in", "enumerate", "(", "soft_alignment", ")", ":", "\n", "            ", "for", "tgt_idx", ",", "val", "in", "enumerate", "(", "row", ")", ":", "\n", "                ", "if", "val", ">", "args", ".", "threshold", ":", "\n", "                    ", "links", ".", "append", "(", "f\"{src_idx + 1}-{tgt_idx + 1}\"", ")", "\n", "", "", "", "print", "(", "\" \"", ".", "join", "(", "links", ")", ")", "\n", "\n", "if", "i", "%", "1000", "==", "999", ":", "\n", "            ", "logging", ".", "info", "(", "\"Processed %d pairs.\"", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.run_viterbi.load_vocab": [[17, 26], ["file.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "file", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "file", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.run_viterbi.main": [[28, 95], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "run_viterbi.load_vocab", "run_viterbi.load_vocab", "logging.info", "line.strip().split", "torch.load.viterbi", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "torch.tensor().cuda", "torch.tensor().cuda", "print", "print", "print", "print", "print", "line.strip", "readable_ops.append", "readable_ops.append", "readable_ops.append", "string_1.split", "list", "string_2.split", "list", "torch.tensor", "torch.tensor", "alignment.append"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.viterbi"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"input\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "default", "=", "sys", ".", "stdin", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output-format\"", ",", "default", "=", "\"nice\"", ",", "choices", "=", "[", "\"nice\"", ",", "\"tsv\"", ",", "\"alignment\"", "]", ",", "\n", "help", "=", "\"Nice for command line, tsv for processing, alignment=subtitutitons \"", "\n", "\"in word alignment format.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "src_vocab", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "for", "line", "in", "args", ".", "input", ":", "\n", "        ", "line_split", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "string_1", ",", "string_2", "=", "line_split", "[", "0", "]", ",", "line_split", "[", "1", "]", "\n", "string_1_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_1", ".", "split", "(", ")", "if", "args", ".", "src_tokenized", "else", "list", "(", "string_1", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "string_2_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "string_2", ".", "split", "(", ")", "if", "args", ".", "tgt_tokenized", "else", "list", "(", "string_2", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "\n", "string_1_idx", "=", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "string_1_tok", "]", "\n", "string_2_idx", "=", "[", "tgt_stoi", "[", "s", "]", "for", "s", "in", "string_2_tok", "]", "\n", "\n", "_", ",", "edit_ops", "=", "model", ".", "viterbi", "(", "\n", "torch", ".", "tensor", "(", "[", "string_1_idx", "]", ")", ".", "cuda", "(", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "string_2_idx", "]", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "if", "args", ".", "output_format", "==", "\"alignment\"", ":", "\n", "            ", "alignment", "=", "[", "]", "\n", "for", "operation", ",", "_", ",", "idx", "in", "edit_ops", "[", "1", ":", "-", "1", "]", ":", "\n", "                ", "if", "operation", "==", "\"subs\"", ":", "\n", "                    ", "src_id", ",", "tgt_id", "=", "idx", "\n", "alignment", ".", "append", "(", "f\"{src_id}-{tgt_id}\"", ")", "\n", "", "", "print", "(", "\" \"", ".", "join", "(", "alignment", ")", ")", "\n", "continue", "\n", "\n", "", "if", "args", ".", "output_format", "==", "\"nice\"", ":", "\n", "            ", "print", "(", "f\"{string_1} \u21e8 {string_2}\"", ")", "\n", "\n", "", "readable_ops", "=", "[", "]", "\n", "for", "operation", ",", "chars", ",", "_", "in", "edit_ops", "[", "1", ":", "-", "1", "]", ":", "\n", "            ", "if", "operation", "==", "\"delete\"", ":", "\n", "                ", "readable_ops", ".", "append", "(", "f\"-{src_vocab[chars]}\"", ")", "\n", "", "if", "operation", "==", "\"insert\"", ":", "\n", "                ", "readable_ops", ".", "append", "(", "f\"+{tgt_vocab[chars]}\"", ")", "\n", "", "if", "operation", "==", "\"subs\"", ":", "\n", "                ", "readable_ops", ".", "append", "(", "\n", "f\"{src_vocab[chars[0]]}\u2192{tgt_vocab[chars[1]]}\"", ")", "\n", "\n", "", "", "if", "args", ".", "output_format", "==", "\"nice\"", ":", "\n", "            ", "print", "(", "\" \"", ".", "join", "(", "readable_ops", ")", ")", "\n", "print", "(", ")", "\n", "", "if", "args", ".", "output_format", "==", "\"tsv\"", ":", "\n", "            ", "print", "(", "string_1", ",", "string_2", ",", "\" \"", ".", "join", "(", "readable_ops", ")", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.load_vocab": [[7, 16], ["file.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "file", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "file", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.load_transliteration_data": [[18, 42], ["torchtext.data.Field", "torchtext.data.Field", "torchtext.data.TabularDataset.splits", "data.Field.build_vocab", "data.Field.build_vocab", "torchtext.data.Iterator.splits", "len", "s.split", "s.split"], "function", ["None"], ["", "def", "load_transliteration_data", "(", "\n", "data_prefix", ",", "batch_size", ",", "device", ",", "src_tokenized", "=", "False", ",", "\n", "tgt_tokenized", "=", "False", ")", ":", "\n", "    ", "src_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "src_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "tgt_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "tgt_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "\n", "train_data", ",", "val_data", ",", "test_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "data_prefix", ",", "train", "=", "'train.txt'", ",", "\n", "validation", "=", "'eval.txt'", ",", "test", "=", "'test.txt'", ",", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'ar'", ",", "src_text_field", ")", ",", "(", "'en'", ",", "tgt_text_field", ")", "]", ")", "\n", "\n", "src_text_field", ".", "build_vocab", "(", "train_data", ")", "\n", "tgt_text_field", ".", "build_vocab", "(", "train_data", ")", "\n", "\n", "train_iter", ",", "val_iter", ",", "test_iter", "=", "data", ".", "Iterator", ".", "splits", "(", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", ",", "\n", "batch_sizes", "=", "(", "batch_size", ",", "16", ",", "16", ")", ",", "\n", "shuffle", "=", "True", ",", "device", "=", "device", ",", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "ar", ")", ")", "\n", "\n", "return", "(", "src_text_field", ",", "tgt_text_field", ",", "train_iter", ",", "val_iter", ",", "test_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids": [[44, 57], ["separator.join", "isinstance", "real_chars.append"], "function", ["None"], ["", "def", "decode_ids", "(", "ids_list", ",", "vocab", ",", "tokenized", "=", "False", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "vocab", ",", "list", ")", ":", "\n", "        ", "vocab", "=", "vocab", ".", "vocab", ".", "itos", "\n", "", "separator", "=", "\" \"", "if", "tokenized", "else", "\"\"", "\n", "chars", "=", "[", "vocab", "[", "i", "]", "for", "i", "in", "ids_list", "]", "\n", "if", "chars", "[", "0", "]", "==", "\"<s>\"", ":", "\n", "        ", "chars", "=", "chars", "[", "1", ":", "]", "\n", "", "real_chars", "=", "[", "]", "\n", "for", "char", "in", "chars", ":", "\n", "        ", "if", "char", "in", "[", "\"<s>\"", ",", "\"</s>\"", ",", "\"<pad>\"", "]", ":", "\n", "            ", "break", "\n", "", "real_chars", ".", "append", "(", "char", ")", "\n", "", "return", "separator", ".", "join", "(", "real_chars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate": [[59, 72], ["zip", "editdistance.eval", "cers.append", "sum", "len", "hyp.split", "ref.split", "len"], "function", ["None"], ["", "def", "char_error_rate", "(", "hyps", ",", "refs", ",", "tokenized", "=", "False", ",", "average", "=", "True", ")", ":", "\n", "    ", "cers", "=", "[", "]", "\n", "for", "hyp", ",", "ref", "in", "zip", "(", "hyps", ",", "refs", ")", ":", "\n", "        ", "if", "tokenized", ":", "\n", "            ", "hyp", ",", "ref", "=", "hyp", ".", "split", "(", ")", ",", "ref", ".", "split", "(", ")", "\n", "", "edit_ops", "=", "editdistance", ".", "eval", "(", "hyp", ",", "ref", ")", "\n", "if", "not", "ref", ":", "\n", "# TODO this is a BUG and needs to be fixed", "\n", "            ", "continue", "\n", "", "cers", ".", "append", "(", "edit_ops", "/", "len", "(", "ref", ")", ")", "\n", "", "if", "average", ":", "\n", "        ", "return", "sum", "(", "cers", ")", "/", "len", "(", "cers", ")", "\n", "", "return", "cers", "\n", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_baseline_cognates_classification.cat_examples": [[25, 29], ["None"], "function", ["None"], ["def", "cat_examples", "(", "dataset", ",", "text_field", ")", ":", "\n", "    ", "dataset", ".", "fields", "[", "\"text\"", "]", "=", "text_field", "\n", "for", "example", "in", "dataset", ".", "examples", ":", "\n", "        ", "example", ".", "text", "=", "example", ".", "src", "+", "example", ".", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_baseline_cognates_classification.main": [[31, 210], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "torchtext.data.Field", "torchtext.data.Field", "torch.device", "torchtext.data.TabularDataset.splits", "train_baseline_cognates_classification.cat_examples", "train_baseline_cognates_classification.cat_examples", "train_baseline_cognates_classification.cat_examples", "data.Field.build_vocab", "experiment.save_vocab", "experiment.save_vocab", "torchtext.data.Iterator.splits", "transformers.BertConfig", "transformers.BertForSequenceClassification().to", "torch.optim.Adam", "range", "logging.info", "logging.info", "logging.info", "torch.load", "torch.load.eval", "os.path.join", "os.path.join", "torch.load.parameters", "enumerate", "torch.no_grad", "enumerate", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.sum", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "torch.cuda.is_available", "len", "transformers.BertForSequenceClassification", "torch.load.", "loss.backward", "logging.info", "optim.Adam.step", "optim.Adam.zero_grad", "zip", "len", "numpy.std", "numpy.std", "experiment.get_timestamp", "s.split", "len", "train_batch.text.to", "torch.load.eval", "torch.load.train", "torch.functional.F.softmax", "train_batch.label.to", "torch.no_grad", "enumerate", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.sum", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "true_scores.append", "false_scores.append", "zip", "len", "numpy.std", "numpy.std", "torch.save", "logging.info", "torch.load.", "prob.cpu().numpy", "prob.cpu().numpy", "parser.parse_args.data_prefix.replace", "torch.functional.F.softmax", "true_scores.append", "false_scores.append", "prob.cpu", "prob.cpu", "torch.load.", "prob.cpu().numpy", "prob.cpu().numpy", "prob.cpu", "prob.cpu"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_baseline_cognates_classification.cat_examples", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_baseline_cognates_classification.cat_examples", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_baseline_cognates_classification.cat_examples", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden-size\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention-heads\"", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--delay-update\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Update model every N steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "1000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--patience\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of validations witout improvement before finishing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning-rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-frequency\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "f\"_hidden{args.hidden_size}\"", "+", "\n", "f\"_attheads{args.attention_heads}\"", "+", "\n", "f\"_layers{args.layers}\"", "+", "\n", "f\"_batch{args.batch_size}\"", "+", "\n", "f\"_patence{args.patience}\"", "+", "\n", "f\"_delay{args.delay_update}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"cognates_class_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "\n", "text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "lambda", "s", ":", "s", ".", "split", "(", ")", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "labels_field", "=", "data", ".", "Field", "(", "sequential", "=", "False", ",", "use_vocab", "=", "False", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "train_data", ",", "val_data", ",", "test_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "args", ".", "data_prefix", ",", "train", "=", "'train.txt'", ",", "\n", "validation", "=", "'eval.txt'", ",", "test", "=", "'test.txt'", ",", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'src'", ",", "text_field", ")", ",", "(", "'tgt'", ",", "text_field", ")", ",", "\n", "(", "'label'", ",", "labels_field", ")", "]", ")", "\n", "\n", "cat_examples", "(", "train_data", ",", "text_field", ")", "\n", "cat_examples", "(", "val_data", ",", "text_field", ")", "\n", "cat_examples", "(", "test_data", ",", "text_field", ")", "\n", "\n", "text_field", ".", "build_vocab", "(", "train_data", ")", "\n", "save_vocab", "(", "\n", "text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "\n", "train_iter", ",", "val_iter", ",", "test_iter", "=", "data", ".", "Iterator", ".", "splits", "(", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", ",", "batch_sizes", "=", "[", "args", ".", "batch_size", "]", "*", "3", ",", "\n", "shuffle", "=", "True", ",", "device", "=", "device", ",", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "text", ")", ")", "\n", "\n", "config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "len", "(", "text_field", ".", "vocab", ")", ",", "\n", "is_decoder", "=", "False", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_hidden_layers", "=", "args", ".", "layers", ",", "\n", "num_attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "intermediate_size", "=", "2", "*", "args", ".", "hidden_size", ",", "\n", "hidden_act", "=", "'relu'", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "num_labels", "=", "2", ")", "\n", "\n", "model", "=", "BertForSequenceClassification", "(", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "step", "=", "0", "\n", "best_f_score", "=", "0.0", "\n", "stalled", "=", "0", "\n", "for", "_", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "            ", "break", "\n", "", "for", "_", ",", "train_batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "            ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "                ", "break", "\n", "", "step", "+=", "1", "\n", "\n", "loss", ",", "_", "=", "model", "(", "\n", "train_batch", ".", "text", ".", "to", "(", "device", ")", ",", "\n", "labels", "=", "train_batch", ".", "label", ".", "to", "(", "device", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"step: %d, train loss = %.3g\"", ",", "step", ",", "loss", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "step", "%", "args", ".", "validation_frequency", "==", "args", ".", "validation_frequency", "-", "1", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "false_scores", "=", "[", "]", "\n", "true_scores", "=", "[", "]", "\n", "for", "j", ",", "val_ex", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                        ", "score", "=", "F", ".", "softmax", "(", "model", "(", "val_ex", ".", "text", ")", "[", "0", "]", ",", "dim", "=", "1", ")", "[", ":", ",", "1", "]", "\n", "for", "prob", ",", "label", "in", "zip", "(", "score", ",", "val_ex", ".", "label", ")", ":", "\n", "                            ", "if", "label", "==", "1", ":", "\n", "                                ", "true_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                                ", "false_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "if", "j", ">", "10", ":", "\n", "                            ", "break", "\n", "\n", "", "", "pos_mean", "=", "np", ".", "mean", "(", "true_scores", ")", "\n", "neg_mean", "=", "np", ".", "mean", "(", "false_scores", ")", "\n", "boundary", "=", "(", "pos_mean", "+", "neg_mean", ")", "/", "2", "\n", "\n", "true_positive", "=", "np", ".", "sum", "(", "true_scores", ">", "boundary", ")", "\n", "false_positive", "=", "np", ".", "sum", "(", "false_scores", ">", "boundary", ")", "\n", "precision", "=", "(", "\n", "true_positive", "/", "(", "true_positive", "+", "false_positive", ")", ")", "\n", "recall", "=", "true_positive", "/", "len", "(", "true_scores", ")", "\n", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"neural true  scores: %.3f +/- %.3f\"", ",", "\n", "pos_mean", ",", "np", ".", "std", "(", "true_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"neural false scores: %.3f +/- %.3f\"", ",", "\n", "neg_mean", ",", "np", ".", "std", "(", "false_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"Precision: %.3f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Recall: %.3f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"F1-score: %.3f\"", ",", "f_score", ")", "\n", "\n", "if", "f_score", ">", "best_f_score", ":", "\n", "                        ", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "best_f_score", "=", "f_score", "\n", "stalled", "=", "0", "\n", "", "else", ":", "\n", "                        ", "stalled", "+=", "1", "\n", "\n", "", "if", "stalled", ">", "0", ":", "\n", "                        ", "logging", ".", "info", "(", "\"Stalled %d times.\"", ",", "stalled", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"TRANING FINISHED, TESTING\"", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "false_scores", "=", "[", "]", "\n", "true_scores", "=", "[", "]", "\n", "for", "j", ",", "test_ex", "in", "enumerate", "(", "test_iter", ")", ":", "\n", "            ", "score", "=", "F", ".", "softmax", "(", "model", "(", "test_ex", ".", "text", ")", "[", "0", "]", ",", "dim", "=", "1", ")", "[", ":", ",", "1", "]", "\n", "for", "prob", ",", "label", "in", "zip", "(", "score", ",", "test_ex", ".", "label", ")", ":", "\n", "                ", "if", "label", "==", "1", ":", "\n", "                    ", "true_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "false_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "pos_mean", "=", "np", ".", "mean", "(", "true_scores", ")", "\n", "neg_mean", "=", "np", ".", "mean", "(", "false_scores", ")", "\n", "boundary", "=", "(", "pos_mean", "+", "neg_mean", ")", "/", "2", "\n", "\n", "true_positive", "=", "np", ".", "sum", "(", "true_scores", ">", "boundary", ")", "\n", "false_positive", "=", "np", ".", "sum", "(", "false_scores", ">", "boundary", ")", "\n", "precision", "=", "true_positive", "/", "(", "true_positive", "+", "false_positive", ")", "\n", "recall", "=", "true_positive", "/", "len", "(", "true_scores", ")", "\n", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"neural true  scores: %.3f +/- %.3f\"", ",", "\n", "pos_mean", ",", "np", ".", "std", "(", "true_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"neural false scores: %.3f +/- %.3f\"", ",", "\n", "neg_mean", ",", "np", ".", "std", "(", "false_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"Precision: %.3f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Recall: %.3f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"F1-score: %.3f\"", ",", "f_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_statistical.main": [[15, 146], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.TabularDataset.splits", "data.Field.build_vocab", "data.Field.build_vocab", "experiment.save_vocab", "experiment.save_vocab", "logging.info", "torchtext.data.Iterator.splits", "statistical_model.EditDistStatModel", "logging.info", "range", "logging.info", "os.path.join", "os.path.join", "parser.parse_args.data_prefix.replace", "statistical_model.EditDistStatModel.", "stat_expecations.append", "experiment.get_timestamp", "len", "statistical_model.EditDistStatModel.maximize_expectation", "logging.info", "logging.info", "logging.info", "s.split", "s.split", "entropy.cpu", "torch.save", "torch.no_grad", "enumerate", "logging.info", "logging.info", "statistical_model.EditDistStatModel.viterbi", "logging.info", "torch.save", "logging.info", "transliteration_utils.decode_ids", "transliteration_utils.decode_ids", "logging.info", "logging.info", "statistical_model.EditDistStatModel.weights.exp"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.statistical_model.EditDistStatModel.maximize_expectation", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.NeuralEditDistBase.viterbi", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.decode_ids"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, source side are space separated tokens.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, target side are space separated tokens.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--patience\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Early stopping patience.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning-rate\"", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "\"src_tokenized\"", "if", "args", ".", "src_tokenized", "else", "\"\"", "+", "\n", "\"tgt_tokenized\"", "if", "args", ".", "tgt_tokenized", "else", "\"\"", "+", "\n", "f\"_learning_rate_{args.learning_rate}\"", "+", "\n", "f\"_patience{args.patience}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"edit_stat_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "\n", "src_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "args", ".", "src_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "tgt_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "args", ".", "tgt_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "\n", "train_data", ",", "val_data", ",", "test_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "args", ".", "data_prefix", ",", "train", "=", "'train.txt'", ",", "\n", "validation", "=", "'eval.txt'", ",", "test", "=", "'test.txt'", ",", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'ar'", ",", "src_text_field", ")", ",", "(", "'en'", ",", "tgt_text_field", ")", "]", ")", "\n", "\n", "# Use val data beacuse iterating through train data would take agas.", "\n", "src_text_field", ".", "build_vocab", "(", "val_data", ")", "\n", "tgt_text_field", ".", "build_vocab", "(", "val_data", ")", "\n", "\n", "save_vocab", "(", "\n", "src_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "tgt_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "logging", ".", "info", "(", "\"Loaded data, created vocabularies..\"", ")", "\n", "\n", "# pylint: disable=W0632", "\n", "train_iter", ",", "val_iter", ",", "_", "=", "data", ".", "Iterator", ".", "splits", "(", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", ",", "batch_sizes", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "shuffle", "=", "True", ",", "device", "=", "0", ",", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "ar", ")", ")", "\n", "# pylint: enable=W0632", "\n", "\n", "model", "=", "EditDistStatModel", "(", "src_text_field", ".", "vocab", ",", "tgt_text_field", ".", "vocab", ")", "\n", "\n", "smallest_tgttropy", "=", "1e9", "\n", "examples", "=", "0", "\n", "stat_expecations", "=", "[", "]", "\n", "logging", ".", "info", "(", "\"Training starts.\"", ")", "\n", "best_val_score", "=", "0", "\n", "stalled", "=", "0", "\n", "for", "_", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "for", "train_ex", "in", "train_iter", ":", "\n", "            ", "examples", "+=", "1", "\n", "exp_counts", "=", "model", "(", "train_ex", ".", "ar", ",", "train_ex", ".", "en", ")", "\n", "stat_expecations", ".", "append", "(", "exp_counts", ")", "\n", "\n", "if", "examples", "%", "10", "==", "9", ":", "\n", "                ", "model", ".", "maximize_expectation", "(", "\n", "stat_expecations", ",", "learning_rate", "=", "args", ".", "learning_rate", ")", "\n", "entropy", "=", "-", "(", "\n", "model", ".", "weights", "*", "model", ".", "weights", ".", "exp", "(", ")", ")", ".", "sum", "(", ")", "\n", "logging", ".", "info", "(", "\"stat. model entropy = %.10g\"", ",", "entropy", ".", "cpu", "(", ")", ")", "\n", "stat_expecations", "=", "[", "]", "\n", "\n", "if", "entropy", "<", "smallest_tgttropy", ":", "\n", "                    ", "smallest_tgttropy", "=", "entropy", "\n", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "\n", "", "", "if", "examples", "%", "200", "==", "199", ":", "\n", "                ", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"Validation:\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "total_score", "=", "0", "\n", "val_examples", "=", "0", "\n", "for", "j", ",", "val_ex", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                        ", "val_examples", "+=", "1", "\n", "stat_score", "=", "model", ".", "viterbi", "(", "val_ex", ".", "ar", ",", "val_ex", ".", "en", ")", "\n", "total_score", "+=", "stat_score", "\n", "\n", "if", "j", "<", "10", ":", "\n", "                            ", "src_string", "=", "decode_ids", "(", "\n", "val_ex", ".", "ar", "[", "0", "]", ",", "src_text_field", ")", "\n", "tgt_string", "=", "decode_ids", "(", "\n", "val_ex", ".", "en", "[", "0", "]", ",", "tgt_text_field", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "\"%s -> %s  %f\"", ",", "src_string", ",", "tgt_string", ",", "\n", "stat_score", ")", "\n", "\n", "", "if", "j", "==", "10", ":", "\n", "                            ", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "", "", "val_score", "=", "total_score", "/", "val_examples", "\n", "logging", ".", "info", "(", "\n", "\"Validation score: %f\"", ",", "val_score", ")", "\n", "\n", "if", "val_score", ">", "best_val_score", ":", "\n", "                        ", "best_val_score", "=", "val_score", "\n", "stalled", "=", "0", "\n", "logging", ".", "info", "(", "\"New maximum!\"", ")", "\n", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "", "else", ":", "\n", "                        ", "stalled", "+=", "1", "\n", "logging", ".", "info", "(", "\n", "\"Previous best %f, stalled %d times.\"", ",", "\n", "best_val_score", ",", "stalled", ")", "\n", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "                        ", "break", "\n", "", "", "", "", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "            ", "break", "\n", "\n", "", "", "logging", ".", "info", "(", "\"Training finished, best model was saved.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.cnn.CNNEncoder.__init__": [[17, 40], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Dropout", "torch.nn.LayerNorm", "ValueError", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "cnn.CNNEncoder.cnn_layers.append", "cnn.CNNEncoder.cnn_norms.append", "torch.nn.Conv1d", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "vocab", ",", "hidden_size", ",", "embedding_size", ",", "layers", "=", "0", ",", "\n", "window", "=", "3", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "window", "%", "2", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only even window sizes are allowed.\"", ")", "\n", "\n", "", "self", ".", "layers", "=", "layers", "\n", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "vocab", ")", ",", "embedding_size", ")", "\n", "self", ".", "pos_embeddings", "=", "nn", ".", "Embedding", "(", "512", ",", "embedding_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "embedd_norm", "=", "nn", ".", "LayerNorm", "(", "embedding_size", ")", "\n", "\n", "if", "layers", ">", "0", ":", "\n", "            ", "self", ".", "cnn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "cnn_norms", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "                ", "self", ".", "cnn_layers", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "embedding_size", ",", "2", "*", "hidden_size", ",", "\n", "window", ",", "padding", "=", "window", "-", "1", ")", ")", "\n", "self", ".", "cnn_norms", ".", "append", "(", "nn", ".", "LayerNorm", "(", "hidden_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.cnn.CNNEncoder.forward": [[41, 64], ["torch.arange().unsqueeze().to", "cnn.CNNEncoder.embedd_norm", "hasattr", "cnn.CNNEncoder.embeddings", "cnn.CNNEncoder.pos_embeddings", "cnn.CNNEncoder.dropout", "range", "torch.arange().unsqueeze", "cnn.CNNEncoder.cnn_layer().transpose", "cnn.CNNEncoder.cnn_norm", "attention_mask.float().unsqueeze", "torch.functional.F.glu", "attention_mask.float().unsqueeze", "cnn.CNNEncoder.dropout", "torch.arange", "cnn.CNNEncoder.dropout", "cnn.CNNEncoder.cnn_layer", "input_ids.size", "attention_mask.float", "input_ids.size", "attention_mask.float", "cnn.CNNEncoder.transpose", "cnn.CNNEncoder.transpose"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ")", ":", "\n", "        ", "input_range", "=", "torch", ".", "arange", "(", "\n", "input_ids", ".", "size", "(", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "\n", "output", "=", "(", "\n", "self", ".", "embeddings", "(", "input_ids", ")", "+", "self", ".", "pos_embeddings", "(", "input_range", ")", ")", "\n", "output", "=", "self", ".", "embedd_norm", "(", "self", ".", "dropout", "(", "output", ")", ")", "\n", "\n", "# Backward compatibility of saved models", "\n", "if", "hasattr", "(", "self", ",", "\"layers\"", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "                ", "cnn_output", "=", "output", "*", "attention_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "cnn_output", "=", "F", ".", "glu", "(", "self", ".", "cnn_layers", "[", "i", "]", "(", "\n", "output", ".", "transpose", "(", "2", ",", "1", ")", ")", ".", "transpose", "(", "\n", "2", ",", "1", ")", ")", "[", ":", ",", ":", "input_ids", ".", "size", "(", "1", ")", "]", "\n", "output", "=", "self", ".", "cnn_norms", "[", "i", "]", "(", "self", ".", "dropout", "(", "cnn_output", ")", "+", "output", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cnn_layer", "is", "not", "None", ":", "\n", "                ", "output", "=", "output", "*", "attention_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "output", "=", "self", ".", "cnn_layer", "(", "output", ".", "transpose", "(", "2", ",", "1", ")", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "cnn_norm", "(", "self", ".", "dropout", "(", "output", ")", ")", "\n", "\n", "", "", "return", "output", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.cnn.CNNDecoder.__init__": [[73, 108], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Dropout", "torch.nn.LayerNorm", "ValueError", "NotImplementedError", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "cnn.CNNDecoder.cnn_layers.append", "cnn.CNNDecoder.cnn_norms.append", "torch.nn.Conv1d", "torch.nn.LayerNorm", "cnn.CNNDecoder.atts.append", "cnn.CNNDecoder.att_norms.append", "transformers.modeling_bert.BertSelfAttention", "torch.nn.LayerNorm", "rnn.AttConfig"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "vocab", ",", "hidden_size", ",", "embedding_size", ",", "layers", "=", "0", ",", "window", "=", "3", ",", "\n", "use_attention", "=", "False", ",", "attention_heads", "=", "8", ",", "dropout", "=", "0.1", ",", "\n", "output_proj", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "window", "%", "2", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only even window sizes are allowed.\"", ")", "\n", "", "if", "output_proj", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "vocab", ")", ",", "embedding_size", ")", "\n", "self", ".", "pos_embeddings", "=", "nn", ".", "Embedding", "(", "512", ",", "embedding_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "use_attention", "=", "use_attention", "\n", "self", ".", "layers", "=", "layers", "\n", "\n", "self", ".", "embedd_norm", "=", "nn", ".", "LayerNorm", "(", "embedding_size", ")", "\n", "\n", "if", "layers", ">", "0", ":", "\n", "            ", "self", ".", "cnn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "cnn_norms", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "atts", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "att_norms", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "\n", "                ", "self", ".", "cnn_layers", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "embedding_size", ",", "2", "*", "hidden_size", ",", "\n", "window", ",", "padding", "=", "window", "-", "1", ")", ")", "\n", "self", ".", "cnn_norms", ".", "append", "(", "nn", ".", "LayerNorm", "(", "hidden_size", ")", ")", "\n", "\n", "if", "use_attention", ":", "\n", "                    ", "self", ".", "atts", ".", "append", "(", "BertSelfAttention", "(", "\n", "AttConfig", "(", "hidden_size", ",", "attention_heads", ",", "True", ",", "dropout", ")", ")", ")", "\n", "self", ".", "att_norms", ".", "append", "(", "nn", ".", "LayerNorm", "(", "hidden_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.cnn.CNNDecoder.forward": [[109, 152], ["torch.arange().unsqueeze().to", "cnn.CNNDecoder.embedd_norm", "hasattr", "cnn.CNNDecoder.embeddings", "cnn.CNNDecoder.pos_embeddings", "cnn.CNNDecoder.dropout", "range", "torch.arange().unsqueeze", "cnn.CNNDecoder.cnn_norm", "encoder_attention_mask.unsqueeze().unsqueeze", "cnn.CNNDecoder.att_norm", "attention_mask.float().unsqueeze", "torch.functional.F.glu", "encoder_attention_mask.unsqueeze().unsqueeze", "attentions.append", "attention_mask.float().unsqueeze", "cnn.CNNDecoder.cnn_layer().transpose", "cnn.CNNDecoder.att", "torch.arange", "cnn.CNNDecoder.dropout", "encoder_attention_mask.unsqueeze", "cnn.CNNDecoder.dropout", "input_ids.size", "attention_mask.float", "input_ids.size", "encoder_attention_mask.unsqueeze", "cnn.CNNDecoder.dropout", "attention_mask.float", "cnn.CNNDecoder.cnn_layer", "input_ids.size", "cnn.CNNDecoder.transpose", "cnn.CNNDecoder.transpose"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "\n", "encoder_hidden_states", "=", "None", ",", "encoder_attention_mask", "=", "None", ")", ":", "\n", "        ", "input_range", "=", "torch", ".", "arange", "(", "\n", "input_ids", ".", "size", "(", "1", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "\n", "output", "=", "(", "\n", "self", ".", "embeddings", "(", "input_ids", ")", "+", "self", ".", "pos_embeddings", "(", "input_range", ")", ")", "\n", "output", "=", "self", ".", "embedd_norm", "(", "self", ".", "dropout", "(", "output", ")", ")", "\n", "\n", "attentions", "=", "[", "]", "\n", "if", "hasattr", "(", "self", ",", "\"layers\"", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "                ", "cnn_output", "=", "output", "*", "attention_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "cnn_output", "=", "F", ".", "glu", "(", "self", ".", "cnn_layers", "[", "i", "]", "(", "\n", "output", ".", "transpose", "(", "2", ",", "1", ")", ")", ".", "transpose", "(", "\n", "2", ",", "1", ")", ")", "[", ":", ",", ":", "input_ids", ".", "size", "(", "1", ")", "]", "\n", "output", "=", "self", ".", "cnn_norms", "[", "i", "]", "(", "self", ".", "dropout", "(", "cnn_output", ")", "+", "output", ")", "\n", "\n", "if", "self", ".", "use_attention", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                    ", "unsq_enc_att_mask", "=", "(", "\n", "encoder_attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "context", ",", "att_dist", "=", "self", ".", "atts", "[", "i", "]", "(", "\n", "output", ",", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "unsq_enc_att_mask", ")", "\n", "attentions", ".", "append", "(", "att_dist", ")", "\n", "output", "=", "self", ".", "att_norms", "[", "i", "]", "(", "output", "+", "self", ".", "dropout", "(", "context", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cnn_layer", "is", "not", "None", ":", "\n", "                ", "cnn_output", "=", "output", "*", "attention_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "cnn_output", "=", "self", ".", "cnn_layer", "(", "\n", "output", ".", "transpose", "(", "2", ",", "1", ")", ")", ".", "transpose", "(", "\n", "2", ",", "1", ")", "[", ":", ",", ":", "input_ids", ".", "size", "(", "1", ")", "]", "\n", "output", "=", "self", ".", "cnn_norm", "(", "cnn_output", "+", "output", ")", "\n", "\n", "", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "                ", "unsq_enc_att_mask", "=", "(", "\n", "encoder_attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "context", "=", "self", ".", "att", "(", "\n", "output", ",", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "unsq_enc_att_mask", ")", "[", "0", "]", "\n", "output", "=", "self", ".", "att_norm", "(", "output", "+", "self", ".", "dropout", "(", "context", ")", ")", "\n", "\n", "", "", "return", "output", ",", "None", ",", "attentions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.classification_data_for_cognates.main": [[12, 55], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "random.seed", "collections.defaultdict", "csv.DictReader", "parser.parse_args.dataset_file.close", "print", "collections.defaultdict.items", "len", "print", "list", "range", "print", "random.shuffle", "per_class_listing[].append", "collections.defaultdict.keys", "random.choice", "random.choice", "random.choice", "classification_examples.append", "print", "argparse.FileType", "random.choice", "classification_examples.append"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"dataset_file\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "85604", ")", "\n", "parser", ".", "add_argument", "(", "\"--negative-oversample\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "\n", "per_class_listing", "=", "defaultdict", "(", "list", ")", "\n", "reader", "=", "csv", ".", "DictReader", "(", "args", ".", "dataset_file", ",", "dialect", "=", "'excel-tab'", ")", "\n", "for", "item", "in", "reader", ":", "\n", "        ", "per_class_listing", "[", "item", "[", "\"COGNATE_CLASS\"", "]", "]", ".", "append", "(", "item", "[", "'TOKENS'", "]", ")", "\n", "\n", "", "args", ".", "dataset_file", ".", "close", "(", ")", "\n", "print", "(", "\"Dataset loaded in memory.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "classification_examples", "=", "[", "]", "\n", "for", "_", ",", "instances", "in", "per_class_listing", ".", "items", "(", ")", ":", "\n", "        ", "for", "inst1", "in", "instances", ":", "\n", "            ", "for", "inst2", "in", "instances", ":", "\n", "                ", "classification_examples", ".", "append", "(", "f\"{inst1}\\t{inst2}\\t1\"", ")", "\n", "\n", "", "", "", "n_positive_examples", "=", "len", "(", "classification_examples", ")", "\n", "print", "(", "f\"Generated {n_positive_examples} positive examples.\"", ",", "\n", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "classes", "=", "list", "(", "per_class_listing", ".", "keys", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "negative_oversample", "*", "n_positive_examples", ")", ":", "\n", "        ", "cls_1", "=", "random", ".", "choice", "(", "classes", ")", "\n", "cls_2", "=", "cls_1", "\n", "while", "cls_1", "==", "cls_2", ":", "\n", "            ", "cls_2", "=", "random", ".", "choice", "(", "classes", ")", "\n", "\n", "", "inst1", "=", "random", ".", "choice", "(", "per_class_listing", "[", "cls_1", "]", ")", "\n", "inst2", "=", "random", ".", "choice", "(", "per_class_listing", "[", "cls_2", "]", ")", "\n", "classification_examples", ".", "append", "(", "f\"{inst1}\\t{inst2}\\t0\"", ")", "\n", "", "print", "(", "\"Generated negative samples.\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "random", ".", "shuffle", "(", "classification_examples", ")", "\n", "\n", "for", "ex", "in", "classification_examples", ":", "\n", "        ", "print", "(", "ex", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_transliteration_classification.main": [[24, 284], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "torchtext.data.Field", "torchtext.data.Field", "torch.device", "torchtext.data.TabularDataset.splits", "data.Field.build_vocab", "data.Field.build_vocab", "experiment.save_vocab", "experiment.save_vocab", "torchtext.data.Iterator.splits", "models.EditDistNeuralModelConcurrent().to", "logging.info", "torch.nn.BCELoss", "torch.nn.KLDivLoss", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "open", "open", "logging.info", "time.time", "range", "logging.info", "logging.info", "logging.info", "torch.load", "torch.load.eval", "torchtext.data.Field", "data.Field.build_vocab", "os.path.join", "os.path.join", "torch.load.parameters", "os.path.join", "os.path.join", "torch.no_grad", "enumerate", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.sum", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "ValueError", "torch.cuda.is_available", "models.EditDistNeuralModelConcurrent", "sum", "target.unsqueeze().unsqueeze", "torch.load.", "nn.BCELoss.", "nn.KLDivLoss.sum", "nn.CrossEntropyLoss.", "loss.backward", "logging.info", "optim.Adam.step", "optim.Adam.zero_grad", "print", "zip", "len", "numpy.std", "numpy.std", "experiment.get_timestamp", "len", "src_mask.unsqueeze", "tgt_mask.unsqueeze", "logprobs.exp", "action_scores.reshape", "torch.full().to().reshape", "torch.load.eval", "torch.load.train", "torch.load.probabilities", "s.split", "x.reshape().size", "target.unsqueeze", "nn.KLDivLoss.", "action_mask.sum", "torch.no_grad", "enumerate", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.sum", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "print", "logging.info", "true_scores.append", "false_scores.append", "s.split", "torch.load.parameters", "action_scores.reshape", "expected_counts.reshape", "torch.full().to", "zip", "len", "numpy.std", "numpy.std", "torch.save", "time.time", "logging.info", "prob.cpu().numpy", "prob.cpu().numpy", "x.reshape", "torch.load.probabilities", "torch.full", "true_scores.append", "false_scores.append", "prob.cpu", "prob.cpu", "prob.cpu().numpy", "prob.cpu().numpy", "parser.parse_args.data_prefix.replace", "prob.cpu", "prob.cpu"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelConcurrent.probabilities", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelConcurrent.probabilities"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--share-encoders\"", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-type\"", ",", "default", "=", "'transformer'", ",", "\n", "choices", "=", "[", "\"transformer\"", ",", "\"rnn\"", ",", "\"embeddings\"", ",", "\"cnn\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--embedding-dim\"", ",", "default", "=", "64", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden-size\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention-heads\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--delay-update\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Update model every N steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--interpretation-loss\"", ",", "default", "=", "None", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--bce-loss\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--positive-example-loss\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--negative-example-loss\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, source side is space-separated.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, target side are space-separated.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--patience\"", ",", "default", "=", "20", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of no-improvement validations before \"", "\n", "\"early finishing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning-rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--validation-frequency\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# TODO PARAMTERICZE LOSSES", "\n", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "f\"_model{args.model_type}\"", "+", "\n", "f\"_hidden{args.hidden_size}\"", "+", "\n", "f\"_attheads{args.attention_heads}\"", "+", "\n", "f\"_layers{args.layers}\"", "+", "\n", "f\"_interpretationLoss{args.interpretation_loss}\"", "+", "\n", "f\"_posLoss{args.positive_example_loss}\"", "+", "\n", "f\"_negLoss{args.negative_example_loss}\"", "+", "\n", "f\"_interpretationLoss{args.interpretation_loss}\"", "+", "\n", "f\"_batch{args.batch_size}\"", "+", "\n", "f\"_patence{args.patience}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"edit_class_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "# tb_writer = SummaryWriter(experiment_dir)", "\n", "\n", "src_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "args", ".", "src_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "if", "args", ".", "share_encoders", ":", "\n", "        ", "if", "args", ".", "src_tokenized", "!=", "args", ".", "tgt_tokenized", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Source and target must be tokenized the same way when \"", "\n", "\"sharing encoders.\"", ")", "\n", "", "tgt_text_field", "=", "src_text_field", "\n", "", "else", ":", "\n", "        ", "tgt_text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "args", ".", "tgt_tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "", "labels_field", "=", "data", ".", "Field", "(", "sequential", "=", "False", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "train_data", ",", "val_data", ",", "test_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "args", ".", "data_prefix", ",", "train", "=", "'train.txt'", ",", "\n", "validation", "=", "'eval.txt'", ",", "test", "=", "'test.txt'", ",", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'ar'", ",", "src_text_field", ")", ",", "(", "'en'", ",", "tgt_text_field", ")", ",", "\n", "(", "'labels'", ",", "labels_field", ")", "]", ")", "\n", "\n", "src_text_field", ".", "build_vocab", "(", "train_data", ")", "\n", "if", "not", "args", ".", "share_encoders", ":", "\n", "        ", "tgt_text_field", ".", "build_vocab", "(", "train_data", ")", "\n", "", "labels_field", ".", "build_vocab", "(", "train_data", ")", "\n", "true_class_label", "=", "labels_field", ".", "vocab", ".", "stoi", "[", "'1'", "]", "\n", "\n", "save_vocab", "(", "\n", "src_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "tgt_text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "\n", "train_iter", ",", "val_iter", ",", "test_iter", "=", "data", ".", "Iterator", ".", "splits", "(", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", ",", "batch_sizes", "=", "[", "args", ".", "batch_size", "]", "*", "3", ",", "\n", "shuffle", "=", "True", ",", "device", "=", "device", ",", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "ar", ")", ")", "\n", "\n", "model", "=", "EditDistNeuralModelConcurrent", "(", "\n", "src_text_field", ".", "vocab", ",", "tgt_text_field", ".", "vocab", ",", "device", ",", "\n", "model_type", "=", "args", ".", "model_type", ",", "\n", "hidden_dim", "=", "args", ".", "hidden_size", ",", "\n", "hidden_layers", "=", "args", ".", "layers", ",", "\n", "attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "share_encoders", "=", "args", ".", "share_encoders", ")", ".", "to", "(", "device", ")", "\n", "logging", ".", "info", "(", "\n", "\"Model parameters: %dk\"", ",", "\n", "sum", "(", "[", "x", ".", "reshape", "(", "-", "1", ")", ".", "size", "(", "0", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", "]", ")", "/", "1000", ")", "\n", "\n", "class_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "kl_div_loss", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'none'", ")", "\n", "xent_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "train_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"train_loss.tsv\"", ")", ",", "\"w\"", ")", "\n", "valid_curve_file", "=", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"valid_f1.tsv\"", ")", ",", "\"w\"", ")", "\n", "\n", "step", "=", "0", "\n", "stalled", "=", "0", "\n", "best_f_score", "=", "0", "\n", "best_boundary", "=", "0.5", "\n", "last_save_time", "=", "0", "\n", "\n", "logging", ".", "info", "(", "\"Start training.\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "            ", "break", "\n", "", "for", "train_batch", "in", "train_iter", ":", "\n", "            ", "if", "stalled", ">", "args", ".", "patience", ":", "\n", "                ", "break", "\n", "", "step", "+=", "1", "\n", "\n", "target", "=", "(", "train_batch", ".", "labels", "==", "true_class_label", ")", ".", "float", "(", ")", "\n", "pos_mask", "=", "target", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "neg_mask", "=", "1", "-", "pos_mask", "\n", "\n", "src_mask", "=", "(", "train_batch", ".", "ar", "!=", "model", ".", "src_pad", ")", ".", "float", "(", ")", "\n", "tgt_mask", "=", "(", "train_batch", ".", "en", "!=", "model", ".", "tgt_pad", ")", ".", "float", "(", ")", "\n", "\n", "action_mask", "=", "src_mask", ".", "unsqueeze", "(", "2", ")", "*", "tgt_mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "action_scores", ",", "expected_counts", ",", "logprobs", ",", "distorted_probs", "=", "model", "(", "\n", "train_batch", ".", "ar", ",", "train_batch", ".", "en", ")", "\n", "\n", "bce_loss", "=", "class_loss", "(", "logprobs", ".", "exp", "(", ")", ",", "target", ")", "\n", "pos_samples_loss", "=", "kl_div_loss", "(", "\n", "action_scores", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "expected_counts", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", ".", "sum", "(", "1", ")", "\n", "neg_samples_loss", "=", "xent_loss", "(", "\n", "action_scores", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "torch", ".", "full", "(", "action_scores", ".", "shape", "[", ":", "-", "1", "]", ",", "\n", "3", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", ".", "reshape", "(", "-", "1", ")", ")", "\n", "\n", "pos_loss", "=", "(", "\n", "(", "action_mask", "*", "pos_mask", ")", ".", "reshape", "(", "-", "1", ")", "*", "pos_samples_loss", ")", ".", "mean", "(", ")", "\n", "neg_loss", "=", "(", "\n", "(", "action_mask", "*", "neg_mask", ")", ".", "reshape", "(", "-", "1", ")", "*", "neg_samples_loss", ")", ".", "mean", "(", ")", "\n", "loss", "=", "(", "\n", "args", ".", "positive_example_loss", "*", "pos_loss", "+", "\n", "args", ".", "negative_example_loss", "*", "neg_loss", "+", "\n", "args", ".", "bce_loss", "*", "bce_loss", ")", "\n", "\n", "distortion_loss", "=", "0", "\n", "if", "args", ".", "interpretation_loss", "is", "not", "None", ":", "\n", "                ", "distortion_loss", "=", "(", "\n", "(", "action_mask", "*", "distorted_probs", ")", ".", "sum", "(", ")", "/", "action_mask", ".", "sum", "(", ")", ")", "\n", "loss", "+=", "args", ".", "interpretation_loss", "*", "distortion_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "\"step: %d, train loss = %.3g (positive: %.3g, negative: %.3g, \"", "\n", "\"BCE: %.3g, \"", "\"distortion: %.3g)\"", ",", "\n", "step", ",", "loss", ",", "pos_loss", ",", "neg_loss", ",", "bce_loss", ",", "distortion_loss", ")", "\n", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "print", "(", "f\"{step:d}\\t{loss:.3g}\"", ",", "file", "=", "train_curve_file", ")", "\n", "\n", "if", "step", "%", "args", ".", "validation_frequency", "==", "args", ".", "validation_frequency", "-", "1", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "false_scores", "=", "[", "]", "\n", "true_scores", "=", "[", "]", "\n", "for", "j", ",", "val_ex", "in", "enumerate", "(", "val_iter", ")", ":", "\n", "                        ", "score", "=", "model", ".", "probabilities", "(", "val_ex", ".", "ar", ",", "val_ex", ".", "en", ")", "[", "0", "]", "\n", "for", "prob", ",", "label", "in", "zip", "(", "score", ",", "val_ex", ".", "labels", ")", ":", "\n", "                            ", "if", "label", "==", "true_class_label", ":", "\n", "                                ", "true_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                                ", "false_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "if", "j", ">", "10", ":", "\n", "                            ", "break", "\n", "\n", "", "", "pos_mean", "=", "np", ".", "mean", "(", "true_scores", ")", "\n", "neg_mean", "=", "np", ".", "mean", "(", "false_scores", ")", "\n", "boundary", "=", "(", "pos_mean", "+", "neg_mean", ")", "/", "2", "\n", "\n", "true_positive", "=", "np", ".", "sum", "(", "true_scores", ">", "boundary", ")", "\n", "false_positive", "=", "np", ".", "sum", "(", "false_scores", ">", "boundary", ")", "\n", "precision", "=", "(", "\n", "true_positive", "/", "(", "true_positive", "+", "false_positive", ")", ")", "\n", "recall", "=", "true_positive", "/", "len", "(", "true_scores", ")", "\n", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"neural true  scores: %.3f +/- %.3f\"", ",", "\n", "pos_mean", ",", "np", ".", "std", "(", "true_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"neural false scores: %.3f +/- %.3f\"", ",", "\n", "neg_mean", ",", "np", ".", "std", "(", "false_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"Precision: %.3f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Recall: %.3f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"F1-score: %.3f\"", ",", "f_score", ")", "\n", "\n", "if", "f_score", ">", "best_f_score", ":", "\n", "                        ", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "best_f_score", "=", "f_score", "\n", "best_boundary", "=", "boundary", "\n", "stalled", "=", "0", "\n", "last_save_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "stalled", "+=", "1", "\n", "\n", "", "if", "stalled", ">", "0", ":", "\n", "                        ", "logging", ".", "info", "(", "\"Stalled %d times (best F score %.3f)\"", ",", "\n", "stalled", ",", "best_f_score", ")", "\n", "\n", "", "print", "(", "f\"{step:d}\\t{f_score:.3g}\"", ",", "file", "=", "valid_curve_file", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"TRANING FINISHED.\"", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "false_scores", "=", "[", "]", "\n", "true_scores", "=", "[", "]", "\n", "for", "j", ",", "test_ex", "in", "enumerate", "(", "test_iter", ")", ":", "\n", "            ", "score", "=", "model", ".", "probabilities", "(", "test_ex", ".", "ar", ",", "test_ex", ".", "en", ")", "[", "0", "]", "\n", "for", "prob", ",", "label", "in", "zip", "(", "score", ",", "test_ex", ".", "labels", ")", ":", "\n", "                ", "if", "label", "==", "true_class_label", ":", "\n", "                    ", "true_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "false_scores", ".", "append", "(", "prob", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "pos_mean", "=", "np", ".", "mean", "(", "true_scores", ")", "\n", "neg_mean", "=", "np", ".", "mean", "(", "false_scores", ")", "\n", "\n", "true_positive", "=", "np", ".", "sum", "(", "true_scores", ">", "best_boundary", ")", "\n", "false_positive", "=", "np", ".", "sum", "(", "false_scores", ">", "best_boundary", ")", "\n", "precision", "=", "true_positive", "/", "(", "true_positive", "+", "false_positive", ")", "\n", "recall", "=", "true_positive", "/", "len", "(", "true_scores", ")", "\n", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"neural true  scores: %.3f +/- %.3f\"", ",", "\n", "pos_mean", ",", "np", ".", "std", "(", "true_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"neural false scores: %.3f +/- %.3f\"", ",", "\n", "neg_mean", ",", "np", ".", "std", "(", "false_scores", ")", ")", "\n", "logging", ".", "info", "(", "\"Precision: %.3f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Recall: %.3f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"F1-score: %.3f\"", ",", "f_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_alignent.main": [[9, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "zip", "print", "print", "print", "set", "set", "len", "recalls.append", "precisions.append", "len", "len", "len", "len", "len", "len", "len", "argparse.FileType", "argparse.FileType", "gt_line.strip().split", "pred_line.strip().split", "set.intersection", "precisions.append", "recalls.append", "f_scores.append", "len", "f_scores.append", "f_scores.append", "sum", "sum", "sum", "len", "gt_line.strip", "pred_line.strip"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"ground_truth\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "help", "=", "\"Ground truth alignment.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"prediction\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "nargs", "=", "\"?\"", ",", "\n", "help", "=", "\"Predicted alignment.\"", ",", "default", "=", "sys", ".", "stdin", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "precisions", "=", "[", "]", "\n", "recalls", "=", "[", "]", "\n", "f_scores", "=", "[", "]", "\n", "\n", "for", "gt_line", ",", "pred_line", "in", "zip", "(", "args", ".", "ground_truth", ",", "args", ".", "prediction", ")", ":", "\n", "        ", "gt_set", "=", "set", "(", "gt_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "prediction_set", "=", "set", "(", "pred_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "in_both_size", "=", "len", "(", "gt_set", ".", "intersection", "(", "prediction_set", ")", ")", "\n", "\n", "if", "in_both_size", "==", "0", ":", "\n", "            ", "precisions", ".", "append", "(", "0.", ")", "\n", "recalls", ".", "append", "(", "0.", ")", "\n", "f_scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "recall", "=", "in_both_size", "/", "len", "(", "gt_set", ")", "\n", "recalls", ".", "append", "(", "recall", ")", "\n", "if", "prediction_set", ":", "\n", "            ", "precision", "=", "in_both_size", "/", "len", "(", "prediction_set", ")", "\n", "", "else", ":", "\n", "            ", "precision", "=", "1.", "\n", "", "precisions", ".", "append", "(", "precision", ")", "\n", "\n", "if", "recall", "+", "precision", ">", "0", ":", "\n", "            ", "f_scores", ".", "append", "(", "2", "*", "recall", "*", "precision", "/", "(", "recall", "+", "precision", ")", ")", "\n", "", "else", ":", "\n", "            ", "f_scores", ".", "append", "(", "0.", ")", "\n", "\n", "", "", "assert", "len", "(", "precisions", ")", "==", "len", "(", "recalls", ")", "\n", "assert", "len", "(", "precisions", ")", "==", "len", "(", "f_scores", ")", "\n", "\n", "mean_precision", "=", "100", "*", "sum", "(", "precisions", ")", "/", "len", "(", "precisions", ")", "\n", "mean_recall", "=", "100", "*", "sum", "(", "recalls", ")", "/", "len", "(", "recalls", ")", "\n", "mean_f_score", "=", "100", "*", "sum", "(", "f_scores", ")", "/", "len", "(", "f_scores", ")", "\n", "\n", "print", "(", "f\"Precision: {mean_precision:.2f}\"", ")", "\n", "print", "(", "f\"Recall:    {mean_recall:.2f}\"", ")", "\n", "print", "(", "f\"F-Score:   {mean_f_score:.2f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.CNN.__init__": [[83, 128], ["super().__init__", "int", "range", "torch.Parameter", "torch.Parameter", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "numpy.floor", "math.floor", "torch.Conv2d", "torch.Conv2d", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "stance.CNN.add_module", "stance.CNN.add_module", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "stance.CNN.add_module", "stance.CNN.add_module"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "is_increasing", ",", "num_layers", ",", "filter_counts", ",", "max_len_token", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        params is_increasing: whether the filter size is increasing or decreasing\n        params num_layers: number of layers in the CNN\n        params filter_counts: dictionary of filter index to filter size\n        params max_len_token: maximum number of tokens in sentence\n        \"\"\"", "\n", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "decreasing", "=", "0", "\n", "if", "not", "is_increasing", ":", "\n", "            ", "decreasing", "=", "1", "\n", "", "assert", "1", "<=", "num_layers", "<=", "4", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "\n", "map_conv_layer_to_filter_size", "=", "{", "\n", "4", ":", "[", "[", "3", ",", "5", ",", "5", ",", "7", "]", ",", "[", "7", ",", "5", ",", "5", ",", "3", "]", "]", ",", "\n", "3", ":", "[", "[", "5", ",", "5", ",", "7", "]", ",", "[", "7", ",", "5", ",", "5", "]", "]", ",", "\n", "2", ":", "[", "[", "5", ",", "3", "]", ",", "[", "5", ",", "3", "]", "]", ",", "\n", "1", ":", "[", "[", "7", "]", ",", "[", "7", "]", "]", "}", "\n", "pool_output_height", "=", "int", "(", "np", ".", "floor", "(", "max_len_token", "/", "2.0", ")", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "num_layers", "+", "1", ")", ":", "\n", "            ", "filter_size", "=", "map_conv_layer_to_filter_size", "[", "self", ".", "num_layers", "]", "[", "decreasing", "]", "[", "i", "-", "1", "]", "\n", "padding_size", "=", "math", ".", "floor", "(", "filter_size", "/", "2", ")", "\n", "prev_filter_count", "=", "1", "\n", "if", "i", ">", "1", ":", "\n", "                ", "prev_filter_count", "=", "filter_counts", "[", "i", "-", "2", "]", "\n", "", "convlyr", "=", "nn", ".", "Conv2d", "(", "prev_filter_count", ",", "filter_counts", "[", "i", "-", "1", "]", ",", "filter_size", ",", "padding", "=", "padding_size", ",", "stride", "=", "1", ")", "\n", "if", "i", "==", "1", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_1\"", ",", "convlyr", ")", "\n", "", "elif", "i", "==", "2", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_2\"", ",", "convlyr", ")", "\n", "", "elif", "i", "==", "3", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_3\"", ",", "convlyr", ")", "\n", "", "elif", "i", "==", "4", ":", "\n", "                ", "self", ".", "add_module", "(", "\"cnn_4\"", ",", "convlyr", ")", "\n", "\n", "", "", "self", ".", "align_weights", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "filter_counts", "[", "num_layers", "-", "1", "]", ",", "\n", "pool_output_height", ",", "\n", "pool_output_height", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "final_dense", "=", "nn", ".", "Conv2d", "(", "filter_counts", "[", "num_layers", "-", "1", "]", ",", "1", ",", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.CNN.forward": [[129, 154], ["stance.CNN.cnn_1", "stance.CNN.pool", "stance.CNN.pool", "stance.CNN.final_dense().squeeze", "src_tgt_sim.unsqueeze", "stance.CNN.relu", "stance.CNN.cnn_2", "stance.CNN.relu", "stance.CNN.cnn_3", "stance.CNN.relu", "stance.CNN.cnn_4", "stance.CNN.sum().sum", "stance.CNN.final_dense", "stance.CNN.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src_tgt_sim", ",", "src_tgt_mask", ")", ":", "\n", "        ", "\"\"\"Run CNN over input.\n\n        :params src_tgt_sim: tensor representing similarity between source and target\n        :return: scores for similarity\n        \"\"\"", "\n", "\n", "# Needs num channels", "\n", "convd", "=", "self", ".", "cnn_1", "(", "src_tgt_sim", ".", "unsqueeze", "(", "1", ")", ")", "\n", "if", "self", ".", "num_layers", ">", "1", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_2", "(", "convd", ")", "\n", "", "if", "self", ".", "num_layers", ">", "2", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_3", "(", "convd", ")", "\n", "", "if", "self", ".", "num_layers", ">", "3", ":", "\n", "            ", "convd", "=", "self", ".", "relu", "(", "convd", ")", "\n", "convd", "=", "self", ".", "cnn_4", "(", "convd", ")", "\n", "\n", "", "convd_after_pooling", "=", "self", ".", "pool", "(", "convd", ")", "\n", "pooled_mask", "=", "self", ".", "pool", "(", "src_tgt_mask", ")", "\n", "\n", "output", "=", "self", ".", "final_dense", "(", "convd_after_pooling", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "(", "output", "*", "pooled_mask", ")", ".", "sum", "(", "2", ")", ".", "sum", "(", "1", ")", "/", "pooled_mask", ".", "sum", "(", "2", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__": [[164, 181], ["super().__init__", "stance.CNN", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "cnn_increasing", ",", "cnn_num_layers", ",", "cnn_filter_counts", ",", "tgt_encoder", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        param config: config object\n        param vocab: vocab object\n        param max_len_token: max number of tokens\n        \"\"\"", "\n", "super", "(", "Stance", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_encoder", "=", "encoder", "\n", "if", "tgt_encoder", "is", "None", ":", "\n", "            ", "self", ".", "tgt_encoder", "=", "encoder", "\n", "", "else", ":", "\n", "            ", "self", ".", "tgt_encoder", "=", "tgt_encoder", "\n", "\n", "", "self", ".", "CNN", "=", "CNN", "(", "cnn_increasing", ",", "cnn_num_layers", ",", "cnn_filter_counts", ")", "\n", "\n", "# Vector of ones (used for loss)", "\n", "self", ".", "loss", "=", "BCEWithLogitsLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.compute_loss": [[182, 199], ["stance.Stance.score_pair", "stance.Stance.score_pair", "stance.Stance.loss", "stance.Stance.loss", "stance.Stance.loss", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.score_pair", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.score_pair"], ["", "def", "compute_loss", "(", "self", ",", "query", ",", "query_mask", ",", "pos", ",", "pos_mask", ",", "neg", ",", "neg_mask", ")", ":", "\n", "        ", "\"\"\"Compute loss for batch of query positive negative triplets.\n\n        param qry: query tokens (batch size of list of tokens)\n        param pos: positive mention lookup (batch size of list of tokens)\n        param neg: negative mention lookup (batch size of list of tokens)\n        return: loss (batch_size)\n        \"\"\"", "\n", "\n", "pos_score", "=", "self", ".", "score_pair", "(", "query", ",", "pos", ",", "query_mask", ",", "pos_mask", ")", "\n", "neg_score", "=", "self", ".", "score_pair", "(", "query", ",", "neg", ",", "query_mask", ",", "neg_mask", ")", "\n", "\n", "diff_loss", "=", "self", ".", "loss", "(", "pos_score", "-", "neg_score", ",", "torch", ".", "ones_like", "(", "pos_score", ")", ")", "\n", "pos_loss", "=", "self", ".", "loss", "(", "pos_score", ",", "torch", ".", "ones_like", "(", "pos_score", ")", ")", "\n", "neg_loss", "=", "self", ".", "loss", "(", "neg_score", ",", "torch", ".", "zeros_like", "(", "pos_score", ")", ")", "\n", "\n", "return", "diff_loss", "+", "pos_loss", "+", "neg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.score_pair": [[201, 227], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qry_msk.unsqueeze().float", "cnd_msk.unsqueeze().float.unsqueeze().float.unsqueeze().float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "stance.batch_sinkhorn_loss", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "stance.Stance.CNN", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "qry_msk.unsqueeze", "cnd_msk.unsqueeze().float.unsqueeze().float.unsqueeze", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.bmm.size", "torch.bmm.size"], "methods", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.batch_sinkhorn_loss"], ["", "def", "score_pair", "(", "self", ",", "qry_emb", ",", "cnd_emb", ",", "qry_msk", ",", "cnd_msk", ")", ":", "\n", "        ", "\"\"\"Score the batch of query candidate pair.\n\n        Take the dot product of all pairs of embeddings (with bmm) to get similarity matrix\n        Uses optimal transport to align the weights\n        Then runs CNN over the similarity matrix\n\n        param qry: query mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param cnd: candidate mention embedding (batch_size * max_len_token * hidden_state_output_size)\n        param qry_msk: query mention mask (batch_size * max_len_token)\n        param cnd_mask: candidate mention mask (batch_size * max_len_token)\n        return: score for query candidate pairs (batch_size * 1)\n        \"\"\"", "\n", "\n", "qry_cnd_sim", "=", "torch", ".", "bmm", "(", "qry_emb", ",", "torch", ".", "transpose", "(", "cnd_emb", ",", "2", ",", "1", ")", ")", "\n", "\n", "qry_mask", "=", "qry_msk", ".", "unsqueeze", "(", "dim", "=", "2", ")", ".", "float", "(", ")", "\n", "cnd_msk", "=", "cnd_msk", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "float", "(", ")", "\n", "qry_cnd_mask", "=", "torch", ".", "bmm", "(", "qry_mask", ",", "cnd_msk", ")", "\n", "\n", "qry_cnd_dist", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "qry_cnd_sim", ".", "size", "(", ")", ")", ".", "fill_", "(", "torch", ".", "max", "(", "qry_cnd_sim", ")", ")", "-", "qry_cnd_sim", "+", "1e-6", "\n", "qry_cnd_pi", "=", "batch_sinkhorn_loss", "(", "qry_cnd_dist", ",", "qry_cnd_mask", ")", "\n", "qry_cnd_sim_aligned", "=", "torch", ".", "mul", "(", "qry_cnd_sim", ",", "qry_cnd_pi", ")", "\n", "qry_cnd_sim_aligned", "=", "torch", ".", "mul", "(", "qry_cnd_sim_aligned", ",", "qry_cnd_mask", ")", "\n", "\n", "return", "self", ".", "CNN", "(", "qry_cnd_sim_aligned", ",", "qry_cnd_mask", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.batch_sinkhorn_loss": [[24, 80], ["C_mask.size", "range", "torch.exp", "torch.exp", "mu.sum", "nu.sum", "torch.log", "torch.log", "stance.batch_sinkhorn_loss.M"], "function", ["None"], ["def", "batch_sinkhorn_loss", "(", "C", ",", "C_mask", ",", "epsilon", "=", "1", ",", "niter", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    :param C: Batch size by MSL by MSL\n    :param C_mask: Batch size by MSL by MSL\n    :param epsilon:\n    :param n:\n    :param niter:\n    :return:\n    \"\"\"", "\n", "# B by MSL", "\n", "mu", "=", "C_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "mu", "=", "mu", "/", "mu", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "nu", "=", "C_mask", "[", ":", ",", "0", ",", ":", "]", "\n", "nu", "=", "nu", "/", "nu", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Parameters of the Sinkhorn algorithm.", "\n", "rho", "=", "1", "# (.5) **2          # unbalanced transport", "\n", "tau", "=", "-", ".8", "# nesterov-like acceleration", "\n", "lam", "=", "rho", "/", "(", "rho", "+", "epsilon", ")", "# Update exponent", "\n", "thresh", "=", "10", "**", "(", "-", "1", ")", "# stopping criterion", "\n", "\n", "def", "ave", "(", "u", ",", "u1", ")", ":", "\n", "        ", "\"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"", "\n", "return", "tau", "*", "u", "+", "(", "1", "-", "tau", ")", "*", "u1", "\n", "\n", "", "def", "M", "(", "u", ",", "v", ")", ":", "\n", "        ", "\"Modified cost for logarithmic updates\"", "\n", "\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"", "\n", "return", "(", "-", "C", "+", "u", ".", "unsqueeze", "(", "2", ")", "+", "v", ".", "unsqueeze", "(", "1", ")", ")", "/", "epsilon", "\n", "\n", "", "def", "lse", "(", "A", ",", "dim", ")", ":", "\n", "        ", "\"log-sum-exp\"", "\n", "return", "torch", ".", "log", "(", "torch", ".", "exp", "(", "A", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-6", ")", "# add 10^-6 to prevent NaN", "\n", "", "batch_size", "=", "C_mask", ".", "size", "(", "0", ")", "\n", "u", ",", "v", ",", "err", "=", "0.", "*", "mu", ",", "0.", "*", "nu", ",", "0.", "\n", "actual_nits", "=", "0", "# to check if algorithm terminates because of threshold or max iterations reached", "\n", "for", "i", "in", "range", "(", "niter", ")", ":", "\n", "        ", "u1", "=", "u", "# useful to check the update", "\n", "u", "=", "epsilon", "*", "(", "\n", "torch", ".", "log", "(", "mu", ")", "# B by MSL", "\n", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ",", "# M = B by MSL by MSL, lse should sum along the columns", "\n", "dim", "=", "2", ")", ".", "squeeze", "(", ")", ")", "+", "u", "\n", "v", "=", "epsilon", "*", "(", "torch", ".", "log", "(", "nu", ")", "-", "lse", "(", "M", "(", "u", ",", "v", ")", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", ")", "+", "v", "\n", "# accelerated unbalanced iterations", "\n", "# u = ave( u, lam * ( epsilon * ( torch.log(mu) - lse(M(u,v)).squeeze()   ) + u ) )", "\n", "# v = ave( v, lam * ( epsilon * ( torch.log(nu) - lse(M(u,v).t()).squeeze() ) + v ) )", "\n", "err", "=", "(", "u", "-", "u1", ")", ".", "abs", "(", ")", ".", "sum", "(", ")", "/", "batch_size", "\n", "\n", "actual_nits", "+=", "1", "\n", "if", "(", "err", "<", "thresh", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ":", "\n", "            ", "break", "\n", "", "", "U", ",", "V", "=", "u", ",", "v", "\n", "pi", "=", "torch", ".", "exp", "(", "M", "(", "U", ",", "V", ")", ")", "# Transport plan pi = diag(a)*K*diag(b)", "\n", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab": [[19, 28], ["file.close", "collections.defaultdict", "enumerate", "vocab.append", "token.strip"], "function", ["None"], ["def", "load_vocab", "(", "file", ")", ":", "\n", "    ", "vocab", "=", "[", "]", "\n", "for", "token", "in", "file", ":", "\n", "        ", "vocab", ".", "append", "(", "token", ".", "strip", "(", ")", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "stoi", "=", "defaultdict", "(", "int", ")", "\n", "for", "i", ",", "symb", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "stoi", "[", "symb", "]", "=", "i", "\n", "", "return", "vocab", ",", "stoi", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.main": [[30, 82], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "logging.info", "eval_statistical_generation.load_vocab", "eval_statistical_generation.load_vocab", "logging.info", "enumerate", "logging.info", "transliteration_utils.char_error_rate", "logging.info", "print", "line.strip().split", "torch.tensor", "torch.tensor", "references.append", "hypotheses.append", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType", "logging.info", "line.strip", "torch.load.decode", "src.split", "list", "tgt.split", "list"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.eval_statistical_generation.load_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.transliteration_utils.char_error_rate", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.models.EditDistNeuralModelProgressive.decode"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"rb\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"src_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"tgt_vocab\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"data\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--src-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt-tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model", "=", "torch", ".", "load", "(", "args", ".", "model", ")", "\n", "logging", ".", "info", "(", "\"Model loaded.\"", ")", "\n", "src_vocab", ",", "src_stoi", "=", "load_vocab", "(", "args", ".", "src_vocab", ")", "\n", "tgt_vocab", ",", "tgt_stoi", "=", "load_vocab", "(", "args", ".", "tgt_vocab", ")", "\n", "logging", ".", "info", "(", "\"Vocabularies loaded.\"", ")", "\n", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "\n", "references", "=", "[", "]", "\n", "hypotheses", "=", "[", "]", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "args", ".", "data", ")", ":", "\n", "        ", "total", "+=", "1", "\n", "src", ",", "tgt", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "src_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "src", ".", "split", "(", ")", "if", "args", ".", "src_tokenized", "else", "list", "(", "src", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "tgt_tok", "=", "(", "\n", "[", "\"<s>\"", "]", "+", "\n", "(", "tgt", ".", "split", "(", ")", "if", "args", ".", "tgt_tokenized", "else", "list", "(", "tgt", ")", ")", "+", "\n", "[", "\"</s>\"", "]", ")", "\n", "\n", "src_idx", "=", "torch", ".", "tensor", "(", "[", "[", "src_stoi", "[", "s", "]", "for", "s", "in", "src_tok", "]", "]", ")", "\n", "tgt_idx", "=", "torch", ".", "tensor", "(", "[", "[", "tgt_stoi", "[", "s", "]", "for", "s", "in", "tgt_tok", "]", "]", ")", "\n", "\n", "hyp", "=", "[", "tgt_vocab", "[", "idx", "]", "for", "idx", "in", "model", ".", "decode", "(", "src_idx", ")", "]", "\n", "hyp_str", "=", "\" \"", ".", "join", "(", "hyp", ")", "if", "args", ".", "tgt_tokenized", "else", "\"\"", ".", "join", "(", "hyp", ")", "\n", "correct", "+=", "hyp_str", "==", "tgt", "\n", "\n", "references", ".", "append", "(", "tgt", ")", "\n", "hypotheses", ".", "append", "(", "hyp_str", ")", "\n", "\n", "if", "i", "<", "10", ":", "\n", "            ", "logging", ".", "info", "(", "\"'%s' -> '%s' (%s)\"", ",", "src", ",", "hyp_str", ",", "tgt", ")", "\n", "\n", "", "", "wer", "=", "1", "-", "correct", "/", "total", "\n", "logging", ".", "info", "(", "\"WER: %.3f\"", ",", "wer", ")", "\n", "cer", "=", "char_error_rate", "(", "hypotheses", ",", "references", ",", "tokenized", "=", "args", ".", "tgt_tokenized", ")", "\n", "logging", ".", "info", "(", "\"CER: %.3f\"", ",", "cer", ")", "\n", "print", "(", "cer", ",", "wer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_stance_classification.eval_model": [[25, 75], ["true_positives.float", "torch.no_grad", "batch.src.to", "batch.tgt.to", "model.score_pair", "batch.label.sum", "true_positives.float", "encoder", "encoder"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.score_pair"], ["def", "eval_model", "(", "encoder", ",", "model", ",", "data_iter", ",", "threshold", ",", "device", ")", ":", "\n", "    ", "true_positives", "=", "0", "\n", "false_positives", "=", "0", "\n", "ground_truth_positives", "=", "0", "\n", "ground_truth_negatives", "=", "0", "\n", "\n", "pos_scores_sum", "=", "0", "\n", "neg_scores_sum", "=", "0", "\n", "\n", "for", "batch", "in", "data_iter", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "query", "=", "batch", ".", "src", ".", "to", "(", "device", ")", "\n", "query_mask", "=", "query", "!=", "1", "\n", "pos", "=", "batch", ".", "tgt", ".", "to", "(", "device", ")", "\n", "pos_mask", "=", "pos", "!=", "1", "\n", "\n", "encoded_query", "=", "encoder", "(", "\n", "query", ",", "attention_mask", "=", "query_mask", ")", "[", "0", "]", "\n", "encoded_pos", "=", "encoder", "(", "pos", ",", "attention_mask", "=", "pos_mask", ")", "[", "0", "]", "\n", "scores", "=", "model", ".", "score_pair", "(", "\n", "encoded_query", ",", "encoded_pos", ",", "\n", "query_mask", ",", "pos_mask", ")", "\n", "\n", "ground_truth_positives", "+=", "batch", ".", "label", ".", "sum", "(", ")", "\n", "ground_truth_negatives", "+=", "(", "1", "-", "batch", ".", "label", ")", ".", "sum", "(", ")", "\n", "pos_scores_sum", "+=", "(", "batch", ".", "label", "*", "scores", ")", ".", "sum", "(", ")", "\n", "neg_scores_sum", "+=", "(", "(", "1", "-", "batch", ".", "label", ")", "*", "scores", ")", ".", "sum", "(", ")", "\n", "\n", "model_positives", "=", "(", "scores", ">", "threshold", ")", ".", "long", "(", ")", "\n", "true_positives", "+=", "(", "\n", "batch", ".", "label", "*", "model_positives", ")", ".", "sum", "(", ")", "\n", "false_positives", "+=", "(", "\n", "(", "1", "-", "batch", ".", "label", ")", "*", "model_positives", ")", ".", "sum", "(", ")", "\n", "\n", "", "", "if", "true_positives", "+", "false_positives", "==", "0", ":", "\n", "        ", "precision", "=", "0", "\n", "", "else", ":", "\n", "        ", "precision", "=", "(", "\n", "true_positives", ".", "float", "(", ")", "/", "\n", "(", "true_positives", "+", "false_positives", ")", ")", "\n", "", "recall", "=", "true_positives", ".", "float", "(", ")", "/", "ground_truth_positives", "\n", "if", "precision", "+", "recall", "==", "0", ":", "\n", "        ", "f_score", "=", "0", "\n", "", "else", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "", "pos_score_avg", "=", "pos_scores_sum", "/", "ground_truth_positives", "\n", "neg_score_avg", "=", "neg_scores_sum", "/", "ground_truth_negatives", "\n", "\n", "return", "f_score", ",", "precision", ",", "recall", ",", "pos_score_avg", ",", "neg_score_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_stance_classification.main": [[77, 260], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "experiment.experiment_logging", "os.path.join", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torch.device", "torchtext.data.TabularDataset.splits", "data.Field.build_vocab", "experiment.save_vocab", "experiment.save_vocab", "torchtext.data.Iterator.splits", "stance.Stance().to", "torch.optim.Adam", "range", "torchtext.data.TabularDataset.splits", "os.path.join", "os.path.join", "transformers.BertConfig", "transformers.BertModel().to", "cnn.CNNEncoder.parameters", "enumerate", "logging.info", "logging.info", "logging.info", "logging.info", "Stance().to.eval", "train_stance_classification.eval_model", "logging.info", "logging.info", "logging.info", "torch.cuda.is_available", "rnn.RNNEncoder", "stance.Stance", "train_batch.src.to", "train_batch.tgt.to", "train_batch.neg.to", "Stance().to.compute_loss", "model.compute_loss.backward", "experiment.get_timestamp", "len", "len", "transformers.BertModel", "cnn.CNNEncoder", "cnn.CNNEncoder.", "cnn.CNNEncoder.", "cnn.CNNEncoder.", "optim.Adam.step", "optim.Adam.zero_grad", "logging.info", "Stance().to.eval", "train_stance_classification.eval_model", "logging.info", "logging.info", "logging.info", "logging.info", "Stance().to.train", "s.split", "cnn.CNNEncoder", "ValueError", "logging.info", "logging.info", "logging.info", "parser.parse_args.data_prefix.replace"], "function", ["home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.experiment_logging", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.save_vocab", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_stance_classification.eval_model", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.stance.Stance.compute_loss", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.experiment.get_timestamp", "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.None.train_stance_classification.eval_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"data_prefix\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenized\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, input is space-separated.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden-size\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--attention-heads\"", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--window\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "\"CNN window width.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--delay-update\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Update model every N steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "default", "=", "1000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--model-type\"", ",", "default", "=", "'transformer'", ",", "\n", "choices", "=", "[", "\"transformer\"", ",", "\"rnn\"", ",", "\"embeddings\"", ",", "\"cnn\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--patience\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number of validations witout improvement before finishing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning-rate\"", ",", "default", "=", "1e-4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-decrease-count\"", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Number learning rate decays before \"", "\n", "\"early stopping.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-decrease-ratio\"", ",", "default", "=", "0.7", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Factor by which the learning rate is decayed.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log-directory\"", ",", "default", "=", "\"experiments\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Number of steps between validations.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "experiment_params", "=", "(", "\n", "args", ".", "data_prefix", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", "+", "\n", "f\"_model{args.model_type}\"", "+", "\n", "f\"_hidden{args.hidden_size}\"", "+", "\n", "f\"_attheads{args.attention_heads}\"", "+", "\n", "f\"_layers{args.layers}\"", "+", "\n", "f\"_batch{args.batch_size}\"", "+", "\n", "f\"_patence{args.patience}\"", "+", "\n", "f\"_delay{args.delay_update}\"", ")", "\n", "experiment_dir", "=", "experiment_logging", "(", "\n", "args", ".", "log_directory", ",", "\n", "f\"stance_{experiment_params}_{get_timestamp()}\"", ",", "args", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"model.pt\"", ")", "\n", "\n", "text_field", "=", "data", ".", "Field", "(", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", "if", "args", ".", "tokenized", "else", "list", ",", "\n", "init_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "batch_first", "=", "True", ")", "\n", "labels_field", "=", "data", ".", "Field", "(", "sequential", "=", "False", ",", "use_vocab", "=", "False", ")", "\n", "labels_field", "=", "data", ".", "Field", "(", "sequential", "=", "False", ",", "use_vocab", "=", "False", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "train_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "args", ".", "data_prefix", ",", "train", "=", "'train_stance.txt'", ",", "\n", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'src'", ",", "text_field", ")", ",", "(", "'tgt'", ",", "text_field", ")", ",", "(", "'neg'", ",", "text_field", ")", "]", ")", "[", "0", "]", "\n", "val_data", ",", "test_data", "=", "data", ".", "TabularDataset", ".", "splits", "(", "\n", "path", "=", "args", ".", "data_prefix", ",", "\n", "validation", "=", "'eval.txt'", ",", "test", "=", "'test.txt'", ",", "format", "=", "'tsv'", ",", "\n", "fields", "=", "[", "(", "'src'", ",", "text_field", ")", ",", "(", "'tgt'", ",", "text_field", ")", ",", "(", "'label'", ",", "labels_field", ")", "]", ")", "\n", "\n", "# Use val data beacuse iterating through train data would take agas.", "\n", "text_field", ".", "build_vocab", "(", "val_data", ")", "\n", "save_vocab", "(", "\n", "text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"src_vocab\"", ")", ")", "\n", "save_vocab", "(", "\n", "text_field", ".", "vocab", ".", "itos", ",", "os", ".", "path", ".", "join", "(", "experiment_dir", ",", "\"tgt_vocab\"", ")", ")", "\n", "\n", "train_iter", ",", "val_iter", ",", "test_iter", "=", "data", ".", "Iterator", ".", "splits", "(", "\n", "(", "train_data", ",", "val_data", ",", "test_data", ")", ",", "batch_sizes", "=", "[", "args", ".", "batch_size", "]", "*", "3", ",", "\n", "shuffle", "=", "True", ",", "device", "=", "device", ",", "sort_key", "=", "lambda", "x", ":", "len", "(", "x", ".", "src", ")", ")", "\n", "\n", "encoder", "=", "None", "\n", "if", "args", ".", "model_type", "==", "\"transformer\"", ":", "\n", "        ", "config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "len", "(", "text_field", ".", "vocab", ")", ",", "\n", "is_decoder", "=", "False", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "num_hidden_layers", "=", "args", ".", "layers", ",", "\n", "num_attention_heads", "=", "args", ".", "attention_heads", ",", "\n", "intermediate_size", "=", "2", "*", "args", ".", "hidden_size", ",", "\n", "hidden_act", "=", "'relu'", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "num_labels", "=", "2", ")", "\n", "encoder", "=", "BertModel", "(", "config", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"rnn\"", ":", "\n", "        ", "encoder", "=", "RNNEncoder", "(", "\n", "text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "layers", ",", "dropout", "=", "0.1", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"embeddings\"", ":", "\n", "        ", "encoder", "=", "CNNEncoder", "(", "\n", "text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "\n", "args", ".", "hidden_size", ",", "window", "=", "1", ",", "layers", "=", "0", ",", "dropout", "=", "0.1", ")", "\n", "", "elif", "args", ".", "model_type", "==", "\"cnn\"", ":", "\n", "        ", "encoder", "=", "CNNEncoder", "(", "\n", "text_field", ".", "vocab", ",", "args", ".", "hidden_size", ",", "\n", "args", ".", "hidden_size", ",", "window", "=", "args", ".", "window", ",", "layers", "=", "args", ".", "layers", ",", "dropout", "=", "0.1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Uknown uncoder type.\"", ")", "\n", "\n", "", "model", "=", "Stance", "(", "encoder", ",", "False", ",", "1", ",", "[", "args", ".", "hidden_size", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "encoder", ".", "parameters", "(", ")", ")", "\n", "\n", "step", "=", "0", "\n", "best_f_score", "=", "0.0", "\n", "stalled", "=", "0", "\n", "remaining_lr_decrease", "=", "args", ".", "lr_decrease_count", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "threshold", "=", "0.", "\n", "for", "epoch_n", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "remaining_lr_decrease", "==", "0", ":", "\n", "            ", "break", "\n", "", "for", "_", ",", "train_batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "            ", "if", "remaining_lr_decrease", "==", "0", ":", "\n", "                ", "break", "\n", "", "step", "+=", "1", "\n", "\n", "query", "=", "train_batch", ".", "src", ".", "to", "(", "device", ")", "\n", "query_mask", "=", "query", "!=", "1", "\n", "pos", "=", "train_batch", ".", "tgt", ".", "to", "(", "device", ")", "\n", "pos_mask", "=", "pos", "!=", "1", "\n", "neg", "=", "train_batch", ".", "neg", ".", "to", "(", "device", ")", "\n", "neg_mask", "=", "neg", "!=", "1", "\n", "\n", "encoded_query", "=", "encoder", "(", "query", ",", "attention_mask", "=", "query_mask", ")", "[", "0", "]", "\n", "encoded_pos", "=", "encoder", "(", "pos", ",", "attention_mask", "=", "pos_mask", ")", "[", "0", "]", "\n", "encoded_neg", "=", "encoder", "(", "neg", ",", "attention_mask", "=", "neg_mask", ")", "[", "0", "]", "\n", "\n", "loss", "=", "model", ".", "compute_loss", "(", "\n", "encoded_query", ",", "query_mask", ",", "encoded_pos", ",", "pos_mask", ",", "\n", "encoded_neg", ",", "neg_mask", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "step", "%", "args", ".", "delay_update", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "logging", ".", "info", "(", "\n", "\"step: %d (ep. %d), train loss = %.3g\"", ",", "\n", "step", ",", "epoch_n", "+", "1", ",", "loss", ")", "\n", "\n", "", "if", "step", "%", "10", "==", "9", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "(", "f_score", ",", "precision", ",", "recall", ",", "\n", "pos_score_avg", ",", "neg_score_avg", ")", "=", "eval_model", "(", "\n", "encoder", ",", "model", ",", "val_iter", ",", "threshold", ",", "device", ")", "\n", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"\u2295 %.3f    \u2296 %.3f\"", ",", "pos_score_avg", ",", "neg_score_avg", ")", "\n", "logging", ".", "info", "(", "\n", "\"P: %.3f   R: %.3f   F: %.3f\"", ",", "precision", ",", "recall", ",", "f_score", ")", "\n", "threshold", "=", "(", "pos_score_avg", "+", "neg_score_avg", ")", "/", "2", "\n", "\n", "if", "f_score", ">", "best_f_score", ":", "\n", "                    ", "best_f_score", "=", "f_score", "\n", "stalled", "=", "0", "\n", "logging", ".", "info", "(", "\"New best.\"", ")", "\n", "", "else", ":", "\n", "                    ", "stalled", "+=", "1", "\n", "logging", ".", "info", "(", "\"Patience %d/%d.\"", ",", "stalled", ",", "args", ".", "patience", ")", "\n", "\n", "", "if", "stalled", ">=", "args", ".", "patience", ":", "\n", "                    ", "learning_rate", "*=", "args", ".", "lr_decrease_ratio", "\n", "logging", ".", "info", "(", "\"Decrease learning rate to %f.\"", ",", "learning_rate", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                        ", "param_group", "[", "'lr'", "]", "=", "learning_rate", "\n", "", "remaining_lr_decrease", "-=", "1", "\n", "stalled", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"Training done, best F-score %.3f.\"", ",", "best_f_score", ")", "\n", "logging", ".", "info", "(", "\"\"", ")", "\n", "logging", ".", "info", "(", "\"TESTING\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "(", "f_score", ",", "precision", ",", "recall", ",", "\n", "pos_score_avg", ",", "neg_score_avg", ")", "=", "eval_model", "(", "\n", "encoder", ",", "model", ",", "val_iter", ",", "threshold", ",", "device", ")", "\n", "logging", ".", "info", "(", "\"Precision: %.3f\"", ",", "precision", ")", "\n", "logging", ".", "info", "(", "\"Recall:    %.3f\"", ",", "recall", ")", "\n", "logging", ".", "info", "(", "\"F-Score:   %.3f\"", ",", "f_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jlibovicky_neural-string-edit-distance.alignment.intersect.main": [[9, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "zip", "fw_line.strip().split", "set", "print", "argparse.FileType", "argparse.FileType", "bw_line.strip().split", "fw_line.strip", "intersection.append", "bw_line.strip"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "__doc__", ")", "\n", "parser", ".", "add_argument", "(", "\"forward\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"backward\"", ",", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "for", "fw_line", ",", "bw_line", "in", "zip", "(", "args", ".", "forward", ",", "args", ".", "backward", ")", ":", "\n", "        ", "fw_tokens", "=", "fw_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "bw_tokens", "=", "set", "(", "bw_line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "intersection", "=", "[", "]", "\n", "for", "tok", "in", "fw_tokens", ":", "\n", "            ", "if", "tok", "in", "bw_tokens", ":", "\n", "                ", "intersection", ".", "append", "(", "tok", ")", "\n", "\n", "", "", "print", "(", "\" \"", ".", "join", "(", "intersection", ")", ")", "\n", "\n"]]}