{"home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.FlatFolderDataset.__init__": [[38, 43], ["torch.Dataset.__init__", "list", "pathlib.Path().glob", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", ")", ":", "\n", "        ", "super", "(", "FlatFolderDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "paths", "=", "list", "(", "Path", "(", "self", ".", "root", ")", ".", "glob", "(", "'*'", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.FlatFolderDataset.__getitem__": [[44, 49], ["PIL.Image.open().convert", "test_fast.FlatFolderDataset.transform", "PIL.Image.open", "str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "str", "(", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.FlatFolderDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.FlatFolderDataset.name": [[53, 55], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'FlatFolderDataset'", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.test_transform": [[24, 30], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor"], "function", ["None"], ["def", "test_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "Resize", "(", "size", "=", "(", "512", ",", "512", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_fast.hr_transform": [[31, 36], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "hr_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_CLIPstyler.img_denormalize": [[66, 74], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "img_denormalize", "(", "image", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "image", "*", "std", "+", "mean", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_CLIPstyler.img_normalize": [[75, 83], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "img_normalize", "(", "image", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_CLIPstyler.clip_normalize": [[84, 93], ["torch.interpolate", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "clip_normalize", "(", "image", ",", "device", ")", ":", "\n", "    ", "image", "=", "F", ".", "interpolate", "(", "image", ",", "size", "=", "224", ",", "mode", "=", "'bicubic'", ")", "\n", "mean", "=", "torch", ".", "tensor", "(", "[", "0.48145466", ",", "0.4578275", ",", "0.40821073", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.26862954", ",", "0.26130258", ",", "0.27577711", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_CLIPstyler.get_image_prior_losses": [[95, 104], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "get_image_prior_losses", "(", "inputs_jit", ")", ":", "\n", "    ", "diff1", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "\n", "diff2", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "diff3", "=", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", "1", ":", "]", "\n", "diff4", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", "1", ":", "]", "\n", "\n", "loss_var_l2", "=", "torch", ".", "norm", "(", "diff1", ")", "+", "torch", ".", "norm", "(", "diff2", ")", "+", "torch", ".", "norm", "(", "diff3", ")", "+", "torch", ".", "norm", "(", "diff4", ")", "\n", "\n", "return", "loss_var_l2", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_CLIPstyler.compose_text_with_templates": [[105, 107], ["template.format"], "function", ["None"], ["", "def", "compose_text_with_templates", "(", "text", ":", "str", ",", "templates", "=", "imagenet_templates", ")", "->", "list", ":", "\n", "    ", "return", "[", "template", ".", "format", "(", "text", ")", "for", "template", "in", "templates", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.UpBlock.__init__": [[7, 23], ["torch.Module.__init__", "torch.Upsample", "torch.Upsample", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", "=", "128", ",", "out_channel", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "upsample", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "out_channel", "+", "in_channel", ",", "out_channel", ",", "\n", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_channel", ",", "out_channel", ",", "\n", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "self", ".", "skip", "=", "nn", ".", "Conv2d", "(", "out_channel", "+", "in_channel", ",", "out_channel", ",", "1", ",", "1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.UpBlock.forward": [[24, 30], ["StyleNet.UpBlock.upsample", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "StyleNet.UpBlock.conv", "StyleNet.UpBlock.skip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "FB_in", ")", ":", "\n", "        ", "out_temp", "=", "self", ".", "upsample", "(", "input", ")", "\n", "out_temp", "=", "torch", ".", "cat", "(", "[", "out_temp", ",", "FB_in", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv", "(", "out_temp", ")", "+", "self", ".", "skip", "(", "out_temp", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.DownBlock.__init__": [[32, 45], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", "=", "3", ",", "out_channel", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channel", ",", "out_channel", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_channel", ",", "out_channel", ",", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "skip", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "out_channel", ",", "1", ",", "1", ",", "0", ")", "\n", "# self.downsample = nn.MaxPool2d(2,2)", "\n", "self", ".", "downsample", "=", "nn", ".", "Conv2d", "(", "out_channel", ",", "out_channel", ",", "4", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.DownBlock.forward": [[46, 50], ["StyleNet.DownBlock.downsample", "StyleNet.DownBlock.conv", "StyleNet.DownBlock.skip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out_temp", "=", "self", ".", "conv", "(", "input", ")", "+", "self", ".", "skip", "(", "input", ")", "\n", "out", "=", "self", ".", "downsample", "(", "out_temp", ")", "\n", "return", "out", ",", "out_temp", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.EncodingBlock.__init__": [[52, 67], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", "=", "256", ",", "out_channel", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channel", ",", "out_channel", ",", "\n", "3", ",", "1", ",", "1", ")", ",", "\n", "# nn.BatchNorm2d(out_channel),", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_channel", ",", "out_channel", ",", "\n", "3", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channel", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "skip", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "out_channel", ",", "1", ",", "1", ",", "0", ")", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.EncodingBlock.forward": [[67, 70], ["StyleNet.EncodingBlock.conv", "StyleNet.EncodingBlock.skip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "input", ")", "+", "self", ".", "skip", "(", "input", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.UNet.__init__": [[72, 87], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "StyleNet.EncodingBlock", "StyleNet.DownBlock", "StyleNet.DownBlock", "StyleNet.DownBlock", "StyleNet.EncodingBlock", "StyleNet.UpBlock", "StyleNet.UpBlock", "StyleNet.UpBlock", "StyleNet.EncodingBlock", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ngf", "=", "16", ",", "input_channel", "=", "3", ",", "output_channel", "=", "3", ")", ":", "\n", "        ", "super", "(", "UNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_init", "=", "nn", ".", "Conv2d", "(", "input_channel", ",", "ngf", ",", "1", ",", "1", ",", "0", ")", "\n", "self", ".", "init", "=", "EncodingBlock", "(", "ngf", ",", "ngf", ")", "\n", "self", ".", "down1", "=", "DownBlock", "(", "ngf", ",", "ngf", ")", "\n", "self", ".", "down2", "=", "DownBlock", "(", "ngf", ",", "2", "*", "ngf", ")", "\n", "self", ".", "down3", "=", "DownBlock", "(", "2", "*", "ngf", ",", "4", "*", "ngf", ")", "\n", "\n", "self", ".", "encoding", "=", "EncodingBlock", "(", "4", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "self", ".", "up3", "=", "UpBlock", "(", "8", "*", "ngf", ",", "4", "*", "ngf", ")", "\n", "self", ".", "up2", "=", "UpBlock", "(", "4", "*", "ngf", ",", "2", "*", "ngf", ")", "\n", "self", ".", "up1", "=", "UpBlock", "(", "2", "*", "ngf", ",", "ngf", ")", "\n", "self", ".", "out", "=", "EncodingBlock", "(", "2", "*", "ngf", ",", "ngf", ")", "\n", "self", ".", "conv_fin", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "output_channel", ",", "1", ",", "1", ",", "0", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.StyleNet.UNet.forward": [[88, 105], ["StyleNet.UNet.conv_init", "StyleNet.UNet.init", "StyleNet.UNet.down1", "StyleNet.UNet.down2", "StyleNet.UNet.down3", "StyleNet.UNet.encoding", "StyleNet.UNet.up3", "StyleNet.UNet.up2", "StyleNet.UNet.up1", "StyleNet.UNet.out", "StyleNet.UNet.conv_fin", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "StyleNet.UNet.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "use_sigmoid", "=", "True", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv_init", "(", "x", ")", "\n", "x", "=", "self", ".", "init", "(", "x", ")", "\n", "d1", ",", "d1_f", "=", "self", ".", "down1", "(", "x", ")", "\n", "d2", ",", "d2_f", "=", "self", ".", "down2", "(", "d1", ")", "\n", "d3", ",", "d3_f", "=", "self", ".", "down3", "(", "d2", ")", "\n", "\n", "h", "=", "self", ".", "encoding", "(", "d3", ")", "\n", "hu3", "=", "self", ".", "up3", "(", "h", ",", "d3_f", ")", "\n", "hu2", "=", "self", ".", "up2", "(", "hu3", ",", "d2_f", ")", "\n", "hu1", "=", "self", ".", "up1", "(", "hu2", ",", "d1_f", ")", "\n", "\n", "h", "=", "self", ".", "out", "(", "torch", ".", "cat", "(", "[", "hu1", ",", "x", "]", ",", "dim", "=", "1", ")", ")", "\n", "h", "=", "self", ".", "conv_fin", "(", "h", ")", "\n", "if", "use_sigmoid", ":", "\n", "            ", "h", "=", "self", ".", "sigmoid", "(", "h", ")", "\n", "", "return", "h", "", "", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.Predictor.setup": [[19, 28], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "predict.Predictor.VGG.to", "predict.Predictor.VGG.parameters", "StyleNet.UNet", "predict.Predictor.style_net.to", "clip.load", "torchvision.models.vgg19", "parameter.requires_grad_", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["None"], ["    ", "def", "setup", "(", "self", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "VGG", "=", "models", ".", "vgg19", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "self", ".", "VGG", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "parameter", "in", "self", ".", "VGG", ".", "parameters", "(", ")", ":", "\n", "            ", "parameter", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "style_net", "=", "StyleNet", ".", "UNet", "(", ")", "\n", "self", ".", "style_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "clip_model", ",", "preprocess", "=", "clip", ".", "load", "(", "'ViT-B/32'", ",", "self", ".", "device", ",", "jit", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.Predictor.predict": [[29, 145], ["cog.input", "cog.input", "cog.input", "argparse.Namespace", "utils.load_image2", "content_image.to.to.to", "utils.get_features", "torch.Adam", "torch.Adam", "torch.Adam", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "range", "str", "pathlib.Path", "predict.img_normalize", "predict.Predictor.style_net.parameters", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "predict.compose_text_with_templates", "clip.tokenize().to", "predict.Predictor.clip_model.encode_text().detach", "text_features.mean.mean.mean", "text_features.mean.mean.norm", "predict.compose_text_with_templates", "clip.tokenize().to", "predict.Predictor.clip_model.encode_text().detach", "text_source.mean.mean.mean", "text_source.mean.mean.norm", "predict.Predictor.clip_model.encode_image", "predict.Predictor.clone().norm", "torch.optim.lr_scheduler.StepLR.step", "torch.optim.lr_scheduler.StepLR.step", "torch.optim.lr_scheduler.StepLR.step", "predict.Predictor.style_net().to", "predict.Predictor.requires_grad_", "utils.get_features", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predict.Predictor.clip_model.encode_image", "predict.Predictor.clone().norm", "img_direction.clone().norm", "text_direction.norm", "loss_temp.mean", "predict.Predictor.clip_model.encode_image", "predict.Predictor.clone().norm", "glob_direction.clone().norm", "total_loss_epoch.append", "torch.Adam.zero_grad", "total_loss.backward", "torch.Adam.step", "tempfile.mkdtemp", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomPerspective", "torchvision.transforms.Resize", "predict.clip_normalize", "predict.img_normalize", "torchvision.transforms.Compose.", "torchvision.transforms.Compose.", "torch.cat.append", "torch.cat.append", "torch.cat.append", "predict.clip_normalize", "predict.Predictor.size", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "predict.clip_normalize", "predict.get_image_prior_losses", "clip.tokenize", "predict.Predictor.clip_model.encode_text", "clip.tokenize", "predict.Predictor.clip_model.encode_text", "predict.Predictor.clone", "predict.Predictor.style_net", "predict.Predictor.clone", "img_direction.clone", "predict.Predictor.clone", "glob_direction.clone", "predict.checkin", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.load_image2", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.get_features", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.img_normalize", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.compose_text_with_templates", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.compose_text_with_templates", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.get_features", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.clip_normalize", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.img_normalize", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.clip_normalize", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.clip_normalize", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.get_image_prior_losses", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.checkin"], ["", "@", "cog", ".", "input", "(", "\"image\"", ",", "type", "=", "Path", ",", "help", "=", "\"Input image (will be cropped before style transfer)\"", ")", "\n", "@", "cog", ".", "input", "(", "\"text\"", ",", "type", "=", "str", ",", "help", "=", "\"text for style transfer\"", ")", "\n", "@", "cog", ".", "input", "(", "\"iterations\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"training iterations\"", ")", "\n", "def", "predict", "(", "self", ",", "image", ",", "text", ",", "iterations", ")", ":", "\n", "        ", "training_args", "=", "{", "\n", "\"lambda_tv\"", ":", "2e-3", ",", "\n", "\"lambda_patch\"", ":", "9000", ",", "\n", "\"lambda_dir\"", ":", "500", ",", "\n", "\"lambda_c\"", ":", "150", ",", "\n", "\"crop_size\"", ":", "128", ",", "\n", "\"num_crops\"", ":", "64", ",", "\n", "\"img_size\"", ":", "512", ",", "\n", "\"max_step\"", ":", "iterations", ",", "\n", "\"lr\"", ":", "5e-4", ",", "\n", "\"thresh\"", ":", "0.7", ",", "\n", "\"content_path\"", ":", "str", "(", "image", ")", ",", "\n", "\"text\"", ":", "text", "\n", "}", "\n", "args", "=", "Namespace", "(", "**", "training_args", ")", "\n", "out_path", "=", "Path", "(", "tempfile", ".", "mkdtemp", "(", ")", ")", "/", "\"out.png\"", "\n", "\n", "content_path", "=", "args", ".", "content_path", "\n", "content_image", "=", "utils", ".", "load_image2", "(", "content_path", ",", "img_size", "=", "512", ")", "\n", "\n", "content_image", "=", "content_image", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "content_features", "=", "utils", ".", "get_features", "(", "img_normalize", "(", "content_image", ",", "self", ".", "device", ")", ",", "self", ".", "VGG", ")", "\n", "\n", "content_weight", "=", "args", ".", "lambda_c", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "style_net", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "100", ",", "gamma", "=", "0.5", ")", "\n", "steps", "=", "args", ".", "max_step", "\n", "\n", "total_loss_epoch", "=", "[", "]", "\n", "cropper", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "args", ".", "crop_size", ")", "\n", "]", ")", "\n", "augment", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomPerspective", "(", "fill", "=", "0", ",", "p", "=", "1", ",", "distortion_scale", "=", "0.5", ")", ",", "\n", "transforms", ".", "Resize", "(", "224", ")", "\n", "]", ")", "\n", "prompt", "=", "args", ".", "text", "\n", "source", "=", "\"a Photo\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "template_text", "=", "compose_text_with_templates", "(", "prompt", ",", "imagenet_templates", ")", "\n", "tokens", "=", "clip", ".", "tokenize", "(", "template_text", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "text_features", "=", "self", ".", "clip_model", ".", "encode_text", "(", "tokens", ")", ".", "detach", "(", ")", "\n", "text_features", "=", "text_features", ".", "mean", "(", "axis", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "text_features", "/=", "text_features", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "template_source", "=", "compose_text_with_templates", "(", "source", ",", "imagenet_templates", ")", "\n", "tokens_source", "=", "clip", ".", "tokenize", "(", "template_source", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "text_source", "=", "self", ".", "clip_model", ".", "encode_text", "(", "tokens_source", ")", ".", "detach", "(", ")", "\n", "text_source", "=", "text_source", ".", "mean", "(", "axis", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "text_source", "/=", "text_source", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "source_features", "=", "self", ".", "clip_model", ".", "encode_image", "(", "clip_normalize", "(", "content_image", ",", "self", ".", "device", ")", ")", "\n", "source_features", "/=", "(", "source_features", ".", "clone", "(", ")", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "", "num_crops", "=", "args", ".", "num_crops", "\n", "for", "epoch", "in", "range", "(", "0", ",", "steps", "+", "1", ")", ":", "\n", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "target", "=", "self", ".", "style_net", "(", "content_image", ",", "use_sigmoid", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "target_features", "=", "utils", ".", "get_features", "(", "img_normalize", "(", "target", ",", "self", ".", "device", ")", ",", "self", ".", "VGG", ")", "\n", "\n", "content_loss", "=", "0", "\n", "\n", "content_loss", "+=", "torch", ".", "mean", "(", "(", "target_features", "[", "'conv4_2'", "]", "-", "content_features", "[", "'conv4_2'", "]", ")", "**", "2", ")", "\n", "content_loss", "+=", "torch", ".", "mean", "(", "(", "target_features", "[", "'conv5_2'", "]", "-", "content_features", "[", "'conv5_2'", "]", ")", "**", "2", ")", "\n", "\n", "loss_patch", "=", "0", "\n", "img_proc", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "num_crops", ")", ":", "\n", "                ", "target_crop", "=", "cropper", "(", "target", ")", "\n", "target_crop", "=", "augment", "(", "target_crop", ")", "\n", "img_proc", ".", "append", "(", "target_crop", ")", "\n", "\n", "", "img_proc", "=", "torch", ".", "cat", "(", "img_proc", ",", "dim", "=", "0", ")", "\n", "img_aug", "=", "img_proc", "\n", "\n", "image_features", "=", "self", ".", "clip_model", ".", "encode_image", "(", "clip_normalize", "(", "img_aug", ",", "self", ".", "device", ")", ")", "\n", "image_features", "/=", "(", "image_features", ".", "clone", "(", ")", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "img_direction", "=", "(", "image_features", "-", "source_features", ")", "\n", "img_direction", "/=", "img_direction", ".", "clone", "(", ")", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "text_direction", "=", "(", "text_features", "-", "text_source", ")", ".", "repeat", "(", "image_features", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "text_direction", "/=", "text_direction", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "loss_temp", "=", "(", "1", "-", "torch", ".", "cosine_similarity", "(", "img_direction", ",", "text_direction", ",", "dim", "=", "1", ")", ")", "\n", "loss_temp", "[", "loss_temp", "<", "args", ".", "thresh", "]", "=", "0", "\n", "loss_patch", "+=", "loss_temp", ".", "mean", "(", ")", "\n", "\n", "glob_features", "=", "self", ".", "clip_model", ".", "encode_image", "(", "clip_normalize", "(", "target", ",", "self", ".", "device", ")", ")", "\n", "glob_features", "/=", "(", "glob_features", ".", "clone", "(", ")", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "glob_direction", "=", "(", "glob_features", "-", "source_features", ")", "\n", "glob_direction", "/=", "glob_direction", ".", "clone", "(", ")", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "loss_glob", "=", "(", "1", "-", "torch", ".", "cosine_similarity", "(", "glob_direction", ",", "text_direction", ",", "dim", "=", "1", ")", ")", ".", "mean", "(", ")", "\n", "\n", "reg_tv", "=", "args", ".", "lambda_tv", "*", "get_image_prior_losses", "(", "target", ")", "\n", "\n", "total_loss", "=", "args", ".", "lambda_patch", "*", "loss_patch", "+", "content_weight", "*", "content_loss", "+", "reg_tv", "+", "args", ".", "lambda_dir", "*", "loss_glob", "\n", "total_loss_epoch", ".", "append", "(", "total_loss", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "epoch", "%", "20", "==", "0", "or", "epoch", "==", "steps", ":", "\n", "                ", "yield", "checkin", "(", "epoch", ",", "target", ",", "total_loss", ",", "content_loss", ",", "loss_patch", ",", "loss_glob", ",", "reg_tv", ",", "out_path", ")", "\n", "\n", "", "", "return", "out_path", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.checkin": [[147, 160], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "sys.stderr.write", "sys.stderr.write", "sys.stderr.write", "sys.stderr.write", "sys.stderr.write", "sys.stderr.write", "target.clone", "torch.clamp", "torch.clamp", "torch.clamp", "torchvision.transforms.functional.adjust_contrast", "torchvision.utils.save_image", "str", "total_loss.item", "content_loss.item", "loss_patch.item", "loss_glob.item", "reg_tv.item"], "function", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "checkin", "(", "epoch", ",", "target", ",", "total_loss", ",", "content_loss", ",", "loss_patch", ",", "loss_glob", ",", "reg_tv", ",", "out_path", ")", ":", "\n", "    ", "sys", ".", "stderr", ".", "write", "(", "f'After {epoch} iterations'", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "f'Total loss: {total_loss.item()}'", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "f'Content loss: {content_loss.item()}'", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "f'patch loss: {loss_patch.item()}'", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "f'dir loss: {loss_glob.item()}'", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "f'TV loss: {reg_tv.item()}'", ")", "\n", "output_image", "=", "target", ".", "clone", "(", ")", "\n", "output_image", "=", "torch", ".", "clamp", "(", "output_image", ",", "0", ",", "1", ")", "\n", "output_image", "=", "adjust_contrast", "(", "output_image", ",", "1.5", ")", "\n", "save_image", "(", "output_image", ",", "str", "(", "out_path", ")", ",", "nrow", "=", "1", ",", "normalize", "=", "True", ")", "\n", "return", "out_path", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.img_normalize": [[162, 169], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "img_normalize", "(", "image", ",", "device", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.clip_normalize": [[171, 179], ["torch.interpolate", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "clip_normalize", "(", "image", ",", "device", ")", ":", "\n", "    ", "image", "=", "F", ".", "interpolate", "(", "image", ",", "size", "=", "224", ",", "mode", "=", "'bicubic'", ")", "\n", "mean", "=", "torch", ".", "tensor", "(", "[", "0.48145466", ",", "0.4578275", ",", "0.40821073", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.26862954", ",", "0.26130258", ",", "0.27577711", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.get_image_prior_losses": [[181, 188], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "get_image_prior_losses", "(", "inputs_jit", ")", ":", "\n", "    ", "diff1", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "\n", "diff2", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "diff3", "=", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", "1", ":", "]", "\n", "diff4", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", "1", ":", "]", "\n", "loss_var_l2", "=", "torch", ".", "norm", "(", "diff1", ")", "+", "torch", ".", "norm", "(", "diff2", ")", "+", "torch", ".", "norm", "(", "diff3", ")", "+", "torch", ".", "norm", "(", "diff4", ")", "\n", "return", "loss_var_l2", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.predict.compose_text_with_templates": [[190, 192], ["template.format", "template.imagenet_templates", "template.imagenet_templates"], "function", ["None"], ["", "def", "compose_text_with_templates", "(", "text", ":", "str", ",", "templates", "=", "imagenet_templates", ")", "->", "list", ":", "\n", "    ", "return", "[", "template", ".", "format", "(", "text", ")", "for", "template", "in", "templates", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.FlatFolderDataset.__init__": [[44, 49], ["torch.Dataset.__init__", "list", "pathlib.Path().glob", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", ")", ":", "\n", "        ", "super", "(", "FlatFolderDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "paths", "=", "list", "(", "Path", "(", "self", ".", "root", ")", ".", "glob", "(", "'*'", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.FlatFolderDataset.__getitem__": [[50, 55], ["PIL.Image.open().convert", "test_intp.FlatFolderDataset.transform", "PIL.Image.open", "str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "str", "(", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.FlatFolderDataset.__len__": [[56, 58], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.FlatFolderDataset.name": [[59, 61], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'FlatFolderDataset'", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.intp": [[24, 29], ["zip", "model3.parameters", "model1.parameters", "model2.parameters", "torch.Parameter"], "function", ["None"], ["def", "intp", "(", "model1", ",", "model2", ",", "model3", ",", "decay", "=", "0.999", ")", ":", "\n", "\n", "    ", "for", "p_out", ",", "p_in1", ",", "p_in2", "in", "zip", "(", "model3", ".", "parameters", "(", ")", ",", "model1", ".", "parameters", "(", ")", ",", "model2", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "p_out", ".", "data", "=", "nn", ".", "Parameter", "(", "p_in1", "*", "(", "1", "-", "decay", ")", "+", "p_in2", "*", "(", "decay", ")", ")", ";", "\n", "", "return", "model3", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.test_transform": [[30, 36], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "test_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "Resize", "(", "size", "=", "(", "512", ",", "512", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_intp.hr_transform": [[37, 42], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "hr_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.sampler.InfiniteSamplerWrapper.__init__": [[19, 21], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "self", ".", "num_samples", "=", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.sampler.InfiniteSamplerWrapper.__iter__": [[22, 24], ["iter", "sampler.InfiniteSampler"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.sampler.InfiniteSampler"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "InfiniteSampler", "(", "self", ".", "num_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.sampler.InfiniteSamplerWrapper.__len__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "2", "**", "31", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.sampler.InfiniteSampler": [[5, 16], ["numpy.random.permutation", "numpy.random.seed", "numpy.random.permutation"], "function", ["None"], ["def", "InfiniteSampler", "(", "n", ")", ":", "\n", "# i = 0", "\n", "    ", "i", "=", "n", "-", "1", "\n", "order", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "while", "True", ":", "\n", "        ", "yield", "order", "[", "i", "]", "\n", "i", "+=", "1", "\n", "if", "i", ">=", "n", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", ")", "\n", "order", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.calc_mean_std": [[4, 13], ["feat.size", "feat_var.sqrt().view", "feat.view().mean().view", "len", "feat.view().var", "feat_var.sqrt", "feat.view().mean", "feat.view", "feat.view"], "function", ["None"], ["def", "calc_mean_std", "(", "feat", ",", "eps", "=", "1e-5", ")", ":", "\n", "# eps is a small value added to the variance to avoid divide-by-zero.", "\n", "    ", "size", "=", "feat", ".", "size", "(", ")", "\n", "assert", "(", "len", "(", "size", ")", "==", "4", ")", "\n", "N", ",", "C", "=", "size", "[", ":", "2", "]", "\n", "feat_var", "=", "feat", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", ".", "var", "(", "dim", "=", "2", ")", "+", "eps", "\n", "feat_std", "=", "feat_var", ".", "sqrt", "(", ")", ".", "view", "(", "N", ",", "C", ",", "1", ",", "1", ")", "\n", "feat_mean", "=", "feat", ".", "view", "(", "N", ",", "C", ",", "-", "1", ")", ".", "mean", "(", "dim", "=", "2", ")", ".", "view", "(", "N", ",", "C", ",", "1", ",", "1", ")", "\n", "return", "feat_mean", ",", "feat_std", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.adaptive_instance_normalization": [[15, 32], ["content_feat.size", "function.calc_mean_std", "content_feat.size", "function.calc_mean_std", "function.calc_mean_std", "content_std.expand", "ext_style[].expand", "content_std.expand", "style_mean.expand", "content_mean.expand", "ext_style[].expand", "content_feat.size", "style_feat.size", "content_mean.expand", "style_std.expand"], "function", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.calc_mean_std", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.calc_mean_std", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.calc_mean_std"], ["", "def", "adaptive_instance_normalization", "(", "content_feat", ",", "style_feat", ",", "ext_style", "=", "None", ")", ":", "\n", "    ", "if", "ext_style", "is", "not", "None", ":", "\n", "        ", "size", "=", "content_feat", ".", "size", "(", ")", "\n", "content_mean", ",", "content_std", "=", "calc_mean_std", "(", "content_feat", ")", "\n", "\n", "normalized_feat", "=", "(", "content_feat", "-", "content_mean", ".", "expand", "(", "\n", "size", ")", ")", "/", "content_std", ".", "expand", "(", "size", ")", "\n", "return", "normalized_feat", "*", "ext_style", "[", "0", "]", ".", "expand", "(", "size", ")", "+", "ext_style", "[", "1", "]", ".", "expand", "(", "size", ")", "\n", "", "else", ":", "\n", "        ", "assert", "(", "content_feat", ".", "size", "(", ")", "[", ":", "2", "]", "==", "style_feat", ".", "size", "(", ")", "[", ":", "2", "]", ")", "\n", "size", "=", "content_feat", ".", "size", "(", ")", "\n", "style_mean", ",", "style_std", "=", "calc_mean_std", "(", "style_feat", ")", "\n", "content_mean", ",", "content_std", "=", "calc_mean_std", "(", "content_feat", ")", "\n", "\n", "normalized_feat", "=", "(", "content_feat", "-", "content_mean", ".", "expand", "(", "\n", "size", ")", ")", "/", "content_std", ".", "expand", "(", "size", ")", "\n", "return", "normalized_feat", "*", "style_std", ".", "expand", "(", "size", ")", "+", "style_mean", ".", "expand", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._calc_feat_flatten_mean_std": [[34, 42], ["isinstance", "feat.view", "feat.view.mean", "feat.view.std", "feat.size"], "function", ["None"], ["", "", "def", "_calc_feat_flatten_mean_std", "(", "feat", ")", ":", "\n", "# takes 3D feat (C, H, W), return mean and std of array within channels", "\n", "    ", "assert", "(", "feat", ".", "size", "(", ")", "[", "0", "]", "==", "3", ")", "\n", "assert", "(", "isinstance", "(", "feat", ",", "torch", ".", "FloatTensor", ")", ")", "\n", "feat_flatten", "=", "feat", ".", "view", "(", "3", ",", "-", "1", ")", "\n", "mean", "=", "feat_flatten", ".", "mean", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "feat_flatten", ".", "std", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "feat_flatten", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._mat_sqrt": [[44, 47], ["torch.svd", "torch.mm", "torch.mm", "V.t", "D.pow().diag", "D.pow"], "function", ["None"], ["", "def", "_mat_sqrt", "(", "x", ")", ":", "\n", "    ", "U", ",", "D", ",", "V", "=", "torch", ".", "svd", "(", "x", ")", "\n", "return", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "U", ",", "D", ".", "pow", "(", "0.5", ")", ".", "diag", "(", ")", ")", ",", "V", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function.coral": [[49, 76], ["function._calc_feat_flatten_mean_std", "function._calc_feat_flatten_mean_std", "torch.mm", "source_f_transfer.view", "source_f_std.expand_as", "torch.mm", "torch.eye", "target_f_std.expand_as", "torch.mm", "torch.eye", "function._mat_sqrt", "torch.mm", "target_f_mean.expand_as", "source.size", "source_f_mean.expand_as", "source_f_norm.t", "target_f_mean.expand_as", "target_f_norm.t", "torch.inverse", "target_f_std.expand_as", "function._mat_sqrt"], "function", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._calc_feat_flatten_mean_std", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._calc_feat_flatten_mean_std", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._mat_sqrt", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.function._mat_sqrt"], ["", "def", "coral", "(", "source", ",", "target", ")", ":", "\n", "# assume both source and target are 3D array (C, H, W)", "\n", "# Note: flatten -> f", "\n", "\n", "    ", "source_f", ",", "source_f_mean", ",", "source_f_std", "=", "_calc_feat_flatten_mean_std", "(", "source", ")", "\n", "source_f_norm", "=", "(", "source_f", "-", "source_f_mean", ".", "expand_as", "(", "\n", "source_f", ")", ")", "/", "source_f_std", ".", "expand_as", "(", "source_f", ")", "\n", "source_f_cov_eye", "=", "torch", ".", "mm", "(", "source_f_norm", ",", "source_f_norm", ".", "t", "(", ")", ")", "+", "torch", ".", "eye", "(", "3", ")", "\n", "\n", "target_f", ",", "target_f_mean", ",", "target_f_std", "=", "_calc_feat_flatten_mean_std", "(", "target", ")", "\n", "target_f_norm", "=", "(", "target_f", "-", "target_f_mean", ".", "expand_as", "(", "\n", "target_f", ")", ")", "/", "target_f_std", ".", "expand_as", "(", "target_f", ")", "\n", "target_f_cov_eye", "=", "torch", ".", "mm", "(", "target_f_norm", ",", "target_f_norm", ".", "t", "(", ")", ")", "+", "torch", ".", "eye", "(", "3", ")", "\n", "\n", "source_f_norm_transfer", "=", "torch", ".", "mm", "(", "\n", "_mat_sqrt", "(", "target_f_cov_eye", ")", ",", "\n", "torch", ".", "mm", "(", "torch", ".", "inverse", "(", "_mat_sqrt", "(", "source_f_cov_eye", ")", ")", ",", "\n", "source_f_norm", ")", "\n", ")", "\n", "\n", "source_f_transfer", "=", "source_f_norm_transfer", "*", "target_f_std", ".", "expand_as", "(", "source_f_norm", ")", "+", "target_f_mean", ".", "expand_as", "(", "source_f_norm", ")", "\n", "\n", "return", "source_f_transfer", ".", "view", "(", "source", ".", "size", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.decoder_cls.__init__": [[5, 37], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Upsample", "torch.Upsample", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Upsample", "torch.Upsample", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Upsample", "torch.Upsample", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "decoder_cls", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "decode", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "256", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "128", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "64", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "(", "3", ",", "3", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "3", ",", "(", "3", ",", "3", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.decoder_cls.forward": [[38, 40], ["fast_stylenet.decoder_cls.decode"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "content", ")", ":", "\n", "        ", "return", "self", ".", "decode", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.__init__": [[131, 145], ["torch.Module.__init__", "list", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MSELoss", "torch.MSELoss", "encoder.children", "getattr().parameters", "getattr"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "enc_layers", "=", "list", "(", "encoder", ".", "children", "(", ")", ")", "\n", "self", ".", "enc_1", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", ":", "4", "]", ")", "# input -> relu1_1", "\n", "self", ".", "enc_2", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "4", ":", "11", "]", ")", "# relu1_1 -> relu2_1", "\n", "self", ".", "enc_3", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "11", ":", "18", "]", ")", "# relu2_1 -> relu3_1", "\n", "self", ".", "enc_4", "=", "nn", ".", "Sequential", "(", "*", "enc_layers", "[", "18", ":", "31", "]", ")", "# relu3_1 -> relu4_1", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "mse_loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "# fix the encoder", "\n", "for", "name", "in", "[", "'enc_1'", ",", "'enc_2'", ",", "'enc_3'", ",", "'enc_4'", "]", ":", "\n", "            ", "for", "param", "in", "getattr", "(", "self", ",", "name", ")", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.encode_with_intermediate": [[147, 153], ["range", "getattr", "results.append", "getattr."], "methods", ["None"], ["", "", "", "def", "encode_with_intermediate", "(", "self", ",", "input", ")", ":", "\n", "        ", "results", "=", "[", "input", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "func", "=", "getattr", "(", "self", ",", "'enc_{:d}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "results", ".", "append", "(", "func", "(", "results", "[", "-", "1", "]", ")", ")", "\n", "", "return", "results", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.encode": [[155, 159], ["range", "getattr"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "input", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "input", "=", "getattr", "(", "self", ",", "'enc_{:d}'", ".", "format", "(", "i", "+", "1", ")", ")", "(", "input", ")", "\n", "", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.calc_content_loss": [[160, 164], ["fast_stylenet.Net.mse_loss", "input.size", "target.size"], "methods", ["None"], ["", "def", "calc_content_loss", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "assert", "(", "input", ".", "size", "(", ")", "==", "target", ".", "size", "(", ")", ")", "\n", "assert", "(", "target", ".", "requires_grad", "is", "False", ")", "\n", "return", "self", ".", "mse_loss", "(", "input", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.forward": [[165, 177], ["fast_stylenet.Net.encode", "fast_stylenet.Net.encode_with_intermediate", "fast_stylenet.Net.decoder", "fast_stylenet.Net.encode_with_intermediate", "fast_stylenet.Net.calc_content_loss"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.encode", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.encode_with_intermediate", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.encode_with_intermediate", "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.fast_stylenet.Net.calc_content_loss"], ["", "def", "forward", "(", "self", ",", "content", ")", ":", "\n", "\n", "        ", "content_feat", "=", "self", ".", "encode", "(", "content", ")", "\n", "ct", "=", "self", ".", "encode_with_intermediate", "(", "content", ")", "\n", "t", "=", "content_feat", "\n", "\n", "g_t", "=", "self", ".", "decoder", "(", "t", ")", "\n", "g_t_feats", "=", "self", ".", "encode_with_intermediate", "(", "g_t", ")", "\n", "\n", "loss_c", "=", "self", ".", "calc_content_loss", "(", "g_t_feats", "[", "-", "1", "]", ",", "ct", "[", "-", "1", "]", ")", "\n", "\n", "return", "loss_c", ",", "g_t", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__": [[52, 57], ["torch.Dataset.__init__", "list", "pathlib.Path().glob", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", ")", ":", "\n", "        ", "super", "(", "FlatFolderDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "paths", "=", "list", "(", "Path", "(", "self", ".", "root", ")", ".", "glob", "(", "'*'", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__getitem__": [[58, 63], ["PIL.Image.open().convert", "train_fast.FlatFolderDataset.transform", "PIL.Image.open", "str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "paths", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "str", "(", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.FlatFolderDataset.name": [[67, 69], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'FlatFolderDataset'", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.train_transform": [[23, 29], ["torchvision.transforms.Compose", "torchvision.transforms.RandomCrop", "torchvision.transforms.ToTensor"], "function", ["None"], ["def", "train_transform", "(", "crop_size", "=", "224", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "RandomCrop", "(", "crop_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "", "def", "test_transform", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.test_transform": [[29, 35], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "test_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "Resize", "(", "size", "=", "(", "512", ",", "512", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.hr_transform": [[36, 41], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "hr_transform", "(", ")", ":", "\n", "    ", "transform_list", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", "\n", "]", "\n", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.img_normalize": [[42, 50], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "img_normalize", "(", "image", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.load_image": [[70, 81], ["PIL.Image.open", "torchvision.transforms.Compose", "[].unsqueeze", "image.resize.resize", "torchvision.transforms.ToTensor", "transforms.Compose."], "function", ["None"], ["", "", "def", "load_image", "(", "img_path", ",", "img_size", "=", "None", ")", ":", "\n", "\n", "    ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "if", "img_size", "is", "not", "None", ":", "\n", "        ", "image", "=", "image", ".", "resize", "(", "(", "img_size", ",", "img_size", ")", ")", "\n", "", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "image", "=", "transform", "(", "image", ")", "[", ":", "3", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.adjust_learning_rate": [[82, 87], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "iteration_count", ")", ":", "\n", "    ", "\"\"\"Imitating the original implementation\"\"\"", "\n", "lr", "=", "args", ".", "lr", "/", "(", "1.0", "+", "args", ".", "lr_decay", "*", "iteration_count", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.clip_normalize": [[88, 97], ["torch.interpolate", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "", "def", "clip_normalize", "(", "image", ")", ":", "\n", "    ", "image", "=", "F", ".", "interpolate", "(", "image", ",", "size", "=", "224", ",", "mode", "=", "'bicubic'", ")", "\n", "mean", "=", "torch", ".", "tensor", "(", "[", "0.48145466", ",", "0.4578275", ",", "0.40821073", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "0.26862954", ",", "0.26130258", ",", "0.27577711", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.reverse_normalize": [[98, 106], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mean.view.view", "std.view.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "reverse_normalize", "(", "image", ")", ":", "\n", "    ", "mean", "=", "torch", ".", "tensor", "(", "[", "-", "0.485", "/", "0.229", ",", "-", "0.456", "/", "0.224", ",", "-", "0.406", "/", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "[", "1.", "/", "0.229", ",", "1.", "/", "0.224", ",", "1.", "/", "0.225", "]", ")", ".", "to", "(", "device", ")", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "image", "=", "(", "image", "-", "mean", ")", "/", "std", "\n", "return", "image", "\n", "", "def", "get_image_prior_losses", "(", "inputs_jit", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.get_image_prior_losses": [[106, 116], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "get_image_prior_losses", "(", "inputs_jit", ")", ":", "\n", "# COMPUTE total variation regularization loss", "\n", "    ", "diff1", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "\n", "diff2", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "diff3", "=", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", "1", ":", "]", "\n", "diff4", "=", "inputs_jit", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "-", "inputs_jit", "[", ":", ",", ":", ",", "1", ":", ",", "1", ":", "]", "\n", "\n", "loss_var_l2", "=", "torch", ".", "norm", "(", "diff1", ")", "+", "torch", ".", "norm", "(", "diff2", ")", "+", "torch", ".", "norm", "(", "diff3", ")", "+", "torch", ".", "norm", "(", "diff4", ")", "\n", "\n", "return", "loss_var_l2", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.train_fast.compose_text_with_templates": [[167, 169], ["template.format"], "function", ["None"], ["def", "compose_text_with_templates", "(", "text", ":", "str", ",", "templates", "=", "imagenet_templates", ")", "->", "list", ":", "\n", "    ", "return", "[", "template", ".", "format", "(", "text", ")", "for", "template", "in", "templates", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.load_image": [[7, 20], ["PIL.Image.open", "torchvision.transforms.Compose", "[].unsqueeze", "image.resize.resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "transforms.Compose."], "function", ["None"], ["def", "load_image", "(", "img_path", ",", "img_size", "=", "None", ")", ":", "\n", "\n", "    ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "if", "img_size", "is", "not", "None", ":", "\n", "        ", "image", "=", "image", ".", "resize", "(", "(", "img_size", ",", "img_size", ")", ")", "# change image size to (3, img_size, img_size)", "\n", "\n", "", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ",", "# this is from ImageNet dataset", "\n", "]", ")", "\n", "image", "=", "transform", "(", "image", ")", "[", ":", "3", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "image", "\n", "", "def", "load_image2", "(", "img_path", ",", "img_height", "=", "None", ",", "img_width", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.load_image2": [[20, 33], ["PIL.Image.open", "torchvision.transforms.Compose", "[].unsqueeze", "image.resize.resize", "torchvision.transforms.ToTensor", "transforms.Compose."], "function", ["None"], ["", "def", "load_image2", "(", "img_path", ",", "img_height", "=", "None", ",", "img_width", "=", "None", ")", ":", "\n", "\n", "    ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "if", "img_width", "is", "not", "None", ":", "\n", "        ", "image", "=", "image", ".", "resize", "(", "(", "img_width", ",", "img_height", ")", ")", "# change image size to (3, img_size, img_size)", "\n", "\n", "", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "\n", "image", "=", "transform", "(", "image", ")", "[", ":", "3", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.im_convert": [[34, 44], ["tensor.to().clone().detach", "image.clip.numpy().squeeze", "image.clip.transpose", "image.clip.clip", "numpy.array", "tensor.to().clone", "image.clip.numpy", "numpy.array", "tensor.to"], "function", ["None"], ["", "def", "im_convert", "(", "tensor", ")", ":", "\n", "\n", "    ", "image", "=", "tensor", ".", "to", "(", "\"cpu\"", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "image", "=", "image", ".", "numpy", "(", ")", ".", "squeeze", "(", "0", ")", "# change size to (channel, height, width)", "\n", "\n", "image", "=", "image", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "image", "=", "image", "*", "np", ".", "array", "(", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", "+", "np", ".", "array", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ")", "# change into unnormalized image", "\n", "image", "=", "image", ".", "clip", "(", "0", ",", "1", ")", "# in the previous steps, we change PIL image(0, 255) into tensor(0.0, 1.0), so convert it", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.im_convert2": [[45, 56], ["tensor.to().clone().detach", "image.clip.numpy().squeeze", "image.clip.transpose", "image.clip.clip", "tensor.to().clone", "image.clip.numpy", "tensor.to"], "function", ["None"], ["", "def", "im_convert2", "(", "tensor", ")", ":", "\n", "    ", "\"\"\" Display a tensor as an image. \"\"\"", "\n", "\n", "image", "=", "tensor", ".", "to", "(", "\"cpu\"", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "image", "=", "image", ".", "numpy", "(", ")", ".", "squeeze", "(", "0", ")", "# change size to (channel, height, width)", "\n", "\n", "image", "=", "image", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "# change into unnormalized image", "\n", "image", "=", "image", ".", "clip", "(", "0", ",", "1", ")", "# in the previous steps, we change PIL image(0, 255) into tensor(0.0, 1.0), so convert it", "\n", "\n", "return", "image", "\n", "", "def", "get_features", "(", "image", ",", "model", ",", "layers", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.get_features": [[56, 75], ["model._modules.items", "layer"], "function", ["None"], ["", "def", "get_features", "(", "image", ",", "model", ",", "layers", "=", "None", ")", ":", "\n", "\n", "    ", "if", "layers", "is", "None", ":", "\n", "        ", "layers", "=", "{", "'0'", ":", "'conv1_1'", ",", "\n", "'5'", ":", "'conv2_1'", ",", "\n", "'10'", ":", "'conv3_1'", ",", "\n", "'19'", ":", "'conv4_1'", ",", "\n", "'21'", ":", "'conv4_2'", ",", "\n", "'28'", ":", "'conv5_1'", ",", "\n", "'31'", ":", "'conv5_2'", "\n", "}", "\n", "", "features", "=", "{", "}", "\n", "x", "=", "image", "\n", "for", "name", ",", "layer", "in", "model", ".", "_modules", ".", "items", "(", ")", ":", "\n", "        ", "x", "=", "layer", "(", "x", ")", "\n", "if", "name", "in", "layers", ":", "\n", "            ", "features", "[", "layers", "[", "name", "]", "]", "=", "x", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.rand_bbox": [[78, 88], ["numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["", "def", "rand_bbox", "(", "size", ",", "res", ")", ":", "\n", "    ", "W", "=", "size", "\n", "H", "=", "size", "\n", "cut_w", "=", "res", "\n", "cut_h", "=", "res", "\n", "tx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "W", "-", "cut_w", ")", "\n", "ty", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "H", "-", "cut_h", ")", "\n", "bbx1", "=", "tx", "\n", "bby1", "=", "ty", "\n", "return", "bbx1", ",", "bby1", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.rand_sampling": [[90, 96], ["utils.rand_bbox"], "function", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.rand_bbox"], ["", "def", "rand_sampling", "(", "args", ",", "content_image", ")", ":", "\n", "    ", "bbxl", "=", "[", "]", "\n", "bbyl", "=", "[", "]", "\n", "bbx1", ",", "bby1", "=", "rand_bbox", "(", "args", ".", "img_size", ",", "args", ".", "crop_size", ")", "\n", "crop_img", "=", "content_image", "[", ":", ",", ":", ",", "bby1", ":", "bby1", "+", "args", ".", "crop_size", ",", "bbx1", ":", "bbx1", "+", "args", ".", "crop_size", "]", "\n", "return", "crop_img", "\n", "\n"]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.rand_sampling_all": [[97, 106], ["range", "utils.rand_bbox", "bbxl.append", "bbyl.append"], "function", ["home.repos.pwc.inspect_result.cyclomon_clipstyler.None.utils.rand_bbox"], ["", "def", "rand_sampling_all", "(", "args", ")", ":", "\n", "    ", "bbxl", "=", "[", "]", "\n", "bbyl", "=", "[", "]", "\n", "out", "=", "[", "]", "\n", "for", "cc", "in", "range", "(", "50", ")", ":", "\n", "        ", "bbx1", ",", "bby1", "=", "rand_bbox", "(", "args", ".", "img_size", ",", "args", ".", "crop_size", ")", "\n", "bbxl", ".", "append", "(", "bbx1", ")", "\n", "bbyl", ".", "append", "(", "bby1", ")", "\n", "", "return", "bbxl", ",", "bbyl", "\n", "", ""]], "home.repos.pwc.inspect_result.cyclomon_clipstyler.None.test_video.test_transform": [[16, 25], ["transform_list.append", "torchvision.transforms.Compose", "transform_list.append", "transform_list.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop"], "function", ["None"], ["def", "test_transform", "(", "width", ",", "height", ",", "crop", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "width", "!=", "0", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "(", "width", ",", "height", ")", ")", ")", "\n", "", "if", "crop", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "CenterCrop", "(", "size", ")", ")", "\n", "", "transform_list", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "return", "transform", "\n", "\n"]]}