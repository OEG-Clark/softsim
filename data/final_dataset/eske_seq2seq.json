{"home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.failure": [[24, 26], ["print"], "function", ["None"], ["", "def", "failure", "(", "message", ")", ":", "\n", "    ", "print", "(", "'{}failure: {}{}'", ".", "format", "(", "FAIL", ",", "message", ",", "ENDC", ")", ")", "\n", "", "def", "success", "(", "message", ")", ":", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.success": [[26, 28], ["print"], "function", ["None"], ["", "def", "success", "(", "message", ")", ":", "\n", "    ", "print", "(", "'{}success: {}{}'", ".", "format", "(", "OKGREEN", ",", "message", ",", "ENDC", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.get_best_score": [[37, 54], ["open", "len", "re.search", "len", "scores.append", "max", "min", "float", "re.search.group"], "function", ["None"], ["", "def", "get_best_score", "(", "log_file", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "with", "open", "(", "log_file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "score_", "=", "re", ".", "search", "(", "r' (score|bleu|ter|loss|cer|wer|bleu1)=(.*?) '", ",", "line", "+", "' '", ")", "\n", "\n", "if", "score_", ":", "\n", "                ", "scores", ".", "append", "(", "float", "(", "score_", ".", "group", "(", "2", ")", ")", ")", "\n", "\n", "", "", "", "if", "len", "(", "scores", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "elif", "len", "(", "scores", ")", "==", "1", ":", "\n", "        ", "return", "scores", "[", "0", "]", "\n", "", "elif", "scores", "[", "0", "]", "<=", "scores", "[", "-", "1", "]", ":", "\n", "        ", "return", "max", "(", "scores", ")", "\n", "", "else", ":", "\n", "        ", "return", "min", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run": [[56, 91], ["os.path.join", "os.path.join", "os.path.basename", "print", "re.search", "subprocess.check_output().decode", "open", "f.write", "run-tests.failure", "float", "run-tests.get_best_score", "e.output.decode", "e.output.decode.strip().split", "float.group", "run-tests.success", "subprocess.check_output", "run-tests.success", "run-tests.failure", "e.output.decode.strip"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.failure", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.get_best_score", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.success", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.success", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.failure"], ["", "", "def", "run", "(", "dir_", ",", "score", "=", "None", ")", ":", "\n", "    ", "config_file", "=", "os", ".", "path", ".", "join", "(", "dir_", ",", "'config.yaml'", ")", "\n", "log_file_", "=", "os", ".", "path", ".", "join", "(", "dir_", ",", "'log.txt'", ")", "\n", "name", "=", "os", ".", "path", ".", "basename", "(", "dir_", ")", "\n", "\n", "if", "score", "is", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "score", "=", "get_best_score", "(", "log_file_", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "", "print", "(", "'Running {}'", ".", "format", "(", "name", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "output", "=", "subprocess", ".", "check_output", "(", "[", "'./seq2seq.sh'", ",", "config_file", ",", "'--eval'", "]", "+", "extra_params", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ")", ".", "decode", "(", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "\n", "        ", "output", "=", "e", ".", "output", ".", "decode", "(", ")", "\n", "\n", "", "scores", "=", "output", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "-", "1", "]", "+", "' '", "\n", "score_", "=", "re", ".", "search", "(", "r' (score|bleu|ter|loss|cer|wer|bleu1)=(.*?) '", ",", "scores", ")", "\n", "\n", "with", "open", "(", "log_file", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "output", ")", "\n", "\n", "", "if", "not", "score_", ":", "\n", "        ", "failure", "(", "'unable to run test (see log file)'", ")", "\n", "", "else", ":", "\n", "        ", "score_", "=", "float", "(", "score_", ".", "group", "(", "2", ")", ")", "\n", "if", "score", "is", "None", ":", "\n", "            ", "success", "(", "'obtained {}'", ".", "format", "(", "score_", ")", ")", "\n", "", "elif", "score_", "==", "score", ":", "\n", "            ", "success", "(", "'scores matching ({})'", ".", "format", "(", "score_", ")", ")", "\n", "", "else", ":", "\n", "            ", "failure", "(", "'obtained {}, expected {}'", ".", "format", "(", "score_", ",", "score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.AMU.avg.sort_key": [[16, 22], ["keys.index", "len"], "function", ["None"], ["def", "sort_key", "(", "item", ")", ":", "\n", "    ", "key", ",", "_", "=", "item", "\n", "if", "key", "in", "keys", ":", "\n", "        ", "return", "keys", ".", "index", "(", "key", ")", "\n", "", "else", ":", "\n", "        ", "return", "len", "(", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.vocab-stats.extract_deletes": [[34, 45], ["deletes.append"], "function", ["None"], ["def", "extract_deletes", "(", "ops", ",", "src_words", ")", ":", "\n", "    ", "i", "=", "0", "\n", "deletes", "=", "[", "]", "\n", "\n", "for", "op", "in", "ops", ":", "\n", "        ", "if", "op", "==", "'<KEEP>'", ":", "\n", "            ", "i", "+=", "1", "\n", "", "elif", "op", "==", "'<DEL>'", ":", "\n", "            ", "deletes", ".", "append", "(", "src_words", "[", "i", "]", ")", "\n", "\n", "", "", "return", "deletes", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.get-best-score.print_scores": [[25, 118], ["open", "max", "sorted", "print", "re.match", "re.search", "re.findall", "d.get", "scores.items", "next", "sorted.pop", "sorted.items", "int", "divmod", "divmod", "divmod", "dateutil.parser.parse", "get-best-score.print_scores.read_time"], "function", ["None"], ["def", "print_scores", "(", "log_file", ",", "time", "=", "False", ",", "label", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "log_file", ")", "as", "log_file", ":", "\n", "        ", "scores", "=", "{", "}", "\n", "times", "=", "{", "}", "\n", "current_step", "=", "0", "\n", "max_step", "=", "0", "\n", "starting_time", "=", "None", "\n", "param_count", "=", "None", "\n", "\n", "def", "read_time", "(", "line", ")", ":", "\n", "            ", "if", "not", "time", ":", "\n", "                ", "return", "None", "\n", "", "m", "=", "re", ".", "match", "(", "'../.. ..:..:..'", ",", "line", ")", "\n", "if", "m", ":", "\n", "                ", "return", "dateutil", ".", "parser", ".", "parse", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "\n", "", "", "for", "line", "in", "log_file", ":", "\n", "            ", "if", "starting_time", "is", "None", ":", "\n", "                ", "starting_time", "=", "read_time", "(", "line", ")", "\n", "", "if", "param_count", "is", "None", ":", "\n", "                ", "m", "=", "re", ".", "search", "(", "'number of parameters: (.*)'", ",", "line", ")", "\n", "if", "m", ":", "\n", "                    ", "param_count", "=", "m", ".", "group", "(", "1", ")", "\n", "\n", "", "", "m", "=", "re", ".", "search", "(", "'step (\\d+)'", ",", "line", ")", "\n", "if", "m", ":", "\n", "                ", "current_step", "=", "int", "(", "m", ".", "group", "(", "1", ")", ")", "\n", "times", ".", "setdefault", "(", "current_step", ",", "read_time", "(", "line", ")", ")", "\n", "max_step", "=", "max", "(", "max_step", ",", "current_step", ")", "\n", "continue", "\n", "\n", "", "if", "args", ".", "task_name", "is", "not", "None", ":", "\n", "                ", "if", "not", "re", ".", "search", "(", "args", ".", "task_name", ",", "line", ")", ":", "\n", "                    ", "continue", "\n", "", "", "if", "args", ".", "dev_prefix", "is", "not", "None", ":", "\n", "                ", "if", "not", "re", ".", "search", "(", "args", ".", "task_name", ",", "line", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "m", "=", "re", ".", "findall", "(", "'(loss|bleu|score|ter|wer|cer|bleu1|penalty|ratio)=(\\d+.\\d+)'", ",", "line", ")", "\n", "if", "m", ":", "\n", "                ", "scores_", "=", "{", "k", ":", "float", "(", "v", ")", "for", "k", ",", "v", "in", "m", "}", "\n", "scores", ".", "setdefault", "(", "current_step", ",", "scores_", ")", "\n", "\n", "", "", "def", "key", "(", "d", ")", ":", "\n", "            ", "score", "=", "d", ".", "get", "(", "args", ".", "score", ".", "lower", "(", ")", ")", "\n", "if", "score", "is", "None", ":", "\n", "                ", "score", "=", "d", ".", "get", "(", "'score'", ")", "\n", "\n", "", "if", "args", ".", "score", "in", "(", "'ter'", ",", "'wer'", ",", "'cer'", ",", "'loss'", ")", ":", "\n", "                ", "score", "=", "-", "score", "\n", "", "return", "score", "\n", "\n", "", "step", ",", "best", "=", "max", "(", "scores", ".", "items", "(", ")", ",", "key", "=", "lambda", "p", ":", "key", "(", "p", "[", "1", "]", ")", ")", "\n", "\n", "if", "'score'", "in", "best", ":", "\n", "            ", "missing_key", "=", "next", "(", "k", "for", "k", "in", "[", "'bleu'", ",", "'ter'", ",", "'wer'", ",", "'cer'", ",", "'bleu1'", ",", "'loss'", "]", "if", "k", "not", "in", "best", ")", "\n", "best", "[", "missing_key", "]", "=", "best", ".", "pop", "(", "'score'", ")", "\n", "\n", "", "keys", "=", "[", "args", ".", "score", ",", "'bleu'", ",", "'ter'", ",", "'wer'", ",", "'cer'", ",", "'bleu1'", ",", "'loss'", ",", "'penalty'", ",", "'ratio'", "]", "\n", "best", "=", "sorted", "(", "best", ".", "items", "(", ")", ",", "key", "=", "lambda", "p", ":", "keys", ".", "index", "(", "p", "[", "0", "]", ")", ")", "\n", "\n", "def", "pretty_time", "(", "seconds", ")", ":", "\n", "            ", "seconds", "=", "int", "(", "seconds", ")", "\n", "s", "=", "[", "]", "\n", "days", ",", "seconds", "=", "divmod", "(", "seconds", ",", "3600", "*", "24", ")", "\n", "if", "days", ">", "0", ":", "\n", "                ", "s", ".", "append", "(", "'{}d'", ".", "format", "(", "days", ")", ")", "\n", "", "hours", ",", "seconds", "=", "divmod", "(", "seconds", ",", "3600", ")", "\n", "if", "hours", ">", "0", ":", "\n", "                ", "s", ".", "append", "(", "'{}h'", ".", "format", "(", "hours", ")", ")", "\n", "", "minutes", ",", "seconds", "=", "divmod", "(", "seconds", ",", "60", ")", "\n", "if", "minutes", ">", "0", "and", "days", "==", "0", ":", "\n", "                ", "s", ".", "append", "(", "'{}min'", ".", "format", "(", "minutes", ")", ")", "\n", "", "if", "days", "==", "0", "and", "hours", "==", "0", "and", "minutes", "<", "5", "and", "seconds", ">", "0", ":", "\n", "                ", "s", ".", "append", "(", "'{}s'", ".", "format", "(", "seconds", ")", ")", "\n", "", "return", "''", ".", "join", "(", "s", ")", "\n", "\n", "", "if", "time", ":", "\n", "            ", "total_time", "=", "(", "times", "[", "max_step", "]", "-", "starting_time", ")", ".", "total_seconds", "(", ")", "\n", "train_time", "=", "(", "times", "[", "step", "]", "-", "starting_time", ")", ".", "total_seconds", "(", ")", "\n", "time_string", "=", "' time={}/{}'", ".", "format", "(", "pretty_time", "(", "train_time", ")", ",", "pretty_time", "(", "total_time", ")", ")", "\n", "", "else", ":", "\n", "            ", "time_string", "=", "''", "\n", "\n", "", "if", "label", "is", "None", ":", "\n", "            ", "label", "=", "''", "\n", "", "if", "args", ".", "params", "and", "param_count", "is", "not", "None", ":", "\n", "            ", "param_string", "=", "' params={}'", ".", "format", "(", "param_count", ")", "\n", "", "else", ":", "\n", "            ", "param_string", "=", "''", "\n", "\n", "", "print", "(", "label", "+", "' '", ".", "join", "(", "itertools", ".", "starmap", "(", "'{}={:.2f}'", ".", "format", ",", "best", ")", ")", ",", "\n", "'step={}/{}'", ".", "format", "(", "step", ",", "max_step", ")", "+", "param_string", "+", "time_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_files": [[52, 62], ["files.append", "file_.close", "codecs.open"], "function", ["None"], ["@", "contextmanager", "\n", "def", "open_files", "(", "names", ",", "mode", "=", "'r'", ")", ":", "\n", "    ", "files", "=", "[", "]", "\n", "try", ":", "\n", "        ", "for", "name_", "in", "names", ":", "\n", "            ", "files", ".", "append", "(", "codecs", ".", "open", "(", "name_", ",", "mode", "=", "mode", ")", ")", "\n", "", "yield", "files", "\n", "", "finally", ":", "\n", "        ", "for", "file_", "in", "files", ":", "\n", "            ", "file_", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files": [[64, 76], ["range", "files.append", "file_.close", "tempfile.NamedTemporaryFile", "temporary_files.append"], "function", ["None"], ["", "", "", "@", "contextmanager", "\n", "def", "open_temp_files", "(", "num", "=", "1", ",", "mode", "=", "'w'", ",", "delete", "=", "False", ")", ":", "\n", "    ", "files", "=", "[", "]", "\n", "try", ":", "\n", "        ", "for", "_", "in", "range", "(", "num", ")", ":", "\n", "            ", "files", ".", "append", "(", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "mode", ",", "delete", "=", "delete", ")", ")", "\n", "if", "not", "delete", ":", "\n", "                ", "temporary_files", ".", "append", "(", "files", "[", "-", "1", "]", ".", "name", ")", "\n", "", "", "yield", "files", "\n", "", "finally", ":", "\n", "        ", "for", "file_", "in", "files", ":", "\n", "            ", "file_", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.read_vocabulary": [[78, 82], ["open", "dict", "line.strip", "map", "enumerate"], "function", ["None"], ["", "", "", "def", "read_vocabulary", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "vocab_file", ":", "\n", "        ", "words", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "vocab_file", "]", "\n", "return", "dict", "(", "map", "(", "reversed", ",", "enumerate", "(", "words", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.create_vocabulary": [[84, 107], ["logging.info", "collections.Counter", "dict", "open", "open", "output_file.writelines", "map", "sorted", "len", "enumerate", "line.strip", "line.split", "collections.Counter.items", "collections.Counter.items"], "function", ["None"], ["", "", "def", "create_vocabulary", "(", "filename", ",", "output_filename", ",", "size", ",", "character_level", "=", "False", ",", "min_count", "=", "1", ")", ":", "\n", "    ", "logging", ".", "info", "(", "'creating vocabulary {} from {}'", ".", "format", "(", "output_filename", ",", "\n", "filename", ")", ")", "\n", "vocab", "=", "Counter", "(", ")", "\n", "with", "open", "(", "filename", ")", "as", "input_file", ",", "open", "(", "output_filename", ",", "'w'", ")", "as", "output_file", ":", "\n", "        ", "for", "line", "in", "input_file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "if", "character_level", "else", "line", ".", "split", "(", ")", "\n", "\n", "for", "w", "in", "line", ":", "\n", "                ", "vocab", "[", "w", "]", "+=", "1", "\n", "\n", "", "", "if", "min_count", ">", "1", ":", "\n", "            ", "vocab", "=", "{", "w", ":", "c", "for", "(", "w", ",", "c", ")", "in", "vocab", ".", "items", "(", ")", "if", "c", ">=", "min_count", "}", "\n", "\n", "", "vocab", "=", "{", "w", ":", "c", "for", "(", "w", ",", "c", ")", "in", "vocab", ".", "items", "(", ")", "if", "w", "not", "in", "_START_VOCAB", "}", "\n", "vocab_list", "=", "_START_VOCAB", "+", "sorted", "(", "vocab", ",", "key", "=", "lambda", "w", ":", "(", "-", "vocab", "[", "w", "]", ",", "w", ")", ")", "\n", "if", "0", "<", "size", "<", "len", "(", "vocab_list", ")", ":", "\n", "            ", "vocab_list", "=", "vocab_list", "[", ":", "size", "]", "\n", "\n", "", "output_file", ".", "writelines", "(", "w", "+", "'\\n'", "for", "w", "in", "vocab_list", ")", "\n", "\n", "", "return", "dict", "(", "map", "(", "reversed", ",", "enumerate", "(", "vocab_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_file": [[109, 153], ["logging.info", "prepare-data.open_temp_files", "open", "enumerate", "subprocess.Popen.wait", "processes.append", "processes.append", "processes.append", "processes.append", "processes.append", "processes.append", "processes.append", "processes.append", "processes.append", "subprocess.Popen", "os.path.join", "prepare-data.process_file.path_to"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files"], ["", "def", "process_file", "(", "filename", ",", "lang", ",", "ext", ",", "args", ")", ":", "\n", "    ", "logging", ".", "info", "(", "'processing '", "+", "filename", ")", "\n", "\n", "with", "open_temp_files", "(", "num", "=", "1", ")", "as", "output_", ",", "open", "(", "filename", ")", "as", "input_", ":", "\n", "        ", "output_", ",", "=", "output_", "\n", "\n", "def", "path_to", "(", "script_name", ")", ":", "\n", "            ", "if", "args", ".", "scripts", "is", "None", ":", "\n", "                ", "return", "script_name", "# assume script is in PATH", "\n", "", "else", ":", "\n", "                ", "return", "os", ".", "path", ".", "join", "(", "args", ".", "scripts", ",", "script_name", ")", "\n", "\n", "", "", "processes", "=", "[", "[", "'cat'", "]", "]", "# just copy file if there is no other operation", "\n", "\n", "if", "ext", "in", "args", ".", "deescape_special_chars", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'deescape-special-chars.perl'", ")", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "unescape_special_chars", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'unescape-special-chars.perl'", ")", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "normalize_punk", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'normalize-punctuation.perl'", ")", ",", "'-l'", ",", "lang", "]", ")", "\n", "", "if", "args", ".", "normalize_moses", ":", "\n", "            ", "processes", ".", "append", "(", "[", "'sed'", ",", "'s/|//g'", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "subwords", ":", "\n", "            ", "processes", ".", "append", "(", "[", "'sed'", ",", "'s/@\\\\+/@/g'", "]", ")", "# @@ is used as delimiter for subwords", "\n", "", "if", "ext", "not", "in", "args", ".", "no_tokenize", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'tokenizer.perl'", ")", ",", "'-l'", ",", "lang", ",", "'-threads'", ",", "str", "(", "args", ".", "threads", ")", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "lowercase", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'lowercase.perl'", ")", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "normalize_digits", ":", "\n", "            ", "processes", ".", "append", "(", "[", "'sed'", ",", "'s/[[:digit:]]/0/g'", "]", ")", "\n", "", "if", "ext", "in", "args", ".", "escape_special_chars", ":", "\n", "            ", "processes", ".", "append", "(", "[", "path_to", "(", "'escape-special-chars.perl'", ")", "]", ")", "\n", "\n", "", "ps", "=", "None", "\n", "\n", "for", "i", ",", "process", "in", "enumerate", "(", "processes", ")", ":", "\n", "            ", "stdout", "=", "output_", "if", "i", "==", "len", "(", "processes", ")", "-", "1", "else", "subprocess", ".", "PIPE", "\n", "stdin", "=", "input_", "if", "i", "==", "0", "else", "ps", ".", "stdout", "\n", "\n", "ps", "=", "subprocess", ".", "Popen", "(", "process", ",", "stdin", "=", "stdin", ",", "stdout", "=", "stdout", ",", "\n", "stderr", "=", "open", "(", "'/dev/null'", ",", "'w'", ")", ")", "\n", "\n", "", "ps", ".", "wait", "(", ")", "\n", "return", "output_", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.filter_corpus": [[155, 165], ["prepare-data.open_files", "prepare-data.open_temp_files", "zip", "len", "all", "zip", "output_file.write", "len", "zip", "line.split"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.open_files", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files"], ["", "", "def", "filter_corpus", "(", "filenames", ",", "args", ")", ":", "\n", "    ", "with", "open_files", "(", "filenames", ")", "as", "input_files", ",", "open_temp_files", "(", "len", "(", "filenames", ")", ")", "as", "output_files", ":", "\n", "        ", "for", "lines", "in", "zip", "(", "*", "input_files", ")", ":", "\n", "            ", "if", "all", "(", "min_", "<=", "len", "(", "line", ".", "split", "(", ")", ")", "<=", "max_", "for", "line", ",", "min_", ",", "max_", "\n", "in", "zip", "(", "lines", ",", "args", ".", "min", ",", "args", ".", "max", ")", ")", ":", "\n", "                ", "for", "line", ",", "output_file", "in", "zip", "(", "lines", ",", "output_files", ")", ":", "\n", "                    ", "output_file", ".", "write", "(", "line", ")", "\n", "\n", "", "", "", "return", "[", "f", ".", "name", "for", "f", "in", "output_files", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_corpus": [[167, 199], ["prepare-data.process_file", "prepare-data.open_files", "prepare-data.open_temp_files", "zip", "len", "list", "random.shuffle", "zip", "zip", "all", "set", "list", "output_file.write", "any", "lines.append", "set", "len", "zip", "line.split", "zip"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_file", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.open_files", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files"], ["", "", "def", "process_corpus", "(", "filenames", ",", "args", ")", ":", "\n", "    ", "filenames", "=", "[", "process_file", "(", "filename", ",", "lang", ",", "ext", ",", "args", ")", "\n", "for", "lang", ",", "ext", ",", "filename", "in", "zip", "(", "args", ".", "lang", ",", "args", ".", "extensions", ",", "filenames", ")", "]", "\n", "\n", "with", "open_files", "(", "filenames", ")", "as", "input_files", ",", "open_temp_files", "(", "len", "(", "filenames", ")", ")", "as", "output_files", ":", "\n", "\n", "# (lazy) sequence of sentence tuples", "\n", "        ", "all_lines", "=", "(", "lines", "for", "lines", "in", "zip", "(", "*", "input_files", ")", "if", "\n", "all", "(", "min_", "<=", "len", "(", "line", ".", "split", "(", ")", ")", "<=", "max_", "for", "line", ",", "min_", ",", "max_", "\n", "in", "zip", "(", "lines", ",", "args", ".", "min", ",", "args", ".", "max", ")", ")", ")", "\n", "\n", "if", "args", ".", "remove_duplicate_lines", ":", "\n", "            ", "seen_lines", "=", "[", "set", "(", ")", "for", "_", "in", "filenames", "]", "\n", "lines", "=", "[", "]", "\n", "for", "line_tuple", "in", "all_lines", ":", "\n", "                ", "if", "not", "any", "(", "line", "in", "seen_lines_", "for", "line", ",", "seen_lines_", "in", "\n", "zip", "(", "line_tuple", ",", "seen_lines", ")", ")", ":", "\n", "                    ", "lines", ".", "append", "(", "line_tuple", ")", "\n", "", "", "all_lines", "=", "lines", "\n", "", "elif", "args", ".", "remove_duplicates", ":", "\n", "            ", "all_lines", "=", "list", "(", "set", "(", "all_lines", ")", ")", "\n", "\n", "", "if", "args", ".", "shuffle", ":", "\n", "            ", "all_lines", "=", "list", "(", "all_lines", ")", "# not lazy anymore", "\n", "random", ".", "shuffle", "(", "all_lines", ")", "\n", "\n", "", "for", "lines", "in", "all_lines", ":", "# keeps it lazy if no shuffle", "\n", "            ", "for", "line", ",", "output_file", "in", "zip", "(", "lines", ",", "output_files", ")", ":", "\n", "                ", "output_file", ".", "write", "(", "line", ")", "\n", "\n", "", "", "return", "[", "f", ".", "name", "for", "f", "in", "output_files", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.split_corpus": [[201, 218], ["prepare-data.open_files", "output_filenames.append", "prepare-data.open_temp_files", "zip", "output_filenames.append", "output_file.writelines", "len", "itertools.islice"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.open_files", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files"], ["", "", "def", "split_corpus", "(", "filenames", ",", "sizes", ")", ":", "\n", "    ", "with", "open_files", "(", "filenames", ")", "as", "input_files", ":", "\n", "        ", "output_filenames", "=", "[", "]", "\n", "\n", "for", "size", "in", "sizes", ":", "\n", "            ", "if", "size", "==", "0", ":", "\n", "                ", "output_filenames", ".", "append", "(", "None", ")", "\n", "continue", "\n", "\n", "", "with", "open_temp_files", "(", "num", "=", "len", "(", "filenames", ")", ")", "as", "output_files", ":", "\n", "                ", "for", "input_file", ",", "output_file", "in", "zip", "(", "input_files", ",", "output_files", ")", ":", "\n", "# if size is None, this will read the whole file,", "\n", "# that's why we put train last", "\n", "                    ", "output_file", ".", "writelines", "(", "islice", "(", "input_file", ",", "size", ")", ")", "\n", "", "output_filenames", ".", "append", "(", "[", "f", ".", "name", "for", "f", "in", "output_files", "]", ")", "\n", "\n", "", "", "return", "output_filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.create_subwords": [[220, 223], ["subprocess.call", "str"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.call"], ["", "", "def", "create_subwords", "(", "filename", ",", "output_filename", ",", "size", ")", ":", "\n", "    ", "cmd", "=", "[", "'scripts/bpe/learn_bpe.py'", ",", "'--input'", ",", "filename", ",", "'-s'", ",", "str", "(", "size", ")", ",", "'--output'", ",", "output_filename", "]", "\n", "subprocess", ".", "call", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.apply_subwords": [[225, 232], ["prepare-data.open_temp_files", "subprocess.call"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.open_temp_files", "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.call"], ["", "def", "apply_subwords", "(", "filename", ",", "bpe_filename", ")", ":", "\n", "    ", "with", "open_temp_files", "(", "num", "=", "1", ")", "as", "output_", ":", "\n", "        ", "output_", ",", "=", "output_", "\n", "cmd", "=", "[", "'scripts/bpe/apply_bpe.py'", ",", "'--input'", ",", "filename", ",", "'--codes'", ",", "bpe_filename", "]", "\n", "subprocess", ".", "call", "(", "cmd", ",", "stdout", "=", "output_", ")", "\n", "\n", "return", "output_", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_corpora": [[234, 298], ["any", "zip", "logging.info", "prepare-data.split_corpus", "enumerate", "zip", "prepare-data.process_corpus", "prepare-data.filter_corpus", "zip", "prepare-data.filter_corpus", "shutil.move", "os.path.join", "prepare-data.create_subwords", "prepare-data.apply_subwords", "zip"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.split_corpus", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_corpus", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.filter_corpus", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.filter_corpus", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.create_subwords", "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.apply_subwords"], ["", "", "def", "process_corpora", "(", "args", ",", "corpora", ",", "output_corpora", ",", "sizes", ")", ":", "\n", "    ", "for", "corpus", "in", "corpora", ":", "\n", "        ", "if", "corpus", "is", "not", "None", ":", "\n", "            ", "corpus", "[", ":", "]", "=", "process_corpus", "(", "corpus", ",", "args", ")", "\n", "\n", "# split corpus into train/dev/test", "\n", "# size of 0: no corpus is created", "\n", "# size of None: copy everything (default for train)", "\n", "# if dev/test corpus is provided, we don't split", "\n", "", "", "if", "any", "(", "sizes", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'splitting files'", ")", "\n", "split_corpora", "=", "split_corpus", "(", "corpora", "[", "-", "1", "]", ",", "sizes", ")", "\n", "\n", "# union of `filenames` and `split_filenames`_", "\n", "for", "i", ",", "split_corpus_", "in", "enumerate", "(", "split_corpora", ")", ":", "\n", "            ", "if", "split_corpus_", "is", "not", "None", ":", "\n", "                ", "corpora", "[", "i", "]", "=", "split_corpus_", "\n", "\n", "# filter corpora by line length", "\n", "# TODO: character-level filtering", "\n", "", "", "", "for", "corpus", "in", "corpora", ":", "\n", "        ", "if", "corpus", "is", "not", "None", ":", "\n", "            ", "corpus", "[", ":", "]", "=", "filter_corpus", "(", "corpus", ",", "args", ")", "\n", "\n", "# create subwords and process files accordingly", "\n", "", "", "if", "args", ".", "subwords", ":", "\n", "        ", "if", "args", ".", "bpe_path", ":", "\n", "            ", "bpe_filenames", "=", "args", ".", "bpe_path", "\n", "", "else", ":", "\n", "            ", "bpe_filenames", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'bpe.{}'", ".", "format", "(", "ext", ")", ")", "\n", "for", "ext", "in", "args", ".", "extensions", "\n", "]", "\n", "\n", "# create subwords", "\n", "train_corpus", "=", "corpora", "[", "-", "1", "]", "\n", "for", "ext", ",", "filename", ",", "bpe_filename", ",", "size", "in", "zip", "(", "args", ".", "extensions", ",", "train_corpus", ",", "bpe_filenames", ",", "\n", "args", ".", "vocab_size", ")", ":", "\n", "                ", "if", "ext", "in", "args", ".", "subwords", ":", "\n", "# this does not ensure a vocabulary size of `size`", "\n", "                    ", "create_subwords", "(", "filename", ",", "bpe_filename", ",", "size", ")", "\n", "\n", "# apply subwords to train, dev and test", "\n", "", "", "", "for", "corpus", "in", "corpora", ":", "\n", "            ", "if", "corpus", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "filenames", "=", "[", "\n", "apply_subwords", "(", "filename", ",", "bpe_filename", ")", "if", "ext", "in", "args", ".", "subwords", "else", "filename", "\n", "for", "ext", ",", "filename", ",", "bpe_filename", "in", "zip", "(", "args", ".", "extensions", ",", "corpus", ",", "bpe_filenames", ")", "\n", "]", "\n", "\n", "# filter lines by length again...", "\n", "filenames", "=", "filter_corpus", "(", "filenames", ",", "args", ")", "\n", "corpus", "[", ":", "]", "=", "filenames", "\n", "\n", "# move temporary files to their destination", "\n", "", "", "for", "corpus", ",", "output_corpus", "in", "zip", "(", "corpora", ",", "output_corpora", ")", ":", "\n", "        ", "if", "corpus", "is", "None", ":", "\n", "            ", "continue", "\n", "", "for", "filename", ",", "output_filename", "in", "zip", "(", "corpus", ",", "output_corpus", ")", ":", "\n", "            ", "shutil", ".", "move", "(", "filename", ",", "output_filename", ")", "\n", "\n", "", "corpus", "[", ":", "]", "=", "output_corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.process_vocabularies": [[300, 329], ["logging.info", "zip", "os.path.join", "zip", "prepare-data.create_vocabulary", "shutil.copy"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.scripts.prepare-data.create_vocabulary"], ["", "", "def", "process_vocabularies", "(", "args", ",", "corpora", ")", ":", "\n", "## create vocabularies", "\n", "    ", "vocab_output_filenames", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}.{}'", ".", "format", "(", "args", ".", "vocab_prefix", ",", "ext", ")", ")", "\n", "for", "ext", "in", "args", ".", "extensions", "\n", "]", "\n", "\n", "if", "args", ".", "vocab_path", "is", "not", "None", ":", "\n", "# copy vocabularies if necessary", "\n", "        ", "for", "vocab_filename", ",", "output_filename", "in", "zip", "(", "args", ".", "vocab_path", ",", "\n", "vocab_output_filenames", ")", ":", "\n", "            ", "if", "vocab_filename", "!=", "output_filename", ":", "\n", "                ", "shutil", ".", "copy", "(", "vocab_filename", ",", "output_filename", ")", "\n", "", "", "return", "\n", "\n", "", "logging", ".", "info", "(", "'creating vocabulary files'", ")", "\n", "# training corpus is used to create vocabulary", "\n", "train_corpus", "=", "corpora", "[", "-", "1", "]", "\n", "\n", "for", "filename", ",", "output_filename", ",", "size", ",", "ext", ",", "min_count", "in", "zip", "(", "train_corpus", ",", "\n", "vocab_output_filenames", ",", "\n", "args", ".", "vocab_size", ",", "\n", "args", ".", "extensions", ",", "\n", "args", ".", "min_count", ")", ":", "\n", "        ", "if", "ext", "in", "args", ".", "subwords", ":", "\n", "            ", "size", "=", "0", "\n", "\n", "", "character_level", "=", "ext", "in", "args", ".", "character_level", "\n", "create_vocabulary", "(", "filename", ",", "output_filename", ",", "size", ",", "character_level", ",", "min_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.plot-loss.boldify": [[242, 247], ["None"], "function", ["None"], ["def", "boldify", "(", "text", ")", ":", "\n", "    ", "if", "args", ".", "no_bold", ":", "\n", "        ", "return", "text", "\n", "", "else", ":", "\n", "        ", "return", "'\\033[1m'", "+", "text", "+", "'\\033[0m'", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.stats.info_dict": [[54, 85], ["sum", "len", "min", "max", "collections.OrderedDict", "enumerate", "collections.OrderedDict.items", "counter.values", "counter.values", "counter.values", "counter.most_common", "collections.OrderedDict.items", "summary.append", "len"], "function", ["None"], ["", "", "", "def", "info_dict", "(", "title", ",", "counter", ")", ":", "\n", "    ", "total", "=", "sum", "(", "counter", ".", "values", "(", ")", ")", "\n", "unique", "=", "len", "(", "counter", ")", "\n", "avg", "=", "total", "/", "unique", "\n", "min_", "=", "min", "(", "counter", ".", "values", "(", ")", ")", "\n", "max_", "=", "max", "(", "counter", ".", "values", "(", ")", ")", "\n", "\n", "cumulative_count", "=", "0", "\n", "coverage", "=", "OrderedDict", "(", "[", "(", "90", ",", "0", ")", ",", "(", "95", ",", "0", ")", ",", "(", "99", ",", "0", ")", "]", ")", "\n", "\n", "for", "i", ",", "pair", "in", "enumerate", "(", "counter", ".", "most_common", "(", ")", ",", "1", ")", ":", "\n", "        ", "_", ",", "count", "=", "pair", "\n", "cumulative_count", "+=", "count", "\n", "\n", "for", "percent", ",", "count", "in", "coverage", ".", "items", "(", ")", ":", "\n", "            ", "if", "count", "==", "0", "and", "cumulative_count", "*", "100", ">=", "percent", "*", "total", ":", "\n", "                ", "coverage", "[", "percent", "]", "=", "i", "\n", "\n", "", "", "", "summary", "=", "[", "\n", "'{}\\n{}'", ".", "format", "(", "title", ",", "'-'", "*", "len", "(", "title", ")", ")", ",", "\n", "'Total:   {}'", ".", "format", "(", "total", ")", ",", "\n", "'Unique:  {}'", ".", "format", "(", "unique", ")", ",", "\n", "'Minimum: {}'", ".", "format", "(", "min_", ")", ",", "\n", "'Maximum: {}'", ".", "format", "(", "max_", ")", ",", "\n", "'Average: {:.1f}'", ".", "format", "(", "avg", ")", "\n", "]", "\n", "\n", "for", "percent", ",", "count", "in", "coverage", ".", "items", "(", ")", ":", "\n", "        ", "summary", ".", "append", "(", "'{}% cov: {}'", ".", "format", "(", "percent", ",", "count", ")", ")", "\n", "\n", "", "return", "'\\n  '", ".", "join", "(", "summary", ")", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.scripts.stats.info_lengths": [[87, 117], ["sum", "collections.OrderedDict", "sorted", "collections.OrderedDict.items", "counter.values", "sum", "counter.items", "collections.OrderedDict.items", "summary.append", "min", "max", "len", "counter.items"], "function", ["None"], ["", "def", "info_lengths", "(", "title", ",", "counter", ")", ":", "\n", "    ", "total", "=", "sum", "(", "counter", ".", "values", "(", ")", ")", "\n", "avg", "=", "sum", "(", "k", "*", "v", "for", "k", ",", "v", "in", "counter", ".", "items", "(", ")", ")", "/", "total", "\n", "\n", "coverage", "=", "OrderedDict", "(", "[", "(", "1", ",", "0", ")", ",", "(", "5", ",", "0", ")", ",", "(", "10", ",", "0", ")", ",", "\n", "(", "50", ",", "0", ")", ",", "(", "90", ",", "0", ")", ",", "(", "95", ",", "0", ")", ",", "(", "99", ",", "0", ")", "]", ")", "\n", "\n", "cumulative_count", "=", "0", "\n", "prev_k", "=", "0", "\n", "\n", "for", "k", ",", "v", "in", "sorted", "(", "counter", ".", "items", "(", ")", ")", ":", "\n", "        ", "cumulative_count", "+=", "v", "\n", "\n", "for", "percent", ",", "count", "in", "coverage", ".", "items", "(", ")", ":", "\n", "            ", "if", "count", "==", "0", "and", "cumulative_count", "*", "100", ">=", "percent", "*", "total", ":", "\n", "                ", "coverage", "[", "percent", "]", "=", "prev_k", "if", "percent", "<", "50", "else", "k", "\n", "\n", "", "", "prev_k", "=", "k", "\n", "\n", "", "summary", "=", "[", "\n", "'{}\\n{}'", ".", "format", "(", "title", ",", "'-'", "*", "len", "(", "title", ")", ")", ",", "\n", "'Minimum: {}'", ".", "format", "(", "min", "(", "counter", ")", ")", ",", "\n", "'Maximum: {}'", ".", "format", "(", "max", "(", "counter", ")", ")", ",", "\n", "'Average: {:.1f}'", ".", "format", "(", "avg", ")", ",", "\n", "]", "\n", "\n", "for", "percent", ",", "count", "in", "coverage", ".", "items", "(", ")", ":", "\n", "        ", "summary", ".", "append", "(", "'{}{:2d}%:   {}'", ".", "format", "(", "'<='", "if", "percent", "<", "50", "else", "'>='", ",", "percent", ",", "count", ")", ")", "\n", "\n", "", "return", "'\\n  '", ".", "join", "(", "summary", ")", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.mfcc": [[8, 34], ["base.fbank", "numpy.log", "base.lifter", "numpy.ones", "scipy.fftpack.dct", "numpy.log"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.fbank", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.lifter", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["def", "mfcc", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "numcep", "=", "13", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "ceplifter", "=", "22", ",", "appendEnergy", "=", "True", ",", "\n", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute MFCC features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param numcep: the number of cepstrum to return, default 13\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ",", "winfunc", ")", "\n", "feat", "=", "numpy", ".", "log", "(", "feat", ")", "\n", "feat", "=", "dct", "(", "feat", ",", "type", "=", "2", ",", "axis", "=", "1", ",", "norm", "=", "'ortho'", ")", "[", ":", ",", ":", "numcep", "]", "\n", "feat", "=", "lifter", "(", "feat", ",", "ceplifter", ")", "\n", "if", "appendEnergy", ":", "feat", "[", ":", ",", "0", "]", "=", "numpy", ".", "log", "(", "energy", ")", "# replace first cepstral coefficient with log of frame energy", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.fbank": [[35, 65], ["python_speech_features.sigproc.preemphasis", "python_speech_features.sigproc.framesig", "python_speech_features.sigproc.powspec", "numpy.sum", "numpy.where", "base.get_filterbanks", "numpy.dot", "numpy.where", "numpy.ones", "numpy.finfo", "numpy.finfo"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.preemphasis", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.framesig", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.powspec", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.get_filterbanks"], ["", "def", "fbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "\n", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute Mel-filterbank energy features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n        second return value is the energy in each frame (total energy, unwindowed)\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "signal", "=", "sigproc", ".", "preemphasis", "(", "signal", ",", "preemph", ")", "\n", "frames", "=", "sigproc", ".", "framesig", "(", "signal", ",", "winlen", "*", "samplerate", ",", "winstep", "*", "samplerate", ",", "winfunc", ")", "\n", "pspec", "=", "sigproc", ".", "powspec", "(", "frames", ",", "nfft", ")", "\n", "energy", "=", "numpy", ".", "sum", "(", "pspec", ",", "1", ")", "# this stores the total energy in each frame", "\n", "energy", "=", "numpy", ".", "where", "(", "energy", "==", "0", ",", "numpy", ".", "finfo", "(", "float", ")", ".", "eps", ",", "energy", ")", "# if energy is zero, we get problems with log", "\n", "\n", "fb", "=", "get_filterbanks", "(", "nfilt", ",", "nfft", ",", "samplerate", ",", "lowfreq", ",", "highfreq", ")", "\n", "feat", "=", "numpy", ".", "dot", "(", "pspec", ",", "fb", ".", "T", ")", "# compute the filterbank energies", "\n", "feat", "=", "numpy", ".", "where", "(", "feat", "==", "0", ",", "numpy", ".", "finfo", "(", "float", ")", ".", "eps", ",", "feat", ")", "# if feat is zero, we get problems with log", "\n", "\n", "return", "feat", ",", "energy", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.logfbank": [[66, 83], ["base.fbank", "numpy.log"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.fbank", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "logfbank", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ")", ":", "\n", "    ", "\"\"\"Compute log Mel-filterbank energy features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "feat", ",", "energy", "=", "fbank", "(", "signal", ",", "samplerate", ",", "winlen", ",", "winstep", ",", "nfilt", ",", "nfft", ",", "lowfreq", ",", "highfreq", ",", "preemph", ")", "\n", "return", "numpy", ".", "log", "(", "feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.ssc": [[84, 112], ["python_speech_features.sigproc.preemphasis", "python_speech_features.sigproc.framesig", "python_speech_features.sigproc.powspec", "numpy.where", "base.get_filterbanks", "numpy.dot", "numpy.tile", "numpy.ones", "numpy.linspace", "numpy.dot", "numpy.finfo", "numpy.size", "numpy.size"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.preemphasis", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.framesig", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.powspec", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.get_filterbanks"], ["", "def", "ssc", "(", "signal", ",", "samplerate", "=", "16000", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.01", ",", "\n", "nfilt", "=", "26", ",", "nfft", "=", "512", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ",", "preemph", "=", "0.97", ",", "\n", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Compute Spectral Subband Centroid features from an audio signal.\n\n    :param signal: the audio signal from which to compute features. Should be an N*1 array\n    :param samplerate: the samplerate of the signal we are working with.\n    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n    :param nfilt: the number of filters in the filterbank, default 26.\n    :param nfft: the FFT size. Default is 512.\n    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "signal", "=", "sigproc", ".", "preemphasis", "(", "signal", ",", "preemph", ")", "\n", "frames", "=", "sigproc", ".", "framesig", "(", "signal", ",", "winlen", "*", "samplerate", ",", "winstep", "*", "samplerate", ",", "winfunc", ")", "\n", "pspec", "=", "sigproc", ".", "powspec", "(", "frames", ",", "nfft", ")", "\n", "pspec", "=", "numpy", ".", "where", "(", "pspec", "==", "0", ",", "numpy", ".", "finfo", "(", "float", ")", ".", "eps", ",", "pspec", ")", "# if things are all zeros we get problems", "\n", "\n", "fb", "=", "get_filterbanks", "(", "nfilt", ",", "nfft", ",", "samplerate", ",", "lowfreq", ",", "highfreq", ")", "\n", "feat", "=", "numpy", ".", "dot", "(", "pspec", ",", "fb", ".", "T", ")", "# compute the filterbank energies", "\n", "R", "=", "numpy", ".", "tile", "(", "numpy", ".", "linspace", "(", "1", ",", "samplerate", "/", "2", ",", "numpy", ".", "size", "(", "pspec", ",", "1", ")", ")", ",", "(", "numpy", ".", "size", "(", "pspec", ",", "0", ")", ",", "1", ")", ")", "\n", "\n", "return", "numpy", ".", "dot", "(", "pspec", "*", "R", ",", "fb", ".", "T", ")", "/", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.hz2mel": [[113, 120], ["numpy.log10"], "function", ["None"], ["", "def", "hz2mel", "(", "hz", ")", ":", "\n", "    ", "\"\"\"Convert a value in Hertz to Mels\n\n    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "2595", "*", "numpy", ".", "log10", "(", "1", "+", "hz", "/", "700.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.mel2hz": [[121, 128], ["None"], "function", ["None"], ["", "def", "mel2hz", "(", "mel", ")", ":", "\n", "    ", "\"\"\"Convert a value in Mels to Hertz\n\n    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n    \"\"\"", "\n", "return", "700", "*", "(", "10", "**", "(", "mel", "/", "2595.0", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.get_filterbanks": [[129, 158], ["base.hz2mel", "base.hz2mel", "numpy.linspace", "numpy.floor", "numpy.zeros", "range", "range", "range", "int", "int", "int", "int", "base.mel2hz"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.hz2mel", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.hz2mel", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.mel2hz"], ["", "def", "get_filterbanks", "(", "nfilt", "=", "20", ",", "nfft", "=", "512", ",", "samplerate", "=", "16000", ",", "lowfreq", "=", "0", ",", "highfreq", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n\n    :param nfilt: the number of filters in the filterbank, default 20.\n    :param nfft: the FFT size. Default is 512.\n    :param samplerate: the samplerate of the signal we are working with. Affects mel spacing.\n    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n    :param highfreq: highest band edge of mel filters, default samplerate/2\n    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n    \"\"\"", "\n", "highfreq", "=", "highfreq", "or", "samplerate", "/", "2", "\n", "assert", "highfreq", "<=", "samplerate", "/", "2", ",", "\"highfreq is greater than samplerate/2\"", "\n", "\n", "# compute points evenly spaced in mels", "\n", "lowmel", "=", "hz2mel", "(", "lowfreq", ")", "\n", "highmel", "=", "hz2mel", "(", "highfreq", ")", "\n", "melpoints", "=", "numpy", ".", "linspace", "(", "lowmel", ",", "highmel", ",", "nfilt", "+", "2", ")", "\n", "# our points are in Hz, but we use fft bins, so we have to convert", "\n", "#  from Hz to fft bin number", "\n", "bin", "=", "numpy", ".", "floor", "(", "(", "nfft", "+", "1", ")", "*", "mel2hz", "(", "melpoints", ")", "/", "samplerate", ")", "\n", "\n", "fbank", "=", "numpy", ".", "zeros", "(", "[", "nfilt", ",", "nfft", "//", "2", "+", "1", "]", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nfilt", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ")", ":", "\n", "            ", "fbank", "[", "j", ",", "i", "]", "=", "(", "i", "-", "bin", "[", "j", "]", ")", "/", "(", "bin", "[", "j", "+", "1", "]", "-", "bin", "[", "j", "]", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "bin", "[", "j", "+", "1", "]", ")", ",", "int", "(", "bin", "[", "j", "+", "2", "]", ")", ")", ":", "\n", "            ", "fbank", "[", "j", ",", "i", "]", "=", "(", "bin", "[", "j", "+", "2", "]", "-", "i", ")", "/", "(", "bin", "[", "j", "+", "2", "]", "-", "bin", "[", "j", "+", "1", "]", ")", "\n", "", "", "return", "fbank", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.lifter": [[159, 174], ["numpy.shape", "numpy.arange", "numpy.sin"], "function", ["None"], ["", "def", "lifter", "(", "cepstra", ",", "L", "=", "22", ")", ":", "\n", "    ", "\"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n    magnitude of the high frequency DCT coeffs.\n\n    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n    \"\"\"", "\n", "if", "L", ">", "0", ":", "\n", "        ", "nframes", ",", "ncoeff", "=", "numpy", ".", "shape", "(", "cepstra", ")", "\n", "n", "=", "numpy", ".", "arange", "(", "ncoeff", ")", "\n", "lift", "=", "1", "+", "(", "L", "/", "2.", ")", "*", "numpy", ".", "sin", "(", "numpy", ".", "pi", "*", "n", "/", "L", ")", "\n", "return", "lift", "*", "cepstra", "\n", "", "else", ":", "\n", "# values of L <= 0, do nothing", "\n", "        ", "return", "cepstra", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.base.delta": [[175, 191], ["len", "numpy.empty_like", "numpy.pad", "range", "ValueError", "sum", "numpy.dot", "numpy.arange", "range"], "function", ["None"], ["", "", "def", "delta", "(", "feat", ",", "N", ")", ":", "\n", "    ", "\"\"\"Compute delta features from a feature vector sequence.\n\n    :param feat: A numpy array of size (NUMFRAMES by number of features) containing features. Each row holds 1 feature vector.\n    :param N: For each frame, calculate delta features based on preceding and following N frames\n    :returns: A numpy array of size (NUMFRAMES by number of features) containing delta features. Each row holds 1 delta feature vector.\n    \"\"\"", "\n", "if", "N", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'N must be an integer >= 1'", ")", "\n", "", "NUMFRAMES", "=", "len", "(", "feat", ")", "\n", "denominator", "=", "2", "*", "sum", "(", "[", "i", "**", "2", "for", "i", "in", "range", "(", "1", ",", "N", "+", "1", ")", "]", ")", "\n", "delta_feat", "=", "numpy", ".", "empty_like", "(", "feat", ")", "\n", "padded", "=", "numpy", ".", "pad", "(", "feat", ",", "(", "(", "N", ",", "N", ")", ",", "(", "0", ",", "0", ")", ")", ",", "mode", "=", "'edge'", ")", "# padded version of feat", "\n", "for", "t", "in", "range", "(", "NUMFRAMES", ")", ":", "\n", "        ", "delta_feat", "[", "t", "]", "=", "numpy", ".", "dot", "(", "numpy", ".", "arange", "(", "-", "N", ",", "N", "+", "1", ")", ",", "padded", "[", "t", ":", "t", "+", "2", "*", "N", "+", "1", "]", ")", "/", "denominator", "# [t : t+2*N+1] == [(N+t)-N : (N+t)+N+1]", "\n", "", "return", "delta_feat", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.round_half_up": [[10, 12], ["int", "decimal.Decimal().quantize", "decimal.Decimal", "decimal.Decimal"], "function", ["None"], ["def", "round_half_up", "(", "number", ")", ":", "\n", "    ", "return", "int", "(", "decimal", ".", "Decimal", "(", "number", ")", ".", "quantize", "(", "decimal", ".", "Decimal", "(", "'1'", ")", ",", "rounding", "=", "decimal", ".", "ROUND_HALF_UP", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.rolling_window": [[14, 19], ["numpy.lib.stride_tricks.as_strided"], "function", ["None"], ["", "def", "rolling_window", "(", "a", ",", "window", ",", "step", "=", "1", ")", ":", "\n", "# http://ellisvalentiner.com/post/2017-03-21-np-strides-trick", "\n", "    ", "shape", "=", "a", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "a", ".", "shape", "[", "-", "1", "]", "-", "window", "+", "1", ",", "window", ")", "\n", "strides", "=", "a", ".", "strides", "+", "(", "a", ".", "strides", "[", "-", "1", "]", ",", ")", "\n", "return", "numpy", ".", "lib", ".", "stride_tricks", ".", "as_strided", "(", "a", ",", "shape", "=", "shape", ",", "strides", "=", "strides", ")", "[", ":", ":", "step", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.framesig": [[21, 54], ["len", "int", "int", "int", "numpy.zeros", "numpy.concatenate", "numpy.ones", "sigproc.round_half_up", "sigproc.round_half_up", "winfunc", "sigproc.rolling_window", "numpy.array", "numpy.tile", "int", "numpy.tile", "winfunc", "math.ceil", "numpy.arange", "numpy.tile", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.round_half_up", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.round_half_up", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.rolling_window"], ["", "def", "framesig", "(", "sig", ",", "frame_len", ",", "frame_step", ",", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ",", "stride_trick", "=", "True", ")", ":", "\n", "    ", "\"\"\"Frame a signal into overlapping frames.\n\n    :param sig: the audio signal to frame.\n    :param frame_len: length of each frame measured in samples.\n    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n    \"\"\"", "\n", "slen", "=", "len", "(", "sig", ")", "\n", "frame_len", "=", "int", "(", "round_half_up", "(", "frame_len", ")", ")", "\n", "frame_step", "=", "int", "(", "round_half_up", "(", "frame_step", ")", ")", "\n", "if", "slen", "<=", "frame_len", ":", "\n", "        ", "numframes", "=", "1", "\n", "", "else", ":", "\n", "        ", "numframes", "=", "1", "+", "int", "(", "math", ".", "ceil", "(", "(", "1.0", "*", "slen", "-", "frame_len", ")", "/", "frame_step", ")", ")", "\n", "\n", "", "padlen", "=", "int", "(", "(", "numframes", "-", "1", ")", "*", "frame_step", "+", "frame_len", ")", "\n", "\n", "zeros", "=", "numpy", ".", "zeros", "(", "(", "padlen", "-", "slen", ",", ")", ")", "\n", "padsignal", "=", "numpy", ".", "concatenate", "(", "(", "sig", ",", "zeros", ")", ")", "\n", "if", "stride_trick", ":", "\n", "        ", "win", "=", "winfunc", "(", "frame_len", ")", "\n", "frames", "=", "rolling_window", "(", "padsignal", ",", "window", "=", "frame_len", ",", "step", "=", "frame_step", ")", "\n", "", "else", ":", "\n", "        ", "indices", "=", "numpy", ".", "tile", "(", "numpy", ".", "arange", "(", "0", ",", "frame_len", ")", ",", "(", "numframes", ",", "1", ")", ")", "+", "numpy", ".", "tile", "(", "\n", "numpy", ".", "arange", "(", "0", ",", "numframes", "*", "frame_step", ",", "frame_step", ")", ",", "(", "frame_len", ",", "1", ")", ")", ".", "T", "\n", "indices", "=", "numpy", ".", "array", "(", "indices", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "frames", "=", "padsignal", "[", "indices", "]", "\n", "win", "=", "numpy", ".", "tile", "(", "winfunc", "(", "frame_len", ")", ",", "(", "numframes", ",", "1", ")", ")", "\n", "\n", "", "return", "frames", "*", "win", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.deframesig": [[56, 89], ["sigproc.round_half_up", "sigproc.round_half_up", "numpy.array", "numpy.zeros", "numpy.zeros", "winfunc", "range", "numpy.ones", "numpy.shape", "numpy.tile", "numpy.shape", "numpy.arange", "numpy.tile", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.round_half_up", "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.round_half_up"], ["", "def", "deframesig", "(", "frames", ",", "siglen", ",", "frame_len", ",", "frame_step", ",", "winfunc", "=", "lambda", "x", ":", "numpy", ".", "ones", "(", "(", "x", ",", ")", ")", ")", ":", "\n", "    ", "\"\"\"Does overlap-add procedure to undo the action of framesig.\n\n    :param frames: the array of frames.\n    :param siglen: the length of the desired signal, use 0 if unknown. Output will be truncated to siglen samples.\n    :param frame_len: length of each frame measured in samples.\n    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n    :returns: a 1-D signal.\n    \"\"\"", "\n", "frame_len", "=", "round_half_up", "(", "frame_len", ")", "\n", "frame_step", "=", "round_half_up", "(", "frame_step", ")", "\n", "numframes", "=", "numpy", ".", "shape", "(", "frames", ")", "[", "0", "]", "\n", "assert", "numpy", ".", "shape", "(", "frames", ")", "[", "1", "]", "==", "frame_len", ",", "'\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'", "\n", "\n", "indices", "=", "numpy", ".", "tile", "(", "numpy", ".", "arange", "(", "0", ",", "frame_len", ")", ",", "(", "numframes", ",", "1", ")", ")", "+", "numpy", ".", "tile", "(", "\n", "numpy", ".", "arange", "(", "0", ",", "numframes", "*", "frame_step", ",", "frame_step", ")", ",", "(", "frame_len", ",", "1", ")", ")", ".", "T", "\n", "indices", "=", "numpy", ".", "array", "(", "indices", ",", "dtype", "=", "numpy", ".", "int32", ")", "\n", "padlen", "=", "(", "numframes", "-", "1", ")", "*", "frame_step", "+", "frame_len", "\n", "\n", "if", "siglen", "<=", "0", ":", "siglen", "=", "padlen", "\n", "\n", "rec_signal", "=", "numpy", ".", "zeros", "(", "(", "padlen", ",", ")", ")", "\n", "window_correction", "=", "numpy", ".", "zeros", "(", "(", "padlen", ",", ")", ")", "\n", "win", "=", "winfunc", "(", "frame_len", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "numframes", ")", ":", "\n", "        ", "window_correction", "[", "indices", "[", "i", ",", ":", "]", "]", "=", "window_correction", "[", "\n", "indices", "[", "i", ",", ":", "]", "]", "+", "win", "+", "1e-15", "# add a little bit so it is never zero", "\n", "rec_signal", "[", "indices", "[", "i", ",", ":", "]", "]", "=", "rec_signal", "[", "indices", "[", "i", ",", ":", "]", "]", "+", "frames", "[", "i", ",", ":", "]", "\n", "\n", "", "rec_signal", "=", "rec_signal", "/", "window_correction", "\n", "return", "rec_signal", "[", "0", ":", "siglen", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.magspec": [[91, 104], ["numpy.fft.rfft", "numpy.absolute", "logging.warn", "numpy.shape", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.warn"], ["", "def", "magspec", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n    \"\"\"", "\n", "if", "numpy", ".", "shape", "(", "frames", ")", "[", "1", "]", ">", "NFFT", ":", "\n", "        ", "logging", ".", "warn", "(", "\n", "'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.'", ",", "\n", "numpy", ".", "shape", "(", "frames", ")", "[", "1", "]", ",", "NFFT", ")", "\n", "", "complex_spec", "=", "numpy", ".", "fft", ".", "rfft", "(", "frames", ",", "NFFT", ")", "\n", "return", "numpy", ".", "absolute", "(", "complex_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.powspec": [[106, 114], ["numpy.square", "sigproc.magspec"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.magspec"], ["", "def", "powspec", "(", "frames", ",", "NFFT", ")", ":", "\n", "    ", "\"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n    \"\"\"", "\n", "return", "1.0", "/", "NFFT", "*", "numpy", ".", "square", "(", "magspec", "(", "frames", ",", "NFFT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.logpowspec": [[116, 131], ["sigproc.powspec", "numpy.log10", "numpy.max"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.powspec"], ["", "def", "logpowspec", "(", "frames", ",", "NFFT", ",", "norm", "=", "1", ")", ":", "\n", "    ", "\"\"\"Compute the log power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n\n    :param frames: the array of frames. Each row is a frame.\n    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n    :param norm: If norm=1, the log power spectrum is normalised so that the max value (across all frames) is 0.\n    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the log power spectrum of the corresponding frame.\n    \"\"\"", "\n", "ps", "=", "powspec", "(", "frames", ",", "NFFT", ")", ";", "\n", "ps", "[", "ps", "<=", "1e-30", "]", "=", "1e-30", "\n", "lps", "=", "10", "*", "numpy", ".", "log10", "(", "ps", ")", "\n", "if", "norm", ":", "\n", "        ", "return", "lps", "-", "numpy", ".", "max", "(", "lps", ")", "\n", "", "else", ":", "\n", "        ", "return", "lps", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.python_speech_features.sigproc.preemphasis": [[133, 141], ["numpy.append"], "function", ["None"], ["", "", "def", "preemphasis", "(", "signal", ",", "coeff", "=", "0.95", ")", ":", "\n", "    ", "\"\"\"perform preemphasis on the input signal.\n\n    :param signal: The signal to filter.\n    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n    :returns: the filtered signal.\n    \"\"\"", "\n", "return", "numpy", ".", "append", "(", "signal", "[", "0", "]", ",", "signal", "[", "1", ":", "]", "-", "coeff", "*", "signal", "[", ":", "-", "1", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.segment-char-ngrams.create_parser": [[15, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"segment rare words into character n-grams\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input file (default: standard input).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocab'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "metavar", "=", "'PATH'", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Vocabulary file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shortlist'", ",", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "default", "=", "0", ",", "\n", "help", "=", "\"do not segment INT most frequent words in vocabulary (default: '%(default)s')).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-n'", ",", "type", "=", "int", ",", "metavar", "=", "'INT'", ",", "default", "=", "2", ",", "\n", "help", "=", "\"segment rare words into character n-grams of size INT (default: '%(default)s')).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--separator'", ",", "'-s'", ",", "type", "=", "str", ",", "default", "=", "'@@'", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "\"Separator between non-final subword units (default: '%(default)s'))\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_joint_bpe_and_vocab.create_parser": [[31, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "required", "=", "True", ",", "nargs", "=", "'+'", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input texts (multiple allowed).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "required", "=", "True", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file for BPE codes.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--symbols'", ",", "'-s'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Create this many new symbols (each representing a character n-gram) (default: %(default)s))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--separator'", ",", "type", "=", "str", ",", "default", "=", "'@@'", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "\"Separator between non-final subword units (default: '%(default)s'))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--write-vocabulary'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "metavar", "=", "'PATH'", ",", "dest", "=", "'vocab'", ",", "\n", "help", "=", "'Write to these vocabulary files after applying BPE. One per input text. Used for filtering in apply_bpe.py'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--min-frequency'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "metavar", "=", "'FREQ'", ",", "\n", "help", "=", "'Stop if no symbol pair has frequency >= FREQ (default: %(default)s))'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "'-v'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.create_parser": [[27, 54], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input text (default: standard input).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file for BPE codes (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--symbols'", ",", "'-s'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"Create this many new symbols (each representing a character n-gram) (default: %(default)s))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--min-frequency'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "metavar", "=", "'FREQ'", ",", "\n", "help", "=", "'Stop if no symbol pair has frequency >= FREQ (default: %(default)s))'", ")", "\n", "parser", ".", "add_argument", "(", "'--dict-input'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If set, input file is interpreted as a dictionary where each line contains a word-count pair\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "'-v'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"verbose mode.\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.get_vocabulary": [[55, 67], ["collections.Counter", "line.strip().split", "int", "line.split", "line.strip"], "function", ["None"], ["", "def", "get_vocabulary", "(", "fobj", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Read text and return dictionary that encodes vocabulary\n    \"\"\"", "\n", "vocab", "=", "Counter", "(", ")", "\n", "for", "line", "in", "fobj", ":", "\n", "        ", "if", "is_dict", ":", "\n", "            ", "word", ",", "count", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "vocab", "[", "word", "]", "+=", "int", "(", "count", ")", "\n", "", "else", ":", "\n", "            ", "for", "word", "in", "line", ".", "split", "(", ")", ":", "\n", "                ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.update_pair_statistics": [[68, 125], ["collections.defaultdict", "old_word.index", "word.index", "len", "len", "len", "len"], "function", ["None"], ["", "def", "update_pair_statistics", "(", "pair", ",", "changed", ",", "stats", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Minimally update the indices and frequency of symbol pairs\n\n    if we merge a pair of symbols, only pairs that overlap with occurrences\n    of this pair are affected, and need to be updated.\n    \"\"\"", "\n", "stats", "[", "pair", "]", "=", "0", "\n", "indices", "[", "pair", "]", "=", "defaultdict", "(", "int", ")", "\n", "first", ",", "second", "=", "pair", "\n", "new_pair", "=", "first", "+", "second", "\n", "for", "j", ",", "word", ",", "old_word", ",", "freq", "in", "changed", ":", "\n", "\n", "# find all instances of pair, and update frequency/indices around it", "\n", "        ", "i", "=", "0", "\n", "while", "True", ":", "\n", "# find first symbol", "\n", "            ", "try", ":", "\n", "                ", "i", "=", "old_word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# if first symbol is followed by second symbol, we've found an occurrence of pair (old_word[i:i+2])", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "1", "and", "old_word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "# assuming a symbol sequence \"A B C\", if \"B C\" is merged, reduce the frequency of \"A B\"", "\n", "                ", "if", "i", ":", "\n", "                    ", "prev", "=", "old_word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "-=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "-=", "1", "\n", "", "if", "i", "<", "len", "(", "old_word", ")", "-", "2", ":", "\n", "# assuming a symbol sequence \"A B C B\", if \"B C\" is merged, reduce the frequency of \"C B\".", "\n", "# however, skip this if the sequence is A B C B C, because the frequency of \"C B\" will be reduced by the previous code block", "\n", "                    ", "if", "old_word", "[", "i", "+", "2", "]", "!=", "first", "or", "i", ">=", "len", "(", "old_word", ")", "-", "3", "or", "old_word", "[", "i", "+", "3", "]", "!=", "second", ":", "\n", "                        ", "nex", "=", "old_word", "[", "i", "+", "1", ":", "i", "+", "3", "]", "\n", "stats", "[", "nex", "]", "-=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "-=", "1", "\n", "", "", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "i", "+=", "1", "\n", "\n", "", "", "i", "=", "0", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "# find new pair", "\n", "                ", "i", "=", "word", ".", "index", "(", "new_pair", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "break", "\n", "# assuming a symbol sequence \"A BC D\", if \"B C\" is merged, increase the frequency of \"A BC\"", "\n", "", "if", "i", ":", "\n", "                ", "prev", "=", "word", "[", "i", "-", "1", ":", "i", "+", "1", "]", "\n", "stats", "[", "prev", "]", "+=", "freq", "\n", "indices", "[", "prev", "]", "[", "j", "]", "+=", "1", "\n", "# assuming a symbol sequence \"A BC B\", if \"B C\" is merged, increase the frequency of \"BC B\"", "\n", "# however, if the sequence is A BC BC, skip this step because the count of \"BC BC\" will be incremented by the previous code block", "\n", "", "if", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "!=", "new_pair", ":", "\n", "                ", "nex", "=", "word", "[", "i", ":", "i", "+", "2", "]", "\n", "stats", "[", "nex", "]", "+=", "freq", "\n", "indices", "[", "nex", "]", "[", "j", "]", "+=", "1", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.get_pair_statistics": [[127, 144], ["collections.defaultdict", "collections.defaultdict", "enumerate", "collections.defaultdict"], "function", ["None"], ["", "", "", "def", "get_pair_statistics", "(", "vocab", ")", ":", "\n", "    ", "\"\"\"Count frequency of all symbol pairs, and create index\"\"\"", "\n", "\n", "# data structure of pair frequencies", "\n", "stats", "=", "defaultdict", "(", "int", ")", "\n", "\n", "#index from pairs to words", "\n", "indices", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "\n", "for", "i", ",", "(", "word", ",", "freq", ")", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "            ", "stats", "[", "prev_char", ",", "char", "]", "+=", "freq", "\n", "indices", "[", "prev_char", ",", "char", "]", "[", "i", "]", "+=", "1", "\n", "prev_char", "=", "char", "\n", "\n", "", "", "return", "stats", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.replace_pair": [[146, 169], ["pair_str.replace.replace", "re.compile", "indices[].iteritems", "indices[].items", "re.compile.sub", "tuple", "changes.append", "tuple.split", "re.escape"], "function", ["None"], ["", "def", "replace_pair", "(", "pair", ",", "vocab", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\"\"\"", "\n", "first", ",", "second", "=", "pair", "\n", "pair_str", "=", "''", ".", "join", "(", "pair", ")", "\n", "pair_str", "=", "pair_str", ".", "replace", "(", "'\\\\'", ",", "'\\\\\\\\'", ")", "\n", "changes", "=", "[", "]", "\n", "pattern", "=", "re", ".", "compile", "(", "r'(?<!\\S)'", "+", "re", ".", "escape", "(", "first", "+", "' '", "+", "second", ")", "+", "r'(?!\\S)'", ")", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", "0", ")", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "iteritems", "(", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "indices", "[", "pair", "]", ".", "items", "(", ")", "\n", "", "for", "j", ",", "freq", "in", "iterator", ":", "\n", "        ", "if", "freq", "<", "1", ":", "\n", "            ", "continue", "\n", "", "word", ",", "freq", "=", "vocab", "[", "j", "]", "\n", "new_word", "=", "' '", ".", "join", "(", "word", ")", "\n", "new_word", "=", "pattern", ".", "sub", "(", "pair_str", ",", "new_word", ")", "\n", "new_word", "=", "tuple", "(", "new_word", ".", "split", "(", ")", ")", "\n", "\n", "vocab", "[", "j", "]", "=", "(", "new_word", ",", "freq", ")", "\n", "changes", ".", "append", "(", "(", "j", ",", "new_word", ",", "word", ",", "freq", ")", ")", "\n", "\n", "", "return", "changes", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.prune_stats": [[170, 184], ["list", "stats.items"], "function", ["None"], ["", "def", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Prune statistics dict for efficiency of max()\n\n    The frequency of a symbol pair never increases, so pruning is generally safe\n    (until we the most frequent pair is less frequent than a pair we previously pruned)\n    big_stats keeps full statistics for when we need to access pruned items\n    \"\"\"", "\n", "for", "item", ",", "freq", "in", "list", "(", "stats", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "freq", "<", "threshold", ":", "\n", "            ", "del", "stats", "[", "item", "]", "\n", "if", "freq", "<", "0", ":", "\n", "                ", "big_stats", "[", "item", "]", "+=", "freq", "\n", "", "else", ":", "\n", "                ", "big_stats", "[", "item", "]", "=", "freq", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.main": [[186, 227], ["outfile.write", "learn_bpe.get_vocabulary", "dict", "sorted", "learn_bpe.get_pair_statistics", "copy.deepcopy", "range", "dict.items", "max", "outfile.write", "learn_bpe.replace_pair", "learn_bpe.update_pair_statistics", "copy.deepcopy.values", "max", "learn_bpe.prune_stats", "copy.deepcopy", "max", "learn_bpe.prune_stats", "sys.stderr.write", "sys.stderr.write", "learn_bpe.prune_stats", "dict.items", "tuple"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.get_vocabulary", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.get_pair_statistics", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.replace_pair", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.update_pair_statistics", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.prune_stats", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.learn_bpe.prune_stats"], ["", "", "", "", "def", "main", "(", "infile", ",", "outfile", ",", "num_symbols", ",", "min_frequency", "=", "2", ",", "verbose", "=", "False", ",", "is_dict", "=", "False", ")", ":", "\n", "    ", "\"\"\"Learn num_symbols BPE operations from vocabulary, and write to outfile.\n    \"\"\"", "\n", "\n", "# version 0.2 changes the handling of the end-of-word token ('</w>');", "\n", "# version numbering allows bckward compatibility", "\n", "outfile", ".", "write", "(", "'#version: 0.2\\n'", ")", "\n", "\n", "vocab", "=", "get_vocabulary", "(", "infile", ",", "is_dict", ")", "\n", "vocab", "=", "dict", "(", "[", "(", "tuple", "(", "x", "[", ":", "-", "1", "]", ")", "+", "(", "x", "[", "-", "1", "]", "+", "'</w>'", ",", ")", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "vocab", ".", "items", "(", ")", "]", ")", "\n", "sorted_vocab", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "stats", ",", "indices", "=", "get_pair_statistics", "(", "sorted_vocab", ")", "\n", "big_stats", "=", "copy", ".", "deepcopy", "(", "stats", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "max", "(", "stats", ".", "values", "(", ")", ")", "/", "10", "\n", "for", "i", "in", "range", "(", "num_symbols", ")", ":", "\n", "        ", "if", "stats", ":", "\n", "            ", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "\n", "# we probably missed the best pair because of pruning; go back to full statistics", "\n", "", "if", "not", "stats", "or", "(", "i", "and", "stats", "[", "most_frequent", "]", "<", "threshold", ")", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "stats", "=", "copy", ".", "deepcopy", "(", "big_stats", ")", "\n", "most_frequent", "=", "max", "(", "stats", ",", "key", "=", "lambda", "x", ":", "(", "stats", "[", "x", "]", ",", "x", ")", ")", "\n", "# threshold is inspired by Zipfian assumption, but should only affect speed", "\n", "threshold", "=", "stats", "[", "most_frequent", "]", "*", "i", "/", "(", "i", "+", "10000.0", ")", "\n", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n", "", "if", "stats", "[", "most_frequent", "]", "<", "min_frequency", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "'no pair has frequency >= {0}. Stopping\\n'", ".", "format", "(", "min_frequency", ")", ")", "\n", "break", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "'pair {0}: {1} {2} -> {1}{2} (frequency {3})\\n'", ".", "format", "(", "i", ",", "most_frequent", "[", "0", "]", ",", "most_frequent", "[", "1", "]", ",", "stats", "[", "most_frequent", "]", ")", ")", "\n", "", "outfile", ".", "write", "(", "'{0} {1}\\n'", ".", "format", "(", "*", "most_frequent", ")", ")", "\n", "changes", "=", "replace_pair", "(", "most_frequent", ",", "sorted_vocab", ",", "indices", ")", "\n", "update_pair_statistics", "(", "most_frequent", ",", "changes", ",", "stats", ",", "indices", ")", "\n", "stats", "[", "most_frequent", "]", "=", "0", "\n", "if", "not", "i", "%", "100", ":", "\n", "            ", "prune_stats", "(", "stats", ",", "big_stats", ",", "threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.bpe_toy.get_stats": [[21, 28], ["collections.defaultdict", "vocab.items", "word.split", "range", "len"], "function", ["None"], ["def", "get_stats", "(", "vocab", ")", ":", "\n", "  ", "pairs", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "for", "word", ",", "freq", "in", "vocab", ".", "items", "(", ")", ":", "\n", "    ", "symbols", "=", "word", ".", "split", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "symbols", ")", "-", "1", ")", ":", "\n", "      ", "pairs", "[", "symbols", "[", "i", "]", ",", "symbols", "[", "i", "+", "1", "]", "]", "+=", "freq", "\n", "", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.bpe_toy.merge_vocab": [[29, 37], ["re.escape", "re.compile", "re.compile.sub"], "function", ["None"], ["", "def", "merge_vocab", "(", "pair", ",", "v_in", ")", ":", "\n", "  ", "v_out", "=", "{", "}", "\n", "bigram_pattern", "=", "re", ".", "escape", "(", "' '", ".", "join", "(", "pair", ")", ")", "\n", "p", "=", "re", ".", "compile", "(", "r'(?<!\\S)'", "+", "bigram_pattern", "+", "r'(?!\\S)'", ")", "\n", "for", "word", "in", "v_in", ":", "\n", "    ", "w_out", "=", "p", ".", "sub", "(", "''", ".", "join", "(", "pair", ")", ",", "word", ")", "\n", "v_out", "[", "w_out", "]", "=", "v_in", "[", "word", "]", "\n", "", "return", "v_out", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.create_parser": [[29, 61], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["", "def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--ref'", ",", "'-r'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "required", "=", "True", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Reference file\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--hyp'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "metavar", "=", "'PATH'", ",", "\n", "default", "=", "sys", ".", "stdin", ",", "\n", "help", "=", "\"Hypothesis file (default: stdin).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--beta'", ",", "'-b'", ",", "type", "=", "float", ",", "default", "=", "3", ",", "\n", "metavar", "=", "'FLOAT'", ",", "\n", "help", "=", "\"beta parameter (default: '%(default)s')\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ngram'", ",", "'-n'", ",", "type", "=", "int", ",", "default", "=", "6", ",", "\n", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"ngram order (default: '%(default)s')\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--space'", ",", "'-s'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"take spaces into account (default: '%(default)s')\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--precision'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"report precision (default: '%(default)s')\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--recall'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"report recall (default: '%(default)s')\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.extract_ngrams": [[62, 76], ["collections.defaultdict", "range", "words.strip.strip", "range", "words.strip.split", "collections.defaultdict", "len", "len", "tuple"], "function", ["None"], ["", "def", "extract_ngrams", "(", "words", ",", "max_length", "=", "4", ",", "spaces", "=", "False", ")", ":", "\n", "\n", "    ", "if", "not", "spaces", ":", "\n", "        ", "words", "=", "''", ".", "join", "(", "words", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "words", "=", "words", ".", "strip", "(", ")", "\n", "\n", "", "results", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", "int", ")", ")", "\n", "for", "length", "in", "range", "(", "max_length", ")", ":", "\n", "        ", "for", "start_pos", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "            ", "end_pos", "=", "start_pos", "+", "length", "+", "1", "\n", "if", "end_pos", "<=", "len", "(", "words", ")", ":", "\n", "                ", "results", "[", "length", "]", "[", "tuple", "(", "words", "[", "start_pos", ":", "end_pos", "]", ")", "]", "+=", "1", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.get_correct": [[78, 87], ["min"], "function", ["None"], ["", "def", "get_correct", "(", "ngrams_ref", ",", "ngrams_test", ",", "correct", ",", "total", ")", ":", "\n", "\n", "    ", "for", "rank", "in", "ngrams_test", ":", "\n", "        ", "for", "chain", "in", "ngrams_test", "[", "rank", "]", ":", "\n", "            ", "total", "[", "rank", "]", "+=", "ngrams_test", "[", "rank", "]", "[", "chain", "]", "\n", "if", "chain", "in", "ngrams_ref", "[", "rank", "]", ":", "\n", "                ", "correct", "[", "rank", "]", "+=", "min", "(", "ngrams_test", "[", "rank", "]", "[", "chain", "]", ",", "ngrams_ref", "[", "rank", "]", "[", "chain", "]", ")", "\n", "\n", "", "", "", "return", "correct", ",", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.f1": [[89, 103], ["range"], "function", ["None"], ["", "def", "f1", "(", "correct", ",", "total_hyp", ",", "total_ref", ",", "max_length", ",", "beta", "=", "3", ",", "smooth", "=", "0", ")", ":", "\n", "\n", "    ", "precision", "=", "0", "\n", "recall", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "max_length", ")", ":", "\n", "      ", "if", "total_hyp", "[", "i", "]", "+", "smooth", "and", "total_ref", "[", "i", "]", "+", "smooth", ":", "\n", "        ", "precision", "+=", "(", "correct", "[", "i", "]", "+", "smooth", ")", "/", "(", "total_hyp", "[", "i", "]", "+", "smooth", ")", "\n", "recall", "+=", "(", "correct", "[", "i", "]", "+", "smooth", ")", "/", "(", "total_ref", "[", "i", "]", "+", "smooth", ")", "\n", "\n", "", "", "precision", "/=", "max_length", "\n", "recall", "/=", "max_length", "\n", "\n", "return", "(", "1", "+", "beta", "**", "2", ")", "*", "(", "precision", "*", "recall", ")", "/", "(", "(", "beta", "**", "2", "*", "precision", ")", "+", "recall", ")", ",", "precision", ",", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.main": [[104, 128], ["chrF.f1", "print", "args.hyp.readline", "chrF.extract_ngrams", "chrF.extract_ngrams", "chrF.get_correct", "print", "print"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.f1", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.extract_ngrams", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.extract_ngrams", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.chrF.get_correct"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "correct", "=", "[", "0", "]", "*", "args", ".", "ngram", "\n", "total", "=", "[", "0", "]", "*", "args", ".", "ngram", "\n", "total_ref", "=", "[", "0", "]", "*", "args", ".", "ngram", "\n", "for", "line", "in", "args", ".", "ref", ":", "\n", "      ", "line2", "=", "args", ".", "hyp", ".", "readline", "(", ")", "\n", "\n", "ngrams_ref", "=", "extract_ngrams", "(", "line", ",", "max_length", "=", "args", ".", "ngram", ",", "spaces", "=", "args", ".", "space", ")", "\n", "ngrams_test", "=", "extract_ngrams", "(", "line2", ",", "max_length", "=", "args", ".", "ngram", ",", "spaces", "=", "args", ".", "space", ")", "\n", "\n", "get_correct", "(", "ngrams_ref", ",", "ngrams_test", ",", "correct", ",", "total", ")", "\n", "\n", "for", "rank", "in", "ngrams_ref", ":", "\n", "          ", "for", "chain", "in", "ngrams_ref", "[", "rank", "]", ":", "\n", "              ", "total_ref", "[", "rank", "]", "+=", "ngrams_ref", "[", "rank", "]", "[", "chain", "]", "\n", "\n", "", "", "", "chrf", ",", "precision", ",", "recall", "=", "f1", "(", "correct", ",", "total", ",", "total_ref", ",", "args", ".", "ngram", ",", "args", ".", "beta", ")", "\n", "\n", "print", "(", "'chrF3: {0:.4f}'", ".", "format", "(", "chrf", ")", ")", "\n", "if", "args", ".", "precision", ":", "\n", "        ", "print", "(", "'chrPrec: {0:.4f}'", ".", "format", "(", "precision", ")", ")", "\n", "", "if", "args", ".", "recall", ":", "\n", "        ", "print", "(", "'chrRec: {0:.4f}'", ".", "format", "(", "recall", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.BPE.__init__": [[28, 52], ["codes.readline", "codes.readline.startswith", "dict", "dict", "tuple", "codes.seek", "tuple", "item.split", "enumerate", "int", "reversed", "apply_bpe.BPE.bpe_codes.items", "re.sub().split", "list", "enumerate", "re.sub", "codes.readline.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "codes", ",", "merges", "=", "-", "1", ",", "separator", "=", "'@@'", ",", "vocab", "=", "None", ",", "glossaries", "=", "None", ")", ":", "\n", "\n", "# check version information", "\n", "        ", "firstline", "=", "codes", ".", "readline", "(", ")", "\n", "if", "firstline", ".", "startswith", "(", "'#version:'", ")", ":", "\n", "            ", "self", ".", "version", "=", "tuple", "(", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "sub", "(", "r'(\\.0+)*$'", ",", "''", ",", "firstline", ".", "split", "(", ")", "[", "-", "1", "]", ")", ".", "split", "(", "\".\"", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "version", "=", "(", "0", ",", "1", ")", "\n", "codes", ".", "seek", "(", "0", ")", "\n", "\n", "", "self", ".", "bpe_codes", "=", "[", "tuple", "(", "item", ".", "split", "(", ")", ")", "for", "(", "n", ",", "item", ")", "in", "enumerate", "(", "codes", ")", "if", "(", "n", "<", "merges", "or", "merges", "==", "-", "1", ")", "]", "\n", "\n", "# some hacking to deal with duplicates (only consider first instance)", "\n", "self", ".", "bpe_codes", "=", "dict", "(", "[", "(", "code", ",", "i", ")", "for", "(", "i", ",", "code", ")", "in", "reversed", "(", "list", "(", "enumerate", "(", "self", ".", "bpe_codes", ")", ")", ")", "]", ")", "\n", "\n", "self", ".", "bpe_codes_reverse", "=", "dict", "(", "[", "(", "pair", "[", "0", "]", "+", "pair", "[", "1", "]", ",", "pair", ")", "for", "pair", ",", "i", "in", "self", ".", "bpe_codes", ".", "items", "(", ")", "]", ")", "\n", "\n", "self", ".", "separator", "=", "separator", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "glossaries", "=", "glossaries", "if", "glossaries", "else", "[", "]", "\n", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.BPE.segment": [[53, 72], ["sentence.split", "output.append", "output.append", "apply_bpe.BPE._isolate_glossaries", "apply_bpe.encode"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.BPE._isolate_glossaries", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.encode"], ["", "def", "segment", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "\"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "word", "in", "sentence", ".", "split", "(", ")", ":", "\n", "            ", "new_word", "=", "[", "out", "for", "segment", "in", "self", ".", "_isolate_glossaries", "(", "word", ")", "\n", "for", "out", "in", "encode", "(", "segment", ",", "\n", "self", ".", "bpe_codes", ",", "\n", "self", ".", "bpe_codes_reverse", ",", "\n", "self", ".", "vocab", ",", "\n", "self", ".", "separator", ",", "\n", "self", ".", "version", ",", "\n", "self", ".", "cache", ",", "\n", "self", ".", "glossaries", ")", "]", "\n", "\n", "for", "item", "in", "new_word", "[", ":", "-", "1", "]", ":", "\n", "                ", "output", ".", "append", "(", "item", "+", "self", ".", "separator", ")", "\n", "", "output", ".", "append", "(", "new_word", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "' '", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.BPE._isolate_glossaries": [[73, 79], ["apply_bpe.isolate_glossary"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.isolate_glossary"], ["", "def", "_isolate_glossaries", "(", "self", ",", "word", ")", ":", "\n", "        ", "word_segments", "=", "[", "word", "]", "\n", "for", "gloss", "in", "self", ".", "glossaries", ":", "\n", "            ", "word_segments", "=", "[", "out_segments", "for", "segment", "in", "word_segments", "\n", "for", "out_segments", "in", "isolate_glossary", "(", "segment", ",", "gloss", ")", "]", "\n", "", "return", "word_segments", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.create_parser": [[80, 120], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType", "argparse.FileType", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["", "", "def", "create_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "RawDescriptionHelpFormatter", ",", "\n", "description", "=", "\"learn BPE-based word segmentation\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'--input'", ",", "'-i'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "sys", ".", "stdin", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Input file (default: standard input).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--codes'", ",", "'-c'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "metavar", "=", "'PATH'", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"File with BPE codes (created by learn_bpe.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--merges'", ",", "'-m'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "metavar", "=", "'INT'", ",", "\n", "help", "=", "\"Use this many BPE operations (<= number of learned symbols)\"", "+", "\n", "\"default: Apply all the learned merge operations\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "'-o'", ",", "type", "=", "argparse", ".", "FileType", "(", "'w'", ")", ",", "default", "=", "sys", ".", "stdout", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "\"Output file (default: standard output)\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--separator'", ",", "'-s'", ",", "type", "=", "str", ",", "default", "=", "'@@'", ",", "metavar", "=", "'STR'", ",", "\n", "help", "=", "\"Separator between non-final subword units (default: '%(default)s'))\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary'", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"PATH\"", ",", "\n", "help", "=", "\"Vocabulary file (built with get_vocab.py). If provided, this script reverts any merge operations that produce an OOV.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--vocabulary-threshold'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"INT\"", ",", "\n", "help", "=", "\"Vocabulary threshold. If vocabulary is provided, any word with frequency < threshold will be treated as OOV\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--glossaries'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "default", "=", "None", ",", "\n", "metavar", "=", "\"STR\"", ",", "\n", "help", "=", "\"Glossaries. The strings provided in glossaries will not be affected\"", "+", "\n", "\"by the BPE (i.e. they will neither be broken into subwords, nor concatenated with other subwords\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.get_pairs": [[121, 132], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.encode": [[133, 196], ["apply_bpe.get_pairs", "min", "tuple", "word[].endswith", "apply_bpe.check_vocab_and_split", "tuple", "len", "len", "apply_bpe.get_pairs", "tuple", "check_vocab_and_split.index", "tuple.extend", "tuple.append", "tuple.append", "bpe_codes.get", "tuple.extend", "word[].replace", "float", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.get_pairs", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.check_vocab_and_split", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.get_pairs"], ["", "def", "encode", "(", "orig", ",", "bpe_codes", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ",", "version", ",", "cache", ",", "glossaries", "=", "None", ")", ":", "\n", "    ", "\"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n    \"\"\"", "\n", "\n", "if", "orig", "in", "cache", ":", "\n", "        ", "return", "cache", "[", "orig", "]", "\n", "\n", "", "if", "orig", "in", "glossaries", ":", "\n", "        ", "cache", "[", "orig", "]", "=", "(", "orig", ",", ")", "\n", "return", "(", "orig", ",", ")", "\n", "\n", "", "if", "version", "==", "(", "0", ",", "1", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "orig", ")", "+", "(", "'</w>'", ",", ")", "\n", "", "elif", "version", "==", "(", "0", ",", "2", ")", ":", "# more consistent handling of word-final segments", "\n", "        ", "word", "=", "tuple", "(", "orig", "[", ":", "-", "1", "]", ")", "+", "(", "orig", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "        ", "return", "orig", "\n", "\n", "", "while", "True", ":", "\n", "        ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "bpe_codes", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "bpe_codes", ":", "\n", "            ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "# don't print end-of-word symbols", "\n", "", "", "if", "word", "[", "-", "1", "]", "==", "'</w>'", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "\n", "", "elif", "word", "[", "-", "1", "]", ".", "endswith", "(", "'</w>'", ")", ":", "\n", "        ", "word", "=", "word", "[", ":", "-", "1", "]", "+", "(", "word", "[", "-", "1", "]", ".", "replace", "(", "'</w>'", ",", "''", ")", ",", ")", "\n", "\n", "", "if", "vocab", ":", "\n", "        ", "word", "=", "check_vocab_and_split", "(", "word", ",", "bpe_codes_reverse", ",", "vocab", ",", "separator", ")", "\n", "\n", "", "cache", "[", "orig", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.recursive_split": [[197, 223], ["apply_bpe.recursive_split", "apply_bpe.recursive_split"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.recursive_split"], ["", "def", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", "=", "False", ")", ":", "\n", "    ", "\"\"\"Recursively split segment into smaller units (by reversing BPE merges)\n    until all units are either in-vocabulary, or cannot be split futher.\"\"\"", "\n", "\n", "try", ":", "\n", "        ", "if", "final", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "+", "'</w>'", "]", "\n", "right", "=", "right", "[", ":", "-", "4", "]", "\n", "", "else", ":", "\n", "            ", "left", ",", "right", "=", "bpe_codes", "[", "segment", "]", "\n", "", "", "except", ":", "\n", "#sys.stderr.write('cannot split {0} further.\\n'.format(segment))", "\n", "        ", "yield", "segment", "\n", "return", "\n", "\n", "", "if", "left", "+", "separator", "in", "vocab", ":", "\n", "        ", "yield", "left", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "left", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "            ", "yield", "item", "\n", "\n", "", "", "if", "(", "final", "and", "right", "in", "vocab", ")", "or", "(", "not", "final", "and", "right", "+", "separator", "in", "vocab", ")", ":", "\n", "        ", "yield", "right", "\n", "", "else", ":", "\n", "        ", "for", "item", "in", "recursive_split", "(", "right", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "final", ")", ":", "\n", "            ", "yield", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.check_vocab_and_split": [[224, 247], ["out.append", "apply_bpe.recursive_split", "out.append", "apply_bpe.recursive_split", "out.append", "out.append"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.recursive_split", "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.recursive_split"], ["", "", "", "def", "check_vocab_and_split", "(", "orig", ",", "bpe_codes", ",", "vocab", ",", "separator", ")", ":", "\n", "    ", "\"\"\"Check for each segment in word if it is in-vocabulary,\n    and segment OOV segments into smaller units by reversing the BPE merge operations\"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "\n", "for", "segment", "in", "orig", "[", ":", "-", "1", "]", ":", "\n", "        ", "if", "segment", "+", "separator", "in", "vocab", ":", "\n", "            ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "            ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "False", ")", ":", "\n", "                ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "segment", "=", "orig", "[", "-", "1", "]", "\n", "if", "segment", "in", "vocab", ":", "\n", "        ", "out", ".", "append", "(", "segment", ")", "\n", "", "else", ":", "\n", "#sys.stderr.write('OOV: {0}\\n'.format(segment))", "\n", "        ", "for", "item", "in", "recursive_split", "(", "segment", ",", "bpe_codes", ",", "vocab", ",", "separator", ",", "True", ")", ":", "\n", "            ", "out", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.read_vocabulary": [[249, 262], ["set", "line.split", "int", "set.add"], "function", ["None"], ["", "def", "read_vocabulary", "(", "vocab_file", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"read vocabulary file produced by get_vocab.py, and filter according to frequency threshold.\n    \"\"\"", "\n", "\n", "vocabulary", "=", "set", "(", ")", "\n", "\n", "for", "line", "in", "vocab_file", ":", "\n", "        ", "word", ",", "freq", "=", "line", ".", "split", "(", ")", "\n", "freq", "=", "int", "(", "freq", ")", "\n", "if", "threshold", "==", "None", "or", "freq", ">=", "threshold", ":", "\n", "            ", "vocabulary", ".", "add", "(", "word", ")", "\n", "\n", "", "", "return", "vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.apply_bpe.isolate_glossary": [[263, 278], ["word.split", "segment.strip", "splits[].strip"], "function", ["None"], ["", "def", "isolate_glossary", "(", "word", ",", "glossary", ")", ":", "\n", "    ", "\"\"\"\n    Isolate a glossary present inside a word.\n\n    Returns a list of subwords. In which all 'glossary' glossaries are isolated \n\n    For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:\n        ['1934', 'USA', 'B', 'USA']\n    \"\"\"", "\n", "if", "word", "==", "glossary", "or", "glossary", "not", "in", "word", ":", "\n", "        ", "return", "[", "word", "]", "\n", "", "else", ":", "\n", "        ", "splits", "=", "word", ".", "split", "(", "glossary", ")", "\n", "segments", "=", "[", "segment", ".", "strip", "(", ")", "for", "split", "in", "splits", "[", ":", "-", "1", "]", "for", "segment", "in", "[", "split", ",", "glossary", "]", "if", "segment", "!=", "''", "]", "\n", "return", "segments", "+", "[", "splits", "[", "-", "1", "]", ".", "strip", "(", ")", "]", "if", "splits", "[", "-", "1", "]", "!=", "''", "else", "segments", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.bpe.concat-bpe.build_vocab": [[9, 20], ["set", "word.endswith", "set.add", "set.add", "set.add"], "function", ["None"], ["def", "build_vocab", "(", "bpe_pairs", ")", ":", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "for", "a", ",", "b", "in", "bpe_pairs", ":", "\n", "        ", "words", "=", "[", "a", ",", "b", ",", "a", "+", "b", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", ".", "endswith", "(", "'</w>'", ")", ":", "\n", "                ", "vocab", ".", "add", "(", "word", "[", ":", "-", "4", "]", ")", "\n", "", "else", ":", "\n", "                ", "vocab", ".", "add", "(", "word", "+", "'@@'", ")", "\n", "vocab", ".", "add", "(", "word", ")", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.post_editing.well-formed.is_well_formed": [[10, 43], ["line.split", "len", "c.isalpha", "x.isdigit", "x.isalpha", "x.isupper"], "function", ["None"], ["def", "is_well_formed", "(", "line", ")", ":", "\n", "    ", "if", "len", "(", "line", ")", "<", "21", ":", "\n", "        ", "return", "False", "\n", "\n", "", "x", "=", "line", "[", "0", "]", "\n", "if", "not", "x", ".", "isdigit", "(", ")", "and", "not", "(", "x", ".", "isalpha", "(", ")", "and", "x", ".", "isupper", "(", ")", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "not", "line", "[", "-", "2", "]", "in", "punk", ":", "# last character is '\\n'", "\n", "        ", "return", "False", "\n", "\n", "", "i", "=", "0", "\n", "k", "=", "0", "\n", "\n", "for", "c", "in", "line", ":", "\n", "        ", "if", "c", "==", "' '", ":", "\n", "            ", "continue", "\n", "\n", "", "k", "+=", "1", "\n", "if", "c", ".", "isalpha", "(", ")", ":", "\n", "            ", "i", "+=", "1", "\n", "\n", "", "", "j", "=", "0", "\n", "prev", "=", "None", "\n", "for", "word", "in", "line", ".", "split", "(", ")", ":", "\n", "        ", "if", "prev", "is", "not", "None", "and", "word", "==", "prev", ":", "\n", "            ", "j", "+=", "1", "\n", "if", "j", ">", "3", ":", "\n", "                ", "return", "False", "\n", "", "", "else", ":", "\n", "            ", "prev", "=", "word", "\n", "j", "=", "1", "\n", "\n", "", "", "return", "i", ">=", "20", "and", "i", ">=", "k", "*", "0.75", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.post_editing.extract-edits.levenshtein_legacy": [[22, 46], ["functools.lru_cache", "extract-edits.levenshtein_legacy", "extract-edits.levenshtein_legacy", "min", "len", "extract-edits.levenshtein_legacy", "res.append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.post_editing.extract-edits.levenshtein_legacy", "home.repos.pwc.inspect_result.eske_seq2seq.post_editing.extract-edits.levenshtein_legacy", "home.repos.pwc.inspect_result.eske_seq2seq.post_editing.extract-edits.levenshtein_legacy"], ["@", "functools", ".", "lru_cache", "(", "maxsize", "=", "1024", ")", "\n", "def", "levenshtein_legacy", "(", "src", ",", "trg", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Dynamic programming by memoization", "\n", "# This recursive solution is easier, but much slower than the `true` dynamic programming solution", "\n", "# (due to important dictionary lookup overhead, and probably not exactly constant lookup time)", "\n", "\n", "    ", "if", "len", "(", "src", ")", "==", "0", ":", "\n", "        ", "return", "len", "(", "trg", ")", ",", "[", "(", "'insert'", ",", "w", ")", "for", "w", "in", "trg", "]", "\n", "", "elif", "len", "(", "trg", ")", "==", "0", ":", "\n", "        ", "return", "len", "(", "src", ")", ",", "[", "'delete'", "for", "_", "in", "src", "]", "\n", "\n", "", "insert", "=", "levenshtein_legacy", "(", "src", ",", "trg", "[", "1", ":", "]", ")", "\n", "delete", "=", "levenshtein_legacy", "(", "src", "[", "1", ":", "]", ",", "trg", ")", "\n", "\n", "res", "=", "[", "\n", "(", "1", "+", "delete", "[", "0", "]", ",", "[", "'delete'", "]", "+", "delete", "[", "1", "]", ")", ",", "\n", "(", "1", "+", "insert", "[", "0", "]", ",", "[", "(", "'insert'", ",", "trg", "[", "0", "]", ")", "]", "+", "insert", "[", "1", "]", ")", ",", "\n", "]", "\n", "\n", "if", "src", "[", "0", "]", "==", "trg", "[", "0", "]", ":", "\n", "        ", "keep", "=", "levenshtein_legacy", "(", "src", "[", "1", ":", "]", ",", "trg", "[", "1", ":", "]", ")", "\n", "res", ".", "append", "(", "(", "keep", "[", "0", "]", ",", "[", "(", "'keep'", ",", "src", "[", "0", "]", ")", "]", "+", "keep", "[", "1", "]", ")", ")", "\n", "\n", "", "return", "min", "(", "res", ",", "key", "=", "lambda", "p", ":", "p", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.post_editing.extract-edits.levenshtein": [[48, 99], ["range", "numpy.zeros", "numpy.zeros", "range", "range", "range", "range", "len", "len", "len", "len", "len", "min", "res.append", "res.append", "len", "len", "len", "len", "random.random", "len"], "function", ["None"], ["", "def", "levenshtein", "(", "src", ",", "trg", ",", "sub_cost", "=", "1.0", ",", "del_cost", "=", "1.0", ",", "ins_cost", "=", "1.0", ",", "randomize", "=", "False", ")", ":", "\n", "    ", "INS", ",", "DEL", ",", "KEEP", ",", "SUB", "=", "range", "(", "4", ")", "\n", "op_names", "=", "'insert'", ",", "'delete'", ",", "'keep'", ",", "'sub'", "\n", "\n", "# reverse sequences to do `forward` backtracking", "\n", "# this is useful to give priority to certain operations (we want insertions to occur before deletions)", "\n", "src", "=", "src", "[", ":", ":", "-", "1", "]", "\n", "trg", "=", "trg", "[", ":", ":", "-", "1", "]", "\n", "\n", "costs", "=", "np", ".", "zeros", "(", "(", "len", "(", "trg", ")", "+", "1", ",", "len", "(", "src", ")", "+", "1", ")", ")", "\n", "ops", "=", "np", ".", "zeros", "(", "(", "len", "(", "trg", ")", "+", "1", ",", "len", "(", "src", ")", "+", "1", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "costs", "[", "0", "]", "=", "range", "(", "len", "(", "src", ")", "+", "1", ")", "\n", "costs", "[", ":", ",", "0", "]", "=", "range", "(", "len", "(", "trg", ")", "+", "1", ")", "\n", "ops", "[", "0", "]", "=", "DEL", "\n", "ops", "[", ":", ",", "0", "]", "=", "INS", "\n", "\n", "if", "randomize", ":", "\n", "        ", "key", "=", "lambda", "p", ":", "(", "p", "[", "0", "]", ",", "random", ".", "random", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "key", "=", "lambda", "p", ":", "p", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "trg", ")", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "len", "(", "src", ")", "+", "1", ")", ":", "\n", "            ", "c", ",", "op", "=", "(", "sub_cost", ",", "SUB", ")", "if", "trg", "[", "i", "-", "1", "]", "!=", "src", "[", "j", "-", "1", "]", "else", "(", "0", ",", "KEEP", ")", "\n", "costs", "[", "i", ",", "j", "]", ",", "ops", "[", "i", ",", "j", "]", "=", "min", "(", "[", "\n", "(", "costs", "[", "i", "-", "1", ",", "j", "]", "+", "ins_cost", ",", "INS", ")", ",", "\n", "(", "costs", "[", "i", ",", "j", "-", "1", "]", "+", "del_cost", ",", "DEL", ")", ",", "\n", "(", "costs", "[", "i", "-", "1", ",", "j", "-", "1", "]", "+", "c", ",", "op", ")", ",", "\n", "]", ",", "key", "=", "key", ")", "\n", "\n", "# backtracking", "\n", "", "", "i", ",", "j", "=", "len", "(", "trg", ")", ",", "len", "(", "src", ")", "\n", "cost", "=", "costs", "[", "i", ",", "j", "]", "\n", "\n", "res", "=", "[", "]", "\n", "\n", "while", "i", ">", "0", "or", "j", ">", "0", ":", "\n", "        ", "op", "=", "ops", "[", "i", ",", "j", "]", "\n", "op_name", "=", "op_names", "[", "op", "]", "\n", "\n", "if", "op", "==", "DEL", ":", "\n", "            ", "res", ".", "append", "(", "op_name", ")", "\n", "j", "-=", "1", "\n", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "(", "op_name", ",", "trg", "[", "i", "-", "1", "]", ")", ")", "\n", "i", "-=", "1", "\n", "if", "op", "!=", "INS", ":", "\n", "                ", "j", "-=", "1", "\n", "\n", "", "", "", "return", "cost", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.CellInitializer.__init__": [[88, 92], ["tensorflow.orthogonal_initializer", "tensorflow.python.ops.init_ops.glorot_uniform_initializer", "tensorflow.get_variable_scope"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell_size", ")", ":", "\n", "        ", "self", ".", "cell_size", "=", "cell_size", "\n", "self", ".", "default_initializer", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "initializer", "or", "init_ops", ".", "glorot_uniform_initializer", "(", ")", "\n", "self", ".", "initializer", "=", "tf", ".", "orthogonal_initializer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.CellInitializer.__call__": [[93, 105], ["range", "tensorflow.concat", "rnn.CellInitializer.default_initializer", "W.append", "U.append", "len", "rnn.CellInitializer.default_initializer", "rnn.CellInitializer.initializer", "tensorflow.concat", "tensorflow.concat"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ",", "verify_shape", "=", "None", ")", ":", "\n", "        ", "if", "len", "(", "shape", ")", "==", "1", "or", "shape", "[", "1", "]", "%", "self", ".", "cell_size", "!=", "0", ":", "\n", "            ", "return", "self", ".", "default_initializer", "(", "shape", ",", "dtype", "=", "dtype", ",", "partition_info", "=", "partition_info", ")", "\n", "\n", "", "input_size", "=", "shape", "[", "0", "]", "-", "self", ".", "cell_size", "\n", "\n", "W", ",", "U", "=", "[", "]", ",", "[", "]", "\n", "for", "_", "in", "range", "(", "shape", "[", "1", "]", "//", "self", ".", "cell_size", ")", ":", "\n", "            ", "W", ".", "append", "(", "self", ".", "default_initializer", "(", "shape", "=", "[", "input_size", ",", "self", ".", "cell_size", "]", ")", ")", "\n", "U", ".", "append", "(", "self", ".", "initializer", "(", "shape", "=", "[", "self", ".", "cell_size", ",", "self", ".", "cell_size", "]", ")", ")", "\n", "\n", "", "return", "tf", ".", "concat", "(", "[", "tf", ".", "concat", "(", "W", ",", "axis", "=", "1", ")", ",", "tf", ".", "concat", "(", "U", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell.__init__": [[108, 128], ["super().__init__", "tensorflow.concat", "tensorflow.random_uniform", "rnn.DropoutGRUCell._enumerated_map_structure", "rnn.DropoutGRUCell._enumerated_map_structure", "tensorflow.TensorShape().as_list", "rnn.DropoutGRUCell.__init__.batch_noise"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__", "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._enumerated_map_structure", "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._enumerated_map_structure"], ["    ", "def", "__init__", "(", "self", ",", "num_units", ",", "activation", "=", "None", ",", "reuse", "=", "None", ",", "kernel_initializer", "=", "None", ",", "bias_initializer", "=", "None", ",", "\n", "layer_norm", "=", "False", ",", "state_keep_prob", "=", "None", ",", "input_keep_prob", "=", "None", ",", "input_size", "=", "None", ",", "final", "=", "False", ")", ":", "\n", "        ", "super", "(", "DropoutGRUCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_activation", "=", "activation", "or", "tf", ".", "nn", ".", "tanh", "\n", "self", ".", "_kernel_initializer", "=", "kernel_initializer", "\n", "self", ".", "_bias_initializer", "=", "bias_initializer", "\n", "self", ".", "_layer_norm", "=", "layer_norm", "\n", "self", ".", "_state_keep_prob", "=", "state_keep_prob", "\n", "self", ".", "_input_keep_prob", "=", "input_keep_prob", "\n", "self", ".", "_final", "=", "final", "\n", "\n", "def", "batch_noise", "(", "s", ")", ":", "\n", "            ", "s", "=", "tf", ".", "concat", "(", "(", "[", "1", "]", ",", "tf", ".", "TensorShape", "(", "s", ")", ".", "as_list", "(", ")", ")", ",", "0", ")", "\n", "return", "tf", ".", "random_uniform", "(", "s", ")", "\n", "\n", "", "if", "input_keep_prob", "is", "not", "None", ":", "\n", "            ", "self", ".", "_input_noise", "=", "DropoutGRUCell", ".", "_enumerated_map_structure", "(", "lambda", "i", ",", "s", ":", "batch_noise", "(", "s", ")", ",", "input_size", ")", "\n", "", "if", "state_keep_prob", "is", "not", "None", ":", "\n", "            ", "self", ".", "_state_noise", "=", "DropoutGRUCell", ".", "_enumerated_map_structure", "(", "lambda", "i", ",", "s", ":", "batch_noise", "(", "s", ")", ",", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell.state_size": [[129, 132], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell.output_size": [[133, 136], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._enumerated_map_structure": [[137, 147], ["tensorflow.python.util.nest.map_structure", "map_fn"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_enumerated_map_structure", "(", "map_fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "ix", "=", "[", "0", "]", "\n", "\n", "def", "enumerated_fn", "(", "*", "inner_args", ",", "**", "inner_kwargs", ")", ":", "\n", "            ", "r", "=", "map_fn", "(", "ix", "[", "0", "]", ",", "*", "inner_args", ",", "**", "inner_kwargs", ")", "\n", "ix", "[", "0", "]", "+=", "1", "\n", "return", "r", "\n", "\n", "", "return", "nest", ".", "map_structure", "(", "enumerated_fn", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._dropout": [[148, 158], ["rnn.DropoutGRUCell._enumerated_map_structure", "tensorflow.floor", "ret.set_shape", "tensorflow.div", "value.get_shape"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._enumerated_map_structure", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "@", "staticmethod", "\n", "def", "_dropout", "(", "values", ",", "recurrent_noise", ",", "keep_prob", ")", ":", "\n", "        ", "def", "dropout", "(", "index", ",", "value", ",", "noise", ")", ":", "\n", "            ", "random_tensor", "=", "keep_prob", "+", "noise", "\n", "binary_tensor", "=", "tf", ".", "floor", "(", "random_tensor", ")", "\n", "ret", "=", "tf", ".", "div", "(", "value", ",", "keep_prob", ")", "*", "binary_tensor", "\n", "ret", ".", "set_shape", "(", "value", ".", "get_shape", "(", ")", ")", "\n", "return", "ret", "\n", "\n", "", "return", "DropoutGRUCell", ".", "_enumerated_map_structure", "(", "dropout", ",", "values", ",", "recurrent_noise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell.call": [[159, 197], ["tensorflow.concat", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.sigmoid", "tensorflow.split", "rnn.DropoutGRUCell._activation", "rnn.DropoutGRUCell._dropout", "rnn.DropoutGRUCell._dropout", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.contrib.layers.layer_norm", "tensorflow.contrib.layers.layer_norm"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._dropout", "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.DropoutGRUCell._dropout"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "concat", "(", "inputs", ",", "axis", "=", "1", ")", "\n", "input_size", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "state_size", "=", "state", ".", "shape", "[", "1", "]", "\n", "dtype", "=", "inputs", ".", "dtype", "\n", "\n", "if", "self", ".", "_state_keep_prob", ":", "\n", "            ", "dropped_state", "=", "DropoutGRUCell", ".", "_dropout", "(", "state", ",", "self", ".", "_state_noise", ",", "self", ".", "_state_keep_prob", ")", "\n", "", "else", ":", "\n", "            ", "dropped_state", "=", "state", "\n", "\n", "", "if", "self", ".", "_input_keep_prob", ":", "\n", "            ", "dropped_inputs", "=", "DropoutGRUCell", ".", "_dropout", "(", "inputs", ",", "self", ".", "_input_noise", ",", "self", ".", "_input_keep_prob", ")", "\n", "", "else", ":", "\n", "            ", "dropped_inputs", "=", "inputs", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'state'", ")", ":", "\n", "            ", "state_weights", "=", "tf", ".", "get_variable", "(", "'kernel'", ",", "[", "state_size", ",", "3", "*", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "initializer", "=", "self", ".", "_kernel_initializer", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'input'", ")", ":", "\n", "            ", "input_weights", "=", "tf", ".", "get_variable", "(", "'kernel'", ",", "[", "input_size", ",", "3", "*", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "initializer", "=", "self", ".", "_kernel_initializer", ")", "\n", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "3", "*", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "initializer", "=", "self", ".", "_bias_initializer", ")", "\n", "\n", "inputs_", "=", "tf", ".", "matmul", "(", "dropped_inputs", ",", "input_weights", ")", "\n", "state_", "=", "tf", ".", "matmul", "(", "dropped_state", ",", "state_weights", ")", "\n", "\n", "if", "self", ".", "_layer_norm", ":", "\n", "            ", "state_", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "state_", ")", "\n", "inputs_", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "inputs_", ")", "\n", "\n", "", "size", "=", "2", "*", "self", ".", "_num_units", "\n", "value", "=", "tf", ".", "nn", ".", "sigmoid", "(", "state_", "[", ":", ",", ":", "size", "]", "+", "inputs_", "[", ":", ",", ":", "size", "]", "+", "bias", "[", ":", "size", "]", ")", "\n", "r", ",", "u", "=", "tf", ".", "split", "(", "value", "=", "value", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "c", "=", "self", ".", "_activation", "(", "inputs_", "[", ":", ",", "size", ":", "]", "+", "state_", "[", ":", ",", "size", ":", "]", "*", "r", "+", "bias", "[", "size", ":", "]", ")", "\n", "\n", "new_h", "=", "u", "*", "state", "+", "(", "1", "-", "u", ")", "*", "c", "\n", "return", "new_h", ",", "new_h", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.GRUCell.__init__": [[200, 208], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", ",", "activation", "=", "None", ",", "reuse", "=", "None", ",", "kernel_initializer", "=", "None", ",", "bias_initializer", "=", "None", ",", "\n", "layer_norm", "=", "False", ")", ":", "\n", "        ", "super", "(", "GRUCell", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_activation", "=", "activation", "or", "tf", ".", "nn", ".", "tanh", "\n", "self", ".", "_kernel_initializer", "=", "kernel_initializer", "\n", "self", ".", "_bias_initializer", "=", "bias_initializer", "\n", "self", ".", "_layer_norm", "=", "layer_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.GRUCell.state_size": [[209, 212], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.GRUCell.output_size": [[213, 216], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.GRUCell.call": [[217, 256], ["tensorflow.concat", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.sigmoid", "tensorflow.split", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "rnn.GRUCell._activation", "tensorflow.python.ops.init_ops.constant_initializer", "tensorflow.contrib.layers.layer_norm", "tensorflow.contrib.layers.layer_norm", "tensorflow.concat", "tensorflow.contrib.layers.layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "concat", "(", "inputs", ",", "axis", "=", "1", ")", "\n", "input_size", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "state_size", "=", "state", ".", "shape", "[", "1", "]", "\n", "dtype", "=", "inputs", ".", "dtype", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"gates\"", ")", ":", "\n", "            ", "bias_initializer", "=", "self", ".", "_bias_initializer", "\n", "if", "self", ".", "_bias_initializer", "is", "None", "and", "not", "self", ".", "_layer_norm", ":", "# bias of 1 for layer norm?", "\n", "                ", "bias_initializer", "=", "init_ops", ".", "constant_initializer", "(", "1.0", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "2", "*", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "initializer", "=", "bias_initializer", ")", "\n", "weights", "=", "tf", ".", "get_variable", "(", "'kernel'", ",", "[", "input_size", "+", "state_size", ",", "2", "*", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "self", ".", "_kernel_initializer", ")", "\n", "\n", "inputs_", "=", "tf", ".", "matmul", "(", "inputs", ",", "weights", "[", ":", "input_size", "]", ")", "\n", "state_", "=", "tf", ".", "matmul", "(", "state", ",", "weights", "[", "input_size", ":", "]", ")", "\n", "\n", "if", "self", ".", "_layer_norm", ":", "\n", "                ", "inputs_", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "inputs_", ",", "scope", "=", "'inputs'", ")", "\n", "state_", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "state_", ",", "scope", "=", "'state'", ")", "\n", "\n", "", "value", "=", "tf", ".", "nn", ".", "sigmoid", "(", "inputs_", "+", "state_", "+", "bias", ")", "\n", "r", ",", "u", "=", "tf", ".", "split", "(", "value", "=", "value", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"candidate\"", ")", ":", "\n", "            ", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "initializer", "=", "self", ".", "_bias_initializer", ")", "\n", "weights", "=", "tf", ".", "get_variable", "(", "'kernel'", ",", "[", "input_size", "+", "state_size", ",", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "self", ".", "_kernel_initializer", ")", "\n", "\n", "c", "=", "tf", ".", "matmul", "(", "tf", ".", "concat", "(", "[", "inputs", ",", "r", "*", "state", "]", ",", "axis", "=", "1", ")", ",", "weights", ")", "\n", "\n", "if", "self", ".", "_layer_norm", ":", "\n", "                ", "c", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "c", ")", "\n", "\n", "", "c", "=", "self", ".", "_activation", "(", "c", "+", "bias", ")", "\n", "\n", "", "new_h", "=", "u", "*", "state", "+", "(", "1", "-", "u", ")", "*", "c", "\n", "return", "new_h", ",", "new_h", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.__init__": [[262, 269], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "forget_bias", "=", "1.0", ",", "activation", "=", "None", ",", "reuse", "=", "None", ",", "fact_size", "=", "None", ",", "proj_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "PLSTM", ",", "self", ")", ".", "__init__", "(", "_reuse", "=", "reuse", ")", "\n", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_activation", "=", "activation", "or", "tf", ".", "tanh", "\n", "self", ".", "_fact_size", "=", "fact_size", "\n", "self", ".", "_proj_size", "=", "proj_size", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.state_size": [[270, 276], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_proj_size", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_num_units", "+", "self", ".", "_proj_size", "\n", "", "else", ":", "\n", "            ", "return", "2", "*", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.output_size": [[277, 283], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_proj_size", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_proj_size", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.call": [[284, 305], ["tensorflow.split", "tensorflow.concat", "tensorflow.layers.dense", "tensorflow.split", "tensorflow.concat", "tensorflow.layers.dense", "rnn.PLSTM._activation", "sigmoid", "tensorflow.layers.dense", "sigmoid", "sigmoid", "rnn.PLSTM._activation"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "state", ")", ":", "\n", "        ", "sigmoid", "=", "tf", ".", "sigmoid", "\n", "size", "=", "[", "self", ".", "state_size", "-", "self", ".", "output_size", ",", "self", ".", "output_size", "]", "\n", "c", ",", "h", "=", "tf", ".", "split", "(", "value", "=", "state", ",", "num_or_size_splits", "=", "size", ",", "axis", "=", "1", ")", "\n", "\n", "T", "=", "tf", ".", "concat", "(", "[", "inputs", ",", "h", "]", ",", "axis", "=", "1", ")", "\n", "if", "self", ".", "_fact_size", "is", "not", "None", ":", "\n", "            ", "T", "=", "tf", ".", "layers", ".", "dense", "(", "T", ",", "self", ".", "_fact_size", ",", "use_bias", "=", "False", ",", "name", "=", "'factorization'", ")", "\n", "", "T", "=", "tf", ".", "layers", ".", "dense", "(", "T", ",", "4", "*", "self", ".", "_num_units", ",", "use_bias", "=", "True", ")", "\n", "\n", "# i = input_gate, j = new_input, f = forget_gate, o = output_gate", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "tf", ".", "split", "(", "T", ",", "num_or_size_splits", "=", "4", ",", "axis", "=", "1", ")", "\n", "new_c", "=", "c", "*", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", ")", "+", "sigmoid", "(", "i", ")", "*", "self", ".", "_activation", "(", "j", ")", "\n", "\n", "new_h", "=", "self", ".", "_activation", "(", "new_c", ")", "*", "sigmoid", "(", "o", ")", "\n", "\n", "if", "self", ".", "_proj_size", "is", "not", "None", ":", "\n", "            ", "new_h", "=", "tf", ".", "layers", ".", "dense", "(", "new_h", ",", "self", ".", "_proj_size", ",", "use_bias", "=", "False", ",", "name", "=", "'projection'", ")", "\n", "\n", "", "new_state", "=", "tf", ".", "concat", "(", "[", "new_c", ",", "new_h", "]", ",", "1", ")", "\n", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.stack_bidirectional_dynamic_rnn": [[6, 60], ["tensorflow.variable_scope", "enumerate", "tuple", "tuple", "zip", "states_fw.append", "states_bw.append", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "rnn.apply_time_pooling", "tensorflow.layers.dense", "len", "tensorflow.layers.batch_normalization", "inter_layer_activation.lower", "tensorflow.nn.relu", "tensorflow.nn.dropout", "len", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.apply_time_pooling"], ["def", "stack_bidirectional_dynamic_rnn", "(", "cells_fw", ",", "cells_bw", ",", "inputs", ",", "initial_states_fw", "=", "None", ",", "initial_states_bw", "=", "None", ",", "\n", "dtype", "=", "None", ",", "sequence_length", "=", "None", ",", "parallel_iterations", "=", "None", ",", "scope", "=", "None", ",", "\n", "time_pooling", "=", "None", ",", "pooling_avg", "=", "None", ",", "initializer", "=", "None", ",", "inter_layers", "=", "None", ",", "\n", "inter_layer_activation", "=", "None", ",", "batch_norm", "=", "None", ",", "inter_layer_keep_prob", "=", "None", ",", "\n", "pervasive_dropout", "=", "None", ",", "training", "=", "True", ")", ":", "\n", "    ", "states_fw", "=", "[", "]", "\n", "states_bw", "=", "[", "]", "\n", "prev_layer", "=", "inputs", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"stack_bidirectional_rnn\"", ",", "initializer", "=", "initializer", ")", ":", "\n", "        ", "for", "i", ",", "(", "cell_fw", ",", "cell_bw", ")", "in", "enumerate", "(", "zip", "(", "cells_fw", ",", "cells_bw", ")", ")", ":", "\n", "            ", "initial_state_fw", "=", "None", "\n", "initial_state_bw", "=", "None", "\n", "if", "initial_states_fw", ":", "\n", "                ", "initial_state_fw", "=", "initial_states_fw", "[", "i", "]", "\n", "", "if", "initial_states_bw", ":", "\n", "                ", "initial_state_bw", "=", "initial_states_bw", "[", "i", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'cell_{}'", ".", "format", "(", "i", ")", ")", ":", "\n", "                ", "outputs", ",", "(", "state_fw", ",", "state_bw", ")", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell_fw", ",", "\n", "cell_bw", ",", "\n", "prev_layer", ",", "\n", "initial_state_fw", "=", "initial_state_fw", ",", "\n", "initial_state_bw", "=", "initial_state_bw", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "dtype", "=", "dtype", ")", "\n", "# Concat the outputs to create the new input.", "\n", "prev_layer", "=", "tf", ".", "concat", "(", "outputs", ",", "axis", "=", "2", ")", "\n", "\n", "if", "time_pooling", "and", "i", "<", "len", "(", "cells_fw", ")", "-", "1", ":", "\n", "                    ", "prev_layer", ",", "sequence_length", "=", "apply_time_pooling", "(", "prev_layer", ",", "sequence_length", ",", "time_pooling", "[", "i", "]", ",", "\n", "pooling_avg", ")", "\n", "\n", "", "if", "inter_layers", "and", "len", "(", "inter_layers", ")", ">", "i", "and", "inter_layers", "[", "i", "]", ":", "\n", "                    ", "layer_size", "=", "inter_layers", "[", "i", "]", "\n", "prev_layer", "=", "tf", ".", "layers", ".", "dense", "(", "prev_layer", ",", "layer_size", ",", "use_bias", "=", "not", "batch_norm", ")", "\n", "\n", "if", "batch_norm", ":", "\n", "                        ", "prev_layer", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "prev_layer", ",", "training", "=", "training", ")", "\n", "\n", "", "if", "inter_layer_activation", ".", "lower", "(", ")", "==", "'relu'", ":", "\n", "                        ", "prev_layer", "=", "tf", ".", "nn", ".", "relu", "(", "prev_layer", ")", "\n", "\n", "", "if", "inter_layer_keep_prob", "is", "not", "None", ":", "\n", "                        ", "noise_shape", "=", "[", "1", ",", "1", ",", "tf", ".", "shape", "(", "prev_layer", ")", "[", "2", "]", "]", "if", "pervasive_dropout", "else", "None", "\n", "prev_layer", "=", "tf", ".", "nn", ".", "dropout", "(", "prev_layer", ",", "keep_prob", "=", "inter_layer_keep_prob", ",", "\n", "noise_shape", "=", "noise_shape", ")", "\n", "\n", "", "", "", "states_fw", ".", "append", "(", "state_fw", ")", "\n", "states_bw", ".", "append", "(", "state_bw", ")", "\n", "\n", "", "", "return", "prev_layer", ",", "tuple", "(", "states_fw", ")", ",", "tuple", "(", "states_bw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.apply_time_pooling": [[62, 82], ["tensorflow.reshape", "range", "tensorflow.stack", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.stack", "tensorflow.pad", "tensorflow.reduce_sum", "len", "tf.reshape.get_shape", "range", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "def", "apply_time_pooling", "(", "inputs", ",", "sequence_length", ",", "stride", ",", "pooling_avg", "=", "False", ")", ":", "\n", "    ", "shape", "=", "[", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ",", "inputs", ".", "get_shape", "(", ")", "[", "2", "]", ".", "value", "]", "\n", "\n", "if", "pooling_avg", ":", "\n", "        ", "inputs_", "=", "[", "inputs", "[", ":", ",", "i", ":", ":", "stride", ",", ":", "]", "for", "i", "in", "range", "(", "stride", ")", "]", "\n", "\n", "max_len", "=", "tf", ".", "shape", "(", "inputs_", "[", "0", "]", ")", "[", "1", "]", "\n", "for", "k", "in", "range", "(", "1", ",", "stride", ")", ":", "\n", "            ", "len_", "=", "tf", ".", "shape", "(", "inputs_", "[", "k", "]", ")", "[", "1", "]", "\n", "paddings", "=", "tf", ".", "stack", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "max_len", "-", "len_", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "inputs_", "[", "k", "]", "=", "tf", ".", "pad", "(", "inputs_", "[", "k", "]", ",", "paddings", "=", "paddings", ")", "\n", "\n", "", "inputs", "=", "tf", ".", "reduce_sum", "(", "inputs_", ",", "axis", "=", "0", ")", "/", "len", "(", "inputs_", ")", "\n", "", "else", ":", "\n", "        ", "inputs", "=", "inputs", "[", ":", ",", ":", ":", "stride", ",", ":", "]", "\n", "\n", "", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "tf", ".", "stack", "(", "[", "shape", "[", "0", "]", ",", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", ",", "shape", "[", "2", "]", "]", ")", ")", "\n", "sequence_length", "=", "(", "sequence_length", "+", "stride", "-", "1", ")", "//", "stride", "# rounding up", "\n", "\n", "return", "inputs", ",", "sequence_length", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.get_state_size": [[306, 313], ["cell_type.lower", "cell_type.lower"], "function", ["None"], ["", "", "def", "get_state_size", "(", "cell_type", ",", "cell_size", ",", "proj_size", "=", "None", ",", "layers", "=", "1", ")", ":", "\n", "    ", "if", "cell_type", ".", "lower", "(", ")", "==", "'plstm'", "and", "proj_size", "is", "not", "None", ":", "\n", "        ", "return", "proj_size", ",", "(", "proj_size", "+", "cell_size", ")", "*", "layers", "\n", "", "elif", "cell_type", ".", "lower", "(", ")", "in", "(", "'lstm'", ",", "'plstm'", ")", ":", "\n", "        ", "return", "cell_size", ",", "cell_size", "*", "2", "*", "layers", "\n", "", "else", ":", "\n", "        ", "return", "cell_size", ",", "cell_size", "*", "layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights": [[9, 21], ["tensorflow.cumsum", "tensorflow.range", "tensorflow.tile", "tensorflow.to_float", "tensorflow.stop_gradient", "tensorflow.to_float", "tensorflow.expand_dims", "tensorflow.equal", "tensorflow.concat", "tensorflow.not_equal", "tensorflow.to_float", "tensorflow.shape", "tensorflow.shape", "tensorflow.ones", "tensorflow.shape", "tensorflow.stack", "translate.utils.EOS_ID"], "function", ["None"], ["def", "get_weights", "(", "sequence", ",", "eos_id", ",", "include_first_eos", "=", "True", ")", ":", "\n", "    ", "cumsum", "=", "tf", ".", "cumsum", "(", "tf", ".", "to_float", "(", "tf", ".", "not_equal", "(", "sequence", ",", "eos_id", ")", ")", ",", "axis", "=", "1", ")", "\n", "range_", "=", "tf", ".", "range", "(", "start", "=", "1", ",", "limit", "=", "tf", ".", "shape", "(", "sequence", ")", "[", "1", "]", "+", "1", ")", "\n", "range_", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "range_", ",", "axis", "=", "0", ")", ",", "[", "tf", ".", "shape", "(", "sequence", ")", "[", "0", "]", ",", "1", "]", ")", "\n", "weights", "=", "tf", ".", "to_float", "(", "tf", ".", "equal", "(", "cumsum", ",", "tf", ".", "to_float", "(", "range_", ")", ")", ")", "\n", "\n", "if", "include_first_eos", ":", "\n", "        ", "weights", "=", "weights", "[", ":", ",", ":", "-", "1", "]", "\n", "shape", "=", "[", "tf", ".", "shape", "(", "weights", ")", "[", "0", "]", ",", "1", "]", "\n", "weights", "=", "tf", ".", "concat", "(", "[", "tf", ".", "ones", "(", "tf", ".", "stack", "(", "shape", ")", ")", ",", "weights", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "tf", ".", "stop_gradient", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.resize_like": [[23, 30], ["tensorflow.tile", "tensorflow.reshape", "tensorflow.shape", "beam_search.get_shape", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.shape", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "def", "resize_like", "(", "src", ",", "dst", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "src", ")", "[", "0", "]", "\n", "beam_size", "=", "tf", ".", "shape", "(", "dst", ")", "[", "0", "]", "//", "batch_size", "\n", "shape", "=", "get_shape", "(", "src", ")", "[", "1", ":", "]", "\n", "src", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "src", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "beam_size", "]", "+", "[", "1", "]", "*", "len", "(", "shape", ")", ")", "\n", "src", "=", "tf", ".", "reshape", "(", "src", ",", "tf", ".", "stack", "(", "[", "batch_size", "*", "beam_size", "]", "+", "shape", ")", ")", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape": [[32, 39], ["tensor.shape.as_list", "tensorflow.unstack", "tensorflow.shape", "zip"], "function", ["None"], ["", "def", "get_shape", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Returns static shape if available and dynamic shape otherwise.\"\"\"", "\n", "static_shape", "=", "tensor", ".", "shape", ".", "as_list", "(", ")", "\n", "dynamic_shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "dims", "=", "[", "s", "[", "1", "]", "if", "s", "[", "0", "]", "is", "None", "else", "s", "[", "0", "]", "\n", "for", "s", "in", "zip", "(", "static_shape", ",", "dynamic_shape", ")", "]", "\n", "return", "dims", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.batch_gather": [[41, 60], ["beam_search.get_shape", "tensorflow.reshape", "tensorflow.convert_to_tensor", "tensorflow.reshape", "tensorflow.gather", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "def", "batch_gather", "(", "tensor", ",", "indices", ")", ":", "\n", "    ", "\"\"\"Gather in batch from a tensor of arbitrary size.\n\n    In pseduocode this module will produce the following:\n    output[i] = tf.gather(tensor[i], indices[i])\n\n    Args:\n      tensor: Tensor of arbitrary size.\n      indices: Vector of indices.\n    Returns:\n      output: A tensor of gathered values.\n    \"\"\"", "\n", "shape", "=", "get_shape", "(", "tensor", ")", "\n", "flat_first", "=", "tf", ".", "reshape", "(", "tensor", ",", "[", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "]", "+", "shape", "[", "2", ":", "]", ")", "\n", "indices", "=", "tf", ".", "convert_to_tensor", "(", "indices", ")", "\n", "offset_shape", "=", "[", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "indices", ".", "shape", ".", "ndims", "-", "1", ")", "\n", "offset", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "shape", "[", "0", "]", ")", "*", "shape", "[", "1", "]", ",", "offset_shape", ")", "\n", "output", "=", "tf", ".", "gather", "(", "flat_first", ",", "indices", "+", "offset", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.log_softmax": [[62, 66], ["tensorflow.reduce_max", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.exp"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "log_softmax", "(", "x", ",", "axis", ",", "temperature", "=", "None", ")", ":", "\n", "    ", "T", "=", "temperature", "or", "1.0", "\n", "my_max", "=", "tf", ".", "reduce_max", "(", "x", "/", "T", ",", "axis", "=", "axis", ",", "keep_dims", "=", "True", ")", "\n", "return", "x", "-", "(", "tf", ".", "log", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "x", "/", "T", "-", "my_max", ")", ",", "axis", ",", "keep_dims", "=", "True", ")", ")", "+", "my_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.softmax": [[68, 75], ["tensorflow.reduce_max", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.clip_by_value"], "function", ["None"], ["", "def", "softmax", "(", "e", ",", "temperature", "=", "None", ")", ":", "\n", "    ", "e", "-=", "tf", ".", "reduce_max", "(", "e", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "T", "=", "temperature", "or", "1.0", "\n", "exp", "=", "tf", ".", "exp", "(", "e", "/", "T", ")", "\n", "y", "=", "tf", ".", "reduce_sum", "(", "exp", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "weights", "=", "exp", "/", "tf", ".", "clip_by_value", "(", "y", ",", "10e-37", ",", "10e+37", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.random_sampling": [[77, 144], ["tensorflow.concat", "tensorflow.concat", "tensorflow.log", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.constant", "tensorflow.while_loop", "tensorflow.shape", "tensorflow.tile", "tf.concat.append", "tensorflow.reshape", "tensorflow.zeros", "tensorflow.split", "enumerate", "tensorflow.map_fn", "tensorflow.to_int32", "tensorflow.squeeze", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.TensorShape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.zeros", "zip", "tensorflow.reshape", "new_states.append", "tensorflow.reshape", "tensorflow.log", "tensorflow.multinomial", "tensorflow.transpose", "len", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "update_fun", "tensorflow.shape", "beam_search.softmax", "tensorflow.expand_dims", "tensorflow.expand_dims", "len", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.softmax"], ["", "def", "random_sampling", "(", "update_funs", ",", "initial_states", ",", "sequence_length", ",", "beam_size", ",", "temperature", "=", "None", ",", "parallel_iterations", "=", "16", ",", "\n", "swap_memory", "=", "True", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "initial_states", "[", "0", "]", ")", "[", "0", "]", "\n", "\n", "state_sizes", "=", "[", "tf", ".", "shape", "(", "state", ")", "[", "1", "]", "for", "state", "in", "initial_states", "]", "\n", "states", "=", "[", "]", "\n", "for", "initial_state", "in", "initial_states", ":", "\n", "        ", "state", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_state", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "states", ".", "append", "(", "state", ")", "\n", "", "states", "=", "tf", ".", "concat", "(", "states", ",", "axis", "=", "2", ")", "\n", "\n", "scores", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "ones", "(", "shape", "=", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "beam_size", "-", "1", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "tf", ".", "log", "(", "scores", ")", "\n", "\n", "ids", "=", "tf", ".", "tile", "(", "[", "[", "utils", ".", "BOS_ID", "]", "]", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "hypotheses", "=", "tf", ".", "expand_dims", "(", "ids", ",", "axis", "=", "2", ")", "\n", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "'time'", ")", "\n", "\n", "def", "time_step", "(", "time", ",", "hypotheses", ",", "states", ",", "token_ids", ")", ":", "\n", "        ", "token_ids", "=", "tf", ".", "reshape", "(", "token_ids", ",", "[", "batch_size", "*", "beam_size", "]", ")", "\n", "token_scores", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ")", "\n", "\n", "new_states", "=", "[", "]", "\n", "states", "=", "tf", ".", "split", "(", "states", ",", "num_or_size_splits", "=", "len", "(", "initial_states", ")", ",", "axis", "=", "2", ")", "\n", "\n", "for", "k", ",", "(", "state", ",", "state_size", ",", "update_fun", ")", "in", "enumerate", "(", "zip", "(", "states", ",", "state_sizes", ",", "update_funs", ")", ")", ":", "\n", "            ", "state", "=", "tf", ".", "reshape", "(", "state", ",", "[", "batch_size", "*", "beam_size", ",", "state_size", "]", ")", "\n", "\n", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "if", "len", "(", "update_funs", ")", "==", "1", "else", "'model_{}'", ".", "format", "(", "k", "+", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "state", ",", "logits", "=", "update_fun", "(", "state", ",", "token_ids", ",", "time", ")", "\n", "\n", "", "new_states", ".", "append", "(", "state", ")", "\n", "\n", "num_classes", "=", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "beam_size", ",", "num_classes", "]", ")", "\n", "token_scores", "+=", "tf", ".", "log", "(", "softmax", "(", "logits", ",", "temperature", ")", ")", "\n", "\n", "", "fn", "=", "lambda", "x", ":", "tf", ".", "multinomial", "(", "x", ",", "num_samples", "=", "1", ")", "\n", "indices", "=", "tf", ".", "map_fn", "(", "fn", ",", "tf", ".", "transpose", "(", "token_scores", ",", "[", "1", ",", "0", ",", "2", "]", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "indices", "=", "tf", ".", "to_int32", "(", "indices", ")", "\n", "indices", "=", "tf", ".", "squeeze", "(", "indices", ",", "axis", "=", "2", ")", "\n", "indices", "=", "tf", ".", "transpose", "(", "indices", ",", "[", "1", ",", "0", "]", ")", "\n", "\n", "hypotheses", "=", "tf", ".", "concat", "(", "[", "hypotheses", ",", "tf", ".", "expand_dims", "(", "indices", ",", "axis", "=", "2", ")", "]", ",", "axis", "=", "2", ")", "\n", "states", "=", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "state", ",", "axis", "=", "2", ")", "for", "state", "in", "new_states", "]", ",", "axis", "=", "2", ")", "\n", "return", "time", "+", "1", ",", "hypotheses", ",", "states", ",", "indices", "\n", "\n", "", "loop_vars", "=", "[", "time", ",", "hypotheses", ",", "states", ",", "ids", "]", "\n", "shapes", "=", "[", "tf", ".", "TensorShape", "(", "[", "None", "]", "*", "len", "(", "var", ".", "shape", ")", ")", "for", "var", "in", "loop_vars", "]", "\n", "\n", "def", "cond", "(", "time", ",", "*", "_", ")", ":", "\n", "        ", "return", "time", "<", "sequence_length", "\n", "\n", "", "_", ",", "hypotheses", ",", "states", ",", "ids", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "cond", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "loop_vars", ",", "\n", "shape_invariants", "=", "shapes", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ")", "\n", "\n", "hypotheses", "=", "hypotheses", "[", ":", ",", ":", ",", "1", ":", "]", "# remove BOS symbol", "\n", "\n", "return", "hypotheses", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.rnn_beam_search": [[146, 249], ["tensorflow.concat", "tensorflow.concat", "tensorflow.log", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.constant", "tensorflow.while_loop", "tensorflow.shape", "tensorflow.tile", "tf.concat.append", "tensorflow.reshape", "tensorflow.zeros", "tensorflow.split", "enumerate", "tensorflow.expand_dims", "tensorflow.one_hot", "tensorflow.nn.top_k", "tensorflow.concat", "tensorflow.concat", "tensorflow.TensorShape", "tensorflow.logical_and", "tensorflow.reshape", "beam_search.get_weights", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.nn.top_k", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.zeros", "zip", "tensorflow.reshape", "tensorflow.reshape", "new_states.append", "tensorflow.reshape", "beam_search.log_softmax", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.reshape", "beam_search.batch_gather", "tensorflow.to_float", "tensorflow.to_int32", "tensorflow.shape", "tensorflow.shape", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "update_fun", "tensorflow.shape", "beam_search.batch_gather", "beam_search.batch_gather", "tensorflow.expand_dims", "tensorflow.not_equal", "len", "tensorflow.reduce_sum", "tensorflow.tile", "len", "tensorflow.expand_dims", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.log_softmax", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.batch_gather", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.batch_gather", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.batch_gather"], ["", "def", "rnn_beam_search", "(", "update_funs", ",", "initial_states", ",", "sequence_length", ",", "beam_size", ",", "len_normalization", "=", "None", ",", "\n", "temperature", "=", "None", ",", "parallel_iterations", "=", "16", ",", "swap_memory", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param update_funs: function to compute the next state and logits given the current state and previous ids\n    :param initial_states: recurrent model states\n    :param sequence_length: maximum output length\n    :param beam_size: beam size\n    :param len_normalization: length normalization coefficient (0 or None for no length normalization)\n    :return: tensor of size (batch_size, beam_size, seq_len) containing the beam-search hypotheses sorted by\n        best score (axis 1), and tensor of size (batch_size, beam_size) containing the said scores.\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "initial_states", "[", "0", "]", ")", "[", "0", "]", "\n", "\n", "state_sizes", "=", "[", "tf", ".", "shape", "(", "state", ")", "[", "1", "]", "for", "state", "in", "initial_states", "]", "\n", "states", "=", "[", "]", "\n", "for", "initial_state", "in", "initial_states", ":", "\n", "        ", "state", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_state", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "beam_size", ",", "1", "]", ")", "\n", "states", ".", "append", "(", "state", ")", "\n", "", "states", "=", "tf", ".", "concat", "(", "states", ",", "axis", "=", "2", ")", "\n", "\n", "scores", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "ones", "(", "shape", "=", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "beam_size", "-", "1", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "scores", "=", "tf", ".", "log", "(", "scores", ")", "\n", "\n", "ids", "=", "tf", ".", "tile", "(", "[", "[", "utils", ".", "BOS_ID", "]", "]", ",", "[", "batch_size", ",", "beam_size", "]", ")", "\n", "hypotheses", "=", "tf", ".", "expand_dims", "(", "ids", ",", "axis", "=", "2", ")", "\n", "\n", "mask", "=", "tf", ".", "ones", "(", "[", "batch_size", ",", "beam_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "'time'", ")", "\n", "\n", "def", "time_step", "(", "time", ",", "mask", ",", "hypotheses", ",", "states", ",", "token_ids", ",", "scores", ")", ":", "\n", "        ", "token_ids", "=", "tf", ".", "reshape", "(", "token_ids", ",", "[", "batch_size", "*", "beam_size", "]", ")", "\n", "token_scores", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "beam_size", ",", "1", "]", ")", "\n", "\n", "new_states", "=", "[", "]", "\n", "states", "=", "tf", ".", "split", "(", "states", ",", "num_or_size_splits", "=", "state_sizes", ",", "axis", "=", "2", ")", "\n", "\n", "for", "k", ",", "(", "state", ",", "state_size", ",", "update_fun", ")", "in", "enumerate", "(", "zip", "(", "states", ",", "state_sizes", ",", "update_funs", ")", ")", ":", "\n", "            ", "state", "=", "tf", ".", "reshape", "(", "state", ",", "[", "batch_size", "*", "beam_size", ",", "state_size", "]", ")", "\n", "\n", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "if", "len", "(", "update_funs", ")", "==", "1", "else", "'model_{}'", ".", "format", "(", "k", "+", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "state", ",", "logits", "=", "update_fun", "(", "state", ",", "token_ids", ",", "time", ")", "\n", "\n", "", "state", "=", "tf", ".", "reshape", "(", "state", ",", "[", "batch_size", ",", "beam_size", ",", "state_size", "]", ")", "\n", "new_states", ".", "append", "(", "state", ")", "\n", "\n", "num_classes", "=", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", "\n", "logits", "=", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "beam_size", ",", "num_classes", "]", ")", "\n", "token_scores", "+=", "log_softmax", "(", "logits", ",", "axis", "=", "2", ",", "temperature", "=", "temperature", ")", "\n", "\n", "", "num_classes", "=", "tf", ".", "shape", "(", "token_scores", ")", "[", "2", "]", "\n", "mask1", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "2", ")", "\n", "mask2", "=", "tf", ".", "one_hot", "(", "indices", "=", "[", "[", "utils", ".", "EOS_ID", "]", "]", ",", "depth", "=", "num_classes", ")", "\n", "token_scores", "=", "token_scores", "*", "mask1", "+", "(", "1", "-", "mask1", ")", "*", "(", "1", "-", "mask2", ")", "*", "-", "1e30", "\n", "\n", "sum_logprobs", "=", "tf", ".", "expand_dims", "(", "scores", ",", "axis", "=", "2", ")", "+", "token_scores", "\n", "\n", "scores", ",", "indices", "=", "tf", ".", "nn", ".", "top_k", "(", "\n", "tf", ".", "reshape", "(", "sum_logprobs", ",", "[", "batch_size", ",", "num_classes", "*", "beam_size", "]", ")", ",", "\n", "k", "=", "beam_size", ")", "\n", "\n", "beam_ids", "=", "indices", "//", "num_classes", "\n", "token_ids", "=", "indices", "%", "num_classes", "\n", "\n", "states", "=", "tf", ".", "concat", "(", "[", "batch_gather", "(", "state", ",", "beam_ids", ")", "for", "state", "in", "new_states", "]", ",", "axis", "=", "2", ")", "\n", "hypotheses", "=", "tf", ".", "concat", "(", "[", "batch_gather", "(", "hypotheses", ",", "beam_ids", ")", ",", "tf", ".", "expand_dims", "(", "token_ids", ",", "axis", "=", "2", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n", "mask", "=", "(", "batch_gather", "(", "mask", ",", "beam_ids", ")", "*", "tf", ".", "to_float", "(", "tf", ".", "not_equal", "(", "token_ids", ",", "utils", ".", "EOS_ID", ")", ")", ")", "\n", "return", "time", "+", "1", ",", "mask", ",", "hypotheses", ",", "states", ",", "token_ids", ",", "scores", "\n", "\n", "", "loop_vars", "=", "[", "time", ",", "mask", ",", "hypotheses", ",", "states", ",", "ids", ",", "scores", "]", "\n", "shapes", "=", "[", "tf", ".", "TensorShape", "(", "[", "None", "]", "*", "len", "(", "var", ".", "shape", ")", ")", "for", "var", "in", "loop_vars", "]", "\n", "\n", "def", "cond", "(", "time", ",", "mask", ",", "*", "_", ")", ":", "\n", "        ", "p1", "=", "time", "<", "sequence_length", "\n", "p2", "=", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "1", "-", "mask", ")", ")", "<", "batch_size", "*", "beam_size", "\n", "return", "tf", ".", "logical_and", "(", "p1", ",", "p2", ")", "\n", "\n", "", "_", ",", "mask", ",", "hypotheses", ",", "states", ",", "ids", ",", "scores", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "cond", ",", "\n", "body", "=", "time_step", ",", "\n", "loop_vars", "=", "loop_vars", ",", "\n", "shape_invariants", "=", "shapes", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ")", "\n", "\n", "hypotheses", "=", "hypotheses", "[", ":", ",", ":", ",", "1", ":", "]", "# remove BOS symbol", "\n", "\n", "if", "len_normalization", ":", "\n", "        ", "n", "=", "tf", ".", "shape", "(", "hypotheses", ")", "[", "1", "]", "\n", "sequence_length", "=", "tf", ".", "shape", "(", "hypotheses", ")", "[", "2", "]", "\n", "sel_ids_", "=", "tf", ".", "reshape", "(", "hypotheses", ",", "shape", "=", "[", "batch_size", "*", "n", ",", "sequence_length", "]", ")", "\n", "mask", "=", "get_weights", "(", "sel_ids_", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "length", "=", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ")", "\n", "length", "=", "tf", ".", "reshape", "(", "length", ",", "shape", "=", "[", "batch_size", ",", "n", "]", ")", "\n", "scores", "/=", "(", "length", "**", "len_normalization", ")", "\n", "scores", ",", "indices", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "k", "=", "beam_size", ",", "sorted", "=", "True", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "beam_size", "]", ")", ",", "indices", "]", ",", "axis", "=", "2", ")", "\n", "hypotheses", "=", "tf", ".", "gather_nd", "(", "hypotheses", ",", "indices", ")", "\n", "\n", "", "return", "hypotheses", ",", "scores", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.CellWrapper.__init__": [[39, 43], ["tensorflow.contrib.rnn.RNNCell.__init__", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__"], ["def", "__init__", "(", "self", ",", "cell", ")", ":", "\n", "        ", "super", "(", "CellWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cell", "=", "cell", "\n", "self", ".", "num_splits", "=", "len", "(", "cell", ".", "state_size", ")", "if", "isinstance", "(", "cell", ".", "state_size", ",", "tuple", ")", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.CellWrapper.state_size": [[44, 47], ["sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "self", ".", "cell", ".", "state_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.CellWrapper.output_size": [[48, 51], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.CellWrapper.__call__": [[52, 56], ["tensorflow.split", "models.CellWrapper.cell", "tensorflow.concat"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "state", "=", "tf", ".", "split", "(", "value", "=", "state", ",", "num_or_size_splits", "=", "self", ".", "num_splits", ",", "axis", "=", "1", ")", "\n", "new_h", ",", "new_state", "=", "self", ".", "cell", "(", "inputs", ",", "state", ",", "scope", "=", "scope", ")", "\n", "return", "new_h", ",", "tf", ".", "concat", "(", "new_state", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.auto_reuse": [[12, 28], ["str", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tensorflow.tf.nn.dynamic_rnn", "tensorflow.tf.get_variable", "tensorflow.tf.layers.dense"], "function", ["None"], ["def", "auto_reuse", "(", "fun", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper that automatically handles the `reuse' parameter.\n    This is rather risky, as it can lead to reusing variables\n    by mistake.\n    \"\"\"", "\n", "def", "fun_", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "fun", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "if", "'reuse'", "in", "str", "(", "e", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "True", ")", ":", "\n", "                    ", "return", "fun", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "e", "\n", "", "", "", "return", "fun_", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder": [[58, 368], ["enumerate", "tensorflow.concat", "translate.rnn.get_state_size", "tensorflow.device", "tensorflow.variable_scope", "dict", "tensorflow.stack", "tensorflow.gather_nd", "tf.gather_nd.set_shape", "encoder_states.append", "new_encoder_input_length.append", "tensorflow.random_uniform_initializer", "tensorflow.random_normal_initializer", "get_variable", "get_variable", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.nn.embedding_lookup", "tensorflow.reshape", "tensorflow.range", "tensorflow.nn.embedding_lookup", "tensorflow.tile", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "enumerate", "tensorflow.expand_dims", "enumerate", "tensorflow.reshape", "tensorflow.nn.embedding_lookup", "tensorflow.expand_dims", "tensorflow.tile", "enumerate", "tensorflow.concat", "tensorflow.nn.relu", "tensorflow.zeros", "tensorflow.concat", "tensorflow.nn.pool", "tensorflow.to_int32", "range", "tensorflow.concat", "dense", "encoder_outputs.append", "encoder.cell_type.lower", "models.CellWrapper", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.stack", "tensorflow.expand_dims", "tensorflow.shape", "dense", "get_variable", "tensorflow.nn.conv2d", "tensorflow.to_int32", "tensorflow.shape", "translate.conv_lstm.BasicConvLSTMCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.concat", "tensorflow.expand_dims", "get_variable", "tensorflow.nn.convolution", "inputs.append", "tensorflow.to_int32", "tensorflow.ceil", "tf.nn.relu.get_shape", "get_variable", "tensorflow.tile", "translate.rnn.stack_bidirectional_dynamic_rnn", "translate.rnn.CellInitializer", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "models.multi_encoder.get_cell"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.get_state_size", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.stack_bidirectional_dynamic_rnn"], ["", "", "def", "multi_encoder", "(", "encoder_inputs", ",", "encoders", ",", "encoder_input_length", ",", "other_inputs", "=", "None", ",", "training", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Build multiple encoders according to the configuration in `encoders`, reading from `encoder_inputs`.\n    The result is a list of the outputs produced by those encoders (for each time-step), and their final state.\n\n    :param encoder_inputs: list of tensors of shape (batch_size, input_length), one tensor for each encoder.\n    :param encoders: list of encoder configurations\n    :param encoder_input_length: list of tensors of shape (batch_size,) (one tensor for each encoder)\n    :return:\n      encoder outputs: a list of tensors of shape (batch_size, input_length, encoder_cell_size), hidden states of the\n        encoders.\n      encoder state: concatenation of the final states of all encoders, tensor of shape (batch_size, sum_of_state_sizes)\n      new_encoder_input_length: list of tensors of shape (batch_size,) with the true length of the encoder outputs.\n        May be different than `encoder_input_length` because of maxout strides, and time pooling.\n    \"\"\"", "\n", "encoder_states", "=", "[", "]", "\n", "encoder_outputs", "=", "[", "]", "\n", "new_encoder_input_length", "=", "[", "]", "\n", "\n", "for", "i", ",", "encoder", "in", "enumerate", "(", "encoders", ")", ":", "\n", "\n", "# create embeddings in the global scope (allows sharing between encoder and decoder)", "\n", "        ", "weight_scale", "=", "encoder", ".", "embedding_weight_scale", "or", "encoder", ".", "weight_scale", "\n", "if", "weight_scale", "is", "None", ":", "\n", "            ", "initializer", "=", "None", "# FIXME", "\n", "", "elif", "encoder", ".", "embedding_initializer", "==", "'uniform'", "or", "(", "encoder", ".", "embedding_initializer", "is", "None", "\n", "and", "encoder", ".", "initializer", "==", "'uniform'", ")", ":", "\n", "            ", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "weight_scale", ",", "maxval", "=", "weight_scale", ")", "\n", "", "else", ":", "\n", "            ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "weight_scale", ")", "\n", "\n", "", "device", "=", "None", "if", "encoder", ".", "embeddings_on_gpu", "else", "'/cpu:0'", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "# embeddings can take a very large amount of memory, so", "\n", "# storing them in GPU memory can be impractical", "\n", "            ", "if", "encoder", ".", "binary", ":", "\n", "                ", "embeddings", "=", "None", "# inputs are token ids, which need to be mapped to vectors (embeddings)", "\n", "", "else", ":", "\n", "                ", "embedding_shape", "=", "[", "encoder", ".", "vocab_size", ",", "encoder", ".", "embedding_size", "]", "\n", "embeddings", "=", "get_variable", "(", "'embedding_{}'", ".", "format", "(", "encoder", ".", "name", ")", ",", "shape", "=", "embedding_shape", ",", "\n", "initializer", "=", "initializer", ")", "\n", "", "if", "encoder", ".", "pos_embedding_size", ":", "\n", "                ", "pos_embedding_shape", "=", "[", "encoder", ".", "max_len", "+", "1", ",", "encoder", ".", "pos_embedding_size", "]", "\n", "pos_embeddings", "=", "get_variable", "(", "'pos_embedding_{}'", ".", "format", "(", "encoder", ".", "name", ")", ",", "shape", "=", "pos_embedding_shape", ",", "\n", "initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "                ", "pos_embeddings", "=", "None", "\n", "\n", "", "", "if", "encoder", ".", "use_lstm", "is", "False", ":", "\n", "            ", "encoder", ".", "cell_type", "=", "'GRU'", "\n", "\n", "", "cell_output_size", ",", "cell_state_size", "=", "get_state_size", "(", "encoder", ".", "cell_type", ",", "encoder", ".", "cell_size", ",", "\n", "encoder", ".", "lstm_proj_size", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'encoder_{}'", ".", "format", "(", "encoder", ".", "name", ")", ")", ":", "\n", "            ", "encoder_inputs_", "=", "encoder_inputs", "[", "i", "]", "\n", "initial_inputs", "=", "encoder_inputs_", "\n", "encoder_input_length_", "=", "encoder_input_length", "[", "i", "]", "\n", "\n", "def", "get_cell", "(", "input_size", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "                ", "if", "encoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "                    ", "cell", "=", "CellWrapper", "(", "BasicLSTMCell", "(", "encoder", ".", "cell_size", ",", "reuse", "=", "reuse", ")", ")", "\n", "", "elif", "encoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'plstm'", ":", "\n", "                    ", "cell", "=", "PLSTM", "(", "encoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "fact_size", "=", "encoder", ".", "lstm_fact_size", ",", "\n", "proj_size", "=", "encoder", ".", "lstm_proj_size", ")", "\n", "", "elif", "encoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'dropoutgru'", ":", "\n", "                    ", "cell", "=", "DropoutGRUCell", "(", "encoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "layer_norm", "=", "encoder", ".", "layer_norm", ",", "\n", "input_size", "=", "input_size", ",", "input_keep_prob", "=", "encoder", ".", "rnn_input_keep_prob", ",", "\n", "state_keep_prob", "=", "encoder", ".", "rnn_state_keep_prob", ")", "\n", "", "else", ":", "\n", "                    ", "cell", "=", "GRUCell", "(", "encoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "layer_norm", "=", "encoder", ".", "layer_norm", ")", "\n", "\n", "", "if", "encoder", ".", "use_dropout", "and", "encoder", ".", "cell_type", ".", "lower", "(", ")", "!=", "'dropoutgru'", ":", "\n", "                    ", "cell", "=", "DropoutWrapper", "(", "cell", ",", "input_keep_prob", "=", "encoder", ".", "rnn_input_keep_prob", ",", "\n", "output_keep_prob", "=", "encoder", ".", "rnn_output_keep_prob", ",", "\n", "state_keep_prob", "=", "encoder", ".", "rnn_state_keep_prob", ",", "\n", "variational_recurrent", "=", "encoder", ".", "pervasive_dropout", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "input_size", "=", "input_size", ")", "\n", "", "return", "cell", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "1", "]", "\n", "\n", "if", "embeddings", "is", "not", "None", ":", "\n", "                ", "flat_inputs", "=", "tf", ".", "reshape", "(", "encoder_inputs_", ",", "[", "tf", ".", "multiply", "(", "batch_size", ",", "time_steps", ")", "]", ")", "\n", "flat_inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeddings", ",", "flat_inputs", ")", "\n", "encoder_inputs_", "=", "tf", ".", "reshape", "(", "flat_inputs", ",", "\n", "tf", ".", "stack", "(", "[", "batch_size", ",", "time_steps", ",", "flat_inputs", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "]", ")", ")", "\n", "", "if", "pos_embeddings", "is", "not", "None", ":", "\n", "                ", "pos_inputs_", "=", "tf", ".", "range", "(", "time_steps", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "pos_inputs_", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "pos_embeddings", ",", "pos_inputs_", ")", "\n", "pos_inputs_", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "pos_inputs_", ",", "axis", "=", "0", ")", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "encoder_inputs_", "=", "tf", ".", "concat", "(", "[", "encoder_inputs_", ",", "pos_inputs_", "]", ",", "axis", "=", "2", ")", "\n", "\n", "", "if", "other_inputs", "is", "not", "None", ":", "\n", "                ", "encoder_inputs_", "=", "tf", ".", "concat", "(", "[", "encoder_inputs_", ",", "other_inputs", "]", ",", "axis", "=", "2", ")", "\n", "\n", "", "if", "encoder", ".", "use_dropout", ":", "\n", "                ", "noise_shape", "=", "[", "1", ",", "time_steps", ",", "1", "]", "if", "encoder", ".", "pervasive_dropout", "else", "[", "batch_size", ",", "time_steps", ",", "1", "]", "\n", "encoder_inputs_", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_inputs_", ",", "keep_prob", "=", "encoder", ".", "word_keep_prob", ",", "\n", "noise_shape", "=", "noise_shape", ")", "\n", "\n", "size", "=", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "2", "]", "\n", "noise_shape", "=", "[", "1", ",", "1", ",", "size", "]", "if", "encoder", ".", "pervasive_dropout", "else", "[", "batch_size", ",", "time_steps", ",", "size", "]", "\n", "encoder_inputs_", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_inputs_", ",", "keep_prob", "=", "encoder", ".", "embedding_keep_prob", ",", "\n", "noise_shape", "=", "noise_shape", ")", "\n", "\n", "", "if", "encoder", ".", "input_layers", ":", "\n", "                ", "for", "j", ",", "layer_size", "in", "enumerate", "(", "encoder", ".", "input_layers", ")", ":", "\n", "                    ", "if", "encoder", ".", "input_layer_activation", "is", "not", "None", "and", "encoder", ".", "input_layer_activation", ".", "lower", "(", ")", "==", "'relu'", ":", "\n", "                        ", "activation", "=", "tf", ".", "nn", ".", "relu", "\n", "", "else", ":", "\n", "                        ", "activation", "=", "tf", ".", "tanh", "\n", "\n", "", "if", "encoder", ".", "batch_norm", ":", "\n", "                        ", "encoder_inputs_", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "encoder_inputs_", ",", "training", "=", "training", ",", "\n", "name", "=", "'input_batch_norm_{}'", ".", "format", "(", "j", "+", "1", ")", ")", "\n", "\n", "", "encoder_inputs_", "=", "dense", "(", "encoder_inputs_", ",", "layer_size", ",", "activation", "=", "activation", ",", "use_bias", "=", "True", ",", "\n", "name", "=", "'layer_{}'", ".", "format", "(", "j", ")", ")", "\n", "if", "encoder", ".", "use_dropout", ":", "\n", "                        ", "encoder_inputs_", "=", "tf", ".", "nn", ".", "dropout", "(", "encoder_inputs_", ",", "keep_prob", "=", "encoder", ".", "input_layer_keep_prob", ")", "\n", "\n", "", "", "", "if", "encoder", ".", "conv_filters", ":", "\n", "                ", "encoder_inputs_", "=", "tf", ".", "expand_dims", "(", "encoder_inputs_", ",", "axis", "=", "3", ")", "\n", "\n", "for", "k", ",", "out_channels", "in", "enumerate", "(", "encoder", ".", "conv_filters", ",", "1", ")", ":", "\n", "                    ", "in_channels", "=", "encoder_inputs_", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "filter_height", ",", "filter_width", "=", "encoder", ".", "conv_size", "\n", "\n", "strides", "=", "encoder", ".", "conv_strides", "or", "[", "1", ",", "1", "]", "\n", "strides", "=", "[", "1", "]", "+", "strides", "+", "[", "1", "]", "\n", "\n", "filter_", "=", "get_variable", "(", "'filter_{}'", ".", "format", "(", "k", ")", ",", "\n", "[", "filter_height", ",", "filter_width", ",", "in_channels", ",", "out_channels", "]", ")", "\n", "encoder_inputs_", "=", "tf", ".", "nn", ".", "conv2d", "(", "encoder_inputs_", ",", "filter_", ",", "strides", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "if", "encoder", ".", "batch_norm", ":", "\n", "                        ", "encoder_inputs_", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "encoder_inputs_", ",", "training", "=", "training", ",", "\n", "name", "=", "'conv_batch_norm_{}'", ".", "format", "(", "k", ")", ")", "\n", "", "if", "encoder", ".", "conv_activation", "is", "not", "None", "and", "encoder", ".", "conv_activation", ".", "lower", "(", ")", "==", "'relu'", ":", "\n", "                        ", "encoder_inputs_", "=", "tf", ".", "nn", ".", "relu", "(", "encoder_inputs_", ")", "\n", "\n", "", "encoder_input_length_", "=", "tf", ".", "to_int32", "(", "tf", ".", "ceil", "(", "encoder_input_length_", "/", "strides", "[", "1", "]", ")", ")", "\n", "\n", "", "feature_size", "=", "encoder_inputs_", ".", "shape", "[", "2", "]", ".", "value", "\n", "channels", "=", "encoder_inputs_", ".", "shape", "[", "3", "]", ".", "value", "\n", "time_steps", "=", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "1", "]", "\n", "\n", "encoder_inputs_", "=", "tf", ".", "reshape", "(", "encoder_inputs_", ",", "[", "batch_size", ",", "time_steps", ",", "feature_size", "*", "channels", "]", ")", "\n", "conv_outputs_", "=", "encoder_inputs_", "\n", "\n", "if", "encoder", ".", "conv_lstm_size", ":", "\n", "                    ", "cell", "=", "BasicConvLSTMCell", "(", "[", "feature_size", ",", "channels", "]", ",", "encoder", ".", "conv_lstm_size", ",", "1", ")", "\n", "encoder_inputs_", ",", "_", "=", "tf", ".", "nn", ".", "bidirectional_dynamic_rnn", "(", "\n", "cell", ",", "cell", ",", "encoder_inputs_", ",", "\n", "dtype", "=", "tf", ".", "float32", "\n", ")", "\n", "encoder_inputs_", "=", "tf", ".", "concat", "(", "encoder_inputs_", ",", "axis", "=", "2", ")", "\n", "\n", "", "", "if", "encoder", ".", "convolutions", ":", "\n", "                ", "if", "encoder", ".", "binary", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "pad", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeddings", ",", "utils", ".", "BOS_ID", ")", "\n", "pad", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "pad", ",", "axis", "=", "0", ")", ",", "axis", "=", "1", ")", "\n", "pad", "=", "tf", ".", "tile", "(", "pad", ",", "[", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "\n", "# Fully Character-Level NMT without Explicit Segmentation, Lee et al. 2016", "\n", "inputs", "=", "[", "]", "\n", "\n", "for", "w", ",", "filter_size", "in", "enumerate", "(", "encoder", ".", "convolutions", ",", "1", ")", ":", "\n", "                    ", "filter_", "=", "get_variable", "(", "'filter_{}'", ".", "format", "(", "w", ")", ",", "[", "w", ",", "encoder", ".", "embedding_size", ",", "filter_size", "]", ")", "\n", "\n", "if", "w", ">", "1", ":", "\n", "                        ", "right", "=", "(", "w", "-", "1", ")", "//", "2", "\n", "left", "=", "(", "w", "-", "1", ")", "-", "right", "\n", "pad_right", "=", "tf", ".", "tile", "(", "pad", ",", "[", "1", ",", "right", ",", "1", "]", ")", "\n", "pad_left", "=", "tf", ".", "tile", "(", "pad", ",", "[", "1", ",", "left", ",", "1", "]", ")", "\n", "inputs_", "=", "tf", ".", "concat", "(", "[", "pad_left", ",", "encoder_inputs_", ",", "pad_right", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                        ", "inputs_", "=", "encoder_inputs_", "\n", "\n", "", "inputs_", "=", "tf", ".", "nn", ".", "convolution", "(", "inputs_", ",", "filter", "=", "filter_", ",", "padding", "=", "'VALID'", ")", "\n", "inputs", ".", "append", "(", "inputs_", ")", "\n", "\n", "", "encoder_inputs_", "=", "tf", ".", "concat", "(", "inputs", ",", "axis", "=", "2", ")", "\n", "# if encoder.convolution_activation.lower() == 'relu':", "\n", "encoder_inputs_", "=", "tf", ".", "nn", ".", "relu", "(", "encoder_inputs_", ")", "\n", "\n", "", "if", "encoder", ".", "maxout_stride", ":", "\n", "                ", "if", "encoder", ".", "binary", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "stride", "=", "encoder", ".", "maxout_stride", "\n", "k", "=", "tf", ".", "to_int32", "(", "tf", ".", "ceil", "(", "time_steps", "/", "stride", ")", "*", "stride", ")", "-", "time_steps", "# TODO: simpler", "\n", "pad", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "k", ",", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "2", "]", "]", ")", "\n", "encoder_inputs_", "=", "tf", ".", "concat", "(", "[", "encoder_inputs_", ",", "pad", "]", ",", "axis", "=", "1", ")", "\n", "encoder_inputs_", "=", "tf", ".", "nn", ".", "pool", "(", "encoder_inputs_", ",", "window_shape", "=", "[", "stride", "]", ",", "pooling_type", "=", "'MAX'", ",", "\n", "padding", "=", "'VALID'", ",", "strides", "=", "[", "stride", "]", ")", "\n", "encoder_input_length_", "=", "tf", ".", "to_int32", "(", "tf", ".", "ceil", "(", "encoder_input_length_", "/", "stride", ")", ")", "\n", "\n", "", "if", "encoder", ".", "highway_layers", ":", "\n", "                ", "x", "=", "encoder_inputs_", "\n", "for", "j", "in", "range", "(", "encoder", ".", "highway_layers", ")", ":", "\n", "                    ", "size", "=", "x", ".", "shape", "[", "2", "]", ".", "value", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'highway_{}'", ".", "format", "(", "j", "+", "1", ")", ")", ":", "\n", "                        ", "g", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "size", ",", "activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "use_bias", "=", "True", ",", "name", "=", "'g'", ")", "\n", "y", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "size", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "use_bias", "=", "True", ",", "name", "=", "'y'", ")", "\n", "x", "=", "g", "*", "y", "+", "(", "1", "-", "g", ")", "*", "x", "\n", "\n", "", "", "encoder_inputs_", "=", "x", "\n", "\n", "# Contrary to Theano's RNN implementation, states after the sequence length are zero", "\n", "# (while Theano repeats last state)", "\n", "", "inter_layer_keep_prob", "=", "None", "if", "not", "encoder", ".", "use_dropout", "else", "encoder", ".", "inter_layer_keep_prob", "\n", "\n", "parameters", "=", "dict", "(", "\n", "inputs", "=", "encoder_inputs_", ",", "sequence_length", "=", "encoder_input_length_", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "parallel_iterations", "=", "encoder", ".", "parallel_iterations", ",", "\n", "inter_layers", "=", "encoder", ".", "inter_layers", ",", "inter_layer_activation", "=", "encoder", ".", "inter_layer_activation", ",", "\n", "batch_norm", "=", "encoder", ".", "batch_norm", ",", "inter_layer_keep_prob", "=", "inter_layer_keep_prob", ",", "\n", "pervasive_dropout", "=", "encoder", ".", "pervasive_dropout", ",", "training", "=", "training", "\n", ")", "\n", "\n", "input_size", "=", "encoder_inputs_", ".", "get_shape", "(", ")", "[", "2", "]", ".", "value", "\n", "\n", "def", "get_initial_state", "(", "name", "=", "'initial_state'", ")", ":", "\n", "                ", "if", "encoder", ".", "train_initial_states", ":", "\n", "                    ", "initial_state", "=", "get_variable", "(", "name", ",", "initializer", "=", "tf", ".", "zeros", "(", "cell_state_size", ")", ")", "\n", "return", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_state", ",", "axis", "=", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "return", "None", "\n", "\n", "", "", "if", "encoder", ".", "bidir", ":", "\n", "                ", "rnn", "=", "lambda", "reuse", ":", "stack_bidirectional_dynamic_rnn", "(", "\n", "cells_fw", "=", "[", "get_cell", "(", "input_size", "if", "j", "==", "0", "else", "2", "*", "cell_output_size", ",", "reuse", "=", "reuse", ")", "\n", "for", "j", "in", "range", "(", "encoder", ".", "layers", ")", "]", ",", "\n", "cells_bw", "=", "[", "get_cell", "(", "input_size", "if", "j", "==", "0", "else", "2", "*", "cell_output_size", ",", "reuse", "=", "reuse", ")", "\n", "for", "j", "in", "range", "(", "encoder", ".", "layers", ")", "]", ",", "\n", "initial_states_fw", "=", "[", "get_initial_state", "(", "'initial_state_fw'", ")", "]", "*", "encoder", ".", "layers", ",", "\n", "initial_states_bw", "=", "[", "get_initial_state", "(", "'initial_state_bw'", ")", "]", "*", "encoder", ".", "layers", ",", "\n", "time_pooling", "=", "encoder", ".", "time_pooling", ",", "pooling_avg", "=", "encoder", ".", "pooling_avg", ",", "\n", "**", "parameters", ")", "\n", "\n", "initializer", "=", "CellInitializer", "(", "encoder", ".", "cell_size", ")", "if", "encoder", ".", "orthogonal_init", "else", "None", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "initializer", "=", "initializer", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "encoder_outputs_", ",", "_", ",", "encoder_states_", "=", "rnn", "(", "reuse", "=", "False", ")", "\n", "", "except", "ValueError", ":", "# Multi-task scenario where we're reusing the same RNN parameters", "\n", "                        ", "encoder_outputs_", ",", "_", ",", "encoder_states_", "=", "rnn", "(", "reuse", "=", "True", ")", "\n", "", "", "", "else", ":", "\n", "                ", "if", "encoder", ".", "time_pooling", "or", "encoder", ".", "final_state", "==", "'concat_last'", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "if", "encoder", ".", "layers", ">", "1", ":", "\n", "                    ", "cell", "=", "MultiRNNCell", "(", "[", "get_cell", "(", "input_size", "if", "j", "==", "0", "else", "cell_output_size", ")", "\n", "for", "j", "in", "range", "(", "encoder", ".", "layers", ")", "]", ")", "\n", "initial_state", "=", "(", "get_initial_state", "(", ")", ",", ")", "*", "encoder", ".", "layers", "\n", "", "else", ":", "\n", "                    ", "cell", "=", "get_cell", "(", "input_size", ")", "\n", "initial_state", "=", "get_initial_state", "(", ")", "\n", "\n", "", "encoder_outputs_", ",", "encoder_states_", "=", "auto_reuse", "(", "tf", ".", "nn", ".", "dynamic_rnn", ")", "(", "cell", "=", "cell", ",", "\n", "initial_state", "=", "initial_state", ",", "\n", "**", "parameters", ")", "\n", "\n", "", "if", "encoder", ".", "time_pooling", ":", "\n", "                ", "for", "stride", "in", "encoder", ".", "time_pooling", "[", ":", "encoder", ".", "layers", "-", "1", "]", ":", "\n", "                    ", "encoder_input_length_", "=", "(", "encoder_input_length_", "+", "stride", "-", "1", ")", "//", "stride", "# rounding up", "\n", "\n", "", "", "last_backward", "=", "encoder_outputs_", "[", ":", ",", "0", ",", "cell_output_size", ":", "]", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "batch_size", ")", ",", "encoder_input_length_", "-", "1", "]", ",", "axis", "=", "1", ")", "\n", "last_forward", "=", "tf", ".", "gather_nd", "(", "encoder_outputs_", "[", ":", ",", ":", ",", ":", "cell_output_size", "]", ",", "indices", ")", "\n", "last_forward", ".", "set_shape", "(", "[", "None", ",", "cell_output_size", "]", ")", "\n", "\n", "if", "encoder", ".", "final_state", "==", "'concat_last'", ":", "# concats last states of all backward layers (full LSTM states)", "\n", "                ", "encoder_state_", "=", "tf", ".", "concat", "(", "encoder_states_", ",", "axis", "=", "1", ")", "\n", "", "elif", "encoder", ".", "final_state", "==", "'average'", ":", "\n", "                ", "mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length_", ",", "maxlen", "=", "tf", ".", "shape", "(", "encoder_outputs_", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "2", ")", "\n", "encoder_state_", "=", "tf", ".", "reduce_sum", "(", "mask", "*", "encoder_outputs_", ",", "axis", "=", "1", ")", "/", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ")", "\n", "", "elif", "encoder", ".", "final_state", "==", "'average_inputs'", ":", "\n", "                ", "mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length_", ",", "maxlen", "=", "tf", ".", "shape", "(", "encoder_inputs_", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "axis", "=", "2", ")", "\n", "encoder_state_", "=", "tf", ".", "reduce_sum", "(", "mask", "*", "encoder_inputs_", ",", "axis", "=", "1", ")", "/", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ")", "\n", "", "elif", "encoder", ".", "bidir", "and", "encoder", ".", "final_state", "==", "'last_both'", ":", "\n", "                ", "encoder_state_", "=", "tf", ".", "concat", "(", "[", "last_forward", ",", "last_backward", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "encoder", ".", "final_state", "==", "'none'", ":", "\n", "                ", "encoder_state_", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "0", "]", ")", "\n", "", "elif", "encoder", ".", "bidir", "and", "not", "encoder", ".", "final_state", "==", "'last_forward'", ":", "# last backward hidden state", "\n", "                ", "encoder_state_", "=", "last_backward", "\n", "", "else", ":", "# last forward hidden state", "\n", "                ", "encoder_state_", "=", "last_forward", "\n", "\n", "", "if", "encoder", ".", "bidir", "and", "encoder", ".", "bidir_projection", ":", "\n", "                ", "encoder_outputs_", "=", "dense", "(", "encoder_outputs_", ",", "cell_output_size", ",", "use_bias", "=", "False", ",", "name", "=", "'bidir_projection'", ")", "\n", "\n", "", "if", "encoder", ".", "attend_inputs", ":", "\n", "                ", "encoder_outputs", ".", "append", "(", "encoder_inputs_", ")", "\n", "", "elif", "encoder", ".", "attend_both", ":", "\n", "                ", "encoder_outputs", ".", "append", "(", "tf", ".", "concat", "(", "[", "encoder_inputs_", ",", "encoder_outputs_", "]", ",", "axis", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "                ", "encoder_outputs", ".", "append", "(", "encoder_outputs_", ")", "\n", "\n", "", "encoder_states", ".", "append", "(", "encoder_state_", ")", "\n", "new_encoder_input_length", ".", "append", "(", "encoder_input_length_", ")", "\n", "\n", "", "", "encoder_state", "=", "tf", ".", "concat", "(", "encoder_states", ",", "1", ")", "\n", "return", "encoder_outputs", ",", "encoder_state", ",", "new_encoder_input_length", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.compute_energy": [[370, 414], ["dense", "tensorflow.expand_dims", "dense", "get_variable", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "dense", "dense", "tensorflow.einsum", "tensorflow.contrib.layers.layer_norm", "tensorflow.contrib.layers.layer_norm", "tensorflow.tile", "tensorflow.tile", "tensorflow.tile", "tensorflow.to_float", "tensorflow.log", "dense", "get_variable", "tensorflow.reshape", "tensorflow.nn.conv2d", "tensorflow.squeeze", "dense", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.stack", "tensorflow.tanh", "tensorflow.range", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "compute_energy", "(", "hidden", ",", "state", ",", "encoder", ",", "time", "=", "None", ",", "input_length", "=", "None", ",", "prev_weights", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "hidden", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "hidden", ")", "[", "1", "]", "\n", "\n", "if", "encoder", ".", "attn_keep_prob", "is", "not", "None", ":", "\n", "        ", "state_noise_shape", "=", "[", "1", ",", "tf", ".", "shape", "(", "state", ")", "[", "1", "]", "]", "if", "encoder", ".", "pervasive_dropout", "else", "None", "\n", "state", "=", "tf", ".", "nn", ".", "dropout", "(", "state", ",", "keep_prob", "=", "encoder", ".", "attn_keep_prob", ",", "noise_shape", "=", "state_noise_shape", ")", "\n", "hidden_noise_shape", "=", "[", "1", ",", "1", ",", "tf", ".", "shape", "(", "hidden", ")", "[", "2", "]", "]", "if", "encoder", ".", "pervasive_dropout", "else", "None", "\n", "hidden", "=", "tf", ".", "nn", ".", "dropout", "(", "hidden", ",", "keep_prob", "=", "encoder", ".", "attn_keep_prob", ",", "noise_shape", "=", "hidden_noise_shape", ")", "\n", "\n", "", "if", "encoder", ".", "mult_attn", ":", "\n", "        ", "state", "=", "dense", "(", "state", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "False", ",", "name", "=", "'state'", ")", "\n", "hidden", "=", "dense", "(", "hidden", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "False", ",", "name", "=", "'hidden'", ")", "\n", "return", "tf", ".", "einsum", "(", "'ijk,ik->ij'", ",", "hidden", ",", "state", ")", "\n", "\n", "", "y", "=", "dense", "(", "state", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "not", "encoder", ".", "layer_norm", ",", "name", "=", "'W_a'", ")", "\n", "y", "=", "tf", ".", "expand_dims", "(", "y", ",", "axis", "=", "1", ")", "\n", "\n", "if", "encoder", ".", "layer_norm", ":", "\n", "        ", "y", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "y", ",", "scope", "=", "'layer_norm_state'", ")", "\n", "hidden", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "hidden", ",", "center", "=", "False", ",", "scope", "=", "'layer_norm_hidden'", ")", "\n", "\n", "", "y", "+=", "dense", "(", "hidden", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "False", ",", "name", "=", "'U_a'", ")", "\n", "\n", "if", "encoder", ".", "position_bias", "and", "input_length", "is", "not", "None", "and", "time", "is", "not", "None", ":", "\n", "        ", "src_pos", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "time_steps", ")", ",", "axis", "=", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "trg_pos", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "time", ",", "[", "1", ",", "1", "]", ")", ",", "[", "batch_size", ",", "time_steps", "]", ")", "\n", "src_len", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "input_length", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "time_steps", "]", ")", "# - 1", "\n", "pos_feats", "=", "tf", ".", "to_float", "(", "tf", ".", "stack", "(", "[", "src_pos", ",", "trg_pos", ",", "src_len", "]", ",", "axis", "=", "2", ")", ")", "\n", "pos_feats", "=", "tf", ".", "log", "(", "1", "+", "pos_feats", ")", "\n", "\n", "y", "+=", "dense", "(", "pos_feats", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "False", ",", "name", "=", "'P_a'", ")", "\n", "\n", "", "if", "encoder", ".", "attn_filters", ":", "\n", "        ", "filter_shape", "=", "[", "encoder", ".", "attn_filter_length", "*", "2", "+", "1", ",", "1", ",", "1", ",", "encoder", ".", "attn_filters", "]", "\n", "filter_", "=", "get_variable", "(", "'filter'", ",", "filter_shape", ")", "\n", "prev_weights", "=", "tf", ".", "reshape", "(", "prev_weights", ",", "tf", ".", "stack", "(", "[", "batch_size", ",", "time_steps", ",", "1", ",", "1", "]", ")", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "prev_weights", ",", "filter_", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "conv", "=", "tf", ".", "squeeze", "(", "conv", ",", "axis", "=", "2", ")", "\n", "\n", "y", "+=", "dense", "(", "conv", ",", "encoder", ".", "attn_size", ",", "use_bias", "=", "False", ",", "name", "=", "'C_a'", ")", "\n", "\n", "", "v", "=", "get_variable", "(", "'v_a'", ",", "[", "encoder", ".", "attn_size", "]", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "v", "*", "tf", ".", "tanh", "(", "y", ")", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.global_attention": [[416, 440], ["tensorflow.variable_scope", "models.compute_energy", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.nn.sigmoid", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.one_hot", "tensorflow.reduce_max", "tensorflow.argmax", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.models.compute_energy"], ["", "def", "global_attention", "(", "state", ",", "hidden_states", ",", "encoder", ",", "encoder_input_length", ",", "scope", "=", "None", ",", "context", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "'attention_{}'", ".", "format", "(", "encoder", ".", "name", ")", ")", ":", "\n", "        ", "if", "context", "is", "not", "None", "and", "encoder", ".", "use_context", ":", "\n", "            ", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "context", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "e", "=", "compute_energy", "(", "hidden_states", ",", "state", ",", "encoder", ",", "input_length", "=", "encoder_input_length", ",", "**", "kwargs", ")", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length", ",", "maxlen", "=", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "e", "*=", "mask", "\n", "\n", "if", "encoder", ".", "attn_norm_fun", "==", "'none'", ":", "\n", "            ", "weights", "=", "e", "\n", "", "elif", "encoder", ".", "attn_norm_fun", "==", "'sigmoid'", ":", "\n", "            ", "weights", "=", "tf", ".", "nn", ".", "sigmoid", "(", "e", ")", "\n", "", "elif", "encoder", ".", "attn_norm_fun", "==", "'max'", ":", "\n", "            ", "weights", "=", "tf", ".", "one_hot", "(", "tf", ".", "argmax", "(", "e", ",", "-", "1", ")", ",", "depth", "=", "tf", ".", "shape", "(", "e", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "e", "-=", "tf", ".", "reduce_max", "(", "e", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "T", "=", "encoder", ".", "attn_temperature", "or", "1.0", "\n", "exp", "=", "tf", ".", "exp", "(", "e", "/", "T", ")", "*", "mask", "\n", "weights", "=", "exp", "/", "tf", ".", "reduce_sum", "(", "exp", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "\n", "", "weighted_average", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "weights", ",", "2", ")", "*", "hidden_states", ",", "axis", "=", "1", ")", "\n", "\n", "return", "weighted_average", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.no_attention": [[442, 447], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.shape", "tensorflow.stack", "tensorflow.shape"], "function", ["None"], ["", "", "def", "no_attention", "(", "state", ",", "hidden_states", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "state", ")", "[", "0", "]", "\n", "weighted_average", "=", "tf", ".", "zeros", "(", "shape", "=", "tf", ".", "stack", "(", "[", "batch_size", ",", "0", "]", ")", ")", "\n", "weights", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", "]", ")", "\n", "return", "weighted_average", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.average_attention": [[449, 456], ["tensorflow.to_float", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.to_float", "tensorflow.expand_dims", "tensorflow.shape"], "function", ["None"], ["", "def", "average_attention", "(", "hidden_states", ",", "encoder_input_length", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# attention with fixed weights (average of all hidden states)", "\n", "    ", "lengths", "=", "tf", ".", "to_float", "(", "tf", ".", "expand_dims", "(", "encoder_input_length", ",", "axis", "=", "1", ")", ")", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length", ",", "maxlen", "=", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", ")", "\n", "weights", "=", "tf", ".", "to_float", "(", "mask", ")", "/", "lengths", "\n", "weighted_average", "=", "tf", ".", "reduce_sum", "(", "hidden_states", "*", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "2", ")", ",", "axis", "=", "1", ")", "\n", "return", "weighted_average", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.last_state_attention": [[458, 464], ["tensorflow.one_hot", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "last_state_attention", "(", "hidden_states", ",", "encoder_input_length", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "weights", "=", "tf", ".", "one_hot", "(", "encoder_input_length", "-", "1", ",", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", ")", "\n", "weights", "=", "tf", ".", "to_float", "(", "weights", ")", "\n", "\n", "weighted_average", "=", "tf", ".", "reduce_sum", "(", "hidden_states", "*", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "2", ")", ",", "axis", "=", "1", ")", "\n", "return", "weighted_average", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.local_attention": [[466, 538], ["tensorflow.shape", "tensorflow.shape", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.to_float", "tf.concat.get_shape", "tensorflow.expand_dims", "tensorflow.reshape", "tensorflow.minimum", "tensorflow.to_float", "range", "tensorflow.concat", "dense", "tensorflow.one_hot", "tensorflow.minimum", "tensorflow.maximum", "tensorflow.to_float", "tensorflow.reduce_sum", "tf.reduce_sum.append", "tensorflow.to_float", "tensorflow.reduce_sum", "get_variable", "get_variable", "tensorflow.nn.sigmoid", "tensorflow.reshape", "tensorflow.minimum", "tensorflow.tile", "tensorflow.reshape", "tensorflow.sequence_mask", "tensorflow.reduce_sum", "tensorflow.to_int32", "tensorflow.one_hot", "tensorflow.one_hot", "tensorflow.matmul", "tensorflow.to_float", "tensorflow.stack", "models.compute_energy", "tensorflow.reduce_max", "tensorflow.exp", "tensorflow.squeeze", "tensorflow.to_int32", "tensorflow.expand_dims", "tensorflow.to_int32", "tensorflow.expand_dims", "tensorflow.nn.tanh", "tensorflow.range", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.squeeze", "tensorflow.squeeze", "tensorflow.matmul", "tensorflow.shape", "tensorflow.pow"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.compute_energy"], ["", "def", "local_attention", "(", "state", ",", "hidden_states", ",", "encoder", ",", "encoder_input_length", ",", "pos", "=", "None", ",", "scope", "=", "None", ",", "context", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "state", ")", "[", "0", "]", "\n", "attn_length", "=", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", "\n", "\n", "if", "context", "is", "not", "None", "and", "encoder", ".", "use_context", ":", "\n", "        ", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "context", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "state_size", "=", "state", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "'attention_{}'", ".", "format", "(", "encoder", ".", "name", ")", ")", ":", "\n", "        ", "encoder_input_length", "=", "tf", ".", "to_float", "(", "tf", ".", "expand_dims", "(", "encoder_input_length", ",", "axis", "=", "1", ")", ")", "\n", "\n", "if", "pos", "is", "not", "None", ":", "\n", "            ", "pos", "=", "tf", ".", "reshape", "(", "pos", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "pos", "=", "tf", ".", "minimum", "(", "pos", ",", "encoder_input_length", "-", "1", ")", "\n", "\n", "", "if", "pos", "is", "not", "None", "and", "encoder", ".", "attn_window_size", ">", "0", ":", "\n", "# `pred_edits` scenario, where we know the aligned pos", "\n", "# when the windows size is non-zero, we concatenate consecutive encoder states", "\n", "# and map it to the right attention vector size.", "\n", "            ", "weights", "=", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "tf", ".", "to_int32", "(", "tf", ".", "squeeze", "(", "pos", ",", "axis", "=", "1", ")", ")", ",", "depth", "=", "attn_length", ")", ")", "\n", "\n", "weighted_average", "=", "[", "]", "\n", "for", "offset", "in", "range", "(", "-", "encoder", ".", "attn_window_size", ",", "encoder", ".", "attn_window_size", "+", "1", ")", ":", "\n", "                ", "pos_", "=", "pos", "+", "offset", "\n", "pos_", "=", "tf", ".", "minimum", "(", "pos_", ",", "encoder_input_length", "-", "1", ")", "\n", "pos_", "=", "tf", ".", "maximum", "(", "pos_", ",", "0", ")", "# TODO: when pos is < 0, use <S> or </S>", "\n", "weights_", "=", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "tf", ".", "to_int32", "(", "tf", ".", "squeeze", "(", "pos_", ",", "axis", "=", "1", ")", ")", ",", "depth", "=", "attn_length", ")", ")", "\n", "weighted_average_", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "weights_", ",", "axis", "=", "2", ")", "*", "hidden_states", ",", "axis", "=", "1", ")", "\n", "weighted_average", ".", "append", "(", "weighted_average_", ")", "\n", "\n", "", "weighted_average", "=", "tf", ".", "concat", "(", "weighted_average", ",", "axis", "=", "1", ")", "\n", "weighted_average", "=", "dense", "(", "weighted_average", ",", "encoder", ".", "attn_size", ")", "\n", "", "elif", "pos", "is", "not", "None", ":", "\n", "            ", "weights", "=", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "tf", ".", "to_int32", "(", "tf", ".", "squeeze", "(", "pos", ",", "axis", "=", "1", ")", ")", ",", "depth", "=", "attn_length", ")", ")", "\n", "weighted_average", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "2", ")", "*", "hidden_states", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "# Local attention of Luong et al. (http://arxiv.org/abs/1508.04025)", "\n", "            ", "wp", "=", "get_variable", "(", "'Wp'", ",", "[", "state_size", ",", "state_size", "]", ")", "\n", "vp", "=", "get_variable", "(", "'vp'", ",", "[", "state_size", ",", "1", "]", ")", "\n", "\n", "pos", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "matmul", "(", "state", ",", "wp", ")", ")", ",", "vp", ")", ")", "\n", "pos", "=", "encoder_input_length", "*", "pos", "\n", "pos", "=", "tf", ".", "reshape", "(", "pos", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "pos", "=", "tf", ".", "minimum", "(", "pos", ",", "encoder_input_length", "-", "1", ")", "\n", "\n", "idx", "=", "tf", ".", "tile", "(", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "attn_length", ")", ")", ",", "tf", ".", "stack", "(", "[", "batch_size", "]", ")", ")", "\n", "idx", "=", "tf", ".", "reshape", "(", "idx", ",", "[", "-", "1", ",", "attn_length", "]", ")", "\n", "\n", "low", "=", "pos", "-", "encoder", ".", "attn_window_size", "\n", "high", "=", "pos", "+", "encoder", ".", "attn_window_size", "\n", "\n", "mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length_", ",", "maxlen", "=", "tf", ".", "shape", "(", "hidden_states", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "if", "encoder", ".", "attn_window_size", ">", "0", ":", "\n", "                ", "e", "=", "compute_energy", "(", "hidden_states", ",", "state", ",", "encoder", ",", "input_length", "=", "encoder_input_length_", ",", "**", "kwargs", ")", "\n", "e", "-=", "tf", ".", "reduce_max", "(", "e", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "exp", "=", "tf", ".", "exp", "(", "e", ")", "*", "mask", "\n", "weights", "=", "exp", "/", "tf", ".", "reduce_sum", "(", "exp", ",", "axis", "=", "-", "1", ",", "keep_dims", "=", "True", ")", "\n", "weights_", "=", "weights", "\n", "\n", "sigma", "=", "encoder", ".", "attn_window_size", "/", "2.0", "\n", "div", "=", "-", "tf", ".", "pow", "(", "(", "idx", "-", "pos", ")", ",", "2.0", ")", "/", "(", "2", "*", "sigma", "**", "2", ")", "\n", "weights", "*=", "tf", ".", "exp", "(", "div", ")", "# result of the truncated normal distribution", "\n", "# normalize to keep a probability distribution", "\n", "# weights /= (tf.reduce_sum(weights, axis=1, keep_dims=True) + 10e-12)", "\n", "", "else", ":", "\n", "                ", "weights", "=", "mask", "# FIXME (mask is not differentiable)", "\n", "\n", "", "weighted_average", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "expand_dims", "(", "weights", ",", "axis", "=", "2", ")", "*", "hidden_states", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "weighted_average", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention": [[540, 570], ["attention_functions.get", "range", "tensorflow.concat", "attention_functions.get.", "context_vectors.append", "weights.append", "sum", "len", "tensorflow.variable_scope", "dense"], "function", ["None"], ["", "", "def", "attention", "(", "encoder", ",", "scope", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "attention_functions", "=", "{", "\n", "'global'", ":", "global_attention", ",", "\n", "'local'", ":", "local_attention", ",", "\n", "'none'", ":", "no_attention", ",", "\n", "'average'", ":", "average_attention", ",", "\n", "'last_state'", ":", "last_state_attention", "\n", "}", "\n", "attention_function", "=", "attention_functions", ".", "get", "(", "encoder", ".", "attention_type", ",", "global_attention", ")", "\n", "\n", "context_vectors", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "\n", "attn_heads", "=", "encoder", ".", "attn_heads", "or", "1", "\n", "scope", "=", "scope", "or", "'attention_{}'", ".", "format", "(", "encoder", ".", "name", ")", "\n", "for", "i", "in", "range", "(", "attn_heads", ")", ":", "\n", "        ", "scope_", "=", "scope", "if", "i", "==", "0", "else", "scope", "+", "'_{}'", ".", "format", "(", "i", "+", "1", ")", "\n", "\n", "context_vector", ",", "weights_", "=", "attention_function", "(", "encoder", "=", "encoder", ",", "scope", "=", "scope_", ",", "**", "kwargs", ")", "\n", "context_vectors", ".", "append", "(", "context_vector", ")", "\n", "weights", ".", "append", "(", "weights_", ")", "\n", "\n", "", "context_vector", "=", "tf", ".", "concat", "(", "context_vectors", ",", "axis", "=", "-", "1", ")", "\n", "weights", "=", "sum", "(", "weights", ")", "/", "len", "(", "weights", ")", "\n", "\n", "if", "encoder", ".", "attn_mapping", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "            ", "context_vector", "=", "dense", "(", "context_vector", ",", "encoder", ".", "attn_mapping", ",", "use_bias", "=", "False", ",", "name", "=", "'output'", ")", "\n", "\n", "", "", "return", "context_vector", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_attention": [[572, 597], ["enumerate", "zip", "translate.beam_search.resize_like", "translate.beam_search.resize_like", "models.attention", "attns.append", "weights.append", "tensorflow.reduce_sum", "tensorflow.concat", "tensorflow.stack"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.resize_like", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.resize_like", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention"], ["", "def", "multi_attention", "(", "state", ",", "hidden_states", ",", "encoders", ",", "encoder_input_length", ",", "pos", "=", "None", ",", "aggregation_method", "=", "'sum'", ",", "\n", "prev_weights", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "attns", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "\n", "context_vector", "=", "None", "\n", "for", "i", ",", "(", "hidden", ",", "encoder", ",", "input_length", ")", "in", "enumerate", "(", "zip", "(", "hidden_states", ",", "encoders", ",", "encoder_input_length", ")", ")", ":", "\n", "        ", "pos_", "=", "pos", "[", "i", "]", "if", "pos", "is", "not", "None", "else", "None", "\n", "prev_weights_", "=", "prev_weights", "[", "i", "]", "if", "prev_weights", "is", "not", "None", "else", "None", "\n", "\n", "hidden", "=", "beam_search", ".", "resize_like", "(", "hidden", ",", "state", ")", "\n", "input_length", "=", "beam_search", ".", "resize_like", "(", "input_length", ",", "state", ")", "\n", "\n", "context_vector", ",", "weights_", "=", "attention", "(", "state", "=", "state", ",", "hidden_states", "=", "hidden", ",", "encoder", "=", "encoder", ",", "\n", "encoder_input_length", "=", "input_length", ",", "pos", "=", "pos_", ",", "context", "=", "context_vector", ",", "\n", "prev_weights", "=", "prev_weights_", ",", "**", "kwargs", ")", "\n", "attns", ".", "append", "(", "context_vector", ")", "\n", "weights", ".", "append", "(", "weights_", ")", "\n", "\n", "", "if", "aggregation_method", "==", "'sum'", ":", "\n", "        ", "context_vector", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "stack", "(", "attns", ",", "axis", "=", "2", ")", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "context_vector", "=", "tf", ".", "concat", "(", "attns", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "context_vector", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder": [[599, 969], ["translate.rnn.get_state_size", "tensorflow.shape", "tensorflow.constant", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray().unstack", "tensorflow.TensorArray", "tensorflow.TensorArray", "tensorflow.TensorArray", "tf.TensorArray().unstack.read", "models.attention_decoder.embed"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.get_state_size"], ["", "def", "attention_decoder", "(", "decoder_inputs", ",", "initial_state", ",", "attention_states", ",", "encoders", ",", "decoder", ",", "encoder_input_length", ",", "\n", "feed_previous", "=", "0.0", ",", "align_encoder_id", "=", "0", ",", "feed_argmax", "=", "True", ",", "training", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    :param decoder_inputs: int32 tensor of shape (batch_size, output_length)\n    :param initial_state: initial state of the decoder (usually the final state of the encoder),\n      as a float32 tensor of shape (batch_size, initial_state_size). This state is mapped to the\n      correct state size for the decoder.\n    :param attention_states: list of tensors of shape (batch_size, input_length, encoder_cell_size),\n      the hidden states of the encoder(s) (one tensor for each encoder).\n    :param encoders: configuration of the encoders\n    :param decoder: configuration of the decoder\n    :param encoder_input_length: list of int32 tensors of shape (batch_size,), tells for each encoder,\n     the true length of each sequence in the batch (sequences in the same batch are padded to all have the same\n     length).\n    :param feed_previous: scalar tensor corresponding to the probability to use previous decoder output\n      instead of the ground truth as input for the decoder (1 when decoding, between 0 and 1 when training)\n    :param feed_argmax: boolean tensor, when True the greedy decoder outputs the word with the highest\n    probability (argmax). When False, it samples a word from the probability distribution (softmax).\n    :param align_encoder_id: outputs attention weights for this encoder. Also used when predicting edit operations\n    (pred_edits), to specifify which encoder reads the sequence to post-edit (MT).\n\n    :return:\n      outputs of the decoder as a tensor of shape (batch_size, output_length, decoder_cell_size)\n      attention weights as a tensor of shape (output_length, encoders, batch_size, input_length)\n    \"\"\"", "\n", "\n", "cell_output_size", ",", "cell_state_size", "=", "get_state_size", "(", "decoder", ".", "cell_type", ",", "decoder", ".", "cell_size", ",", "\n", "decoder", ".", "lstm_proj_size", ",", "decoder", ".", "layers", ")", "\n", "\n", "assert", "not", "decoder", ".", "pred_maxout_layer", "or", "cell_output_size", "%", "2", "==", "0", ",", "'cell size must be a multiple of 2'", "\n", "\n", "if", "decoder", ".", "use_lstm", "is", "False", ":", "\n", "        ", "decoder", ".", "cell_type", "=", "'GRU'", "\n", "\n", "", "embedding_shape", "=", "[", "decoder", ".", "vocab_size", ",", "decoder", ".", "embedding_size", "]", "\n", "weight_scale", "=", "decoder", ".", "embedding_weight_scale", "or", "decoder", ".", "weight_scale", "\n", "if", "weight_scale", "is", "None", ":", "\n", "        ", "initializer", "=", "None", "# FIXME", "\n", "", "elif", "decoder", ".", "embedding_initializer", "==", "'uniform'", "or", "(", "decoder", ".", "embedding_initializer", "is", "None", "\n", "and", "decoder", ".", "initializer", "==", "'uniform'", ")", ":", "\n", "        ", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "weight_scale", ",", "maxval", "=", "weight_scale", ")", "\n", "", "else", ":", "\n", "        ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "weight_scale", ")", "\n", "\n", "", "device", "=", "None", "if", "decoder", ".", "embeddings_on_gpu", "else", "'/cpu:0'", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "        ", "embedding", "=", "get_variable", "(", "'embedding_{}'", ".", "format", "(", "decoder", ".", "name", ")", ",", "shape", "=", "embedding_shape", ",", "initializer", "=", "initializer", ")", "\n", "\n", "", "input_shape", "=", "tf", ".", "shape", "(", "decoder_inputs", ")", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "\n", "time_steps", "=", "input_shape", "[", "1", "]", "\n", "\n", "scope_name", "=", "'decoder_{}'", ".", "format", "(", "decoder", ".", "name", ")", "\n", "scope_name", "+=", "'/'", "+", "'_'", ".", "join", "(", "encoder", ".", "name", "for", "encoder", "in", "encoders", ")", "\n", "\n", "def", "embed", "(", "input_", ")", ":", "\n", "        ", "embedded_input", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "input_", ")", "\n", "\n", "if", "decoder", ".", "use_dropout", "and", "decoder", ".", "word_keep_prob", "is", "not", "None", ":", "\n", "            ", "noise_shape", "=", "[", "1", ",", "1", "]", "if", "decoder", ".", "pervasive_dropout", "else", "[", "tf", ".", "shape", "(", "input_", ")", "[", "0", "]", ",", "1", "]", "\n", "embedded_input", "=", "tf", ".", "nn", ".", "dropout", "(", "embedded_input", ",", "keep_prob", "=", "decoder", ".", "word_keep_prob", ",", "noise_shape", "=", "noise_shape", ")", "\n", "", "if", "decoder", ".", "use_dropout", "and", "decoder", ".", "embedding_keep_prob", "is", "not", "None", ":", "\n", "            ", "size", "=", "tf", ".", "shape", "(", "embedded_input", ")", "[", "1", "]", "\n", "noise_shape", "=", "[", "1", ",", "size", "]", "if", "decoder", ".", "pervasive_dropout", "else", "[", "tf", ".", "shape", "(", "input_", ")", "[", "0", "]", ",", "size", "]", "\n", "embedded_input", "=", "tf", ".", "nn", ".", "dropout", "(", "embedded_input", ",", "keep_prob", "=", "decoder", ".", "embedding_keep_prob", ",", "\n", "noise_shape", "=", "noise_shape", ")", "\n", "\n", "", "return", "embedded_input", "\n", "\n", "", "def", "get_cell", "(", "input_size", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "cells", "=", "[", "]", "\n", "\n", "for", "j", "in", "range", "(", "decoder", ".", "layers", ")", ":", "\n", "            ", "input_size_", "=", "input_size", "if", "j", "==", "0", "else", "cell_output_size", "\n", "\n", "if", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "                ", "cell", "=", "CellWrapper", "(", "BasicLSTMCell", "(", "decoder", ".", "cell_size", ",", "reuse", "=", "reuse", ")", ")", "\n", "", "elif", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'plstm'", ":", "\n", "                ", "cell", "=", "PLSTM", "(", "decoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "fact_size", "=", "decoder", ".", "lstm_fact_size", ",", "\n", "proj_size", "=", "decoder", ".", "lstm_proj_size", ")", "\n", "", "elif", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'dropoutgru'", ":", "\n", "                ", "cell", "=", "DropoutGRUCell", "(", "decoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "layer_norm", "=", "decoder", ".", "layer_norm", ",", "\n", "input_size", "=", "input_size_", ",", "input_keep_prob", "=", "decoder", ".", "rnn_input_keep_prob", ",", "\n", "state_keep_prob", "=", "decoder", ".", "rnn_state_keep_prob", ")", "\n", "", "else", ":", "\n", "                ", "cell", "=", "GRUCell", "(", "decoder", ".", "cell_size", ",", "reuse", "=", "reuse", ",", "layer_norm", "=", "decoder", ".", "layer_norm", ")", "\n", "\n", "", "if", "decoder", ".", "use_dropout", "and", "decoder", ".", "cell_type", ".", "lower", "(", ")", "!=", "'dropoutgru'", ":", "\n", "                ", "cell", "=", "DropoutWrapper", "(", "cell", ",", "input_keep_prob", "=", "decoder", ".", "rnn_input_keep_prob", ",", "\n", "output_keep_prob", "=", "decoder", ".", "rnn_output_keep_prob", ",", "\n", "state_keep_prob", "=", "decoder", ".", "rnn_state_keep_prob", ",", "\n", "variational_recurrent", "=", "decoder", ".", "pervasive_dropout", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "input_size", "=", "input_size_", ")", "\n", "", "cells", ".", "append", "(", "cell", ")", "\n", "\n", "", "if", "len", "(", "cells", ")", "==", "1", ":", "\n", "            ", "return", "cells", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "CellWrapper", "(", "MultiRNNCell", "(", "cells", ")", ")", "\n", "\n", "", "", "def", "look", "(", "time", ",", "state", ",", "input_", ",", "prev_weights", "=", "None", ",", "pos", "=", "None", ",", "context", "=", "None", ")", ":", "\n", "        ", "prev_weights_", "=", "[", "prev_weights", "if", "i", "==", "align_encoder_id", "else", "None", "for", "i", "in", "range", "(", "len", "(", "encoders", ")", ")", "]", "\n", "pos_", "=", "None", "\n", "if", "decoder", ".", "pred_edits", ":", "\n", "            ", "pos_", "=", "[", "pos", "if", "i", "==", "align_encoder_id", "else", "None", "for", "i", "in", "range", "(", "len", "(", "encoders", ")", ")", "]", "\n", "", "if", "decoder", ".", "attn_prev_word", ":", "\n", "            ", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "input_", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "decoder", ".", "attn_prev_attn", "and", "context", "is", "not", "None", ":", "\n", "            ", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "context", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "decoder", ".", "hidden_state_scaling", ":", "\n", "            ", "attention_states_", "=", "[", "states", "*", "decoder", ".", "hidden_state_scaling", "for", "states", "in", "attention_states", "]", "\n", "", "else", ":", "\n", "            ", "attention_states_", "=", "attention_states", "\n", "\n", "", "parameters", "=", "dict", "(", "hidden_states", "=", "attention_states_", ",", "encoder_input_length", "=", "encoder_input_length", ",", "\n", "encoders", "=", "encoders", ",", "aggregation_method", "=", "decoder", ".", "aggregation_method", ")", "\n", "context", ",", "new_weights", "=", "multi_attention", "(", "state", ",", "time", "=", "time", ",", "pos", "=", "pos_", ",", "prev_weights", "=", "prev_weights_", ",", "**", "parameters", ")", "\n", "\n", "if", "decoder", ".", "context_mapping", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "scope_name", ")", ":", "\n", "                ", "activation", "=", "tf", ".", "nn", ".", "tanh", "if", "decoder", ".", "context_mapping_activation", "==", "'tanh'", "else", "None", "\n", "use_bias", "=", "not", "decoder", ".", "context_mapping_no_bias", "\n", "context", "=", "dense", "(", "context", ",", "decoder", ".", "context_mapping", ",", "use_bias", "=", "use_bias", ",", "activation", "=", "activation", ",", "\n", "name", "=", "'context_mapping'", ")", "\n", "\n", "", "", "return", "context", ",", "new_weights", "[", "align_encoder_id", "]", "\n", "\n", "", "def", "update", "(", "state", ",", "input_", ",", "context", "=", "None", ",", "symbol", "=", "None", ")", ":", "\n", "        ", "if", "context", "is", "not", "None", "and", "decoder", ".", "rnn_feed_attn", ":", "\n", "            ", "input_", "=", "tf", ".", "concat", "(", "[", "input_", ",", "context", "]", ",", "axis", "=", "1", ")", "\n", "", "input_size", "=", "input_", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "\n", "initializer", "=", "CellInitializer", "(", "decoder", ".", "cell_size", ")", "if", "decoder", ".", "orthogonal_init", "else", "None", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "initializer", "=", "initializer", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "output", ",", "new_state", "=", "get_cell", "(", "input_size", ")", "(", "input_", ",", "state", ")", "\n", "", "except", "ValueError", ":", "# auto_reuse doesn't work with LSTM cells", "\n", "                ", "output", ",", "new_state", "=", "get_cell", "(", "input_size", ",", "reuse", "=", "True", ")", "(", "input_", ",", "state", ")", "\n", "\n", "", "", "if", "decoder", ".", "skip_update", "and", "decoder", ".", "pred_edits", "and", "symbol", "is", "not", "None", ":", "\n", "            ", "is_del", "=", "tf", ".", "equal", "(", "symbol", ",", "utils", ".", "DEL_ID", ")", "\n", "new_state", "=", "tf", ".", "where", "(", "is_del", ",", "state", ",", "new_state", ")", "\n", "\n", "", "if", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'lstm'", "and", "decoder", ".", "use_lstm_full_state", ":", "\n", "            ", "output", "=", "new_state", "\n", "\n", "", "return", "output", ",", "new_state", "\n", "\n", "", "def", "update_pos", "(", "pos", ",", "symbol", ",", "max_pos", "=", "None", ")", ":", "\n", "        ", "if", "not", "decoder", ".", "pred_edits", ":", "\n", "            ", "return", "pos", "\n", "\n", "", "is_keep", "=", "tf", ".", "equal", "(", "symbol", ",", "utils", ".", "KEEP_ID", ")", "\n", "is_del", "=", "tf", ".", "equal", "(", "symbol", ",", "utils", ".", "DEL_ID", ")", "\n", "is_not_ins", "=", "tf", ".", "logical_or", "(", "is_keep", ",", "is_del", ")", "\n", "\n", "pos", "=", "beam_search", ".", "resize_like", "(", "pos", ",", "symbol", ")", "\n", "max_pos", "=", "beam_search", ".", "resize_like", "(", "max_pos", ",", "symbol", ")", "\n", "\n", "pos", "+=", "tf", ".", "to_float", "(", "is_not_ins", ")", "\n", "if", "max_pos", "is", "not", "None", ":", "\n", "            ", "pos", "=", "tf", ".", "minimum", "(", "pos", ",", "tf", ".", "to_float", "(", "max_pos", ")", ")", "\n", "", "return", "pos", "\n", "\n", "", "def", "generate", "(", "state", ",", "input_", ",", "context", ")", ":", "\n", "        ", "if", "decoder", ".", "pred_use_lstm_state", "is", "False", ":", "# for back-compatibility", "\n", "             ", "state", "=", "state", "[", ":", ",", "-", "cell_output_size", ":", "]", "\n", "\n", "", "projection_input", "=", "[", "state", ",", "context", "]", "\n", "if", "decoder", ".", "use_previous_word", ":", "\n", "            ", "projection_input", ".", "insert", "(", "1", ",", "input_", ")", "# for back-compatibility", "\n", "\n", "", "output_", "=", "tf", ".", "concat", "(", "projection_input", ",", "axis", "=", "1", ")", "\n", "\n", "if", "decoder", ".", "pred_deep_layer", ":", "\n", "            ", "deep_layer_size", "=", "decoder", ".", "pred_deep_layer_size", "or", "decoder", ".", "embedding_size", "\n", "if", "decoder", ".", "layer_norm", ":", "\n", "                ", "output_", "=", "dense", "(", "output_", ",", "deep_layer_size", ",", "use_bias", "=", "False", ",", "name", "=", "'deep_output'", ")", "\n", "output_", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "output_", ",", "activation_fn", "=", "tf", ".", "nn", ".", "tanh", ",", "scope", "=", "'output_layer_norm'", ")", "\n", "", "else", ":", "\n", "                ", "output_", "=", "dense", "(", "output_", ",", "deep_layer_size", ",", "activation", "=", "tf", ".", "tanh", ",", "use_bias", "=", "True", ",", "name", "=", "'deep_output'", ")", "\n", "\n", "", "if", "decoder", ".", "use_dropout", ":", "\n", "                ", "size", "=", "tf", ".", "shape", "(", "output_", ")", "[", "1", "]", "\n", "noise_shape", "=", "[", "1", ",", "size", "]", "if", "decoder", ".", "pervasive_dropout", "else", "None", "\n", "output_", "=", "tf", ".", "nn", ".", "dropout", "(", "output_", ",", "keep_prob", "=", "decoder", ".", "deep_layer_keep_prob", ",", "noise_shape", "=", "noise_shape", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "decoder", ".", "pred_maxout_layer", ":", "\n", "                ", "maxout_size", "=", "decoder", ".", "maxout_size", "or", "cell_output_size", "\n", "output_", "=", "dense", "(", "output_", ",", "maxout_size", ",", "use_bias", "=", "True", ",", "name", "=", "'maxout'", ")", "\n", "if", "decoder", ".", "old_maxout", ":", "# for back-compatibility with old models", "\n", "                    ", "output_", "=", "tf", ".", "nn", ".", "pool", "(", "tf", ".", "expand_dims", "(", "output_", ",", "axis", "=", "2", ")", ",", "window_shape", "=", "[", "2", "]", ",", "pooling_type", "=", "'MAX'", ",", "\n", "padding", "=", "'SAME'", ",", "strides", "=", "[", "2", "]", ")", "\n", "output_", "=", "tf", ".", "squeeze", "(", "output_", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "                    ", "output_", "=", "tf", ".", "maximum", "(", "*", "tf", ".", "split", "(", "output_", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "", "if", "decoder", ".", "pred_embed_proj", ":", "\n", "# intermediate projection to embedding size (before projecting to vocabulary size)", "\n", "# this is useful to reduce the number of parameters, and", "\n", "# to use the output embeddings for output projection (tie_embeddings parameter)", "\n", "                ", "output_", "=", "dense", "(", "output_", ",", "decoder", ".", "embedding_size", ",", "use_bias", "=", "False", ",", "name", "=", "'softmax0'", ")", "\n", "\n", "", "", "if", "decoder", ".", "tie_embeddings", "and", "(", "decoder", ".", "pred_embed_proj", "or", "decoder", ".", "pred_deep_layer", ")", ":", "\n", "            ", "bias", "=", "get_variable", "(", "'softmax1/bias'", ",", "shape", "=", "[", "decoder", ".", "vocab_size", "]", ")", "\n", "output_", "=", "tf", ".", "matmul", "(", "output_", ",", "tf", ".", "transpose", "(", "embedding", ")", ")", "+", "bias", "\n", "", "else", ":", "\n", "            ", "output_", "=", "dense", "(", "output_", ",", "decoder", ".", "vocab_size", ",", "use_bias", "=", "True", ",", "name", "=", "'softmax1'", ")", "\n", "", "return", "output_", "\n", "\n", "", "if", "decoder", ".", "use_dropout", ":", "# FIXME: why no pervasive dropout here?", "\n", "        ", "initial_state", "=", "tf", ".", "nn", ".", "dropout", "(", "initial_state", ",", "keep_prob", "=", "decoder", ".", "initial_state_keep_prob", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope_name", ")", ":", "\n", "        ", "activation_fn", "=", "None", "if", "decoder", ".", "initial_state", "==", "'linear'", "else", "tf", ".", "nn", ".", "tanh", "\n", "if", "decoder", ".", "initial_state", "==", "'trained'", ":", "\n", "            ", "initial_state", "=", "get_variable", "(", "shape", "=", "[", "cell_state_size", "]", ",", "name", "=", "'initial_state'", ")", "\n", "initial_state", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "initial_state", ",", "axis", "=", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "", "elif", "decoder", ".", "initial_state", "==", "'zero'", ":", "\n", "            ", "initial_state", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "batch_size", ",", "cell_state_size", "]", ")", "\n", "", "elif", "decoder", ".", "layer_norm", ":", "\n", "            ", "initial_state", "=", "dense", "(", "initial_state", ",", "cell_state_size", ",", "use_bias", "=", "False", ",", "name", "=", "'initial_state_projection'", ")", "\n", "initial_state", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "initial_state", ",", "activation_fn", "=", "activation_fn", ",", "\n", "scope", "=", "'initial_state_layer_norm'", ")", "\n", "", "else", ":", "\n", "            ", "initial_state", "=", "dense", "(", "initial_state", ",", "cell_state_size", ",", "use_bias", "=", "True", ",", "name", "=", "'initial_state_projection'", ",", "\n", "activation", "=", "activation_fn", ")", "\n", "\n", "", "", "if", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'lstm'", "and", "decoder", ".", "use_lstm_full_state", ":", "\n", "        ", "initial_output", "=", "initial_state", "\n", "", "else", ":", "\n", "# Last layer's state is the right-most part. Output is the left-most part of an LSTM's state.", "\n", "        ", "initial_output", "=", "initial_state", "[", ":", ",", "-", "cell_output_size", ":", "]", "\n", "\n", "", "time", "=", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "tf", ".", "int32", ",", "name", "=", "'time'", ")", "\n", "outputs", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "time_steps", ")", "\n", "samples", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "int64", ",", "size", "=", "time_steps", ")", "\n", "inputs", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "int64", ",", "size", "=", "time_steps", ")", ".", "unstack", "(", "tf", ".", "to_int64", "(", "tf", ".", "transpose", "(", "decoder_inputs", ")", ")", ")", "\n", "\n", "states", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "time_steps", ")", "\n", "weights", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "time_steps", ")", "\n", "attns", "=", "tf", ".", "TensorArray", "(", "dtype", "=", "tf", ".", "float32", ",", "size", "=", "time_steps", ")", "\n", "\n", "initial_symbol", "=", "inputs", ".", "read", "(", "0", ")", "# first symbol is BOS", "\n", "initial_input", "=", "embed", "(", "initial_symbol", ")", "\n", "initial_pos", "=", "tf", ".", "zeros", "(", "[", "batch_size", "]", ",", "tf", ".", "float32", ")", "\n", "initial_weights", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "attention_states", "[", "align_encoder_id", "]", ")", "[", ":", "2", "]", ")", "\n", "zero_context", "=", "tf", ".", "zeros", "(", "shape", "=", "tf", ".", "shape", "(", "attention_states", "[", "align_encoder_id", "]", "[", ":", ",", "0", "]", ")", ")", "# FIXME", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'decoder_{}'", ".", "format", "(", "decoder", ".", "name", ")", ")", ":", "\n", "        ", "initial_context", ",", "_", "=", "look", "(", "0", ",", "initial_output", ",", "initial_input", ",", "pos", "=", "initial_pos", ",", "prev_weights", "=", "initial_weights", ",", "\n", "context", "=", "zero_context", ")", "\n", "", "initial_data", "=", "tf", ".", "concat", "(", "[", "initial_state", ",", "initial_context", ",", "tf", ".", "expand_dims", "(", "initial_pos", ",", "axis", "=", "1", ")", ",", "initial_weights", "]", ",", "\n", "axis", "=", "1", ")", "\n", "context_size", "=", "initial_context", ".", "shape", "[", "1", "]", ".", "value", "\n", "\n", "def", "get_logits", "(", "state", ",", "ids", ",", "time", ")", ":", "# for beam-search decoding", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'decoder_{}'", ".", "format", "(", "decoder", ".", "name", ")", ")", ":", "\n", "            ", "state", ",", "context", ",", "pos", ",", "prev_weights", "=", "tf", ".", "split", "(", "state", ",", "[", "cell_state_size", ",", "context_size", ",", "1", ",", "-", "1", "]", ",", "axis", "=", "1", ")", "\n", "input_", "=", "embed", "(", "ids", ")", "\n", "\n", "pos", "=", "tf", ".", "squeeze", "(", "pos", ",", "axis", "=", "1", ")", "\n", "pos", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "time", ",", "0", ")", ",", "\n", "lambda", ":", "pos", ",", "\n", "lambda", ":", "update_pos", "(", "pos", ",", "ids", ",", "encoder_input_length", "[", "align_encoder_id", "]", ")", ")", "\n", "\n", "if", "decoder", ".", "cell_type", ".", "lower", "(", ")", "==", "'lstm'", "and", "decoder", ".", "use_lstm_full_state", ":", "\n", "                ", "output", "=", "state", "\n", "", "else", ":", "\n", "# Output is always the right-most part of the state (even with multi-layer RNNs)", "\n", "# However, this only works at test time, because different dropout operations can be used", "\n", "# on state and output.", "\n", "                ", "output", "=", "state", "[", ":", ",", "-", "cell_output_size", ":", "]", "\n", "\n", "", "if", "decoder", ".", "conditional_rnn", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'conditional_1'", ")", ":", "\n", "                    ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ")", "\n", "", "", "elif", "decoder", ".", "update_first", ":", "\n", "                ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ",", "None", ",", "ids", ")", "\n", "", "elif", "decoder", ".", "generate_first", ":", "\n", "                ", "output", ",", "state", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "time", ",", "0", ")", ",", "\n", "lambda", ":", "(", "output", ",", "state", ")", ",", "\n", "lambda", ":", "update", "(", "state", ",", "input_", ",", "context", ",", "ids", ")", ")", "\n", "\n", "", "context", ",", "new_weights", "=", "look", "(", "time", ",", "output", ",", "input_", ",", "pos", "=", "pos", ",", "prev_weights", "=", "prev_weights", ",", "context", "=", "context", ")", "\n", "\n", "if", "decoder", ".", "conditional_rnn", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'conditional_2'", ")", ":", "\n", "                    ", "output", ",", "state", "=", "update", "(", "state", ",", "context", ")", "\n", "", "", "elif", "not", "decoder", ".", "generate_first", ":", "\n", "                ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ",", "context", ",", "ids", ")", "\n", "\n", "", "logits", "=", "generate", "(", "output", ",", "input_", ",", "context", ")", "\n", "\n", "pos", "=", "tf", ".", "expand_dims", "(", "pos", ",", "axis", "=", "1", ")", "\n", "state", "=", "tf", ".", "concat", "(", "[", "state", ",", "context", ",", "pos", ",", "new_weights", "]", ",", "axis", "=", "1", ")", "\n", "return", "state", ",", "logits", "\n", "\n", "", "", "def", "_time_step", "(", "time", ",", "input_", ",", "input_symbol", ",", "pos", ",", "state", ",", "output", ",", "outputs", ",", "states", ",", "weights", ",", "attns", ",", "prev_weights", ",", "\n", "samples", ",", "context", ")", ":", "\n", "        ", "if", "decoder", ".", "conditional_rnn", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'conditional_1'", ")", ":", "\n", "                ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ")", "\n", "", "", "elif", "decoder", ".", "update_first", ":", "\n", "            ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ",", "None", ",", "input_symbol", ")", "\n", "\n", "", "context", ",", "new_weights", "=", "look", "(", "time", ",", "output", ",", "input_", ",", "pos", "=", "pos", ",", "prev_weights", "=", "prev_weights", ",", "context", "=", "context", ")", "\n", "\n", "if", "decoder", ".", "conditional_rnn", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'conditional_2'", ")", ":", "\n", "                ", "output", ",", "state", "=", "update", "(", "state", ",", "context", ")", "\n", "", "", "elif", "not", "decoder", ".", "generate_first", ":", "\n", "            ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ",", "context", ",", "input_symbol", ")", "\n", "\n", "", "output_", "=", "generate", "(", "output", ",", "input_", ",", "context", ")", "\n", "\n", "argmax", "=", "lambda", ":", "tf", ".", "argmax", "(", "output_", ",", "1", ")", "\n", "target", "=", "lambda", ":", "inputs", ".", "read", "(", "time", "+", "1", ")", "\n", "softmax", "=", "lambda", ":", "tf", ".", "squeeze", "(", "tf", ".", "multinomial", "(", "tf", ".", "log", "(", "tf", ".", "nn", ".", "softmax", "(", "output_", ")", ")", ",", "num_samples", "=", "1", ")", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "use_target", "=", "tf", ".", "logical_and", "(", "time", "<", "time_steps", "-", "1", ",", "tf", ".", "random_uniform", "(", "[", "]", ")", ">=", "feed_previous", ")", "\n", "predicted_symbol", "=", "tf", ".", "case", "(", "[", "\n", "(", "use_target", ",", "target", ")", ",", "\n", "(", "tf", ".", "logical_not", "(", "feed_argmax", ")", ",", "softmax", ")", "]", ",", "\n", "default", "=", "argmax", ")", "# default case is useful for beam-search", "\n", "\n", "predicted_symbol", ".", "set_shape", "(", "[", "None", "]", ")", "\n", "predicted_symbol", "=", "tf", ".", "stop_gradient", "(", "predicted_symbol", ")", "\n", "\n", "input_", "=", "embed", "(", "predicted_symbol", ")", "\n", "pos", "=", "update_pos", "(", "pos", ",", "predicted_symbol", ",", "encoder_input_length", "[", "align_encoder_id", "]", ")", "\n", "\n", "samples", "=", "samples", ".", "write", "(", "time", ",", "predicted_symbol", ")", "\n", "attns", "=", "attns", ".", "write", "(", "time", ",", "context", ")", "\n", "weights", "=", "weights", ".", "write", "(", "time", ",", "new_weights", ")", "\n", "states", "=", "states", ".", "write", "(", "time", ",", "state", ")", "\n", "outputs", "=", "outputs", ".", "write", "(", "time", ",", "output_", ")", "\n", "\n", "if", "not", "decoder", ".", "conditional_rnn", "and", "not", "decoder", ".", "update_first", "and", "decoder", ".", "generate_first", ":", "\n", "            ", "output", ",", "state", "=", "update", "(", "state", ",", "input_", ",", "context", ",", "predicted_symbol", ")", "\n", "\n", "", "return", "(", "time", "+", "1", ",", "input_", ",", "predicted_symbol", ",", "pos", ",", "state", ",", "output", ",", "outputs", ",", "states", ",", "weights", ",", "attns", ",", "new_weights", ",", "\n", "samples", ",", "context", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'decoder_{}'", ".", "format", "(", "decoder", ".", "name", ")", ")", ":", "\n", "        ", "_", ",", "_", ",", "_", ",", "new_pos", ",", "new_state", ",", "_", ",", "outputs", ",", "states", ",", "weights", ",", "attns", ",", "new_weights", ",", "samples", ",", "_", "=", "tf", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "time", ",", "*", "_", ":", "time", "<", "time_steps", ",", "\n", "body", "=", "_time_step", ",", "\n", "loop_vars", "=", "(", "time", ",", "initial_input", ",", "initial_symbol", ",", "initial_pos", ",", "initial_state", ",", "initial_output", ",", "outputs", ",", "\n", "weights", ",", "states", ",", "attns", ",", "initial_weights", ",", "samples", ",", "initial_context", ")", ",", "\n", "parallel_iterations", "=", "decoder", ".", "parallel_iterations", ",", "\n", "swap_memory", "=", "decoder", ".", "swap_memory", ")", "\n", "\n", "", "outputs", "=", "outputs", ".", "stack", "(", ")", "\n", "weights", "=", "weights", ".", "stack", "(", ")", "# batch_size, encoders, output time, input time", "\n", "states", "=", "states", ".", "stack", "(", ")", "\n", "attns", "=", "attns", ".", "stack", "(", ")", "\n", "samples", "=", "samples", ".", "stack", "(", ")", "\n", "\n", "# put batch_size as first dimension", "\n", "outputs", "=", "tf", ".", "transpose", "(", "outputs", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "weights", "=", "tf", ".", "transpose", "(", "weights", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "states", "=", "tf", ".", "transpose", "(", "states", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "attns", "=", "tf", ".", "transpose", "(", "attns", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "samples", "=", "tf", ".", "transpose", "(", "samples", ")", "\n", "\n", "return", "outputs", ",", "weights", ",", "states", ",", "attns", ",", "samples", ",", "get_logits", ",", "initial_data", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.encoder_decoder": [[971, 1045], ["dict", "models.multi_encoder", "models.attention_decoder", "translate.beam_search.get_weights", "models.sequence_loss", "translate.beam_search.get_weights", "models.sequence_loss", "models.reinforce_baseline", "translate.beam_search.get_weights", "models.baseline_loss", "tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.to_int32", "tensorflow.to_float", "tensorflow.matmul", "tensorflow.sqrt", "tensorflow.to_float", "translate.beam_search.get_weights", "encoder_input_length.append", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.stop_gradient", "tensorflow.to_int32", "tensorflow.range", "tensorflow.range", "tensorflow.reduce_sum", "tensorflow.stop_gradient", "tensorflow.to_float"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.reinforce_baseline", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.baseline_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights"], ["", "def", "encoder_decoder", "(", "encoders", ",", "decoders", ",", "encoder_inputs", ",", "targets", ",", "feed_previous", ",", "align_encoder_id", "=", "0", ",", "\n", "encoder_input_length", "=", "None", ",", "feed_argmax", "=", "True", ",", "rewards", "=", "None", ",", "use_baseline", "=", "True", ",", "\n", "training", "=", "True", ",", "global_step", "=", "None", ",", "\n", "monotonicity_weight", "=", "None", ",", "monotonicity_dist", "=", "None", ",", "monotonicity_decay", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "decoder", "=", "decoders", "[", "0", "]", "\n", "targets", "=", "targets", "[", "0", "]", "# single decoder", "\n", "\n", "if", "encoder_input_length", "is", "None", ":", "\n", "        ", "encoder_input_length", "=", "[", "]", "\n", "for", "encoder_inputs_", "in", "encoder_inputs", ":", "\n", "            ", "mask", "=", "get_weights", "(", "encoder_inputs_", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "encoder_input_length", ".", "append", "(", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n", "", "", "parameters", "=", "dict", "(", "encoders", "=", "encoders", ",", "decoder", "=", "decoder", ",", "encoder_inputs", "=", "encoder_inputs", ",", "\n", "feed_argmax", "=", "feed_argmax", ",", "training", "=", "training", ")", "\n", "\n", "attention_states", ",", "encoder_state", ",", "encoder_input_length", "=", "multi_encoder", "(", "\n", "encoder_input_length", "=", "encoder_input_length", ",", "**", "parameters", ")", "\n", "\n", "outputs", ",", "attention_weights", ",", "_", ",", "_", ",", "samples", ",", "beam_fun", ",", "initial_data", "=", "attention_decoder", "(", "\n", "attention_states", "=", "attention_states", ",", "initial_state", "=", "encoder_state", ",", "feed_previous", "=", "feed_previous", ",", "\n", "decoder_inputs", "=", "targets", "[", ":", ",", ":", "-", "1", "]", ",", "align_encoder_id", "=", "align_encoder_id", ",", "encoder_input_length", "=", "encoder_input_length", ",", "\n", "**", "parameters", "\n", ")", "\n", "\n", "if", "use_baseline", ":", "\n", "        ", "baseline_rewards", "=", "reinforce_baseline", "(", "outputs", ",", "rewards", ")", "# FIXME: use logits or decoder outputs?", "\n", "baseline_weights", "=", "get_weights", "(", "samples", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "False", ")", "\n", "baseline_loss_", "=", "baseline_loss", "(", "rewards", "=", "baseline_rewards", ",", "weights", "=", "baseline_weights", ")", "\n", "", "else", ":", "\n", "        ", "baseline_rewards", "=", "rewards", "\n", "baseline_loss_", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reinforce_weights", "=", "get_weights", "(", "samples", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "reinforce_loss", "=", "sequence_loss", "(", "logits", "=", "outputs", ",", "targets", "=", "samples", ",", "weights", "=", "reinforce_weights", ",", "\n", "rewards", "=", "baseline_rewards", ")", "\n", "\n", "trg_mask", "=", "get_weights", "(", "targets", "[", ":", ",", "1", ":", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "xent_loss", "=", "sequence_loss", "(", "logits", "=", "outputs", ",", "targets", "=", "targets", "[", ":", ",", "1", ":", "]", ",", "weights", "=", "trg_mask", ")", "\n", "\n", "if", "monotonicity_weight", ":", "\n", "        ", "monotonicity_dist", "=", "monotonicity_dist", "or", "1.0", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "attention_weights", ")", "[", "0", "]", "\n", "src_len", "=", "tf", ".", "shape", "(", "attention_weights", ")", "[", "2", "]", "\n", "trg_len", "=", "tf", ".", "shape", "(", "attention_weights", ")", "[", "1", "]", "\n", "\n", "src_indices", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "src_len", ")", ",", "shape", "=", "[", "1", ",", "1", ",", "src_len", "]", ")", ",", "[", "batch_size", ",", "trg_len", ",", "1", "]", ")", "\n", "trg_indices", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "trg_len", ")", ",", "shape", "=", "[", "1", ",", "trg_len", ",", "1", "]", ")", ",", "[", "batch_size", ",", "1", ",", "src_len", "]", ")", "\n", "\n", "source_length", "=", "encoder_input_length", "[", "0", "]", "\n", "target_length", "=", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "trg_mask", ",", "axis", "=", "1", ")", ")", "\n", "true_src_len", "=", "tf", ".", "reshape", "(", "source_length", ",", "shape", "=", "[", "batch_size", ",", "1", ",", "1", "]", ")", "-", "1", "\n", "true_trg_len", "=", "tf", ".", "reshape", "(", "target_length", ",", "shape", "=", "[", "batch_size", ",", "1", ",", "1", "]", ")", "-", "1", "\n", "\n", "src_mask", "=", "tf", ".", "to_float", "(", "tf", ".", "sequence_mask", "(", "source_length", ",", "maxlen", "=", "src_len", ")", ")", "\n", "mask", "=", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "trg_mask", ",", "axis", "=", "2", ")", ",", "tf", ".", "expand_dims", "(", "src_mask", ",", "axis", "=", "1", ")", ")", "\n", "\n", "monotonous", "=", "tf", ".", "sqrt", "(", "(", "(", "true_trg_len", "*", "src_indices", "-", "true_src_len", "*", "trg_indices", ")", "**", "2", ")", "\n", "/", "(", "true_trg_len", "**", "2", "+", "true_src_len", "**", "2", ")", ")", "\n", "monotonous", "=", "tf", ".", "to_float", "(", "monotonous", "<", "monotonicity_dist", ")", "\n", "non_monotonous", "=", "(", "1", "-", "monotonous", ")", "*", "mask", "\n", "attn_loss", "=", "tf", ".", "reduce_sum", "(", "attention_weights", "*", "tf", ".", "stop_gradient", "(", "non_monotonous", ")", ")", "/", "tf", ".", "to_float", "(", "batch_size", ")", "\n", "\n", "if", "monotonicity_decay", ":", "\n", "            ", "decay", "=", "tf", ".", "stop_gradient", "(", "0.5", "**", "(", "tf", ".", "to_float", "(", "global_step", ")", "/", "monotonicity_decay", ")", ")", "\n", "", "else", ":", "\n", "            ", "decay", "=", "1.0", "\n", "\n", "", "xent_loss", "+=", "monotonicity_weight", "*", "decay", "*", "attn_loss", "\n", "\n", "", "losses", "=", "[", "xent_loss", ",", "reinforce_loss", ",", "baseline_loss_", "]", "\n", "\n", "return", "losses", ",", "[", "outputs", "]", ",", "attention_weights", ",", "samples", ",", "beam_fun", ",", "initial_data", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.reconstruction_encoder_decoder": [[1047, 1096], ["models.multi_encoder", "models.attention_decoder", "translate.beam_search.get_weights", "models.sequence_loss", "models.attention_decoder", "translate.beam_search.get_weights", "tensorflow.sequence_mask", "tensorflow.einsum", "tensorflow.to_float", "translate.beam_search.get_weights", "tensorflow.to_int32", "models.sequence_loss", "tensorflow.shape", "tensorflow.shape", "tensorflow.matmul", "tensorflow.eye", "tensorflow.norm", "tensorflow.to_float", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss"], ["", "def", "reconstruction_encoder_decoder", "(", "encoders", ",", "decoders", ",", "encoder_inputs", ",", "targets", ",", "feed_previous", ",", "\n", "encoder_input_length", "=", "None", ",", "training", "=", "True", ",", "reconstruction_weight", "=", "1.0", ",", "\n", "reconstruction_attn_weight", "=", "0.05", ",", "**", "kwargs", ")", ":", "\n", "    ", "encoders", "=", "encoders", "[", ":", "1", "]", "\n", "\n", "if", "encoder_input_length", "is", "None", ":", "\n", "        ", "weights", "=", "get_weights", "(", "encoder_inputs", "[", "0", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "encoder_input_length", "=", "[", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "weights", ",", "axis", "=", "1", ")", ")", "]", "\n", "\n", "", "attention_states", ",", "encoder_state", ",", "encoder_input_length", "=", "multi_encoder", "(", "\n", "encoder_input_length", "=", "encoder_input_length", ",", "encoders", "=", "encoders", ",", "encoder_inputs", "=", "encoder_inputs", ",", "\n", "training", "=", "training", ")", "\n", "\n", "outputs", ",", "attention_weights", ",", "states", ",", "_", ",", "samples", ",", "beam_fun", ",", "initial_data", "=", "attention_decoder", "(", "\n", "attention_states", "=", "attention_states", ",", "initial_state", "=", "encoder_state", ",", "feed_previous", "=", "feed_previous", ",", "\n", "decoder_inputs", "=", "targets", "[", "0", "]", "[", ":", ",", ":", "-", "1", "]", ",", "encoder_input_length", "=", "encoder_input_length", ",", "\n", "decoder", "=", "decoders", "[", "0", "]", ",", "training", "=", "training", ",", "encoders", "=", "encoders", "\n", ")", "\n", "\n", "target_weights", "=", "get_weights", "(", "targets", "[", "0", "]", "[", ":", ",", "1", ":", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "target_length", "=", "[", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "target_weights", ",", "axis", "=", "1", ")", ")", "]", "\n", "\n", "xent_loss", "=", "sequence_loss", "(", "logits", "=", "outputs", ",", "targets", "=", "targets", "[", "0", "]", "[", ":", ",", "1", ":", "]", ",", "weights", "=", "target_weights", ")", "\n", "\n", "reconstructed_outputs", ",", "reconstructed_weights", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "attention_decoder", "(", "\n", "attention_states", "=", "[", "states", "]", ",", "initial_state", "=", "states", "[", ":", ",", "-", "1", ",", ":", "]", ",", "feed_previous", "=", "feed_previous", ",", "\n", "decoder_inputs", "=", "targets", "[", "1", "]", "[", ":", ",", ":", "-", "1", "]", ",", "encoder_input_length", "=", "target_length", ",", "\n", "decoder", "=", "decoders", "[", "1", "]", ",", "training", "=", "training", ",", "encoders", "=", "decoders", "[", ":", "1", "]", "\n", ")", "\n", "\n", "target_weights", "=", "get_weights", "(", "targets", "[", "1", "]", "[", ":", ",", "1", ":", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "xent_loss", "+=", "reconstruction_weight", "*", "sequence_loss", "(", "logits", "=", "reconstructed_outputs", ",", "targets", "=", "targets", "[", "1", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "weights", "=", "target_weights", ")", "\n", "\n", "max_src_len", "=", "tf", ".", "shape", "(", "reconstructed_weights", ")", "[", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "reconstructed_weights", ")", "[", "0", "]", "\n", "\n", "attn_loss", "=", "tf", ".", "matmul", "(", "reconstructed_weights", ",", "attention_weights", ")", "-", "tf", ".", "eye", "(", "max_src_len", ")", "\n", "\n", "src_mask", "=", "tf", ".", "sequence_mask", "(", "encoder_input_length", "[", "0", "]", ",", "maxlen", "=", "max_src_len", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "src_mask", "=", "tf", ".", "einsum", "(", "'ij,ik->ijk'", ",", "src_mask", ",", "src_mask", ")", "\n", "attn_loss", "*=", "tf", ".", "to_float", "(", "src_mask", ")", "# don't take padding words into account", "\n", "\n", "attn_loss", "=", "tf", ".", "norm", "(", "attn_loss", ")", "/", "tf", ".", "to_float", "(", "batch_size", ")", "\n", "xent_loss", "+=", "reconstruction_attn_weight", "*", "attn_loss", "\n", "\n", "attention_weights", "=", "[", "attention_weights", ",", "reconstructed_weights", "]", "\n", "losses", "=", "[", "xent_loss", ",", "None", ",", "None", "]", "\n", "return", "losses", ",", "[", "outputs", "]", ",", "attention_weights", ",", "samples", ",", "beam_fun", ",", "initial_data", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.chained_encoder_decoder": [[1098, 1208], ["translate.beam_search.get_weights", "dict", "models.multi_encoder", "tensorflow.concat", "models.attention_decoder", "models.sequence_loss", "dict", "models.multi_encoder", "models.attention_decoder", "models.sequence_loss", "len", "translate.beam_search.get_weights", "input_weights.append", "encoder_input_length.append", "tensorflow.shape", "tensorflow.ones", "decoder.cell_type.lower", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "tensorflow.concat", "tensorflow.to_int32", "tensorflow.concat", "tensorflow.matmul", "tensorflow.reduce_sum", "tensorflow.stack", "tf.stop_gradient.get_shape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.einsum", "tensorflow.nn.tanh", "tf.nn.tanh.get_shape", "attention_states[].get_shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "def", "chained_encoder_decoder", "(", "encoders", ",", "decoders", ",", "encoder_inputs", ",", "targets", ",", "feed_previous", ",", "\n", "chaining_strategy", "=", "None", ",", "align_encoder_id", "=", "0", ",", "chaining_non_linearity", "=", "False", ",", "\n", "chaining_loss_ratio", "=", "1.0", ",", "chaining_stop_gradient", "=", "False", ",", "training", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "decoder", "=", "decoders", "[", "0", "]", "\n", "targets", "=", "targets", "[", "0", "]", "# single decoder", "\n", "\n", "assert", "len", "(", "encoders", ")", "==", "2", "\n", "\n", "encoder_input_length", "=", "[", "]", "\n", "input_weights", "=", "[", "]", "\n", "for", "encoder_inputs_", "in", "encoder_inputs", ":", "\n", "        ", "weights", "=", "get_weights", "(", "encoder_inputs_", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "input_weights", ".", "append", "(", "weights", ")", "\n", "encoder_input_length", ".", "append", "(", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "weights", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n", "", "target_weights", "=", "get_weights", "(", "targets", "[", ":", ",", "1", ":", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "\n", "parameters", "=", "dict", "(", "encoders", "=", "encoders", "[", "1", ":", "]", ",", "decoder", "=", "encoders", "[", "0", "]", ",", "training", "=", "training", ")", "\n", "\n", "attention_states", ",", "encoder_state", ",", "encoder_input_length", "[", "1", ":", "]", "=", "multi_encoder", "(", "\n", "encoder_inputs", "[", "1", ":", "]", ",", "encoder_input_length", "=", "encoder_input_length", "[", "1", ":", "]", ",", "**", "parameters", ")", "\n", "\n", "decoder_inputs", "=", "encoder_inputs", "[", "0", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "batch_size", "=", "tf", ".", "shape", "(", "decoder_inputs", ")", "[", "0", "]", "\n", "\n", "pad", "=", "tf", ".", "ones", "(", "shape", "=", "tf", ".", "stack", "(", "[", "batch_size", ",", "1", "]", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "*", "utils", ".", "BOS_ID", "\n", "decoder_inputs", "=", "tf", ".", "concat", "(", "[", "pad", ",", "decoder_inputs", "]", ",", "axis", "=", "1", ")", "\n", "\n", "outputs", ",", "attention_weights_1", ",", "states", ",", "attns", ",", "_", ",", "_", ",", "_", "=", "attention_decoder", "(", "\n", "attention_states", "=", "attention_states", ",", "initial_state", "=", "encoder_state", ",", "decoder_inputs", "=", "decoder_inputs", ",", "\n", "encoder_input_length", "=", "encoder_input_length", "[", "1", ":", "]", ",", "**", "parameters", "\n", ")", "\n", "\n", "chaining_loss", "=", "sequence_loss", "(", "logits", "=", "outputs", ",", "targets", "=", "encoder_inputs", "[", "0", "]", ",", "weights", "=", "input_weights", "[", "0", "]", ")", "\n", "\n", "if", "'lstm'", "in", "decoder", ".", "cell_type", ".", "lower", "(", ")", ":", "\n", "        ", "size", "=", "states", ".", "get_shape", "(", ")", "[", "2", "]", ".", "value", "\n", "decoder_outputs", "=", "states", "[", ":", ",", ":", ",", "size", "//", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "decoder_outputs", "=", "states", "\n", "\n", "", "if", "chaining_strategy", "==", "'share_states'", ":", "\n", "        ", "other_inputs", "=", "states", "\n", "", "elif", "chaining_strategy", "==", "'share_outputs'", ":", "\n", "        ", "other_inputs", "=", "decoder_outputs", "\n", "", "else", ":", "\n", "        ", "other_inputs", "=", "None", "\n", "\n", "", "if", "other_inputs", "is", "not", "None", "and", "chaining_stop_gradient", ":", "\n", "        ", "other_inputs", "=", "tf", ".", "stop_gradient", "(", "other_inputs", ")", "\n", "\n", "", "parameters", "=", "dict", "(", "encoders", "=", "encoders", "[", ":", "1", "]", ",", "decoder", "=", "decoder", ",", "encoder_inputs", "=", "encoder_inputs", "[", ":", "1", "]", ",", "\n", "other_inputs", "=", "other_inputs", ",", "training", "=", "training", ")", "\n", "\n", "attention_states", ",", "encoder_state", ",", "encoder_input_length", "[", ":", "1", "]", "=", "multi_encoder", "(", "\n", "encoder_input_length", "=", "encoder_input_length", "[", ":", "1", "]", ",", "**", "parameters", ")", "\n", "\n", "if", "chaining_stop_gradient", ":", "\n", "        ", "attns", "=", "tf", ".", "stop_gradient", "(", "attns", ")", "\n", "states", "=", "tf", ".", "stop_gradient", "(", "states", ")", "\n", "decoder_outputs", "=", "tf", ".", "stop_gradient", "(", "decoder_outputs", ")", "\n", "\n", "", "if", "chaining_strategy", "==", "'concat_attns'", ":", "\n", "        ", "attention_states", "[", "0", "]", "=", "tf", ".", "concat", "(", "[", "attention_states", "[", "0", "]", ",", "attns", "]", ",", "axis", "=", "2", ")", "\n", "", "elif", "chaining_strategy", "==", "'concat_states'", ":", "\n", "        ", "attention_states", "[", "0", "]", "=", "tf", ".", "concat", "(", "[", "attention_states", "[", "0", "]", ",", "states", "]", ",", "axis", "=", "2", ")", "\n", "", "elif", "chaining_strategy", "==", "'sum_attns'", ":", "\n", "        ", "attention_states", "[", "0", "]", "+=", "attns", "\n", "", "elif", "chaining_strategy", "in", "(", "'map_attns'", ",", "'map_states'", ",", "'map_outputs'", ")", ":", "\n", "        ", "if", "chaining_strategy", "==", "'map_attns'", ":", "\n", "            ", "x", "=", "attns", "\n", "", "elif", "chaining_strategy", "==", "'map_outputs'", ":", "\n", "            ", "x", "=", "decoder_outputs", "\n", "", "else", ":", "\n", "            ", "x", "=", "states", "\n", "\n", "", "shape", "=", "[", "x", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "attention_states", "[", "0", "]", ".", "get_shape", "(", ")", "[", "-", "1", "]", "]", "\n", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"map_attns/matrix\"", ",", "shape", "=", "shape", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"map_attns/bias\"", ",", "shape", "=", "shape", "[", "-", "1", ":", "]", ")", "\n", "\n", "x", "=", "tf", ".", "einsum", "(", "'ijk,kl->ijl'", ",", "x", ",", "w", ")", "+", "b", "\n", "if", "chaining_non_linearity", ":", "\n", "            ", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "\n", "", "attention_states", "[", "0", "]", "+=", "x", "\n", "\n", "", "outputs", ",", "attention_weights_2", ",", "_", ",", "_", ",", "samples", ",", "beam_fun", ",", "initial_data", "=", "attention_decoder", "(", "\n", "attention_states", "=", "attention_states", ",", "initial_state", "=", "encoder_state", ",", "\n", "feed_previous", "=", "feed_previous", ",", "decoder_inputs", "=", "targets", "[", ":", ",", ":", "-", "1", "]", ",", "\n", "align_encoder_id", "=", "0", ",", "encoder_input_length", "=", "encoder_input_length", "[", ":", "1", "]", ",", "\n", "**", "parameters", "\n", ")", "\n", "\n", "xent_loss", "=", "sequence_loss", "(", "logits", "=", "outputs", ",", "targets", "=", "targets", "[", ":", ",", "1", ":", "]", ",", "\n", "weights", "=", "target_weights", ")", "\n", "\n", "if", "chaining_loss", "is", "not", "None", "and", "chaining_loss_ratio", ":", "\n", "        ", "xent_loss", "+=", "chaining_loss_ratio", "*", "chaining_loss", "\n", "\n", "", "losses", "=", "[", "xent_loss", ",", "None", ",", "None", "]", "\n", "\n", "if", "align_encoder_id", "==", "0", ":", "\n", "        ", "attention_weights", "=", "attention_weights_2", "\n", "", "elif", "align_encoder_id", "==", "2", ":", "\n", "        ", "attention_weights", "=", "tf", ".", "matmul", "(", "attention_weights_2", ",", "attention_weights_1", ")", "\n", "", "else", ":", "\n", "        ", "attention_weights", "=", "attention_weights_1", "\n", "\n", "", "return", "losses", ",", "[", "outputs", "]", ",", "attention_weights", ",", "samples", ",", "beam_fun", ",", "initial_data", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_task_encoder_decoder": [[1210, 1263], ["list", "enumerate", "itertools.product", "dict", "models.multi_encoder", "models.attention_decoder", "translate.beam_search.get_weights", "models.sequence_loss", "outputs.append", "attention_weights.append", "beam_fun.append", "initial_data.append", "translate.beam_search.get_weights", "encoder_input_length.append", "range", "range", "tensorflow.to_int32", "len", "len", "len", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.models.multi_encoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.attention_decoder", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights", "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_weights"], ["", "def", "multi_task_encoder_decoder", "(", "encoders", ",", "decoders", ",", "encoder_inputs", ",", "targets", ",", "feed_previous", ",", "encoder_input_length", "=", "None", ",", "\n", "feed_argmax", "=", "True", ",", "training", "=", "True", ",", "task_ratios", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "encoder_input_length", "is", "None", ":", "\n", "        ", "encoder_input_length", "=", "[", "]", "\n", "for", "encoder_inputs_", "in", "encoder_inputs", ":", "\n", "            ", "mask", "=", "get_weights", "(", "encoder_inputs_", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "encoder_input_length", ".", "append", "(", "tf", ".", "to_int32", "(", "tf", ".", "reduce_sum", "(", "mask", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n", "", "", "outputs", "=", "[", "]", "\n", "attention_weights", "=", "[", "]", "\n", "beam_fun", "=", "[", "]", "\n", "initial_data", "=", "[", "]", "\n", "\n", "xent_loss", "=", "0", "\n", "\n", "tasks", "=", "list", "(", "product", "(", "range", "(", "len", "(", "encoders", ")", ")", ",", "range", "(", "len", "(", "decoders", ")", ")", ")", ")", "\n", "for", "i", ",", "(", "encoder_id", ",", "decoder_id", ")", "in", "enumerate", "(", "tasks", ")", ":", "\n", "        ", "if", "not", "task_ratios", ":", "\n", "            ", "ratio", "=", "1.0", "/", "len", "(", "tasks", ")", "\n", "", "else", ":", "\n", "            ", "ratio", "=", "task_ratios", "[", "i", "]", "\n", "\n", "", "if", "ratio", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "encoders_", "=", "[", "encoders", "[", "encoder_id", "]", "]", "\n", "decoder", "=", "decoders", "[", "decoder_id", "]", "\n", "encoder_inputs_", "=", "[", "encoder_inputs", "[", "encoder_id", "]", "]", "\n", "encoder_input_length_", "=", "[", "encoder_input_length", "[", "encoder_id", "]", "]", "\n", "targets_", "=", "targets", "[", "decoder_id", "]", "\n", "\n", "parameters", "=", "dict", "(", "encoders", "=", "encoders_", ",", "decoder", "=", "decoder", ",", "encoder_inputs", "=", "encoder_inputs_", ",", "\n", "feed_argmax", "=", "feed_argmax", ",", "training", "=", "training", ")", "\n", "\n", "attention_states_", ",", "encoder_state_", ",", "encoder_input_length_", "=", "multi_encoder", "(", "\n", "encoder_input_length", "=", "encoder_input_length_", ",", "**", "parameters", ")", "\n", "\n", "outputs_", ",", "attention_weights_", ",", "_", ",", "_", ",", "samples_", ",", "beam_fun_", ",", "initial_data_", "=", "attention_decoder", "(", "\n", "attention_states", "=", "attention_states_", ",", "initial_state", "=", "encoder_state_", ",", "feed_previous", "=", "feed_previous", ",", "\n", "decoder_inputs", "=", "targets_", "[", ":", ",", ":", "-", "1", "]", ",", "align_encoder_id", "=", "0", ",", "encoder_input_length", "=", "encoder_input_length_", ",", "\n", "**", "parameters", "\n", ")", "\n", "\n", "trg_mask", "=", "get_weights", "(", "targets_", "[", ":", ",", "1", ":", "]", ",", "utils", ".", "EOS_ID", ",", "include_first_eos", "=", "True", ")", "\n", "xent_loss_", "=", "sequence_loss", "(", "logits", "=", "outputs_", ",", "targets", "=", "targets_", "[", ":", ",", "1", ":", "]", ",", "weights", "=", "trg_mask", ")", "\n", "xent_loss", "+=", "ratio", "*", "xent_loss_", "\n", "outputs", ".", "append", "(", "outputs_", ")", "\n", "attention_weights", ".", "append", "(", "attention_weights_", ")", "\n", "beam_fun", ".", "append", "(", "beam_fun_", ")", "\n", "initial_data", ".", "append", "(", "initial_data_", ")", "\n", "\n", "", "losses", "=", "[", "xent_loss", ",", "None", ",", "None", "]", "\n", "return", "losses", ",", "[", "outputs", "[", "0", "]", "]", ",", "attention_weights", "[", "0", "]", ",", "None", ",", "beam_fun", "[", "0", "]", ",", "initial_data", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.softmax": [[1265, 1271], ["tensorflow.exp", "tensorflow.clip_by_value", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ",", "mask", "=", "None", ")", ":", "\n", "    ", "e", "=", "tf", ".", "exp", "(", "logits", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "e", "*=", "mask", "\n", "\n", "", "return", "e", "/", "tf", ".", "clip_by_value", "(", "tf", ".", "reduce_sum", "(", "e", ",", "axis", "=", "dim", ",", "keep_dims", "=", "True", ")", ",", "10e-37", ",", "10e+37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.sequence_loss": [[1273, 1299], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.shape", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.stop_gradient", "tensorflow.reduce_sum", "tensorflow.to_float", "logits.get_shape"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "def", "sequence_loss", "(", "logits", ",", "targets", ",", "weights", ",", "average_across_timesteps", "=", "False", ",", "average_across_batch", "=", "True", ",", "rewards", "=", "None", ")", ":", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "targets", ")", "[", "0", "]", "\n", "time_steps", "=", "tf", ".", "shape", "(", "targets", ")", "[", "1", "]", "\n", "\n", "logits_", "=", "tf", ".", "reshape", "(", "logits", ",", "tf", ".", "stack", "(", "[", "time_steps", "*", "batch_size", ",", "logits", ".", "get_shape", "(", ")", "[", "2", "]", ".", "value", "]", ")", ")", "\n", "targets_", "=", "tf", ".", "reshape", "(", "targets", ",", "tf", ".", "stack", "(", "[", "time_steps", "*", "batch_size", "]", ")", ")", "\n", "\n", "crossent", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits_", ",", "labels", "=", "targets_", ")", "\n", "crossent", "=", "tf", ".", "reshape", "(", "crossent", ",", "tf", ".", "stack", "(", "[", "batch_size", ",", "time_steps", "]", ")", ")", "\n", "\n", "if", "rewards", "is", "not", "None", ":", "\n", "        ", "crossent", "*=", "tf", ".", "stop_gradient", "(", "rewards", ")", "\n", "\n", "", "log_perp", "=", "tf", ".", "reduce_sum", "(", "crossent", "*", "weights", ",", "axis", "=", "1", ")", "\n", "\n", "if", "average_across_timesteps", ":", "\n", "        ", "total_size", "=", "tf", ".", "reduce_sum", "(", "weights", ",", "axis", "=", "1", ")", "\n", "total_size", "+=", "1e-12", "# just to avoid division by 0 for all-0 weights", "\n", "log_perp", "/=", "total_size", "\n", "\n", "", "cost", "=", "tf", ".", "reduce_sum", "(", "log_perp", ")", "\n", "\n", "if", "average_across_batch", ":", "\n", "        ", "return", "cost", "/", "tf", ".", "to_float", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "        ", "return", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.reinforce_baseline": [[1301, 1320], ["dense", "tensorflow.squeeze", "tensorflow.stop_gradient", "tensorflow.constant_initializer"], "function", ["None"], ["", "", "def", "reinforce_baseline", "(", "decoder_states", ",", "reward", ")", ":", "\n", "    ", "\"\"\"\n    Center the reward by computing a baseline reward over decoder states.\n\n    :param decoder_states: internal states of the decoder, tensor of shape (batch_size, time_steps, state_size)\n    :param reward: reward for each time step, tensor of shape (batch_size, time_steps)\n    :return: reward - computed baseline, tensor of shape (batch_size, time_steps)\n    \"\"\"", "\n", "# batch_size = tf.shape(decoder_states)[0]", "\n", "# time_steps = tf.shape(decoder_states)[1]", "\n", "# state_size = decoder_states.get_shape()[2]", "\n", "# states = tf.reshape(decoder_states, shape=tf.stack([batch_size * time_steps, state_size]))", "\n", "\n", "baseline", "=", "dense", "(", "tf", ".", "stop_gradient", "(", "decoder_states", ")", ",", "units", "=", "1", ",", "activation", "=", "None", ",", "name", "=", "'reward_baseline'", ",", "\n", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "0.01", ")", ")", "\n", "baseline", "=", "tf", ".", "squeeze", "(", "baseline", ",", "axis", "=", "2", ")", "\n", "\n", "# baseline = tf.reshape(baseline, shape=tf.stack([batch_size, time_steps]))", "\n", "return", "reward", "-", "baseline", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.models.baseline_loss": [[1322, 1343], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.to_float"], "function", ["None"], ["", "def", "baseline_loss", "(", "rewards", ",", "weights", ",", "average_across_timesteps", "=", "False", ",", "average_across_batch", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param rewards: tensor of shape (batch_size, time_steps)\n    :param weights: tensor of shape (batch_size, time_steps)\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "rewards", ")", "[", "0", "]", "\n", "\n", "cost", "=", "rewards", "**", "2", "\n", "cost", "=", "tf", ".", "reduce_sum", "(", "cost", "*", "weights", ",", "axis", "=", "1", ")", "\n", "\n", "if", "average_across_timesteps", ":", "\n", "        ", "total_size", "=", "tf", ".", "reduce_sum", "(", "weights", ",", "axis", "=", "1", ")", "\n", "total_size", "+=", "1e-12", "# just to avoid division by 0 for all-0 weights", "\n", "cost", "/=", "total_size", "\n", "\n", "", "cost", "=", "tf", ".", "reduce_sum", "(", "cost", ")", "\n", "\n", "if", "average_across_batch", ":", "\n", "        ", "cost", "/=", "tf", ".", "to_float", "(", "batch_size", ")", "\n", "\n", "", "return", "cost", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm.BasicConvLSTMCell.__init__": [[10, 30], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "filter_size", ",", "num_features", ",", "forget_bias", "=", "1.0", ",", "\n", "state_is_tuple", "=", "False", ",", "activation", "=", "tf", ".", "nn", ".", "tanh", ")", ":", "\n", "        ", "\"\"\"\n          shape: int tuple, height and width of the cell\n          filter_size: int tuple, height and width of the filter\n          num_features: int, depth of the cell\n          forget_bias: float, forget gates bias\n          state_is_tuple: If True, accepted and returned states are 2-tuples of\n            the `c_state` and `m_state`.  If False, they are concatenated\n            along the column axis.  The latter behavior will soon be deprecated.\n          activation: activation function of the inner states\n        \"\"\"", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "height", ",", "self", ".", "width", "=", "self", ".", "shape", "\n", "self", ".", "filter_size", "=", "filter_size", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "_num_units", "=", "self", ".", "num_features", "*", "self", ".", "height", "*", "self", ".", "width", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "self", ".", "_activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm.BasicConvLSTMCell.state_size": [[31, 35], ["tensorflow.contrib.rnn.LSTMStateTuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "(", "LSTMStateTuple", "(", "self", ".", "_num_units", ",", "self", ".", "_num_units", ")", "\n", "if", "self", ".", "_state_is_tuple", "else", "2", "*", "self", ".", "_num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm.BasicConvLSTMCell.output_size": [[36, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm.BasicConvLSTMCell.__call__": [[40, 72], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "conv_lstm._conv_linear", "tensorflow.split", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.split", "tensorflow.shape", "conv_lstm.BasicConvLSTMCell._activation", "tensorflow.nn.sigmoid", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.concat", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "conv_lstm.BasicConvLSTMCell._activation", "type"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm._conv_linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Long short-term memory cell (LSTM).\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"BasicLSTMCell\"", "\n", "# Parameters of gates are concatenated into one multiply for efficiency.", "\n", "            ", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "c", ",", "h", "=", "state", "\n", "", "else", ":", "\n", "                ", "c", ",", "h", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "2", ",", "value", "=", "state", ")", "\n", "\n", "", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "batch_size", ",", "self", ".", "height", ",", "self", ".", "width", ",", "1", "]", ")", "\n", "c", "=", "tf", ".", "reshape", "(", "c", ",", "[", "batch_size", ",", "self", ".", "height", ",", "self", ".", "width", ",", "self", ".", "num_features", "]", ")", "\n", "h", "=", "tf", ".", "reshape", "(", "h", ",", "[", "batch_size", ",", "self", ".", "height", ",", "self", ".", "width", ",", "self", ".", "num_features", "]", ")", "\n", "\n", "concat", "=", "_conv_linear", "(", "[", "inputs", ",", "h", "]", ",", "self", ".", "filter_size", ",", "self", ".", "num_features", "*", "4", ",", "True", ")", "\n", "\n", "# i = input_gate, j = new_input, f = forget_gate, o = output_gate", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "tf", ".", "split", "(", "axis", "=", "3", ",", "num_or_size_splits", "=", "4", ",", "value", "=", "concat", ")", "\n", "\n", "new_c", "=", "(", "c", "*", "tf", ".", "nn", ".", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", ")", "+", "tf", ".", "nn", ".", "sigmoid", "(", "i", ")", "*", "\n", "self", ".", "_activation", "(", "j", ")", ")", "\n", "new_h", "=", "self", ".", "_activation", "(", "new_c", ")", "*", "tf", ".", "nn", ".", "sigmoid", "(", "o", ")", "\n", "\n", "new_h", "=", "tf", ".", "reshape", "(", "new_h", ",", "[", "batch_size", ",", "self", ".", "_num_units", "]", ")", "\n", "new_c", "=", "tf", ".", "reshape", "(", "new_c", ",", "[", "batch_size", ",", "self", ".", "_num_units", "]", ")", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "new_state", "=", "LSTMStateTuple", "(", "new_c", ",", "new_h", ")", "\n", "", "else", ":", "\n", "                ", "new_state", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "new_c", ",", "new_h", "]", ")", "\n", "\n", "", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm.BasicConvLSTMCell.zero_state": [[73, 83], ["tensorflow.zeros"], "methods", ["None"], ["", "", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"Return zero-filled state tensor(s).\n        Args:\n          batch_size: int, float, or unit Tensor representing the batch size.\n          dtype: the data type to use for the state.\n        Returns:\n          tensor of shape '[batch_size x shape[0] x shape[1] x num_features]\n          filled with zeros\n        \"\"\"", "\n", "return", "tf", ".", "zeros", "(", "[", "batch_size", ",", "self", ".", "_num_units", "*", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.conv_lstm._conv_linear": [[84, 127], ["a.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "len", "ValueError", "ValueError", "len", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "a.get_shape", "tensorflow.concat", "tensorflow.constant_initializer", "str", "str"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["", "", "def", "_conv_linear", "(", "args", ",", "filter_size", ",", "num_features", ",", "bias", ",", "bias_start", "=", "0.0", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"convolution:\n    Args:\n      args: a 4D Tensor or a list of 4D, batch x n, Tensors.\n      filter_size: int tuple of filter height and width.\n      num_features: int, number of features.\n      bias_start: starting value to initialize the bias; 0 by default.\n      scope: VariableScope for the created subgraph; defaults to \"Linear\".\n    Returns:\n      A 4D Tensor with shape [batch h w num_features]\n    Raises:\n      ValueError: if some of the arguments has unspecified or wrong shape.\n    \"\"\"", "\n", "\n", "# Calculate the total size of arguments on dimension 1.", "\n", "total_arg_size_depth", "=", "0", "\n", "shapes", "=", "[", "a", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "a", "in", "args", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "        ", "if", "len", "(", "shape", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\"Linear is expecting 4D arguments: %s\"", "%", "str", "(", "shapes", ")", ")", "\n", "", "if", "not", "shape", "[", "3", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Linear expects shape[4] of arguments: %s\"", "%", "str", "(", "shapes", ")", ")", "\n", "", "else", ":", "\n", "            ", "total_arg_size_depth", "+=", "shape", "[", "3", "]", "\n", "\n", "", "", "dtype", "=", "[", "a", ".", "dtype", "for", "a", "in", "args", "]", "[", "0", "]", "\n", "\n", "# Now the computation.", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"Conv\"", ")", ":", "\n", "        ", "matrix", "=", "tf", ".", "get_variable", "(", "\n", "\"Matrix\"", ",", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "total_arg_size_depth", ",", "num_features", "]", ",", "dtype", "=", "dtype", ")", "\n", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "            ", "res", "=", "tf", ".", "nn", ".", "conv2d", "(", "args", "[", "0", "]", ",", "matrix", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "tf", ".", "nn", ".", "conv2d", "(", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "args", ")", ",", "matrix", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "", "if", "not", "bias", ":", "\n", "            ", "return", "res", "\n", "", "bias_term", "=", "tf", ".", "get_variable", "(", "\n", "\"Bias\"", ",", "[", "num_features", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "\n", "bias_start", ",", "dtype", "=", "dtype", ")", ")", "\n", "", "return", "res", "+", "bias_term", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.__init__": [[7, 25], ["enumerate", "dict", "dict.update", "translate.translation_model.TranslationModel", "multitask_model.MultiTaskModel.models.append", "multitask_model.MultiTaskModel.ratios.append", "sum"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tasks", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "models", "=", "[", "]", "\n", "self", ".", "ratios", "=", "[", "]", "\n", "\n", "for", "i", ",", "task", "in", "enumerate", "(", "tasks", ",", "1", ")", ":", "\n", "            ", "if", "task", ".", "name", "is", "None", ":", "\n", "                ", "task", ".", "name", "=", "'task_{}'", ".", "format", "(", "i", ")", "\n", "\n", "# merging both dictionaries (task parameters have a higher precedence)", "\n", "", "kwargs_", "=", "dict", "(", "**", "kwargs", ")", "\n", "kwargs_", ".", "update", "(", "task", ")", "\n", "model", "=", "TranslationModel", "(", "**", "kwargs_", ")", "\n", "\n", "self", ".", "models", ".", "append", "(", "model", ")", "\n", "self", ".", "ratios", ".", "append", "(", "task", ".", "ratio", "if", "task", ".", "ratio", "is", "not", "None", "else", "1", ")", "\n", "\n", "", "self", ".", "main_model", "=", "self", ".", "models", "[", "0", "]", "\n", "self", ".", "ratios", "=", "[", "ratio", "/", "sum", "(", "self", ".", "ratios", ")", "for", "ratio", "in", "self", ".", "ratios", "]", "# unit normalization", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.train": [[26, 51], ["translate.utils.log", "translate.utils.log", "model.init_training", "numpy.random.choice", "model.train_step", "len", "translate.utils.log", "multitask_model.MultiTaskModel.main_model.save", "model.save", "model.manage_best_checkpoints", "model.save", "model.manage_best_checkpoints"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.init_training", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.train_step", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.manage_best_checkpoints", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.manage_best_checkpoints"], ["", "def", "train", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "utils", ".", "log", "(", "'initializing {}'", ".", "format", "(", "model", ".", "name", ")", ")", "\n", "model", ".", "init_training", "(", "**", "kwargs", ")", "\n", "\n", "", "utils", ".", "log", "(", "'starting training'", ")", "\n", "while", "True", ":", "\n", "            ", "i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "models", ")", ",", "1", ",", "p", "=", "self", ".", "ratios", ")", "[", "0", "]", "\n", "model", "=", "self", ".", "models", "[", "i", "]", "\n", "try", ":", "\n", "                ", "model", ".", "train_step", "(", "**", "kwargs", ")", "\n", "", "except", "(", "utils", ".", "FinishedTrainingException", ",", "KeyboardInterrupt", ")", ":", "\n", "                ", "utils", ".", "log", "(", "'exiting...'", ")", "\n", "self", ".", "main_model", ".", "save", "(", ")", "\n", "return", "\n", "", "except", "utils", ".", "EvalException", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "model", ".", "save", "(", ")", "\n", "step", ",", "score", "=", "model", ".", "training", ".", "scores", "[", "-", "1", "]", "\n", "model", ".", "manage_best_checkpoints", "(", "step", ",", "score", ")", "\n", "", "", "except", "utils", ".", "CheckpointException", ":", "\n", "                ", "if", "i", "==", "0", ":", "# only save main model (includes all variables)", "\n", "                    ", "model", ".", "save", "(", ")", "\n", "step", ",", "score", "=", "model", ".", "training", ".", "scores", "[", "-", "1", "]", "\n", "model", ".", "manage_best_checkpoints", "(", "step", ",", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.decode": [[52, 54], ["multitask_model.MultiTaskModel.main_model.decode"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode"], ["", "", "", "", "def", "decode", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "main_model", ".", "decode", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.evaluate": [[55, 57], ["multitask_model.MultiTaskModel.main_model.evaluate"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.evaluate"], ["", "def", "evaluate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "main_model", ".", "evaluate", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.align": [[58, 60], ["multitask_model.MultiTaskModel.main_model.align"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.align"], ["", "def", "align", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "main_model", ".", "align", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.initialize": [[61, 63], ["multitask_model.MultiTaskModel.main_model.initialize"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.initialize"], ["", "def", "initialize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "main_model", ".", "initialize", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.multitask_model.MultiTaskModel.save": [[64, 66], ["multitask_model.MultiTaskModel.main_model.save"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save"], ["", "def", "save", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "main_model", ".", "save", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.__init__": [[18, 119], ["tensorflow.Variable", "translation_model.TranslationModel.learning_rate.assign", "translate.utils.get_filenames", "translate.utils.debug", "translation_model.TranslationModel.read_vocab", "zip", "translate.utils.debug", "translation_model.TranslationModel.seq2seq_model.create_beam_op", "translate.utils.AttrDict", "translation_model.TranslationModel.binary.append", "translation_model.TranslationModel.binary.append", "dict", "tensorflow.device", "tensorflow.Variable", "tensorflow.Variable", "enumerate", "translate.seq2seq_model.Seq2SeqModel", "translation_model.TranslationModel.models.append", "encoder_or_decoder.get", "zip", "open", "dict", "list", "len", "tensorflow.variable_scope", "translate.seq2seq_model.Seq2SeqModel", "translation_model.TranslationModel.models.append", "vocab.vocab.items", "line.split"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_filenames", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.read_vocab", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.create_beam_op"], ["    ", "def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ",", "checkpoint_dir", ",", "learning_rate", ",", "learning_rate_decay_factor", ",", "\n", "batch_size", ",", "keep_best", "=", "1", ",", "dev_prefix", "=", "None", ",", "name", "=", "None", ",", "ref_ext", "=", "None", ",", "\n", "pred_edits", "=", "False", ",", "dual_output", "=", "False", ",", "binary", "=", "None", ",", "truncate_lines", "=", "True", ",", "ensemble", "=", "False", ",", "\n", "checkpoints", "=", "None", ",", "beam_size", "=", "1", ",", "len_normalization", "=", "1", ",", "lexicon", "=", "None", ",", "debug", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "character_level", "=", "{", "}", "\n", "self", ".", "binary", "=", "[", "]", "\n", "self", ".", "debug", "=", "debug", "\n", "\n", "for", "encoder_or_decoder", "in", "encoders", "+", "decoders", ":", "\n", "            ", "encoder_or_decoder", ".", "ext", "=", "encoder_or_decoder", ".", "ext", "or", "encoder_or_decoder", ".", "name", "\n", "self", ".", "character_level", "[", "encoder_or_decoder", ".", "ext", "]", "=", "encoder_or_decoder", ".", "character_level", "\n", "self", ".", "binary", ".", "append", "(", "encoder_or_decoder", ".", "get", "(", "'binary'", ",", "False", ")", ")", "\n", "\n", "", "self", ".", "encoders", ",", "self", ".", "decoders", "=", "encoders", ",", "decoders", "\n", "\n", "self", ".", "char_output", "=", "decoders", "[", "0", "]", ".", "character_level", "\n", "\n", "self", ".", "src_ext", "=", "[", "encoder", ".", "ext", "for", "encoder", "in", "encoders", "]", "\n", "self", ".", "trg_ext", "=", "[", "decoder", ".", "ext", "for", "decoder", "in", "decoders", "]", "\n", "\n", "self", ".", "extensions", "=", "self", ".", "src_ext", "+", "self", ".", "trg_ext", "\n", "\n", "self", ".", "ref_ext", "=", "ref_ext", "\n", "if", "self", ".", "ref_ext", "is", "not", "None", ":", "\n", "            ", "self", ".", "binary", ".", "append", "(", "False", ")", "\n", "\n", "", "self", ".", "pred_edits", "=", "pred_edits", "\n", "self", ".", "dual_output", "=", "dual_output", "\n", "\n", "self", ".", "dev_prefix", "=", "dev_prefix", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "max_input_len", "=", "[", "encoder", ".", "max_len", "for", "encoder", "in", "encoders", "]", "\n", "self", ".", "max_output_len", "=", "[", "decoder", ".", "max_len", "for", "decoder", "in", "decoders", "]", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n", "if", "truncate_lines", ":", "\n", "            ", "self", ".", "max_len", "=", "None", "# we let seq2seq.get_batch handle long lines (by truncating them)", "\n", "", "else", ":", "# the line reader will drop lines that are too long", "\n", "            ", "self", ".", "max_len", "=", "dict", "(", "zip", "(", "self", ".", "extensions", ",", "self", ".", "max_input_len", "+", "self", ".", "max_output_len", ")", ")", "\n", "\n", "", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "learning_rate", ",", "trainable", "=", "False", ",", "name", "=", "'learning_rate'", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "learning_rate_decay_op", "=", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "learning_rate", "*", "learning_rate_decay_factor", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'global_step'", ")", "\n", "self", ".", "baseline_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "'baseline_step'", ")", "\n", "\n", "", "self", ".", "filenames", "=", "utils", ".", "get_filenames", "(", "extensions", "=", "self", ".", "extensions", ",", "dev_prefix", "=", "dev_prefix", ",", "name", "=", "name", ",", "\n", "ref_ext", "=", "ref_ext", ",", "binary", "=", "self", ".", "binary", ",", "**", "kwargs", ")", "\n", "utils", ".", "debug", "(", "'reading vocabularies'", ")", "\n", "self", ".", "vocabs", "=", "None", "\n", "self", ".", "src_vocab", ",", "self", ".", "trg_vocab", "=", "None", ",", "None", "\n", "self", ".", "read_vocab", "(", ")", "\n", "\n", "for", "encoder_or_decoder", ",", "vocab", "in", "zip", "(", "encoders", "+", "decoders", ",", "self", ".", "vocabs", ")", ":", "\n", "            ", "if", "vocab", ":", "\n", "                ", "if", "encoder_or_decoder", ".", "vocab_size", ":", "# reduce vocab size", "\n", "                    ", "vocab", ".", "reverse", "[", ":", "]", "=", "vocab", ".", "reverse", "[", ":", "encoder_or_decoder", ".", "vocab_size", "]", "\n", "for", "token", ",", "token_id", "in", "list", "(", "vocab", ".", "vocab", ".", "items", "(", ")", ")", ":", "\n", "                        ", "if", "token_id", ">=", "encoder_or_decoder", ".", "vocab_size", ":", "\n", "                            ", "del", "vocab", ".", "vocab", "[", "token", "]", "\n", "", "", "", "else", ":", "\n", "                    ", "encoder_or_decoder", ".", "vocab_size", "=", "len", "(", "vocab", ".", "reverse", ")", "\n", "\n", "", "", "", "utils", ".", "debug", "(", "'creating model'", ")", "\n", "\n", "self", ".", "models", "=", "[", "]", "\n", "if", "ensemble", "and", "checkpoints", "is", "not", "None", ":", "\n", "            ", "for", "i", ",", "_", "in", "enumerate", "(", "checkpoints", ",", "1", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'model_{}'", ".", "format", "(", "i", ")", ")", ":", "\n", "                    ", "model", "=", "Seq2SeqModel", "(", "encoders", ",", "decoders", ",", "self", ".", "learning_rate", ",", "self", ".", "global_step", ",", "name", "=", "name", ",", "\n", "pred_edits", "=", "pred_edits", ",", "dual_output", "=", "dual_output", ",", "\n", "baseline_step", "=", "self", ".", "baseline_step", ",", "**", "kwargs", ")", "\n", "self", ".", "models", ".", "append", "(", "model", ")", "\n", "", "", "self", ".", "seq2seq_model", "=", "self", ".", "models", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "seq2seq_model", "=", "Seq2SeqModel", "(", "encoders", ",", "decoders", ",", "self", ".", "learning_rate", ",", "self", ".", "global_step", ",", "name", "=", "name", ",", "\n", "pred_edits", "=", "pred_edits", ",", "dual_output", "=", "dual_output", ",", "\n", "baseline_step", "=", "self", ".", "baseline_step", ",", "**", "kwargs", ")", "\n", "self", ".", "models", ".", "append", "(", "self", ".", "seq2seq_model", ")", "\n", "\n", "", "self", ".", "seq2seq_model", ".", "create_beam_op", "(", "self", ".", "models", ",", "len_normalization", ")", "\n", "\n", "self", ".", "batch_iterator", "=", "None", "\n", "self", ".", "dev_batches", "=", "None", "\n", "self", ".", "train_size", "=", "None", "\n", "self", ".", "saver", "=", "None", "\n", "self", ".", "keep_best", "=", "keep_best", "\n", "self", ".", "checkpoint_dir", "=", "checkpoint_dir", "\n", "self", ".", "epoch", "=", "None", "\n", "\n", "self", ".", "training", "=", "utils", ".", "AttrDict", "(", ")", "# used to keep track of training", "\n", "\n", "if", "lexicon", ":", "\n", "            ", "with", "open", "(", "lexicon", ")", "as", "lexicon_file", ":", "\n", "                ", "self", ".", "lexicon", "=", "dict", "(", "line", ".", "split", "(", ")", "for", "line", "in", "lexicon_file", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "lexicon", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.read_data": [[120, 138], ["translate.utils.debug", "translate.utils.get_batch_iterator", "translate.utils.debug", "translate.utils.get_batches", "translate.utils.read_dataset"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_batch_iterator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_batches", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_dataset"], ["", "", "def", "read_data", "(", "self", ",", "max_train_size", ",", "max_dev_size", ",", "read_ahead", "=", "10", ",", "batch_mode", "=", "'standard'", ",", "shuffle", "=", "True", ",", "\n", "crash_test", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "utils", ".", "debug", "(", "'reading training data'", ")", "\n", "self", ".", "batch_iterator", ",", "self", ".", "train_size", "=", "utils", ".", "get_batch_iterator", "(", "\n", "self", ".", "filenames", ".", "train", ",", "self", ".", "extensions", ",", "self", ".", "vocabs", ",", "self", ".", "batch_size", ",", "\n", "max_size", "=", "max_train_size", ",", "character_level", "=", "self", ".", "character_level", ",", "max_seq_len", "=", "self", ".", "max_len", ",", "\n", "read_ahead", "=", "read_ahead", ",", "mode", "=", "batch_mode", ",", "shuffle", "=", "shuffle", ",", "binary", "=", "self", ".", "binary", ",", "crash_test", "=", "crash_test", "\n", ")", "\n", "\n", "utils", ".", "debug", "(", "'reading development data'", ")", "\n", "\n", "dev_sets", "=", "[", "\n", "utils", ".", "read_dataset", "(", "dev", ",", "self", ".", "extensions", ",", "self", ".", "vocabs", ",", "max_size", "=", "max_dev_size", ",", "\n", "character_level", "=", "self", ".", "character_level", ",", "binary", "=", "self", ".", "binary", ")", "[", "0", "]", "\n", "for", "dev", "in", "self", ".", "filenames", ".", "dev", "\n", "]", "\n", "# subset of the dev set whose loss is periodically evaluated", "\n", "self", ".", "dev_batches", "=", "[", "utils", ".", "get_batches", "(", "dev_set", ",", "batch_size", "=", "self", ".", "batch_size", ")", "for", "dev_set", "in", "dev_sets", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.read_vocab": [[139, 146], ["translate.utils.initialize_vocabulary", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.initialize_vocabulary"], ["", "def", "read_vocab", "(", "self", ")", ":", "\n", "# don't try reading vocabulary for encoders that take pre-computed features", "\n", "        ", "self", ".", "vocabs", "=", "[", "\n", "None", "if", "binary", "else", "utils", ".", "initialize_vocabulary", "(", "vocab_path", ")", "\n", "for", "vocab_path", ",", "binary", "in", "zip", "(", "self", ".", "filenames", ".", "vocab", ",", "self", ".", "binary", ")", "\n", "]", "\n", "self", ".", "src_vocab", ",", "self", ".", "trg_vocab", "=", "self", ".", "vocabs", "[", ":", "len", "(", "self", ".", "src_ext", ")", "]", ",", "self", ".", "vocabs", "[", "len", "(", "self", ".", "src_ext", ")", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode_sentence": [[147, 149], ["next", "translation_model.TranslationModel.decode_batch"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode_batch"], ["", "def", "decode_sentence", "(", "self", ",", "sentence_tuple", ",", "remove_unk", "=", "False", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "decode_batch", "(", "[", "sentence_tuple", "]", ",", "remove_unk", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode_batch": [[150, 241], ["enumerate", "int", "list", "translation_model.TranslationModel.seq2seq_model.greedy_decoding", "zip", "enumerate", "math.ceil", "map", "zip", "zip", "range", "translate.utils.sentence_to_token_ids", "zip", "list", "translate.utils.reverse_edits.append", "batch_weights[].squeeze", "translate.utils.heatmap", "src_tokens[].split", "numpy.argmax", "translation_model.TranslationModel.decode_batch.replace"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.greedy_decoding", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.sentence_to_token_ids", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.heatmap"], ["", "def", "decode_batch", "(", "self", ",", "sentence_tuples", ",", "batch_size", ",", "remove_unk", "=", "False", ",", "fix_edits", "=", "True", ",", "unk_replace", "=", "False", ",", "\n", "align", "=", "False", ",", "reverse", "=", "False", ",", "output", "=", "None", ")", ":", "\n", "        ", "if", "batch_size", "==", "1", ":", "\n", "            ", "batches", "=", "(", "[", "sentence_tuple", "]", "for", "sentence_tuple", "in", "sentence_tuples", ")", "# lazy", "\n", "", "else", ":", "\n", "            ", "batch_count", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "sentence_tuples", ")", "/", "batch_size", ")", ")", "\n", "batches", "=", "[", "sentence_tuples", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "for", "i", "in", "range", "(", "batch_count", ")", "]", "\n", "\n", "", "def", "map_to_ids", "(", "sentence_tuple", ")", ":", "\n", "            ", "token_ids", "=", "[", "\n", "sentence", "if", "vocab", "is", "None", "else", "\n", "utils", ".", "sentence_to_token_ids", "(", "sentence", ",", "vocab", ".", "vocab", ",", "character_level", "=", "self", ".", "character_level", ".", "get", "(", "ext", ")", ")", "\n", "for", "ext", ",", "vocab", ",", "sentence", "in", "zip", "(", "self", ".", "extensions", ",", "self", ".", "vocabs", ",", "sentence_tuple", ")", "\n", "]", "\n", "return", "token_ids", "\n", "\n", "", "line_id", "=", "0", "\n", "for", "batch_id", ",", "batch", "in", "enumerate", "(", "batches", ")", ":", "\n", "            ", "token_ids", "=", "list", "(", "map", "(", "map_to_ids", ",", "batch", ")", ")", "\n", "batch_token_ids", ",", "batch_weights", "=", "self", ".", "seq2seq_model", ".", "greedy_decoding", "(", "token_ids", ",", "beam_size", "=", "self", ".", "beam_size", ",", "\n", "align", "=", "unk_replace", "or", "align", "or", "self", ".", "debug", ")", "\n", "batch_token_ids", "=", "zip", "(", "*", "batch_token_ids", ")", "\n", "\n", "for", "sentence_id", ",", "(", "src_tokens", ",", "trg_token_ids", ")", "in", "enumerate", "(", "zip", "(", "batch", ",", "batch_token_ids", ")", ")", ":", "\n", "                ", "line_id", "+=", "1", "\n", "trg_tokens", "=", "[", "]", "\n", "\n", "for", "trg_token_ids_", ",", "vocab", "in", "zip", "(", "trg_token_ids", ",", "self", ".", "trg_vocab", ")", ":", "\n", "                    ", "trg_token_ids_", "=", "list", "(", "trg_token_ids_", ")", "# from np array to list", "\n", "if", "utils", ".", "EOS_ID", "in", "trg_token_ids_", ":", "\n", "                        ", "trg_token_ids_", "=", "trg_token_ids_", "[", ":", "trg_token_ids_", ".", "index", "(", "utils", ".", "EOS_ID", ")", "]", "\n", "\n", "", "trg_tokens_", "=", "[", "vocab", ".", "reverse", "[", "i", "]", "if", "i", "<", "len", "(", "vocab", ".", "reverse", ")", "else", "utils", ".", "_UNK", "\n", "for", "i", "in", "trg_token_ids_", "]", "\n", "trg_tokens", ".", "append", "(", "trg_tokens_", ")", "\n", "\n", "", "if", "align", ":", "\n", "                    ", "weights_", "=", "batch_weights", "[", "sentence_id", "]", ".", "squeeze", "(", ")", "\n", "max_len_", "=", "weights_", ".", "shape", "[", "1", "]", "\n", "\n", "if", "self", ".", "binary", "[", "0", "]", ":", "\n", "                        ", "src_tokens_", "=", "None", "\n", "", "else", ":", "\n", "                        ", "src_tokens_", "=", "src_tokens", "[", "0", "]", ".", "split", "(", ")", "[", ":", "max_len_", "-", "1", "]", "+", "[", "utils", ".", "_EOS", "]", "\n", "src_tokens_", "=", "[", "token", "if", "token", "in", "self", ".", "src_vocab", "[", "0", "]", ".", "vocab", "else", "utils", ".", "_UNK", "for", "token", "in", "src_tokens_", "]", "\n", "weights_", "=", "weights_", "[", ":", ",", ":", "len", "(", "src_tokens_", ")", "]", "\n", "\n", "", "trg_tokens_", "=", "trg_tokens", "[", "0", "]", "[", ":", "weights_", ".", "shape", "[", "0", "]", "-", "1", "]", "+", "[", "utils", ".", "_EOS", "]", "\n", "weights_", "=", "weights_", "[", ":", "len", "(", "trg_tokens_", ")", "]", "\n", "output_file", "=", "output", "and", "'{}.{}.pdf'", ".", "format", "(", "output", ",", "line_id", ")", "\n", "utils", ".", "heatmap", "(", "src_tokens_", ",", "trg_tokens_", ",", "weights_", ",", "reverse", "=", "reverse", ",", "output_file", "=", "output_file", ")", "\n", "\n", "", "if", "self", ".", "debug", "or", "unk_replace", ":", "\n", "                    ", "weights", "=", "batch_weights", "[", "sentence_id", "]", "\n", "src_words", "=", "src_tokens", "[", "0", "]", ".", "split", "(", ")", "\n", "align_ids", "=", "np", ".", "argmax", "(", "weights", "[", ":", ",", ":", "len", "(", "src_words", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "align_ids", "=", "[", "0", "]", "*", "len", "(", "trg_tokens", "[", "0", "]", ")", "\n", "", "def", "replace", "(", "token", ",", "align_id", ")", ":", "\n", "                    ", "if", "self", ".", "debug", "and", "(", "not", "unk_replace", "or", "token", "==", "utils", ".", "_UNK", ")", ":", "\n", "                        ", "suffix", "=", "'({})'", ".", "format", "(", "align_id", ")", "\n", "", "else", ":", "\n", "                        ", "suffix", "=", "''", "\n", "", "if", "token", "==", "utils", ".", "_UNK", "and", "unk_replace", ":", "\n", "                        ", "token", "=", "src_words", "[", "align_id", "]", "\n", "if", "not", "token", "[", "0", "]", ".", "isupper", "(", ")", "and", "self", ".", "lexicon", "is", "not", "None", "and", "token", "in", "self", ".", "lexicon", ":", "\n", "                            ", "token", "=", "self", ".", "lexicon", "[", "token", "]", "\n", "", "", "return", "token", "+", "suffix", "\n", "\n", "", "trg_tokens", "[", "0", "]", "=", "[", "replace", "(", "token", ",", "align_id", ")", "for", "align_id", ",", "token", "in", "zip", "(", "align_ids", ",", "trg_tokens", "[", "0", "]", ")", "]", "\n", "\n", "if", "self", ".", "pred_edits", ":", "\n", "# first output is ops, second output is words", "\n", "                    ", "raw_hypothesis", "=", "' '", ".", "join", "(", "'_'", ".", "join", "(", "tokens", ")", "for", "tokens", "in", "zip", "(", "*", "trg_tokens", ")", ")", "\n", "src_words", "=", "src_tokens", "[", "0", "]", ".", "split", "(", ")", "\n", "trg_tokens", "=", "utils", ".", "reverse_edits", "(", "src_words", ",", "trg_tokens", ",", "fix", "=", "fix_edits", ")", "\n", "trg_tokens", "=", "[", "token", "for", "token", "in", "trg_tokens", "if", "token", "not", "in", "utils", ".", "_START_VOCAB", "]", "\n", "# FIXME: char-level", "\n", "", "else", ":", "\n", "                    ", "trg_tokens", "=", "trg_tokens", "[", "0", "]", "\n", "raw_hypothesis", "=", "''", ".", "join", "(", "trg_tokens", ")", "if", "self", ".", "char_output", "else", "' '", ".", "join", "(", "trg_tokens", ")", "\n", "\n", "", "if", "remove_unk", ":", "\n", "                    ", "trg_tokens", "=", "[", "token", "for", "token", "in", "trg_tokens", "if", "token", "!=", "utils", ".", "_UNK", "]", "\n", "\n", "", "if", "self", ".", "char_output", ":", "\n", "                    ", "hypothesis", "=", "''", ".", "join", "(", "trg_tokens", ")", "\n", "", "else", ":", "\n", "                    ", "hypothesis", "=", "' '", ".", "join", "(", "trg_tokens", ")", ".", "replace", "(", "'@@ '", ",", "''", ")", "# merge subwords units", "\n", "\n", "", "yield", "hypothesis", ",", "raw_hypothesis", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.align": [[243, 281], ["translate.utils.read_lines", "enumerate", "len", "len", "Exception", "any", "itertools.islice", "translation_model.TranslationModel.seq2seq_model.step", "weights.squeeze.squeeze.squeeze", "translate.utils.heatmap", "translate.utils.sentence_to_token_ids", "zip", "len", "len", "lines[].split", "translation_model.TranslationModel.character_level.get"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines", "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.step", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.heatmap", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.sentence_to_token_ids"], ["", "", "", "def", "align", "(", "self", ",", "output", "=", "None", ",", "align_encoder_id", "=", "0", ",", "reverse", "=", "False", ",", "max_test_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "filenames", ".", "test", ")", "!=", "len", "(", "self", ".", "extensions", ")", ":", "\n", "            ", "raise", "Exception", "(", "'wrong number of input files'", ")", "\n", "\n", "", "binary", "=", "self", ".", "binary", "and", "any", "(", "self", ".", "binary", ")", "\n", "\n", "paths", "=", "self", ".", "filenames", ".", "test", "or", "[", "None", "]", "\n", "lines", "=", "utils", ".", "read_lines", "(", "paths", ",", "binary", "=", "self", ".", "binary", ")", "\n", "\n", "if", "max_test_size", ":", "\n", "            ", "lines", "=", "itertools", ".", "islice", "(", "lines", ",", "max_test_size", ")", "\n", "\n", "", "for", "line_id", ",", "lines", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "token_ids", "=", "[", "\n", "sentence", "if", "vocab", "is", "None", "else", "\n", "utils", ".", "sentence_to_token_ids", "(", "sentence", ",", "vocab", ".", "vocab", ",", "character_level", "=", "self", ".", "character_level", ".", "get", "(", "ext", ")", ")", "\n", "for", "ext", ",", "vocab", ",", "sentence", "in", "zip", "(", "self", ".", "extensions", ",", "self", ".", "vocabs", ",", "lines", ")", "\n", "]", "\n", "\n", "_", ",", "weights", "=", "self", ".", "seq2seq_model", ".", "step", "(", "data", "=", "[", "token_ids", "]", ",", "align", "=", "True", ",", "update_model", "=", "False", ")", "\n", "\n", "trg_vocab", "=", "self", ".", "trg_vocab", "[", "0", "]", "\n", "trg_token_ids", "=", "token_ids", "[", "len", "(", "self", ".", "src_ext", ")", "]", "\n", "trg_tokens", "=", "[", "trg_vocab", ".", "reverse", "[", "i", "]", "if", "i", "<", "len", "(", "trg_vocab", ".", "reverse", ")", "else", "utils", ".", "_UNK", "for", "i", "in", "trg_token_ids", "]", "\n", "\n", "weights", "=", "weights", "[", "0", "]", "# can contain a list of forward and backward attention (cf. reconstruction decoders)", "\n", "weights", "=", "weights", ".", "squeeze", "(", ")", "\n", "max_len", "=", "weights", ".", "shape", "[", "1", "]", "\n", "\n", "if", "binary", ":", "\n", "                ", "src_tokens", "=", "None", "\n", "", "else", ":", "\n", "                ", "src_tokens", "=", "lines", "[", "align_encoder_id", "]", ".", "split", "(", ")", "[", ":", "max_len", "-", "1", "]", "+", "[", "utils", ".", "_EOS", "]", "\n", "", "trg_tokens", "=", "trg_tokens", "[", ":", "weights", ".", "shape", "[", "0", "]", "-", "1", "]", "+", "[", "utils", ".", "_EOS", "]", "\n", "\n", "output_file", "=", "output", "and", "'{}.{}.pdf'", ".", "format", "(", "output", ",", "line_id", "+", "1", ")", "\n", "\n", "utils", ".", "heatmap", "(", "src_tokens", ",", "trg_tokens", ",", "weights", ",", "output_file", "=", "output_file", ",", "reverse", "=", "reverse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode": [[283, 319], ["translate.utils.log", "translate.utils.read_lines", "translation_model.TranslationModel.decode_batch", "open", "itertools.islice", "list", "output_file.write", "output_file.flush", "output_file.close"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode_batch"], ["", "", "def", "decode", "(", "self", ",", "output", "=", "None", ",", "remove_unk", "=", "False", ",", "raw_output", "=", "False", ",", "max_test_size", "=", "None", ",", "unk_replace", "=", "False", ",", "\n", "align", "=", "False", ",", "reverse", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "utils", ".", "log", "(", "'starting decoding'", ")", "\n", "\n", "# empty `test` means that we read from standard input, which is not possible with multiple encoders", "\n", "# assert len(self.src_ext) == 1 or self.filenames.test", "\n", "# check that there is the right number of files for decoding", "\n", "# assert not self.filenames.test or len(self.filenames.test) == len(self.src_ext)", "\n", "\n", "output_file", "=", "None", "\n", "try", ":", "\n", "            ", "output_file", "=", "sys", ".", "stdout", "if", "output", "is", "None", "else", "open", "(", "output", ",", "'w'", ")", "\n", "paths", "=", "self", ".", "filenames", ".", "test", "or", "[", "None", "]", "\n", "lines", "=", "utils", ".", "read_lines", "(", "paths", ",", "binary", "=", "self", ".", "binary", ")", "\n", "\n", "if", "max_test_size", ":", "\n", "                ", "lines", "=", "itertools", ".", "islice", "(", "lines", ",", "max_test_size", ")", "\n", "\n", "", "if", "not", "self", ".", "filenames", ".", "test", ":", "# interactive mode", "\n", "                ", "batch_size", "=", "1", "\n", "", "else", ":", "\n", "                ", "batch_size", "=", "self", ".", "batch_size", "\n", "lines", "=", "list", "(", "lines", ")", "\n", "\n", "", "hypothesis_iter", "=", "self", ".", "decode_batch", "(", "lines", ",", "batch_size", ",", "remove_unk", "=", "remove_unk", ",", "unk_replace", "=", "unk_replace", ",", "\n", "align", "=", "align", ",", "reverse", "=", "reverse", ",", "output", "=", "output", ")", "\n", "\n", "for", "hypothesis", ",", "raw", "in", "hypothesis_iter", ":", "\n", "                ", "if", "raw_output", ":", "\n", "                    ", "hypothesis", "=", "raw", "\n", "\n", "", "output_file", ".", "write", "(", "hypothesis", "+", "'\\n'", ")", "\n", "output_file", ".", "flush", "(", ")", "\n", "", "", "finally", ":", "\n", "            ", "if", "output_file", "is", "not", "None", ":", "\n", "                ", "output_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.evaluate": [[320, 458], ["translate.utils.log", "isinstance", "enumerate", "zip", "list", "list", "range", "score_info.insert", "translate.utils.log", "scores.append", "sum", "sum", "translate.utils.read_lines", "translate.utils.read_lines", "len", "len", "len", "references.append", "translation_model.TranslationModel.decode_batch", "enumerate", "score_info.append", "score_info.insert", "len", "map", "len", "len", "ref_[].strip().replace().replace", "len", "open", "zip", "[].decode", "[].decode.splitlines", "zip", "[].decode.splitlines.append", "open.close", "scores_.append", "map", "open.write", "open.flush", "getattr", "getattr.", "len", "len", "len", "ref_[].strip().replace", "translation_model.TranslationModel.seq2seq_model.step", "len", "len", "subprocess.Popen().communicate", "ref_[].strip", "subprocess.Popen"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode_batch", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode", "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.step"], ["", "", "", "def", "evaluate", "(", "self", ",", "score_functions", ",", "on_dev", "=", "True", ",", "output", "=", "None", ",", "remove_unk", "=", "False", ",", "max_dev_size", "=", "None", ",", "\n", "raw_output", "=", "False", ",", "fix_edits", "=", "True", ",", "max_test_size", "=", "None", ",", "post_process_script", "=", "None", ",", "\n", "unk_replace", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Decode a dev or test set, and perform evaluation with respect to gold standard, using the provided\n        scoring function. If `output` is defined, also save the decoding output to this file.\n        When evaluating development data (`on_dev` to True), several dev sets can be specified (`dev_prefix` parameter\n        in configuration files), and a score is computed for each of them.\n\n        :param score_function: name of the scoring function used to score and rank models (typically 'bleu_score')\n        :param on_dev: if True, evaluate the dev corpus, otherwise evaluate the test corpus\n        :param output: save the hypotheses to this file\n        :param remove_unk: remove the UNK symbols from the output\n        :param max_dev_size: maximum number of lines to read from dev files\n        :param max_test_size: maximum number of lines to read from test files\n        :param raw_output: save raw decoder output (don't do post-processing like UNK deletion or subword\n            concatenation). The evaluation is still done with the post-processed output.\n        :param fix_edits: when predicting edit operations, pad shorter hypotheses with KEEP symbols.\n        :return: scores of each corpus to evaluate\n        \"\"\"", "\n", "utils", ".", "log", "(", "'starting evaluation'", ")", "\n", "\n", "if", "on_dev", ":", "\n", "            ", "filenames", "=", "self", ".", "filenames", ".", "dev", "\n", "", "else", ":", "\n", "            ", "filenames", "=", "[", "self", ".", "filenames", ".", "test", "]", "\n", "\n", "# convert `output` into a list, for zip", "\n", "", "if", "isinstance", "(", "output", ",", "str", ")", ":", "\n", "            ", "output", "=", "[", "output", "]", "\n", "", "elif", "output", "is", "None", ":", "\n", "            ", "output", "=", "[", "None", "]", "*", "len", "(", "filenames", ")", "\n", "\n", "", "scores", "=", "[", "]", "\n", "\n", "# evaluation on multiple corpora", "\n", "for", "dev_id", ",", "(", "filenames_", ",", "output_", ",", "prefix", ")", "in", "enumerate", "(", "zip", "(", "filenames", ",", "output", ",", "self", ".", "dev_prefix", ")", ")", ":", "\n", "            ", "if", "self", ".", "ref_ext", "is", "not", "None", ":", "\n", "                ", "filenames_", "=", "filenames_", "[", ":", "len", "(", "self", ".", "src_ext", ")", "]", "+", "filenames_", "[", "-", "1", ":", "]", "\n", "\n", "", "if", "self", ".", "dev_batches", ":", "\n", "                ", "dev_batches", "=", "self", ".", "dev_batches", "[", "dev_id", "]", "\n", "dev_loss", "=", "sum", "(", "self", ".", "seq2seq_model", ".", "step", "(", "batch", ",", "update_model", "=", "False", ")", ".", "loss", "*", "len", "(", "batch", ")", "\n", "for", "batch", "in", "dev_batches", ")", "\n", "dev_loss", "/=", "sum", "(", "map", "(", "len", ",", "dev_batches", ")", ")", "\n", "", "else", ":", "# TODO", "\n", "                ", "dev_loss", "=", "0", "\n", "\n", "", "src_lines", "=", "list", "(", "utils", ".", "read_lines", "(", "filenames_", "[", ":", "len", "(", "self", ".", "src_ext", ")", "]", ",", "binary", "=", "self", ".", "binary", "[", ":", "len", "(", "self", ".", "src_ext", ")", "]", ")", ")", "\n", "trg_lines", "=", "list", "(", "utils", ".", "read_lines", "(", "[", "filenames_", "[", "len", "(", "self", ".", "src_ext", ")", "]", "]", ")", ")", "\n", "\n", "assert", "len", "(", "trg_lines", ")", "%", "len", "(", "src_lines", ")", "==", "0", "\n", "\n", "references", "=", "[", "]", "\n", "ref_count", "=", "len", "(", "trg_lines", ")", "//", "len", "(", "src_lines", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "src_lines", ")", ")", ":", "\n", "                ", "ref", "=", "trg_lines", "[", "i", "*", "ref_count", ":", "(", "i", "+", "1", ")", "*", "ref_count", "]", "\n", "ref", "=", "[", "ref_", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "'@@ '", ",", "''", ")", ".", "replace", "(", "'@@'", ",", "''", ")", "for", "ref_", "in", "ref", "]", "\n", "references", ".", "append", "(", "ref", ")", "\n", "\n", "", "if", "on_dev", "and", "max_dev_size", ":", "\n", "                ", "max_size", "=", "max_dev_size", "\n", "", "elif", "not", "on_dev", "and", "max_test_size", ":", "\n", "                ", "max_size", "=", "max_test_size", "\n", "", "else", ":", "\n", "                ", "max_size", "=", "len", "(", "src_lines", ")", "\n", "\n", "", "src_lines", "=", "src_lines", "[", ":", "max_size", "]", "\n", "references", "=", "references", "[", ":", "max_size", "]", "\n", "\n", "hypotheses", "=", "[", "]", "\n", "output_file", "=", "None", "\n", "try", ":", "\n", "                ", "if", "output_", "is", "not", "None", ":", "\n", "                    ", "output_file", "=", "open", "(", "output_", ",", "'w'", ")", "\n", "\n", "", "hypothesis_iter", "=", "self", ".", "decode_batch", "(", "src_lines", ",", "self", ".", "batch_size", ",", "remove_unk", "=", "remove_unk", ",", "\n", "fix_edits", "=", "fix_edits", ",", "unk_replace", "=", "unk_replace", ")", "\n", "if", "post_process_script", "is", "not", "None", ":", "\n", "                    ", "hypotheses", ",", "raw", "=", "zip", "(", "*", "hypothesis_iter", ")", "\n", "data", "=", "'\\n'", ".", "join", "(", "hypotheses", ")", ".", "encode", "(", ")", "\n", "data", "=", "Popen", "(", "[", "post_process_script", "]", ",", "stdout", "=", "PIPE", ",", "stdin", "=", "PIPE", ")", ".", "communicate", "(", "input", "=", "data", ")", "[", "0", "]", ".", "decode", "(", ")", "\n", "hypotheses", "=", "data", ".", "splitlines", "(", ")", "\n", "hypothesis_iter", "=", "zip", "(", "hypotheses", ",", "raw", ")", "\n", "\n", "", "for", "i", ",", "hypothesis", "in", "enumerate", "(", "hypothesis_iter", ")", ":", "\n", "                    ", "hypothesis", ",", "raw", "=", "hypothesis", "\n", "hypotheses", ".", "append", "(", "hypothesis", ")", "\n", "if", "output_file", "is", "not", "None", ":", "\n", "                        ", "if", "raw_output", ":", "\n", "                            ", "hypothesis", "=", "raw", "\n", "", "output_file", ".", "write", "(", "hypothesis", "+", "'\\n'", ")", "\n", "output_file", ".", "flush", "(", ")", "\n", "", "", "", "finally", ":", "\n", "                ", "if", "output_file", "is", "not", "None", ":", "\n", "                    ", "output_file", ".", "close", "(", ")", "\n", "\n", "", "", "scores_", "=", "[", "]", "\n", "summary", "=", "None", "\n", "\n", "for", "score_function", "in", "score_functions", ":", "\n", "                ", "try", ":", "\n", "                    ", "if", "score_function", "!=", "'bleu'", ":", "\n", "                        ", "references_", "=", "[", "ref", "[", "0", "]", "for", "ref", "in", "references", "]", "\n", "", "else", ":", "\n", "                        ", "references_", "=", "references", "\n", "\n", "", "if", "score_function", "==", "'loss'", ":", "\n", "                        ", "score", "=", "dev_loss", "\n", "reversed_", "=", "True", "\n", "", "else", ":", "\n", "                        ", "fun", "=", "getattr", "(", "evaluation", ",", "'corpus_'", "+", "score_function", ")", "\n", "try", ":", "\n", "                            ", "reversed_", "=", "fun", ".", "reversed", "\n", "", "except", "AttributeError", ":", "\n", "                            ", "reversed_", "=", "False", "\n", "", "score", ",", "score_summary", "=", "fun", "(", "hypotheses", ",", "references_", ")", "\n", "summary", "=", "summary", "or", "score_summary", "\n", "\n", "", "scores_", ".", "append", "(", "(", "score_function", ",", "score", ",", "reversed_", ")", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "score_info", "=", "[", "'{}={:.2f}'", ".", "format", "(", "key", ",", "value", ")", "for", "key", ",", "value", ",", "_", "in", "scores_", "]", "\n", "score_info", ".", "insert", "(", "0", ",", "prefix", ")", "\n", "if", "summary", ":", "\n", "                ", "score_info", ".", "append", "(", "summary", ")", "\n", "\n", "", "if", "self", ".", "name", "is", "not", "None", ":", "\n", "                ", "score_info", ".", "insert", "(", "0", ",", "self", ".", "name", ")", "\n", "\n", "", "utils", ".", "log", "(", "' '", ".", "join", "(", "map", "(", "str", ",", "score_info", ")", ")", ")", "\n", "\n", "# main score", "\n", "_", ",", "score", ",", "reversed_", "=", "scores_", "[", "0", "]", "\n", "scores", ".", "append", "(", "-", "score", "if", "reversed_", "else", "score", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.train": [[459, 483], ["translation_model.TranslationModel.init_training", "translate.utils.log", "translate.utils.log", "range", "translation_model.TranslationModel.baseline_step.eval", "translation_model.TranslationModel.seq2seq_model.reinforce_step", "translation_model.TranslationModel.train_step", "translation_model.TranslationModel.baseline_step.eval", "next", "translate.utils.log", "translation_model.TranslationModel.save", "translation_model.TranslationModel.save", "translation_model.TranslationModel.manage_best_checkpoints", "translation_model.TranslationModel.save"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.init_training", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.reinforce_step", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.train_step", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.manage_best_checkpoints", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save"], ["", "def", "train", "(", "self", ",", "baseline_steps", "=", "0", ",", "loss_function", "=", "'xent'", ",", "use_baseline", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "init_training", "(", "**", "kwargs", ")", "\n", "\n", "if", "(", "loss_function", "==", "'reinforce'", "and", "use_baseline", "and", "baseline_steps", ">", "0", "and", "\n", "self", ".", "baseline_step", ".", "eval", "(", ")", "<", "baseline_steps", ")", ":", "\n", "            ", "utils", ".", "log", "(", "'pre-training reinforce baseline'", ")", "\n", "for", "i", "in", "range", "(", "baseline_steps", "-", "self", ".", "baseline_step", ".", "eval", "(", ")", ")", ":", "\n", "                ", "self", ".", "seq2seq_model", ".", "reinforce_step", "(", "next", "(", "self", ".", "batch_iterator", ")", ",", "update_model", "=", "False", ",", "\n", "use_sgd", "=", "False", ",", "update_baseline", "=", "True", ")", "\n", "\n", "", "", "utils", ".", "log", "(", "'starting training'", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "train_step", "(", "loss_function", "=", "loss_function", ",", "use_baseline", "=", "use_baseline", ",", "**", "kwargs", ")", "\n", "", "except", "(", "utils", ".", "FinishedTrainingException", ",", "KeyboardInterrupt", ")", ":", "\n", "                ", "utils", ".", "log", "(", "'exiting...'", ")", "\n", "self", ".", "save", "(", ")", "\n", "return", "\n", "", "except", "utils", ".", "EvalException", ":", "\n", "                ", "self", ".", "save", "(", ")", "\n", "step", ",", "score", "=", "self", ".", "training", ".", "scores", "[", "-", "1", "]", "\n", "self", ".", "manage_best_checkpoints", "(", "step", ",", "score", ")", "\n", "", "except", "utils", ".", "CheckpointException", ":", "\n", "                ", "self", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.init_training": [[484, 508], ["translation_model.TranslationModel.read_data", "translation_model.TranslationModel.global_step.eval", "translation_model.TranslationModel.epoch.eval", "range", "kwargs.get", "kwargs.get", "next"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.read_data"], ["", "", "", "def", "init_training", "(", "self", ",", "sgd_after_n_epoch", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "read_data", "(", "**", "kwargs", ")", "\n", "self", ".", "epoch", "=", "self", ".", "batch_size", "*", "self", ".", "global_step", "//", "self", ".", "train_size", "\n", "\n", "global_step", "=", "self", ".", "global_step", ".", "eval", "(", ")", "\n", "epoch", "=", "self", ".", "epoch", ".", "eval", "(", ")", "\n", "if", "sgd_after_n_epoch", "is", "not", "None", "and", "epoch", ">=", "sgd_after_n_epoch", ":", "# already switched to SGD", "\n", "            ", "self", ".", "training", ".", "use_sgd", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "training", ".", "use_sgd", "=", "False", "\n", "\n", "", "if", "kwargs", ".", "get", "(", "'batch_mode'", ")", "!=", "'random'", "and", "not", "kwargs", ".", "get", "(", "'shuffle'", ")", ":", "\n", "# read all the data up to this step (only if the batch iteration method is deterministic)", "\n", "            ", "for", "_", "in", "range", "(", "global_step", ")", ":", "\n", "                ", "next", "(", "self", ".", "batch_iterator", ")", "\n", "\n", "# those parameters are used to track the progress of training", "\n", "", "", "self", ".", "training", ".", "time", "=", "0", "\n", "self", ".", "training", ".", "steps", "=", "0", "\n", "self", ".", "training", ".", "loss", "=", "0", "\n", "self", ".", "training", ".", "baseline_loss", "=", "0", "\n", "self", ".", "training", ".", "losses", "=", "[", "]", "\n", "self", ".", "training", ".", "last_decay", "=", "global_step", "\n", "self", ".", "training", ".", "scores", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.train_step": [[509, 597], ["time.time", "step_function", "getattr", "translation_model.TranslationModel.global_step.eval", "translation_model.TranslationModel.epoch.eval", "translate.utils.debug", "next", "time.time", "translate.utils.log", "translation_model.TranslationModel.training.losses.append", "os.path.join", "os.makedirs", "dict", "translation_model.TranslationModel.evaluate", "translation_model.TranslationModel.training.scores.append", "translation_model.TranslationModel.learning_rate.eval", "translation_model.TranslationModel.global_step.eval", "translation_model.TranslationModel.epoch.eval", "translation_model.TranslationModel.learning_rate_decay_op.eval", "translate.utils.debug", "translate.utils.debug", "translation_model.TranslationModel.learning_rate.eval", "os.path.join", "translation_model.TranslationModel.learning_rate.assign().eval", "len", "max", "translation_model.TranslationModel.learning_rate_decay_op.eval", "translation_model.TranslationModel.learning_rate.eval", "translation_model.TranslationModel.learning_rate.assign"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.evaluate", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug"], ["", "def", "train_step", "(", "self", ",", "steps_per_checkpoint", ",", "model_dir", ",", "steps_per_eval", "=", "None", ",", "max_steps", "=", "0", ",", "\n", "max_epochs", "=", "0", ",", "eval_burn_in", "=", "0", ",", "decay_if_no_progress", "=", "None", ",", "decay_after_n_epoch", "=", "None", ",", "\n", "decay_every_n_epoch", "=", "None", ",", "sgd_after_n_epoch", "=", "None", ",", "sgd_learning_rate", "=", "None", ",", "min_learning_rate", "=", "None", ",", "\n", "loss_function", "=", "'xent'", ",", "use_baseline", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "min_learning_rate", "is", "not", "None", "and", "self", ".", "learning_rate", ".", "eval", "(", ")", "<", "min_learning_rate", ":", "\n", "            ", "utils", ".", "debug", "(", "'learning rate is too small: stopping'", ")", "\n", "raise", "utils", ".", "FinishedTrainingException", "\n", "", "if", "0", "<", "max_steps", "<=", "self", ".", "global_step", ".", "eval", "(", ")", "or", "0", "<", "max_epochs", "<=", "self", ".", "epoch", ".", "eval", "(", ")", ":", "\n", "            ", "raise", "utils", ".", "FinishedTrainingException", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "loss_function", "==", "'reinforce'", ":", "\n", "            ", "step_function", "=", "self", ".", "seq2seq_model", ".", "reinforce_step", "\n", "", "else", ":", "\n", "            ", "step_function", "=", "self", ".", "seq2seq_model", ".", "step", "\n", "\n", "", "res", "=", "step_function", "(", "next", "(", "self", ".", "batch_iterator", ")", ",", "update_model", "=", "True", ",", "use_sgd", "=", "self", ".", "training", ".", "use_sgd", ",", "\n", "update_baseline", "=", "True", ")", "\n", "\n", "self", ".", "training", ".", "loss", "+=", "res", ".", "loss", "\n", "self", ".", "training", ".", "baseline_loss", "+=", "getattr", "(", "res", ",", "'baseline_loss'", ",", "0", ")", "\n", "\n", "self", ".", "training", ".", "time", "+=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "self", ".", "training", ".", "steps", "+=", "1", "\n", "\n", "global_step", "=", "self", ".", "global_step", ".", "eval", "(", ")", "\n", "epoch", "=", "self", ".", "epoch", ".", "eval", "(", ")", "\n", "\n", "if", "decay_after_n_epoch", "is", "not", "None", "and", "self", ".", "batch_size", "*", "global_step", ">=", "decay_after_n_epoch", "*", "self", ".", "train_size", ":", "\n", "            ", "if", "decay_every_n_epoch", "is", "not", "None", "and", "(", "self", ".", "batch_size", "*", "(", "global_step", "-", "self", ".", "training", ".", "last_decay", ")", "\n", ">=", "decay_every_n_epoch", "*", "self", ".", "train_size", ")", ":", "\n", "                ", "self", ".", "learning_rate_decay_op", ".", "eval", "(", ")", "\n", "utils", ".", "debug", "(", "'  decaying learning rate to: {:.3g}'", ".", "format", "(", "self", ".", "learning_rate", ".", "eval", "(", ")", ")", ")", "\n", "self", ".", "training", ".", "last_decay", "=", "global_step", "\n", "\n", "", "", "if", "sgd_after_n_epoch", "is", "not", "None", "and", "epoch", ">=", "sgd_after_n_epoch", ":", "\n", "            ", "if", "not", "self", ".", "training", ".", "use_sgd", ":", "\n", "                ", "utils", ".", "debug", "(", "'epoch {}, starting to use SGD'", ".", "format", "(", "epoch", "+", "1", ")", ")", "\n", "self", ".", "training", ".", "use_sgd", "=", "True", "\n", "if", "sgd_learning_rate", "is", "not", "None", ":", "\n", "                    ", "self", ".", "learning_rate", ".", "assign", "(", "sgd_learning_rate", ")", ".", "eval", "(", ")", "\n", "", "self", ".", "training", ".", "last_decay", "=", "global_step", "# reset learning rate decay", "\n", "\n", "", "", "if", "steps_per_checkpoint", "and", "global_step", "%", "steps_per_checkpoint", "==", "0", ":", "\n", "            ", "loss", "=", "self", ".", "training", ".", "loss", "/", "self", ".", "training", ".", "steps", "\n", "baseline_loss", "=", "self", ".", "training", ".", "baseline_loss", "/", "self", ".", "training", ".", "steps", "\n", "step_time", "=", "self", ".", "training", ".", "time", "/", "self", ".", "training", ".", "steps", "\n", "\n", "summary", "=", "'step {} epoch {} learning rate {:.3g} step-time {:.3f} loss {:.3f}'", ".", "format", "(", "\n", "global_step", ",", "epoch", "+", "1", ",", "self", ".", "learning_rate", ".", "eval", "(", ")", ",", "step_time", ",", "loss", ")", "\n", "\n", "if", "self", ".", "name", "is", "not", "None", ":", "\n", "                ", "summary", "=", "'{} {}'", ".", "format", "(", "self", ".", "name", ",", "summary", ")", "\n", "", "if", "use_baseline", "and", "loss_function", "==", "'reinforce'", ":", "\n", "                ", "summary", "=", "'{} baseline-loss {:.4f}'", ".", "format", "(", "summary", ",", "baseline_loss", ")", "\n", "\n", "", "utils", ".", "log", "(", "summary", ")", "\n", "\n", "if", "decay_if_no_progress", "and", "len", "(", "self", ".", "training", ".", "losses", ")", ">=", "decay_if_no_progress", ":", "\n", "                ", "if", "loss", ">=", "max", "(", "self", ".", "training", ".", "losses", "[", ":", "decay_if_no_progress", "]", ")", ":", "\n", "                    ", "self", ".", "learning_rate_decay_op", ".", "eval", "(", ")", "\n", "\n", "", "", "self", ".", "training", ".", "losses", ".", "append", "(", "loss", ")", "\n", "self", ".", "training", ".", "loss", ",", "self", ".", "training", ".", "time", ",", "self", ".", "training", ".", "steps", ",", "self", ".", "training", ".", "baseline_loss", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "", "if", "steps_per_eval", "and", "global_step", "%", "steps_per_eval", "==", "0", "and", "0", "<=", "eval_burn_in", "<=", "global_step", ":", "\n", "\n", "            ", "eval_dir", "=", "'eval'", "if", "self", ".", "name", "is", "None", "else", "'eval_{}'", ".", "format", "(", "self", ".", "name", ")", "\n", "eval_output", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "eval_dir", ")", "\n", "\n", "os", ".", "makedirs", "(", "eval_output", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# if there are several dev files, we define several output files", "\n", "output", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "eval_output", ",", "'{}.{}.out'", ".", "format", "(", "prefix", ",", "global_step", ")", ")", "\n", "for", "prefix", "in", "self", ".", "dev_prefix", "\n", "]", "\n", "\n", "kwargs_", "=", "dict", "(", "kwargs", ")", "\n", "kwargs_", "[", "'output'", "]", "=", "output", "\n", "score", ",", "*", "_", "=", "self", ".", "evaluate", "(", "on_dev", "=", "True", ",", "**", "kwargs_", ")", "\n", "self", ".", "training", ".", "scores", ".", "append", "(", "(", "global_step", ",", "score", ")", ")", "\n", "\n", "", "if", "steps_per_eval", "and", "global_step", "%", "steps_per_eval", "==", "0", ":", "\n", "            ", "raise", "utils", ".", "EvalException", "\n", "", "elif", "steps_per_checkpoint", "and", "global_step", "%", "steps_per_checkpoint", "==", "0", ":", "\n", "            ", "raise", "utils", ".", "CheckpointException", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.manage_best_checkpoints": [[598, 651], ["os.path.join", "any", "scores.append", "translate.utils.warn", "sorted", "os.path.join", "any", "all", "os.listdir", "sorted", "open", "open", "translate.utils.log", "filename.startswith", "os.listdir", "f.write", "filename.replace", "shutil.copy", "filename.startswith", "float", "int", "translation_model.TranslationModel.manage_best_checkpoints.full_path"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.warn", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "", "def", "manage_best_checkpoints", "(", "self", ",", "step", ",", "score", ")", ":", "\n", "        ", "score_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'scores.txt'", ")", "\n", "# try loading previous scores", "\n", "try", ":", "\n", "            ", "with", "open", "(", "score_filename", ")", "as", "f", ":", "\n", "# list of pairs (score, step)", "\n", "                ", "scores", "=", "[", "(", "float", "(", "line", ".", "split", "(", ")", "[", "0", "]", ")", ",", "int", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", ")", "for", "line", "in", "f", "]", "\n", "", "", "except", "IOError", ":", "\n", "            ", "scores", "=", "[", "]", "\n", "\n", "", "if", "any", "(", "step_", ">=", "step", "for", "_", ",", "step_", "in", "scores", ")", ":", "\n", "            ", "utils", ".", "warn", "(", "'inconsistent scores.txt file'", ")", "\n", "\n", "", "best_scores", "=", "sorted", "(", "scores", ",", "reverse", "=", "True", ")", "[", ":", "self", ".", "keep_best", "]", "\n", "\n", "def", "full_path", "(", "filename", ")", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "filename", ")", "\n", "\n", "", "if", "any", "(", "score_", "<", "score", "for", "score_", ",", "_", "in", "best_scores", ")", "or", "not", "best_scores", ":", "\n", "# if this checkpoint is in the top, save it under a special name", "\n", "\n", "            ", "prefix", "=", "'translate-{}.'", ".", "format", "(", "step", ")", "\n", "dest_prefix", "=", "'best-{}.'", ".", "format", "(", "step", ")", "\n", "\n", "absolute_best", "=", "all", "(", "score_", "<", "score", "for", "score_", ",", "_", "in", "best_scores", ")", "\n", "if", "absolute_best", ":", "\n", "                ", "utils", ".", "log", "(", "'new best model'", ")", "\n", "\n", "", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "                ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "                    ", "dest_filename", "=", "filename", ".", "replace", "(", "prefix", ",", "dest_prefix", ")", "\n", "shutil", ".", "copy", "(", "full_path", "(", "filename", ")", ",", "full_path", "(", "dest_filename", ")", ")", "\n", "\n", "# also copy to `best` if this checkpoint is the absolute best", "\n", "if", "absolute_best", ":", "\n", "                        ", "dest_filename", "=", "filename", ".", "replace", "(", "prefix", ",", "'best.'", ")", "\n", "shutil", ".", "copy", "(", "full_path", "(", "filename", ")", ",", "full_path", "(", "dest_filename", ")", ")", "\n", "\n", "", "", "", "best_scores", "=", "sorted", "(", "best_scores", "+", "[", "(", "score", ",", "step", ")", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "_", ",", "step_", "in", "best_scores", "[", "self", ".", "keep_best", ":", "]", ":", "\n", "# remove checkpoints that are not in the top anymore", "\n", "                ", "prefix", "=", "'best-{}'", ".", "format", "(", "step_", ")", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "                    ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "                        ", "os", ".", "remove", "(", "full_path", "(", "filename", ")", ")", "\n", "\n", "# save scores", "\n", "", "", "", "", "scores", ".", "append", "(", "(", "score", ",", "step", ")", ")", "\n", "\n", "with", "open", "(", "score_filename", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "score_", ",", "step_", "in", "scores", ":", "\n", "                ", "f", ".", "write", "(", "'{:.2f} {}\\n'", ".", "format", "(", "score_", ",", "step_", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.initialize": [[652, 727], ["tensorflow.train.Saver", "sess.run", "zip", "list.append", "translate.utils.debug", "translate.utils.debug", "tensorflow.get_default_session", "float", "tensorflow.global_variables_initializer", "list.append", "list.append", "kwargs.get", "enumerate", "translate.utils.log", "open", "list", "open", "list", "len", "len", "len", "translation_model.load_checkpoint", "translation_model.TranslationModel.global_step.eval", "translation_model.TranslationModel.baseline_step.eval", "open", "sum", "len", "numpy.sqrt", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable.eval", "vocab.vocab.items", "sess.run", "translation_model.load_checkpoint", "translation_model.load_checkpoint", "line.split", "embeddings.values", "sum", "len", "tensorflow.get_variable_scope", "tensorflow.get_variable.assign", "line.strip", "line.strip", "numpy.array", "list", "map", "embeddings.values", "vector.split"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.load_checkpoint", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.load_checkpoint", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.load_checkpoint"], ["", "", "", "def", "initialize", "(", "self", ",", "checkpoints", "=", "None", ",", "reset", "=", "False", ",", "reset_learning_rate", "=", "False", ",", "max_to_keep", "=", "1", ",", "\n", "keep_every_n_hours", "=", "0", ",", "sess", "=", "None", ",", "whitelist", "=", "None", ",", "blacklist", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param checkpoints: list of checkpoints to load (instead of latest checkpoint)\n        :param reset: don't load latest checkpoint, reset learning rate and global step\n        :param reset_learning_rate: reset the learning rate to its initial value\n        :param max_to_keep: keep this many latest checkpoints at all times\n        :param keep_every_n_hours: and keep checkpoints every n hours\n        \"\"\"", "\n", "sess", "=", "sess", "or", "tf", ".", "get_default_session", "(", ")", "\n", "\n", "if", "keep_every_n_hours", "<=", "0", "or", "keep_every_n_hours", "is", "None", ":", "\n", "            ", "keep_every_n_hours", "=", "float", "(", "'inf'", ")", "\n", "\n", "", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "max_to_keep", ",", "keep_checkpoint_every_n_hours", "=", "keep_every_n_hours", ",", "\n", "sharded", "=", "False", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# load pre-trained embeddings", "\n", "for", "encoder_or_decoder", ",", "vocab", "in", "zip", "(", "self", ".", "encoders", "+", "self", ".", "decoders", ",", "self", ".", "vocabs", ")", ":", "\n", "            ", "if", "encoder_or_decoder", ".", "embedding_file", ":", "\n", "                ", "utils", ".", "log", "(", "'loading embeddings from: {}'", ".", "format", "(", "encoder_or_decoder", ".", "embedding_file", ")", ")", "\n", "embeddings", "=", "{", "}", "\n", "with", "open", "(", "encoder_or_decoder", ".", "embedding_file", ")", "as", "embedding_file", ":", "\n", "                    ", "for", "line", "in", "embedding_file", ":", "\n", "                        ", "word", ",", "vector", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "if", "word", "in", "vocab", ".", "vocab", ":", "\n", "                            ", "embeddings", "[", "word", "]", "=", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "vector", ".", "split", "(", ")", ")", ")", ")", "\n", "# standardize (mean of 0, std of 0.01)", "\n", "", "", "", "mean", "=", "sum", "(", "embeddings", ".", "values", "(", ")", ")", "/", "len", "(", "embeddings", ")", "\n", "std", "=", "np", ".", "sqrt", "(", "sum", "(", "(", "value", "-", "mean", ")", "**", "2", "for", "value", "in", "embeddings", ".", "values", "(", ")", ")", ")", "/", "(", "len", "(", "embeddings", ")", "-", "1", ")", "\n", "for", "key", "in", "embeddings", ":", "\n", "                    ", "embeddings", "[", "key", "]", "=", "0.01", "*", "(", "embeddings", "[", "key", "]", "-", "mean", ")", "/", "std", "\n", "\n", "# change TensorFlow variable's value", "\n", "", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "True", ")", ":", "\n", "                    ", "embedding_var", "=", "tf", ".", "get_variable", "(", "'embedding_'", "+", "encoder_or_decoder", ".", "name", ")", "\n", "embedding_value", "=", "embedding_var", ".", "eval", "(", ")", "\n", "for", "word", ",", "i", "in", "vocab", ".", "vocab", ".", "items", "(", ")", ":", "\n", "                        ", "if", "word", "in", "embeddings", ":", "\n", "                            ", "embedding_value", "[", "i", "]", "=", "embeddings", "[", "word", "]", "\n", "", "", "sess", ".", "run", "(", "embedding_var", ".", "assign", "(", "embedding_value", ")", ")", "\n", "\n", "", "", "", "if", "whitelist", ":", "\n", "            ", "with", "open", "(", "whitelist", ")", "as", "f", ":", "\n", "                ", "whitelist", "=", "list", "(", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ")", "\n", "", "", "if", "blacklist", ":", "\n", "            ", "with", "open", "(", "blacklist", ")", "as", "f", ":", "\n", "                ", "blacklist", "=", "list", "(", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "blacklist", "=", "[", "]", "\n", "\n", "", "blacklist", ".", "append", "(", "'dropout_keep_prob'", ")", "\n", "\n", "if", "reset_learning_rate", "or", "reset", ":", "\n", "            ", "blacklist", ".", "append", "(", "'learning_rate'", ")", "\n", "", "if", "reset", ":", "\n", "            ", "blacklist", ".", "append", "(", "'global_step'", ")", "\n", "\n", "", "params", "=", "{", "k", ":", "kwargs", ".", "get", "(", "k", ")", "for", "k", "in", "(", "'variable_mapping'", ",", "'reverse_mapping'", ")", "}", "\n", "\n", "if", "checkpoints", "and", "len", "(", "self", ".", "models", ")", ">", "1", ":", "\n", "            ", "assert", "len", "(", "self", ".", "models", ")", "==", "len", "(", "checkpoints", ")", "\n", "for", "i", ",", "checkpoint", "in", "enumerate", "(", "checkpoints", ",", "1", ")", ":", "\n", "                ", "load_checkpoint", "(", "sess", ",", "None", ",", "checkpoint", ",", "blacklist", "=", "blacklist", ",", "whitelist", "=", "whitelist", ",", "\n", "prefix", "=", "'model_{}'", ".", "format", "(", "i", ")", ",", "**", "params", ")", "\n", "", "", "elif", "checkpoints", ":", "# load partial checkpoints", "\n", "            ", "for", "checkpoint", "in", "checkpoints", ":", "# checkpoint files to load", "\n", "                ", "load_checkpoint", "(", "sess", ",", "None", ",", "checkpoint", ",", "blacklist", "=", "blacklist", ",", "whitelist", "=", "whitelist", ",", "**", "params", ")", "\n", "", "", "elif", "not", "reset", ":", "\n", "            ", "load_checkpoint", "(", "sess", ",", "self", ".", "checkpoint_dir", ",", "blacklist", "=", "blacklist", ",", "whitelist", "=", "whitelist", ",", "**", "params", ")", "\n", "\n", "", "utils", ".", "debug", "(", "'global step: {}'", ".", "format", "(", "self", ".", "global_step", ".", "eval", "(", ")", ")", ")", "\n", "utils", ".", "debug", "(", "'baseline step: {}'", ".", "format", "(", "self", ".", "baseline_step", ".", "eval", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save": [[728, 730], ["translation_model.save_checkpoint", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.save_checkpoint"], ["", "def", "save", "(", "self", ")", ":", "\n", "        ", "save_checkpoint", "(", "tf", ".", "get_default_session", "(", ")", ",", "self", ".", "saver", ",", "self", ".", "checkpoint_dir", ",", "self", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.load_checkpoint": [[739, 802], ["tensorflow.global_variables", "os.path.join", "os.path.exists", "dict", "list", "list", "tensorflow.train.get_checkpoint_state", "os.path.dirname", "list", "var_names_.append", "zip", "translate.utils.log", "tensorflow.train.Saver().restore", "translate.utils.debug", "sorted", "var.name.startswith", "dict.append", "var_names.append", "open", "pickle.load", "re.sub", "re.sub", "list", "name_mapping.items", "variables.values", "translate.utils.debug", "name_mapping.values", "tensorflow.train.Saver", "len", "any", "var.get_shape", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape"], ["def", "load_checkpoint", "(", "sess", ",", "checkpoint_dir", ",", "filename", "=", "None", ",", "blacklist", "=", "(", ")", ",", "prefix", "=", "None", ",", "variable_mapping", "=", "None", ",", "\n", "whitelist", "=", "None", ",", "reverse_mapping", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    if `filename` is None, we load last checkpoint, otherwise\n      we ignore `checkpoint_dir` and load the given checkpoint file.\n    \"\"\"", "\n", "variable_mapping", "=", "variable_mapping", "or", "[", "]", "\n", "reverse_mapping", "=", "reverse_mapping", "or", "[", "]", "\n", "\n", "variable_mapping", "=", "list", "(", "variable_mapping", ")", "+", "global_variable_mapping", "\n", "reverse_mapping", "=", "list", "(", "reverse_mapping", ")", "+", "global_reverse_mapping", "\n", "\n", "if", "filename", "is", "None", ":", "\n", "# load last checkpoint", "\n", "        ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "checkpoint_dir", ")", "\n", "if", "ckpt", "is", "not", "None", ":", "\n", "            ", "filename", "=", "ckpt", ".", "model_checkpoint_path", "\n", "", "", "else", ":", "\n", "        ", "checkpoint_dir", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "\n", "", "vars_", "=", "[", "]", "\n", "var_names", "=", "[", "]", "\n", "for", "var", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "        ", "if", "prefix", "is", "None", "or", "var", ".", "name", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "name", "=", "var", ".", "name", "if", "prefix", "is", "None", "else", "var", ".", "name", "[", "len", "(", "prefix", ")", "+", "1", ":", "]", "\n", "vars_", ".", "append", "(", "var", ")", "\n", "var_names", ".", "append", "(", "name", ")", "\n", "\n", "", "", "var_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'vars.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "var_file", ")", ":", "\n", "        ", "with", "open", "(", "var_file", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "old_names", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "old_names", "=", "list", "(", "var_names", ")", "\n", "\n", "", "name_mapping", "=", "{", "}", "\n", "for", "name", "in", "old_names", ":", "\n", "        ", "name_", "=", "name", "\n", "for", "key", ",", "value", "in", "variable_mapping", ":", "\n", "            ", "name_", "=", "re", ".", "sub", "(", "key", ",", "value", ",", "name_", ")", "\n", "", "name_mapping", "[", "name", "]", "=", "name_", "\n", "\n", "", "var_names_", "=", "[", "]", "\n", "for", "name", "in", "var_names", ":", "\n", "        ", "name_", "=", "name", "\n", "for", "key", ",", "value", "in", "reverse_mapping", ":", "\n", "            ", "name_", "=", "re", ".", "sub", "(", "key", ",", "value", ",", "name_", ")", "\n", "", "if", "name_", "in", "list", "(", "name_mapping", ".", "values", "(", ")", ")", ":", "\n", "            ", "name", "=", "name_", "\n", "", "var_names_", ".", "append", "(", "name", ")", "\n", "", "vars_", "=", "dict", "(", "zip", "(", "var_names_", ",", "vars_", ")", ")", "\n", "\n", "variables", "=", "{", "old_name", "[", ":", "-", "2", "]", ":", "vars_", "[", "new_name", "]", "for", "old_name", ",", "new_name", "in", "name_mapping", ".", "items", "(", ")", "\n", "if", "new_name", "in", "vars_", "and", "not", "any", "(", "prefix", "in", "new_name", "for", "prefix", "in", "blacklist", ")", "and", "\n", "(", "whitelist", "is", "None", "or", "new_name", "in", "whitelist", ")", "}", "\n", "\n", "if", "filename", "is", "not", "None", ":", "\n", "        ", "utils", ".", "log", "(", "'reading model parameters from {}'", ".", "format", "(", "filename", ")", ")", "\n", "tf", ".", "train", ".", "Saver", "(", "variables", ")", ".", "restore", "(", "sess", ",", "filename", ")", "\n", "\n", "utils", ".", "debug", "(", "'retrieved parameters ({})'", ".", "format", "(", "len", "(", "variables", ")", ")", ")", "\n", "for", "var", "in", "sorted", "(", "variables", ".", "values", "(", ")", ",", "key", "=", "lambda", "var", ":", "var", ".", "name", ")", ":", "\n", "            ", "utils", ".", "debug", "(", "'  {} {}'", ".", "format", "(", "var", ".", "name", ",", "var", ".", "get_shape", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.save_checkpoint": [[804, 818], ["os.path.join", "os.makedirs", "translate.utils.log", "os.path.join", "saver.save", "translate.utils.log", "open", "pickle.dump", "tensorflow.global_variables"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.save", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "", "", "def", "save_checkpoint", "(", "sess", ",", "saver", ",", "checkpoint_dir", ",", "step", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "var_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'vars.pkl'", ")", "\n", "name", "=", "name", "or", "'translate'", "\n", "os", ".", "makedirs", "(", "checkpoint_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "with", "open", "(", "var_file", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "var_names", "=", "[", "var", ".", "name", "for", "var", "in", "tf", ".", "global_variables", "(", ")", "]", "\n", "pickle", ".", "dump", "(", "var_names", ",", "f", ")", "\n", "\n", "", "utils", ".", "log", "(", "'saving model to {}'", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "name", ")", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "step", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "utils", ".", "log", "(", "'finished saving model'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.__main__.main": [[76, 303], ["parser.parse_args", "any", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "translate.utils.create_logger", "utils.create_logger.setLevel", "translate.utils.log", "translate.utils.log", "translate.utils.log", "translate.utils.log", "translate.utils.debug", "sorted", "isinstance", "os.path.join", "translate.utils.log", "translate.utils.log", "random.seed", "tensorflow.set_random_seed", "translate.utils.log", "translate.utils.log", "translate.utils.log", "sorted", "translate.utils.log", "tensorflow.ConfigProto", "open", "translate.utils.AttrDict", "open", "translate.utils.AttrDict", "vars().items", "utils.AttrDict.items", "translate.utils.log", "shutil.rmtree", "shutil.copy", "subprocess.check_output().decode().strip", "translate.utils.log", "utils.AttrDict.items", "translate.utils.debug", "utils.AttrDict.items", "random.randrange", "random.randrange", "str", "tensorflow.device", "tensorflow.get_variable_scope().set_initializer", "translate.utils.log", "var.get_shape", "tensorflow.global_variables", "tensorflow.Session", "os.path.join", "yaml.safe_load", "yaml.safe_load", "utils.AttrDict.setdefault", "os.path.exists", "open", "open", "config_file.read", "re.sub", "dest_file.write", "os.path.exists", "os.path.exists", "tarfile.open", "os.listdir", "operator.itemgetter", "translate.utils.AttrDict", "task.setdefault", "translate.utils.AttrDict", "translate.utils.AttrDict", "task.items", "translate.multitask_model.MultiTaskModel", "translate.translation_model.TranslationModel", "tensorflow.global_variables", "len", "main_sess.run", "translate.translation_model.TranslationModel.initialize", "os.path.dirname", "vars", "filename.endswith", "utils.AttrDict.description.strip().split", "subprocess.check_output().decode", "pprint.pformat", "encoder_or_decoder.setdefault", "tensorflow.random_uniform_initializer", "tensorflow.random_normal_initializer", "tensorflow.get_variable_scope", "var.name.startswith", "var.get_shape", "sum", "len", "var.assign", "len", "translate.translation_model.TranslationModel.initialize", "zip", "__main__.main.average_checkpoints"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.create_logger", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.initialize", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode", "home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.get_shape", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.initialize"], ["def", "main", "(", "args", "=", "None", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n", "# read config file and default config", "\n", "with", "open", "(", "'config/default.yaml'", ")", "as", "f", ":", "\n", "        ", "default_config", "=", "utils", ".", "AttrDict", "(", "yaml", ".", "safe_load", "(", "f", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "config", ")", "as", "f", ":", "\n", "        ", "config", "=", "utils", ".", "AttrDict", "(", "yaml", ".", "safe_load", "(", "f", ")", ")", "\n", "\n", "if", "args", ".", "learning_rate", "is", "not", "None", ":", "\n", "            ", "args", ".", "reset_learning_rate", "=", "True", "\n", "\n", "# command-line parameters have higher precedence than config file", "\n", "", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "not", "None", ":", "\n", "                ", "config", "[", "k", "]", "=", "v", "\n", "\n", "# set default values for parameters that are not defined", "\n", "", "", "for", "k", ",", "v", "in", "default_config", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "setdefault", "(", "k", ",", "v", ")", "\n", "\n", "", "", "if", "config", ".", "score_function", ":", "\n", "        ", "config", ".", "score_functions", "=", "evaluation", ".", "name_mapping", "[", "config", ".", "score_function", "]", "\n", "\n", "", "if", "args", ".", "crash_test", ":", "\n", "        ", "config", ".", "max_train_size", "=", "0", "\n", "\n", "", "if", "not", "config", ".", "debug", ":", "\n", "        ", "os", ".", "environ", "[", "'TF_CPP_MIN_LOG_LEVEL'", "]", "=", "'3'", "# disable TensorFlow's debugging logs", "\n", "", "decoding_mode", "=", "any", "(", "arg", "is", "not", "None", "for", "arg", "in", "(", "args", ".", "decode", ",", "args", ".", "eval", ",", "args", ".", "align", ")", ")", "\n", "\n", "# enforce parameter constraints", "\n", "assert", "config", ".", "steps_per_eval", "%", "config", ".", "steps_per_checkpoint", "==", "0", ",", "(", "\n", "'steps-per-eval should be a multiple of steps-per-checkpoint'", ")", "\n", "assert", "decoding_mode", "or", "args", ".", "train", "or", "args", ".", "save", ",", "(", "\n", "'you need to specify at least one action (decode, eval, align, or train)'", ")", "\n", "assert", "not", "(", "args", ".", "average", "and", "args", ".", "ensemble", ")", "\n", "\n", "if", "args", ".", "train", "and", "args", ".", "purge", ":", "\n", "        ", "utils", ".", "log", "(", "'deleting previous model'", ")", "\n", "shutil", ".", "rmtree", "(", "config", ".", "model_dir", ",", "ignore_errors", "=", "True", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "config", ".", "model_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# copy config file to model directory", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "model_dir", ",", "'config.yaml'", ")", "\n", "if", "args", ".", "train", "and", "not", "os", ".", "path", ".", "exists", "(", "config_path", ")", ":", "\n", "        ", "with", "open", "(", "args", ".", "config", ")", "as", "config_file", ",", "open", "(", "config_path", ",", "'w'", ")", "as", "dest_file", ":", "\n", "            ", "content", "=", "config_file", ".", "read", "(", ")", "\n", "content", "=", "re", ".", "sub", "(", "r'model_dir:.*?\\n'", ",", "'model_dir: {}\\n'", ".", "format", "(", "config", ".", "model_dir", ")", ",", "content", ",", "\n", "flags", "=", "re", ".", "MULTILINE", ")", "\n", "dest_file", ".", "write", "(", "content", ")", "\n", "\n", "# also copy default config", "\n", "", "", "config_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "model_dir", ",", "'default.yaml'", ")", "\n", "if", "args", ".", "train", "and", "not", "os", ".", "path", ".", "exists", "(", "config_path", ")", ":", "\n", "        ", "shutil", ".", "copy", "(", "'config/default.yaml'", ",", "config_path", ")", "\n", "\n", "# copy source code to model directory", "\n", "", "tar_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "model_dir", ",", "'code.tar.gz'", ")", "\n", "if", "args", ".", "train", "and", "not", "os", ".", "path", ".", "exists", "(", "tar_path", ")", ":", "\n", "        ", "with", "tarfile", ".", "open", "(", "tar_path", ",", "\"w:gz\"", ")", "as", "tar", ":", "\n", "            ", "for", "filename", "in", "os", ".", "listdir", "(", "'translate'", ")", ":", "\n", "                ", "if", "filename", ".", "endswith", "(", "'.py'", ")", ":", "\n", "                    ", "tar", ".", "add", "(", "os", ".", "path", ".", "join", "(", "'translate'", ",", "filename", ")", ",", "arcname", "=", "filename", ")", "\n", "\n", "", "", "", "", "logging_level", "=", "logging", ".", "DEBUG", "if", "args", ".", "verbose", "else", "logging", ".", "INFO", "\n", "# always log to stdout in decoding and eval modes (to avoid overwriting precious train logs)", "\n", "log_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "model_dir", ",", "config", ".", "log_file", ")", "\n", "logger", "=", "utils", ".", "create_logger", "(", "log_path", "if", "args", ".", "train", "else", "None", ")", "\n", "logger", ".", "setLevel", "(", "logging_level", ")", "\n", "\n", "utils", ".", "log", "(", "'label: {}'", ".", "format", "(", "config", ".", "label", ")", ")", "\n", "utils", ".", "log", "(", "'description:\\n  {}'", ".", "format", "(", "'\\n  '", ".", "join", "(", "config", ".", "description", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", ")", ")", ")", "\n", "\n", "utils", ".", "log", "(", "' '", ".", "join", "(", "sys", ".", "argv", ")", ")", "# print command line", "\n", "try", ":", "# print git hash", "\n", "        ", "commit_hash", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'HEAD'", "]", ")", ".", "decode", "(", ")", ".", "strip", "(", ")", "\n", "utils", ".", "log", "(", "'commit hash {}'", ".", "format", "(", "commit_hash", ")", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "utils", ".", "log", "(", "'tensorflow version: {}'", ".", "format", "(", "tf", ".", "__version__", ")", ")", "\n", "\n", "# log parameters", "\n", "utils", ".", "debug", "(", "'program arguments'", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "config", ".", "items", "(", ")", ",", "key", "=", "itemgetter", "(", "0", ")", ")", ":", "\n", "        ", "utils", ".", "debug", "(", "'  {:<20} {}'", ".", "format", "(", "k", ",", "pformat", "(", "v", ")", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "config", ".", "dev_prefix", ",", "str", ")", ":", "\n", "        ", "config", ".", "dev_prefix", "=", "[", "config", ".", "dev_prefix", "]", "\n", "\n", "", "if", "config", ".", "tasks", "is", "not", "None", ":", "\n", "        ", "config", ".", "tasks", "=", "[", "utils", ".", "AttrDict", "(", "task", ")", "for", "task", "in", "config", ".", "tasks", "]", "\n", "tasks", "=", "config", ".", "tasks", "\n", "", "else", ":", "\n", "        ", "tasks", "=", "[", "config", "]", "\n", "\n", "", "for", "task", "in", "tasks", ":", "\n", "        ", "for", "parameter", ",", "value", "in", "config", ".", "items", "(", ")", ":", "\n", "            ", "task", ".", "setdefault", "(", "parameter", ",", "value", ")", "\n", "\n", "", "task", ".", "encoders", "=", "[", "utils", ".", "AttrDict", "(", "encoder", ")", "for", "encoder", "in", "task", ".", "encoders", "]", "\n", "task", ".", "decoders", "=", "[", "utils", ".", "AttrDict", "(", "decoder", ")", "for", "decoder", "in", "task", ".", "decoders", "]", "\n", "\n", "for", "encoder_or_decoder", "in", "task", ".", "encoders", "+", "task", ".", "decoders", ":", "\n", "            ", "for", "parameter", ",", "value", "in", "task", ".", "items", "(", ")", ":", "\n", "                ", "encoder_or_decoder", ".", "setdefault", "(", "parameter", ",", "value", ")", "\n", "\n", "", "", "if", "args", ".", "max_len", ":", "\n", "            ", "args", ".", "max_input_len", "=", "args", ".", "max_len", "\n", "", "if", "args", ".", "max_output_len", ":", "# override decoder's max len", "\n", "            ", "task", ".", "decoders", "[", "0", "]", ".", "max_len", "=", "args", ".", "max_output_len", "\n", "", "if", "args", ".", "max_input_len", ":", "# override encoder's max len", "\n", "            ", "task", ".", "encoders", "[", "0", "]", ".", "max_len", "=", "args", ".", "max_input_len", "\n", "\n", "", "", "config", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "config", ".", "model_dir", ",", "'checkpoints'", ")", "\n", "\n", "# setting random seeds", "\n", "if", "config", ".", "seed", "is", "None", ":", "\n", "        ", "config", ".", "seed", "=", "random", ".", "randrange", "(", "sys", ".", "maxsize", ")", "\n", "", "if", "config", ".", "tf_seed", "is", "None", ":", "\n", "        ", "config", ".", "tf_seed", "=", "random", ".", "randrange", "(", "sys", ".", "maxsize", ")", "\n", "", "utils", ".", "log", "(", "'python random seed: {}'", ".", "format", "(", "config", ".", "seed", ")", ")", "\n", "utils", ".", "log", "(", "'tf random seed:     {}'", ".", "format", "(", "config", ".", "tf_seed", ")", ")", "\n", "random", ".", "seed", "(", "config", ".", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "config", ".", "tf_seed", ")", "\n", "\n", "device", "=", "None", "\n", "if", "config", ".", "no_gpu", ":", "\n", "        ", "device", "=", "'/cpu:0'", "\n", "device_id", "=", "None", "\n", "", "elif", "config", ".", "gpu_id", "is", "not", "None", ":", "\n", "        ", "device", "=", "'/gpu:{}'", ".", "format", "(", "config", ".", "gpu_id", ")", "\n", "device_id", "=", "config", ".", "gpu_id", "\n", "", "else", ":", "\n", "        ", "device_id", "=", "0", "\n", "\n", "# hide other GPUs so that TensorFlow won't use memory on them", "\n", "", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "''", "if", "device_id", "is", "None", "else", "str", "(", "device_id", ")", "\n", "\n", "utils", ".", "log", "(", "'creating model'", ")", "\n", "utils", ".", "log", "(", "'using device: {}'", ".", "format", "(", "device", ")", ")", "\n", "\n", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "        ", "if", "config", ".", "weight_scale", ":", "\n", "            ", "if", "config", ".", "initializer", "==", "'uniform'", ":", "\n", "                ", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "config", ".", "weight_scale", ",", "maxval", "=", "config", ".", "weight_scale", ")", "\n", "", "else", ":", "\n", "                ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "config", ".", "weight_scale", ")", "\n", "", "", "else", ":", "\n", "            ", "initializer", "=", "None", "\n", "\n", "", "tf", ".", "get_variable_scope", "(", ")", ".", "set_initializer", "(", "initializer", ")", "\n", "\n", "# exempt from creating gradient ops", "\n", "config", ".", "decode_only", "=", "decoding_mode", "\n", "\n", "if", "config", ".", "tasks", "is", "not", "None", ":", "\n", "            ", "model", "=", "MultiTaskModel", "(", "**", "config", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "TranslationModel", "(", "**", "config", ")", "\n", "\n", "# count parameters", "\n", "# not counting parameters created by training algorithm (e.g. Adam)", "\n", "", "", "variables", "=", "[", "var", "for", "var", "in", "tf", ".", "global_variables", "(", ")", "if", "not", "var", ".", "name", ".", "startswith", "(", "'gradients'", ")", "]", "\n", "utils", ".", "log", "(", "'model parameters ({})'", ".", "format", "(", "len", "(", "variables", ")", ")", ")", "\n", "parameter_count", "=", "0", "\n", "for", "var", "in", "sorted", "(", "variables", ",", "key", "=", "lambda", "var", ":", "var", ".", "name", ")", ":", "\n", "        ", "utils", ".", "log", "(", "'  {} {}'", ".", "format", "(", "var", ".", "name", ",", "var", ".", "get_shape", "(", ")", ")", ")", "\n", "v", "=", "1", "\n", "for", "d", "in", "var", ".", "get_shape", "(", ")", ":", "\n", "            ", "v", "*=", "d", ".", "value", "\n", "", "parameter_count", "+=", "v", "\n", "", "utils", ".", "log", "(", "'number of parameters: {:.2f}M'", ".", "format", "(", "parameter_count", "/", "1e6", ")", ")", "\n", "\n", "tf_config", "=", "tf", ".", "ConfigProto", "(", "log_device_placement", "=", "False", ",", "allow_soft_placement", "=", "True", ")", "\n", "tf_config", ".", "gpu_options", ".", "allow_growth", "=", "config", ".", "allow_growth", "\n", "tf_config", ".", "gpu_options", ".", "per_process_gpu_memory_fraction", "=", "config", ".", "mem_fraction", "\n", "\n", "def", "average_checkpoints", "(", "main_sess", ",", "sessions", ")", ":", "\n", "        ", "for", "var", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "            ", "avg_value", "=", "sum", "(", "sess", ".", "run", "(", "var", ")", "for", "sess", "in", "sessions", ")", "/", "len", "(", "sessions", ")", "\n", "main_sess", ".", "run", "(", "var", ".", "assign", "(", "avg_value", ")", ")", "\n", "\n", "", "", "with", "tf", ".", "Session", "(", "config", "=", "tf_config", ")", "as", "sess", ":", "\n", "        ", "best_checkpoint", "=", "os", ".", "path", ".", "join", "(", "config", ".", "checkpoint_dir", ",", "'best'", ")", "\n", "\n", "params", "=", "{", "'variable_mapping'", ":", "config", ".", "variable_mapping", ",", "'reverse_mapping'", ":", "config", ".", "reverse_mapping", "}", "\n", "if", "config", ".", "ensemble", "and", "len", "(", "config", ".", "checkpoints", ")", ">", "1", ":", "\n", "            ", "model", ".", "initialize", "(", "config", ".", "checkpoints", ",", "**", "params", ")", "\n", "", "elif", "config", ".", "average", "and", "len", "(", "config", ".", "checkpoints", ")", ">", "1", ":", "\n", "            ", "model", ".", "initialize", "(", "reset", "=", "True", ")", "\n", "sessions", "=", "[", "tf", ".", "Session", "(", "config", "=", "tf_config", ")", "for", "_", "in", "config", ".", "checkpoints", "]", "\n", "for", "sess_", ",", "checkpoint", "in", "zip", "(", "sessions", ",", "config", ".", "checkpoints", ")", ":", "\n", "                ", "model", ".", "initialize", "(", "sess", "=", "sess_", ",", "checkpoints", "=", "[", "checkpoint", "]", ",", "**", "params", ")", "\n", "", "average_checkpoints", "(", "sess", ",", "sessions", ")", "\n", "", "elif", "(", "not", "config", ".", "checkpoints", "and", "decoding_mode", "and", "\n", "(", "os", ".", "path", ".", "isfile", "(", "best_checkpoint", "+", "'.index'", ")", "or", "os", ".", "path", ".", "isfile", "(", "best_checkpoint", "+", "'.index'", ")", ")", ")", ":", "\n", "# in decoding and evaluation mode, unless specified otherwise (by `checkpoints`),", "\n", "# try to load the best checkpoint", "\n", "            ", "model", ".", "initialize", "(", "[", "best_checkpoint", "]", ",", "**", "params", ")", "\n", "", "else", ":", "\n", "# loads last checkpoint, unless `reset` is true", "\n", "            ", "model", ".", "initialize", "(", "**", "config", ")", "\n", "\n", "", "if", "config", ".", "output", "is", "not", "None", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "config", ".", "output", ")", "\n", "if", "dirname", ":", "\n", "                ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "", "try", ":", "\n", "            ", "if", "args", ".", "save", ":", "\n", "                ", "model", ".", "save", "(", ")", "\n", "", "elif", "args", ".", "decode", "is", "not", "None", ":", "\n", "                ", "if", "config", ".", "align", "is", "not", "None", ":", "\n", "                    ", "config", ".", "align", "=", "True", "\n", "", "model", ".", "decode", "(", "**", "config", ")", "\n", "", "elif", "args", ".", "eval", "is", "not", "None", ":", "\n", "                ", "model", ".", "evaluate", "(", "on_dev", "=", "False", ",", "**", "config", ")", "\n", "", "elif", "args", ".", "align", "is", "not", "None", ":", "\n", "                ", "model", ".", "align", "(", "**", "config", ")", "\n", "", "elif", "args", ".", "train", ":", "\n", "                ", "model", ".", "train", "(", "**", "config", ")", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.__init__": [[14, 117], ["tensorflow.group", "tensorflow.group", "tensorflow.constant", "tensorflow.constant", "tensorflow.placeholder", "tuple", "tensorflow.placeholder", "architecture", "seq2seq_model.Seq2SeqModel.get_optimizers", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "seq2seq_model.Seq2SeqModel.encoder_inputs.append", "seq2seq_model.Seq2SeqModel.encoder_input_length.append", "functools.partial", "translate.utils.AttrDict", "tensorflow.argmax", "tensorflow.placeholder", "functools.partial.", "encoder_or_decoder.get", "tensorflow.Variable", "dropout_on.append", "dropout_off.append", "functools.partial.", "functools.partial.", "tensorflow.Variable.assign", "tensorflow.Variable.assign", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_optimizers"], ["    ", "def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ",", "learning_rate", ",", "global_step", ",", "max_gradient_norm", ",", "use_dropout", "=", "False", ",", "\n", "freeze_variables", "=", "None", ",", "feed_previous", "=", "0.0", ",", "optimizer", "=", "'sgd'", ",", "decode_only", "=", "False", ",", "\n", "len_normalization", "=", "1.0", ",", "name", "=", "None", ",", "chained_encoders", "=", "False", ",", "baseline_step", "=", "None", ",", "\n", "use_baseline", "=", "True", ",", "reverse_input", "=", "False", ",", "reconstruction_decoders", "=", "False", ",", "multi_task", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "encoders", "=", "encoders", "\n", "self", ".", "decoders", "=", "decoders", "\n", "self", ".", "temperature", "=", "self", ".", "decoders", "[", "0", "]", ".", "temperature", "\n", "self", ".", "pred_edits", "=", "decoders", "[", "0", "]", ".", "pred_edits", "\n", "\n", "self", ".", "name", "=", "name", "\n", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "global_step", "=", "global_step", "\n", "self", ".", "baseline_step", "=", "baseline_step", "\n", "self", ".", "use_baseline", "=", "use_baseline", "\n", "\n", "self", ".", "max_output_len", "=", "[", "decoder", ".", "max_len", "for", "decoder", "in", "decoders", "]", "\n", "self", ".", "max_input_len", "=", "[", "encoder", ".", "max_len", "for", "encoder", "in", "encoders", "]", "\n", "self", ".", "len_normalization", "=", "len_normalization", "\n", "self", ".", "reverse_input", "=", "reverse_input", "\n", "\n", "dropout_on", "=", "[", "]", "\n", "dropout_off", "=", "[", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "            ", "for", "encoder_or_decoder", "in", "encoders", "+", "decoders", ":", "\n", "                ", "names", "=", "[", "'rnn_input'", ",", "'rnn_output'", ",", "'rnn_state'", ",", "'initial_state'", ",", "'word'", ",", "'input_layer'", ",", "'output'", ",", "\n", "'attn'", ",", "'deep_layer'", ",", "'inter_layer'", ",", "'embedding'", "]", "\n", "\n", "for", "name", "in", "names", ":", "\n", "                    ", "value", "=", "encoder_or_decoder", ".", "get", "(", "name", "+", "'_dropout'", ")", "\n", "var_name", "=", "name", "+", "'_keep_prob'", "\n", "if", "not", "value", ":", "\n", "                        ", "encoder_or_decoder", "[", "var_name", "]", "=", "1.0", "\n", "continue", "\n", "", "var", "=", "tf", ".", "Variable", "(", "1", "-", "value", ",", "trainable", "=", "False", ",", "name", "=", "var_name", ")", "\n", "encoder_or_decoder", "[", "var_name", "]", "=", "var", "\n", "dropout_on", ".", "append", "(", "var", ".", "assign", "(", "1.0", "-", "value", ")", ")", "\n", "dropout_off", ".", "append", "(", "var", ".", "assign", "(", "1.0", ")", ")", "\n", "\n", "", "", "", "self", ".", "dropout_on", "=", "tf", ".", "group", "(", "*", "dropout_on", ")", "\n", "self", ".", "dropout_off", "=", "tf", ".", "group", "(", "*", "dropout_off", ")", "\n", "\n", "self", ".", "feed_previous", "=", "tf", ".", "constant", "(", "feed_previous", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "feed_argmax", "=", "tf", ".", "constant", "(", "True", ",", "dtype", "=", "tf", ".", "bool", ")", "# feed with argmax or sample from softmax", "\n", "self", ".", "training", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "(", ")", ")", "\n", "\n", "self", ".", "encoder_inputs", "=", "[", "]", "\n", "self", ".", "encoder_input_length", "=", "[", "]", "\n", "for", "encoder", "in", "encoders", ":", "\n", "            ", "shape", "=", "[", "None", ",", "None", ",", "encoder", ".", "embedding_size", "]", "if", "encoder", ".", "binary", "else", "[", "None", ",", "None", "]", "\n", "dtype", "=", "tf", ".", "float32", "if", "encoder", ".", "binary", "else", "tf", ".", "int32", "\n", "encoder_input", "=", "tf", ".", "placeholder", "(", "dtype", "=", "dtype", ",", "shape", "=", "shape", ",", "name", "=", "'encoder_{}'", ".", "format", "(", "encoder", ".", "name", ")", ")", "\n", "encoder_input_length", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "\n", "name", "=", "'encoder_input_length_{}'", ".", "format", "(", "encoder", ".", "name", ")", ")", "\n", "self", ".", "encoder_inputs", ".", "append", "(", "encoder_input", ")", "\n", "self", ".", "encoder_input_length", ".", "append", "(", "encoder_input_length", ")", "\n", "\n", "# starts with BOS, and ends with EOS", "\n", "", "self", ".", "targets", "=", "tuple", "(", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'target_{}'", ".", "format", "(", "decoder", ".", "name", ")", ")", "\n", "for", "decoder", "in", "decoders", "\n", "]", ")", "\n", "self", ".", "rewards", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'rewards'", ")", "\n", "\n", "if", "reconstruction_decoders", ":", "\n", "            ", "architecture", "=", "models", ".", "reconstruction_encoder_decoder", "\n", "", "elif", "chained_encoders", "and", "self", ".", "pred_edits", ":", "\n", "            ", "architecture", "=", "models", ".", "chained_encoder_decoder", "# no REINFORCE for now", "\n", "", "elif", "multi_task", ":", "\n", "            ", "architecture", "=", "models", ".", "multi_task_encoder_decoder", "\n", "", "else", ":", "\n", "            ", "architecture", "=", "models", ".", "encoder_decoder", "\n", "\n", "", "tensors", "=", "architecture", "(", "encoders", ",", "decoders", ",", "self", ".", "encoder_inputs", ",", "self", ".", "targets", ",", "self", ".", "feed_previous", ",", "\n", "encoder_input_length", "=", "self", ".", "encoder_input_length", ",", "feed_argmax", "=", "self", ".", "feed_argmax", ",", "\n", "rewards", "=", "self", ".", "rewards", ",", "use_baseline", "=", "use_baseline", ",", "training", "=", "self", ".", "training", ",", "\n", "global_step", "=", "self", ".", "global_step", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "losses", ",", "self", ".", "outputs", ",", "self", ".", "attention_weights", ",", "self", ".", "samples", ",", "self", ".", "beam_fun", ",", "self", ".", "initial_data", "=", "tensors", "\n", "\n", "self", ".", "xent_loss", ",", "self", ".", "reinforce_loss", ",", "self", ".", "baseline_loss", "=", "self", ".", "losses", "\n", "self", ".", "loss", "=", "self", ".", "xent_loss", "# main loss", "\n", "\n", "optimizers", "=", "self", ".", "get_optimizers", "(", "optimizer", ",", "learning_rate", ")", "\n", "\n", "if", "not", "decode_only", ":", "\n", "            ", "get_update_ops", "=", "functools", ".", "partial", "(", "self", ".", "get_update_op", ",", "opts", "=", "optimizers", ",", "\n", "max_gradient_norm", "=", "max_gradient_norm", ",", "freeze_variables", "=", "freeze_variables", ")", "\n", "\n", "self", ".", "update_ops", "=", "utils", ".", "AttrDict", "(", "{", "\n", "'xent'", ":", "get_update_ops", "(", "self", ".", "xent_loss", ",", "global_step", "=", "self", ".", "global_step", ")", ",", "\n", "'reinforce'", ":", "get_update_ops", "(", "self", ".", "reinforce_loss", ",", "global_step", "=", "self", ".", "global_step", ")", ",", "\n", "}", ")", "\n", "\n", "if", "use_baseline", ":", "\n", "                ", "self", ".", "update_ops", "[", "'baseline'", "]", "=", "get_update_ops", "(", "self", ".", "baseline_loss", ",", "global_step", "=", "self", ".", "baseline_step", ")", "\n", "\n", "", "", "self", ".", "models", "=", "[", "self", "]", "\n", "self", ".", "beam_outputs", "=", "tf", ".", "expand_dims", "(", "tf", ".", "argmax", "(", "self", ".", "outputs", "[", "0", "]", ",", "axis", "=", "2", ")", ",", "axis", "=", "1", ")", "\n", "self", ".", "beam_scores", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "tf", ".", "shape", "(", "self", ".", "beam_outputs", ")", "[", "0", "]", ",", "1", "]", ")", "\n", "self", ".", "beam_size", "=", "tf", ".", "placeholder", "(", "shape", "=", "(", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.create_beam_op": [[118, 128], ["translate.beam_search.rnn_beam_search"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.beam_search.rnn_beam_search"], ["", "def", "create_beam_op", "(", "self", ",", "models", ",", "len_normalization", ")", ":", "\n", "        ", "self", ".", "len_normalization", "=", "len_normalization", "\n", "self", ".", "models", "=", "models", "\n", "beam_funs", "=", "[", "model", ".", "beam_fun", "for", "model", "in", "models", "]", "\n", "initial_data", "=", "[", "model", ".", "initial_data", "for", "model", "in", "models", "]", "\n", "beam_output", "=", "beam_search", ".", "rnn_beam_search", "(", "beam_funs", ",", "initial_data", ",", "self", ".", "max_output_len", "[", "0", "]", ",", "self", ".", "beam_size", ",", "\n", "len_normalization", ",", "temperature", "=", "self", ".", "temperature", ",", "\n", "parallel_iterations", "=", "self", ".", "decoders", "[", "0", "]", ".", "parallel_iterations", ",", "\n", "swap_memory", "=", "self", ".", "decoders", "[", "0", "]", ".", "swap_memory", ")", "\n", "self", ".", "beam_outputs", ",", "self", ".", "beam_scores", "=", "beam_output", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_optimizers": [[129, 142], ["tensorflow.train.GradientDescentOptimizer", "optimizer_name.lower", "tensorflow.train.AdadeltaOptimizer", "optimizer_name.lower", "tensorflow.train.AdamOptimizer"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_optimizers", "(", "optimizer_name", ",", "learning_rate", ")", ":", "\n", "        ", "sgd_opt", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "\n", "if", "optimizer_name", ".", "lower", "(", ")", "==", "'adadelta'", ":", "\n", "# same epsilon and rho as Bahdanau et al. 2015", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdadeltaOptimizer", "(", "learning_rate", "=", "learning_rate", ",", "epsilon", "=", "1e-06", ",", "rho", "=", "0.95", ")", "\n", "", "elif", "optimizer_name", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "            ", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "", "else", ":", "\n", "            ", "opt", "=", "sgd_opt", "\n", "\n", "", "return", "opt", ",", "sgd_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_update_op": [[143, 173], ["tensorflow.gradients", "tensorflow.clip_by_global_norm", "tensorflow.get_collection", "update_ops.append", "tensorflow.trainable_variables", "any", "tensorflow.trainable_variables", "tensorflow.variable_scope", "tensorflow.control_dependencies", "opt.apply_gradients", "re.match", "list", "zip"], "methods", ["None"], ["", "def", "get_update_op", "(", "self", ",", "loss", ",", "opts", ",", "global_step", "=", "None", ",", "max_gradient_norm", "=", "None", ",", "freeze_variables", "=", "None", ")", ":", "\n", "        ", "if", "loss", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "freeze_variables", "=", "freeze_variables", "or", "[", "]", "\n", "\n", "# compute gradient only for variables that are not frozen", "\n", "frozen_parameters", "=", "[", "var", ".", "name", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "if", "any", "(", "re", ".", "match", "(", "var_", ",", "var", ".", "name", ")", "for", "var_", "in", "freeze_variables", ")", "]", "\n", "params", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", "not", "in", "frozen_parameters", "]", "\n", "self", ".", "params", "=", "params", "\n", "\n", "gradients", "=", "tf", ".", "gradients", "(", "loss", ",", "params", ")", "\n", "\n", "# from translate.memory_saving_gradients import gradients as mem_save_gradients", "\n", "# gradients = mem_save_gradients(loss, params, checkpoints='speed')  # try 'memory'", "\n", "\n", "if", "max_gradient_norm", ":", "\n", "            ", "gradients", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "max_gradient_norm", ")", "\n", "\n", "", "update_ops", "=", "[", "]", "\n", "for", "opt", "in", "opts", ":", "\n", "            ", "update_ops_", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'gradients'", "if", "self", ".", "name", "is", "None", "else", "'gradients_{}'", ".", "format", "(", "self", ".", "name", ")", ")", ":", "\n", "                ", "with", "tf", ".", "control_dependencies", "(", "update_ops_", ")", ":", "# update batch_norm's moving averages", "\n", "                    ", "update_op", "=", "opt", ".", "apply_gradients", "(", "list", "(", "zip", "(", "gradients", ",", "params", ")", ")", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "", "update_ops", ".", "append", "(", "update_op", ")", "\n", "\n", "", "return", "update_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.reinforce_step": [[174, 224], ["seq2seq_model.Seq2SeqModel.get_batch", "range", "tensorflow.get_default_session().run", "getattr", "seq2seq_model.Seq2SeqModel.reinforce_step.compute_rewards"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_batch", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run"], ["", "def", "reinforce_step", "(", "self", ",", "data", ",", "update_model", "=", "True", ",", "align", "=", "False", ",", "use_sgd", "=", "False", ",", "update_baseline", "=", "True", ",", "\n", "reward_function", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# self.dropout_on.run()", "\n", "\n", "        ", "encoder_inputs", ",", "targets", ",", "input_length", "=", "self", ".", "get_batch", "(", "data", ")", "\n", "input_feed", "=", "{", "self", ".", "targets", ":", "targets", ",", "self", ".", "feed_argmax", ":", "False", ",", "self", ".", "feed_previous", ":", "1.0", ",", "self", ".", "training", ":", "True", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "encoders", ")", ")", ":", "\n", "            ", "input_feed", "[", "self", ".", "encoder_inputs", "[", "i", "]", "]", "=", "encoder_inputs", "[", "i", "]", "\n", "input_feed", "[", "self", ".", "encoder_input_length", "[", "i", "]", "]", "=", "input_length", "[", "i", "]", "\n", "\n", "", "samples", ",", "outputs", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "[", "self", ".", "samples", ",", "self", ".", "outputs", "]", ",", "input_feed", ")", "\n", "\n", "if", "reward_function", "is", "None", ":", "\n", "            ", "reward_function", "=", "'sentence_bleu'", "\n", "", "reward_function", "=", "getattr", "(", "evaluation", ",", "reward_function", ")", "\n", "\n", "def", "compute_reward", "(", "output", ",", "target", ")", ":", "\n", "            ", "j", ",", "=", "np", ".", "where", "(", "output", "==", "utils", ".", "EOS_ID", ")", "# array of indices whose value is EOS_ID", "\n", "if", "len", "(", "j", ")", ">", "0", ":", "\n", "                ", "output", "=", "output", "[", ":", "j", "[", "0", "]", "]", "\n", "\n", "", "j", ",", "=", "np", ".", "where", "(", "target", "==", "utils", ".", "EOS_ID", ")", "\n", "if", "len", "(", "j", ")", ">", "0", ":", "\n", "                ", "target", "=", "target", "[", ":", "j", "[", "0", "]", "]", "\n", "\n", "", "return", "reward_function", "(", "output", ",", "target", ")", "\n", "\n", "", "def", "compute_rewards", "(", "outputs", ",", "targets", ")", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "compute_reward", "(", "output", ",", "target", ")", "for", "output", ",", "target", "in", "zip", "(", "outputs", ",", "targets", ")", "]", ")", "\n", "\n", "", "rewards", "=", "compute_rewards", "(", "samples", ",", "targets", "[", "0", "]", "[", ":", ",", "1", ":", "]", ")", "\n", "rewards", "=", "np", ".", "stack", "(", "[", "rewards", "]", "*", "samples", ".", "shape", "[", "1", "]", ",", "axis", "=", "1", ")", "\n", "\n", "input_feed", "[", "self", ".", "outputs", "[", "0", "]", "]", "=", "outputs", "[", "0", "]", "\n", "input_feed", "[", "self", ".", "samples", "]", "=", "samples", "\n", "input_feed", "[", "self", ".", "rewards", "]", "=", "rewards", "\n", "\n", "output_feed", "=", "{", "'loss'", ":", "self", ".", "reinforce_loss", ",", "'baseline_loss'", ":", "self", ".", "baseline_loss", "}", "\n", "if", "update_model", ":", "\n", "            ", "output_feed", "[", "'update'", "]", "=", "self", ".", "update_ops", ".", "reinforce", "[", "1", "]", "if", "use_sgd", "else", "self", ".", "update_ops", ".", "reinforce", "[", "0", "]", "\n", "", "if", "self", ".", "use_baseline", "and", "update_baseline", ":", "\n", "            ", "output_feed", "[", "'baseline_update'", "]", "=", "self", ".", "update_ops", ".", "baseline", "[", "0", "]", "# FIXME", "\n", "\n", "", "if", "align", ":", "\n", "            ", "output_feed", "[", "'weights'", "]", "=", "self", ".", "attention_weights", "\n", "\n", "", "res", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "return", "namedtuple", "(", "'output'", ",", "'loss weights baseline_loss'", ")", "(", "res", "[", "'loss'", "]", ",", "res", ".", "get", "(", "'weights'", ")", ",", "\n", "res", ".", "get", "(", "'baseline_loss'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.step": [[225, 246], ["seq2seq_model.Seq2SeqModel.get_batch", "range", "tensorflow.get_default_session().run", "seq2seq_model.Seq2SeqModel.dropout_on.run", "seq2seq_model.Seq2SeqModel.dropout_off.run", "len", "collections.namedtuple", "tensorflow.get_default_session().run.get", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_batch", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run"], ["", "def", "step", "(", "self", ",", "data", ",", "update_model", "=", "True", ",", "align", "=", "False", ",", "use_sgd", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "update_model", ":", "\n", "            ", "self", ".", "dropout_on", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout_off", ".", "run", "(", ")", "\n", "\n", "", "encoder_inputs", ",", "targets", ",", "input_length", "=", "self", ".", "get_batch", "(", "data", ")", "\n", "input_feed", "=", "{", "self", ".", "targets", ":", "targets", ",", "self", ".", "training", ":", "True", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "encoders", ")", ")", ":", "\n", "            ", "input_feed", "[", "self", ".", "encoder_inputs", "[", "i", "]", "]", "=", "encoder_inputs", "[", "i", "]", "\n", "input_feed", "[", "self", ".", "encoder_input_length", "[", "i", "]", "]", "=", "input_length", "[", "i", "]", "\n", "\n", "", "output_feed", "=", "{", "'loss'", ":", "self", ".", "xent_loss", "}", "\n", "if", "update_model", ":", "\n", "            ", "output_feed", "[", "'update'", "]", "=", "self", ".", "update_ops", ".", "xent", "[", "1", "]", "if", "use_sgd", "else", "self", ".", "update_ops", ".", "xent", "[", "0", "]", "\n", "", "if", "align", ":", "\n", "            ", "output_feed", "[", "'weights'", "]", "=", "self", ".", "attention_weights", "\n", "\n", "", "res", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "return", "namedtuple", "(", "'output'", ",", "'loss weights'", ")", "(", "res", "[", "'loss'", "]", ",", "res", ".", "get", "(", "'weights'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.greedy_decoding": [[247, 274], ["seq2seq_model.Seq2SeqModel.get_batch", "tensorflow.get_default_session().run", "model.dropout_off.run", "range", "tensorflow.get_default_session().run.get", "len", "tensorflow.get_default_session", "len", "len"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_batch", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run", "home.repos.pwc.inspect_result.eske_seq2seq.None.run-tests.run"], ["", "def", "greedy_decoding", "(", "self", ",", "token_ids", ",", "align", "=", "False", ",", "beam_size", "=", "1", ")", ":", "\n", "        ", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "model", ".", "dropout_off", ".", "run", "(", ")", "\n", "\n", "", "data", "=", "[", "\n", "ids", "+", "[", "[", "]", "for", "_", "in", "self", ".", "decoders", "]", "if", "len", "(", "ids", ")", "==", "len", "(", "self", ".", "encoders", ")", "else", "ids", "\n", "for", "ids", "in", "token_ids", "\n", "]", "\n", "\n", "batch", "=", "self", ".", "get_batch", "(", "data", ",", "decoding", "=", "True", ")", "\n", "encoder_inputs", ",", "targets", ",", "input_length", "=", "batch", "\n", "\n", "input_feed", "=", "{", "self", ".", "beam_size", ":", "beam_size", "}", "\n", "for", "model", "in", "self", ".", "models", ":", "\n", "            ", "input_feed", "[", "model", ".", "targets", "]", "=", "targets", "\n", "input_feed", "[", "model", ".", "feed_previous", "]", "=", "1.0", "\n", "input_feed", "[", "model", ".", "training", "]", "=", "False", "\n", "for", "i", "in", "range", "(", "len", "(", "model", ".", "encoders", ")", ")", ":", "\n", "                ", "input_feed", "[", "model", ".", "encoder_inputs", "[", "i", "]", "]", "=", "encoder_inputs", "[", "i", "]", "\n", "input_feed", "[", "model", ".", "encoder_input_length", "[", "i", "]", "]", "=", "input_length", "[", "i", "]", "\n", "\n", "", "", "output_feed", "=", "{", "'outputs'", ":", "self", ".", "beam_outputs", "}", "\n", "if", "align", ":", "\n", "            ", "output_feed", "[", "'weights'", "]", "=", "self", ".", "attention_weights", "\n", "\n", "", "res", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "output_feed", ",", "input_feed", ")", "\n", "return", "[", "res", "[", "'outputs'", "]", "[", ":", ",", "0", ",", ":", "]", "]", ",", "res", ".", "get", "(", "'weights'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.seq2seq_model.Seq2SeqModel.get_batch": [[275, 336], ["max", "enumerate", "range", "numpy.array", "numpy.array", "numpy.array", "range", "min", "max", "zip", "inputs[].append", "input_length[].append", "len", "zip", "len", "len", "zip", "range", "min", "len", "len", "numpy.zeros", "targets[].append", "targets[].append", "len", "len", "zip", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "data", ",", "decoding", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param data:\n        :param decoding: set this parameter to True to output dummy\n          data for the decoder side (using the maximum output size)\n        :return:\n        \"\"\"", "\n", "inputs", "=", "[", "[", "]", "for", "_", "in", "self", ".", "encoders", "]", "\n", "targets", "=", "[", "[", "]", "for", "_", "in", "self", ".", "decoders", "]", "\n", "input_length", "=", "[", "[", "]", "for", "_", "in", "self", ".", "encoders", "]", "\n", "\n", "# maximum input length of each encoder in this batch", "\n", "max_input_len", "=", "[", "max", "(", "len", "(", "data_", "[", "i", "]", ")", "for", "data_", "in", "data", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "encoders", ")", ")", "]", "\n", "\n", "if", "self", ".", "max_input_len", "is", "not", "None", ":", "\n", "            ", "max_input_len", "=", "[", "min", "(", "len_", ",", "max_len", ")", "for", "len_", ",", "max_len", "in", "zip", "(", "max_input_len", ",", "self", ".", "max_input_len", ")", "]", "\n", "\n", "# maximum output length in this batch", "\n", "", "if", "decoding", ":", "\n", "            ", "max_output_len", "=", "self", ".", "max_output_len", "\n", "", "else", ":", "\n", "            ", "max_output_len", "=", "[", "max", "(", "len", "(", "data_", "[", "i", "]", ")", "for", "data_", "in", "data", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "encoders", ")", ",", "len", "(", "self", ".", "encoders", ")", "+", "len", "(", "self", ".", "decoders", ")", ")", "]", "\n", "if", "self", ".", "max_output_len", "is", "not", "None", ":", "\n", "                ", "max_output_len", "=", "[", "min", "(", "len_", ",", "max_len", ")", "for", "len_", ",", "max_len", "in", "zip", "(", "max_output_len", ",", "self", ".", "max_output_len", ")", "]", "\n", "\n", "", "", "for", "sentences", "in", "data", ":", "\n", "            ", "src_sentences", "=", "sentences", "[", ":", "len", "(", "self", ".", "encoders", ")", "]", "\n", "trg_sentences", "=", "sentences", "[", "len", "(", "self", ".", "encoders", ")", ":", "]", "\n", "\n", "for", "i", ",", "(", "encoder", ",", "src_sentence", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "encoders", ",", "src_sentences", ")", ")", ":", "\n", "                ", "src_sentence", "=", "src_sentence", "[", ":", "max_input_len", "[", "i", "]", "]", "\n", "pad_symbol", "=", "np", ".", "zeros", "(", "encoder", ".", "embedding_size", ",", "dtype", "=", "np", ".", "float32", ")", "if", "encoder", ".", "binary", "else", "utils", ".", "EOS_ID", "\n", "# pad sequences so that all sequences in the same batch have the same length", "\n", "\n", "eos", "=", "0", "if", "encoder", ".", "binary", "else", "1", "# end of sentence marker for non-binary input", "\n", "encoder_pad", "=", "[", "pad_symbol", "]", "*", "(", "eos", "+", "max_input_len", "[", "i", "]", "-", "len", "(", "src_sentence", ")", ")", "\n", "\n", "if", "self", ".", "reverse_input", ":", "\n", "                    ", "src_sentence", "=", "src_sentence", "[", ":", ":", "-", "1", "]", "\n", "\n", "", "inputs", "[", "i", "]", ".", "append", "(", "src_sentence", "+", "encoder_pad", ")", "\n", "input_length", "[", "i", "]", ".", "append", "(", "len", "(", "src_sentence", ")", "+", "eos", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "decoders", ")", ")", ":", "\n", "                ", "if", "decoding", ":", "\n", "                    ", "targets", "[", "i", "]", ".", "append", "(", "[", "utils", ".", "BOS_ID", "]", "*", "self", ".", "max_output_len", "[", "i", "]", "+", "[", "utils", ".", "EOS_ID", "]", ")", "\n", "", "else", ":", "\n", "                    ", "trg_sentence", "=", "trg_sentences", "[", "i", "]", "[", ":", "max_output_len", "[", "i", "]", "]", "\n", "decoder_pad_size", "=", "max_output_len", "[", "i", "]", "-", "len", "(", "trg_sentence", ")", "+", "1", "\n", "trg_sentence", "=", "[", "utils", ".", "BOS_ID", "]", "+", "trg_sentence", "+", "[", "utils", ".", "EOS_ID", "]", "*", "decoder_pad_size", "\n", "targets", "[", "i", "]", ".", "append", "(", "trg_sentence", ")", "\n", "\n", "# convert lists to numpy arrays", "\n", "", "", "", "inputs", "=", "[", "np", ".", "array", "(", "inputs_", ",", "dtype", "=", "np", ".", "float32", "if", "encoder", ".", "binary", "else", "np", ".", "int32", ")", "\n", "for", "encoder", ",", "inputs_", "in", "zip", "(", "self", ".", "encoders", ",", "inputs", ")", "]", "\n", "# starts with BOS and ends with EOS", "\n", "targets", "=", "[", "np", ".", "array", "(", "targets_", ",", "dtype", "=", "np", ".", "int32", ")", "for", "targets_", "in", "targets", "]", "\n", "input_length", "=", "[", "np", ".", "array", "(", "input_length_", ",", "dtype", "=", "np", ".", "int32", ")", "for", "input_length_", "in", "input_length", "]", "\n", "\n", "return", "inputs", ",", "targets", ",", "input_length", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.FinishedTrainingException.__init__": [[43, 45], ["utils.debug"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "debug", "(", "'finished training'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__": [[84, 87], ["dict.__init__"], "methods", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "AttrDict", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "__dict__", "=", "self", "# dark magic", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.AttrDict.__getattr__": [[88, 90], ["utils.AttrDict.__dict__.get"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", ".", "get", "(", "item", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.open_files": [[52, 72], ["files.append", "open.close", "open"], "function", ["None"], ["", "@", "contextmanager", "\n", "def", "open_files", "(", "names", ",", "mode", "=", "'r'", ")", ":", "\n", "    ", "\"\"\" Safely open a list of files in a context manager.\n    Example:\n    >>> with open_files(['foo.txt', 'bar.csv']) as (f1, f2):\n    ...   pass\n    \"\"\"", "\n", "\n", "files", "=", "[", "]", "\n", "try", ":", "\n", "        ", "for", "name_", "in", "names", ":", "\n", "            ", "if", "name_", "is", "None", ":", "\n", "                ", "file_", "=", "sys", ".", "stdin", "if", "'r'", "in", "mode", "else", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "                ", "file_", "=", "open", "(", "name_", ",", "mode", "=", "mode", ")", "\n", "", "files", ".", "append", "(", "file_", ")", "\n", "", "yield", "files", "\n", "", "finally", ":", "\n", "        ", "for", "file_", "in", "files", ":", "\n", "            ", "file_", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.reverse_edits": [[92, 135], ["len", "enumerate", "zip", "target.append", "edit.startswith", "len", "target.append", "edit.startswith", "target.append", "len", "len"], "function", ["None"], ["", "", "def", "reverse_edits", "(", "source", ",", "edits", ",", "fix", "=", "True", ",", "strict", "=", "False", ")", ":", "\n", "    ", "if", "len", "(", "edits", ")", "==", "1", ":", "# transform list of edits as a list of (op, word) tuples", "\n", "        ", "edits", "=", "edits", "[", "0", "]", "\n", "for", "i", ",", "edit", "in", "enumerate", "(", "edits", ")", ":", "\n", "            ", "if", "edit", "in", "(", "_KEEP", ",", "_DEL", ",", "_INS", ",", "_SUB", ")", ":", "\n", "                ", "edit", "=", "(", "edit", ",", "edit", ")", "\n", "", "elif", "edit", ".", "startswith", "(", "_INS", "+", "'_'", ")", ":", "\n", "                ", "edit", "=", "(", "_INS", ",", "edit", "[", "len", "(", "_INS", "+", "'_'", ")", ":", "]", ")", "\n", "", "elif", "edit", ".", "startswith", "(", "_SUB", "+", "'_'", ")", ":", "\n", "                ", "edit", "=", "(", "_SUB", ",", "edit", "[", "len", "(", "_SUB", "+", "'_'", ")", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "edit", "=", "(", "_INS", ",", "edit", ")", "\n", "\n", "", "edits", "[", "i", "]", "=", "edit", "\n", "", "", "else", ":", "\n", "        ", "edits", "=", "zip", "(", "*", "edits", ")", "\n", "\n", "", "src_words", "=", "source", "\n", "target", "=", "[", "]", "\n", "consistent", "=", "True", "\n", "i", "=", "0", "\n", "\n", "for", "op", ",", "word", "in", "edits", ":", "\n", "        ", "if", "strict", "and", "not", "consistent", ":", "\n", "            ", "break", "\n", "", "if", "op", "in", "(", "_DEL", ",", "_KEEP", ",", "_SUB", ")", ":", "\n", "            ", "if", "i", ">=", "len", "(", "src_words", ")", ":", "\n", "                ", "consistent", "=", "False", "\n", "continue", "\n", "\n", "", "if", "op", "==", "_KEEP", ":", "\n", "                ", "target", ".", "append", "(", "src_words", "[", "i", "]", ")", "\n", "", "elif", "op", "==", "_SUB", ":", "\n", "                ", "target", ".", "append", "(", "word", ")", "\n", "\n", "", "i", "+=", "1", "\n", "", "else", ":", "# op is INS", "\n", "            ", "target", ".", "append", "(", "word", ")", "\n", "\n", "", "", "if", "fix", ":", "\n", "        ", "target", "+=", "src_words", "[", "i", ":", "]", "\n", "\n", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.initialize_vocabulary": [[137, 160], ["os.path.exists", "dict", "ValueError", "open", "rev_vocab.extend", "line.rstrip", "collections.namedtuple", "f.readlines", "enumerate"], "function", ["None"], ["", "def", "initialize_vocabulary", "(", "vocabulary_path", ")", ":", "\n", "    ", "\"\"\"\n    Initialize vocabulary from file.\n\n    We assume the vocabulary is stored one-item-per-line, so a file:\n      dog\n      cat\n    will result in a vocabulary {'dog': 0, 'cat': 1}, and a reversed vocabulary ['dog', 'cat'].\n\n    :param vocabulary_path: path to the file containing the vocabulary.\n    :return:\n      the vocabulary (a dictionary mapping string to integers), and\n      the reversed vocabulary (a list, which reverses the vocabulary mapping).\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "vocabulary_path", ")", ":", "\n", "        ", "rev_vocab", "=", "[", "]", "\n", "with", "open", "(", "vocabulary_path", ")", "as", "f", ":", "\n", "            ", "rev_vocab", ".", "extend", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "rev_vocab", "=", "[", "line", ".", "rstrip", "(", "'\\n'", ")", "for", "line", "in", "rev_vocab", "]", "\n", "vocab", "=", "dict", "(", "[", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "enumerate", "(", "rev_vocab", ")", "]", ")", "\n", "return", "namedtuple", "(", "'vocab'", ",", "'vocab reverse'", ")", "(", "vocab", ",", "rev_vocab", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"vocabulary file %s not found\"", ",", "vocabulary_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.sentence_to_token_ids": [[162, 178], ["sentence.rstrip", "sentence.split", "vocabulary.get"], "function", ["None"], ["", "", "def", "sentence_to_token_ids", "(", "sentence", ",", "vocabulary", ",", "character_level", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Convert a string to list of integers representing token-ids.\n\n    For example, a sentence \"I have a dog\" may become tokenized into\n    [\"I\", \"have\", \"a\", \"dog\"] and with vocabulary {\"I\": 1, \"have\": 2,\n    \"a\": 4, \"dog\": 7\"} this function will return [1, 2, 4, 7].\n\n    :param sentence: a string, the sentence to convert to token-ids\n    :param vocabulary: a dictionary mapping tokens to integers\n    :param character_level: treat sentence as a string of characters, and\n        not as a string of words\n    :return: a list of integers, the token-ids for the sentence.\n    \"\"\"", "\n", "sentence", "=", "sentence", ".", "rstrip", "(", "'\\n'", ")", "if", "character_level", "else", "sentence", ".", "split", "(", ")", "\n", "return", "[", "vocabulary", ".", "get", "(", "w", ",", "UNK_ID", ")", "for", "w", "in", "sentence", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_filenames": [[180, 236], ["os.path.join", "list", "os.path.join", "os.path.join", "os.makedirs", "zip", "list", "collections.namedtuple", "collections.namedtuple.", "os.path.join", "list.append", "os.path.dirname", "list.pop", "len", "utils.debug", "shutil.copy", "len", "os.path.join", "os.path.exists", "os.path.exists", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug"], ["", "def", "get_filenames", "(", "data_dir", ",", "model_dir", ",", "extensions", ",", "train_prefix", ",", "dev_prefix", ",", "vocab_prefix", ",", "name", "=", "None", ",", "\n", "ref_ext", "=", "None", ",", "binary", "=", "None", ",", "decode", "=", "None", ",", "eval", "=", "None", ",", "align", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Get a bunch of file prefixes and extensions, and output the list of filenames to be used\n    by the model.\n\n    :param data_dir: directory where all the the data is stored\n    :param extensions: list of file extensions, in the right order (last extension is always the target)\n    :param train_prefix: name of the training corpus (usually 'train')\n    :param dev_prefix: name of the dev corpus (usually 'dev')\n    :param vocab_prefix: prefix of the vocab files (usually 'vocab')\n    :param kwargs: optional contains an additional 'decode', 'eval' or 'align' parameter\n    :return: namedtuple containing the filenames\n    \"\"\"", "\n", "train_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "train_prefix", ")", "\n", "dev_path", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "prefix", ")", "for", "prefix", "in", "dev_prefix", "]", "\n", "\n", "train", "=", "[", "'{}.{}'", ".", "format", "(", "train_path", ",", "ext", ")", "for", "ext", "in", "extensions", "]", "\n", "\n", "dev_extensions", "=", "list", "(", "extensions", ")", "\n", "if", "ref_ext", "is", "not", "None", "and", "ref_ext", "!=", "extensions", "[", "-", "1", "]", ":", "\n", "        ", "dev_extensions", ".", "append", "(", "ref_ext", ")", "\n", "\n", "", "dev", "=", "[", "[", "'{}.{}'", ".", "format", "(", "path", ",", "ext", ")", "for", "ext", "in", "dev_extensions", "]", "for", "path", "in", "dev_path", "]", "\n", "\n", "vocab_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "vocab_prefix", ")", "\n", "vocab_src", "=", "[", "'{}.{}'", ".", "format", "(", "vocab_path", ",", "ext", ")", "for", "ext", "in", "extensions", "]", "\n", "\n", "data", "=", "'data'", "if", "name", "is", "None", "else", "'data_{}'", ".", "format", "(", "name", ")", "\n", "vocab_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "data", ",", "'vocab'", ")", "\n", "vocab", "=", "[", "'{}.{}'", ".", "format", "(", "vocab_path", ",", "ext", ")", "for", "ext", "in", "extensions", "]", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "vocab_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "binary", "=", "binary", "or", "[", "False", "]", "*", "len", "(", "vocab", ")", "\n", "for", "src", ",", "dest", ",", "binary_", "in", "zip", "(", "vocab_src", ",", "vocab", ",", "binary", ")", ":", "\n", "        ", "if", "not", "binary_", "and", "not", "os", ".", "path", ".", "exists", "(", "dest", ")", ":", "\n", "            ", "debug", "(", "'copying vocab to {}'", ".", "format", "(", "dest", ")", ")", "\n", "shutil", ".", "copy", "(", "src", ",", "dest", ")", "\n", "\n", "", "", "exts", "=", "list", "(", "extensions", ")", "\n", "if", "decode", "is", "not", "None", ":", "# empty list means we decode from standard input", "\n", "        ", "test", "=", "decode", "\n", "exts", ".", "pop", "(", "-", "1", ")", "\n", "", "elif", "eval", "is", "not", "None", ":", "\n", "        ", "if", "ref_ext", "is", "not", "None", ":", "\n", "            ", "exts", "[", "-", "1", "]", "=", "ref_ext", "\n", "", "test", "=", "eval", "or", "dev_prefix", "[", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "test", "=", "align", "or", "dev_prefix", "[", ":", "1", "]", "\n", "\n", "", "if", "len", "(", "test", ")", "==", "1", "and", "not", "(", "decode", "and", "os", ".", "path", ".", "exists", "(", "test", "[", "0", "]", ")", ")", ":", "\n", "        ", "corpus_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "test", "[", "0", "]", ")", "if", "not", "os", ".", "path", ".", "dirname", "(", "test", "[", "0", "]", ")", "else", "test", "[", "0", "]", "\n", "test", "=", "[", "'{}.{}'", ".", "format", "(", "corpus_path", ",", "ext", ")", "for", "ext", "in", "exts", "]", "\n", "\n", "", "filenames", "=", "namedtuple", "(", "'filenames'", ",", "[", "'train'", ",", "'dev'", ",", "'test'", ",", "'vocab'", "]", ")", "\n", "return", "filenames", "(", "train", ",", "dev", ",", "test", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_dataset": [[238, 278], ["utils.read_lines_from_position", "utils.debug", "utils.debug", "utils.debug", "data_set.append", "data_set.sort", "utils.debug", "all", "any", "len", "len", "utils.sentence_to_token_ids", "zip", "len", "len", "len", "list", "character_level.get", "len", "zip", "map"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines_from_position", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.sentence_to_token_ids"], ["", "def", "read_dataset", "(", "paths", ",", "extensions", ",", "vocabs", ",", "max_size", "=", "None", ",", "character_level", "=", "None", ",", "sort_by_length", "=", "False", ",", "\n", "max_seq_len", "=", "None", ",", "from_position", "=", "None", ",", "binary", "=", "None", ")", ":", "\n", "    ", "data_set", "=", "[", "]", "\n", "\n", "if", "from_position", "is", "not", "None", ":", "\n", "        ", "debug", "(", "'reading from position: {}'", ".", "format", "(", "from_position", ")", ")", "\n", "\n", "", "line_reader", "=", "read_lines_from_position", "(", "paths", ",", "from_position", "=", "from_position", ",", "binary", "=", "binary", ")", "\n", "character_level", "=", "character_level", "or", "{", "}", "\n", "\n", "positions", "=", "None", "\n", "\n", "for", "inputs", ",", "positions", "in", "line_reader", ":", "\n", "        ", "if", "len", "(", "data_set", ")", ">", "0", "and", "len", "(", "data_set", ")", "%", "100000", "==", "0", ":", "\n", "            ", "debug", "(", "\"  lines read: {}\"", ".", "format", "(", "len", "(", "data_set", ")", ")", ")", "\n", "\n", "", "lines", "=", "[", "\n", "input_", "if", "binary_", "else", "\n", "sentence_to_token_ids", "(", "input_", ",", "vocab", ".", "vocab", ",", "character_level", "=", "character_level", ".", "get", "(", "ext", ")", ")", "\n", "for", "input_", ",", "vocab", ",", "binary_", ",", "ext", "in", "zip", "(", "inputs", ",", "vocabs", ",", "binary", ",", "extensions", ")", "\n", "]", "\n", "\n", "if", "not", "all", "(", "lines", ")", ":", "# skip empty inputs", "\n", "            ", "continue", "\n", "# skip lines that are too long", "\n", "", "if", "max_seq_len", "and", "any", "(", "len", "(", "line", ")", ">", "max_seq_len", "[", "ext", "]", "for", "line", ",", "ext", "in", "zip", "(", "lines", ",", "extensions", ")", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "data_set", ".", "append", "(", "lines", ")", "\n", "\n", "if", "max_size", "and", "len", "(", "data_set", ")", ">=", "max_size", ":", "\n", "            ", "break", "\n", "\n", "", "", "debug", "(", "'files: {}'", ".", "format", "(", "' '", ".", "join", "(", "paths", ")", ")", ")", "\n", "debug", "(", "'lines reads: {}'", ".", "format", "(", "len", "(", "data_set", ")", ")", ")", "\n", "\n", "if", "sort_by_length", ":", "\n", "        ", "data_set", ".", "sort", "(", "key", "=", "lambda", "lines", ":", "list", "(", "map", "(", "len", ",", "lines", ")", ")", ")", "\n", "\n", "", "return", "data_set", ",", "positions", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.random_batch_iterator": [[280, 290], ["random.sample"], "function", ["None"], ["", "def", "random_batch_iterator", "(", "data", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    The most basic form of batch iterator.\n\n    :param data: the dataset to segment into batches\n    :param batch_size: the size of a batch\n    :return: an iterator which yields random batches (indefinitely)\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "yield", "random", ".", "sample", "(", "data", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.basic_batch_iterator": [[292, 303], ["range", "random.shuffle", "len", "len"], "function", ["None"], ["", "", "def", "basic_batch_iterator", "(", "data", ",", "batch_size", ",", "shuffle", "=", "False", ",", "allow_smaller", "=", "True", ")", ":", "\n", "    ", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "data", ")", "\n", "\n", "", "batch_count", "=", "len", "(", "data", ")", "//", "batch_size", "\n", "\n", "if", "allow_smaller", "and", "batch_count", "*", "batch_size", "<", "len", "(", "data", ")", ":", "\n", "        ", "batch_count", "+=", "1", "\n", "\n", "", "for", "i", "in", "range", "(", "batch_count", ")", ":", "\n", "        ", "yield", "data", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.cycling_batch_iterator": [[305, 318], ["utils.basic_batch_iterator"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.basic_batch_iterator"], ["", "", "def", "cycling_batch_iterator", "(", "data", ",", "batch_size", ",", "shuffle", "=", "True", ",", "allow_smaller", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Indefinitely cycle through a dataset and yield batches (the dataset is shuffled\n    at each new epoch)\n\n    :param data: the dataset to segment into batches\n    :param batch_size: the size of a batch\n    :return: an iterator which yields batches (indefinitely)\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "iterator", "=", "basic_batch_iterator", "(", "data", ",", "batch_size", ",", "shuffle", "=", "shuffle", ",", "allow_smaller", "=", "allow_smaller", ")", "\n", "for", "batch", "in", "iterator", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_ahead_batch_iterator": [[320, 371], ["utils.basic_batch_iterator", "heapq.nlargest", "heapq.nlargest", "sorted", "utils.random_batch_iterator", "utils.cycling_batch_iterator", "batches.append", "sum", "any", "random.shuffle", "len", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.basic_batch_iterator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.random_batch_iterator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.cycling_batch_iterator"], ["", "", "", "def", "read_ahead_batch_iterator", "(", "data", ",", "batch_size", ",", "read_ahead", "=", "10", ",", "shuffle", "=", "True", ",", "allow_smaller", "=", "True", ",", "\n", "mode", "=", "'standard'", ",", "cycle", "=", "True", ",", "crash_test", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Same iterator as `cycling_batch_iterator`, except that it reads a number of batches\n    at once, and sorts their content according to their size.\n\n    This is useful for training, where all the sequences in one batch need to be padded\n     to the same length as the longest sequence in the batch.\n\n    :param data: the dataset to segment into batches\n    :param batch_size: the size of a batch\n    :param read_ahead: number of batches to read ahead of time and sort (larger numbers\n      mean faster training, but less random behavior)\n    :return: an iterator which yields batches (indefinitely)\n    \"\"\"", "\n", "if", "not", "cycle", ":", "\n", "        ", "iterator", "=", "basic_batch_iterator", "(", "data", ",", "batch_size", ",", "shuffle", "=", "shuffle", ",", "allow_smaller", "=", "allow_smaller", ")", "\n", "", "elif", "mode", "==", "'random'", ":", "\n", "        ", "iterator", "=", "random_batch_iterator", "(", "data", ",", "batch_size", ")", "\n", "", "else", ":", "\n", "        ", "iterator", "=", "cycling_batch_iterator", "(", "data", ",", "batch_size", ",", "shuffle", "=", "shuffle", ",", "allow_smaller", "=", "allow_smaller", ")", "\n", "\n", "", "if", "crash_test", ":", "\n", "        ", "n", "=", "batch_size", "//", "2", "\n", "dummy_batch", "=", "heapq", ".", "nlargest", "(", "n", ",", "data", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "0", "]", ")", ")", "\n", "dummy_batch", "+=", "heapq", ".", "nlargest", "(", "batch_size", "-", "n", ",", "data", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "1", "]", ")", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "yield", "dummy_batch", "\n", "\n", "", "", "if", "read_ahead", "is", "None", "or", "read_ahead", "<=", "1", ":", "\n", "        ", "yield", "from", "iterator", "\n", "\n", "", "while", "True", ":", "\n", "        ", "batches", "=", "[", "]", "\n", "for", "batch", "in", "iterator", ":", "\n", "            ", "batches", ".", "append", "(", "batch", ")", "\n", "if", "len", "(", "batches", ")", ">=", "read_ahead", ":", "\n", "                ", "break", "\n", "\n", "", "", "data_", "=", "sorted", "(", "sum", "(", "batches", ",", "[", "]", ")", ",", "key", "=", "lambda", "lines", ":", "len", "(", "lines", "[", "-", "1", "]", ")", ")", "\n", "batches", "=", "[", "data_", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "for", "i", "in", "range", "(", "read_ahead", ")", "]", "\n", "batches", "=", "[", "batch", "for", "batch", "in", "batches", "if", "batch", "]", "# filter empty batches", "\n", "\n", "if", "not", "any", "(", "batches", ")", ":", "\n", "            ", "break", "\n", "\n", "", "if", "shuffle", ":", "# TODO: enable shuffling here without epoch shuffling", "\n", "            ", "random", ".", "shuffle", "(", "batches", ")", "\n", "", "for", "batch", "in", "batches", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_batch_iterator": [[373, 410], ["functools.partial", "functools.partial", "functools.partial.", "open", "sum", "utils.debug", "functools.partial", "functools.partial.", "utils.get_batch_iterator.generator"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug"], ["", "", "", "def", "get_batch_iterator", "(", "paths", ",", "extensions", ",", "vocabs", ",", "batch_size", ",", "max_size", "=", "None", ",", "character_level", "=", "None", ",", "\n", "sort_by_length", "=", "False", ",", "max_seq_len", "=", "None", ",", "read_ahead", "=", "10", ",", "shuffle", "=", "True", ",", "\n", "binary", "=", "None", ",", "mode", "=", "'standard'", ",", "crash_test", "=", "False", ")", ":", "\n", "    ", "read_shard", "=", "functools", ".", "partial", "(", "read_dataset", ",", "\n", "paths", "=", "paths", ",", "extensions", "=", "extensions", ",", "vocabs", "=", "vocabs", ",", "max_size", "=", "max_size", ",", "max_seq_len", "=", "max_seq_len", ",", "\n", "character_level", "=", "character_level", ",", "sort_by_length", "=", "sort_by_length", ",", "binary", "=", "binary", ")", "\n", "batch_iterator", "=", "functools", ".", "partial", "(", "read_ahead_batch_iterator", ",", "batch_size", "=", "batch_size", ",", "read_ahead", "=", "read_ahead", ",", "\n", "shuffle", "=", "shuffle", ",", "mode", "=", "mode", ",", "crash_test", "=", "crash_test", ")", "\n", "\n", "# FIXME: crash test only for first shard", "\n", "with", "open", "(", "paths", "[", "-", "1", "]", ")", "as", "f", ":", "# count lines", "\n", "        ", "line_count", "=", "sum", "(", "1", "for", "_", "in", "f", ")", "\n", "debug", "(", "'total line count: {}'", ".", "format", "(", "line_count", ")", ")", "\n", "\n", "", "shard", ",", "position", "=", "read_shard", "(", ")", "\n", "if", "not", "max_size", "or", "line_count", "<=", "max_size", ":", "\n", "# training set is small enough to fit entirely into memory (single shard)", "\n", "        ", "return", "batch_iterator", "(", "shard", ")", ",", "line_count", "\n", "", "else", ":", "\n", "        ", "batch_iterator", "=", "functools", ".", "partial", "(", "batch_iterator", ",", "cycle", "=", "False", ")", "\n", "\n", "def", "generator", "(", "position", ",", "shard", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "if", "len", "(", "shard", ")", "<", "max_size", ":", "\n", "# last shard, start again from the beginning of the dataset", "\n", "                    ", "position", "=", "None", "\n", "\n", "", "size", "=", "0", "\n", "for", "batch", "in", "batch_iterator", "(", "shard", ")", ":", "\n", "                    ", "size", "+=", "len", "(", "batch", ")", "\n", "yield", "batch", "\n", "\n", "if", "size", ">=", "len", "(", "shard", ")", ":", "# cycle through this shard only once, then read next shard", "\n", "                        ", "shard", ",", "position", "=", "read_shard", "(", "from_position", "=", "position", ")", "\n", "break", "\n", "\n", "", "", "", "", "return", "generator", "(", "position", ",", "shard", ")", ",", "line_count", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.get_batches": [[412, 438], ["random.shuffle", "int", "len", "math.ceil", "range", "len"], "function", ["None"], ["", "", "def", "get_batches", "(", "data", ",", "batch_size", ",", "batches", "=", "0", ",", "allow_smaller", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Segment `data` into a given number of fixed-size batches. The dataset is automatically shuffled.\n\n    This function is for smaller datasets, when you need access to the entire dataset at once (e.g. dev set).\n    For larger (training) datasets, where you may want to lazily iterate over batches\n    and cycle several times through the entire dataset, prefer batch iterators\n    (such as `cycling_batch_iterator`).\n\n    :param data: the dataset to segment into batches (a list of data points)\n    :param batch_size: the size of a batch\n    :param batches: number of batches to return (0 for the largest possible number)\n    :param allow_smaller: allow the last batch to be smaller\n    :return: a list of batches (which are lists of `batch_size` data points)\n    \"\"\"", "\n", "if", "not", "allow_smaller", ":", "\n", "        ", "max_batches", "=", "len", "(", "data", ")", "//", "batch_size", "\n", "", "else", ":", "\n", "        ", "max_batches", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "data", ")", "/", "batch_size", ")", ")", "\n", "\n", "", "if", "batches", "<", "1", "or", "batches", ">", "max_batches", ":", "\n", "        ", "batches", "=", "max_batches", "\n", "\n", "", "random", ".", "shuffle", "(", "data", ")", "\n", "batches", "=", "[", "data", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "for", "i", "in", "range", "(", "batches", ")", "]", "\n", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_binary_features": [[440, 462], ["open", "numpy.load", "range", "f.seek", "numpy.load", "list", "f.tell"], "function", ["None"], ["", "def", "read_binary_features", "(", "filename", ",", "from_position", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Reads a binary file containing vector features. First two (int32) numbers correspond to\n    number of entries (lines), and dimension of the vectors.\n    Each entry is a numpy array of shape (nframes, dim).\n\n    Use `scripts/speech/extract-audio-features.py` or `scripts/speech/extract.py` to create such a file for audio (MFCCs).\n\n    :param filename: path to the binary file containing the features\n    :return: list of arrays of shape (frames, dimension)\n    \"\"\"", "\n", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "lines", ",", "dim", "=", "np", ".", "load", "(", "f", ")", "\n", "if", "from_position", "is", "not", "None", ":", "\n", "            ", "f", ".", "seek", "(", "from_position", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "lines", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "feats", "=", "np", ".", "load", "(", "f", ")", "\n", "yield", "list", "(", "feats", ")", ",", "f", ".", "tell", "(", ")", "\n", "", "except", "OSError", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines": [[464, 470], ["zip", "len", "zip", "map", "open", "operator.itemgetter", "utils.read_binary_features"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_binary_features"], ["", "", "", "", "def", "read_lines", "(", "paths", ",", "binary", "=", "None", ")", ":", "\n", "    ", "binary", "=", "binary", "or", "[", "False", "]", "*", "len", "(", "paths", ")", "\n", "return", "zip", "(", "*", "[", "sys", ".", "stdin", "if", "path", "is", "None", "else", "\n", "map", "(", "operator", ".", "itemgetter", "(", "0", ")", ",", "read_binary_features", "(", "path", ")", ")", "if", "binary_", "\n", "else", "open", "(", "path", ")", "\n", "for", "path", ",", "binary_", "in", "zip", "(", "paths", ",", "binary", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_text_from_position": [[472, 481], ["open", "f.seek", "f.readline", "f.tell"], "function", ["None"], ["", "def", "read_text_from_position", "(", "filename", ",", "from_position", "=", "None", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "if", "from_position", "is", "not", "None", ":", "\n", "            ", "f", ".", "seek", "(", "from_position", ")", "\n", "", "while", "True", ":", "\n", "            ", "line", "=", "f", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "                ", "break", "\n", "", "yield", "line", ",", "f", ".", "tell", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_lines_from_position": [[483, 495], ["zip", "len", "len", "utils.read_binary_features", "utils.read_text_from_position", "zip", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_binary_features", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.read_text_from_position"], ["", "", "", "def", "read_lines_from_position", "(", "paths", ",", "from_position", "=", "None", ",", "binary", "=", "None", ")", ":", "\n", "    ", "binary", "=", "binary", "or", "[", "False", "]", "*", "len", "(", "paths", ")", "\n", "from_position", "=", "from_position", "or", "[", "None", "]", "*", "len", "(", "paths", ")", "\n", "\n", "iterators", "=", "[", "\n", "read_binary_features", "(", "path", ",", "from_position_", ")", "if", "binary_", "else", "\n", "read_text_from_position", "(", "path", ",", "from_position_", ")", "\n", "for", "path", ",", "binary_", ",", "from_position_", "in", "zip", "(", "paths", ",", "binary", ",", "from_position", ")", "\n", "]", "\n", "\n", "for", "data", "in", "zip", "(", "*", "iterators", ")", ":", "\n", "        ", "yield", "tuple", "(", "zip", "(", "*", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.create_logger": [[497, 517], ["logging.Formatter", "logging.StreamHandler", "logging.FileHandler.setFormatter", "logging.getLogger", "logging.getLogger.addHandler", "os.makedirs", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger", "logging.getLogger.addHandler", "os.path.dirname"], "function", ["None"], ["", "", "def", "create_logger", "(", "log_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Initialize global logger and return it.\n\n    :param log_file: log to this file, or to standard output if None\n    :return: created logger\n    \"\"\"", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "fmt", "=", "'%(asctime)s %(message)s'", ",", "datefmt", "=", "'%m/%d %H:%M:%S'", ")", "\n", "if", "log_file", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "log_file", ")", ",", "exist_ok", "=", "True", ")", "\n", "handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "addHandler", "(", "handler", ")", "\n", "\n", "", "handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "addHandler", "(", "handler", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log": [[519, 521], ["logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "log", "(", "msg", ",", "level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "logging", ".", "getLogger", "(", "__name__", ")", ".", "log", "(", "level", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.debug": [[523, 524], ["utils.log"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "debug", "(", "msg", ")", ":", "log", "(", "msg", ",", "level", "=", "logging", ".", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.warn": [[526, 527], ["utils.log"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["def", "warn", "(", "msg", ")", ":", "log", "(", "msg", ",", "level", "=", "logging", ".", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.heatmap": [[529, 602], ["list", "list", "plt.subplots", "plt.autoscale", "ax.pcolor", "ax.set_frame_on", "ax.set_yticks", "ax.set_xticks", "ax.invert_yaxis", "ax.xaxis.tick_top", "ax.set_xticklabels", "ax.set_yticklabels", "ax.tick_params", "plt.xticks", "plt.yticks", "plt.subplots_adjust", "max", "max", "fig.set_size_inches", "matplotlib.rcParams.update", "token_mapping.items", "map", "map", "plt.xticks", "plt.tight_layout", "ax.set_aspect", "ax.grid", "plt.show", "plt.savefig", "token.replace.replace", "numpy.arange", "numpy.arange", "len", "len"], "function", ["None"], ["def", "heatmap", "(", "xlabels", "=", "None", ",", "ylabels", "=", "None", ",", "weights", "=", "None", ",", "output_file", "=", "None", ",", "reverse", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Draw a heatmap showing the alignment between two sequences.\n\n    :param xlabels: input words\n    :param ylabels: output words\n    :param weights: numpy array of shape (len(xlabels), len(ylabels))\n    :param output_file: write the figure to this file, or show it into a window if None\n    \"\"\"", "\n", "import", "matplotlib", "\n", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "\n", "if", "reverse", "and", "not", "ylabels", ":", "\n", "        ", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "18", "}", ")", "\n", "\n", "", "def", "prettify", "(", "token", ")", ":", "\n", "        ", "token_mapping", "=", "{", "\n", "'&quot;'", ":", "'\"'", ",", "\n", "'&apos;'", ":", "'\\''", ",", "\n", "'&amp;'", ":", "'&'", ",", "\n", "'@@'", ":", "'_'", "\n", "}", "\n", "for", "x", ",", "y", "in", "token_mapping", ".", "items", "(", ")", ":", "\n", "            ", "token", "=", "token", ".", "replace", "(", "x", ",", "y", ")", "\n", "", "return", "token", "\n", "\n", "", "xlabels", "=", "xlabels", "or", "[", "]", "\n", "ylabels", "=", "ylabels", "or", "[", "]", "\n", "xlabels", "=", "list", "(", "map", "(", "prettify", ",", "xlabels", ")", ")", "\n", "ylabels", "=", "list", "(", "map", "(", "prettify", ",", "ylabels", ")", ")", "\n", "\n", "if", "reverse", ":", "\n", "        ", "xlabels", ",", "ylabels", "=", "ylabels", ",", "xlabels", "\n", "weights", "=", "weights", ".", "T", "\n", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "plt", ".", "autoscale", "(", "enable", "=", "True", ",", "axis", "=", "'x'", ",", "tight", "=", "True", ")", "\n", "#ax.pcolor(weights, cmap=plt.cm.Greys)", "\n", "ax", ".", "pcolor", "(", "weights", ",", "cmap", "=", "plt", ".", "cm", ".", "Greys", ")", "\n", "ax", ".", "set_frame_on", "(", "False", ")", "\n", "# plt.colorbar(mappable=heatmap_)", "\n", "\n", "# put the major ticks at the middle of each cell", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "weights", ".", "shape", "[", "0", "]", ")", "+", "0.5", ",", "minor", "=", "False", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "weights", ".", "shape", "[", "1", "]", ")", "+", "0.5", ",", "minor", "=", "False", ")", "\n", "ax", ".", "invert_yaxis", "(", ")", "\n", "ax", ".", "xaxis", ".", "tick_top", "(", ")", "\n", "\n", "ax", ".", "set_xticklabels", "(", "xlabels", ",", "minor", "=", "False", ")", "\n", "ax", ".", "set_yticklabels", "(", "ylabels", ",", "minor", "=", "False", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'both'", ",", "which", "=", "'both'", ",", "length", "=", "0", ")", "\n", "\n", "if", "not", "reverse", ":", "\n", "        ", "plt", ".", "xticks", "(", "rotation", "=", "90", ")", "\n", "\n", "", "plt", ".", "xticks", "(", "fontsize", "=", "18", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "18", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0", ",", "hspace", "=", "0", ")", "\n", "\n", "if", "not", "reverse", "or", "ylabels", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "ax", ".", "set_aspect", "(", "'equal'", ")", "\n", "ax", ".", "grid", "(", "True", ")", "\n", "\n", "", "xsize", "=", "max", "(", "2.0", "+", "len", "(", "xlabels", ")", "/", "3", ",", "8.0", ")", "\n", "ysize", "=", "max", "(", "2.0", "+", "len", "(", "ylabels", ")", "/", "3", ",", "8.0", ")", "\n", "fig", ".", "set_size_inches", "(", "xsize", ",", "ysize", ",", "forward", "=", "True", ")", "\n", "\n", "if", "output_file", "is", "None", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_file", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.alignment_to_text": [[604, 618], ["open", "output_file.write", "range", "output_file.replace().replace", "len", "output_file.write", "range", "output_file.write", "len", "output_file.write", "output_file.replace", "str"], "function", ["None"], ["", "", "def", "alignment_to_text", "(", "xlabels", "=", "None", ",", "ylabels", "=", "None", ",", "weights", "=", "None", ",", "output_file", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    :param xlabels: input words\n    :param ylabels: output words\n    :param weights: numpy array of shape (len(xlabels), len(ylabels))\n    :param output_file: write the matrix in this file\n    \"\"\"", "\n", "with", "open", "(", "output_file", ".", "replace", "(", "'svg'", ",", "'txt'", ")", ".", "replace", "(", "'jpg'", ",", "'txt'", ")", ",", "'w'", ")", "as", "output_file", ":", "\n", "        ", "output_file", ".", "write", "(", "' \\t'", "+", "'\\t'", ".", "join", "(", "xlabels", ")", "+", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ylabels", ")", ")", ":", "\n", "            ", "output_file", ".", "write", "(", "ylabels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "xlabels", ")", ")", ":", "\n", "                ", "output_file", ".", "write", "(", "'\\t'", "+", "str", "(", "weights", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "output_file", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein": [[13, 59], ["range", "numpy.zeros", "numpy.zeros", "range", "range", "range", "range", "len", "len", "len", "len", "len", "min", "res.append", "res.append", "len", "len", "len", "len", "random.random", "len"], "function", ["None"], ["def", "levenshtein", "(", "src", ",", "trg", ",", "sub_cost", "=", "1.0", ",", "del_cost", "=", "1.0", ",", "ins_cost", "=", "1.0", ",", "randomize", "=", "True", ")", ":", "\n", "    ", "DEL", ",", "INS", ",", "KEEP", ",", "SUB", "=", "range", "(", "4", ")", "\n", "op_names", "=", "'delete'", ",", "'insert'", ",", "'keep'", ",", "'sub'", "\n", "\n", "costs", "=", "np", ".", "zeros", "(", "(", "len", "(", "trg", ")", "+", "1", ",", "len", "(", "src", ")", "+", "1", ")", ")", "\n", "ops", "=", "np", ".", "zeros", "(", "(", "len", "(", "trg", ")", "+", "1", ",", "len", "(", "src", ")", "+", "1", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "costs", "[", "0", "]", "=", "range", "(", "len", "(", "src", ")", "+", "1", ")", "\n", "costs", "[", ":", ",", "0", "]", "=", "range", "(", "len", "(", "trg", ")", "+", "1", ")", "\n", "ops", "[", "0", "]", "=", "DEL", "\n", "ops", "[", ":", ",", "0", "]", "=", "INS", "\n", "\n", "if", "randomize", ":", "\n", "        ", "key", "=", "lambda", "p", ":", "(", "p", "[", "0", "]", ",", "random", ".", "random", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "key", "=", "None", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "trg", ")", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "len", "(", "src", ")", "+", "1", ")", ":", "\n", "            ", "c", ",", "op", "=", "(", "sub_cost", ",", "SUB", ")", "if", "trg", "[", "i", "-", "1", "]", "!=", "src", "[", "j", "-", "1", "]", "else", "(", "0", ",", "KEEP", ")", "\n", "costs", "[", "i", ",", "j", "]", ",", "ops", "[", "i", ",", "j", "]", "=", "min", "(", "[", "\n", "(", "costs", "[", "i", ",", "j", "-", "1", "]", "+", "del_cost", ",", "DEL", ")", ",", "\n", "(", "costs", "[", "i", "-", "1", ",", "j", "]", "+", "ins_cost", ",", "INS", ")", ",", "\n", "(", "costs", "[", "i", "-", "1", ",", "j", "-", "1", "]", "+", "c", ",", "op", ")", ",", "\n", "]", ",", "key", "=", "key", ")", "\n", "\n", "# backtracking", "\n", "", "", "i", ",", "j", "=", "len", "(", "trg", ")", ",", "len", "(", "src", ")", "\n", "cost", "=", "costs", "[", "i", ",", "j", "]", "\n", "\n", "res", "=", "[", "]", "\n", "\n", "while", "i", ">", "0", "or", "j", ">", "0", ":", "\n", "        ", "op", "=", "ops", "[", "i", ",", "j", "]", "\n", "op_name", "=", "op_names", "[", "op", "]", "\n", "\n", "if", "op", "==", "DEL", ":", "\n", "            ", "res", ".", "append", "(", "op_name", ")", "\n", "j", "-=", "1", "\n", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "(", "op_name", ",", "trg", "[", "i", "-", "1", "]", ")", ")", "\n", "i", "-=", "1", "\n", "if", "op", "!=", "INS", ":", "\n", "                ", "j", "-=", "1", "\n", "\n", "", "", "", "return", "cost", ",", "res", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.sentence_bleu": [[61, 98], ["range", "min", "len", "collections.Counter", "collections.Counter", "sum", "sum", "math.exp", "math.exp", "zip", "zip", "collections.Counter.values", "float", "min", "math.log", "collections.Counter.items", "len", "len", "range", "range"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "sentence_bleu", "(", "hypothesis", ",", "reference", ",", "smoothing", "=", "True", ",", "order", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Compute sentence-level BLEU score between a translation hypothesis and a reference.\n\n    :param hypothesis: list of tokens or token ids\n    :param reference: list of tokens or token ids\n    :param smoothing: apply smoothing (recommended, especially for short sequences)\n    :param order: count n-grams up to this value of n.\n    :param kwargs: additional (unused) parameters\n    :return: BLEU score (float)\n    \"\"\"", "\n", "log_score", "=", "0", "\n", "\n", "if", "len", "(", "hypothesis", ")", "==", "0", ":", "\n", "        ", "return", "0", "\n", "\n", "", "for", "i", "in", "range", "(", "order", ")", ":", "\n", "        ", "hyp_ngrams", "=", "Counter", "(", "zip", "(", "*", "[", "hypothesis", "[", "j", ":", "]", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", ")", ")", "\n", "ref_ngrams", "=", "Counter", "(", "zip", "(", "*", "[", "reference", "[", "j", ":", "]", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", ")", ")", "\n", "\n", "numerator", "=", "sum", "(", "min", "(", "count", ",", "ref_ngrams", "[", "bigram", "]", ")", "for", "bigram", ",", "count", "in", "hyp_ngrams", ".", "items", "(", ")", ")", "\n", "denominator", "=", "sum", "(", "hyp_ngrams", ".", "values", "(", ")", ")", "\n", "\n", "if", "smoothing", ":", "\n", "            ", "numerator", "+=", "1", "\n", "denominator", "+=", "1", "\n", "\n", "", "score", "=", "numerator", "/", "denominator", "\n", "\n", "if", "score", "==", "0", ":", "\n", "            ", "log_score", "+=", "float", "(", "'-inf'", ")", "\n", "", "else", ":", "\n", "            ", "log_score", "+=", "math", ".", "log", "(", "score", ")", "/", "order", "\n", "\n", "", "", "bp", "=", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "len", "(", "reference", ")", "/", "len", "(", "hypothesis", ")", ")", ")", "\n", "\n", "return", "math", ".", "exp", "(", "log_score", ")", "*", "bp", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator": [[100, 105], ["None"], "function", ["None"], ["", "def", "score_function_decorator", "(", "reversed", "=", "False", ")", ":", "\n", "    ", "def", "decorator", "(", "func", ")", ":", "\n", "        ", "func", ".", "reversed", "=", "reversed", "\n", "return", "func", "\n", "", "return", "decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.divide": [[107, 112], ["numpy.errstate", "numpy.true_divide", "numpy.isfinite"], "function", ["None"], ["", "def", "divide", "(", "x", ",", "y", ")", ":", "\n", "    ", "with", "np", ".", "errstate", "(", "divide", "=", "'ignore'", ",", "invalid", "=", "'ignore'", ")", ":", "\n", "        ", "z", "=", "np", ".", "true_divide", "(", "x", ",", "y", ")", "\n", "z", "[", "~", "np", ".", "isfinite", "(", "z", ")", "]", "=", "0", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_bleu": [[114, 170], ["numpy.zeros", "numpy.zeros", "zip", "evaluation.divide", "math.exp", "isinstance", "hyp.split.split", "len", "min", "range", "min", "ref_.split", "map", "collections.Counter", "collections.Counter", "sum", "sum", "sum", "math.exp", "collections.Counter", "collections.Counter.items", "zip", "collections.Counter.values", "zip", "max", "min", "abs", "collections.Counter.items", "math.log", "float", "len", "range", "range"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.divide", "home.repos.pwc.inspect_result.eske_seq2seq.translate.utils.log"], ["", "def", "corpus_bleu", "(", "hypotheses", ",", "references", ",", "smoothing", "=", "False", ",", "order", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Computes the BLEU score at the corpus-level between a list of translation hypotheses and references.\n    With the default settings, this computes the exact same score as `multi-bleu.perl`.\n\n    All corpus-based evaluation functions should follow this interface.\n\n    :param hypotheses: list of strings\n    :param references: list of strings\n    :param smoothing: apply +1 smoothing\n    :param order: count n-grams up to this value of n. `multi-bleu.perl` uses a value of 4.\n    :param kwargs: additional (unused) parameters\n    :return: score (float), and summary containing additional information (str)\n    \"\"\"", "\n", "total", "=", "np", ".", "zeros", "(", "(", "order", ",", ")", ")", "\n", "correct", "=", "np", ".", "zeros", "(", "(", "order", ",", ")", ")", "\n", "\n", "hyp_length", "=", "0", "\n", "ref_length", "=", "0", "\n", "\n", "for", "hyp", ",", "ref", "in", "zip", "(", "hypotheses", ",", "references", ")", ":", "\n", "        ", "if", "isinstance", "(", "ref", ",", "str", ")", ":", "\n", "            ", "ref", "=", "[", "ref", "]", "\n", "\n", "", "hyp", "=", "hyp", ".", "split", "(", ")", "\n", "ref", "=", "[", "ref_", ".", "split", "(", ")", "for", "ref_", "in", "ref", "]", "\n", "\n", "hyp_length", "+=", "len", "(", "hyp", ")", "\n", "ref_length", "+=", "min", "(", "map", "(", "len", ",", "ref", ")", ",", "key", "=", "lambda", "l", ":", "(", "abs", "(", "l", "-", "len", "(", "hyp", ")", ")", ",", "l", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "order", ")", ":", "\n", "            ", "ref_ngrams", "=", "Counter", "(", ")", "\n", "for", "ref_", "in", "ref", ":", "\n", "                ", "c", "=", "Counter", "(", "zip", "(", "*", "[", "ref_", "[", "j", ":", "]", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", ")", ")", "\n", "for", "ngram", ",", "count", "in", "c", ".", "items", "(", ")", ":", "\n", "                    ", "ref_ngrams", "[", "ngram", "]", "=", "max", "(", "count", ",", "ref_ngrams", "[", "ngram", "]", ")", "\n", "\n", "", "", "hyp_ngrams", "=", "Counter", "(", "zip", "(", "*", "[", "hyp", "[", "j", ":", "]", "for", "j", "in", "range", "(", "i", "+", "1", ")", "]", ")", ")", "\n", "\n", "total", "[", "i", "]", "+=", "sum", "(", "hyp_ngrams", ".", "values", "(", ")", ")", "\n", "correct", "[", "i", "]", "+=", "sum", "(", "min", "(", "count", ",", "ref_ngrams", "[", "bigram", "]", ")", "for", "bigram", ",", "count", "in", "hyp_ngrams", ".", "items", "(", ")", ")", "\n", "\n", "", "", "if", "smoothing", ":", "\n", "        ", "total", "+=", "1", "\n", "correct", "+=", "1", "\n", "\n", "", "scores", "=", "divide", "(", "correct", ",", "total", ")", "\n", "\n", "score", "=", "math", ".", "exp", "(", "\n", "sum", "(", "math", ".", "log", "(", "score", ")", "if", "score", ">", "0", "else", "float", "(", "'-inf'", ")", "for", "score", "in", "scores", ")", "/", "order", "\n", ")", "\n", "\n", "bp", "=", "min", "(", "1", ",", "math", ".", "exp", "(", "1", "-", "ref_length", "/", "hyp_length", ")", ")", "if", "hyp_length", ">", "0", "else", "0.0", "\n", "bleu", "=", "100", "*", "bp", "*", "score", "\n", "\n", "return", "bleu", ",", "'penalty={:.3f} ratio={:.3f}'", ".", "format", "(", "bp", ",", "hyp_length", "/", "ref_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_ter": [[172, 191], ["evaluation.score_function_decorator", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile", "enumerate", "hypothesis_file.flush", "reference_file.flush", "subprocess.check_output().decode", "zip", "hypothesis_file.write", "reference_file.write", "cmd.append", "re.findall", "subprocess.check_output", "float"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.translation_model.TranslationModel.decode"], ["", "@", "score_function_decorator", "(", "reversed", "=", "True", ")", "\n", "def", "corpus_ter", "(", "hypotheses", ",", "references", ",", "case_sensitive", "=", "True", ",", "tercom_path", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "tercom_path", "=", "tercom_path", "or", "'scripts/tercom.jar'", "\n", "\n", "with", "tempfile", ".", "NamedTemporaryFile", "(", "'w'", ")", "as", "hypothesis_file", ",", "tempfile", ".", "NamedTemporaryFile", "(", "'w'", ")", "as", "reference_file", ":", "\n", "        ", "for", "i", ",", "(", "hypothesis", ",", "reference", ")", "in", "enumerate", "(", "zip", "(", "hypotheses", ",", "references", ")", ")", ":", "\n", "            ", "hypothesis_file", ".", "write", "(", "'{} ({})\\n'", ".", "format", "(", "hypothesis", ",", "i", ")", ")", "\n", "reference_file", ".", "write", "(", "'{} ({})\\n'", ".", "format", "(", "reference", ",", "i", ")", ")", "\n", "", "hypothesis_file", ".", "flush", "(", ")", "\n", "reference_file", ".", "flush", "(", ")", "\n", "\n", "cmd", "=", "[", "'java'", ",", "'-jar'", ",", "tercom_path", ",", "'-h'", ",", "hypothesis_file", ".", "name", ",", "'-r'", ",", "reference_file", ".", "name", "]", "\n", "if", "case_sensitive", ":", "\n", "            ", "cmd", ".", "append", "(", "'-s'", ")", "\n", "\n", "", "output", "=", "subprocess", ".", "check_output", "(", "cmd", ")", ".", "decode", "(", ")", "\n", "\n", "error", "=", "re", ".", "findall", "(", "r'Total TER: (.*?) '", ",", "output", ",", "re", ".", "MULTILINE", ")", "[", "0", "]", "\n", "return", "float", "(", "error", ")", "*", "100", ",", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_wer": [[193, 209], ["evaluation.score_function_decorator", "sum", "sum", "len", "tuple", "tuple", "len", "zip", "sum", "len", "len", "s.split", "evaluation.levenshtein", "evaluation.corpus_wer.split"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein"], ["", "", "@", "score_function_decorator", "(", "reversed", "=", "True", ")", "\n", "def", "corpus_wer", "(", "hypotheses", ",", "references", ",", "char_based", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "def", "split", "(", "s", ")", ":", "\n", "        ", "return", "tuple", "(", "s", ")", "if", "char_based", "else", "tuple", "(", "s", ".", "split", "(", ")", ")", "\n", "\n", "", "scores", "=", "[", "\n", "levenshtein", "(", "split", "(", "hyp", ")", ",", "split", "(", "ref", ")", ")", "[", "0", "]", "/", "len", "(", "split", "(", "ref", ")", ")", "\n", "for", "hyp", ",", "ref", "in", "zip", "(", "hypotheses", ",", "references", ")", "\n", "]", "\n", "\n", "score", "=", "100", "*", "sum", "(", "scores", ")", "/", "len", "(", "scores", ")", "\n", "\n", "hyp_length", "=", "sum", "(", "len", "(", "hyp", ".", "split", "(", ")", ")", "for", "hyp", "in", "hypotheses", ")", "\n", "ref_length", "=", "sum", "(", "len", "(", "ref", ".", "split", "(", ")", ")", "for", "ref", "in", "references", ")", "\n", "\n", "return", "score", ",", "'ratio={:.3f}'", ".", "format", "(", "hyp_length", "/", "ref_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_cer": [[211, 214], ["evaluation.score_function_decorator", "evaluation.corpus_wer"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_wer"], ["", "@", "score_function_decorator", "(", "reversed", "=", "True", ")", "\n", "def", "corpus_cer", "(", "hypotheses", ",", "references", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "corpus_wer", "(", "hypotheses", ",", "references", ",", "char_based", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_bleu1": [[216, 219], ["evaluation.score_function_decorator", "evaluation.corpus_bleu"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_bleu"], ["", "@", "score_function_decorator", "(", "reversed", "=", "False", ")", "\n", "def", "corpus_bleu1", "(", "hypotheses", ",", "references", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "corpus_bleu", "(", "hypotheses", ",", "references", ",", "order", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_scores": [[221, 242], ["evaluation.corpus_bleu", "evaluation.corpus_wer", "evaluation.corpus_cer", "evaluation.corpus_bleu1", "collections.OrderedDict", "evaluation.corpus_ter", "collections.OrderedDict.items"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_bleu", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_wer", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_cer", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_bleu1", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_ter"], ["", "def", "corpus_scores", "(", "hypotheses", ",", "references", ",", "main", "=", "'bleu'", ",", "**", "kwargs", ")", ":", "\n", "    ", "bleu_score", ",", "summary", "=", "corpus_bleu", "(", "hypotheses", ",", "references", ")", "\n", "# ter, _ = corpus_ter(hypotheses, references)", "\n", "try", ":", "\n", "        ", "ter", ",", "_", "=", "corpus_ter", "(", "hypotheses", ",", "references", ")", "\n", "", "except", ":", "# Java not installed", "\n", "        ", "ter", "=", "0.0", "\n", "\n", "", "wer", ",", "_", "=", "corpus_wer", "(", "hypotheses", ",", "references", ")", "\n", "cer", ",", "_", "=", "corpus_cer", "(", "hypotheses", ",", "references", ")", "\n", "bleu1", ",", "_", "=", "corpus_bleu1", "(", "hypotheses", ",", "references", ")", "\n", "\n", "scores", "=", "OrderedDict", "(", "[", "(", "'bleu'", ",", "bleu_score", ")", ",", "(", "'ter'", ",", "ter", ")", ",", "(", "'wer'", ",", "wer", ")", ",", "(", "'bleu1'", ",", "bleu1", ")", ",", "(", "'cer'", ",", "cer", ")", "]", ")", "\n", "\n", "if", "main", "is", "not", "None", ":", "\n", "        ", "main_score", "=", "scores", "[", "main", "]", "\n", "", "else", ":", "\n", "        ", "main_score", "=", "None", "\n", "\n", "", "summary", "=", "' '", ".", "join", "(", "[", "'{}={:.2f}'", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "scores", ".", "items", "(", ")", "if", "k", "!=", "main", "]", "+", "[", "summary", "]", ")", "\n", "return", "main_score", ",", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_scores_ter": [[244, 247], ["evaluation.score_function_decorator", "evaluation.corpus_scores"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_scores"], ["", "@", "score_function_decorator", "(", "reversed", "=", "True", ")", "\n", "def", "corpus_scores_ter", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "corpus_scores", "(", "*", "args", ",", "main", "=", "'ter'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_scores_wer": [[249, 252], ["evaluation.score_function_decorator", "evaluation.corpus_scores"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.score_function_decorator", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.corpus_scores"], ["", "@", "score_function_decorator", "(", "reversed", "=", "True", ")", "\n", "def", "corpus_scores_wer", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "corpus_scores", "(", "*", "args", ",", "main", "=", "'wer'", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein_rec": [[257, 269], ["functools.lru_cache", "min", "len", "len", "len", "len", "int", "evaluation.levenshtein_rec", "evaluation.levenshtein_rec", "evaluation.levenshtein_rec"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein_rec", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein_rec", "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.levenshtein_rec"], ["@", "functools", ".", "lru_cache", "(", "maxsize", "=", "1024", ")", "\n", "def", "levenshtein_rec", "(", "src", ",", "trg", ")", ":", "\n", "# Dynamic programming by memoization", "\n", "    ", "if", "len", "(", "src", ")", "==", "0", ":", "\n", "        ", "return", "len", "(", "trg", ")", "\n", "", "elif", "len", "(", "trg", ")", "==", "0", ":", "\n", "        ", "return", "len", "(", "src", ")", "\n", "\n", "", "return", "min", "(", "\n", "int", "(", "src", "[", "0", "]", "!=", "trg", "[", "0", "]", ")", "+", "levenshtein_rec", "(", "src", "[", "1", ":", "]", ",", "trg", "[", "1", ":", "]", ")", ",", "\n", "1", "+", "levenshtein_rec", "(", "src", "[", "1", ":", "]", ",", "trg", ")", ",", "\n", "1", "+", "levenshtein_rec", "(", "src", ",", "trg", "[", "1", ":", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.eske_seq2seq.translate.evaluation.tercom_statistics": [[272, 315], ["os.remove", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile", "enumerate", "hypothesis_file.flush", "reference_file.flush", "tempfile.mktemp", "open", "subprocess.call", "open", "zip", "hypothesis_file.write", "reference_file.write", "cmd.append", "line.strip().split", "stats.append", "len", "len", "dict", "len", "len", "total.items", "line.strip", "zip", "float", "x.replace"], "function", ["home.repos.pwc.inspect_result.eske_seq2seq.translate.rnn.PLSTM.call"], ["", "def", "tercom_statistics", "(", "hypotheses", ",", "references", ",", "case_sensitive", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "'w'", ")", "as", "hypothesis_file", ",", "tempfile", ".", "NamedTemporaryFile", "(", "'w'", ")", "as", "reference_file", ":", "\n", "        ", "for", "i", ",", "(", "hypothesis", ",", "reference", ")", "in", "enumerate", "(", "zip", "(", "hypotheses", ",", "references", ")", ")", ":", "\n", "            ", "hypothesis_file", ".", "write", "(", "'{} ({})\\n'", ".", "format", "(", "hypothesis", ",", "i", ")", ")", "\n", "reference_file", ".", "write", "(", "'{} ({})\\n'", ".", "format", "(", "reference", ",", "i", ")", ")", "\n", "", "hypothesis_file", ".", "flush", "(", ")", "\n", "reference_file", ".", "flush", "(", ")", "\n", "\n", "filename", "=", "tempfile", ".", "mktemp", "(", ")", "\n", "\n", "cmd", "=", "[", "'java'", ",", "'-jar'", ",", "'scripts/tercom.jar'", ",", "'-h'", ",", "hypothesis_file", ".", "name", ",", "'-r'", ",", "reference_file", ".", "name", ",", "\n", "'-o'", ",", "'sum'", ",", "'-n'", ",", "filename", "]", "\n", "if", "case_sensitive", ":", "\n", "            ", "cmd", ".", "append", "(", "'-s'", ")", "\n", "\n", "", "output", "=", "open", "(", "'/dev/null'", ",", "'w'", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "stdout", "=", "output", ",", "stderr", "=", "output", ")", "\n", "\n", "", "with", "open", "(", "filename", "+", "'.sum'", ")", "as", "f", ":", "\n", "        ", "fields", "=", "[", "'DEL'", ",", "'INS'", ",", "'SUB'", ",", "'SHIFT'", ",", "'WORD_SHIFT'", ",", "'ERRORS'", ",", "'REF_WORDS'", ",", "'TER'", "]", "\n", "\n", "stats", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "values", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "if", "len", "(", "values", ")", "!=", "9", ":", "\n", "                ", "continue", "\n", "", "try", ":", "\n", "# values = np.array([float(x) for x in values[1:]])", "\n", "                ", "values", "=", "dict", "(", "zip", "(", "fields", ",", "[", "float", "(", "x", ".", "replace", "(", "','", ",", "'.'", ")", ")", "for", "x", "in", "values", "[", "1", ":", "]", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "continue", "\n", "\n", "", "stats", ".", "append", "(", "values", ")", "\n", "\n", "", "assert", "len", "(", "stats", ")", "==", "len", "(", "hypotheses", ")", "+", "1", "\n", "\n", "total", "=", "stats", "[", "-", "1", "]", "\n", "stats", "=", "stats", "[", ":", "-", "1", "]", "\n", "total", "=", "{", "k", ":", "v", "/", "len", "(", "stats", ")", "for", "k", ",", "v", "in", "total", ".", "items", "(", ")", "}", "\n", "\n", "", "os", ".", "remove", "(", "filename", "+", "'.sum'", ")", "\n", "\n", "return", "total", ",", "stats", "\n", "\n"]]}