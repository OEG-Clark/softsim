{"home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_dcn.main": [[25, 206], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pandas.DataFrame", "print", "parameters[].drop", "print", "print", "print", "training_spec.items", "print", "enumerate", "print", "argparse.ArgumentParser.print_usage", "sys.exit", "int", "int", "int", "int", "numpy.sum", "parameters.append.append", "print", "print", "numpy.random.seed", "helpers.dataset.Dataset", "parameters.append.drop().iterrows", "print", "print", "enumerate", "parameters.append.append", "print", "sys.exit", "len", "print", "getattr", "print", "model_log[].append", "training.compression.train_dcn", "os.path.join", "os.path.isfile", "print", "print", "parser.parse_args.fill.endswith", "sorted", "print", "json.loads", "parameters.append.append", "pandas.read_csv", "numpy.ceil", "parser.parse_args.split.split", "parser.parse_args.split.split", "parser.parse_args.split.split", "parameters.append.drop", "len", "params.to_dict().items", "parameters.append.to_string", "print", "parameters.append.to_csv", "ValueError", "len", "model_log.keys", "p.replace", "helpers.debugging.mem", "helpers.utils.is_nan", "open", "json.load", "params.to_dict", "len", "key.lower", "key.lower"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.train_dcn", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.mem", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_nan", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a neural imaging pipeline'", ")", "\n", "\n", "# Parameters related to the training data", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "dest", "=", "'data'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/rgb/mni32k'", ",", "\n", "help", "=", "'directory with training & validation images (png)'", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "dest", "=", "'split'", ",", "action", "=", "'store'", ",", "default", "=", "'16000:800:2'", ",", "\n", "help", "=", "'data split with #training:#validation:#validation_patches - e.g., 16000:800:2'", ")", "\n", "parser", ".", "add_argument", "(", "'--patch'", ",", "dest", "=", "'patch_size'", ",", "action", "=", "'store'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'training patch size'", ")", "\n", "\n", "# Parameters of the DCN", "\n", "parser", ".", "add_argument", "(", "'--dcn'", ",", "dest", "=", "'dcn'", ",", "action", "=", "'store'", ",", "default", "=", "'TwitterDCN'", ",", "help", "=", "'specific DCN class name'", ")", "\n", "parser", ".", "add_argument", "(", "'--params'", ",", "dest", "=", "'dcn_params'", ",", "action", "=", "'append'", ",", "help", "=", "'Extra parameters for DCN constructor (JSON string)'", ")", "\n", "parser", ".", "add_argument", "(", "'--param_list'", ",", "dest", "=", "'dcn_param_list'", ",", "default", "=", "None", ",", "help", "=", "'CSV file with DCN configurations'", ")", "\n", "\n", "# General", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "dest", "=", "'out_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/models/dcn/playground'", ",", "\n", "help", "=", "'output directory for storing trained models'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "dest", "=", "'epochs'", ",", "action", "=", "'store'", ",", "default", "=", "1500", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--v_schedule'", ",", "dest", "=", "'validation_schedule'", ",", "action", "=", "'store'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "'Validation schedule - evaluate the model every v_schedule epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "dest", "=", "'learning_rate'", ",", "action", "=", "'store'", ",", "default", "=", "1e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--v_train'", ",", "dest", "=", "'validation_is_training'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use the model in training mode while testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_aug'", ",", "dest", "=", "'no_aug'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disable data augmentation (flipping + gamma correction)'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "dest", "=", "'resume'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Resume training from last checkpoint, if possible'", ")", "\n", "parser", ".", "add_argument", "(", "'--dry'", ",", "dest", "=", "'dry'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Dry run (no training - only does model setup)'", ")", "\n", "parser", ".", "add_argument", "(", "'--group'", ",", "dest", "=", "'run_group'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Specify run group (sub-selects scenarios for running)'", ")", "\n", "parser", ".", "add_argument", "(", "'--fill'", ",", "dest", "=", "'fill'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Path of the extended scenarios table with appended result columns'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "dcn", ":", "\n", "        ", "print", "(", "'A DCN needs to be specified!'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "parameters", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'scenario'", ",", "'label'", ",", "'active'", ",", "'run_group'", "]", ")", "\n", "\n", "try", ":", "\n", "        ", "if", "args", ".", "dcn_params", "is", "not", "None", ":", "\n", "\n", "            ", "for", "p", "in", "args", ".", "dcn_params", ":", "\n", "                ", "cli_params", "=", "json", ".", "loads", "(", "p", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "cli_params", "[", "'scenario'", "]", "=", "np", ".", "nan", "\n", "cli_params", "[", "'label'", "]", "=", "'command-line'", "\n", "cli_params", "[", "'active'", "]", "=", "True", "\n", "cli_params", "[", "'run_group'", "]", "=", "np", ".", "nan", "\n", "\n", "parameters", "=", "parameters", ".", "append", "(", "cli_params", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "if", "args", ".", "dcn_param_list", "is", "not", "None", ":", "\n", "            ", "parameters", "=", "parameters", ".", "append", "(", "pd", ".", "read_csv", "(", "args", ".", "dcn_param_list", ")", ",", "ignore_index", "=", "True", ",", "sort", "=", "True", ")", "\n", "\n", "", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", "as", "e", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error: '", ",", "e", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "# Round the number of epochs to align with the sampling rate", "\n", "", "args", ".", "epochs", "=", "int", "(", "np", ".", "ceil", "(", "args", ".", "epochs", "/", "args", ".", "validation_schedule", ")", "*", "args", ".", "validation_schedule", ")", "+", "1", "\n", "\n", "training_spec", "=", "{", "\n", "'seed'", ":", "1234", ",", "\n", "'dataset'", ":", "args", ".", "data", ",", "\n", "'n_images'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "0", "]", ")", ",", "\n", "'v_images'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ",", "\n", "'valid_patches'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "2", "]", ")", ",", "\n", "'n_epochs'", ":", "args", ".", "epochs", ",", "\n", "'batch_size'", ":", "50", ",", "\n", "'patch_size'", ":", "args", ".", "patch_size", ",", "\n", "'sample_dropout'", ":", "False", ",", "\n", "'learning_rate'", ":", "args", ".", "learning_rate", ",", "\n", "'learning_rate_reduction_schedule'", ":", "1000", ",", "\n", "'learning_rate_reduction_factor'", ":", "0.5", ",", "\n", "'validation_schedule'", ":", "args", ".", "validation_schedule", ",", "\n", "'convergence_threshold'", ":", "1e-5", ",", "\n", "'current_epoch'", ":", "0", ",", "\n", "'validation_is_training'", ":", "args", ".", "validation_is_training", ",", "\n", "'augmentation_probs'", ":", "{", "\n", "'resize'", ":", "0.0", ",", "\n", "'flip_h'", ":", "0.0", "if", "args", ".", "no_aug", "else", "0.5", ",", "\n", "'flip_v'", ":", "0.0", "if", "args", ".", "no_aug", "else", "0.5", ",", "\n", "'gamma'", ":", "0.0", "if", "args", ".", "no_aug", "else", "0.5", ",", "\n", "}", "\n", "}", "\n", "\n", "if", "np", ".", "sum", "(", "parameters", "[", "'active'", "]", "==", "True", ")", "==", "0", ":", "\n", "        ", "parameters", ".", "append", "(", "{", "'name'", ":", "'default'", ",", "'active'", ":", "True", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "print", "(", "'DCN model: {}'", ".", "format", "(", "args", ".", "dcn", ")", ")", "\n", "\n", "if", "args", ".", "run_group", "is", "not", "None", ":", "\n", "        ", "parameters", "=", "parameters", "[", "parameters", "[", "'run_group'", "]", "==", "args", ".", "run_group", "]", "\n", "\n", "", "parameters", "=", "parameters", "[", "parameters", "[", "'active'", "]", "]", ".", "drop", "(", "columns", "=", "[", "'active'", ",", "'run_group'", "]", ")", "\n", "print", "(", "'# DCN parameter list [{} active configs]:\\n'", ".", "format", "(", "len", "(", "parameters", ")", ")", ")", "\n", "print", "(", "parameters", ")", "\n", "\n", "print", "(", "'\\n# Training Spec:'", ")", "\n", "for", "key", ",", "value", "in", "training_spec", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "' {:50s}: {}'", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "\n", "# Load the dataset", "\n", "", "if", "not", "args", ".", "dry", ":", "\n", "        ", "print", "(", "'\\n# Dataset:'", ")", "\n", "np", ".", "random", ".", "seed", "(", "training_spec", "[", "'seed'", "]", ")", "\n", "data", "=", "dataset", ".", "Dataset", "(", "args", ".", "data", ",", "n_images", "=", "training_spec", "[", "'n_images'", "]", ",", "v_images", "=", "training_spec", "[", "'v_images'", "]", ",", "load", "=", "'y'", ",", "\n", "val_rgb_patch_size", "=", "training_spec", "[", "'patch_size'", "]", ",", "val_n_patches", "=", "training_spec", "[", "'valid_patches'", "]", ")", "\n", "\n", "for", "key", "in", "[", "'Training'", ",", "'Validation'", "]", ":", "\n", "            ", "print", "(", "'{:>16s} [{:5.1f} GB] : Y -> {} '", ".", "format", "(", "\n", "'{} data'", ".", "format", "(", "key", ")", ",", "\n", "helpers", ".", "debugging", ".", "mem", "(", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'y'", "]", ")", ",", "\n", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'y'", "]", ".", "shape", "\n", ")", ",", "flush", "=", "True", ")", "\n", "\n", "", "", "model_log", "=", "{", "}", "\n", "\n", "# If requested, add columns to include results", "\n", "parameters", "[", "'ssim'", "]", "=", "np", ".", "nan", "\n", "parameters", "[", "'entropy'", "]", "=", "np", ".", "nan", "\n", "parameters", "[", "'loss'", "]", "=", "np", ".", "nan", "\n", "\n", "print", "(", "'\\n# Training:\\n'", ")", "\n", "\n", "for", "counter", ",", "(", "index", ",", "params", ")", "in", "enumerate", "(", "parameters", ".", "drop", "(", "columns", "=", "[", "'scenario'", ",", "'label'", "]", ")", ".", "iterrows", "(", ")", ")", ":", "\n", "\n", "        ", "print", "(", "'## Scenario {} - {} / {}'", ".", "format", "(", "index", ",", "counter", "+", "1", ",", "len", "(", "parameters", ")", ")", ")", "\n", "\n", "# Create a DCN according to the spec", "\n", "dcn_params", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "params", ".", "to_dict", "(", ")", ".", "items", "(", ")", "if", "not", "utils", ".", "is_nan", "(", "v", ")", "}", "\n", "dcn", "=", "getattr", "(", "compression", ",", "args", ".", "dcn", ")", "(", "patch_size", "=", "training_spec", "[", "'patch_size'", "]", ",", "**", "dcn_params", ")", "\n", "\n", "model_code", "=", "dcn", ".", "model_code", "\n", "\n", "if", "model_code", "in", "model_log", ":", "\n", "            ", "print", "(", "'WARNING - model {} already registered by scenario {}'", ".", "format", "(", "model_code", ",", "index", ")", ")", "\n", "model_log", "[", "model_code", "]", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "model_log", "[", "model_code", "]", "=", "[", "index", "]", "\n", "\n", "", "if", "not", "args", ".", "dry", ":", "\n", "            ", "train_dcn", "(", "dcn", ",", "training_spec", ",", "data", ",", "args", ".", "out_dir", ")", "\n", "\n", "# Fill the table with results, if requested", "\n", "", "if", "args", ".", "fill", "is", "not", "None", ":", "\n", "\n", "            ", "results_json", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_dir", ",", "dcn", ".", "model_code", ",", "dcn", ".", "scoped_name", ",", "'progress.json'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "results_json", ")", ":", "\n", "\n", "                ", "with", "open", "(", "results_json", ")", "as", "f", ":", "\n", "                    ", "results", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "parameters", ".", "loc", "[", "index", ",", "'ssim'", "]", "=", "results", "[", "'performance'", "]", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "parameters", ".", "loc", "[", "index", ",", "'loss'", "]", "=", "results", "[", "'performance'", "]", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "parameters", ".", "loc", "[", "index", ",", "'entropy'", "]", "=", "results", "[", "'performance'", "]", "[", "'entropy'", "]", "[", "'training'", "]", "[", "-", "1", "]", "\n", "\n", "", "", "", "if", "args", ".", "fill", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "fill", "==", "'-'", ":", "\n", "            ", "print", "(", "'\\n# Training Results'", ")", "\n", "print", "(", "parameters", ".", "to_string", "(", ")", ")", "\n", "", "elif", "args", ".", "fill", ".", "endswith", "(", "'.csv'", ")", ":", "\n", "            ", "print", "(", "'Saving the results to {}'", ".", "format", "(", "args", ".", "fill", ")", ")", "\n", "parameters", ".", "to_csv", "(", "args", ".", "fill", ",", "index", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid value for the output results file: {}'", ".", "format", "(", "args", ".", "fill", ")", ")", "\n", "\n", "", "", "if", "args", ".", "dry", ":", "\n", "        ", "print", "(", "'\\n# List of instantiated models [{}]:'", ".", "format", "(", "len", "(", "model_log", ")", ")", ")", "\n", "for", "index", ",", "key", "in", "enumerate", "(", "sorted", "(", "model_log", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "print", "(", "'{}  {:3d}. {} -> {}'", ".", "format", "(", "' '", "if", "len", "(", "model_log", "[", "key", "]", ")", "==", "1", "else", "'!'", ",", "index", ",", "key", ",", "model_log", "[", "key", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_nip.develop_image": [[19, 119], ["os.path.isdir", "isinstance", "tfmodel.restore.process().numpy", "helpers.metrics.psnr", "helpers.metrics.ssim", "print", "print", "print", "print", "plt.subplots", "helpers.plots.image", "helpers.plots.image", "plt.show", "plt.close", "helpers.fsutil.listdir", "os.path.join", "os.path.join", "ValueError", "models.tfmodel.restore", "print", "helpers.dataset.Dataset", "dataset.Dataset.next_validation_batch", "print", "tfmodel.restore.set_cfa_pattern", "tfmodel.restore.set_srgb_conversion", "len", "helpers.plots.thumbnails", "helpers.plots.thumbnails", "raw.process.squeeze", "sample_Y.squeeze.squeeze", "os.path.join", "ValueError", "os.path.join", "os.path.join", "os.path.isdir", "FileNotFoundError", "open", "json.load", "print", "helpers.raw.unpack", "helpers.raw.process", "tfmodel.restore.process", "float", "float", "getattr", "getattr", "tfmodel.restore.load_model", "numpy.array", "srgb.round().tolist", "metrics.psnr.mean", "metrics.ssim.mean", "srgb.round"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model"], ["def", "develop_image", "(", "pipeline", ",", "camera", "=", "None", ",", "batch", "=", "None", ",", "image", "=", "None", ",", "patch_size", "=", "0", ",", "patches", "=", "2", ",", "root_dir", "=", "'./data'", ",", "pipeline_args", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Display a patch developed by a neural imaging pipeline.\n    \"\"\"", "\n", "\n", "if", "camera", "is", "not", "None", ":", "\n", "        ", "supported_cameras", "=", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'models'", ",", "'nip'", ")", ",", "'.*'", ")", "\n", "if", "camera", "not", "in", "supported_cameras", ":", "\n", "            ", "raise", "ValueError", "(", "'Camera data not found ({})! Available cameras: {}'", ".", "format", "(", "camera", ",", "', '", ".", "join", "(", "supported_cameras", ")", ")", ")", "\n", "", "root_dirname", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'models'", ",", "'nip'", ",", "camera", ")", "\n", "data_dirname", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "'training_data'", ",", "camera", ")", "\n", "\n", "", "if", "patch_size", "!=", "0", "and", "(", "patch_size", "<", "4", "or", "patch_size", ">", "2048", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Patch size seems to be invalid!'", ")", "\n", "\n", "# Lazy imports to minimize delay for invalid command line parameters", "\n", "", "import", "numpy", "as", "np", "\n", "import", "imageio", "as", "io", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "import", "tensorflow", "as", "tf", "\n", "from", "models", "import", "pipelines", "\n", "\n", "# Construct the NIP model ---------------------------------------------------------------------", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "pipeline", ")", ":", "\n", "# Restore a NIP model from a training log", "\n", "        ", "model", "=", "tfmodel", ".", "restore", "(", "pipeline", ",", "pipelines", ")", "\n", "", "else", ":", "\n", "# Construct the NIP model from class name (and optional arguments)", "\n", "        ", "if", "pipeline_args", "is", "None", ":", "\n", "            ", "model", "=", "getattr", "(", "pipelines", ",", "pipeline", ")", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "getattr", "(", "pipelines", ",", "pipeline", ")", "(", "**", "pipeline_args", ")", "\n", "\n", "", "loaded_model", "=", "False", "\n", "candidate_dirs", "=", "[", "os", ".", "path", ".", "join", "(", "root_dirname", ",", "model", ".", "model_code", ")", ",", "os", ".", "path", ".", "join", "(", "root_dirname", ")", "]", "\n", "for", "candidate", "in", "candidate_dirs", ":", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "candidate", ")", ":", "\n", "                ", "model", ".", "load_model", "(", "candidate", ")", "\n", "loaded_model", "=", "True", "\n", "break", "\n", "\n", "", "", "if", "not", "loaded_model", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f'Could not find the corresponding model: {candidate_dirs}'", ")", "\n", "\n", "# Load image(s) -------------------------------------------------------------------------------", "\n", "\n", "", "", "if", "image", "is", "None", "and", "batch", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading a batch of {} images'", ".", "format", "(", "batch", ")", ")", "\n", "data", "=", "dataset", ".", "Dataset", "(", "data_dirname", ",", "n_images", "=", "0", ",", "v_images", "=", "batch", ",", "val_rgb_patch_size", "=", "patch_size", "or", "256", ",", "val_n_patches", "=", "patches", ")", "\n", "sample_x", ",", "sample_y", "=", "data", ".", "next_validation_batch", "(", "0", ",", "data", ".", "count_validation", ")", "\n", "\n", "with", "open", "(", "'config/cameras.json'", ")", "as", "f", ":", "\n", "            ", "cameras", "=", "json", ".", "load", "(", "f", ")", "\n", "cfa", ",", "srgb", "=", "cameras", "[", "camera", "]", "[", "'cfa'", "]", ",", "np", ".", "array", "(", "cameras", "[", "camera", "]", "[", "'srgb'", "]", ")", "\n", "\n", "", "", "elif", "image", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading a RAW image {}'", ".", "format", "(", "image", ")", ")", "\n", "sample_x", ",", "cfa", ",", "srgb", ",", "_", "=", "raw", ".", "unpack", "(", "image", ",", "expand", "=", "True", ")", "\n", "sample_y", "=", "raw", ".", "process", "(", "image", ",", "brightness", "=", "None", ",", "expand", "=", "True", ")", "\n", "\n", "", "if", "isinstance", "(", "model", ",", "pipelines", ".", "ClassicISP", ")", ":", "\n", "        ", "print", "(", "'Configuring ISP to CFA: {} & sRGB {}'", ".", "format", "(", "cfa", ",", "srgb", ".", "round", "(", "2", ")", ".", "tolist", "(", ")", ")", ")", "\n", "model", ".", "set_cfa_pattern", "(", "cfa", ")", "\n", "model", ".", "set_srgb_conversion", "(", "srgb", ")", "\n", "\n", "", "sample_Y", "=", "model", ".", "process", "(", "sample_x", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "patch_size", ">", "0", ":", "\n", "        ", "xx", "=", "(", "sample_y", ".", "shape", "[", "2", "]", "-", "patch_size", ")", "//", "2", "\n", "yy", "=", "(", "sample_y", ".", "shape", "[", "1", "]", "-", "patch_size", ")", "//", "2", "\n", "sample_y", "=", "sample_y", "[", ":", ",", "yy", ":", "yy", "+", "patch_size", ",", "xx", ":", "xx", "+", "patch_size", ",", ":", "]", "\n", "sample_Y", "=", "sample_Y", "[", ":", ",", "yy", ":", "yy", "+", "patch_size", ",", "xx", ":", "xx", "+", "patch_size", ",", ":", "]", "\n", "\n", "", "psnrs", "=", "metrics", ".", "psnr", "(", "sample_y", ",", "sample_Y", ")", "\n", "ssims", "=", "metrics", ".", "ssim", "(", "sample_y", ",", "sample_Y", ")", "\n", "\n", "print", "(", "'sample x: {}'", ".", "format", "(", "sample_x", ".", "shape", ")", ")", "\n", "print", "(", "'sample y: {}'", ".", "format", "(", "sample_y", ".", "shape", ")", ")", "\n", "print", "(", "'sample Y: {}'", ".", "format", "(", "sample_Y", ".", "shape", ")", ")", "\n", "\n", "# Plot images ---------------------------------------------------------------------------------", "\n", "if", "len", "(", "sample_y", ")", ">", "1", ":", "\n", "        ", "sample_y", "=", "plots", ".", "thumbnails", "(", "sample_y", ",", "batch", ",", "True", ")", "\n", "sample_Y", "=", "plots", ".", "thumbnails", "(", "sample_Y", ",", "batch", ",", "True", ")", "\n", "", "else", ":", "\n", "        ", "sample_y", "=", "sample_y", ".", "squeeze", "(", ")", "\n", "sample_Y", "=", "sample_Y", ".", "squeeze", "(", ")", "\n", "\n", "", "print", "(", "'thumbnails: {}'", ".", "format", "(", "sample_y", ".", "shape", ")", ")", "\n", "\n", "ncols", "=", "1", "if", "sample_y", ".", "shape", "[", "1", "]", ">", "sample_y", ".", "shape", "[", "0", "]", "else", "2", "\n", "nrows", "=", "2", "if", "ncols", "==", "1", "else", "1", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "nrows", ",", "ncols", ")", "\n", "\n", "plots", ".", "image", "(", "sample_Y", ",", "'{}, PSNR={:.1f} dB, SSIM={:.2f} : {{}}'", ".", "format", "(", "model", ".", "model_code", ",", "float", "(", "psnrs", ".", "mean", "(", ")", ")", ",", "float", "(", "ssims", ".", "mean", "(", ")", ")", ")", ",", "axes", "=", "axes", "[", "0", "]", ")", "\n", "plots", ".", "image", "(", "sample_y", ",", "'Target RGB images () : {}'", ",", "axes", "=", "axes", "[", "1", "]", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_nip.main": [[121, 151], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "test_nip.develop_image", "print", "argparse.ArgumentParser.print_usage", "sys.exit", "json.loads", "print", "sys.exit", "parser.parse_args.hyperparams_args.replace", "parser.parse_args.hyperparams_args.replace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_nip.develop_image"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Develops RAW images with a selected pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'-n'", ",", "'--nip'", ",", "dest", "=", "'nip'", ",", "action", "=", "'store'", ",", "help", "=", "'model name / path to a trained ISP model'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--image'", ",", "dest", "=", "'image'", ",", "action", "=", "'store'", ",", "help", "=", "'path to a RAW image'", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "'--batch'", ",", "dest", "=", "'batch'", ",", "action", "=", "'store'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "'load a batch of images (batch size)'", ")", "\n", "parser", ".", "add_argument", "(", "'-t'", ",", "'--patches'", ",", "dest", "=", "'patches'", ",", "action", "=", "'store'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of patches per image'", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--patch'", ",", "dest", "=", "'patch'", ",", "action", "=", "'store'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'patch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "'--dir'", ",", "dest", "=", "'dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data'", ",", "\n", "help", "=", "'root directory with images and training data'", ")", "\n", "parser", ".", "add_argument", "(", "'--ha'", ",", "dest", "=", "'hyperparams_args'", ",", "default", "=", "None", ",", "help", "=", "'Set hyper-parameters / override CSV settings if needed (JSON string)'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "nip", ":", "\n", "        ", "print", "(", "'Camera ISP not specified!'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "hyperparams_args", "is", "not", "None", ":", "\n", "            ", "args", ".", "hyperparams_args", "=", "json", ".", "loads", "(", "args", ".", "hyperparams_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "hyperparams_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "develop_image", "(", "args", ".", "nip", ",", "args", ".", "camera", ",", "args", ".", "batch", ",", "args", ".", "image", ",", "args", ".", "patch", ",", "args", ".", "patches", ",", "args", ".", "dir", ",", "args", ".", "hyperparams_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.match_jpeg": [[22, 91], ["compression.codec.simulate_compression", "helpers.metrics.ssim().mean", "compression.jpeg_helpers.compress_batch", "helpers.metrics.ssim().mean", "model.get_codebook", "model.compress().numpy", "helpers.stats.hist", "helpers.stats.hist", "helpers.stats.hist", "counts.clip.clip", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "helpers.plots.image", "helpers.plots.image", "helpers.plots.image", "max", "helpers.plots.image", "helpers.plots.image", "helpers.plots.image", "numpy.prod", "compression.jpeg_helpers.match_quality", "numpy.prod", "counts.clip.sum", "numpy.sum", "helpers.plots.sub", "fig.set_size_inches", "fig.tight_layout", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.image.crop_middle", "helpers.metrics.ssim", "batch_x.squeeze", "print", "helpers.metrics.ssim", "model.compress", "numpy.prod", "numpy.prod", "len", "min", "max", "numpy.prod", "numpy.ceil", "batch_x.squeeze", "batch_y.squeeze", "batch_x.squeeze", "batch_j.squeeze", "numpy.log2", "numpy.log2", "numpy.prod", "numpy.prod", "numpy.log2", "numpy.prod", "numpy.ceil", "len", "numpy.prod", "numpy.prod", "len", "numpy.log2", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.simulate_compression", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.match_quality", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress"], ["def", "match_jpeg", "(", "model", ",", "batch_x", ",", "axes", "=", "None", ",", "match", "=", "'ssim'", ")", ":", "\n", "\n", "# Compress using DCN and get number of bytes", "\n", "    ", "batch_y", ",", "bytes_dcn", "=", "codec", ".", "simulate_compression", "(", "batch_x", ",", "model", ")", "\n", "\n", "ssim_dcn", "=", "metrics", ".", "ssim", "(", "batch_x", ".", "squeeze", "(", ")", ",", "batch_y", ".", "squeeze", "(", ")", ")", ".", "mean", "(", ")", "\n", "bpp_dcn", "=", "8", "*", "bytes_dcn", "/", "np", ".", "prod", "(", "batch_x", ".", "shape", "[", "1", ":", "-", "1", "]", ")", "\n", "target", "=", "ssim_dcn", "if", "match", "==", "'ssim'", "else", "bpp_dcn", "\n", "\n", "try", ":", "\n", "        ", "jpeg_quality", "=", "jpeg_helpers", ".", "match_quality", "(", "batch_x", ".", "squeeze", "(", ")", ",", "target", ",", "match", "=", "match", ")", "\n", "", "except", ":", "\n", "        ", "if", "match", "==", "'ssim'", ":", "\n", "            ", "jpeg_quality", "=", "95", "if", "ssim_dcn", ">", "0.8", "else", "10", "\n", "", "else", ":", "\n", "            ", "jpeg_quality", "=", "95", "if", "bpp_dcn", ">", "3", "else", "10", "\n", "", "print", "(", "'WARNING Could not find a matching JPEG quality factor - guessing {}'", ".", "format", "(", "jpeg_quality", ")", ")", "\n", "\n", "# Compress using JPEG", "\n", "", "batch_j", ",", "bytes_jpeg", "=", "jpeg_helpers", ".", "compress_batch", "(", "batch_x", "[", "0", "]", ",", "jpeg_quality", ",", "effective", "=", "True", ")", "\n", "ssim_jpeg", "=", "metrics", ".", "ssim", "(", "batch_x", ".", "squeeze", "(", ")", ",", "batch_j", ".", "squeeze", "(", ")", ")", ".", "mean", "(", ")", "\n", "bpp_jpg", "=", "8", "*", "bytes_jpeg", "/", "np", ".", "prod", "(", "batch_x", ".", "shape", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# Get stats", "\n", "code_book", "=", "model", ".", "get_codebook", "(", ")", "\n", "batch_z", "=", "model", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "counts", "=", "helpers", ".", "stats", ".", "hist", "(", "batch_z", ",", "code_book", ")", "\n", "counts", "=", "counts", ".", "clip", "(", "min", "=", "1", ")", "\n", "probs", "=", "counts", "/", "counts", ".", "sum", "(", ")", "\n", "entropy", "=", "-", "np", ".", "sum", "(", "probs", "*", "np", ".", "log2", "(", "probs", ")", ")", "\n", "\n", "# Print report", "\n", "print", "(", "'DCN             : {}'", ".", "format", "(", "model", ".", "model_code", ")", ")", "\n", "print", "(", "'Pixels          : {}x{} = {:,} px'", ".", "format", "(", "batch_x", ".", "shape", "[", "1", "]", ",", "batch_x", ".", "shape", "[", "2", "]", ",", "np", ".", "prod", "(", "batch_x", ".", "shape", "[", "1", ":", "-", "1", "]", ")", ")", ")", "\n", "print", "(", "'Bitmap          : {:,} bytes'", ".", "format", "(", "np", ".", "prod", "(", "batch_x", ".", "shape", ")", ")", ")", "\n", "print", "(", "'Code-book size  : {} elements from {} to {}'", ".", "format", "(", "len", "(", "code_book", ")", ",", "min", "(", "code_book", ")", ",", "max", "(", "code_book", ")", ")", ")", "\n", "print", "(", "'Entropy         : {:.2f} bits per symbol'", ".", "format", "(", "entropy", ")", ")", "\n", "print", "(", "'Latent size     : {:,}'", ".", "format", "(", "np", ".", "prod", "(", "batch_z", ".", "shape", ")", ")", ")", "\n", "print", "(", "'PPF Naive       : {:,.0f} --> {:,.0f} bytes [{} bits per element]'", ".", "format", "(", "\n", "np", ".", "prod", "(", "batch_z", ".", "shape", ")", "*", "np", ".", "log2", "(", "len", "(", "code_book", ")", ")", "/", "8", ",", "\n", "np", ".", "prod", "(", "batch_z", ".", "shape", ")", "*", "np", ".", "ceil", "(", "np", ".", "log2", "(", "len", "(", "code_book", ")", ")", ")", "/", "8", ",", "\n", "np", ".", "ceil", "(", "np", ".", "log2", "(", "len", "(", "code_book", ")", ")", ")", "\n", ")", ")", "\n", "print", "(", "'PPF Theoretical : {:,.0f} bytes ({:.2f} bpp)'", ".", "format", "(", "\n", "np", ".", "prod", "(", "batch_z", ".", "shape", ")", "*", "entropy", "/", "8", ",", "\n", "np", ".", "prod", "(", "batch_z", ".", "shape", ")", "*", "entropy", "/", "np", ".", "prod", "(", "batch_x", ".", "shape", "[", "1", ":", "-", "1", "]", ")", ")", ")", "\n", "print", "(", "'FSE Coded       : {:,} bytes ({:.2f} bpp) --> ssim: {:.3f}'", ".", "format", "(", "bytes_dcn", ",", "bpp_dcn", ",", "ssim_dcn", ")", ")", "\n", "print", "(", "'JPEG (Q={:2d})     : {:,} bytes ({:0.2f} bpp) --> ssim: {:.3f} // effective size disregarding JPEG headers'", ".", "format", "(", "jpeg_quality", ",", "bytes_jpeg", ",", "bpp_jpg", ",", "ssim_jpeg", ")", ")", "\n", "\n", "# Plot results", "\n", "if", "axes", "is", "None", ":", "\n", "        ", "fig", ",", "axes", "=", "plots", ".", "sub", "(", "6", ",", "ncols", "=", "3", ")", "\n", "fig", ".", "set_size_inches", "(", "12", ",", "10", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "", "else", ":", "\n", "        ", "fig", "=", "axes", "[", "0", "]", ".", "figure", "\n", "\n", "# Plot full-resolution", "\n", "", "plots", ".", "image", "(", "batch_x", ",", "'Original ({0}x{0})'", ".", "format", "(", "batch_x", ".", "shape", "[", "1", "]", ")", ",", "axes", "=", "axes", "[", "0", "]", ")", "\n", "plots", ".", "image", "(", "batch_y", ",", "'DCN ssim:{:.2f} bpp:{:.2f}'", ".", "format", "(", "ssim_dcn", ",", "bpp_dcn", ")", ",", "axes", "=", "axes", "[", "1", "]", ")", "\n", "plots", ".", "image", "(", "batch_j", ",", "'JPEG {} ssim:{:.2f} bpp:{:.2f}'", ".", "format", "(", "jpeg_quality", ",", "ssim_jpeg", ",", "bpp_jpg", ")", ",", "axes", "=", "axes", "[", "2", "]", ")", "\n", "\n", "# Plot zoom", "\n", "crop_size", "=", "max", "(", "[", "64", ",", "batch_x", ".", "shape", "[", "1", "]", "//", "4", "]", ")", "\n", "plots", ".", "image", "(", "helpers", ".", "image", ".", "crop_middle", "(", "batch_x", ",", "crop_size", ")", ",", "'Original crop ({0}x{0})'", ".", "format", "(", "crop_size", ")", ",", "axes", "=", "axes", "[", "3", "]", ")", "\n", "plots", ".", "image", "(", "helpers", ".", "image", ".", "crop_middle", "(", "batch_y", ",", "crop_size", ")", ",", "'DCN crop ({0}x{0})'", ".", "format", "(", "crop_size", ")", ",", "axes", "=", "axes", "[", "4", "]", ")", "\n", "plots", ".", "image", "(", "helpers", ".", "image", ".", "crop_middle", "(", "batch_j", ",", "crop_size", ")", ",", "'JPEG crop ({0}x{0})'", ".", "format", "(", "crop_size", ")", ",", "axes", "=", "axes", "[", "5", "]", ")", "\n", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.show_example": [[93, 142], ["model.compress().numpy", "model.decompress().numpy", "model.get_codebook", "numpy.floor", "numpy.ceil", "numpy.arange", "numpy.convolve", "numpy.maximum", "helpers.stats.hist", "helpers.stats.hist", "helpers.stats.hist", "helpers.plots.sub", "fig.set_size_inches", "axes[].plot", "axes[].plot", "axes[].legend", "axes[].set_ylabel", "axes[].set_xlabel", "numpy.concatenate", "helpers.plots.image", "fig.tight_layout", "numpy.histogram", "np.maximum.sum", "helpers.stats.hist.sum", "numpy.sum", "numpy.sum", "numpy.argsort", "helpers.metrics.ssim().mean", "model.compress", "model.decompress", "model.compress().numpy.reshape", "np.maximum.max", "helpers.stats.hist.max", "numpy.var", "range", "numpy.mean", "numpy.log2", "numpy.log2", "helpers.plots.thumbnails", "helpers.metrics.ssim", "len", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim"], ["", "def", "show_example", "(", "model", ",", "batch_x", ")", ":", "\n", "\n", "# Compress and decompress model", "\n", "    ", "batch_z", "=", "model", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "batch_y", "=", "model", ".", "decompress", "(", "batch_z", ")", ".", "numpy", "(", ")", "\n", "\n", "# Get empirical histogram of the latent representation", "\n", "codebook", "=", "model", ".", "get_codebook", "(", ")", "\n", "\n", "qmin", "=", "np", ".", "floor", "(", "codebook", "[", "0", "]", ")", "\n", "qmax", "=", "np", ".", "ceil", "(", "codebook", "[", "-", "1", "]", ")", "\n", "\n", "bin_centers", "=", "np", ".", "arange", "(", "qmin", "-", "1", ",", "qmax", "+", "1", ",", "0.1", ")", "\n", "bin_boundaries", "=", "np", ".", "convolve", "(", "bin_centers", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "bin_centers", "=", "bin_centers", "[", "1", ":", "-", "1", "]", "\n", "\n", "hist_emp", "=", "np", ".", "histogram", "(", "batch_z", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", ",", "bins", "=", "bin_boundaries", ",", "density", "=", "True", ")", "[", "0", "]", "\n", "hist_emp", "=", "np", ".", "maximum", "(", "hist_emp", ",", "1e-9", ")", "\n", "hist_emp", "=", "hist_emp", "/", "hist_emp", ".", "sum", "(", ")", "\n", "\n", "# Get TF histogram estimate based on soft quantization", "\n", "hist", "=", "helpers", ".", "stats", ".", "hist", "(", "batch_z", ",", "codebook", ")", "\n", "hist", "=", "hist", "/", "hist", ".", "sum", "(", ")", "\n", "\n", "# Entropy", "\n", "entropy", "=", "-", "np", ".", "sum", "(", "hist", "*", "np", ".", "log2", "(", "hist", ")", ")", "\n", "entropy_emp", "=", "-", "np", ".", "sum", "(", "hist_emp", "*", "np", ".", "log2", "(", "hist_emp", ")", ")", "\n", "\n", "fig", ",", "axes", "=", "plots", ".", "sub", "(", "2", ",", "ncols", "=", "1", ")", "\n", "fig", ".", "set_size_inches", "(", "12", ",", "10", ")", "\n", "\n", "axes", "[", "0", "]", ".", "plot", "(", "bin_centers", ",", "hist_emp", "/", "hist_emp", ".", "max", "(", ")", ",", "'r-'", ")", "\n", "axes", "[", "0", "]", ".", "plot", "(", "codebook", ",", "hist", "/", "hist", ".", "max", "(", ")", ",", "'-bo'", ")", "\n", "\n", "axes", "[", "0", "]", ".", "legend", "(", "[", "'Empirical H={:.2f}'", ".", "format", "(", "entropy_emp", ")", ",", "'TF estimate (soft) H={:.2f}'", ".", "format", "(", "entropy", ")", "]", ")", "\n", "axes", "[", "0", "]", ".", "set_ylabel", "(", "'normalized frequency'", ")", "\n", "axes", "[", "0", "]", ".", "set_xlabel", "(", "'latent values'", ")", "\n", "\n", "# Thumbnails", "\n", "indices", "=", "np", ".", "argsort", "(", "np", ".", "var", "(", "batch_x", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "thumbs_pairs_few", "=", "np", ".", "concatenate", "(", "(", "batch_x", "[", "indices", "]", ",", "batch_y", "[", "indices", "]", ")", ",", "axis", "=", "0", ")", "\n", "thumbs_few", "=", "(", "255", "*", "plots", ".", "thumbnails", "(", "thumbs_pairs_few", ",", "ncols", "=", "len", "(", "batch_x", ")", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "ssim_values", "=", "[", "metrics", ".", "ssim", "(", "batch_x", "[", "i", "]", ",", "batch_y", "[", "i", "]", ")", ".", "mean", "(", ")", "for", "i", "in", "range", "(", "len", "(", "batch_x", ")", ")", "]", "\n", "\n", "plots", ".", "image", "(", "thumbs_few", ",", "'Sample reconstructions, ssim={:.3f}'", ".", "format", "(", "np", ".", "mean", "(", "ssim_values", ")", ")", ",", "axes", "=", "axes", "[", "1", "]", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.main": [[144, 216], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "helpers.utils.match_option", "helpers.utils.match_option", "helpers.utils.match_option", "compression.codec.restore", "print", "helpers.dataset.Dataset", "dataset.Dataset.next_validation_batch", "test_dcn.show_example", "matplotlib.show", "matplotlib.close", "helpers.loading.discover_images", "helpers.loading.load_images", "compression.codec.restore", "test_dcn.match_jpeg", "matplotlib.show", "matplotlib.close", "batch_x[].astype", "helpers.loading.discover_images", "helpers.loading.load_images", "compression.codec.restore", "test_dcn.match_jpeg", "matplotlib.show", "matplotlib.close", "batch_x[].astype", "compression.ratedistortion.get_jpeg_df", "print", "ratedistortion.get_bpg_df.to_string", "compression.ratedistortion.get_jpeg2k_df", "print", "ratedistortion.get_bpg_df.to_string", "compression.ratedistortion.get_dcn_df", "print", "ratedistortion.get_bpg_df.to_string", "compression.ratedistortion.get_bpg_df", "print", "print", "ratedistortion.get_bpg_df.to_string"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.show_example", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.match_jpeg", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn.match_jpeg", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_jpeg_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_jpeg2k_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_dcn_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_bpg_df"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Test a neural imaging pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'plot'", ",", "help", "=", "'Plot type ({})'", ".", "format", "(", "', '", ".", "join", "(", "supported_plots", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "dest", "=", "'data'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/rgb/clic256/'", ",", "\n", "help", "=", "'directory with training & validation images (png)'", ")", "\n", "parser", ".", "add_argument", "(", "'--images'", ",", "dest", "=", "'images'", ",", "action", "=", "'store'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of images to test'", ")", "\n", "parser", ".", "add_argument", "(", "'--image'", ",", "dest", "=", "'image_id'", ",", "action", "=", "'store'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'ID of the image to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--patch'", ",", "dest", "=", "'patch_size'", ",", "action", "=", "'store'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'training patch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--dcn'", ",", "dest", "=", "'dcn'", ",", "action", "=", "'store'", ",", "\n", "help", "=", "'directory with a trained DCN model'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Match the current", "\n", "args", ".", "plot", "=", "helpers", ".", "utils", ".", "match_option", "(", "args", ".", "plot", ",", "supported_plots", ")", "\n", "\n", "if", "args", ".", "plot", "==", "'batch'", ":", "\n", "        ", "model", ",", "stats", "=", "codec", ".", "restore", "(", "args", ".", "dcn", ",", "args", ".", "patch_size", ",", "fetch_stats", "=", "True", ")", "\n", "print", "(", "'Training stats:'", ",", "stats", ")", "\n", "\n", "data", "=", "dataset", ".", "Dataset", "(", "args", ".", "data", ",", "load", "=", "'y'", ",", "n_images", "=", "0", ",", "v_images", "=", "args", ".", "images", ",", "val_rgb_patch_size", "=", "args", ".", "patch_size", ")", "\n", "batch_x", "=", "data", ".", "next_validation_batch", "(", "0", ",", "args", ".", "images", ")", "\n", "\n", "fig", "=", "show_example", "(", "model", ",", "batch_x", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'jpeg-match-ssim'", ":", "\n", "        ", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "args", ".", "data", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "files", "=", "files", "[", "args", ".", "image_id", ":", "args", ".", "image_id", "+", "1", "]", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "args", ".", "data", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "model", "=", "codec", ".", "restore", "(", "args", ".", "dcn", ",", "batch_x", ".", "shape", "[", "1", "]", ")", "\n", "\n", "fig", "=", "match_jpeg", "(", "model", ",", "batch_x", ",", "match", "=", "'ssim'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'jpeg-match-bpp'", ":", "\n", "        ", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "args", ".", "data", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "files", "=", "files", "[", "args", ".", "image_id", ":", "args", ".", "image_id", "+", "1", "]", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "args", ".", "data", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "model", "=", "codec", ".", "restore", "(", "args", ".", "dcn", ",", "batch_x", ".", "shape", "[", "1", "]", ")", "\n", "\n", "fig", "=", "match_jpeg", "(", "model", ",", "batch_x", ",", "match", "=", "'bpp'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'jpg-trade-off'", ":", "\n", "        ", "df", "=", "ratedistortion", ".", "get_jpeg_df", "(", "args", ".", "data", ",", "write_files", "=", "True", ")", "\n", "print", "(", "df", ".", "to_string", "(", ")", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'jp2-trade-off'", ":", "\n", "        ", "df", "=", "ratedistortion", ".", "get_jpeg2k_df", "(", "args", ".", "data", ",", "write_files", "=", "True", ")", "\n", "print", "(", "df", ".", "to_string", "(", ")", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'dcn-trade-off'", ":", "\n", "        ", "df", "=", "ratedistortion", ".", "get_dcn_df", "(", "args", ".", "data", ",", "args", ".", "dcn", ",", "write_files", "=", "False", ")", "\n", "print", "(", "df", ".", "to_string", "(", ")", ")", "\n", "\n", "", "elif", "args", ".", "plot", "==", "'bpg-trade-off'", ":", "\n", "        ", "df", "=", "ratedistortion", ".", "get_bpg_df", "(", "args", ".", "data", ",", "write_files", "=", "False", ")", "\n", "print", "(", "df", ".", "to_string", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Error: Unknown plot!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.diff_nip.compare_nips": [[19, 141], ["helpers.fsutil.listdir", "os.path.isdir", "os.path.isdir", "print", "print", "isinstance", "isinstance", "tfmodel.restore.process().numpy", "tfmodel.restore.process().numpy", "helpers.imdiff.compare_ab_ref", "imdiff.compare_ab_ref.suptitle", "plt.show", "plt.close", "os.path.join", "ValueError", "ValueError", "int", "tfmodel.restore", "tfmodel.restore.load_model", "tfmodel.restore", "tfmodel.restore.load_model", "isinstance", "os.path.join", "helpers.fsutil.listdir", "print", "loading.load_images", "print", "tfmodel.restore.set_cfa_pattern", "tfmodel.restore.set_srgb_conversion", "print", "tfmodel.restore.set_cfa_pattern", "tfmodel.restore.set_srgb_conversion", "print", "tikz_save", "imdiff.compare_ab_ref.tight_layout", "imdiff.compare_ab_ref.show", "os.path.join", "os.path.join", "tfmodel.restore.summary", "tfmodel.restore.summary", "open", "json.load", "print", "raw.unpack", "raw.process", "tfmodel.restore.process", "tfmodel.restore.process", "plt.figure", "getattr", "getattr", "getattr", "getattr", "data[].astype", "data[].astype", "numpy.array", "os.path.split", "srgb.round().tolist", "srgb.round().tolist", "helpers.fsutil.split", "re.match", "srgb.round", "srgb.round"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["def", "compare_nips", "(", "model_a_dirname", ",", "model_b_dirname", ",", "camera", "=", "None", ",", "image", "=", "None", ",", "patch_size", "=", "128", ",", "root_dirname", "=", "'./data'", ",", "output_dir", "=", "None", ",", "model_a_args", "=", "None", ",", "model_b_args", "=", "None", ",", "extras", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Display a comparison of two variants of a neural imaging pipeline.\n    :param camera: camera name (e.g., 'Nikon D90')\n    :param model_a_dirname: directory with the first variant of the model\n    :param model_b_dirname: directory with the second variant of the model\n    :param ps: patch size (patch will be taken from the middle)\n    :param image_id: index of the test image\n    :param root_dir: root data directory\n    :param output_dir: set an output directory if the figure should be saved (matplotlib2tikz will be used)\n    \"\"\"", "\n", "# Lazy imports to minimize delay for invalid command line parameters", "\n", "import", "re", "\n", "import", "inspect", "\n", "import", "imageio", "as", "io", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "import", "tensorflow", "as", "tf", "\n", "from", "models", "import", "pipelines", ",", "tfmodel", "\n", "from", "helpers", "import", "raw", ",", "loading", "\n", "\n", "supported_cameras", "=", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "root_dirname", ",", "'models'", ",", "'nip'", ")", ",", "'.*'", ")", "\n", "supported_pipelines", "=", "pipelines", ".", "supported_models", "\n", "\n", "if", "patch_size", ">", "0", "and", "(", "patch_size", "<", "8", "or", "patch_size", ">", "2048", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Patch size seems to be invalid!'", ")", "\n", "\n", "", "if", "camera", "is", "not", "None", "and", "camera", "not", "in", "supported_cameras", ":", "\n", "        ", "raise", "ValueError", "(", "'Camera data not found ({})! Available cameras: {}'", ".", "format", "(", "camera", ",", "', '", ".", "join", "(", "supported_cameras", ")", ")", ")", "\n", "\n", "# Check if the image is an integer", "\n", "", "try", ":", "\n", "        ", "image", "=", "int", "(", "image", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "# Construct the NIP models", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "model_a_dirname", ")", ":", "\n", "# Restore a NIP model from a training log", "\n", "        ", "model_a", "=", "tfmodel", ".", "restore", "(", "model_a_dirname", ",", "pipelines", ")", "\n", "", "else", ":", "\n", "# Construct the NIP model from class name (and optional arguments)", "\n", "        ", "if", "model_a_args", "is", "None", ":", "\n", "            ", "model_a", "=", "getattr", "(", "pipelines", ",", "model_a_dirname", ")", "(", ")", "\n", "", "else", ":", "\n", "            ", "model_a", "=", "getattr", "(", "pipelines", ",", "model_a_dirname", ")", "(", "**", "model_a_args", ")", "\n", "", "model_a", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "root_dirname", ",", "model_a", ".", "model_code", ")", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "model_b_dirname", ")", ":", "\n", "# Restore a NIP model from a training log", "\n", "        ", "model_b", "=", "tfmodel", ".", "restore", "(", "model_b_dirname", ",", "pipelines", ")", "\n", "", "else", ":", "\n", "# Construct the NIP model from class name (and optional arguments)", "\n", "        ", "if", "model_b_args", "is", "None", ":", "\n", "            ", "model_b", "=", "getattr", "(", "pipelines", ",", "model_b_dirname", ")", "(", ")", "\n", "", "else", ":", "\n", "            ", "model_b", "=", "getattr", "(", "pipelines", ",", "model_b_dirname", ")", "(", "**", "model_b_args", ")", "\n", "", "model_b", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "root_dirname", ",", "model_b", ".", "model_code", ")", ")", "\n", "\n", "", "print", "(", "'ISP-A: {}'", ".", "format", "(", "model_a", ".", "summary", "(", ")", ")", ")", "\n", "print", "(", "'ISP-B: {}'", ".", "format", "(", "model_b", ".", "summary", "(", ")", ")", ")", "\n", "\n", "# Load sample data", "\n", "\n", "if", "isinstance", "(", "image", ",", "int", ")", "and", "camera", "is", "not", "None", ":", "\n", "\n", "        ", "data_dirname", "=", "os", ".", "path", ".", "join", "(", "root_dirname", ",", "'raw'", ",", "'training_data'", ",", "camera", ")", "\n", "files", "=", "fsutil", ".", "listdir", "(", "data_dirname", ",", "'.*\\.png'", ")", "\n", "files", "=", "files", "[", "image", ":", "image", "+", "1", "]", "\n", "print", "(", "'Loading image {} from the training set: {}'", ".", "format", "(", "image", ",", "files", ")", ")", "\n", "data", "=", "loading", ".", "load_images", "(", "files", ",", "data_dirname", ")", "\n", "sample_x", ",", "sample_y", "=", "data", "[", "'x'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "16", "-", "1", ")", ",", "data", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "with", "open", "(", "'config/cameras.json'", ")", "as", "f", ":", "\n", "            ", "cameras", "=", "json", ".", "load", "(", "f", ")", "\n", "cfa", ",", "srgb", "=", "cameras", "[", "camera", "]", "[", "'cfa'", "]", ",", "np", ".", "array", "(", "cameras", "[", "camera", "]", "[", "'srgb'", "]", ")", "\n", "\n", "", "image", "=", "files", "[", "0", "]", "\n", "\n", "", "elif", "image", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Loading a RAW image {}'", ".", "format", "(", "image", ")", ")", "\n", "sample_x", ",", "cfa", ",", "srgb", ",", "_", "=", "raw", ".", "unpack", "(", "image", ",", "expand", "=", "True", ")", "\n", "sample_y", "=", "raw", ".", "process", "(", "image", ",", "brightness", "=", "None", ",", "expand", "=", "True", ")", "\n", "image", "=", "os", ".", "path", ".", "split", "(", "image", ")", "[", "-", "1", "]", "\n", "\n", "", "if", "isinstance", "(", "model_a", ",", "pipelines", ".", "ClassicISP", ")", ":", "\n", "        ", "print", "(", "'Configuring ISP-A to CFA: {} & sRGB {}'", ".", "format", "(", "cfa", ",", "srgb", ".", "round", "(", "2", ")", ".", "tolist", "(", ")", ")", ")", "\n", "model_a", ".", "set_cfa_pattern", "(", "cfa", ")", "\n", "model_a", ".", "set_srgb_conversion", "(", "srgb", ")", "\n", "\n", "", "if", "isinstance", "(", "model_b", ",", "pipelines", ".", "ClassicISP", ")", ":", "\n", "        ", "print", "(", "'Configuring ISP-B to CFA: {} & sRGB {}'", ".", "format", "(", "cfa", ",", "srgb", ".", "round", "(", "2", ")", ".", "tolist", "(", ")", ")", ")", "\n", "model_b", ".", "set_cfa_pattern", "(", "cfa", ")", "\n", "model_b", ".", "set_srgb_conversion", "(", "srgb", ")", "\n", "\n", "# Develop images", "\n", "", "sample_ya", "=", "model_a", ".", "process", "(", "sample_x", ")", ".", "numpy", "(", ")", "\n", "sample_yb", "=", "model_b", ".", "process", "(", "sample_x", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "patch_size", ">", "0", ":", "\n", "        ", "print", "(", "'Cropping a {p}x{p} patch from the middle'", ".", "format", "(", "p", "=", "patch_size", ")", ")", "\n", "xx", "=", "(", "sample_x", ".", "shape", "[", "2", "]", "-", "patch_size", "//", "2", ")", "//", "2", "\n", "yy", "=", "(", "sample_x", ".", "shape", "[", "1", "]", "-", "patch_size", "//", "2", ")", "//", "2", "\n", "sample_x", "=", "sample_x", "[", ":", ",", "yy", ":", "yy", "+", "patch_size", ",", "xx", ":", "xx", "+", "patch_size", ",", ":", "]", "\n", "sample_y", "=", "sample_y", "[", ":", ",", "2", "*", "yy", ":", "2", "*", "(", "yy", "+", "patch_size", ")", ",", "2", "*", "xx", ":", "2", "*", "(", "xx", "+", "patch_size", ")", ",", ":", "]", "\n", "sample_ya", "=", "sample_ya", "[", ":", ",", "2", "*", "yy", ":", "2", "*", "(", "yy", "+", "patch_size", ")", ",", "2", "*", "xx", ":", "2", "*", "(", "xx", "+", "patch_size", ")", ",", ":", "]", "\n", "sample_yb", "=", "sample_yb", "[", ":", ",", "2", "*", "yy", ":", "2", "*", "(", "yy", "+", "patch_size", ")", ",", "2", "*", "xx", ":", "2", "*", "(", "xx", "+", "patch_size", ")", ",", ":", "]", "\n", "\n", "# Plot images", "\n", "", "fig", "=", "imdiff", ".", "compare_ab_ref", "(", "sample_y", ",", "sample_ya", ",", "sample_yb", ",", "fig", "=", "plt", ".", "figure", "(", ")", ",", "extras", "=", "extras", ")", "\n", "\n", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "from", "tikzplotlib", "import", "save", "as", "tikz_save", "\n", "dcomp", "=", "[", "x", "for", "x", "in", "fsutil", ".", "split", "(", "model_b_dirname", ")", "if", "re", ".", "match", "(", "'(ln-.*|[0-9]{3})'", ",", "x", ")", "]", "\n", "tikz_save", "(", "'{}/examples_{}_{}_{}_{}.tex'", ".", "format", "(", "output_dir", ",", "camera", ",", "image", ",", "model_a_dirname", ",", "model_b_dirname", ")", ",", "figureheight", "=", "'8cm'", ",", "figurewidth", "=", "'8cm'", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "show", "(", "fig", ")", "\n", "\n", "", "fig", ".", "suptitle", "(", "'{}, A={}, B={}'", ".", "format", "(", "image", ",", "model_a", ".", "model_code", ",", "model_b", ".", "model_code", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.diff_nip.main": [[143, 179], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "diff_nip.compare_nips", "json.loads", "print", "sys.exit", "json.loads", "print", "sys.exit", "parser.parse_args.ha.replace", "parser.parse_args.ha.replace", "parser.parse_args.hb.replace", "parser.parse_args.hb.replace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.diff_nip.compare_nips"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Develops RAW images with a selected pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--image'", ",", "dest", "=", "'image'", ",", "action", "=", "'store'", ",", "\n", "help", "=", "'RAW image path or training image id'", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--patch'", ",", "dest", "=", "'patch'", ",", "action", "=", "'store'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'patch size'", ")", "\n", "parser", ".", "add_argument", "(", "'-a'", ",", "dest", "=", "'model_a_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/models/nip'", ",", "\n", "help", "=", "'path to first model (TF checkpoint dir)'", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "dest", "=", "'model_b_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/models/nip'", ",", "\n", "help", "=", "'path to second model (TF checkpoint dir)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/'", ",", "\n", "help", "=", "'root directory with images and training data'", ")", "\n", "parser", ".", "add_argument", "(", "'-e'", ",", "'--extra'", ",", "dest", "=", "'extras'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'show additional plots (FFTs and diffs)'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "dest", "=", "'out'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'output directory for TikZ output (if set, the figure is not displayed)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ha'", ",", "dest", "=", "'ha'", ",", "default", "=", "None", ",", "help", "=", "'Set hyper-parameters / override CSV settings for model A (JSON string)'", ")", "\n", "parser", ".", "add_argument", "(", "'--hb'", ",", "dest", "=", "'hb'", ",", "default", "=", "None", ",", "help", "=", "'Set hyper-parameters / override CSV settings for model A (JSON string)'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "if", "args", ".", "ha", "is", "not", "None", ":", "args", ".", "ha", "=", "json", ".", "loads", "(", "args", ".", "ha", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "ha", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "hb", "is", "not", "None", ":", "args", ".", "hb", "=", "json", ".", "loads", "(", "args", ".", "hb", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "hb", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "compare_nips", "(", "args", ".", "model_a_dir", ",", "args", ".", "model_b_dir", ",", "args", ".", "camera", ",", "args", ".", "image", ",", "\n", "args", ".", "patch", ",", "args", ".", "dir", ",", "args", ".", "out", ",", "args", ".", "ha", ",", "args", ".", "hb", ",", "extras", "=", "args", ".", "extras", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_manipulation.batch_training": [[21, 158], ["manipulation_classification.ManipulationClassification", "loguru.logger.info", "loguru.logger.info", "FileNotFoundError", "FileNotFoundError", "FileNotFoundError", "os.path.isdir", "os.makedirs", "re.match", "int", "int", "int", "set", "ValueError", "loguru.logger.info", "helpers.dataset.Dataset", "loguru.logger.info", "range", "os.path.isdir", "int", "re.match", "ValueError", "len", "float", "len", "float", "os.path.join", "os.path.join", "os.path.isdir", "loguru.logger.warning", "data_directory.replace().replace.replace().replace", "tuple", "FileNotFoundError", "split.split", "split.split", "split.split", "manipulation_classification.ManipulationClassification.summary", "manipulation_classification.ManipulationClassification.details", "len", "len", "data_directory.replace().replace.replace", "train_manipulation_nip", "int", "re.findall"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.details", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.manipulation.train_manipulation_nip"], ["@", "utils", ".", "logCall", "\n", "def", "batch_training", "(", "nip_model", ",", "camera_names", "=", "None", ",", "root_directory", "=", "None", ",", "loss_metric", "=", "'L2'", ",", "trainables", "=", "None", ",", "\n", "jpeg_quality", "=", "None", ",", "jpeg_mode", "=", "'soft'", ",", "manipulations", "=", "None", ",", "dcn_model", "=", "None", ",", "downsampling", "=", "'pool'", ",", "\n", "end_repetition", "=", "10", ",", "start_repetition", "=", "0", ",", "n_epochs", "=", "1001", ",", "patch", "=", "128", ",", "fan_args", "=", "{", "}", ",", "\n", "use_pretrained", "=", "True", ",", "lambdas_nip", "=", "None", ",", "lambdas_dcn", "=", "None", ",", "nip_directory", "=", "None", ",", "split", "=", "'120:30:4'", ")", ":", "\n", "    ", "\"\"\"\n    Repeat training for multiple NIP regularization strengths.\n    \"\"\"", "\n", "\n", "if", "nip_model", "is", "None", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "'NIP model not specified!'", ")", "\n", "\n", "", "if", "nip_directory", "is", "None", "or", "not", "os", ".", "path", ".", "isdir", "(", "nip_directory", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "'Invalid NIP snapshots directory: {}'", ".", "format", "(", "nip_directory", ")", ")", "\n", "\n", "", "if", "root_directory", "is", "None", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "'Invalid root directory: {}'", ".", "format", "(", "root_directory", ")", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "root_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "root_directory", ")", "\n", "\n", "", "if", "jpeg_quality", "is", "not", "None", ":", "\n", "        ", "if", "re", ".", "match", "(", "'^[0-9]+$'", ",", "jpeg_quality", ")", ":", "\n", "            ", "jpeg_quality", "=", "int", "(", "jpeg_quality", ")", "\n", "", "elif", "re", ".", "match", "(", "'^[0-9\\\\,]+$'", ",", "jpeg_quality", ")", ":", "\n", "            ", "jpeg_quality", "=", "tuple", "(", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "'([0-9]+)'", ",", "jpeg_quality", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "'Invalid JPEG quality: expecting a number or comma separated numbers & got: {}'", ".", "format", "(", "jpeg_quality", ")", ")", "\n", "\n", "# Lazy loading to minimize delays when checking cli parameters", "\n", "", "", "from", "training", ".", "manipulation", "import", "train_manipulation_nip", "\n", "from", "workflows", "import", "manipulation_classification", "\n", "\n", "camera_names", "=", "camera_names", "or", "[", "'D90'", ",", "'D7000'", ",", "'EOS-5D'", ",", "'EOS-40D'", "]", "\n", "\n", "training", "=", "{", "\n", "'use_pretrained_nip'", ":", "use_pretrained", ",", "\n", "'n_epochs'", ":", "n_epochs", ",", "\n", "'patch_size'", ":", "patch", ",", "\n", "'batch_size'", ":", "20", ",", "\n", "'validation_schedule'", ":", "50", ",", "\n", "'learning_rate'", ":", "1e-4", ",", "\n", "'n_images'", ":", "int", "(", "split", ".", "split", "(", "':'", ")", "[", "0", "]", ")", ",", "\n", "'v_images'", ":", "int", "(", "split", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ",", "\n", "'val_n_patches'", ":", "int", "(", "split", ".", "split", "(", "':'", ")", "[", "2", "]", ")", ",", "\n", "}", "\n", "\n", "# Setup trainable elements and regularization -------------------------------------------------", "\n", "\n", "trainables", "=", "trainables", "if", "trainables", "is", "not", "None", "else", "set", "(", ")", "\n", "for", "tr", "in", "trainables", ":", "\n", "        ", "if", "tr", "not", "in", "{", "'nip'", ",", "'dcn'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid specifier of trainable elements: only nip, dcn allowed!'", ")", "\n", "\n", "", "", "training", "[", "'trainable'", "]", "=", "trainables", "\n", "\n", "if", "lambdas_nip", "is", "None", "or", "len", "(", "lambdas_nip", ")", "==", "0", ":", "\n", "        ", "lambdas_nip", "=", "[", "1e-4", ",", "5e-4", ",", "1e-3", ",", "5e-3", ",", "1e-2", ",", "5e-2", ",", "0.1", ",", "0.25", ",", "0.5", ",", "1", "]", "if", "'nip'", "in", "trainables", "else", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "lambdas_nip", "=", "[", "float", "(", "x", ")", "for", "x", "in", "lambdas_nip", "]", "\n", "\n", "", "if", "lambdas_dcn", "is", "None", "or", "len", "(", "lambdas_dcn", ")", "==", "0", ":", "\n", "        ", "lambdas_dcn", "=", "[", "0.1", ",", "0.05", ",", "0.01", ",", "0.005", ",", "0.001", "]", "if", "'dcn'", "in", "trainables", "else", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "lambdas_dcn", "=", "[", "float", "(", "x", ")", "for", "x", "in", "lambdas_dcn", "]", "\n", "\n", "# Setup the distribution channel --------------------------------------------------------------", "\n", "", "if", "downsampling", "not", "in", "[", "'pool'", ",", "'bilinear'", ",", "'none'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported channel down-sampling'", ")", "\n", "\n", "", "if", "dcn_model", "is", "None", "and", "jpeg_quality", "is", "None", ":", "\n", "        ", "jpeg_quality", "=", "50", "\n", "\n", "", "compression_params", "=", "{", "}", "\n", "if", "jpeg_quality", "is", "not", "None", ":", "\n", "        ", "compression_params", "[", "'quality'", "]", "=", "jpeg_quality", "\n", "compression_params", "[", "'codec'", "]", "=", "jpeg_mode", "\n", "", "else", ":", "\n", "        ", "compression_params", "[", "'dirname'", "]", "=", "dcn_model", "\n", "\n", "", "if", "jpeg_quality", "is", "not", "None", ":", "\n", "        ", "compression", "=", "'jpeg'", "\n", "", "elif", "dcn_model", "is", "not", "None", ":", "\n", "        ", "compression", "=", "'dcn'", "\n", "", "else", ":", "\n", "        ", "compression", "=", "'none'", "\n", "\n", "", "distribution", "=", "{", "\n", "'downsampling'", ":", "downsampling", ",", "\n", "'compression'", ":", "compression", ",", "\n", "'compression_params'", ":", "compression_params", "\n", "}", "\n", "\n", "# Construct the workflow ----------------------------------------------------------------------", "\n", "manipulations", "=", "manipulations", "or", "[", "'sharpen'", ",", "'resample'", ",", "'gaussian'", ",", "'jpeg'", "]", "\n", "\n", "flow", "=", "manipulation_classification", ".", "ManipulationClassification", "(", "nip_model", ",", "manipulations", ",", "distribution", ",", "fan_args", ",", "trainables", ",", "raw_patch_size", "=", "training", "[", "'patch_size'", "]", ")", "\n", "logger", ".", "info", "(", "f'Workflow: {flow.summary()}'", ")", "\n", "logger", ".", "info", "(", "f'\\n{flow.details()}'", ")", "\n", "\n", "# Iterate over cameras and train the entire workflow ------------------------------------------ ", "\n", "for", "camera_name", "in", "camera_names", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "f'Loading data for {camera_name}'", ")", "\n", "training", "[", "'camera_name'", "]", "=", "camera_name", "\n", "\n", "# Find the right dataset to load", "\n", "if", "nip_model", "==", "'ONet'", ":", "\n", "# TODO Dirty hack - if the NIP model is the dummy empty model, load RGB images only", "\n", "            ", "data_directory", "=", "os", ".", "path", ".", "join", "(", "root_directory", ",", "'rgb'", ",", "camera_name", ")", "\n", "patch_mul", "=", "2", "\n", "load", "=", "'y'", "\n", "", "else", ":", "\n", "# Otherwise, load (RAW, RGB) pairs for a specific camera", "\n", "            ", "data_directory", "=", "os", ".", "path", ".", "join", "(", "root_directory", ",", "'raw'", ",", "'training_data'", ",", "camera_name", ")", "\n", "patch_mul", "=", "2", "\n", "load", "=", "'xy'", "\n", "\n", "# If the target root directory has no training images, fallback to use the default root", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "data_directory", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "'Training images not found in the target root directory - using default root as image source'", ")", "\n", "data_directory", "=", "data_directory", ".", "replace", "(", "root_directory", ",", "'data/'", ")", ".", "replace", "(", "'//'", ",", "'/'", ")", "\n", "\n", "# Load the image dataset", "\n", "", "data", "=", "dataset", ".", "Dataset", "(", "data_directory", ",", "n_images", "=", "training", "[", "'n_images'", "]", ",", "v_images", "=", "training", "[", "'v_images'", "]", ",", "load", "=", "load", ",", "val_rgb_patch_size", "=", "patch_mul", "*", "training", "[", "'patch_size'", "]", ",", "val_n_patches", "=", "training", "[", "'val_n_patches'", "]", ")", "\n", "\n", "logger", ".", "info", "(", "'Training loop: {} repetitions / {} NIP lambdas {} / {} DCN lambdas {}'", ".", "format", "(", "\n", "end_repetition", "-", "start_repetition", ",", "len", "(", "lambdas_nip", ")", ",", "lambdas_nip", ",", "len", "(", "lambdas_dcn", ")", ",", "lambdas_dcn", ")", ")", "\n", "\n", "# Repeat training with different loss weights", "\n", "for", "rep", "in", "range", "(", "start_repetition", ",", "end_repetition", ")", ":", "\n", "            ", "for", "lr", "in", "lambdas_nip", ":", "\n", "                ", "for", "lc", "in", "lambdas_dcn", ":", "\n", "                    ", "training", "[", "'lambda_nip'", "]", "=", "lr", "\n", "training", "[", "'lambda_dcn'", "]", "=", "lc", "\n", "training", "[", "'run_number'", "]", "=", "rep", "\n", "train_manipulation_nip", "(", "flow", ",", "training", ",", "data", ",", "{", "'root'", ":", "root_directory", ",", "'nip_snapshots'", ":", "nip_directory", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_manipulation.main": [[160, 234], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.manipulations.strip().split", "train_manipulation.batch_training", "json.loads", "print", "sys.exit", "parser.parse_args.manipulations.strip", "parser.parse_args.fan_args.replace", "parser.parse_args.hyperparams_args.replace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_manipulation.batch_training"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'NIP & FAN optimization for manipulation detection'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'general parameters'", ")", "\n", "group", ".", "add_argument", "(", "'--nip'", ",", "dest", "=", "'nip_model'", ",", "action", "=", "'store'", ",", "required", "=", "True", ",", "\n", "help", "=", "'the NIP model (INet, UNet, DNet)'", ")", "\n", "group", ".", "add_argument", "(", "'--cam'", ",", "dest", "=", "'cameras'", ",", "action", "=", "'append'", ",", "\n", "help", "=", "'add cameras for evaluation (repeat if needed)'", ")", "\n", "group", ".", "add_argument", "(", "'--manip'", ",", "dest", "=", "'manipulations'", ",", "action", "=", "'store'", ",", "default", "=", "'sharpen,resample,gaussian,jpeg'", ",", "\n", "help", "=", "'comma-sep. list of manipulations (:strength), e.g., : {}'", ".", "format", "(", "'sharpen:1,jpeg:80,resample,gaussian'", ")", ")", "\n", "group", ".", "add_argument", "(", "'--fan'", ",", "dest", "=", "'fan_args'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Set hyper-parameters for the FAN model (JSON string)'", ")", "\n", "\n", "# Directories", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'directories'", ")", "\n", "group", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'root_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/m/playground/'", ",", "\n", "help", "=", "'the root directory for storing results'", ")", "\n", "group", ".", "add_argument", "(", "'--nip-dir'", ",", "dest", "=", "'nip_directory'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/models/nip/'", ",", "\n", "help", "=", "'the root directory for storing results'", ")", "\n", "\n", "# Training parameters", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'training parameters'", ")", "\n", "group", ".", "add_argument", "(", "'--loss'", ",", "dest", "=", "'loss_metric'", ",", "action", "=", "'store'", ",", "default", "=", "'L2'", ",", "\n", "help", "=", "'loss metric for the NIP (L2, L1, SSIM)'", ")", "\n", "group", ".", "add_argument", "(", "'--split'", ",", "dest", "=", "'split'", ",", "action", "=", "'store'", ",", "default", "=", "'120:30:4'", ",", "\n", "help", "=", "'data split (#training:#validation:#validation_patches): e.g., 120:30:4'", ")", "\n", "group", ".", "add_argument", "(", "'--ln'", ",", "dest", "=", "'lambdas_nip'", ",", "action", "=", "'append'", ",", "\n", "help", "=", "'set custom regularization strength for the NIP (repeat for multiple values)'", ")", "\n", "group", ".", "add_argument", "(", "'--lc'", ",", "dest", "=", "'lambdas_dcn'", ",", "action", "=", "'append'", ",", "\n", "help", "=", "'set custom regularization strength for the DCN (repeat for multiple values)'", ")", "\n", "group", ".", "add_argument", "(", "'--train'", ",", "dest", "=", "'trainables'", ",", "action", "=", "'append'", ",", "\n", "help", "=", "'add trainable elements (nip, dcn)'", ")", "\n", "group", ".", "add_argument", "(", "'--patch'", ",", "dest", "=", "'patch'", ",", "action", "=", "'store'", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "'RGB patch size for NIP output (default 256)'", ")", "\n", "\n", "# Training scope and progress", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'training scope'", ")", "\n", "group", ".", "add_argument", "(", "'--scratch'", ",", "dest", "=", "'from_scratch'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'train NIP from scratch (ignore pre-trained model)'", ")", "\n", "group", ".", "add_argument", "(", "'--start'", ",", "dest", "=", "'start'", ",", "action", "=", "'store'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'first iteration (default 0)'", ")", "\n", "group", ".", "add_argument", "(", "'--end'", ",", "dest", "=", "'end'", ",", "action", "=", "'store'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'last iteration (exclusive, default 10)'", ")", "\n", "group", ".", "add_argument", "(", "'--epochs'", ",", "dest", "=", "'epochs'", ",", "action", "=", "'store'", ",", "default", "=", "1001", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of epochs (default 1001)'", ")", "\n", "\n", "# Distribution channel", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'distribution channel'", ")", "\n", "group", ".", "add_argument", "(", "'--jpeg'", ",", "dest", "=", "'jpeg_quality'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'JPEG quality level (distribution channel)'", ")", "\n", "group", ".", "add_argument", "(", "'--jpeg_mode'", ",", "dest", "=", "'jpeg_mode'", ",", "action", "=", "'store'", ",", "default", "=", "'soft'", ",", "\n", "help", "=", "'JPEG approximation mode: sin, soft, harmonic'", ")", "\n", "group", ".", "add_argument", "(", "'--dcn'", ",", "dest", "=", "'dcn_model'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'DCN compression model path'", ")", "\n", "group", ".", "add_argument", "(", "'--ds'", ",", "dest", "=", "'downsampling'", ",", "action", "=", "'store'", ",", "default", "=", "'pool'", ",", "\n", "help", "=", "'Distribution channel sub-sampling: pool/bilinear/none'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Parse FAN args", "\n", "try", ":", "\n", "        ", "args", ".", "fan_args", "=", "json", ".", "loads", "(", "args", ".", "fan_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "if", "args", ".", "fan_args", "is", "not", "None", "else", "{", "}", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "hyperparams_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "# Split manipulations", "\n", "", "args", ".", "manipulations", "=", "args", ".", "manipulations", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "\n", "batch_training", "(", "args", ".", "nip_model", ",", "args", ".", "cameras", ",", "args", ".", "root_dir", ",", "\n", "args", ".", "loss_metric", ",", "args", ".", "trainables", ",", "args", ".", "jpeg_quality", ",", "args", ".", "jpeg_mode", ",", "\n", "args", ".", "manipulations", ",", "args", ".", "dcn_model", ",", "args", ".", "downsampling", ",", "patch", "=", "args", ".", "patch", "//", "2", ",", "fan_args", "=", "args", ".", "fan_args", ",", "\n", "use_pretrained", "=", "not", "args", ".", "from_scratch", ",", "start_repetition", "=", "args", ".", "start", ",", "end_repetition", "=", "args", ".", "end", ",", "n_epochs", "=", "args", ".", "epochs", ",", "\n", "nip_directory", "=", "args", ".", "nip_directory", ",", "split", "=", "args", ".", "split", ",", "lambdas_nip", "=", "args", ".", "lambdas_nip", ",", "lambdas_dcn", "=", "args", ".", "lambdas_dcn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_nip.get_parameters": [[22, 48], ["pandas.DataFrame", "parameters.rename.append", "len", "parameters.rename.append", "col.startswith", "pandas.read_csv", "parameters[].apply", "parameters.rename.rename"], "function", ["None"], ["def", "get_parameters", "(", "csv_file", ",", "metrics", "=", "(", "'ssim'", ",", "'psnr'", ",", "'loss'", ",", "'params'", ")", ")", ":", "\n", "\n", "    ", "parameters", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'scenario'", ",", "'label'", ",", "'active'", ",", "'run_group'", ",", "'params'", ",", "'model_code'", "]", ")", "\n", "\n", "if", "csv_file", "is", "not", "None", ":", "\n", "        ", "parameters", "=", "parameters", ".", "append", "(", "pd", ".", "read_csv", "(", "csv_file", ")", ",", "ignore_index", "=", "True", ",", "sort", "=", "True", ")", "\n", "\n", "", "if", "len", "(", "parameters", ")", "==", "0", ":", "\n", "        ", "cli_params", "=", "{", "\n", "'scenario'", ":", "np", ".", "nan", ",", "\n", "'label'", ":", "'command-line'", ",", "\n", "'active'", ":", "True", ",", "\n", "'run_group'", ":", "np", ".", "nan", "\n", "}", "\n", "parameters", "=", "parameters", ".", "append", "(", "cli_params", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# If requested, add columns to include validation results", "\n", "", "for", "key", "in", "metrics", ":", "\n", "        ", "parameters", "[", "key", "]", "=", "np", ".", "nan", "\n", "\n", "", "for", "col", "in", "parameters", ".", "columns", ":", "\n", "        ", "if", "col", ".", "startswith", "(", "'@'", ")", ":", "\n", "            ", "parameters", "[", "col", "]", "=", "parameters", "[", "col", "]", ".", "apply", "(", "eval", ")", "\n", "parameters", "=", "parameters", ".", "rename", "(", "columns", "=", "{", "col", ":", "col", "[", "1", ":", "]", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_nip.main": [[50, 245], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "train_nip.get_parameters", "len", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.random.seed", "enumerate", "print", "argparse.ArgumentParser.print_usage", "sys.exit", "print", "argparse.ArgumentParser.print_usage", "sys.exit", "ValueError", "parameters[].drop", "abs", "int", "int", "int", "print", "helpers.dataset.Dataset", "print", "print", "parameters[].drop.drop().iterrows", "isinstance", "model.process", "model.count_parameters", "print", "enumerate", "hasattr", "issubclass", "json.loads", "print", "sys.exit", "dataset.Dataset.summary", "print", "print", "print", "params.update", "getattr", "print", "model.set_cfa_pattern", "model.set_srgb_conversion", "print", "model_log[].append", "numpy.random.uniform().astype", "training.pipeline.train_nip_model", "os.path.join", "print", "print", "parser.parse_args.fill.endswith", "sorted", "print", "getattr", "parser.parse_args.hyperparams_args.replace", "parser.parse_args.hyperparams_args.replace", "helpers.utils.format_number", "len", "parser.parse_args.split.split", "parser.parse_args.split.split", "parser.parse_args.split.split", "parameters[].drop.drop", "params.to_dict().items", "open", "json.load", "numpy.array", "len", "os.path.join", "os.path.isfile", "parameters[].drop.to_string", "print", "parameters[].drop.to_csv", "ValueError", "len", "model_log.keys", "len", "helpers.utils.is_nan", "numpy.random.uniform", "model.pop_metric", "helpers.debugging.mem", "helpers.debugging.mem", "params.to_dict", "open", "json.load", "helpers.utils.get", "len", "key.lower", "key.lower", "key.lower", "key.lower"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_nip.get_parameters", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.train_nip_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_nan", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.mem", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.mem", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a neural imaging pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ")", "\n", "parser", ".", "add_argument", "(", "'-n'", ",", "'--nip'", ",", "dest", "=", "'nip'", ",", "action", "=", "'store'", ",", "help", "=", "'add NIP for training (repeat if needed)'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "dest", "=", "'out_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/models/nip'", ",", "\n", "help", "=", "'output directory for storing trained NIP models'", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "dest", "=", "'data_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/raw/training_data/'", ",", "\n", "help", "=", "'input directory with training data (.npy and .png pairs)'", ")", "\n", "parser", ".", "add_argument", "(", "'--patch'", ",", "dest", "=", "'patch_size'", ",", "action", "=", "'store'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'training patch size (RGB)'", ")", "\n", "parser", ".", "add_argument", "(", "'-e'", ",", "'--epochs'", ",", "dest", "=", "'epochs'", ",", "action", "=", "'store'", ",", "default", "=", "-", "25000", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--ha'", ",", "dest", "=", "'hyperparams_args'", ",", "default", "=", "None", ",", "help", "=", "'Set hyper-parameters / override CSV settings if needed (JSON string)'", ")", "\n", "parser", ".", "add_argument", "(", "'--hp'", ",", "dest", "=", "'hyperparams_csv'", ",", "default", "=", "None", ",", "help", "=", "'CSV file with hyper-parameter configurations'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "dest", "=", "'resume'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Resume training from last checkpoint, if possible'", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "'--split'", ",", "dest", "=", "'split'", ",", "action", "=", "'store'", ",", "default", "=", "'120:30:1'", ",", "\n", "help", "=", "'data split with #training:#validation:#validation_patches - e.g., 120:30:1'", ")", "\n", "parser", ".", "add_argument", "(", "'--dry'", ",", "dest", "=", "'dry'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Dry run (no training - only does model setup)'", ")", "\n", "parser", ".", "add_argument", "(", "'--group'", ",", "dest", "=", "'run_group'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Specify run group (sub-selects scenarios for running)'", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "'--fill'", ",", "dest", "=", "'fill'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Path of the extended scenarios table with appended result columns'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "camera", ":", "\n", "        ", "print", "(", "'A camera needs to be specified!'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "if", "not", "args", ".", "nip", ":", "\n", "        ", "print", "(", "'No neural imaging pipeline specified (--nip)'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# Lazy load to prevent delays in printing syntax help", "\n", "", "from", "models", "import", "pipelines", "\n", "\n", "if", "not", "hasattr", "(", "pipelines", ",", "args", ".", "nip", ")", "or", "not", "issubclass", "(", "getattr", "(", "pipelines", ",", "args", ".", "nip", ")", ",", "pipelines", ".", "NIPModel", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid NIP model ({})! Available NIPs: ({})'", ".", "format", "(", "args", ".", "nip", ",", "pipelines", ".", "supported_models", ")", ")", "\n", "\n", "", "data_directory", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "camera", ")", "\n", "out_directory_root", "=", "args", ".", "out_dir", "\n", "\n", "# List of hyper-parameters", "\n", "parameters", "=", "get_parameters", "(", "args", ".", "hyperparams_csv", ")", "\n", "\n", "if", "args", ".", "run_group", "is", "not", "None", ":", "\n", "        ", "parameters", "=", "parameters", "[", "parameters", "[", "'run_group'", "]", "==", "args", ".", "run_group", "]", "\n", "\n", "# Select only active hyper-parameter configurations", "\n", "", "if", "len", "(", "parameters", ")", ":", "\n", "        ", "parameters", "=", "parameters", "[", "parameters", "[", "'active'", "]", "]", ".", "drop", "(", "columns", "=", "[", "'active'", ",", "'run_group'", "]", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "hyperparams_args", "is", "not", "None", ":", "\n", "            ", "args", ".", "hyperparams_args", "=", "json", ".", "loads", "(", "args", ".", "hyperparams_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "hyperparams_args", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "if", "args", ".", "epochs", "<", "0", ":", "\n", "        ", "convergence_threshold", "=", "1e-6", "\n", "args", ".", "epochs", "=", "abs", "(", "args", ".", "epochs", ")", "\n", "", "else", ":", "\n", "        ", "convergence_threshold", "=", "None", "\n", "\n", "", "threshold_label", "=", "f'(convergence threshold {utils.format_number(convergence_threshold)})'", "if", "convergence_threshold", "is", "not", "None", "else", "'(fixed)'", "\n", "\n", "print", "(", "'# Camera ISP Training'", ")", "\n", "print", "(", "f'Camera          : {args.camera}'", ")", "\n", "print", "(", "f'NIP             : {args.nip}'", ")", "\n", "print", "(", "f'Params (CSV)    : {args.hyperparams_csv}'", ")", "\n", "print", "(", "f'Params override : {args.hyperparams_args}'", ")", "\n", "print", "(", "f'Input           : {data_directory}'", ")", "\n", "print", "(", "f'Output          : {out_directory_root}'", ")", "\n", "print", "(", "f'Resume          : {args.resume}'", ")", "\n", "print", "(", "f'Epochs          : {args.epochs} {threshold_label}'", ")", "\n", "\n", "print", "(", "f'\\n# Hyper-parameter configurations [{len(parameters)} active configs]:\\n'", ")", "\n", "print", "(", "parameters", ")", "\n", "\n", "# Load training and validation data", "\n", "training_spec", "=", "{", "\n", "'seed'", ":", "1234", ",", "\n", "'n_images'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "0", "]", ")", ",", "\n", "'v_images'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ",", "\n", "'valid_patches'", ":", "int", "(", "args", ".", "split", ".", "split", "(", "':'", ")", "[", "2", "]", ")", ",", "\n", "'valid_patch_size'", ":", "256", ",", "\n", "}", "\n", "\n", "np", ".", "random", ".", "seed", "(", "training_spec", "[", "'seed'", "]", ")", "\n", "\n", "# Load and summarize the training data", "\n", "if", "not", "args", ".", "dry", ":", "\n", "        ", "print", "(", "'\\n# Dataset'", ")", "\n", "data", "=", "dataset", ".", "Dataset", "(", "data_directory", ",", "n_images", "=", "training_spec", "[", "'n_images'", "]", ",", "v_images", "=", "training_spec", "[", "'v_images'", "]", ",", "load", "=", "'xy'", ",", "val_rgb_patch_size", "=", "training_spec", "[", "'valid_patch_size'", "]", ",", "val_n_patches", "=", "training_spec", "[", "'valid_patches'", "]", ")", "\n", "\n", "print", "(", "data", ".", "summary", "(", ")", ")", "\n", "\n", "for", "key", "in", "[", "'Training'", ",", "'Validation'", "]", ":", "\n", "            ", "print", "(", "'{:>16s} [{:5.1f} GB] : X -> {}, Y -> {} '", ".", "format", "(", "\n", "'{} data'", ".", "format", "(", "key", ")", ",", "\n", "helpers", ".", "debugging", ".", "mem", "(", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'x'", "]", ")", "+", "helpers", ".", "debugging", ".", "mem", "(", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'y'", "]", ")", ",", "\n", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'x'", "]", ".", "shape", ",", "\n", "data", "[", "key", ".", "lower", "(", ")", "]", "[", "'y'", "]", ".", "shape", "\n", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Lazy loading to prevent delays in basic CLI interaction", "\n", "", "", "import", "tensorflow", "as", "tf", "\n", "\n", "# Train the Desired NIP Models", "\n", "model_log", "=", "{", "}", "\n", "if", "not", "args", ".", "dry", ":", "\n", "        ", "print", "(", "'\\n# Training\\n'", ")", "\n", "# for pipe in args.nip:", "\n", "\n", "", "for", "counter", ",", "(", "index", ",", "params", ")", "in", "enumerate", "(", "parameters", ".", "drop", "(", "columns", "=", "[", "'scenario'", ",", "'label'", ",", "'params'", ",", "'model_code'", "]", ")", ".", "iterrows", "(", ")", ")", ":", "\n", "\n", "        ", "if", "not", "args", ".", "dry", ":", "\n", "            ", "print", "(", "'## {} : Scenario #{} - {} / {}'", ".", "format", "(", "args", ".", "nip", ",", "index", ",", "counter", "+", "1", ",", "len", "(", "parameters", ")", ")", ")", "\n", "\n", "# Set hyper-parameters from the list", "\n", "", "params", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "params", ".", "to_dict", "(", ")", ".", "items", "(", ")", "if", "not", "utils", ".", "is_nan", "(", "v", ")", "}", "\n", "\n", "# Override hyper-parameters if requested", "\n", "if", "args", ".", "hyperparams_args", "is", "not", "None", ":", "\n", "            ", "print", "(", "'info: overriding hyperparameters from the CLI-supplied JSON'", ")", "\n", "params", ".", "update", "(", "args", ".", "hyperparams_args", ")", "\n", "\n", "", "model", "=", "getattr", "(", "pipelines", ",", "args", ".", "nip", ")", "(", "**", "params", ")", "\n", "\n", "if", "isinstance", "(", "model", ",", "pipelines", ".", "ClassicISP", ")", ":", "\n", "            ", "with", "open", "(", "'config/cameras.json'", ")", "as", "f", ":", "\n", "                ", "cameras", "=", "json", ".", "load", "(", "f", ")", "\n", "", "print", "(", "'Configuring ISP to {}: {}'", ".", "format", "(", "args", ".", "camera", ",", "cameras", "[", "args", ".", "camera", "]", ")", ")", "\n", "model", ".", "set_cfa_pattern", "(", "cameras", "[", "args", ".", "camera", "]", "[", "'cfa'", "]", ")", "\n", "model", ".", "set_srgb_conversion", "(", "np", ".", "array", "(", "cameras", "[", "args", ".", "camera", "]", "[", "'srgb'", "]", ")", ")", "\n", "\n", "# Remember trained models", "\n", "", "model_code", "=", "model", ".", "model_code", "\n", "parameters", ".", "loc", "[", "index", ",", "'model_code'", "]", "=", "model", ".", "model_code", "\n", "\n", "if", "model_code", "in", "model_log", ":", "\n", "            ", "print", "(", "'WARNING - model {} already registered by scenario {}'", ".", "format", "(", "model_code", ",", "index", ")", ")", "\n", "model_log", "[", "model_code", "]", ".", "append", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "model_log", "[", "model_code", "]", "=", "[", "index", "]", "\n", "\n", "# Log the number of parameters, process a sample batch first to make sure the model is initialized", "\n", "# (does not happen when using custom tf.keras.Model classes)", "\n", "", "model", ".", "process", "(", "np", ".", "random", ".", "uniform", "(", "size", "=", "(", "1", ",", "128", ",", "128", ",", "4", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "parameters", ".", "loc", "[", "index", ",", "'params'", "]", "=", "model", ".", "count_parameters", "(", ")", "\n", "\n", "# Run training", "\n", "if", "not", "args", ".", "dry", ":", "\n", "            ", "out_dir", "=", "train_nip_model", "(", "model", ",", "args", ".", "camera", ",", "args", ".", "epochs", ",", "validation_loss_threshold", "=", "convergence_threshold", ",", "\n", "patch_size", "=", "args", ".", "patch_size", ",", "resume", "=", "args", ".", "resume", ",", "data", "=", "data", ",", "out_directory_root", "=", "args", ".", "out_dir", ")", "\n", "", "else", ":", "\n", "            ", "out_dir", "=", "os", ".", "path", ".", "join", "(", "out_directory_root", ",", "args", ".", "camera", ",", "model", ".", "model_code", ",", "model", ".", "scoped_name", ")", "\n", "\n", "# Fill results", "\n", "", "if", "args", ".", "fill", "is", "not", "None", ":", "\n", "\n", "            ", "if", "len", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ">", "0", ":", "\n", "                ", "for", "key", "in", "[", "'ssim'", ",", "'psnr'", ",", "'loss'", "]", ":", "\n", "                    ", "parameters", ".", "loc", "[", "index", ",", "key", "]", "=", "model", ".", "pop_metric", "(", "key", ",", "'validation'", ")", "# results['performance'][key]['validation'][-1]", "\n", "\n", "", "", "else", ":", "\n", "                ", "results_json", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'progress.json'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "results_json", ")", ":", "\n", "                    ", "with", "open", "(", "results_json", ")", "as", "f", ":", "\n", "                        ", "results", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "for", "key", "in", "[", "'ssim'", ",", "'psnr'", ",", "'loss'", "]", ":", "\n", "                        ", "parameters", ".", "loc", "[", "index", ",", "key", "]", "=", "utils", ".", "get", "(", "results", ",", "f'performance.{key}.validation'", ")", "[", "-", "1", "]", "\n", "\n", "", "", "", "", "", "if", "args", ".", "fill", "is", "not", "None", ":", "\n", "\n", "        ", "if", "args", ".", "fill", "==", "'-'", ":", "\n", "            ", "print", "(", "'\\n# Training Results'", ")", "\n", "print", "(", "parameters", ".", "to_string", "(", ")", ")", "\n", "", "elif", "args", ".", "fill", ".", "endswith", "(", "'.csv'", ")", ":", "\n", "            ", "print", "(", "'Saving the results to {}'", ".", "format", "(", "args", ".", "fill", ")", ")", "\n", "parameters", ".", "to_csv", "(", "args", ".", "fill", ",", "index", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid value for the output results file: {}'", ".", "format", "(", "args", ".", "fill", ")", ")", "\n", "\n", "", "", "if", "args", ".", "dry", ":", "\n", "        ", "print", "(", "'\\n# List of instantiated models [{}]:'", ".", "format", "(", "len", "(", "model_log", ")", ")", ")", "\n", "for", "index", ",", "key", "in", "enumerate", "(", "sorted", "(", "model_log", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "print", "(", "'{}  {:3d}. {} -> {}'", ".", "format", "(", "' '", "if", "len", "(", "model_log", "[", "key", "]", ")", "==", "1", "else", "'!'", ",", "index", ",", "key", ",", "model_log", "[", "key", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_fan.restore_flow": [[25, 61], ["print", "helpers.utils.get", "workflows.manipulation_classification.ManipulationClassification", "manipulation_classification.ManipulationClassification.fan.load_model", "open", "json.load", "helpers.utils.get", "print", "print", "print", "print", "coreutils.getkey", "os.path.join", "helpers.utils.get.remove", "helpers.utils.get", "os.path.split", "os.path.split"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["def", "restore_flow", "(", "filename", ",", "isp", ",", "manipulations", ",", "jpeg_qf", ",", "jpeg_codec", ",", "dcn_model", ",", "patch_size", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "training_log", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "print", "(", "'\\n[{}]'", ".", "format", "(", "os", ".", "path", ".", "split", "(", "filename", ")", "[", "0", "]", ")", ")", "\n", "\n", "# Setup manipulations", "\n", "if", "manipulations", "is", "None", ":", "\n", "        ", "manipulations", "=", "helpers", ".", "utils", ".", "get", "(", "training_log", ",", "'manipulations'", ")", "\n", "if", "'native'", "in", "manipulations", ":", "manipulations", ".", "remove", "(", "'native'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'info: overriding manipulation list with {}'", ".", "format", "(", "manipulations", ")", ")", "\n", "manipulations", "=", "manipulations", "\n", "\n", "", "try", ":", "\n", "        ", "accuracy", "=", "helpers", ".", "utils", ".", "get", "(", "training_log", ",", "'forensics.performance.accuracy.validation'", ")", "[", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "accuracy", "=", "np", ".", "nan", "\n", "\n", "", "distribution", "=", "helpers", ".", "utils", ".", "get", "(", "training_log", ",", "'distribution'", ")", "\n", "\n", "if", "jpeg_qf", "is", "not", "None", ":", "\n", "        ", "print", "(", "'info: overriding JPEG quality with {}'", ".", "format", "(", "jpeg_qf", ")", ")", "\n", "distribution", "[", "'compression_params'", "]", "[", "'quality'", "]", "=", "jpeg_qf", "\n", "\n", "", "if", "jpeg_codec", "is", "not", "None", ":", "\n", "        ", "print", "(", "'info: overriding JPEG codec with {}'", ".", "format", "(", "jpeg_codec", ")", ")", "\n", "distribution", "[", "'compression_params'", "]", "[", "'codec'", "]", "=", "jpeg_codec", "\n", "\n", "", "if", "dcn_model", "is", "not", "None", ":", "\n", "        ", "print", "(", "'info: overriding DCN model with {}'", ".", "format", "(", "dcn_model", ")", ")", "\n", "distribution", "[", "'compression_params'", "]", "[", "'dirname'", "]", "=", "dcn_model", "\n", "\n", "", "flow", "=", "manipulation_classification", ".", "ManipulationClassification", "(", "isp", ",", "manipulations", ",", "distribution", ",", "coreutils", ".", "getkey", "(", "training_log", ",", "'forensics/args'", ")", ",", "{", "}", ",", "patch_size", "=", "patch_size", ")", "\n", "flow", ".", "fan", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "split", "(", "filename", ")", "[", "0", "]", ",", "'models'", ")", ")", "\n", "return", "flow", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_fan.main": [[62, 125], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "argparse.ArgumentParser.parse_args", "sorted", "print", "print", "parser.parse_args.manipulations.strip().split", "len", "sys.exit", "helpers.dataset.Dataset", "helpers.dataset.Dataset", "str", "dataset.Dataset.summary", "len", "re.findall", "test_fan.restore_flow", "print", "training.validation.validate_fan", "print", "print", "print", "parser.parse_args.manipulations.strip", "pathlib.Path().glob", "flow.summary", "helpers.results_data.confusion_to_text", "numpy.mean", "pathlib.Path", "numpy.diag"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_fan.restore_flow", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_fan", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_to_text"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Test manipulation detection (FAN) on RGB images'", ")", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General settings'", ")", "\n", "group", ".", "add_argument", "(", "'-p'", ",", "'--patch'", ",", "dest", "=", "'patch'", ",", "action", "=", "'store'", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "'patch size'", ")", "\n", "group", ".", "add_argument", "(", "'-i'", ",", "'--images'", ",", "dest", "=", "'images'", ",", "action", "=", "'store'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of validation images (defaults to -1 - use all in the directory)'", ")", "\n", "group", ".", "add_argument", "(", "'--patches'", ",", "dest", "=", "'patches'", ",", "action", "=", "'store'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of validation patches'", ")", "\n", "group", ".", "add_argument", "(", "'--data'", ",", "dest", "=", "'data'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/rgb/native12k'", ",", "\n", "help", "=", "'directory with test RGB images'", ")", "\n", "group", ".", "add_argument", "(", "'--isp'", ",", "dest", "=", "'isp'", ",", "action", "=", "'store'", ",", "default", "=", "'ONet'", ",", "\n", "help", "=", "'test imaging pipeline'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Training session selection'", ")", "\n", "group", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/m/7-raw'", ",", "\n", "help", "=", "'directory with training sessions'", ")", "\n", "group", ".", "add_argument", "(", "'--re'", ",", "dest", "=", "'re'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'regular expression to filter training sessions'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Override training settings'", ")", "\n", "group", ".", "add_argument", "(", "'-q'", ",", "'--jpeg_qf'", ",", "dest", "=", "'jpeg_qf'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "\n", "help", "=", "'Override JPEG quality level (distribution channel)'", ")", "\n", "group", ".", "add_argument", "(", "'-c'", ",", "'--codec'", ",", "dest", "=", "'jpeg_codec'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'Override JPEG codec settings (libjpeg, soft, sin)'", ")", "\n", "group", ".", "add_argument", "(", "'--dcn'", ",", "dest", "=", "'dcn_model'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Coverride DCN model directory'", ")", "\n", "group", ".", "add_argument", "(", "'-m'", ",", "'--manip'", ",", "dest", "=", "'manipulations'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Included manipulations, e.g., : {}'", ".", "format", "(", "'sharpen,jpeg,resample,gaussian'", ")", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Split manipulations", "\n", "if", "args", ".", "manipulations", "is", "not", "None", ":", "\n", "        ", "args", ".", "manipulations", "=", "args", ".", "manipulations", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "\n", "", "json_files", "=", "sorted", "(", "str", "(", "f", ")", "for", "f", "in", "Path", "(", "args", ".", "dir", ")", ".", "glob", "(", "'**/training.json'", ")", ")", "\n", "\n", "if", "len", "(", "json_files", ")", "==", "0", ":", "\n", "        ", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "# Load training / validation data", "\n", "", "if", "args", ".", "isp", "==", "'ONet'", ":", "\n", "        ", "data", "=", "dataset", ".", "Dataset", "(", "args", ".", "data", ",", "n_images", "=", "0", ",", "v_images", "=", "args", ".", "images", ",", "load", "=", "'y'", ",", "val_rgb_patch_size", "=", "2", "*", "args", ".", "patch", ",", "val_n_patches", "=", "args", ".", "patches", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "dataset", ".", "Dataset", "(", "args", ".", "data", ",", "n_images", "=", "0", ",", "v_images", "=", "args", ".", "images", ",", "load", "=", "'xy'", ",", "val_rgb_patch_size", "=", "2", "*", "args", ".", "patch", ",", "val_n_patches", "=", "args", ".", "patches", ")", "\n", "\n", "", "print", "(", "'Data: {}'", ".", "format", "(", "data", ".", "summary", "(", ")", ")", ")", "\n", "print", "(", "'Found {} candidate training sessions ({})'", ".", "format", "(", "len", "(", "json_files", ")", ",", "args", ".", "dir", ")", ")", "\n", "\n", "for", "filename", "in", "json_files", ":", "\n", "\n", "        ", "if", "args", ".", "re", "is", "None", "or", "re", ".", "findall", "(", "args", ".", "re", ",", "filename", ")", ":", "\n", "\n", "            ", "flow", ",", "accuracy", "=", "restore_flow", "(", "filename", ",", "args", ".", "isp", ",", "args", ".", "manipulations", ",", "args", ".", "jpeg_qf", ",", "args", ".", "jpeg_codec", ",", "args", ".", "dcn_model", ",", "args", ".", "patch", ")", "\n", "print", "(", "flow", ".", "summary", "(", ")", ")", "\n", "\n", "_", ",", "conf", "=", "validate_fan", "(", "flow", ",", "data", ")", "\n", "\n", "print", "(", "'Accuracy validated/expected: {:.4f} / {:.4f}'", ".", "format", "(", "np", ".", "mean", "(", "np", ".", "diag", "(", "conf", ")", ")", ",", "accuracy", ")", ")", "\n", "print", "(", "results_data", ".", "confusion_to_text", "(", "(", "100", "*", "conf", ")", ".", "round", "(", "0", ")", ",", "flow", ".", "_forensics_classes", ",", "filename", ",", "'txt'", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Skipping {}...'", ".", "format", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.develop_images.develop_images": [[22, 99], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "print", "print", "helpers.fsutil.listdir", "log.info", "pipeline.endswith", "tqdm.tqdm", "ValueError", "os.path.exists", "IOError", "os.path.exists", "os.makedirs", "tensorflow.Session", "model.load_model", "os.path.join", "os.path.join", "len", "getattr", "tensorflow.get_default_graph", "os.path.exists", "RuntimeError", "os.path.exists", "imageio.imwrite", "os.path.splitext", "raw.process_auto", "rgb.astype.astype", "os.path.splitext", "rgb.astype.astype", "os.path.join", "rgb.astype.astype", "raw.process", "np.load().astype", "model.process().squeeze", "np.load", "model.process"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process_auto", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["def", "develop_images", "(", "camera", ",", "pipeline", ",", "n_images", "=", "0", ",", "root_dir", "=", "'./data'", ",", "model_dir", "=", "'nip'", ",", "dev_dir", "=", "'developed'", ",", "nip_params", "=", "None", ")", ":", "\n", "\n", "    ", "if", "pipeline", "not", "in", "supported_pipelines", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported pipeline model ({})! Available models: {}'", ".", "format", "(", "pipeline", ",", "', '", ".", "join", "(", "supported_pipelines", ")", ")", ")", "\n", "\n", "", "dir_models", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "model_dir", ")", "\n", "nip_directory", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "'training_data'", ",", "camera", ")", "\n", "out_directory", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "dev_dir", ",", "camera", ",", "pipeline", ")", "\n", "raw_directory", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "'images'", ",", "camera", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "nip_directory", ")", ":", "\n", "        ", "raise", "IOError", "(", "'Directory not found! {}'", ".", "format", "(", "nip_directory", ")", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_directory", ")", "\n", "\n", "# Lazy loading of remaining dependencies to ensure responsiveness of the CLI", "\n", "", "import", "numpy", "as", "np", "\n", "import", "imageio", "\n", "import", "tqdm", "\n", "from", "helpers", "import", "raw", "\n", "from", "models", "import", "pipelines", "\n", "\n", "print", "(", "'Camera: {}'", ".", "format", "(", "camera", ")", ")", "\n", "print", "(", "'Pipeline: {}'", ".", "format", "(", "pipeline", ")", ")", "\n", "print", "(", "'NIP Models: {}'", ".", "format", "(", "dir_models", ")", ")", "\n", "print", "(", "'NIP Training Directory: {}'", ".", "format", "(", "nip_directory", ")", ")", "\n", "print", "(", "'Out Directory: {}'", ".", "format", "(", "out_directory", ")", ")", "\n", "\n", "# %% Process Bayer stacks with the given pipeline", "\n", "npy_filenames", "=", "fsutil", ".", "listdir", "(", "nip_directory", ",", "'.*\\.{}$'", ".", "format", "(", "extensions", ")", ")", "\n", "log", ".", "info", "(", "'Camera {} matched {:,} Bayer stacks'", ".", "format", "(", "camera", ",", "len", "(", "npy_filenames", ")", ")", ")", "\n", "\n", "manual_dev_settings", "=", "{", "'use_srgb'", ":", "True", ",", "'use_gamma'", ":", "True", ",", "'brightness'", ":", "None", "}", "\n", "\n", "# Setup the NIP model", "\n", "if", "pipeline", ".", "endswith", "(", "'Net'", ")", ":", "\n", "        ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "model", "=", "getattr", "(", "pipelines", ",", "pipeline", ")", "(", "sess", ",", "tf", ".", "get_default_graph", "(", ")", ",", "loss_metric", "=", "'L2'", ",", "**", "nip_params", ")", "\n", "model", ".", "load_model", "(", "camera", ",", "out_directory_root", "=", "dir_models", ")", "\n", "\n", "# Limit the number of images", "\n", "", "if", "n_images", ">", "0", ":", "\n", "        ", "npy_filenames", "=", "npy_filenames", "[", ":", "n_images", "]", "\n", "\n", "", "for", "npy_file", "in", "tqdm", ".", "tqdm", "(", "npy_filenames", ",", "ncols", "=", "120", ",", "desc", "=", "'Developing ({}/{})'", ".", "format", "(", "camera", ",", "pipeline", ")", ")", ":", "\n", "\n", "# Find the original RAW file (for standard pipelines.py)", "\n", "        ", "raw_file", "=", "os", ".", "path", ".", "join", "(", "raw_directory", ",", "os", ".", "path", ".", "splitext", "(", "npy_file", ")", "[", "0", "]", ")", "\n", "raw_found", "=", "False", "\n", "\n", "for", "extension", "in", "raw_extensions", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "raw_file", "+", "extension", ")", ":", "\n", "                ", "raw_file", "=", "raw_file", "+", "extension", "\n", "raw_found", "=", "True", "\n", "break", "\n", "\n", "", "", "if", "not", "raw_found", ":", "\n", "            ", "raise", "RuntimeError", "(", "'RAW file not found for Bayer stack: {}'", ".", "format", "(", "npy_file", ")", ")", "\n", "\n", "", "out_png", "=", "os", ".", "path", ".", "join", "(", "out_directory", ",", "os", ".", "path", ".", "splitext", "(", "npy_file", ")", "[", "0", "]", "+", "'.png'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_png", ")", ":", "\n", "# Process with the desired pipeline", "\n", "            ", "if", "pipeline", "==", "'libRAW'", ":", "\n", "                ", "rgb", "=", "raw", ".", "process_auto", "(", "raw_file", ")", "\n", "", "elif", "pipeline", "==", "'Python'", ":", "\n", "                ", "rgb", "=", "255", "*", "raw", ".", "process", "(", "raw_file", ",", "**", "manual_dev_settings", ")", "\n", "rgb", "=", "rgb", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "# Find the cached Bayer stack", "\n", "                ", "bayer_file", "=", "os", ".", "path", ".", "join", "(", "nip_directory", ",", "npy_file", ")", "\n", "bayer_stack", "=", "np", ".", "load", "(", "bayer_file", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "16", "-", "1", ")", "\n", "rgb", "=", "255", "*", "model", ".", "process", "(", "bayer_stack", ")", ".", "squeeze", "(", ")", "\n", "rgb", "=", "rgb", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "", "imageio", ".", "imwrite", "(", "out_png", ",", "rgb", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.develop_images.main": [[101, 134], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "argparse.ArgumentParser.print_usage", "sys.exit", "develop_images.develop_images", "json.loads", "print", "sys.exit", "log.error", "parser.parse_args.nip_params.replace", "parser.parse_args.nip_params.replace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.develop_images.develop_images"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Develops RAW images with a selected pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ")", "\n", "parser", ".", "add_argument", "(", "'--pipe'", ",", "dest", "=", "'pipeline'", ",", "action", "=", "'store'", ",", "default", "=", "'libRAW'", ",", "\n", "help", "=", "'imaging pipeline ({})'", ".", "format", "(", "supported_pipelines", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data'", ",", "\n", "help", "=", "'root directory with images and training data'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "dest", "=", "'model_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'nip'", ",", "\n", "help", "=", "'directory with TF models'", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_dir'", ",", "dest", "=", "'dev_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'developed'", ",", "\n", "help", "=", "'output directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--params'", ",", "dest", "=", "'nip_params'", ",", "default", "=", "None", ",", "help", "=", "'Extra parameters for NIP constructor (JSON string)'", ")", "\n", "parser", ".", "add_argument", "(", "'--images'", ",", "dest", "=", "'images'", ",", "action", "=", "'store'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of images to process'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "camera", ":", "\n", "        ", "print", "(", "'A camera needs to be specified!'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "args", ".", "nip_params", "is", "not", "None", ":", "\n", "            ", "args", ".", "nip_params", "=", "json", ".", "loads", "(", "args", ".", "nip_params", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "'WARNING'", ",", "'JSON parsing error for: '", ",", "args", ".", "nip_params", ".", "replace", "(", "'\\''", ",", "'\"'", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "try", ":", "\n", "        ", "develop_images", "(", "args", ".", "camera", ",", "args", ".", "pipeline", ",", "args", ".", "images", ",", "args", ".", "dir", ",", "args", ".", "model_dir", ",", "args", ".", "dev_dir", ",", "nip_params", "=", "args", ".", "nip_params", ")", "\n", "", "except", "Exception", "as", "error", ":", "\n", "        ", "log", ".", "error", "(", "error", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.save_df": [[17, 23], ["df.to_csv", "print", "os.path.isdir", "os.makedirs", "os.path.join"], "function", ["None"], ["def", "save_df", "(", "df", ",", "dirname", ",", "df_filename", ")", ":", "\n", "    ", "if", "dirname", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "dirname", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "", "df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "df_filename", ")", ",", "index", "=", "False", ")", "\n", "print", "(", "'> saving dataframe to {}'", ".", "format", "(", "df_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.display_results": [[25, 228], ["seaborn.set", "helpers.utils.match_option", "print", "print", "RuntimeError", "os.path.isdir", "FileNotFoundError", "helpers.results_data.manipulation_metrics", "seaborn.catplot", "results.save_df", "matplotlib.show", "helpers.results_data.manipulation_metrics", "print", "seaborn.relplot", "results.save_df", "matplotlib.show", "helpers.results_data.manipulation_progress", "results.save_df", "matplotlib.show", "isinstance", "helpers.results_data.confusion_data", "enumerate", "print", "helpers.results_data.manipulation_summary", "results.save_df", "print", "helpers.results_data.manipulation_summary", "df.sort_values.sort_values", "df[].str.split", "helpers.fsutil.strip_prefix", "numpy.argmax", "seaborn.catplot", "matplotlib.show", "helpers.fsutil.split", "len", "print", "sys.exit", "helpers.fsutil.listdir", "len", "print", "numpy.ceil", "numpy.ceil", "matplotlib.figure", "results_data.confusion_data.items", "matplotlib.tight_layout", "matplotlib.show", "len", "df[].str.split.iloc[].endswith", "len", "len", "df.sort_values.groupby", "df.groupby.size().to_frame", "print", "seaborn.color_palette", "helpers.fsutil.listdir", "os.path.join", "len", "seaborn.relplot", "len", "print", "len", "numpy.sqrt", "print", "print", "numpy.mean", "plt.figure.add_subplot", "seaborn.heatmap", "fig.add_subplot.set_title", "print", "df.sort_values.groupby", "df.groupby.size().to_frame", "print", "df[].str.split.iloc[].startswith", "df[].unique", "len", "gb.size().to_frame.join().reset_index().to_string", "helpers.utils.match_option.split", "len", "os.path.join", "helpers.fsutil.listdir", "helpers.fsutil.listdir", "df[].dropna", "results_data.confusion_data.keys", "len", "len", "helpers.results_data.confusion_to_text", "helpers.results_data.confusion_to_text", "numpy.diag", "df.sort_values.groupby().mean().to_string", "gb.size().to_frame.join().reset_index().to_string", "df[].str.split.iloc[].startswith", "df[].unique", "df.groupby.size", "df[].unique", "len", "numpy.linspace().astype", "print", "os.path.join", "print", "cases.append", "df.groupby.size", "gb.size().to_frame.join().reset_index", "df.sort_values.groupby().mean", "gb.size().to_frame.join().reset_index", "set", "all", "numpy.linspace", "int", "df[].str.split.iloc[].unique", "gb.size().to_frame.join", "int", "df.sort_values.groupby", "gb.size().to_frame.join", "re.match", "df.groupby.agg", "len", "df.groupby.agg", "df[].str.split.iloc[].unique"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_metrics", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.save_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_metrics", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.save_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.save_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_data", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.results.save_df", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.strip_prefix", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_to_text", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_to_text", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set"], ["", "", "def", "display_results", "(", "args", ")", ":", "\n", "\n", "    ", "sns", ".", "set", "(", "'paper'", ",", "font_scale", "=", "1", ",", "style", "=", "\"ticks\"", ")", "\n", "plot", "=", "helpers", ".", "utils", ".", "match_option", "(", "args", ".", "plot", ",", "supported_plots", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "dir", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "'Directory {} not found!'", ".", "format", "(", "args", ".", "dir", ")", ")", "\n", "\n", "", "print", "(", "'Results from: {}'", ".", "format", "(", "args", ".", "dir", ")", ")", "\n", "print", "(", "'Matched plotting command: {}'", ".", "format", "(", "plot", ")", ")", "\n", "\n", "postfix", "=", "[", "\n", "fsutil", ".", "split", "(", "args", ".", "dir", ")", "[", "-", "1", "]", ",", "\n", "','", ".", "join", "(", "args", ".", "nips", ")", "if", "args", ".", "nips", "is", "not", "None", "else", "None", ",", "\n", "','", ".", "join", "(", "args", ".", "cameras", ")", "if", "args", ".", "cameras", "is", "not", "None", "else", "None", ",", "\n", "]", "\n", "postfix", "=", "'-'", ".", "join", "(", "x", "for", "x", "in", "postfix", "if", "x", "is", "not", "None", ")", "\n", "\n", "if", "plot", "in", "[", "'ssim'", ",", "'psnr'", ",", "'accuracy'", "]", ":", "\n", "\n", "        ", "df", "=", "results_data", ".", "manipulation_metrics", "(", "args", ".", "nips", ",", "args", ".", "cameras", ",", "root_dir", "=", "args", ".", "dir", ")", "\n", "sns", ".", "catplot", "(", "x", "=", "'ln'", ",", "y", "=", "plot", ",", "col", "=", "'camera'", ",", "row", "=", "'nip'", ",", "data", "=", "df", ",", "kind", "=", "'box'", ")", "\n", "save_df", "(", "df", ",", "args", ".", "df", ",", "'manipulation_metrics-{}.csv'", ".", "format", "(", "postfix", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "return", "\n", "\n", "", "if", "plot", "==", "'scatter-psnr'", "or", "plot", "==", "'scatter-ssim'", ":", "\n", "\n", "        ", "df", "=", "results_data", ".", "manipulation_metrics", "(", "args", ".", "nips", ",", "args", ".", "cameras", ",", "root_dir", "=", "args", ".", "dir", ")", "\n", "\n", "if", "len", "(", "df", ")", "==", "0", ":", "\n", "            ", "print", "(", "'ERROR No results found!'", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "print", "(", "df", ")", "\n", "g", "=", "sns", ".", "relplot", "(", "x", "=", "plot", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", ",", "y", "=", "'accuracy'", ",", "hue", "=", "'ln'", ",", "col", "=", "'camera'", ",", "row", "=", "'nip'", ",", "data", "=", "df", ",", "\n", "palette", "=", "sns", ".", "color_palette", "(", "\"Set2\"", ",", "len", "(", "df", "[", "'ln'", "]", ".", "unique", "(", ")", ")", ")", ")", "\n", "save_df", "(", "df", ",", "args", ".", "df", ",", "'manipulation_metrics-{}.csv'", ".", "format", "(", "postfix", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "return", "\n", "\n", "", "if", "plot", "==", "'progress'", ":", "\n", "\n", "        ", "cases", "=", "[", "]", "\n", "\n", "if", "args", ".", "cameras", "is", "None", ":", "\n", "            ", "args", ".", "cameras", "=", "fsutil", ".", "listdir", "(", "args", ".", "dir", ",", "'.'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "", "for", "cam", "in", "args", ".", "cameras", ":", "\n", "\n", "            ", "nip_models", "=", "args", ".", "nips", "or", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dir", ",", "cam", ")", ",", "'.'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "for", "nip", "in", "nip_models", ":", "\n", "\n", "                ", "reg_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dir", ",", "cam", ",", "nip", ")", "\n", "\n", "if", "args", ".", "regularization", ":", "\n", "# If given, use specified regularization strengths", "\n", "                    ", "reg_list", "=", "args", ".", "regularization", "\n", "", "else", ":", "\n", "# Otherwise, auto-detect available scenarios", "\n", "                    ", "reg_list", "=", "fsutil", ".", "listdir", "(", "reg_path", ",", "'.*'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "if", "len", "(", "reg_list", ")", ">", "4", ":", "\n", "                        ", "indices", "=", "np", ".", "linspace", "(", "0", ",", "len", "(", "reg_list", ")", "-", "1", ",", "4", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "reg_list", "=", "[", "reg_list", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "print", "(", "'! warning - too many experiments to show - sampling: {}'", ".", "format", "(", "reg_list", ")", ")", "\n", "\n", "", "", "for", "reg", "in", "reg_list", ":", "\n", "                    ", "for", "r", "in", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "reg_path", ",", "reg", ")", ",", "'[0-9]+'", ",", "dirs_only", "=", "True", ")", ":", "\n", "                        ", "print", "(", "'* found scenario {}'", ".", "format", "(", "(", "cam", ",", "nip", ",", "reg", ",", "int", "(", "r", ")", ")", ")", ")", "\n", "cases", ".", "append", "(", "(", "cam", ",", "nip", ",", "reg", ",", "int", "(", "r", ")", ")", ")", "\n", "\n", "", "", "", "", "df", ",", "labels", "=", "results_data", ".", "manipulation_progress", "(", "cases", ",", "root_dir", "=", "args", ".", "dir", ")", "\n", "save_df", "(", "df", ",", "args", ".", "df", ",", "'progress-{}.csv'", ".", "format", "(", "postfix", ")", ")", "\n", "\n", "for", "col", "in", "[", "'psnr'", ",", "'accuracy'", "]", ":", "\n", "            ", "if", "len", "(", "df", "[", "col", "]", ".", "dropna", "(", ")", ")", ">", "0", ":", "\n", "                ", "sns", ".", "relplot", "(", "x", "=", "\"step\"", ",", "y", "=", "col", ",", "hue", "=", "'exp'", ",", "row", "=", "'nip'", ",", "col", "=", "'camera'", ",", "style", "=", "'exp'", ",", "kind", "=", "\"line\"", ",", "\n", "legend", "=", "\"full\"", ",", "aspect", "=", "2", ",", "height", "=", "3", ",", "data", "=", "df", ")", "\n", "\n", "", "", "plt", ".", "show", "(", ")", "\n", "return", "\n", "\n", "", "if", "plot", "==", "'conf'", "or", "plot", "==", "'conf-tex'", ":", "\n", "\n", "        ", "if", "isinstance", "(", "args", ".", "nips", ",", "list", ")", ":", "\n", "            ", "if", "len", "(", "args", ".", "nips", ")", ">", "1", ":", "\n", "                ", "print", "(", "'WARNING Only one NIP will be used for this plot!'", ")", "\n", "", "args", ".", "nips", "=", "args", ".", "nips", "[", "0", "]", "\n", "\n", "", "conf", "=", "results_data", ".", "confusion_data", "(", "args", ".", "run", ",", "root_dir", "=", "args", ".", "dir", ")", "\n", "\n", "if", "len", "(", "conf", ")", "==", "0", ":", "\n", "            ", "print", "(", "'ERROR No results found!'", ")", "\n", "return", "\n", "\n", "", "tex_output", "=", "plot", "==", "'conf-tex'", "\n", "plot_data", "=", "not", "tex_output", "if", "len", "(", "conf", ".", "keys", "(", ")", ")", "<", "20", "else", "False", "\n", "\n", "if", "plot_data", ":", "\n", "            ", "images_x", "=", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "len", "(", "conf", ")", ")", ")", "\n", "images_y", "=", "np", ".", "ceil", "(", "len", "(", "conf", ")", "/", "images_x", ")", "\n", "f_size", "=", "3", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "images_x", "*", "f_size", ",", "images_y", "*", "f_size", ")", ")", "\n", "\n", "", "for", "i", ",", "(", "k", ",", "c", ")", "in", "enumerate", "(", "conf", ".", "items", "(", ")", ")", ":", "\n", "            ", "data", "=", "(", "100", "*", "c", "[", "'data'", "]", ")", ".", "round", "(", "0", ")", "\n", "labels", "=", "c", "[", "'labels'", "]", "\n", "if", "tex_output", ":", "\n", "                ", "print", "(", "results_data", ".", "confusion_to_text", "(", "data", ",", "labels", ",", "k", ",", "'tex'", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "results_data", ".", "confusion_to_text", "(", "data", ",", "labels", ",", "k", ",", "'txt'", ")", ")", "\n", "\n", "", "if", "plot_data", ":", "\n", "                ", "acc", "=", "np", ".", "mean", "(", "np", ".", "diag", "(", "data", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "i", "+", "1", ")", "\n", "sns", ".", "heatmap", "(", "data", ",", "annot", "=", "True", ",", "fmt", "=", "\".0f\"", ",", "linewidths", "=", ".5", ",", "xticklabels", "=", "[", "x", "[", "0", "]", "for", "x", "in", "labels", "]", ",", "yticklabels", "=", "labels", ")", "\n", "ax", ".", "set_title", "(", "'{} : acc={:.1f}'", ".", "format", "(", "k", ",", "acc", ")", ")", "\n", "\n", "", "", "if", "plot_data", ":", "\n", "            ", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "return", "\n", "\n", "", "if", "plot", "==", "'df'", ":", "\n", "\n", "        ", "print", "(", "'Searching for \"training.json\" in'", ",", "args", ".", "dir", ")", "\n", "df", "=", "results_data", ".", "manipulation_summary", "(", "args", ".", "dir", ")", "\n", "\n", "if", "len", "(", "df", ")", ">", "0", ":", "\n", "            ", "if", "False", ":", "\n", "                ", "print", "(", "df", ".", "groupby", "(", "'scenario'", ")", ".", "mean", "(", ")", ".", "to_string", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "gb", "=", "df", ".", "groupby", "(", "'scenario'", ")", "\n", "counts", "=", "gb", ".", "size", "(", ")", ".", "to_frame", "(", "name", "=", "'reps'", ")", "\n", "print", "(", "counts", ".", "join", "(", "gb", ".", "agg", "(", "'mean'", ")", ")", ".", "reset_index", "(", ")", ".", "to_string", "(", ")", ")", "\n", "\n", "", "", "save_df", "(", "df", ",", "args", ".", "df", ",", "'summary-{}.csv'", ".", "format", "(", "postfix", ")", ")", "\n", "\n", "return", "\n", "\n", "", "if", "plot", "==", "'auto'", ":", "\n", "\n", "        ", "print", "(", "'Searching for \"training.json\" in'", ",", "args", ".", "dir", ")", "\n", "df", "=", "results_data", ".", "manipulation_summary", "(", "args", ".", "dir", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "'scenario'", ")", "\n", "\n", "guessed_names", "=", "{", "}", "\n", "\n", "# Guess scenario", "\n", "components", "=", "df", "[", "'scenario'", "]", ".", "str", ".", "split", "(", "\"/\"", ",", "expand", "=", "True", ")", "\n", "for", "i", "in", "components", ":", "\n", "# Try to guess the column name based on content", "\n", "            ", "template", "=", "'scenario:{}'", ".", "format", "(", "i", ")", "\n", "if", "components", ".", "iloc", "[", "0", ",", "i", "]", ".", "endswith", "(", "'Net'", ")", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "'nip'", "\n", "", "elif", "components", ".", "iloc", "[", "0", ",", "i", "]", ".", "startswith", "(", "'ln-'", ")", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "'nip reg.'", "\n", "", "elif", "components", ".", "iloc", "[", "0", ",", "i", "]", ".", "startswith", "(", "'lc-'", ")", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "'dcn reg.'", "\n", "", "elif", "set", "(", "components", ".", "iloc", "[", ":", ",", "i", "]", ".", "unique", "(", ")", ")", "==", "{", "'4k'", ",", "'8k'", ",", "'16k'", "}", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "'dcn'", "\n", "", "elif", "all", "(", "[", "re", ".", "match", "(", "'^[0-9]{2,3}$'", ",", "x", ")", "for", "x", "in", "components", ".", "iloc", "[", ":", ",", "i", "]", ".", "unique", "(", ")", "]", ")", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "'jpeg'", "\n", "", "else", ":", "\n", "                ", "guessed_names", "[", "template", "]", "=", "template", "\n", "\n", "", "df", "[", "guessed_names", "[", "template", "]", "]", "=", "components", "[", "i", "]", "\n", "\n", "", "df", "[", "'scenario'", "]", "=", "fsutil", ".", "strip_prefix", "(", "df", "[", "'scenario'", "]", ")", "\n", "\n", "mapping", "=", "{", "}", "\n", "mapping_targets", "=", "[", "'col'", ",", "'col'", ",", "'hue'", ",", "'style'", ",", "'size'", "]", "\n", "mapping_id", "=", "0", "\n", "\n", "# Choose the feature with most unique values as x axis", "\n", "uniques", "=", "[", "len", "(", "df", "[", "guessed_names", "[", "'scenario:{}'", ".", "format", "(", "i", ")", "]", "]", ".", "unique", "(", ")", ")", "for", "i", "in", "components", "]", "\n", "\n", "x_feature", "=", "np", ".", "argmax", "(", "uniques", ")", "\n", "\n", "for", "i", "in", "components", ":", "\n", "            ", "if", "i", "==", "x_feature", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "len", "(", "df", "[", "guessed_names", "[", "'scenario:{}'", ".", "format", "(", "i", ")", "]", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                ", "mapping", "[", "mapping_targets", "[", "mapping_id", "]", "]", "=", "guessed_names", "[", "'scenario:{}'", ".", "format", "(", "i", ")", "]", "\n", "mapping_id", "+=", "1", "\n", "\n", "", "", "sns", ".", "catplot", "(", "x", "=", "guessed_names", "[", "'scenario:{}'", ".", "format", "(", "x_feature", ")", "]", ",", "y", "=", "'accuracy'", ",", "data", "=", "df", ",", "kind", "=", "'box'", ",", "**", "mapping", ")", "\n", "# sns.catplot(x='scenario:0', y='dcn_ssim', data=df, kind='box', **mapping)", "\n", "# sns.scatterplot(x='dcn_ssim', y='accuracy', data=df)", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "if", "len", "(", "df", ")", ">", "0", ":", "\n", "            ", "gb", "=", "df", ".", "groupby", "(", "'scenario'", ")", "\n", "counts", "=", "gb", ".", "size", "(", ")", ".", "to_frame", "(", "name", "=", "'reps'", ")", "\n", "print", "(", "counts", ".", "join", "(", "gb", ".", "agg", "(", "'mean'", ")", ")", ".", "reset_index", "(", ")", ".", "to_string", "(", ")", ")", "\n", "\n", "", "return", "\n", "\n", "", "raise", "RuntimeError", "(", "'No plot matched! Available plots {}'", ".", "format", "(", "', '", ".", "join", "(", "supported_plots", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_jpeg.test_output": [[18, 44], ["models.jpeg.DJPG", "print", "numpy.expand_dims", "models.jpeg.DJPG.process", "numpy.zeros_like", "range", "range", "matplotlib.pylab.show", "imageio.imwrite", "imageio.imread", "matplotlib.pylab.subplot", "helpers.plots.image", "matplotlib.pylab.subplot", "helpers.plots.image", "matplotlib.pylab.subplot", "helpers.plots.image", "batch_x[].squeeze().astype", "batch_x[].squeeze", "numpy.max", "batch_y[].squeeze", "numpy.max", "batch_j[].squeeze", "numpy.max", "batch_x[].squeeze", "numpy.abs", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image"], ["def", "test_output", "(", "image", ",", "jpeg_quality", "=", "50", ",", "rounding_approximation", "=", "None", ")", ":", "\n", "\n", "    ", "jpg", "=", "DJPG", "(", "rounding_approximation", "=", "rounding_approximation", ")", "\n", "print", "(", "jpg", ")", "\n", "\n", "batch_x", "=", "np", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "batch_y", "=", "jpg", ".", "process", "(", "batch_x", "/", "255", ",", "jpeg_quality", ")", "\n", "\n", "n_images", "=", "batch_x", ".", "shape", "[", "0", "]", "\n", "\n", "batch_j", "=", "np", ".", "zeros_like", "(", "batch_x", ")", "\n", "for", "n", "in", "range", "(", "n_images", ")", ":", "\n", "        ", "io", ".", "imwrite", "(", "'/tmp/patch_{}.jpg'", ".", "format", "(", "n", ")", ",", "(", "batch_x", "[", "n", "]", ".", "squeeze", "(", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", ",", "quality", "=", "jpeg_quality", ",", "subsampling", "=", "'4:4:4'", ")", "\n", "batch_j", "[", "n", "]", "=", "io", ".", "imread", "(", "'/tmp/patch_{}.jpg'", ".", "format", "(", "n", ")", ")", "\n", "\n", "", "for", "n", "in", "range", "(", "n_images", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "n_images", ",", "3", ",", "1", "+", "n", "*", "3", ")", "\n", "plots", ".", "image", "(", "batch_x", "[", "n", "]", ".", "squeeze", "(", ")", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "batch_x", ")", ")", ",", "'Input'", ")", "\n", "\n", "plt", ".", "subplot", "(", "n_images", ",", "3", ",", "2", "+", "n", "*", "3", ")", "\n", "plots", ".", "image", "(", "batch_y", "[", "n", "]", ".", "squeeze", "(", ")", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "batch_y", ")", ")", ",", "'dJPEG Model'", ")", "\n", "\n", "plt", ".", "subplot", "(", "n_images", ",", "3", ",", "3", "+", "n", "*", "3", ")", "\n", "plots", ".", "image", "(", "batch_j", "[", "n", "]", ".", "squeeze", "(", ")", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "batch_j", ")", ")", ",", "'libJPG Codec'", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_jpeg.test_quality": [[46, 84], ["models.jpeg.DJPG", "print", "numpy.expand_dims", "numpy.unique().tolist", "print", "matplotlib.pylab.figure", "matplotlib.pylab.plot", "matplotlib.pylab.plot", "matplotlib.pylab.xlabel", "matplotlib.pylab.ylabel", "matplotlib.pylab.xlim", "matplotlib.pylab.ylim", "enumerate", "matplotlib.pylab.show", "models.jpeg.DJPG.process", "imageio.imwrite", "imageio.imread", "psnrs_y.append", "psnrs_j.append", "matplotlib.pylab.title", "matplotlib.pylab.title", "numpy.unique", "numpy.round", "np.expand_dims.squeeze().astype", "skimage.measure.compare_psnr", "skimage.measure.compare_psnr", "matplotlib.pylab.plot", "matplotlib.pylab.text", "numpy.round().astype", "np.expand_dims.squeeze", "np.expand_dims.squeeze", "io.imread.squeeze", "np.expand_dims.squeeze", "jpg.process.squeeze", "numpy.round", "numpy.linspace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "test_quality", "(", "image", ",", "rounding_approximation", "=", "None", ",", "n_quality_levels", "=", "91", ")", ":", "\n", "\n", "    ", "jpg", "=", "DJPG", "(", "rounding_approximation", "=", "rounding_approximation", ")", "\n", "print", "(", "jpg", ")", "\n", "\n", "batch_x", "=", "np", ".", "expand_dims", "(", "image", "[", "0", ":", "1024", ",", "0", ":", "1024", ",", ":", "]", ",", "0", ")", "\n", "\n", "psnrs_y", ",", "psnrs_j", "=", "[", "]", ",", "[", "]", "\n", "\n", "quality_levels", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "np", ".", "linspace", "(", "10", ",", "100", ",", "n_quality_levels", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", ".", "tolist", "(", ")", "\n", "print", "(", "'Using quality levels: {}'", ".", "format", "(", "quality_levels", ")", ")", "\n", "\n", "for", "jpeg_quality", "in", "quality_levels", ":", "\n", "        ", "batch_y", "=", "jpg", ".", "process", "(", "batch_x", "/", "255", ",", "jpeg_quality", ")", "\n", "batch_y", "=", "np", ".", "round", "(", "255", "*", "batch_y", ")", "/", "255", "\n", "io", ".", "imwrite", "(", "'/tmp/patch.jpg'", ",", "(", "batch_x", ".", "squeeze", "(", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", ",", "quality", "=", "jpeg_quality", ",", "subsampling", "=", "'4:4:4'", ")", "\n", "batch_j", "=", "io", ".", "imread", "(", "'/tmp/patch.jpg'", ")", "\n", "psnrs_y", ".", "append", "(", "compare_psnr", "(", "batch_x", ".", "squeeze", "(", ")", ",", "255", "*", "batch_y", ".", "squeeze", "(", ")", ",", "255", ")", ")", "\n", "psnrs_j", ".", "append", "(", "compare_psnr", "(", "batch_x", ".", "squeeze", "(", ")", ",", "batch_j", ".", "squeeze", "(", ")", ",", "255", ")", ")", "\n", "\n", "# Plot", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "plt", ".", "plot", "(", "psnrs_y", ",", "psnrs_j", ",", "'bo'", ",", "alpha", "=", "0.25", ")", "\n", "plt", ".", "plot", "(", "[", "30", ",", "50", "]", ",", "[", "30", ",", "50", "]", ",", "'k:'", ")", "\n", "plt", ".", "xlabel", "(", "'PSNR for dJPEG'", ")", "\n", "plt", ".", "ylabel", "(", "'PSNR for libJPEG'", ")", "\n", "plt", ".", "xlim", "(", "[", "30", ",", "60", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "30", ",", "50", "]", ")", "\n", "if", "rounding_approximation", "is", "None", ":", "\n", "        ", "plt", ".", "title", "(", "'dJPEG vs libJPEG quality (with standard rounding)'", ".", "format", "(", "rounding_approximation", ")", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "title", "(", "'dJPEG vs libJPEG quality (with {} rounding approx.)'", ".", "format", "(", "rounding_approximation", ")", ")", "\n", "\n", "", "for", "i", ",", "q", "in", "enumerate", "(", "quality_levels", ")", ":", "\n", "        ", "if", "q", "%", "10", "==", "0", ":", "\n", "            ", "plt", ".", "plot", "(", "psnrs_y", "[", "i", "]", ",", "psnrs_j", "[", "i", "]", ",", "'ko'", ")", "\n", "plt", ".", "text", "(", "psnrs_y", "[", "i", "]", "+", "1", ",", "psnrs_j", "[", "i", "]", "-", "0.25", ",", "'Q{:02d}'", ".", "format", "(", "q", ")", ")", "\n", "", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_jpeg.main": [[86, 119], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "imageio.imread", "print", "os.path.exists", "print", "test_jpeg.test_output", "test_jpeg.test_quality", "int", "int"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_jpeg.test_output", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_jpeg.test_quality"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Test the dJPEG model'", ")", "\n", "parser", ".", "add_argument", "(", "'mode'", ",", "help", "=", "'Test mode: output / quality'", ")", "\n", "parser", ".", "add_argument", "(", "'--image'", ",", "dest", "=", "'image'", ",", "action", "=", "'store'", ",", "\n", "help", "=", "'test image path'", ")", "\n", "parser", ".", "add_argument", "(", "'--patch'", ",", "dest", "=", "'patch_size'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'patch size (default 256)'", ")", "\n", "parser", ".", "add_argument", "(", "'--quality'", ",", "dest", "=", "'quality'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'the quality level or number of levels for evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--round'", ",", "dest", "=", "'round'", ",", "action", "=", "'store'", ",", "default", "=", "'soft'", ",", "\n", "help", "=", "'rounding approximation mode: sin, soft, harmonic'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "image", "=", "args", ".", "image", "or", "DEFAULT_IMAGE", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "image", ")", ":", "\n", "        ", "print", "(", "'Error: file does not exist! {}'", ".", "format", "(", "args", ".", "image", ")", ")", "\n", "\n", "", "image", "=", "io", ".", "imread", "(", "args", ".", "image", ")", "\n", "\n", "if", "image", ".", "shape", "[", "0", "]", ">", "args", ".", "patch_size", "or", "image", ".", "shape", "[", "1", "]", ">", "args", ".", "patch_size", ":", "\n", "        ", "xx", "=", "(", "image", ".", "shape", "[", "1", "]", "-", "args", ".", "patch_size", ")", "//", "2", "\n", "yy", "=", "(", "image", ".", "shape", "[", "0", "]", "-", "args", ".", "patch_size", ")", "//", "2", "\n", "image", "=", "image", "[", "yy", ":", "yy", "+", "args", ".", "patch_size", ",", "xx", ":", "xx", "+", "args", ".", "patch_size", ",", ":", "]", "\n", "\n", "", "print", "(", "'Using image: {}x{} px'", ".", "format", "(", "*", "image", ".", "shape", "[", ":", "2", "]", ")", ")", "\n", "\n", "if", "args", ".", "mode", "==", "'output'", ":", "\n", "        ", "test_output", "(", "image", ",", "jpeg_quality", "=", "int", "(", "args", ".", "quality", ")", ",", "rounding_approximation", "=", "args", ".", "round", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'quality'", ":", "\n", "        ", "test_quality", "(", "image", ",", "n_quality_levels", "=", "int", "(", "args", ".", "quality", ")", ",", "rounding_approximation", "=", "args", ".", "round", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_dcn_rate_dist.main": [[17, 64], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.codec.split", "collections.OrderedDict", "sum", "compression.ratedistortion.plot_bulk", "int", "parser.parse_args.data.endswith", "parser.parse_args.data.endswith", "matplotlib.tight_layout", "os.path.join", "compression.ratedistortion.plot_bulk.savefig", "print", "matplotlib.tight_layout", "matplotlib.show", "matplotlib.close", "os.path.split"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.plot_bulk", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Compare rate-distortion profiles for various codecs'", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "'--data'", ",", "dest", "=", "'data'", ",", "action", "=", "'store'", ",", "default", "=", "'./data/rgb/clic512'", ",", "\n", "help", "=", "'directory with training & validation images (png)'", ")", "\n", "parser", ".", "add_argument", "(", "'-i'", ",", "'--images'", ",", "dest", "=", "'images'", ",", "action", "=", "'append'", ",", "default", "=", "[", "]", ",", "\n", "help", "=", "'select images for plotting'", ")", "\n", "parser", ".", "add_argument", "(", "'-m'", ",", "'--metric'", ",", "dest", "=", "'metric'", ",", "action", "=", "'store'", ",", "default", "=", "'ssim'", ",", "\n", "help", "=", "'distortion metric (ssim, msssim, msssim_db, psnr'", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--plot'", ",", "dest", "=", "'plot'", ",", "action", "=", "'store'", ",", "default", "=", "'fit'", ",", "\n", "help", "=", "'plot type (aggregate, fit)'", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--codec'", ",", "dest", "=", "'codec'", ",", "action", "=", "'store'", ",", "default", "=", "'jpg,jp2,bpg,dcn'", ",", "\n", "help", "=", "'plot type (aggregate, fit)'", ")", "\n", "parser", ".", "add_argument", "(", "'-o'", ",", "'--out'", ",", "dest", "=", "'output'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'output directory for the figure'", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "'--bpp'", ",", "dest", "=", "'max_bpp'", ",", "action", "=", "'store'", ",", "default", "=", "3", ",", "\n", "help", "=", "'limit for the rate axis (bpp, default=3)'", ")", "\n", "parser", ".", "add_argument", "(", "'-x'", ",", "'--markers'", ",", "dest", "=", "'markers'", ",", "action", "=", "'store'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Draw markers: 0 (none), 1 (only single images), 2 (all markers for the dcn aggregate)'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "codec", "=", "args", ".", "codec", ".", "split", "(", "','", ")", "\n", "args", ".", "images", "=", "[", "int", "(", "x", ")", "for", "x", "in", "args", ".", "images", "]", "\n", "\n", "if", "args", ".", "data", ".", "endswith", "(", "'/'", ")", "or", "args", ".", "data", ".", "endswith", "(", "'\\\\'", ")", ":", "\n", "        ", "args", ".", "data", "=", "args", ".", "data", "[", ":", "-", "1", "]", "\n", "\n", "", "plots", "=", "OrderedDict", "(", ")", "\n", "if", "'jpg'", "in", "args", ".", "codec", ":", "plots", "[", "'jpg'", "]", "=", "(", "'jpeg.csv'", ",", "{", "}", ")", "\n", "if", "'jp2'", "in", "args", ".", "codec", ":", "plots", "[", "'jp2'", "]", "=", "(", "'jpeg2000.csv'", ",", "{", "}", ")", "\n", "if", "'bpg'", "in", "args", ".", "codec", ":", "plots", "[", "'bpg'", "]", "=", "(", "'bpg.csv'", ",", "{", "}", ")", "\n", "if", "'dcn'", "in", "args", ".", "codec", ":", "plots", "[", "'dcn'", "]", "=", "(", "'dcn-7-raw.csv'", ",", "{", "'model_dir'", ":", "'.*basic/'", "}", ")", "\n", "\n", "baseline_count", "=", "sum", "(", "[", "x", "in", "args", ".", "codec", "for", "x", "in", "[", "'jpg'", ",", "'jp2'", ",", "'bpg'", "]", "]", ")", "\n", "\n", "fig", "=", "plot_bulk", "(", "plots", ",", "args", ".", "data", ",", "args", ".", "images", ",", "args", ".", "metric", ",", "args", ".", "plot", ",", "baseline_count", ",", "True", ",", "args", ".", "max_bpp", ",", "args", ".", "markers", ")", "\n", "\n", "# Save or display", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "plt", ".", "tight_layout", "(", "3", ")", "\n", "dset", "=", "os", ".", "path", ".", "split", "(", "args", ".", "data", ")", "[", "-", "1", "]", "\n", "of_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "'tradeoff_{}_{}_{}.pdf'", ".", "format", "(", "dset", ",", "args", ".", "metric", ",", "args", ".", "plot", ")", ")", "\n", "fig", ".", "savefig", "(", "of_name", ",", "bbox_inches", "=", "'tight'", ")", "\n", "print", "(", "'Wrritten to {}'", ".", "format", "(", "of_name", ")", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "tight_layout", "(", "3", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_prepare_training_set.prepare_training_set": [[19, 91], ["os.path.join", "os.path.join", "print", "print", "helpers.fsutil.listdir", "log.info", "log.info", "tqdm.tqdm", "sys.exit", "ValueError", "os.path.exists", "log.error", "sys.exit", "os.path.exists", "os.makedirs", "len", "log.error", "os.path.join", "os.path.join", "len", "open", "exifread.process_file", "log.info", "orientation.startswith", "len", "len", "os.path.join", "raw_filenames_selected.append", "len", "os.path.exists", "numpy.save", "os.path.exists", "imageio.imwrite", "log.error", "log.error", "sys.exit", "os.path.splitext", "os.path.splitext", "helpers.raw.unpack", "helpers.raw.process_auto", "raw.process_auto.astype", "os.path.join", "os.path.join", "ValueError", "helpers.raw.process", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.save", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process_auto", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["def", "prepare_training_set", "(", "camera", ",", "target_pipeline", ",", "dev_settings", ",", "n_images", "=", "150", ",", "root_dir", "=", "'./data/'", ")", ":", "\n", "\n", "    ", "if", "target_pipeline", "not", "in", "[", "'auto'", ",", "'manual'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported target pipeline!'", ")", "\n", "\n", "", "raw_directory", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "'images'", ",", "camera", ")", "\n", "out_directory", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'raw'", ",", "'training_data'", ",", "camera", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "raw_directory", ")", ":", "\n", "        ", "log", ".", "error", "(", "'Directory not found! {}'", ".", "format", "(", "raw_directory", ")", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_directory", ")", "\n", "\n", "", "print", "(", "'RAW Directory: {}'", ".", "format", "(", "raw_directory", ")", ")", "\n", "print", "(", "'Out Directory: {}'", ".", "format", "(", "out_directory", ")", ")", "\n", "\n", "# List RAW files and find the ones with horizontal orientation", "\n", "raw_filenames", "=", "fsutil", ".", "listdir", "(", "raw_directory", ",", "'.*\\.{}$'", ".", "format", "(", "EXTENSIONS", ")", ")", "\n", "log", ".", "info", "(", "'Camera {} matched {:,} RAW images'", ".", "format", "(", "camera", ",", "len", "(", "raw_filenames", ")", ")", ")", "\n", "\n", "raw_filenames_selected", "=", "[", "]", "\n", "\n", "for", "nef_file", "in", "raw_filenames", ":", "\n", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "raw_directory", ",", "nef_file", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "tags", "=", "exifread", ".", "process_file", "(", "f", ",", "details", "=", "False", ",", "stop_tag", "=", "'Image Orientation'", ")", "\n", "orientation", "=", "tags", "[", "'Image Orientation'", "]", ".", "printable", "\n", "log", ".", "info", "(", "'{} -> {}'", ".", "format", "(", "nef_file", ",", "orientation", ")", ")", "\n", "if", "orientation", ".", "startswith", "(", "'Horizontal'", ")", ":", "\n", "                ", "raw_filenames_selected", ".", "append", "(", "nef_file", ")", "\n", "\n", "", "", "if", "len", "(", "raw_filenames_selected", ")", ">=", "n_images", ":", "\n", "            ", "break", "\n", "\n", "", "", "log", ".", "info", "(", "'Collected {} landscape-oriented photos for training'", ".", "format", "(", "len", "(", "raw_filenames_selected", ")", ")", ")", "\n", "\n", "if", "len", "(", "raw_filenames_selected", ")", "<", "n_images", ":", "\n", "        ", "log", ".", "error", "(", "'Not enough horizontal images! Found {} but expected {}.'", ".", "format", "(", "len", "(", "raw_filenames_selected", ")", ",", "n_images", ")", ")", "\n", "\n", "", "dev_settings", "=", "dev_settings", "or", "{", "'use_srgb'", ":", "True", ",", "'use_gamma'", ":", "True", ",", "'brightness'", ":", "None", "}", "\n", "\n", "# Iterate over RAW files and produce:", "\n", "#  1. RGGB Bayer stacks (H/2, W/2, 4)", "\n", "#  2. RGB Optimization target (H, W, 3)", "\n", "for", "nef_file", "in", "tqdm", ".", "tqdm", "(", "raw_filenames_selected", ",", "ncols", "=", "120", ",", "desc", "=", "'Preparing train. data ({})'", ".", "format", "(", "camera", ")", ")", ":", "\n", "\n", "        ", "out_npy", "=", "os", ".", "path", ".", "join", "(", "out_directory", ",", "os", ".", "path", ".", "splitext", "(", "nef_file", ")", "[", "0", "]", "+", "'.npy'", ")", "\n", "out_png", "=", "os", ".", "path", ".", "join", "(", "out_directory", ",", "os", ".", "path", ".", "splitext", "(", "nef_file", ")", "[", "0", "]", "+", "'.png'", ")", "\n", "\n", "try", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "out_npy", ")", ":", "\n", "                ", "image_bayer", "=", "raw", ".", "unpack", "(", "os", ".", "path", ".", "join", "(", "raw_directory", ",", "nef_file", ")", ")", "[", "0", "]", "\n", "image_bayer", "=", "(", "(", "2", "**", "16", "-", "1", ")", "*", "image_bayer", ")", ".", "astype", "(", "np", ".", "uint16", ")", "\n", "np", ".", "save", "(", "out_npy", ",", "image_bayer", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_png", ")", ":", "\n", "                ", "if", "target_pipeline", "==", "'auto'", ":", "\n", "                    ", "rgb", "=", "raw", ".", "process_auto", "(", "os", ".", "path", ".", "join", "(", "raw_directory", ",", "nef_file", ")", ")", "\n", "", "elif", "target_pipeline", "==", "'manual'", ":", "\n", "                    ", "rgb", "=", "255", "*", "raw", ".", "process", "(", "os", ".", "path", ".", "join", "(", "raw_directory", ",", "nef_file", ")", ",", "**", "dev_settings", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "'Unsupported develop mode!'", ")", "\n", "", "imageio", ".", "imwrite", "(", "out_png", ",", "rgb", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "", "", "except", "Exception", "as", "error", ":", "\n", "            ", "log", ".", "error", "(", "'RAW Processing failed for file: {}'", ".", "format", "(", "nef_file", ")", ")", "\n", "log", ".", "error", "(", "error", ")", "\n", "sys", ".", "exit", "(", "2", ")", "\n", "\n", "", "", "sys", ".", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_prepare_training_set.main": [[93, 111], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "train_prepare_training_set.prepare_training_set", "print", "argparse.ArgumentParser.print_usage", "sys.exit"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.None.train_prepare_training_set.prepare_training_set"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Prepare training pairs (raw inputs in *.npy and optimization targets in *.png) for a given camera'", ")", "\n", "parser", ".", "add_argument", "(", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ")", "\n", "parser", ".", "add_argument", "(", "'--target'", ",", "dest", "=", "'target'", ",", "action", "=", "'store'", ",", "default", "=", "'manual'", ",", "\n", "help", "=", "'target for optimization (manual or auto)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'dir'", ",", "action", "=", "'store'", ",", "default", "=", "'./data'", ",", "\n", "help", "=", "'root directory with images and training data'", ")", "\n", "parser", ".", "add_argument", "(", "'--images'", ",", "dest", "=", "'images'", ",", "action", "=", "'store'", ",", "default", "=", "150", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of images to prepare'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "camera", ":", "\n", "        ", "print", "(", "'A camera needs to be specified!'", ")", "\n", "parser", ".", "print_usage", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "prepare_training_set", "(", "args", ".", "camera", ",", "args", ".", "target", ",", "None", ",", "args", ".", "images", ",", "args", ".", "dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_framework.run_test": [[15, 48], ["helpers.utils.shell", "print", "print", "os.path.join", "print", "os.path.join", "config[].format", "print", "sys.exit", "os.path.isfile", "print", "[].format", "os.path.isfile", "print", "sys.exit", "open", "json.load", "[].items", "os.path.join", "print", "filename.format", "filename.format", "helpers.utils.get"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.shell", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get"], ["def", "run_test", "(", "test_name", ",", "config", ",", "args", ")", ":", "\n", "\n", "    ", "if", "not", "args", ".", "verbose", ":", "\n", "        ", "log_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root_dir", ",", "test_name", ")", "\n", "", "else", ":", "\n", "        ", "log_path", "=", "None", "\n", "\n", "", "code", "=", "utils", ".", "shell", "(", "config", "[", "'command'", "]", ".", "format", "(", "cam", "=", "args", ".", "camera", ",", "root", "=", "args", ".", "root_dir", ")", ",", "log_path", ",", "verbosity", "=", "1", ")", "\n", "print", "(", "'\\n  Exit code: {}\\n'", ".", "format", "(", "code", ")", ")", "\n", "\n", "if", "code", "!=", "0", ":", "\n", "        ", "print", "(", "'ERROR non-zero return code for {}'", ".", "format", "(", "'nip-training'", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# Check the output files", "\n", "", "print", "(", "'  Checking expected files:'", ")", "\n", "for", "filename", "in", "config", "[", "'files'", "]", ":", "\n", "        ", "status", "=", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "root_dir", ",", "filename", ".", "format", "(", "args", ".", "camera", ")", ")", ")", "\n", "print", "(", "'    {:84s} [{}]'", ".", "format", "(", "filename", ".", "format", "(", "args", ".", "camera", ")", ",", "OK_STR", "if", "status", "else", "MISS_STR", ")", ")", "\n", "\n", "# Check performance", "\n", "", "training_log", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root_dir", ",", "config", "[", "'performance'", "]", "[", "'file'", "]", ".", "format", "(", "args", ".", "camera", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "training_log", ")", ":", "\n", "        ", "print", "(", "'ERROR file {} does not exist!'", ".", "format", "(", "training_log", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "print", "(", "'\\n  Checking obtained performance:'", ")", "\n", "with", "open", "(", "training_log", ")", "as", "f", ":", "\n", "        ", "perf", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "key", ",", "expected_value", "in", "config", "[", "'performance'", "]", "[", "'values'", "]", ".", "items", "(", ")", ":", "\n", "            ", "obtained_value", "=", "utils", ".", "get", "(", "perf", ",", "key", ",", "sep", "=", "'/'", ")", "[", "-", "1", "]", "\n", "print", "(", "'    {:70s} {:5.2f} > {:5.2f} [{}]'", ".", "format", "(", "key", ",", "obtained_value", ",", "expected_value", ",", "OK_STR", "if", "obtained_value", ">", "expected_value", "else", "FAIL_STR", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_framework.main": [[50, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "helpers.utils.setup_logging", "helpers.tf_helpers.disable_warnings", "helpers.tf_helpers.print_versions", "open", "json.load", "os.path.exists", "print", "shutil.rmtree", "os.path.exists", "os.makedirs", "parser.parse_args.tests.split", "test_framework.run_test"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.setup_logging", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.disable_warnings", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.print_versions", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.None.test_framework.run_test"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a neural imaging pipeline'", ")", "\n", "parser", ".", "add_argument", "(", "'--cam'", ",", "dest", "=", "'camera'", ",", "action", "=", "'store'", ",", "help", "=", "'camera'", ",", "default", "=", "'D90'", ")", "\n", "parser", ".", "add_argument", "(", "'--dir'", ",", "dest", "=", "'root_dir'", ",", "action", "=", "'store'", ",", "default", "=", "'/tmp/neural-imaging'", ",", "\n", "help", "=", "'output directory for temporary results, default: /tmp/neural-imaging'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "dest", "=", "'verbose'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'print the output of tested tools, default: false'", ")", "\n", "parser", ".", "add_argument", "(", "'--keep'", ",", "dest", "=", "'keep'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'do not remove the test root directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--tests'", ",", "dest", "=", "'tests'", ",", "action", "=", "'store'", ",", "default", "=", "None", ",", "\n", "help", "=", "'list of tests to run'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "utils", ".", "setup_logging", "(", ")", "\n", "tf_helpers", ".", "disable_warnings", "(", ")", "\n", "tf_helpers", ".", "print_versions", "(", ")", "\n", "\n", "with", "open", "(", "'config/tests/framework.json'", ")", "as", "f", ":", "\n", "        ", "settings", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "root_dir", ")", "and", "not", "args", ".", "keep", ":", "\n", "        ", "print", "(", "'\\n> deleting {}'", ".", "format", "(", "args", ".", "root_dir", ")", ")", "\n", "shutil", ".", "rmtree", "(", "args", ".", "root_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "root_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "root_dir", ")", "\n", "\n", "", "if", "args", ".", "tests", "is", "None", ":", "\n", "        ", "tests", "=", "[", "'train-nip'", ",", "'resume-nip'", ",", "'train-manipulation'", ",", "'train-dcn'", ",", "'train-manipulation-dcn'", "]", "\n", "", "else", ":", "\n", "        ", "tests", "=", "args", ".", "tests", ".", "split", "(", "','", ")", "\n", "\n", "", "for", "test", "in", "tests", ":", "\n", "        ", "run_test", "(", "test", ",", "settings", "[", "test", "]", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.debugging.pstrace.ApplicationWindow.__init__": [[27, 59], ["psutil.Process", "matplotlib.backends.qt_compat.QtWidgets.QMainWindow.__init__", "matplotlib.backends.qt_compat.QtWidgets.QWidget", "pstrace.ApplicationWindow.setCentralWidget", "matplotlib.backends.qt_compat.QtWidgets.QVBoxLayout", "pstrace.ApplicationWindow.setFixedSize", "pstrace.ApplicationWindow.frameGeometry", "PyQt5.QtWidgets.QDesktopWidget().availableGeometry().center", "pstrace.ApplicationWindow.moveCenter", "pstrace.ApplicationWindow.move", "pstrace.ApplicationWindow.setWindowTitle", "FigureCanvas", "matplotlib.backends.qt_compat.QtWidgets.QVBoxLayout.addWidget", "FigureCanvas.figure.subplots", "FigureCanvas.new_timer", "pstrace.ApplicationWindow._timer.start", "pstrace.ApplicationWindow.topLeft", "matplotlib.figure.Figure", "pstrace.ApplicationWindow.stats.keys", "PyQt5.QtWidgets.QDesktopWidget().availableGeometry", "pstrace.ApplicationWindow.process.name", "PyQt5.QtWidgets.QDesktopWidget"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["    ", "def", "__init__", "(", "self", ",", "pid", ",", "delay", ")", ":", "\n", "\n", "        ", "self", ".", "process", "=", "psutil", ".", "Process", "(", "6704", ")", "\n", "self", ".", "stats", "=", "{", "\n", "'memory'", ":", "[", "]", ",", "\n", "'cpu_percent'", ":", "[", "]", "\n", "}", "\n", "self", ".", "ma", "=", "{", "k", ":", "[", "]", "for", "k", "in", "self", ".", "stats", ".", "keys", "(", ")", "}", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_main", "=", "QtWidgets", ".", "QWidget", "(", ")", "\n", "self", ".", "setCentralWidget", "(", "self", ".", "_main", ")", "\n", "layout", "=", "QtWidgets", ".", "QVBoxLayout", "(", "self", ".", "_main", ")", "\n", "\n", "# Center window", "\n", "self", ".", "setFixedSize", "(", "800", ",", "600", ")", "\n", "qtRectangle", "=", "self", ".", "frameGeometry", "(", ")", "\n", "centerPoint", "=", "QDesktopWidget", "(", ")", ".", "availableGeometry", "(", ")", ".", "center", "(", ")", "\n", "qtRectangle", ".", "moveCenter", "(", "centerPoint", ")", "\n", "self", ".", "move", "(", "qtRectangle", ".", "topLeft", "(", ")", ")", "\n", "\n", "self", ".", "setWindowTitle", "(", "f\"pstrace : pid={pid} ({self.process.name()})\"", ")", "\n", "\n", "dynamic_canvas", "=", "FigureCanvas", "(", "Figure", "(", "figsize", "=", "(", "5", ",", "3", ")", ")", ")", "\n", "layout", ".", "addWidget", "(", "dynamic_canvas", ")", "\n", "# self.addToolBar(QtCore.Qt.BottomToolBarArea, NavigationToolbar(dynamic_canvas, self))", "\n", "\n", "self", ".", "_dynamic_ax", "=", "dynamic_canvas", ".", "figure", ".", "subplots", "(", "2", ",", "sharex", "=", "True", ")", "\n", "self", ".", "_timer", "=", "dynamic_canvas", ".", "new_timer", "(", "\n", "delay", "*", "1000", ",", "[", "(", "self", ".", "_update_canvas", ",", "(", ")", ",", "{", "}", ")", "]", ")", "\n", "self", ".", "_figure", "=", "dynamic_canvas", ".", "figure", "\n", "self", ".", "_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.debugging.pstrace.ApplicationWindow._update_canvas": [[60, 82], ["pstrace.ApplicationWindow.stats[].append", "pstrace.ApplicationWindow.stats[].append", "pstrace.ApplicationWindow.stats.keys", "enumerate", "pstrace.ApplicationWindow._figure.tight_layout", "pstrace.ApplicationWindow.process.cpu_percent", "zip", "ax.clear", "ax.plot", "ax.plot", "max", "ax.plot", "ax.set_ylabel", "ax.figure.canvas.draw", "len", "pstrace.ApplicationWindow.ma[].append", "pstrace.ApplicationWindow.ma[].append", "pstrace.ApplicationWindow.stats.keys", "ax.set_xlabel", "pstrace.ApplicationWindow.process.memory_info", "len", "len"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["", "def", "_update_canvas", "(", "self", ")", ":", "\n", "        ", "self", ".", "stats", "[", "'memory'", "]", ".", "append", "(", "self", ".", "process", ".", "memory_info", "(", ")", "[", "0", "]", "/", "1e9", ")", "\n", "self", ".", "stats", "[", "'cpu_percent'", "]", ".", "append", "(", "self", ".", "process", ".", "cpu_percent", "(", ")", ")", "\n", "\n", "alpha", "=", "0.1", "\n", "for", "k", "in", "self", ".", "stats", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "stats", "[", "k", "]", ")", ">", "1", ":", "\n", "                ", "self", ".", "ma", "[", "k", "]", ".", "append", "(", "alpha", "*", "self", ".", "stats", "[", "k", "]", "[", "-", "1", "]", "+", "(", "1", "-", "alpha", ")", "*", "self", ".", "ma", "[", "k", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "ma", "[", "k", "]", ".", "append", "(", "self", ".", "stats", "[", "k", "]", "[", "-", "1", "]", ")", "\n", "\n", "", "", "for", "i", ",", "(", "ax", ",", "stat", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "_dynamic_ax", ",", "self", ".", "stats", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "ax", ".", "clear", "(", ")", "\n", "ax", ".", "plot", "(", "self", ".", "stats", "[", "stat", "]", ",", "'.-'", ")", "\n", "ax", ".", "plot", "(", "self", ".", "ma", "[", "stat", "]", ",", "'-'", ")", "\n", "max_val", "=", "max", "(", "self", ".", "stats", "[", "stat", "]", ")", "\n", "ax", ".", "plot", "(", "[", "0", ",", "len", "(", "self", ".", "stats", "[", "stat", "]", ")", "]", ",", "[", "max_val", ",", "max_val", "]", ",", "':'", ")", "\n", "if", "i", "==", "len", "(", "self", ".", "stats", ")", "-", "1", ":", "\n", "                ", "ax", ".", "set_xlabel", "(", "'samples'", ")", "\n", "", "ax", ".", "set_ylabel", "(", "stat", ")", "\n", "ax", ".", "figure", ".", "canvas", ".", "draw", "(", ")", "\n", "", "self", ".", "_figure", ".", "tight_layout", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.debugging.pstrace.ApplicationWindow.keyPressEvent": [[83, 86], ["event.key", "pstrace.ApplicationWindow.close"], "methods", ["None"], ["", "def", "keyPressEvent", "(", "self", ",", "event", ")", ":", "\n", "        ", "if", "event", ".", "key", "(", ")", "==", "Qt", ".", "Key_Escape", ":", "\n", "            ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.visualize_distribution": [[19, 79], ["dcn.compress().numpy", "dcn.get_codebook().tolist", "hasattr", "dcn.sess.run().reshape", "histogram.reshape().tolist.reshape().tolist", "numpy.arange", "numpy.convolve", "helpers.stats.entropy", "helpers.stats.entropy", "numpy.unique", "fig.gca.set_xlim", "fig.gca.set_xticks", "fig.gca.stem", "fig.gca.bar", "fig.gca.set_title", "fig.gca.legend", "type", "numpy.min", "data.next_validation_batch", "dcn.compress().numpy.reshape", "numpy.ceil", "numpy.floor", "numpy.ceil", "histogram.reshape().tolist.max", "numpy.histogram", "hist.max", "numpy.round", "matplotlib.figure.Figure", "matplotlib.figure.Figure.gca", "dcn.compress", "dcn.get_codebook", "numpy.max", "dcn.sess.run", "histogram.reshape().tolist.reshape", "numpy.percentile", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook"], ["def", "visualize_distribution", "(", "dcn", ",", "data", ",", "ax", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "\n", "    ", "title", "=", "''", "if", "title", "is", "None", "else", "title", "+", "' '", "\n", "\n", "if", "type", "(", "data", ")", "is", "not", "np", ".", "ndarray", ":", "\n", "        ", "sample_batch_size", "=", "np", ".", "min", "(", "(", "100", ",", "data", ".", "count_validation", ")", ")", "\n", "batch_x", "=", "data", ".", "next_validation_batch", "(", "0", ",", "sample_batch_size", ")", "\n", "", "else", ":", "\n", "        ", "batch_x", "=", "data", "\n", "\n", "# Fetch latent distribution for the current batch", "\n", "", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "batch_z", "=", "batch_z", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", ".", "T", "\n", "\n", "# Get current version of the quantization codebook", "\n", "codebook", "=", "dcn", ".", "get_codebook", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Find x limits for plotting", "\n", "if", "dcn", ".", "_h", ".", "rounding", "==", "'identity'", ":", "\n", "        ", "qmax", "=", "np", ".", "ceil", "(", "np", ".", "max", "(", "np", ".", "abs", "(", "batch_z", ")", ")", ")", "\n", "qmin", "=", "-", "qmax", "\n", "", "else", ":", "\n", "        ", "qmin", "=", "np", ".", "floor", "(", "codebook", "[", "0", "]", ")", "\n", "qmax", "=", "np", ".", "ceil", "(", "codebook", "[", "-", "1", "]", ")", "\n", "\n", "", "feed_dict", "=", "{", "dcn", ".", "x", ":", "batch_x", "}", "\n", "if", "hasattr", "(", "dcn", ",", "'is_training'", ")", ":", "\n", "        ", "feed_dict", "[", "dcn", ".", "is_training", "]", "=", "True", "\n", "\n", "# Get approximation of the soft quantization structures used for entropy estimation", "\n", "", "histogram", "=", "dcn", ".", "sess", ".", "run", "(", "dcn", ".", "histogram", ",", "feed_dict", "=", "feed_dict", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "histogram", "=", "histogram", "/", "histogram", ".", "max", "(", ")", "\n", "histogram", "=", "histogram", ".", "reshape", "(", "(", "-", "1", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# Create a dense version of the quantization bins", "\n", "bin_centers", "=", "np", ".", "arange", "(", "qmin", "-", "1", ",", "qmax", "+", "1", ",", "0.1", ")", "\n", "bin_boundaries", "=", "np", ".", "convolve", "(", "bin_centers", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "bin_centers", "=", "bin_centers", "[", "1", ":", "-", "1", "]", "\n", "\n", "# Compute empirical histogram based on latent representation", "\n", "hist", "=", "np", ".", "histogram", "(", "batch_z", ",", "bins", "=", "bin_boundaries", ",", "density", "=", "True", ")", "[", "0", "]", "\n", "hist", "=", "hist", "/", "hist", ".", "max", "(", ")", "\n", "\n", "entropy", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "codebook", ")", "\n", "\n", "ticks", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "np", ".", "percentile", "(", "batch_z", ",", "[", "1", ",", "5", ",", "25", ",", "50", ",", "75", ",", "95", ",", "99", "]", ")", ")", ")", "\n", "\n", "if", "ax", "is", "None", ":", "\n", "        ", "fig", "=", "Figure", "(", "figsize", "=", "(", "10", ",", "2", ")", ")", "\n", "ax", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "", "ax", ".", "set_xlim", "(", "[", "qmin", "-", "1", ",", "qmax", "+", "1", "]", ")", "\n", "ax", ".", "set_xticks", "(", "ticks", ")", "\n", "ax", ".", "stem", "(", "bin_centers", ",", "hist", ",", "linefmt", "=", "'r:'", ",", "markerfmt", "=", "'r.'", ")", "# width=bin_centers[1] - bin_centers[0]", "\n", "ax", ".", "bar", "(", "codebook", ",", "histogram", ",", "width", "=", "(", "codebook", "[", "1", "]", "-", "codebook", "[", "0", "]", ")", "/", "2", ",", "color", "=", "'b'", ",", "alpha", "=", "0.5", ")", "\n", "ax", ".", "set_title", "(", "'{}QLR histogram (H={:.1f})'", ".", "format", "(", "title", ",", "entropy", ")", ")", "\n", "ax", ".", "legend", "(", "[", "'Quantized values'", ",", "'Soft estimate'", "]", ",", "loc", "=", "'upper right'", ")", "\n", "\n", "# Render the plot as a PNG image and return a bitmap array", "\n", "return", "ax", ".", "figure", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.visualize_codebook": [[81, 102], ["numpy.arange", "dcn.get_codebook().tolist", "matplotlib.figure.Figure", "zip", "matplotlib.figure.Figure.gca().plot", "matplotlib.figure.Figure.gca().plot", "matplotlib.figure.Figure.gca().set_ylim", "matplotlib.figure.Figure.gca().set_xlim", "matplotlib.figure.Figure.gca().set_yticks", "matplotlib.figure.Figure.gca().set_xticks", "matplotlib.figure.Figure.gca().plot", "numpy.zeros_like", "numpy.ones_like", "dcn.get_codebook", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca", "matplotlib.figure.Figure.gca"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook"], ["", "def", "visualize_codebook", "(", "dcn", ")", ":", "\n", "    ", "qmin", "=", "-", "2", "**", "(", "dcn", ".", "latent_bpf", "-", "1", ")", "+", "1", "\n", "qmax", "=", "2", "**", "(", "dcn", ".", "latent_bpf", "-", "1", ")", "\n", "\n", "uniform_cbook", "=", "np", ".", "arange", "(", "qmin", ",", "qmax", "+", "1", ")", "\n", "codebook", "=", "dcn", ".", "get_codebook", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "10", ",", "1", ")", ")", "\n", "\n", "for", "x1", ",", "x2", "in", "zip", "(", "codebook", ",", "uniform_cbook", ")", ":", "\n", "        ", "fig", ".", "gca", "(", ")", ".", "plot", "(", "[", "x1", ",", "x2", "]", ",", "[", "0", ",", "1", "]", ",", "'k:'", ")", "\n", "\n", "", "fig", ".", "gca", "(", ")", ".", "plot", "(", "codebook", ",", "np", ".", "zeros_like", "(", "codebook", ")", ",", "'x'", ")", "\n", "fig", ".", "gca", "(", ")", ".", "plot", "(", "uniform_cbook", ",", "np", ".", "ones_like", "(", "uniform_cbook", ")", ",", "'ro'", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_ylim", "(", "[", "-", "1", ",", "2", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_xlim", "(", "[", "qmin", "-", "1", ",", "qmax", "+", "1", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_yticks", "(", "[", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_xticks", "(", "uniform_cbook", ")", "\n", "\n", "# Render the plot as a PNG image and return a bitmap array", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.save_progress": [[104, 121], ["os.path.join", "data.summary", "open", "json.dump", "repr", "dcn.get_hyperparameters", "dcn.get_codebook().tolist", "dcn.get_codebook"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.get_hyperparameters", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook"], ["", "def", "save_progress", "(", "dcn", ",", "data", ",", "training", ",", "out_dir", ")", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'progress.json'", ")", "\n", "\n", "output_stats", "=", "{", "\n", "'training_spec'", ":", "training", ",", "\n", "'data'", ":", "data", ".", "summary", "(", ")", ",", "\n", "'codec'", ":", "{", "\n", "'model'", ":", "dcn", ".", "class_name", ",", "\n", "'init'", ":", "repr", "(", "dcn", ")", ",", "\n", "'args'", ":", "dcn", ".", "get_hyperparameters", "(", ")", ",", "\n", "'codebook'", ":", "dcn", ".", "get_codebook", "(", ")", ".", "tolist", "(", ")", ",", "\n", "'performance'", ":", "dcn", ".", "performance", ",", "\n", "}", ",", "\n", "}", "\n", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output_stats", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.train_dcn": [[123, 310], ["os.path.join", "print", "os.path.isdir", "print", "os.path.exists", "os.makedirs", "tensorflow.summary.create_file_writer", "tqdm.tqdm", "range", "collections.deque", "collections.deque", "collections.deque", "collections.deque", "collections.deque", "collections.deque", "range", "dcn.get_codebook", "pbar.set_postfix", "pbar.update", "data.next_training_batch", "dcn.training_step", "dcn.training_step.items", "[].append", "dcn.discrete_latent.scaling_factor.numpy", "range", "numpy.concatenate", "imageio.imsave", "compression.save_progress", "dcn.save_model", "numpy.mean", "numpy.mean", "dcn.model_code.split", "numpy.random.choice", "numpy.zeros", "range", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "helpers.image.batch_gamma", "helpers.image.batch_gamma", "[].append", "float", "data.next_validation_batch", "dcn.compress().numpy", "dcn.decompress().numpy", "numpy.linalg.norm", "[].append", "helpers.metrics.batch", "[].append", "helpers.stats.entropy", "helpers.stats.entropy", "[].append", "[].append", "numpy.argsort", "os.path.join", "numpy.concatenate", "dcn.compress", "tf.summary.create_file_writer.flush", "len", "numpy.mean", "numpy.mean", "abs", "numpy.mean", "numpy.random.uniform", "numpy.arange", "len", "skimage.transform.resize", "numpy.mean", "float", "numpy.var", "tf.summary.create_file_writer.as_default", "tensorflow.summary.experimental.set_step", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.image", "tensorflow.summary.histogram", "print", "print", "dcn.compress", "dcn.decompress", "numpy.mean", "helpers.plots.thumbnails", "numpy.expand_dims", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.image", "helpers.plots.thumbnails", "dcn.get_codebook.min", "dcn.get_codebook.max", "dcn.get_codebook.mean", "numpy.var", "numpy.expand_dims", "numpy.convolve", "compression.visualize_codebook"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.save_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.batch_gamma", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.batch_gamma", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.compression.visualize_codebook"], ["", "", "def", "train_dcn", "(", "dcn", ",", "training", ",", "data", ",", "directory", "=", "'./data/models/dcn/playground/'", ",", "overwrite", "=", "False", ",", "tensorboard", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    training {\n\n        'augmentation_probs': {\n            'resize': 0.0,\n            'flip_h': 0.5,\n            'flip_v': 0.5\n        }\n    }\n\n    \"\"\"", "\n", "# Compute the number of available batches", "\n", "n_batches", "=", "data", "[", "'training'", "]", "[", "'y'", "]", ".", "shape", "[", "0", "]", "//", "training", "[", "'batch_size'", "]", "\n", "v_batches", "=", "data", "[", "'validation'", "]", "[", "'y'", "]", ".", "shape", "[", "0", "]", "//", "training", "[", "'batch_size'", "]", "\n", "\n", "# Structures for storing performance stats", "\n", "perf", "=", "dcn", ".", "performance", "\n", "\n", "caches", "=", "{", "\n", "'loss'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", ",", "\n", "'entropy'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", ",", "\n", "'ssim'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", "\n", "}", "\n", "\n", "n_tail", "=", "5", "\n", "learning_rate", "=", "training", "[", "'learning_rate'", "]", "\n", "model_output_dirname", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "dcn", ".", "model_code", ",", "dcn", ".", "scoped_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "model_output_dirname", ")", "and", "not", "overwrite", ":", "\n", "        ", "print", "(", "'WARNING Directory {} exists, skipping... (use overwrite=True)'", ".", "format", "(", "model_output_dirname", ")", ")", "\n", "return", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_dirname", ")", "\n", "\n", "", "print", "(", "'Output directory: {}'", ".", "format", "(", "model_output_dirname", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Create a summary writer and create the necessary directories", "\n", "if", "tensorboard", ":", "\n", "        ", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "model_output_dirname", ")", "\n", "\n", "", "with", "tqdm", ".", "tqdm", "(", "total", "=", "training", "[", "'n_epochs'", "]", ",", "ncols", "=", "160", ",", "desc", "=", "dcn", ".", "model_code", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "as", "pbar", ":", "\n", "\n", "        ", "for", "epoch", "in", "range", "(", "0", ",", "training", "[", "'n_epochs'", "]", ")", ":", "\n", "\n", "            ", "training", "[", "'current_epoch'", "]", "=", "epoch", "\n", "\n", "if", "epoch", ">", "0", "and", "epoch", "%", "training", "[", "'learning_rate_reduction_schedule'", "]", "==", "0", ":", "\n", "                ", "learning_rate", "*=", "training", "[", "'learning_rate_reduction_factor'", "]", "\n", "\n", "# Iterate through batches of the training data", "\n", "", "for", "batch_id", "in", "range", "(", "n_batches", ")", ":", "\n", "\n", "# Pick random patch size - will be resized later for augmentation", "\n", "                ", "current_patch", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "training", "[", "'patch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ")", ",", "\n", "1", ")", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "\n", "'resize'", "]", "else", "training", "[", "'patch_size'", "]", "\n", "\n", "# Sample next batch", "\n", "batch_x", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ",", "current_patch", ")", "\n", "\n", "# If rescaling needed, apply", "\n", "if", "training", "[", "'patch_size'", "]", "!=", "current_patch", ":", "\n", "                    ", "batch_t", "=", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ",", "training", "[", "'patch_size'", "]", ",", "training", "[", "'patch_size'", "]", ",", "3", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "batch_x", ")", ")", ":", "\n", "                        ", "batch_t", "[", "i", "]", "=", "resize", "(", "batch_x", "[", "i", "]", ",", "[", "training", "[", "'patch_size'", "]", ",", "training", "[", "'patch_size'", "]", "]", ",", "\n", "anti_aliasing", "=", "True", ")", "\n", "", "batch_x", "=", "batch_t", "\n", "\n", "# Data augmentation", "\n", "", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "'flip_h'", "]", ":", "batch_x", "=", "batch_x", "[", ":", ",", ":", ",", ":", ":", "-", "1", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "'flip_v'", "]", ":", "batch_x", "=", "batch_x", "[", ":", ",", ":", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "'gamma'", "]", ":", "batch_x", "=", "helpers", ".", "image", ".", "batch_gamma", "(", "batch_x", ")", "\n", "\n", "# Make a training step", "\n", "values", "=", "dcn", ".", "training_step", "(", "batch_x", ",", "learning_rate", ")", "\n", "\n", "for", "key", ",", "value", "in", "values", ".", "items", "(", ")", ":", "\n", "                    ", "caches", "[", "key", "]", "[", "'training'", "]", ".", "append", "(", "value", ")", "\n", "\n", "# Record average values for the whole epoch", "\n", "", "", "for", "key", "in", "[", "'loss'", ",", "'ssim'", ",", "'entropy'", "]", ":", "\n", "                ", "perf", "[", "key", "]", "[", "'training'", "]", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "caches", "[", "key", "]", "[", "'training'", "]", ")", ")", ")", "\n", "\n", "# Get some extra stats", "\n", "", "if", "dcn", ".", "_h", ".", "scale_latent", ":", "\n", "                ", "scaling", "=", "dcn", ".", "discrete_latent", ".", "scaling_factor", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "scaling", "=", "np", ".", "nan", "\n", "\n", "", "codebook", "=", "dcn", ".", "get_codebook", "(", ")", "\n", "\n", "# Iterate through batches of the validation data", "\n", "if", "epoch", "%", "training", "[", "'validation_schedule'", "]", "==", "0", ":", "\n", "\n", "                ", "for", "batch_id", "in", "range", "(", "v_batches", ")", ":", "\n", "                    ", "batch_x", "=", "data", ".", "next_validation_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ")", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "batch_y", "=", "dcn", ".", "decompress", "(", "batch_z", ")", ".", "numpy", "(", ")", "\n", "\n", "# Compute loss", "\n", "loss_value", "=", "np", ".", "linalg", ".", "norm", "(", "batch_x", "-", "batch_y", ")", "\n", "caches", "[", "'loss'", "]", "[", "'validation'", "]", ".", "append", "(", "loss_value", ")", "\n", "\n", "# Compute SSIM", "\n", "ssim_value", "=", "metrics", ".", "batch", "(", "batch_x", ",", "batch_y", ",", "metrics", ".", "ssim", ")", "\n", "caches", "[", "'ssim'", "]", "[", "'validation'", "]", ".", "append", "(", "ssim_value", ")", "\n", "\n", "# Entropy", "\n", "entropy_value", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "codebook", ")", "\n", "caches", "[", "'entropy'", "]", "[", "'validation'", "]", ".", "append", "(", "entropy_value", ")", "\n", "\n", "", "for", "key", "in", "[", "'loss'", ",", "'ssim'", ",", "'entropy'", "]", ":", "\n", "                    ", "perf", "[", "key", "]", "[", "'validation'", "]", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "caches", "[", "key", "]", "[", "'validation'", "]", ")", ")", ")", "\n", "\n", "# Save current snapshot", "\n", "", "indices", "=", "np", ".", "argsort", "(", "np", ".", "var", "(", "batch_x", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "thumbs_pairs_all", "=", "np", ".", "concatenate", "(", "(", "batch_x", "[", "indices", "[", ":", ":", "2", "]", "]", ",", "batch_y", "[", "indices", "[", ":", ":", "2", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "thumbs", "=", "(", "255", "*", "plots", ".", "thumbnails", "(", "thumbs_pairs_all", ",", "ncols", "=", "training", "[", "'batch_size'", "]", "//", "2", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "os", ".", "path", ".", "join", "(", "model_output_dirname", ",", "'thumbnails-{:05d}.png'", ".", "format", "(", "epoch", ")", ")", ",", "thumbs", ")", "\n", "\n", "# Save summaries to TB", "\n", "if", "tensorboard", ":", "\n", "\n", "                    ", "thumbs_pairs_few", "=", "np", ".", "concatenate", "(", "(", "batch_x", "[", "indices", "[", ":", "5", "]", "]", ",", "batch_y", "[", "indices", "[", ":", "5", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "thumbs_few", "=", "(", "255", "*", "plots", ".", "thumbnails", "(", "thumbs_pairs_few", ",", "ncols", "=", "5", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "# Sample latent space", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", "\n", "\n", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "                        ", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "epoch", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss/validation'", ",", "perf", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss/training'", ",", "perf", "[", "'loss'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'ssim/validation'", ",", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'ssim/training'", ",", "perf", "[", "'ssim'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'entropy/training'", ",", "perf", "[", "'entropy'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'scaling'", ",", "scaling", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'images/reconstructed'", ",", "np", ".", "expand_dims", "(", "thumbs_few", ",", "axis", "=", "0", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "'histograms/latent'", ",", "batch_z", ")", "\n", "# tf.summary.image('histograms/latent_approx', np.expand_dims(visualize_distribution(dcn, data), axis=0))", "\n", "\n", "if", "dcn", ".", "_h", ".", "train_codebook", ":", "\n", "                            ", "tf", ".", "summary", ".", "scalar", "(", "'codebook/min'", ",", "codebook", ".", "min", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/max'", ",", "codebook", ".", "max", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/mean'", ",", "codebook", ".", "mean", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/diff_variance'", ",", "np", ".", "var", "(", "np", ".", "convolve", "(", "codebook", ",", "[", "-", "1", ",", "1", "]", ",", "mode", "=", "'valid'", ")", ")", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'codebook/centroids'", ",", "np", ".", "expand_dims", "(", "visualize_codebook", "(", "dcn", ")", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Save stats to a JSON log", "\n", "", "save_progress", "(", "dcn", ",", "data", ",", "training", ",", "model_output_dirname", ")", "\n", "\n", "# Save current checkpoint", "\n", "dcn", ".", "save_model", "(", "model_output_dirname", ",", "epoch", ",", "quiet", "=", "True", ")", "\n", "\n", "# Check for convergence or model deterioration", "\n", "if", "len", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", ")", ">", "5", ":", "\n", "                    ", "current", "=", "np", ".", "mean", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "n_tail", ":", "]", ")", "\n", "previous", "=", "np", ".", "mean", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "(", "n_tail", "+", "1", ")", ":", "-", "1", "]", ")", "\n", "perf_change", "=", "abs", "(", "(", "current", "-", "previous", ")", "/", "previous", ")", "\n", "\n", "if", "perf_change", "<", "training", "[", "'convergence_threshold'", "]", ":", "\n", "                        ", "print", "(", "'Early stopping - the model converged, validation SSIM change {:.4f}'", ".", "format", "(", "perf_change", ")", ")", "\n", "break", "\n", "\n", "", "if", "current", "<", "0.9", "*", "previous", ":", "\n", "                        ", "print", "(", "'Error - SSIM deterioration by more than 10% {:.4f} -> {:.4f}'", ".", "format", "(", "previous", ",", "current", ")", ")", "\n", "break", "\n", "\n", "", "", "", "progress_dict", "=", "{", "\n", "'L'", ":", "np", ".", "mean", "(", "perf", "[", "'loss'", "]", "[", "'training'", "]", "[", "-", "3", ":", "]", ")", ",", "\n", "'Lv'", ":", "np", ".", "mean", "(", "perf", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", ":", "]", ")", ",", "\n", "'lr'", ":", "'{:.1e}'", ".", "format", "(", "learning_rate", ")", ",", "\n", "'ssim'", ":", "'{:.2f}'", ".", "format", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ")", ",", "\n", "'H'", ":", "'{:.1f}'", ".", "format", "(", "np", ".", "mean", "(", "perf", "[", "'entropy'", "]", "[", "'training'", "]", "[", "-", "1", ":", "]", ")", ")", ",", "\n", "}", "\n", "\n", "if", "dcn", ".", "_h", ".", "scale_latent", ":", "\n", "                ", "progress_dict", "[", "'S'", "]", "=", "'{:.1f}'", ".", "format", "(", "scaling", ")", "\n", "\n", "# Update progress bar", "\n", "", "pbar", ".", "set_postfix", "(", "progress_dict", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.validate": [[22, 80], ["numpy.zeros_like", "range", "ValueError", "numpy.minimum", "numpy.ceil", "matplotlib.figure.Figure", "data.next_validation_batch", "model.process().numpy().clip", "developed.squeeze.squeeze", "example_y.squeeze", "float", "float", "ssims.append", "psnrs.append", "losss.append", "matplotlib.figure.Figure.savefig", "helpers.metrics.ssim", "helpers.metrics.psnr", "helpers.metrics.mse", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.set_xticks", "fig.add_subplot.set_yticks", "int", "fig.add_subplot.set_title", "os.path.exists", "os.makedirs", "os.path.join", "model.process().numpy", "helpers.metrics.mae", "fig.add_subplot.imshow", "fig.add_subplot.imshow", "ValueError", "numpy.concatenate", "model.process", "len", "helpers.metrics.ssim"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mse", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mae", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim"], ["def", "validate", "(", "model", ",", "data", ",", "out_directory", ",", "savefig", "=", "False", ",", "epoch", "=", "0", ",", "show_ref", "=", "False", ",", "loss_metric", "=", "'L2'", ")", ":", "\n", "\n", "    ", "ssims", ",", "psnrs", ",", "losss", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "if", "loss_metric", "not", "in", "[", "'L2'", ",", "'L1'", ",", "'SSIM'", ",", "'MS-SSIM'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported loss ({})!'", ".", "format", "(", "loss_metric", ")", ")", "\n", "\n", "", "if", "savefig", ":", "\n", "        ", "images_x", "=", "np", ".", "minimum", "(", "data", ".", "count_validation", ",", "20", "if", "not", "show_ref", "else", "10", ")", "\n", "images_y", "=", "np", ".", "ceil", "(", "data", ".", "count_validation", "/", "images_x", ")", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "40", ",", "1.1", "*", "40", "/", "images_x", "*", "images_y", "*", "(", "1", "if", "not", "show_ref", "else", "0.5", ")", ")", ")", "\n", "\n", "", "developed_out", "=", "np", ".", "zeros_like", "(", "data", "[", "'validation'", "]", "[", "'y'", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "b", "in", "range", "(", "data", ".", "count_validation", ")", ":", "\n", "\n", "# Fetch the next example and develop the RGB image", "\n", "        ", "example_x", ",", "example_y", "=", "data", ".", "next_validation_batch", "(", "b", ",", "1", ")", "\n", "developed", "=", "model", ".", "process", "(", "example_x", ")", ".", "numpy", "(", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "developed_out", "[", "b", ",", ":", ",", ":", ",", ":", "]", "=", "developed", "\n", "developed", "=", "developed", ".", "squeeze", "(", ")", "\n", "reference", "=", "example_y", ".", "squeeze", "(", ")", "\n", "\n", "# Compute loss & quality metrics", "\n", "ssim", "=", "float", "(", "metrics", ".", "ssim", "(", "reference", ",", "developed", ")", ")", "\n", "psnr", "=", "float", "(", "metrics", ".", "psnr", "(", "reference", ",", "developed", ")", ")", "\n", "\n", "if", "loss_metric", "==", "'L2'", ":", "\n", "            ", "loss", "=", "metrics", ".", "mse", "(", "255", "*", "reference", ",", "255", "*", "developed", ")", "\n", "", "elif", "loss_metric", "==", "'L1'", ":", "\n", "            ", "loss", "=", "metrics", ".", "mae", "(", "255", "*", "reference", ",", "255", "*", "developed", ")", "\n", "", "elif", "loss_metric", "==", "'SSIM'", ":", "\n", "            ", "loss", "=", "255", "*", "(", "1", "-", "metrics", ".", "ssim", "(", "reference", ",", "developed", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported loss ({})!'", ".", "format", "(", "loss_metric", ")", ")", "\n", "\n", "", "ssims", ".", "append", "(", "ssim", ")", "\n", "psnrs", ".", "append", "(", "psnr", ")", "\n", "losss", ".", "append", "(", "loss", ")", "\n", "\n", "if", "savefig", ":", "\n", "            ", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "b", "+", "1", ")", "\n", "if", "show_ref", ":", "\n", "                ", "ax", ".", "imshow", "(", "np", ".", "concatenate", "(", "(", "reference", ",", "developed", ")", ",", "axis", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "ax", ".", "imshow", "(", "developed", ")", "\n", "", "ax", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", ".", "set_yticks", "(", "[", "]", ")", "\n", "label_index", "=", "int", "(", "b", "//", "(", "data", ".", "count_validation", "/", "len", "(", "data", ".", "files", "[", "'validation'", "]", ")", ")", ")", "\n", "ax", ".", "set_title", "(", "'{} : {:.1f} dB / {:.2f}'", ".", "format", "(", "data", ".", "files", "[", "'validation'", "]", "[", "label_index", "]", ",", "psnr", ",", "ssim", ")", ",", "fontsize", "=", "6", ")", "\n", "\n", "", "", "if", "savefig", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "out_directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "out_directory", ")", "\n", "", "fig", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_directory", ",", "'validation_{:05d}.jpg'", ".", "format", "(", "epoch", ")", ")", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "150", ")", "\n", "del", "fig", "\n", "\n", "", "return", "ssims", ",", "psnrs", ",", "losss", ",", "developed_out", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.show_progress": [[83, 89], ["plots.perf", "plots.perf.suptitle", "plots.perf.savefig", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.perf"], ["", "def", "show_progress", "(", "isp", ",", "out_directory", ")", ":", "\n", "    ", "from", "helpers", "import", "plots", "\n", "fig", "=", "plots", ".", "perf", "(", "isp", ".", "performance", ",", "[", "'training'", ",", "'validation'", "]", ",", "figwidth", "=", "5", ")", "\n", "fig", ".", "suptitle", "(", "isp", ".", "model_code", ")", "\n", "fig", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_directory", ",", "'progress.png'", ")", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "150", ")", "\n", "del", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.save_progress": [[91, 103], ["os.path.join", "model.get_hyperparameters", "repr", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.get_hyperparameters"], ["", "def", "save_progress", "(", "model", ",", "training_summary", ",", "out_directory", ")", ":", "\n", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "out_directory", ",", "'progress.json'", ")", "\n", "output_stats", "=", "{", "\n", "'performance'", ":", "model", ".", "performance", ",", "\n", "'args'", ":", "model", ".", "get_hyperparameters", "(", ")", ",", "\n", "'model'", ":", "model", ".", "class_name", ",", "\n", "'init'", ":", "repr", "(", "model", ")", ",", "\n", "'summary'", ":", "training_summary", "\n", "}", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output_stats", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.train_nip_model": [[105, 257], ["os.path.join", "collections.OrderedDict", "model.summary", "print", "collections.OrderedDict.items", "print", "print", "pipeline.show_progress", "pipeline.save_progress", "ValueError", "data.next_training_batch", "ValueError", "os.path.exists", "print", "collections.deque", "os.path.join", "print", "model.load_model", "collections.deque", "collections.deque.extend", "isinstance", "print", "tqdm.tqdm", "pbar.update", "range", "model.save_model", "ValueError", "ValueError", "os.path.isfile", "FileNotFoundError", "open", "json.load", "range", "model.log_metric", "pbar.set_postfix", "pbar.update", "min", "data.next_training_batch", "model.training_step", "loss_local.append", "pipeline.validate", "model.log_metric", "model.log_metric", "model.log_metric", "pipeline.save_progress", "model.save_model", "len", "numpy.mean", "numpy.mean", "abs", "model.pop_metric", "model.pop_metric", "model.pop_metric", "max", "len", "print", "len", "min", "min"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.show_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.save_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.validate", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.save_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric"], ["", "", "def", "train_nip_model", "(", "model", ",", "camera_name", ",", "n_epochs", "=", "10000", ",", "lr_schedule", "=", "None", ",", "validation_loss_threshold", "=", "1e-3", ",", "\n", "validation_schedule", "=", "100", ",", "resume", "=", "False", ",", "patch_size", "=", "64", ",", "batch_size", "=", "20", ",", "data", "=", "None", ",", "\n", "out_directory_root", "=", "'./data/models/nip'", ",", "save_best", "=", "False", ",", "discard", "=", "'flat'", ")", ":", "\n", "\n", "    ", "if", "data", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'Training data seems not to be loaded!'", ")", "\n", "\n", "", "try", ":", "\n", "        ", "batch_x", ",", "batch_y", "=", "data", ".", "next_training_batch", "(", "0", ",", "5", ",", "patch_size", "*", "2", ")", "\n", "if", "batch_x", ".", "shape", "!=", "(", "5", ",", "patch_size", ",", "patch_size", ",", "4", ")", "or", "batch_y", ".", "shape", "!=", "(", "5", ",", "2", "*", "patch_size", ",", "2", "*", "patch_size", ",", "3", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'The training batch returned by the dataset instance is of invalid size!'", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "ValueError", "(", "'Data set error: {}'", ".", "format", "(", "e", ")", ")", "\n", "\n", "", "if", "batch_size", ">", "data", ".", "count_training", "or", "batch_size", ">", "data", ".", "count_validation", ":", "\n", "        ", "raise", "ValueError", "(", "f'Batch size ({batch_size}) exceeds dataset size ({data.count_training}/{data.count_validation})!'", ")", "\n", "\n", "# Set up training output", "\n", "", "out_directory", "=", "os", ".", "path", ".", "join", "(", "out_directory_root", ",", "camera_name", ",", "model", ".", "model_code", ",", "model", ".", "scoped_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_directory", ")", "and", "not", "resume", ":", "\n", "        ", "print", "(", "'WARNING directory {} exists, skipping...'", ".", "format", "(", "out_directory", ")", ")", "\n", "return", "out_directory", "\n", "\n", "", "n_batches", "=", "data", ".", "count_training", "//", "batch_size", "\n", "n_tail", "=", "5", "\n", "\n", "if", "not", "resume", ":", "\n", "        ", "losses_buf", "=", "deque", "(", "maxlen", "=", "10", ")", "\n", "start_epoch", "=", "0", "\n", "", "else", ":", "\n", "# Find training summary", "\n", "        ", "summary_file", "=", "os", ".", "path", ".", "join", "(", "out_directory", ",", "'progress.json'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "summary_file", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "'Could not open file {}'", ".", "format", "(", "summary_file", ")", ")", "\n", "\n", "", "print", "(", "'Resuming training from: {}'", ".", "format", "(", "summary_file", ")", ")", "\n", "model", ".", "load_model", "(", "out_directory", ")", "\n", "\n", "with", "open", "(", "summary_file", ")", "as", "f", ":", "\n", "            ", "summary_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# Read performance stats to date", "\n", "", "model", ".", "performance", "=", "summary_data", "[", "'performance'", "]", "\n", "\n", "# Initialize counters", "\n", "start_epoch", "=", "summary_data", "[", "'summary'", "]", "[", "'Epoch'", "]", "\n", "losses_buf", "=", "deque", "(", "maxlen", "=", "10", ")", "\n", "losses_buf", ".", "extend", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "10", ":", "]", ")", "\n", "\n", "", "if", "lr_schedule", "is", "None", ":", "\n", "        ", "lr_schedule", "=", "{", "0", ":", "1e-4", "}", "\n", "", "elif", "isinstance", "(", "lr_schedule", ",", "float", ")", ":", "\n", "        ", "lr_schedule", "=", "{", "0", ":", "lr_schedule", "}", "\n", "\n", "# Collect and print training summary", "\n", "", "training_summary", "=", "OrderedDict", "(", ")", "\n", "training_summary", "[", "'Camera'", "]", "=", "camera_name", "\n", "training_summary", "[", "'Architecture'", "]", "=", "model", ".", "summary", "(", ")", "\n", "training_summary", "[", "'Max epochs'", "]", "=", "n_epochs", "\n", "training_summary", "[", "'Learning rate'", "]", "=", "lr_schedule", "\n", "training_summary", "[", "'Training data size'", "]", "=", "data", "[", "'training'", "]", "[", "'x'", "]", ".", "shape", "\n", "training_summary", "[", "'Validation data size'", "]", "=", "data", "[", "'validation'", "]", "[", "'x'", "]", ".", "shape", "\n", "training_summary", "[", "'# batches'", "]", "=", "n_batches", "\n", "training_summary", "[", "'Patch size'", "]", "=", "patch_size", "\n", "training_summary", "[", "'Batch size'", "]", "=", "batch_size", "\n", "training_summary", "[", "'Validation schedule'", "]", "=", "validation_schedule", "\n", "training_summary", "[", "'Start epoch'", "]", "=", "start_epoch", "\n", "training_summary", "[", "'Saved checkpoint'", "]", "=", "None", "\n", "training_summary", "[", "'Discarding policy'", "]", "=", "discard", "\n", "training_summary", "[", "'Output directory'", "]", "=", "out_directory", "\n", "\n", "print", "(", "'\\n## Training summary'", ")", "\n", "for", "k", ",", "v", "in", "training_summary", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'{:30s}: {}'", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "\n", "", "print", "(", "f'Batches{n_batches}'", ")", "\n", "print", "(", "''", ",", "flush", "=", "True", ")", "\n", "\n", "with", "tqdm", "(", "total", "=", "n_epochs", ",", "ncols", "=", "TQDM_WIDTH", ",", "desc", "=", "'{} for {}'", ".", "format", "(", "model", ".", "model_code", ",", "camera_name", ")", ")", "as", "pbar", ":", "\n", "\n", "        ", "pbar", ".", "update", "(", "start_epoch", ")", "\n", "learning_rate", "=", "1e-4", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "n_epochs", ")", ":", "\n", "\n", "            ", "if", "epoch", "in", "lr_schedule", ":", "\n", "                ", "learning_rate", "=", "lr_schedule", "[", "epoch", "]", "\n", "\n", "", "loss_local", "=", "[", "]", "\n", "\n", "for", "batch_id", "in", "range", "(", "n_batches", ")", ":", "\n", "                ", "batch_x", ",", "batch_y", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "batch_size", ",", "patch_size", ",", "discard", "=", "discard", ")", "\n", "loss", "=", "model", ".", "training_step", "(", "batch_x", ",", "batch_y", ",", "learning_rate", ")", "\n", "loss_local", ".", "append", "(", "loss", ")", "\n", "\n", "# model.log_metric('loss', 'training', loss_counter.result().numpy())", "\n", "", "model", ".", "log_metric", "(", "'loss'", ",", "'training'", ",", "loss_local", ")", "\n", "# losses_buf.append(loss_counter / n_batches)", "\n", "\n", "if", "epoch", "%", "validation_schedule", "==", "0", ":", "\n", "# Use the current model to develop images in the validation set", "\n", "                ", "ssims", ",", "psnrs", ",", "v_losses", ",", "developed", "=", "validate", "(", "model", ",", "data", ",", "out_directory", ",", "True", ",", "epoch", ",", "True", ",", "loss_metric", "=", "model", ".", "loss_metric", ")", "\n", "model", ".", "log_metric", "(", "'ssim'", ",", "'validation'", ",", "ssims", ")", "\n", "model", ".", "log_metric", "(", "'psnr'", ",", "'validation'", ",", "psnrs", ")", "\n", "model", ".", "log_metric", "(", "'loss'", ",", "'validation'", ",", "v_losses", ")", "\n", "\n", "# Generate progress summary", "\n", "training_summary", "[", "'Epoch'", "]", "=", "epoch", "\n", "# show_progress(model, out_directory)", "\n", "save_progress", "(", "model", ",", "training_summary", ",", "out_directory", ")", "\n", "\n", "if", "not", "save_best", "or", "(", "len", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ">", "2", "and", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "<=", "min", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ")", ":", "\n", "                    ", "training_summary", "[", "'Saved checkpoint'", "]", "=", "epoch", "\n", "model", ".", "save_model", "(", "out_directory", ",", "epoch", ",", "quiet", "=", "True", ")", "\n", "\n", "# If model deteriorated by more than 20%, drop the learning rate", "\n", "", "if", "len", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ">", "5", ":", "\n", "                    ", "if", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ">", "1.2", "*", "min", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ":", "\n", "                        ", "learning_rate", "=", "learning_rate", "*", "0.95", "\n", "learning_rate", "=", "max", "(", "(", "learning_rate", ",", "1e-7", ")", ")", "\n", "\n", "# Check for convergence", "\n", "", "", "if", "validation_loss_threshold", "is", "not", "None", "and", "len", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ">", "10", ":", "\n", "                    ", "current", "=", "np", ".", "mean", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "n_tail", ":", "-", "1", "]", ")", "\n", "previous", "=", "np", ".", "mean", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "(", "n_tail", "+", "1", ")", ":", "-", "2", "]", ")", "\n", "vloss_change", "=", "abs", "(", "(", "current", "-", "previous", ")", "/", "previous", ")", "\n", "\n", "if", "vloss_change", "<", "validation_loss_threshold", ":", "\n", "                        ", "print", "(", "'Early stopping - the model converged, validation loss change {}'", ".", "format", "(", "vloss_change", ")", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                    ", "vloss_change", "=", "np", ".", "nan", "\n", "\n", "", "progress_dict", "=", "{", "\n", "'psnr'", ":", "model", ".", "pop_metric", "(", "'psnr'", ",", "'validation'", ")", ",", "\n", "'ssim'", ":", "model", ".", "pop_metric", "(", "'ssim'", ",", "'validation'", ")", "\n", "}", "\n", "\n", "", "pbar", ".", "set_postfix", "(", "loss", "=", "model", ".", "pop_metric", "(", "'loss'", ",", "'training'", ")", ",", "**", "progress_dict", ")", "# , **progress_dict", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "training_summary", "[", "'Epoch'", "]", "=", "epoch", "\n", "if", "not", "save_best", "or", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "<=", "min", "(", "model", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ")", ")", ":", "\n", "        ", "training_summary", "[", "'Saved checkpoint'", "]", "=", "epoch", "\n", "model", ".", "save_model", "(", "out_directory", ",", "epoch", ")", "\n", "", "show_progress", "(", "model", ",", "out_directory", ")", "\n", "save_progress", "(", "model", ",", "training_summary", ",", "out_directory", ")", "\n", "\n", "return", "out_directory", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.pipeline.train_nip_bare": [[259, 303], ["os.path.join", "isinstance", "tqdm.tqdm", "pbar.update", "range", "hasattr", "pbar.update", "range", "data.next_training_batch", "model.training_step", "model.training_step"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step"], ["", "def", "train_nip_bare", "(", "model", ",", "camera_name", ",", "n_epochs", "=", "10000", ",", "lr_schedule", "=", "None", ",", "validation_loss_threshold", "=", "1e-3", ",", "\n", "validation_schedule", "=", "100", ",", "resume", "=", "False", ",", "patch_size", "=", "64", ",", "batch_size", "=", "20", ",", "data", "=", "None", ",", "\n", "out_directory_root", "=", "'./data/models/nip'", ",", "save_best", "=", "False", ",", "discard", "=", "'flat'", ")", ":", "\n", "\n", "# Set up training output", "\n", "    ", "out_directory", "=", "os", ".", "path", ".", "join", "(", "out_directory_root", ",", "camera_name", ",", "model", ".", "model_code", ",", "model", ".", "scoped_name", ")", "\n", "\n", "# n_batches = data.count_training // batch_size", "\n", "n_tail", "=", "5", "\n", "\n", "# losses_buf = deque(maxlen=10)", "\n", "# loss_local = deque(maxlen=n_batches)", "\n", "start_epoch", "=", "0", "\n", "\n", "if", "lr_schedule", "is", "None", ":", "\n", "        ", "lr_schedule", "=", "{", "0", ":", "1e-3", ",", "1000", ":", "1e-4", ",", "2000", ":", "1e-5", "}", "\n", "", "elif", "isinstance", "(", "lr_schedule", ",", "float", ")", ":", "\n", "        ", "lr_schedule", "=", "{", "0", ":", "lr_schedule", "}", "\n", "\n", "", "learning_rate", "=", "1e-3", "\n", "\n", "with", "tqdm", "(", "total", "=", "n_epochs", ",", "ncols", "=", "TQDM_WIDTH", ",", "desc", "=", "'{} for {}'", ".", "format", "(", "model", ".", "model_code", ",", "camera_name", ")", ")", "as", "pbar", ":", "\n", "        ", "pbar", ".", "update", "(", "start_epoch", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "n_epochs", ")", ":", "\n", "\n", "            ", "if", "hasattr", "(", "data", ",", "'next_training_batch'", ")", ":", "\n", "\n", "                ", "for", "batch_id", "in", "range", "(", "data", ".", "count_training", "//", "batch_size", ")", ":", "\n", "                    ", "batch_x", ",", "batch_y", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "batch_size", ",", "patch_size", ",", "discard", "=", "discard", ")", "\n", "loss", "=", "model", ".", "training_step", "(", "batch_x", ",", "batch_y", ",", "learning_rate", ")", "\n", "# loss_local.append(loss)", "\n", "\n", "", "", "else", ":", "\n", "\n", "                ", "for", "batch_x", ",", "batch_y", "in", "data", ":", "\n", "                    ", "model", ".", "training_step", "(", "batch_x", ",", "batch_y", ",", "learning_rate", ")", "\n", "\n", "# model.performance['loss']['training'].append(float(np.mean(loss_local)))", "\n", "# losses_buf.append(model.performance['loss']['training'][-1])", "\n", "\n", "", "", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "return", "out_directory", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_jpeg": [[19, 42], ["numpy.minimum", "range", "isinstance", "ValueError", "data.next_validation_batch", "isinstance", "jpeg.process", "batch_y.numpy.numpy", "results[].append", "results[].append", "results[].append", "float", "helpers.metrics.batch", "helpers.metrics.batch", "numpy.mean", "results.items"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.batch"], ["def", "validate_jpeg", "(", "jpeg", ",", "data", ",", "batch_size", "=", "1", ")", ":", "\n", "\n", "    ", "if", "not", "isinstance", "(", "jpeg", ",", "JPEG", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Codec needs to be as instance of {} but is {}'", ".", "format", "(", "JPEG", ",", "jpeg", ".", "class_name", ")", ")", "\n", "\n", "", "batch_size", "=", "np", ".", "minimum", "(", "batch_size", ",", "data", ".", "count_validation", ")", "\n", "n_batches", "=", "data", ".", "count_validation", "//", "batch_size", "\n", "\n", "results", "=", "{", "k", ":", "[", "]", "for", "k", "in", "(", "'psnr'", ",", "'ssim'", ",", "'entropy'", ")", "}", "\n", "\n", "for", "batch_id", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "batch_x", "=", "data", ".", "next_validation_batch", "(", "batch_id", ",", "batch_size", ")", "\n", "if", "isinstance", "(", "batch_x", ",", "tuple", ")", ":", "\n", "            ", "batch_x", "=", "batch_x", "[", "-", "1", "]", "\n", "\n", "", "batch_y", ",", "entropy", "=", "jpeg", ".", "process", "(", "batch_x", ",", "return_entropy", "=", "True", ")", "\n", "batch_y", "=", "batch_y", ".", "numpy", "(", ")", "\n", "\n", "results", "[", "'ssim'", "]", ".", "append", "(", "metrics", ".", "batch", "(", "batch_x", ",", "batch_y", ",", "metrics", ".", "ssim", ")", ")", "\n", "results", "[", "'psnr'", "]", ".", "append", "(", "metrics", ".", "batch", "(", "batch_x", ",", "batch_y", ",", "metrics", ".", "psnr", ")", ")", "\n", "results", "[", "'entropy'", "]", ".", "append", "(", "entropy", ")", "\n", "\n", "", "return", "{", "k", ":", "float", "(", "np", ".", "mean", "(", "v", ")", ")", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_dcn": [[44, 94], ["data.next_validation_batch", "isinstance", "dcn.process", "float", "helpers.metrics.ssim().tolist", "helpers.metrics.psnr().tolist", "float", "isinstance", "float.numpy", "dcn.loss().numpy", "numpy.minimum", "numpy.ceil", "matplotlib.figure.Figure", "range", "matplotlib.figure.Figure.savefig", "float", "float", "helpers.metrics.ssim", "helpers.metrics.psnr", "matplotlib.figure.Figure.add_subplot", "helpers.plots.image", "os.path.exists", "os.makedirs", "numpy.mean", "numpy.mean", "batch_y.numpy", "batch_y.numpy", "dcn.loss", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image"], ["", "def", "validate_dcn", "(", "dcn", ",", "data", ",", "save_dir", "=", "False", ",", "epoch", "=", "0", ",", "show_ref", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Computes validation metrics for a compression model (DCN). (If not a DCN, the function returns immediately).\n    If requested, plot compressed images to a JPEG image.\n\n    :param dcn: the DCN model\n    :param data: the dataset (instance of Dataset)\n    :param data: the dataset (instance of Dataset)\n    :param save_dir: path to the directory where figures should be generated\n    :param epoch: epoch counter to be appended to the output filename\n    :param show_ref: whether to show only the compressed image or also the input image as reference\n    :return: tuple of lists with per-image measurements of (ssims, psnrs, losses, entropies)\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "dcn", ",", "DCN", ")", ":", "\n", "        ", "return", "\n", "\n", "# Compute latent representations and compressed output", "\n", "", "batch_x", "=", "data", ".", "next_validation_batch", "(", "0", ",", "data", ".", "count_validation", ")", "\n", "if", "isinstance", "(", "batch_x", ",", "tuple", ")", ":", "\n", "        ", "batch_x", "=", "batch_x", "[", "-", "1", "]", "\n", "", "batch_y", ",", "entropy", "=", "dcn", ".", "process", "(", "batch_x", ",", "return_entropy", "=", "True", ")", "\n", "entropy", "=", "float", "(", "entropy", ".", "numpy", "(", ")", ")", "\n", "\n", "ssim", "=", "metrics", ".", "ssim", "(", "batch_x", ",", "batch_y", ".", "numpy", "(", ")", ")", ".", "tolist", "(", ")", "\n", "psnr", "=", "metrics", ".", "psnr", "(", "batch_x", ",", "batch_y", ".", "numpy", "(", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "loss", "=", "float", "(", "dcn", ".", "loss", "(", "batch_x", ",", "batch_y", ",", "entropy", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# If requested, plot a figure with input/output pairs", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "images_x", "=", "np", ".", "minimum", "(", "data", ".", "count_validation", ",", "10", "if", "not", "show_ref", "else", "5", ")", "\n", "images_y", "=", "np", ".", "ceil", "(", "data", ".", "count_validation", "/", "images_x", ")", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "20", ",", "20", "/", "images_x", "*", "images_y", "*", "(", "1", "if", "not", "show_ref", "else", "0.5", ")", ")", ")", "\n", "\n", "for", "b", "in", "range", "(", "data", ".", "count_validation", ")", ":", "\n", "            ", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "b", "+", "1", ")", "\n", "plots", ".", "image", "(", "\n", "np", ".", "concatenate", "(", "(", "batch_x", "[", "b", "]", ",", "batch_y", "[", "b", "]", ")", ",", "axis", "=", "1", ")", "if", "show_ref", "else", "batch_y", "[", "b", "]", ",", "\n", "'{:.1f} / {:.2f}'", ".", "format", "(", "psnr", "[", "b", "]", ",", "ssim", "[", "b", "]", ")", ",", "\n", "axes", "=", "ax", "\n", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "\n", "", "fig", ".", "savefig", "(", "'{}/dcn_validation_{:05d}.jpg'", ".", "format", "(", "save_dir", ",", "epoch", ")", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "100", ",", "quality", "=", "90", ")", "\n", "del", "fig", "\n", "\n", "", "return", "{", "'ssim'", ":", "float", "(", "np", ".", "mean", "(", "ssim", ")", ")", ",", "'psnr'", ":", "float", "(", "np", ".", "mean", "(", "psnr", ")", ")", ",", "'loss'", ":", "loss", ",", "'entropy'", ":", "entropy", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_nip": [[96, 161], ["numpy.zeros_like", "range", "numpy.minimum", "numpy.ceil", "matplotlib.figure.Figure", "data.next_validation_batch", "model.process().numpy().clip", "developed[].squeeze", "example_y.squeeze", "helpers.metrics.ssim().mean", "helpers.metrics.psnr().mean", "ssims.append", "psnrs.append", "losss.append", "matplotlib.figure.Figure.savefig", "numpy.mean", "matplotlib.figure.Figure.add_subplot", "helpers.plots.image", "os.path.exists", "os.makedirs", "model.process().numpy", "helpers.metrics.ssim", "helpers.metrics.psnr", "numpy.power", "numpy.mean", "ValueError", "numpy.abs", "numpy.concatenate", "model.process"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "validate_nip", "(", "model", ",", "data", ",", "save_dir", "=", "False", ",", "epoch", "=", "0", ",", "show_ref", "=", "False", ",", "loss_type", "=", "'L2'", ")", ":", "\n", "    ", "\"\"\"\n    Develops image patches using the given NIP and returns standard image quality measures.\n    If requested, resulting patches are visualized as thumbnails and saved to a directory.\n\n    :param model: the NIP model\n    :param data: the dataset (instance of Dataset)\n    :param data: the dataset (instance of Dataset)\n    :param save_dir: path to the directory where figures should be generated\n    :param epoch: epoch counter to be appended to the output filename\n    :param show_ref: whether to show only the developed image or also the GT target\n    :param loss_type: L1 or L2\n    :return: tuple of lists with per-image measurements of (ssims, psnrs, losss)\n    \"\"\"", "\n", "\n", "ssims", "=", "[", "]", "\n", "psnrs", "=", "[", "]", "\n", "losss", "=", "[", "]", "\n", "\n", "# If requested, plot a figure with output/target pairs", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "images_x", "=", "np", ".", "minimum", "(", "data", ".", "count_validation", ",", "10", "if", "not", "show_ref", "else", "5", ")", "\n", "images_y", "=", "np", ".", "ceil", "(", "data", ".", "count_validation", "/", "images_x", ")", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "20", ",", "20", "/", "images_x", "*", "images_y", "*", "(", "1", "if", "not", "show_ref", "else", "0.5", ")", ")", ")", "\n", "\n", "", "developed_out", "=", "np", ".", "zeros_like", "(", "data", "[", "'validation'", "]", "[", "'y'", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "b", "in", "range", "(", "data", ".", "count_validation", ")", ":", "\n", "        ", "example_x", ",", "example_y", "=", "data", ".", "next_validation_batch", "(", "b", ",", "1", ")", "\n", "developed", "=", "model", ".", "process", "(", "example_x", ")", ".", "numpy", "(", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "developed_out", "[", "b", ",", ":", ",", ":", ",", ":", "]", "=", "developed", "\n", "developed", "=", "developed", "[", ":", ",", ":", ",", ":", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "reference", "=", "example_y", ".", "squeeze", "(", ")", "\n", "\n", "# Compute stats", "\n", "ssim", "=", "metrics", ".", "ssim", "(", "reference", ",", "developed", ")", ".", "mean", "(", ")", "\n", "psnr", "=", "metrics", ".", "psnr", "(", "reference", ",", "developed", ")", ".", "mean", "(", ")", "\n", "\n", "if", "loss_type", "==", "'L2'", ":", "\n", "            ", "loss", "=", "np", ".", "mean", "(", "np", ".", "power", "(", "reference", "-", "developed", ",", "2.0", ")", ")", "\n", "", "elif", "loss_type", "==", "'L1'", ":", "\n", "            ", "loss", "=", "np", ".", "mean", "(", "np", ".", "abs", "(", "reference", "-", "developed", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid loss! Use either L1 or L2.'", ")", "\n", "\n", "", "ssims", ".", "append", "(", "ssim", ")", "\n", "psnrs", ".", "append", "(", "psnr", ")", "\n", "losss", ".", "append", "(", "loss", ")", "\n", "\n", "# Add images to the plot", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "            ", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "b", "+", "1", ")", "\n", "plots", ".", "image", "(", "\n", "np", ".", "concatenate", "(", "(", "reference", ",", "developed", ")", ",", "axis", "=", "1", ")", "if", "show_ref", "else", "developed", ",", "\n", "'{:.1f} dB / {:.2f}'", ".", "format", "(", "psnr", ",", "ssim", ")", ",", "\n", "axes", "=", "ax", "\n", ")", "\n", "\n", "", "", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "", "fig", ".", "savefig", "(", "'{}/nip_validation_{:05d}.jpg'", ".", "format", "(", "save_dir", ",", "epoch", ")", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "100", ",", "quality", "=", "90", ")", "\n", "del", "fig", "\n", "\n", "", "return", "ssims", ",", "psnrs", ",", "losss", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_fan": [[163, 203], ["numpy.minimum", "numpy.zeros", "range", "data.next_validation_batch", "isinstance", "flow._batch_labels", "flow.run_workflow_to_decisions", "range", "accuracies.append", "len", "range", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification._batch_labels", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_workflow_to_decisions"], ["", "def", "validate_fan", "(", "flow", ",", "data", ",", "get_labels", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Generates a confusion matrix for the FAN model from a manipulation classification workflow.\n\n    :param flow: manipulation classification workflow\n    :param data: the dataset (instance of Dataset)\n    :param data: the dataset (instance of Dataset)\n    :param get_labels: whether to return the predicted labels\n    :return: either the accuracy or tuple (accuracy, predicted labels)\n    \"\"\"", "\n", "\n", "batch_size", "=", "np", ".", "minimum", "(", "10", ",", "data", ".", "count_validation", ")", "\n", "n_batches", "=", "data", ".", "count_validation", "//", "batch_size", "\n", "n_classes", "=", "flow", ".", "n_classes", "\n", "conf", "=", "np", ".", "zeros", "(", "(", "n_classes", ",", "n_classes", ")", ")", "\n", "out_labels", "=", "[", "]", "\n", "accuracies", "=", "[", "]", "\n", "\n", "for", "batch", "in", "range", "(", "n_batches", ")", ":", "\n", "\n", "        ", "batch_x", "=", "data", ".", "next_validation_batch", "(", "batch", ",", "batch_size", ")", "\n", "if", "isinstance", "(", "batch_x", ",", "tuple", ")", ":", "\n", "            ", "batch_x", "=", "batch_x", "[", "0", "]", "\n", "\n", "", "batch_y", "=", "flow", ".", "_batch_labels", "(", "len", "(", "batch_x", ")", ")", "\n", "predicted_labels", "=", "flow", ".", "run_workflow_to_decisions", "(", "batch_x", ")", "\n", "\n", "if", "get_labels", ":", "\n", "            ", "out_labels", "+=", "[", "x", "for", "x", "in", "predicted_labels", "]", "\n", "\n", "", "for", "c", "in", "range", "(", "n_classes", ")", ":", "\n", "            ", "for", "c_", "in", "range", "(", "n_classes", ")", ":", "\n", "                ", "conf", "[", "c", ",", "c_", "]", "+=", "np", ".", "sum", "(", "(", "batch_y", "==", "c", ")", "*", "(", "predicted_labels", "==", "c_", ")", ")", "\n", "\n", "", "", "accuracies", ".", "append", "(", "np", ".", "mean", "(", "predicted_labels", "==", "batch_y", ")", ")", "\n", "\n", "", "if", "out_labels", ":", "\n", "        ", "return", "np", ".", "mean", "(", "accuracies", ")", ",", "conf", "/", "(", "n_batches", "*", "batch_size", ")", ",", "out_labels", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "mean", "(", "accuracies", ")", ",", "conf", "/", "(", "n_batches", "*", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.visualize_manipulation_training": [[205, 299], ["matplotlib.figure.Figure", "numpy.array", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "fig.add_subplot.set_ylim", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "fig.add_subplot.set_ylim", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_ylim", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.set_xticks", "fig.add_subplot.set_xticklabels", "fig.add_subplot.set_yticks", "fig.add_subplot.set_yticklabels", "range", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "isinstance", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "range", "range", "fig.add_subplot.text", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_ylim", "matplotlib.figure.Figure.add_subplot", "fig.add_subplot.plot", "fig.add_subplot.plot", "fig.add_subplot.set_ylabel", "matplotlib.figure.Figure.savefig", "numpy.mean", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "helpers.stats.ma_conv", "os.path.exists", "os.makedirs", "numpy.diag"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv"], ["", "", "def", "visualize_manipulation_training", "(", "flow", ",", "epoch", ",", "save_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Visualize progress of manipulation training.\n\n    :param nip: the neural imaging pipeline\n    :param fan: the forensic analysis network\n    :param dcn: the compression model (e.g., deep compression network)\n    :param conf: confusion matrix (see 'confusion()')\n    :param epoch: epoch counter to be appended to the output filename\n    :param save_dir: path to the directory where figures should be generated (figure handle returned otherwise)\n    :param classes: labels for the classes to be used for plotting the confusion matrix\n    :return: None (if output to file requested) or figure handle\n    \"\"\"", "\n", "\n", "# Basic figure setup", "\n", "images_x", "=", "3", "\n", "images_y", "=", "3", "if", "isinstance", "(", "flow", ".", "codec", ",", "DCN", ")", "else", "2", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "18", ",", "10", "/", "images_x", "*", "images_y", ")", ")", "\n", "conf", "=", "np", ".", "array", "(", "flow", ".", "fan", ".", "performance", "[", "'confusion'", "]", ")", "\n", "\n", "# Draw the plots", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "1", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "nip", ".", "performance", "[", "'loss'", "]", "[", "'training'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "nip", ".", "performance", "[", "'loss'", "]", "[", "'training'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'{} NIP loss'", ".", "format", "(", "flow", ".", "nip", ".", "class_name", ")", ")", "\n", "ax", ".", "set_title", "(", "'Loss'", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "2", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "nip", ".", "performance", "[", "'psnr'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "nip", ".", "performance", "[", "'psnr'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'{} NIP psnr'", ".", "format", "(", "flow", ".", "nip", ".", "class_name", ")", ")", "\n", "ax", ".", "set_title", "(", "'PSNR'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "30", ",", "50", "]", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "3", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "nip", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "nip", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'{} NIP ssim'", ".", "format", "(", "flow", ".", "nip", ".", "class_name", ")", ")", "\n", "ax", ".", "set_title", "(", "'SSIM'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "0.8", ",", "1", "]", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "4", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "fan", ".", "performance", "[", "'loss'", "]", "[", "'training'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "fan", ".", "performance", "[", "'loss'", "]", "[", "'training'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'FAN loss'", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "5", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "fan", ".", "performance", "[", "'accuracy'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "fan", ".", "performance", "[", "'accuracy'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'FAN accuracy'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "# The confusion matrix", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "6", ")", "\n", "ax", ".", "imshow", "(", "conf", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "\n", "ax", ".", "set_xticks", "(", "range", "(", "flow", ".", "n_classes", ")", ")", "\n", "ax", ".", "set_xticklabels", "(", "flow", ".", "_forensics_classes", ",", "rotation", "=", "'vertical'", ")", "\n", "ax", ".", "set_yticks", "(", "range", "(", "flow", ".", "n_classes", ")", ")", "\n", "ax", ".", "set_yticklabels", "(", "flow", ".", "_forensics_classes", ")", "\n", "\n", "for", "r", "in", "range", "(", "flow", ".", "n_classes", ")", ":", "\n", "        ", "ax", ".", "text", "(", "r", ",", "r", ",", "'{:.2f}'", ".", "format", "(", "conf", "[", "r", ",", "r", "]", ")", ",", "horizontalalignment", "=", "'center'", ",", "color", "=", "'b'", "if", "conf", "[", "r", ",", "r", "]", ">", "0.5", "else", "'w'", ")", "\n", "\n", "", "ax", ".", "set_xlabel", "(", "'PREDICTED class'", ")", "\n", "ax", ".", "set_ylabel", "(", "'TRUE class'", ")", "\n", "ax", ".", "set_title", "(", "'Accuracy: {:.2f}'", ".", "format", "(", "np", ".", "mean", "(", "np", ".", "diag", "(", "conf", ")", ")", ")", ")", "\n", "\n", "# If the compression model is a trainable DCN, include it's validation metrics", "\n", "if", "images_y", "==", "3", ":", "\n", "        ", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "7", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "codec", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "codec", ".", "performance", "[", "'loss'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'DCN loss'", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "8", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "codec", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "codec", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'DCN ssim'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "0.8", ",", "1", "]", ")", "\n", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "images_y", ",", "images_x", ",", "9", ")", "\n", "ax", ".", "plot", "(", "flow", ".", "codec", ".", "performance", "[", "'entropy'", "]", "[", "'validation'", "]", ",", "'.'", ",", "alpha", "=", "0.25", ")", "\n", "ax", ".", "plot", "(", "helpers", ".", "stats", ".", "ma_conv", "(", "flow", ".", "codec", ".", "performance", "[", "'entropy'", "]", "[", "'validation'", "]", ",", "0", ")", ")", "\n", "ax", ".", "set_ylabel", "(", "'DCN entropy'", ")", "\n", "\n", "", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "", "fig", ".", "savefig", "(", "'{}/manip_validation_{:05d}.jpg'", ".", "format", "(", "save_dir", ",", "epoch", ")", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "100", ")", "\n", "del", "fig", "\n", "\n", "", "else", ":", "\n", "        ", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.save_training_progress": [[301, 353], ["collections.OrderedDict", "collections.OrderedDict", "repr", "collections.OrderedDict", "repr", "flow.fan._h.to_json", "os.path.join", "hasattr", "flow.nip._h.to_json", "collections.OrderedDict", "repr", "hasattr", "flow.codec._h.to_json", "hasattr", "os.path.exists", "os.makedirs", "loguru.logger.info", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json"], ["", "", "def", "save_training_progress", "(", "training_summary", ",", "flow", ",", "root_dir", ",", "quiet", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Saves training progress to a JSON file.\n\n    :param training_summary: dictionary with additional information (e.g., basic training setup)\n    :param nip: the neural imaging pipeline\n    :param fan: the forensic analysis network\n    :param dcn: the compression model (e.g., a deep compression network)\n    :param conf: the confusion matrix of the FAN\n    :param root_dir: output directory\n    \"\"\"", "\n", "\n", "# Populate output structures", "\n", "training", "=", "OrderedDict", "(", ")", "\n", "training", "[", "'summary'", "]", "=", "training_summary", "\n", "training", "[", "'distribution'", "]", "=", "flow", ".", "_distribution", "\n", "training", "[", "'manipulations'", "]", "=", "flow", ".", "_forensics_classes", "\n", "\n", "# The neural imaging pipeline (NIP", "\n", "training", "[", "'nip'", "]", "=", "OrderedDict", "(", ")", "\n", "training", "[", "'nip'", "]", "[", "'model'", "]", "=", "flow", ".", "nip", ".", "class_name", "\n", "training", "[", "'nip'", "]", "[", "'init'", "]", "=", "repr", "(", "flow", ".", "nip", ")", "\n", "training", "[", "'nip'", "]", "[", "'args'", "]", "=", "flow", ".", "nip", ".", "_h", ".", "to_json", "(", ")", "if", "hasattr", "(", "flow", ".", "nip", ",", "'_h'", ")", "else", "{", "}", "\n", "training", "[", "'nip'", "]", "[", "'performance'", "]", "=", "flow", ".", "nip", ".", "performance", "\n", "\n", "# The forensic analysis network (FAN)", "\n", "training", "[", "'forensics'", "]", "=", "OrderedDict", "(", ")", "\n", "training", "[", "'forensics'", "]", "[", "'model'", "]", "=", "flow", ".", "fan", ".", "class_name", "\n", "training", "[", "'forensics'", "]", "[", "'init'", "]", "=", "repr", "(", "flow", ".", "fan", ")", "\n", "training", "[", "'forensics'", "]", "[", "'args'", "]", "=", "flow", ".", "fan", ".", "_h", ".", "to_json", "(", ")", "\n", "training", "[", "'forensics'", "]", "[", "'performance'", "]", "=", "flow", ".", "fan", ".", "performance", "\n", "\n", "# The deep compression network (DCN)", "\n", "if", "flow", ".", "codec", "is", "not", "None", ":", "\n", "        ", "training", "[", "'codec'", "]", "=", "OrderedDict", "(", ")", "\n", "training", "[", "'codec'", "]", "[", "'model'", "]", "=", "flow", ".", "codec", ".", "class_name", "\n", "training", "[", "'codec'", "]", "[", "'init'", "]", "=", "repr", "(", "flow", ".", "codec", ")", "\n", "", "if", "flow", ".", "codec", "is", "not", "None", "and", "hasattr", "(", "flow", ".", "codec", ",", "'_h'", ")", ":", "\n", "        ", "training", "[", "'codec'", "]", "[", "'args'", "]", "=", "flow", ".", "codec", ".", "_h", ".", "to_json", "(", ")", "\n", "", "if", "flow", ".", "codec", "is", "not", "None", "and", "hasattr", "(", "flow", ".", "codec", ",", "'performance'", ")", ":", "\n", "        ", "training", "[", "'codec'", "]", "[", "'performance'", "]", "=", "flow", ".", "codec", ".", "performance", "\n", "\n", "# Make dirs if needed", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "root_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "root_dir", ")", "\n", "\n", "# Save as JSON", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'training.json'", ")", "\n", "if", "not", "quiet", ":", "\n", "        ", "logger", ".", "info", "(", "f'> Training progress --> {filename}'", ")", "\n", "", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "training", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.manipulation.default_training_specs": [[21, 33], ["None"], "function", ["None"], ["def", "default_training_specs", "(", ")", ":", "\n", "    ", "return", "{", "\n", "'use_pretrained_nip'", ":", "True", ",", "\n", "'patch_size'", ":", "64", ",", "\n", "'batch_size'", ":", "10", ",", "\n", "'validation_schedule'", ":", "50", ",", "\n", "'n_epochs'", ":", "1001", ",", "\n", "'learning_rate'", ":", "1e-4", ",", "\n", "'run_number'", ":", "0", ",", "\n", "'lambda_nip'", ":", "0.1", ",", "\n", "'lambda_dcn'", ":", "0", ",", "\n", "'augment'", ":", "False", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.manipulation.train_manipulation_nip": [[36, 336], ["manipulation.default_training_specs", "any", "loguru.logger.info", "flow.is_trainable", "flow.is_trainable", "os.path.join.append", "os.path.join", "loguru.logger.info", "os.path.join", "loguru.logger.info", "collections.deque", "collections.deque", "collections.OrderedDict", "flow.summary", "data.summary", "flow.fan.summary", "flow.nip.summary", "str", "helpers.utils.format_number", "helpers.utils.format_number", "str", "helpers.utils.format_number", "helpers.utils.format_number", "helpers.utils.format_number", "helpers.utils.format_number", "helpers.utils.format_number", "helpers.utils.format_number", "str", "helpers.utils.format_number", "helpers.utils.format_number", "any", "print", "collections.OrderedDict.items", "print", "training.validation.validate_fan", "[].append", "np.identity.tolist", "flow.is_trainable", "flow.is_trainable", "training.validation.save_training_progress", "training.validation.visualize_manipulation_training", "loguru.logger.info", "flow.fan.save_model", "flow.is_trainable", "directories_def.update", "default_training_specs.update", "RuntimeError", "ValueError", "data.is_raw_and_rgb", "os.path.join.append", "os.path.join.append", "os.path.join.append", "os.path.join.append", "os.path.exists", "loguru.logger.debug", "flow.is_trainable", "ValueError", "os.path.join", "loguru.logger.debug", "flow.nip.load_model", "collections.deque", "collections.deque", "flow.codec.summary", "collect_memory_stats.values", "print", "tqdm.tqdm", "numpy.identity", "range", "training.validation.validate_nip", "zip", "isinstance", "os.path.join", "flow.nip.save_model", "flow.is_trainable", "isinstance", "flow.codec.save_model", "shutil.copyfile", "data.next_training_batch", "data.next_training_batch", "ValueError", "flow.nip.count_parameters", "flow.nip.count_parameters", "range", "zip", "flow.is_trainable", "flow.is_trainable", "pbar.set_postfix", "pbar.update", "flow.nip.log_metric", "training.validation.validate_dcn", "validation.validate_jpeg.items", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "required_keys.difference", "ValueError", "ValueError", "flow.training_step", "loss_epoch[].append", "loss_epoch[].append", "model.log_metric", "loss_last_k_epochs[].append", "training.validation.validate_fan", "flow.fan.log_metric", "np.identity.tolist", "flow.is_trainable", "flow.is_trainable", "training.validation.save_training_progress", "flow.fan.save_model", "flow.is_trainable", "numpy.mean", "numpy.mean", "numpy.mean().round", "flow.is_trainable", "isinstance", "flow.codec.estimate_qf", "len", "round", "flow.codec.log_metric", "training.keys", "data.next_training_batch", "data.next_training_batch", "model.pop_metric", "training.validation.validate_nip", "zip", "isinstance", "validation.validate_jpeg.items", "os.path.join", "flow.nip.save_model", "isinstance", "flow.is_trainable", "flow.codec.save_model", "memory[].append", "memory[].append", "flow.nip.log_metric", "training.validation.validate_dcn", "isinstance", "flow.codec.log_metric", "os.path.join", "os.path.join", "round", "round", "numpy.mean", "training.validation.validate_jpeg", "NotImplementedError", "helpers.debugging.memory_usage_proc", "helpers.debugging.memory_usage_resource"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.training.manipulation.default_training_specs", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_fan", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.save_training_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.visualize_manipulation_training", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.is_raw_and_rgb", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_nip", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_dcn", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_fan", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.save_training_progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.estimate_qf", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_nip", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_dcn", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric", "home.repos.pwc.inspect_result.pkorus_neural-imaging.training.validation.validate_jpeg", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_proc", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_resource"], ["", "def", "train_manipulation_nip", "(", "flow", ",", "training", ",", "data", ",", "directories", "=", "None", ",", "overwrite", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Training procedure for the manipulation classification workflow. This function is mainly the boilerplate\n    code that handles parameter sanitization, validation, saving and showing progress, etc. A minimalistic training\n    code would be just (for a single epoch):\n\n    for batch_id in range(n_batches):\n        batch_x, batch_y = data.next_training_batch(batch_id, batch_size, rgb_patch_size)\n        loss, losses = flow.training_step(batch_x, batch_y, lambda_nip, lambda_dcn, learning_rate)\n    \n    See: workflows.manipulation_classification\n    \n    :param flow: an instance of the ManipulationClassification workflow\n    :param training: dict with training setup (see function default_training_specs() for an example)\n    {\n        camera_name          : name of the camera, used to re-load weights of the NIP for a given camera\n        use_pretrained_nip   : boolean flag to enable/disable loading a pre-trained model\n        lambda_nip           : regularization strength to control the trade-off between objectives (image quality)\n        lambda_dcn           : regularization strength to control the trade-off between objectives (compression quality)\n        run_number           : number of the current run ()\n        n_epochs             : number of training epochs\n        learning_rate        : value of the learning rate\n    }\n    :param data: instance of the Dataset\n    :param data: instance of the Dataset\n    :param directories: dict with directories for training output & NIP models \n    {\n        root             : root output directory for saving training progress and model snapshots (default: './data/m/')\n        nip_snapshots    : root directory with pre-trained NIP models (default: './data/models/nip/')\n    }\n    \"\"\"", "\n", "\n", "# Apply default settings", "\n", "directories_def", "=", "{", "'root'", ":", "'./data/m/'", ",", "'nip_snapshots'", ":", "'./data/models/nip/'", "}", "\n", "if", "directories", "is", "not", "None", ":", "\n", "        ", "directories_def", ".", "update", "(", "directories", ")", "\n", "", "directories", "=", "directories_def", "\n", "\n", "training_defaults", "=", "default_training_specs", "(", ")", "\n", "if", "training", "is", "not", "None", ":", "\n", "        ", "training_defaults", ".", "update", "(", "training", ")", "\n", "", "training", "=", "training_defaults", "\n", "\n", "# Check if all needed options are set in training specification", "\n", "required_keys", "=", "{", "'camera_name'", ",", "'use_pretrained_nip'", ",", "'lambda_nip'", ",", "'lambda_dcn'", ",", "'run_number'", ",", "'n_epochs'", ",", "'learning_rate'", ",", "'augment'", "}", "\n", "\n", "# logger.debug(f'Training spec {training.keys()}')", "\n", "\n", "if", "any", "(", "[", "x", "not", "in", "training", "for", "x", "in", "required_keys", "]", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Missing keys in the training dictionary! {}'", ".", "format", "(", "required_keys", ".", "difference", "(", "training", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "if", "data", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'Training data seems not to be loaded!'", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "data", ".", "is_raw_and_rgb", "(", ")", ":", "\n", "            ", "batch_x", ",", "batch_y", "=", "data", ".", "next_training_batch", "(", "0", ",", "1", ",", "training", "[", "'patch_size'", "]", "*", "2", ")", "\n", "if", "batch_x", ".", "shape", "!=", "(", "1", ",", "training", "[", "'patch_size'", "]", ",", "training", "[", "'patch_size'", "]", ",", "4", ")", "or", "batch_y", ".", "shape", "!=", "(", "1", ",", "2", "*", "training", "[", "'patch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ",", "3", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f'The RAW+RGB training batch is of invalid size! {batch_x.shape}'", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_x", "=", "data", ".", "next_training_batch", "(", "0", ",", "1", ",", "training", "[", "'patch_size'", "]", "*", "2", ")", "\n", "if", "batch_x", ".", "shape", "!=", "(", "1", ",", "2", "*", "training", "[", "'patch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ",", "3", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f'The RGB training batch is of invalid size! {batch_x.shape}'", ")", "\n", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "raise", "ValueError", "(", "'Data set error: {}'", ".", "format", "(", "e", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Training manipulation classification: cam={} / lr={:.4f} / run={:3d} / epochs={}, root={}'", ".", "format", "(", "\n", "training", "[", "'camera_name'", "]", ",", "training", "[", "'lambda_nip'", "]", ",", "training", "[", "'run_number'", "]", ",", "training", "[", "'n_epochs'", "]", ",", "\n", "directories", "[", "'root'", "]", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Construct output directory - some example paths:", "\n", "#  root / camera_name / *Net / fixed-nip / fixed-codec / 001 /", "\n", "#  root / camera_name / *Net / lr-0.1000 / lc-0.1000 / 001 /", "\n", "#  root / camera_name / *Net / fixed-nip / lc-0.1000 / 001 /", "\n", "nip_save_dir", "=", "[", "directories", "[", "'root'", "]", ",", "training", "[", "'camera_name'", "]", ",", "flow", ".", "nip", ".", "class_name", "]", "\n", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", ":", "\n", "        ", "nip_save_dir", ".", "append", "(", "'ln-{:0.4f}'", ".", "format", "(", "training", "[", "'lambda_nip'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "nip_save_dir", ".", "append", "(", "'fixed-nip'", ")", "\n", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "        ", "nip_save_dir", ".", "append", "(", "'lc-{:0.4f}'", ".", "format", "(", "training", "[", "'lambda_dcn'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "nip_save_dir", ".", "append", "(", "'fixed-codec'", ")", "\n", "", "nip_save_dir", ".", "append", "(", "'{:03d}'", ".", "format", "(", "training", "[", "'run_number'", "]", ")", ")", "\n", "\n", "nip_save_dir", "=", "os", ".", "path", ".", "join", "(", "*", "nip_save_dir", ")", "\n", "logger", ".", "info", "(", "f'(progress) -> {nip_save_dir}'", ")", "\n", "\n", "model_directory", "=", "os", ".", "path", ".", "join", "(", "nip_save_dir", ",", "'models'", ")", "\n", "logger", ".", "info", "(", "f'(model) ----> {model_directory}'", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "nip_save_dir", ")", "and", "not", "overwrite", ":", "\n", "        ", "logger", ".", "debug", "(", "'Directory exists, skipping...'", ")", "\n", "return", "model_directory", "\n", "\n", "", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", "and", "flow", ".", "nip", ".", "count_parameters", "(", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'It looks like you`re trying to optimize a NIP with no trainable parameters!'", ")", "\n", "\n", "# Basic setup", "\n", "", "learning_rate_decay_schedule", "=", "100", "\n", "learning_rate_decay_rate", "=", "0.90", "\n", "learning_rate", "=", "training", "[", "'learning_rate'", "]", "\n", "n_batches", "=", "data", ".", "count_training", "//", "training", "[", "'batch_size'", "]", "\n", "\n", "# Load different NIP weights if specified", "\n", "if", "training", "[", "'use_pretrained_nip'", "]", "and", "flow", ".", "nip", ".", "count_parameters", "(", ")", ">", "0", ":", "\n", "        ", "nip_dirname", "=", "os", ".", "path", ".", "join", "(", "directories", "[", "'nip_snapshots'", "]", ",", "training", "[", "'camera_name'", "]", ",", "flow", ".", "nip", ".", "model_code", ")", "\n", "logger", ".", "debug", "(", "f'Loading camera model from {nip_dirname}'", ")", "\n", "flow", ".", "nip", ".", "load_model", "(", "nip_dirname", ")", "\n", "\n", "", "model_list", "=", "[", "'nip'", ",", "'fan'", "]", "\n", "\n", "# Containers for storing loss progression", "\n", "loss_epoch", "=", "{", "key", ":", "deque", "(", "maxlen", "=", "n_batches", ")", "for", "key", "in", "model_list", "}", "\n", "loss_epoch", "[", "'similarity-loss'", "]", "=", "deque", "(", "maxlen", "=", "n_batches", ")", "\n", "loss_last_k_epochs", "=", "{", "key", ":", "deque", "(", "maxlen", "=", "10", ")", "for", "key", "in", "model_list", "}", "\n", "loss_last_k_epochs", "[", "'similarity-loss'", "]", "=", "deque", "(", "maxlen", "=", "n_batches", ")", "\n", "\n", "# Collect memory usage (seems to be leaking in matplotlib)", "\n", "collect_memory_stats", "=", "{", "'tf'", ":", "False", ",", "'ram'", ":", "False", "}", "\n", "memory", "=", "{", "'tf-ram'", ":", "[", "]", ",", "'tf-vars'", ":", "[", "]", ",", "'cpu-proc'", ":", "[", "]", ",", "'cpu-resource'", ":", "[", "]", "}", "\n", "\n", "# Collect and print training summary", "\n", "training_summary", "=", "OrderedDict", "(", ")", "\n", "training_summary", "[", "'Problem'", "]", "=", "flow", ".", "summary", "(", ")", "\n", "training_summary", "[", "'Dataset'", "]", "=", "data", ".", "summary", "(", ")", "\n", "training_summary", "[", "'Camera name'", "]", "=", "training", "[", "'camera_name'", "]", "\n", "training_summary", "[", "'Classes'", "]", "=", "f'{flow._forensics_classes}'", "\n", "training_summary", "[", "'FAN model'", "]", "=", "flow", ".", "fan", ".", "summary", "(", ")", "\n", "training_summary", "[", "'NIP model'", "]", "=", "flow", ".", "nip", ".", "summary", "(", ")", "\n", "training_summary", "[", "'Channel Downsampling'", "]", "=", "flow", ".", "_distribution", "[", "'downsampling'", "]", "\n", "training_summary", "[", "'Channel Compression'", "]", "=", "flow", ".", "codec", ".", "summary", "(", ")", "if", "flow", ".", "codec", "is", "not", "None", "else", "'n/a'", "\n", "training_summary", "[", "'Channel Compression Parameters'", "]", "=", "str", "(", "flow", ".", "_distribution", "[", "'compression_params'", "]", ")", "\n", "training_summary", "[", "'Joint optimization'", "]", "=", "f'{flow.trainable_models}'", "\n", "training_summary", "[", "'NIP Regularization'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'lambda_nip'", "]", ")", "\n", "training_summary", "[", "'DCN Regularization'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'lambda_dcn'", "]", ")", "\n", "training_summary", "[", "'NIP loss'", "]", "=", "f'{flow.nip.loss_metric}'", "\n", "training_summary", "[", "'Use pre-trained NIP'", "]", "=", "str", "(", "training", "[", "'use_pretrained_nip'", "]", ")", "\n", "training_summary", "[", "'# Epochs'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'n_epochs'", "]", ")", "\n", "training_summary", "[", "'Patch size'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'patch_size'", "]", ")", "\n", "training_summary", "[", "'Batch size'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'batch_size'", "]", ")", "\n", "training_summary", "[", "'Learning rate'", "]", "=", "utils", ".", "format_number", "(", "training", "[", "'learning_rate'", "]", ")", "\n", "training_summary", "[", "'Learning rate decay schedule'", "]", "=", "utils", ".", "format_number", "(", "learning_rate_decay_schedule", ")", "\n", "training_summary", "[", "'Learning rate decay rate'", "]", "=", "utils", ".", "format_number", "(", "learning_rate_decay_rate", ")", "\n", "training_summary", "[", "'Validation schedule'", "]", "=", "training", "[", "'validation_schedule'", "]", "\n", "training_summary", "[", "'Augmentation'", "]", "=", "str", "(", "training", "[", "'augment'", "]", ")", "\n", "training_summary", "[", "'# train. images'", "]", "=", "utils", ".", "format_number", "(", "data", ".", "count_training", ")", "\n", "training_summary", "[", "'# valid. images'", "]", "=", "utils", ".", "format_number", "(", "data", ".", "count_validation", ")", "\n", "training_summary", "[", "'Batch shape'", "]", "=", "f'{batch_x.shape}'", "\n", "training_summary", "[", "'NIP input patch'", "]", "=", "f'{flow.nip.x.shape}'", "\n", "training_summary", "[", "'NIP output patch'", "]", "=", "f'{flow.nip.y.shape}'", "\n", "training_summary", "[", "'FAN input patch'", "]", "=", "f'{flow.fan.x.shape}'", "\n", "if", "any", "(", "collect_memory_stats", ".", "values", "(", ")", ")", ":", "\n", "        ", "training_summary", "[", "'memory_consumption'", "]", "=", "memory", "\n", "\n", "", "print", "(", "''", ")", "\n", "for", "k", ",", "v", "in", "training_summary", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'{:30s}: {}'", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "", "print", "(", "''", ",", "flush", "=", "True", ")", "\n", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "training", "[", "'n_epochs'", "]", ",", "ncols", "=", "120", ",", "desc", "=", "'Train'", ")", "as", "pbar", ":", "\n", "\n", "        ", "epoch", "=", "0", "\n", "conf", "=", "np", ".", "identity", "(", "flow", ".", "n_classes", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "0", ",", "training", "[", "'n_epochs'", "]", ")", ":", "\n", "\n", "            ", "for", "batch_id", "in", "range", "(", "n_batches", ")", ":", "\n", "\n", "# Extract random patches for the current batch of images", "\n", "                ", "if", "data", ".", "_loaded_data", "==", "'xy'", ":", "\n", "                    ", "batch_x", ",", "batch_y", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "batch_x", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ")", "\n", "batch_y", "=", "batch_x", "\n", "\n", "", "comb_loss", ",", "comp_loss", "=", "flow", ".", "training_step", "(", "batch_x", ",", "batch_y", ",", "training", "[", "'lambda_nip'", "]", ",", "training", "[", "'lambda_dcn'", "]", ",", "training", "[", "'augment'", "]", ",", "learning_rate", ")", "\n", "\n", "loss_epoch", "[", "'fan'", "]", ".", "append", "(", "comb_loss", ")", "\n", "loss_epoch", "[", "'nip'", "]", ".", "append", "(", "comp_loss", "[", "'nip'", "]", ")", "\n", "\n", "# Average and record loss values", "\n", "", "for", "model_name", ",", "model", "in", "zip", "(", "model_list", ",", "[", "flow", ".", "nip", ",", "flow", ".", "fan", "]", ")", ":", "\n", "                ", "model", ".", "log_metric", "(", "'loss'", ",", "'training'", ",", "loss_epoch", "[", "model_name", "]", ")", "\n", "loss_last_k_epochs", "[", "model_name", "]", ".", "append", "(", "model", ".", "pop_metric", "(", "'loss'", ",", "'training'", ")", ")", "\n", "\n", "# Model validation", "\n", "", "if", "epoch", "%", "training", "[", "'validation_schedule'", "]", "==", "0", ":", "\n", "\n", "# Validate the forensics analysis network", "\n", "                ", "accuracy", ",", "conf", "=", "validation", ".", "validate_fan", "(", "flow", ",", "data", ")", "\n", "flow", ".", "fan", ".", "log_metric", "(", "'accuracy'", ",", "'validation'", ",", "accuracy", ")", "\n", "flow", ".", "fan", ".", "performance", "[", "'confusion'", "]", "=", "conf", ".", "tolist", "(", ")", "\n", "\n", "# Validate the NIP model", "\n", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", ":", "\n", "\n", "                    ", "values", "=", "validation", ".", "validate_nip", "(", "flow", ".", "nip", ",", "data", ",", "nip_save_dir", ",", "epoch", "=", "epoch", ",", "show_ref", "=", "True", ",", "loss_type", "=", "flow", ".", "nip", ".", "loss_metric", ")", "\n", "\n", "for", "metric", ",", "val_array", "in", "zip", "(", "[", "'ssim'", ",", "'psnr'", ",", "'loss'", "]", ",", "values", ")", ":", "\n", "                        ", "flow", ".", "nip", ".", "log_metric", "(", "metric", ",", "'validation'", ",", "val_array", ")", "\n", "\n", "# Validate the DCN model", "\n", "", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "                    ", "if", "isinstance", "(", "flow", ".", "codec", ",", "compression", ".", "DCN", ")", ":", "\n", "                        ", "values", "=", "validation", ".", "validate_dcn", "(", "flow", ".", "codec", ",", "data", ",", "nip_save_dir", ",", "epoch", "=", "epoch", ",", "show_ref", "=", "True", ")", "\n", "", "elif", "isinstance", "(", "flow", ".", "codec", ",", "jpeg", ".", "JPEG", ")", ":", "\n", "                        ", "values", "=", "validation", ".", "validate_jpeg", "(", "flow", ".", "codec", ",", "data", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "(", "'Validation for {} codec doesn\\'t seem to be implemented'", ".", "format", "(", "flow", ".", "codec", ")", ")", "\n", "\n", "", "for", "metric", ",", "value", "in", "values", ".", "items", "(", ")", ":", "\n", "                        ", "flow", ".", "codec", ".", "log_metric", "(", "metric", ",", "'validation'", ",", "value", ")", "\n", "\n", "# Save progress stats", "\n", "", "", "validation", ".", "save_training_progress", "(", "training_summary", ",", "flow", ",", "nip_save_dir", ",", "quiet", "=", "True", ")", "\n", "\n", "# Save models", "\n", "flow", ".", "fan", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "fan", ".", "scoped_name", ")", ",", "epoch", ",", "quiet", "=", "True", ")", "\n", "\n", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", ":", "\n", "                    ", "flow", ".", "nip", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "nip", ".", "scoped_name", ")", ",", "epoch", ",", "quiet", "=", "True", ")", "\n", "\n", "", "if", "isinstance", "(", "flow", ".", "codec", ",", "compression", ".", "DCN", ")", "and", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "                    ", "flow", ".", "codec", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "codec", ".", "scoped_name", ")", ",", "epoch", ",", "quiet", "=", "True", ")", "\n", "\n", "# Monitor memory usage - used to have memory leaks in matplotlib", "\n", "", "if", "collect_memory_stats", "[", "'ram'", "]", ":", "\n", "                    ", "memory", "[", "'cpu-proc'", "]", ".", "append", "(", "round", "(", "debugging", ".", "memory_usage_proc", "(", ")", ",", "1", ")", ")", "\n", "memory", "[", "'cpu-resource'", "]", ".", "append", "(", "round", "(", "debugging", ".", "memory_usage_resource", "(", ")", ",", "1", ")", ")", "\n", "\n", "", "", "if", "epoch", "%", "learning_rate_decay_schedule", "==", "0", ":", "\n", "                ", "learning_rate", "*=", "learning_rate_decay_rate", "\n", "\n", "# Update the progress bar", "\n", "", "progress_stats", "=", "{", "\n", "'fan'", ":", "np", ".", "mean", "(", "loss_last_k_epochs", "[", "'fan'", "]", ")", ",", "\n", "'acc'", ":", "flow", ".", "fan", ".", "performance", "[", "'accuracy'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ",", "\n", "}", "\n", "\n", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "                ", "progress_stats", "[", "'codec'", "]", "=", "flow", ".", "codec", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "progress_stats", "[", "'H'", "]", "=", "flow", ".", "codec", ".", "performance", "[", "'entropy'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "\n", "", "if", "np", ".", "mean", "(", "loss_last_k_epochs", "[", "'nip'", "]", ")", ">", "0", ":", "\n", "                ", "progress_stats", "[", "'nip'", "]", "=", "np", ".", "mean", "(", "loss_last_k_epochs", "[", "'nip'", "]", ")", ".", "round", "(", "2", ")", "\n", "\n", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "                ", "progress_stats", "[", "'codec'", "]", "=", "flow", ".", "codec", ".", "performance", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "progress_stats", "[", "'H'", "]", "=", "flow", ".", "codec", ".", "performance", "[", "'entropy'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "\n", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", "and", "isinstance", "(", "flow", ".", "codec", ",", "jpeg", ".", "JPEG", ")", ":", "\n", "                ", "progress_stats", "[", "'JPEG'", "]", "=", "flow", ".", "codec", ".", "estimate_qf", "(", ")", "\n", "\n", "", "if", "len", "(", "flow", ".", "nip", ".", "performance", "[", "'psnr'", "]", "[", "'validation'", "]", ")", ">", "0", ":", "\n", "                ", "progress_stats", "[", "'psnr'", "]", "=", "flow", ".", "nip", ".", "performance", "[", "'psnr'", "]", "[", "'validation'", "]", "[", "-", "1", "]", "\n", "\n", "", "if", "collect_memory_stats", "[", "'ram'", "]", ":", "\n", "                ", "progress_stats", "[", "'ram'", "]", "=", "round", "(", "memory", "[", "'cpu-proc'", "]", "[", "-", "1", "]", "//", "1024", ",", "2", ")", "\n", "\n", "", "pbar", ".", "set_postfix", "(", "**", "progress_stats", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "# Final validation and plotting", "\n", "", "", "accuracy", ",", "conf", "=", "validation", ".", "validate_fan", "(", "flow", ",", "data", ")", "\n", "flow", ".", "fan", ".", "performance", "[", "'accuracy'", "]", "[", "'validation'", "]", ".", "append", "(", "accuracy", ")", "\n", "flow", ".", "fan", ".", "performance", "[", "'confusion'", "]", "=", "conf", ".", "tolist", "(", ")", "\n", "\n", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", ":", "\n", "        ", "values", "=", "validation", ".", "validate_nip", "(", "flow", ".", "nip", ",", "data", ",", "nip_save_dir", ",", "epoch", "=", "epoch", ",", "show_ref", "=", "True", ",", "loss_type", "=", "'L2'", ")", "\n", "for", "metric", ",", "val_array", "in", "zip", "(", "[", "'ssim'", ",", "'psnr'", ",", "'loss'", "]", ",", "values", ")", ":", "\n", "            ", "flow", ".", "nip", ".", "log_metric", "(", "metric", ",", "'validation'", ",", "val_array", ")", "\n", "\n", "", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", ":", "\n", "        ", "if", "isinstance", "(", "flow", ".", "codec", ",", "compression", ".", "DCN", ")", ":", "\n", "            ", "values", "=", "validation", ".", "validate_dcn", "(", "flow", ".", "codec", ",", "data", ",", "nip_save_dir", ",", "epoch", "=", "epoch", ",", "show_ref", "=", "True", ")", "\n", "for", "metric", ",", "val_array", "in", "values", ".", "items", "(", ")", ":", "\n", "                ", "flow", ".", "codec", ".", "log_metric", "(", "metric", ",", "'validation'", ",", "val_array", ")", "\n", "\n", "# Save model progress", "\n", "", "", "", "validation", ".", "save_training_progress", "(", "training_summary", ",", "flow", ",", "nip_save_dir", ")", "\n", "\n", "# Visualize current progress", "\n", "validation", ".", "visualize_manipulation_training", "(", "flow", ",", "epoch", ",", "nip_save_dir", ")", "\n", "\n", "# Save models", "\n", "logger", ".", "info", "(", "'Saving models...'", ")", "\n", "\n", "flow", ".", "fan", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "fan", ".", "scoped_name", ")", ",", "epoch", ")", "\n", "\n", "if", "flow", ".", "is_trainable", "(", "'nip'", ")", ":", "\n", "        ", "flow", ".", "nip", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "nip", ".", "scoped_name", ")", ",", "epoch", ")", "\n", "\n", "", "if", "flow", ".", "is_trainable", "(", "'dcn'", ")", "and", "isinstance", "(", "flow", ".", "codec", ",", "compression", ".", "DCN", ")", ":", "\n", "        ", "flow", ".", "codec", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "codec", ".", "scoped_name", ")", ",", "epoch", ")", "\n", "shutil", ".", "copyfile", "(", "os", ".", "path", ".", "join", "(", "flow", ".", "_distribution", "[", "'compression_params'", "]", "[", "'dirname'", "]", ",", "flow", ".", "codec", ".", "scoped_name", ",", "'progress.json'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "model_directory", ",", "flow", ".", "codec", ".", "scoped_name", ",", "'progress.json'", ")", ")", "\n", "\n", "", "return", "model_directory", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.simulate_compression": [[19, 28], ["codec.compress", "codec.decompress", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress"], ["", "def", "simulate_compression", "(", "batch_x", ",", "dcn", ")", ":", "\n", "    ", "\"\"\"\n    Simulates the entire compression and decompression (writes bytes to memory). Returns decompressed image and the byte count.\n    \"\"\"", "\n", "\n", "compressed_image", "=", "compress", "(", "batch_x", ",", "dcn", ")", "\n", "batch_y", "=", "decompress", "(", "compressed_image", ",", "dcn", ")", "\n", "\n", "return", "batch_y", ",", "len", "(", "compressed_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.compress_n_stats": [[30, 55], ["numpy.zeros_like", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "codec.simulate_compression", "dcn.compress", "helpers.stats.entropy", "skimage.measure.compare_ssim", "skimage.measure.compare_psnr", "stats.keys", "dcn.get_codebook"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.simulate_compression", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook"], ["", "def", "compress_n_stats", "(", "batch_x", ",", "dcn", ")", ":", "\n", "\n", "    ", "batch_y", "=", "np", ".", "zeros_like", "(", "batch_x", ")", "\n", "stats", "=", "{", "\n", "'ssim'", ":", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "'psnr'", ":", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "'entropy'", ":", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "'bytes'", ":", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "'bpp'", ":", "np", ".", "zeros", "(", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ")", "\n", "}", "\n", "\n", "for", "image_id", "in", "range", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "batch_y", "[", "image_id", "]", ",", "image_bytes", "=", "simulate_compression", "(", "batch_x", "[", "image_id", ":", "image_id", "+", "1", "]", ",", "dcn", ")", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", "[", "image_id", ":", "image_id", "+", "1", "]", ")", "\n", "stats", "[", "'bytes'", "]", "[", "image_id", "]", "=", "image_bytes", "\n", "stats", "[", "'entropy'", "]", "[", "image_id", "]", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "dcn", ".", "get_codebook", "(", ")", ")", "\n", "stats", "[", "'ssim'", "]", "[", "image_id", "]", "=", "compare_ssim", "(", "batch_x", "[", "image_id", "]", ",", "batch_y", "[", "image_id", "]", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", "\n", "stats", "[", "'psnr'", "]", "[", "image_id", "]", "=", "compare_psnr", "(", "batch_x", "[", "image_id", "]", ",", "batch_y", "[", "image_id", "]", ",", "data_range", "=", "1", ")", "\n", "stats", "[", "'bpp'", "]", "[", "image_id", "]", "=", "8", "*", "image_bytes", "/", "batch_x", "[", "image_id", "]", ".", "shape", "[", "0", "]", "/", "batch_x", "[", "image_id", "]", ".", "shape", "[", "1", "]", "\n", "\n", "", "if", "batch_x", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "for", "k", "in", "stats", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "k", "]", "=", "stats", "[", "k", "]", "[", "0", "]", "\n", "\n", "", "", "return", "batch_y", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.compare": [[57, 85], ["dcn.sess.run().reshape", "dcn.compress", "dcn.decompress", "scipy.cluster.vq.vq", "bytes", "pyfse.pyfse.compress", "pyfse.pyfse.decompress", "list", "numpy.array().reshape", "dcn.decompress", "dcn.compress.reshape", "indices.astype", "int", "dcn.sess.run", "numpy.prod", "numpy.array"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress"], ["", "def", "compare", "(", "dcn", ",", "batch_x", ")", ":", "\n", "    ", "\"\"\"\n    Compare the quantized and decompressed image with its fully TF-processed counterpart.\n    \"\"\"", "\n", "\n", "code_book", "=", "dcn", ".", "sess", ".", "run", "(", "dcn", ".", "codebook", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", "\n", "batch_y", "=", "dcn", ".", "decompress", "(", "batch_z", ")", "\n", "\n", "# Quantization and coding", "\n", "indices", ",", "distortion", "=", "cluster", ".", "vq", ".", "vq", "(", "batch_z", ".", "reshape", "(", "(", "-", "1", ")", ")", ",", "code_book", ")", "\n", "\n", "# Compress each image", "\n", "data", "=", "bytes", "(", "indices", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "coded_fse", "=", "pyfse", ".", "compress", "(", "data", ")", "\n", "decoded_fse", "=", "pyfse", ".", "decompress", "(", "coded_fse", ",", "int", "(", "np", ".", "prod", "(", "indices", ".", "shape", ")", ")", ")", "\n", "\n", "# Check sanity", "\n", "assert", "data", "==", "decoded_fse", ",", "'Entropy decoding error'", "\n", "\n", "shape", "=", "list", "(", "dcn", ".", "latent_shape", ")", "\n", "shape", "[", "0", "]", "=", "1", "\n", "decoded_indices", "=", "np", ".", "array", "(", "[", "x", "for", "x", "in", "decoded_fse", "]", ")", ".", "reshape", "(", "shape", ")", "\n", "image_q", "=", "code_book", "[", "decoded_indices", "]", "\n", "image_y", "=", "dcn", ".", "decompress", "(", "image_q", ")", "\n", "\n", "return", "batch_y", ",", "image_y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.compress": [[87, 186], ["io.BytesIO", "model.compress().numpy", "numpy.array", "io.BytesIO.write", "model.get_codebook", "range", "numpy.array", "io.BytesIO.write", "io.BytesIO.write", "io.BytesIO.getvalue", "numpy.expand_dims", "np.array.tobytes", "print", "len", "codec.L3ICError", "scipy.cluster.vq.vq", "collections.Counter().items", "print", "print", "print", "pyfse.pyfse.compress", "print", "print", "len", "RuntimeError", "numpy.uint16().tobytes", "io.BytesIO.write", "model.compress", "batch_z[].reshape", "pyfse.pyfse.compress", "coded_layers.append", "batch_z[].reshape", "len", "np.array.tobytes", "print", "np.array.tobytes", "len", "bytes", "numpy.uint8().tobytes", "len", "codec.L3ICError", "collections.Counter", "indices.reshape", "print", "numpy.uint16", "indices.astype", "numpy.uint16().tobytes", "numpy.uint8().tobytes", "collections.Counter().items", "print", "print", "print", "batch_z[].reshape", "len", "numpy.uint8", "batch_z[].reshape", "numpy.uint16", "numpy.uint8", "collections.Counter", "indices.reshape", "len", "batch_z[].reshape"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress"], ["", "def", "compress", "(", "batch_x", ",", "model", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Serialize the image as a bytes sequence. The feature maps are encoded as separate layers.\n\n    ## Bit-stream structure:\n\n    - Latent shape H x W x N = 3 x 1 byte (uint8)\n    - Length of coded layer sizes = 2 bytes (uint16)\n    - Coded layer sizes:\n        - FSE encoded uint16 array of size 2 * N bytes (if possible to compress)\n        - ...or RAW bytes\n    - Coded layers:\n        - FSE encoded uint8 array of latent vector size\n        - ...or RLE encoded uint16 (number) + uint8 (byte) if all bytes are the same\n\n    \"\"\"", "\n", "\n", "if", "batch_x", ".", "ndim", "==", "3", ":", "\n", "        ", "batch_x", "=", "np", ".", "expand_dims", "(", "batch_x", ",", "axis", "=", "0", ")", "\n", "\n", "", "assert", "batch_x", ".", "ndim", "==", "4", "\n", "assert", "batch_x", ".", "shape", "[", "0", "]", "==", "1", "\n", "\n", "image_stream", "=", "io", ".", "BytesIO", "(", ")", "\n", "\n", "# Get latent space representation", "\n", "batch_z", "=", "model", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "latent_shape", "=", "np", ".", "array", "(", "batch_z", ".", "shape", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "# Write latent space shape to the bytestream", "\n", "image_stream", ".", "write", "(", "latent_shape", ".", "tobytes", "(", ")", ")", "\n", "\n", "# Encode feature layers separately", "\n", "coded_layers", "=", "[", "]", "\n", "code_book", "=", "model", ".", "get_codebook", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'[l3ic encoder]'", ",", "'Code book:'", ",", "code_book", ")", "\n", "\n", "", "if", "len", "(", "code_book", ")", ">", "256", ":", "\n", "        ", "raise", "L3ICError", "(", "'Code-books with more than 256 centers are not supported'", ")", "\n", "\n", "", "for", "n", "in", "range", "(", "latent_shape", "[", "-", "1", "]", ")", ":", "\n", "# TODO Should a code book always be used? What about integers?", "\n", "        ", "indices", ",", "_", "=", "cluster", ".", "vq", ".", "vq", "(", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ",", "code_book", ")", "\n", "\n", "try", ":", "\n", "# Compress layer with FSE", "\n", "            ", "coded_layer", "=", "pyfse", ".", "compress", "(", "bytes", "(", "indices", ".", "astype", "(", "np", ".", "uint8", ")", ")", ")", "\n", "", "except", "pyfse", ".", "FSESymbolRepetitionError", ":", "\n", "# All bytes are identical, fallback to RLE", "\n", "            ", "coded_layer", "=", "np", ".", "uint16", "(", "len", "(", "indices", ")", ")", ".", "tobytes", "(", ")", "+", "np", ".", "uint8", "(", "indices", "[", "0", "]", ")", ".", "tobytes", "(", ")", "\n", "", "except", "pyfse", ".", "FSENotCompressibleError", ":", "\n", "# Stream does not compress", "\n", "            ", "coded_layer", "=", "np", ".", "uint8", "(", "indices", ")", ".", "tobytes", "(", ")", "\n", "", "finally", ":", "\n", "            ", "if", "len", "(", "coded_layer", ")", "==", "1", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "layer_stats", "=", "Counter", "(", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", ".", "items", "(", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} values:'", ".", "format", "(", "n", ")", ",", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} code-book indices:'", ".", "format", "(", "n", ")", ",", "indices", ".", "reshape", "(", "(", "-", "1", ")", ")", "[", ":", "20", "]", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} hist:'", ".", "format", "(", "n", ")", ",", "layer_stats", ")", "\n", "\n", "", "raise", "L3ICError", "(", "'Layer {} data compresses to a single byte? Something is wrong!'", ".", "format", "(", "n", ")", ")", "\n", "", "coded_layers", ".", "append", "(", "coded_layer", ")", "\n", "\n", "# Show example layer", "\n", "", "", "if", "verbose", ":", "\n", "        ", "n", "=", "0", "\n", "layer_stats", "=", "Counter", "(", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", ".", "items", "(", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} values:'", ".", "format", "(", "n", ")", ",", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} code-book indices:'", ".", "format", "(", "n", ")", ",", "indices", ".", "reshape", "(", "(", "-", "1", ")", ")", "[", ":", "20", "]", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer {} hist:'", ".", "format", "(", "n", ")", ",", "layer_stats", ")", "\n", "\n", "# Write the layer size array", "\n", "", "layer_lengths", "=", "np", ".", "array", "(", "[", "len", "(", "x", ")", "for", "x", "in", "coded_layers", "]", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "\n", "try", ":", "\n", "        ", "coded_lengths", "=", "pyfse", ".", "compress", "(", "layer_lengths", ".", "tobytes", "(", ")", ")", "\n", "if", "verbose", ":", "print", "(", "'[l3ic encoder]'", ",", "'FSE coded lengths'", ")", "\n", "", "except", "pyfse", ".", "FSENotCompressibleError", ":", "\n", "# If the FSE coded stream is empty - it is not compressible - save natively", "\n", "        ", "if", "verbose", ":", "print", "(", "'[l3ic encoder]'", ",", "'RAW coded lengths'", ")", "\n", "coded_lengths", "=", "layer_lengths", ".", "tobytes", "(", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'[l3ic encoder]'", ",", "'Coded lengths #'", ",", "len", "(", "coded_lengths", ")", ",", "'='", ",", "coded_lengths", ")", "\n", "print", "(", "'[l3ic encoder]'", ",", "'Layer lengths = '", ",", "layer_lengths", ")", "\n", "\n", "", "if", "len", "(", "coded_lengths", ")", "==", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Empty coded layer lengths!'", ")", "\n", "\n", "", "image_stream", ".", "write", "(", "np", ".", "uint16", "(", "len", "(", "coded_lengths", ")", ")", ".", "tobytes", "(", ")", ")", "\n", "image_stream", ".", "write", "(", "coded_lengths", ")", "\n", "\n", "# Write individual layers", "\n", "for", "layer", "in", "coded_layers", ":", "\n", "        ", "image_stream", ".", "write", "(", "layer", ")", "\n", "\n", "", "return", "image_stream", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.decompress": [[188, 266], ["numpy.frombuffer", "numpy.frombuffer", "io.BytesIO.read", "restore.get_codebook", "numpy.zeros", "range", "restore.decompress().numpy", "type", "io.BytesIO", "io.BytesIO.read", "io.BytesIO.read", "int", "print", "print", "pyfse.pyfse.decompress", "numpy.frombuffer", "numpy.frombuffer", "print", "codec.restore", "print", "codec.restore", "io.BytesIO.read", "code_book[].reshape", "collections.Counter().items", "print", "print", "type", "print", "print", "print", "int", "batch_z[].reshape", "restore.decompress", "hasattr", "ValueError", "len", "print", "print", "collections.Counter", "numpy.frombuffer", "int", "len", "pyfse.pyfse.decompress", "len", "batch_z[].reshape", "int", "int", "numpy.frombuffer"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress"], ["", "def", "decompress", "(", "stream", ",", "model", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Decompress an image from the given bytes sequence. See docs of compress for stream details.\n    \"\"\"", "\n", "\n", "if", "type", "(", "stream", ")", "is", "bytes", ":", "\n", "        ", "stream", "=", "io", ".", "BytesIO", "(", "stream", ")", "\n", "", "elif", "type", "(", "stream", ")", "is", "io", ".", "BytesIO", ":", "\n", "        ", "pass", "\n", "", "elif", "not", "hasattr", "(", "stream", ",", "'read'", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported stream type!'", ")", "\n", "\n", "# Read the shape of the latent representation", "\n", "", "latent_x", ",", "latent_y", ",", "n_latent", "=", "np", ".", "frombuffer", "(", "stream", ".", "read", "(", "3", ")", ",", "np", ".", "uint8", ")", "\n", "\n", "# Read the array with layer sizes", "\n", "layer_bytes", "=", "np", ".", "frombuffer", "(", "stream", ".", "read", "(", "2", ")", ",", "np", ".", "uint16", ")", "\n", "coded_layer_lengths", "=", "stream", ".", "read", "(", "int", "(", "layer_bytes", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'[l3ic decoder]'", ",", "'Latent space'", ",", "latent_x", ",", "latent_y", ",", "n_latent", ")", "\n", "print", "(", "'[l3ic decoder]'", ",", "'Layer bytes'", ",", "layer_bytes", ")", "\n", "\n", "", "if", "layer_bytes", "!=", "2", "*", "n_latent", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'[l3ic decoder]'", ",", "'Decoding FSE L'", ")", "\n", "print", "(", "'[l3ic decoder]'", ",", "'Decoding from'", ",", "coded_layer_lengths", ")", "\n", "", "layer_lengths_bytes", "=", "pyfse", ".", "decompress", "(", "coded_layer_lengths", ")", "\n", "layer_lengths", "=", "np", ".", "frombuffer", "(", "layer_lengths_bytes", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'[l3ic decoder]'", ",", "'Decoding RAW L'", ")", "\n", "", "layer_lengths", "=", "np", ".", "frombuffer", "(", "coded_layer_lengths", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'[l3ic decoder]'", ",", "'Layer lengths'", ",", "layer_lengths", ")", "\n", "\n", "# Get the correct DCN model", "\n", "", "if", "model", "is", "None", ":", "\n", "        ", "model", "=", "restore", "(", "'{}c'", ".", "format", "(", "n_latent", ")", ")", "\n", "\n", "", "if", "model", ".", "latent_shape", "[", "-", "1", "]", "!=", "n_latent", ":", "\n", "        ", "print", "(", "'[l3ic decoder]'", ",", "'WARNING'", ",", "'the specified model ({}c) does not match the coded stream ({}c) - switching'", ".", "format", "(", "model", ".", "n_latent", ",", "n_latent", ")", ")", "\n", "model", "=", "restore", "(", "'{}c'", ".", "format", "(", "n_latent", ")", ")", "\n", "\n", "", "code_book", "=", "model", ".", "get_codebook", "(", ")", "\n", "\n", "# Create the latent space array", "\n", "batch_z", "=", "np", ".", "zeros", "(", "(", "1", ",", "latent_x", ",", "latent_y", ",", "n_latent", ")", ")", "\n", "\n", "# Decompress the features separately", "\n", "for", "n", "in", "range", "(", "n_latent", ")", ":", "\n", "        ", "coded_layer", "=", "stream", ".", "read", "(", "int", "(", "layer_lengths", "[", "n", "]", ")", ")", "\n", "try", ":", "\n", "            ", "if", "len", "(", "coded_layer", ")", "==", "3", ":", "\n", "# RLE encoding", "\n", "                ", "count", "=", "np", ".", "frombuffer", "(", "coded_layer", "[", ":", "2", "]", ",", "dtype", "=", "np", ".", "uint16", ")", "[", "0", "]", "\n", "layer_data", "=", "coded_layer", "[", "-", "1", ":", "]", "*", "int", "(", "count", ")", "\n", "", "elif", "len", "(", "coded_layer", ")", "==", "int", "(", "latent_x", ")", "*", "int", "(", "latent_y", ")", ":", "\n", "# If the data could not have been compressed, just read the raw stream", "\n", "                ", "layer_data", "=", "coded_layer", "\n", "", "else", ":", "\n", "                ", "layer_data", "=", "pyfse", ".", "decompress", "(", "coded_layer", ",", "4", "*", "latent_x", "*", "latent_y", ")", "\n", "", "", "except", "pyfse", ".", "FSEException", "as", "e", ":", "\n", "            ", "print", "(", "'[l3ic decoder]'", ",", "'ERROR while decoding layer'", ",", "n", ")", "\n", "print", "(", "'[l3ic decoder]'", ",", "'Stream of size'", ",", "len", "(", "coded_layer", ")", ",", "'bytes ='", ",", "coded_layer", ")", "\n", "raise", "e", "\n", "", "batch_z", "[", "0", ",", ":", ",", ":", ",", "n", "]", "=", "code_book", "[", "np", ".", "frombuffer", "(", "layer_data", ",", "np", ".", "uint8", ")", "]", ".", "reshape", "(", "(", "latent_x", ",", "latent_y", ")", ")", "\n", "\n", "# Show example layer", "\n", "", "if", "verbose", ":", "\n", "        ", "n", "=", "0", "\n", "layer_stats", "=", "Counter", "(", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", ".", "items", "(", ")", "\n", "print", "(", "'[l3ic decoder]'", ",", "'Layer {} values:'", ".", "format", "(", "n", ")", ",", "batch_z", "[", ":", ",", ":", ",", ":", ",", "n", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ")", "\n", "print", "(", "'[l3ic decoder]'", ",", "'Layer {} hist:'", ".", "format", "(", "n", ")", ",", "layer_stats", ")", "\n", "\n", "# Use the DCN decoder to decompress the RGB image", "\n", "", "return", "model", ".", "decompress", "(", "batch_z", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.global_compress": [[268, 273], ["dcn.compress().numpy", "scipy.cluster.vq.vq", "pyfse.pyfse.compress", "dcn.compress().numpy.reshape", "dcn.get_codebook", "bytes", "dcn.compress", "indices.astype"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress"], ["", "def", "global_compress", "(", "dcn", ",", "batch_x", ")", ":", "\n", "# Naive FSE compression of the entire latent repr.", "\n", "    ", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "indices", ",", "distortion", "=", "vq", "(", "batch_z", ".", "reshape", "(", "(", "-", "1", ")", ")", ",", "dcn", ".", "get_codebook", "(", ")", ")", "\n", "return", "pyfse", ".", "compress", "(", "bytes", "(", "indices", ".", "astype", "(", "np", ".", "uint8", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.restore": [[275, 291], ["tfmodel.restore"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore"], ["", "def", "restore", "(", "dir_name", ",", "patch_size", "=", "None", ",", "fetch_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Utility function to simplify restoration of DCN models. Essentially a wrapper over `tfmodel.restore`.\n\n    Instead of writing:\n    -------------------\n    from models import compression\n    tfmodel.restore('data/models/dcn/baselines/16c/', compression, key='codec')\n\n    Just use:\n    ---------\n    from compression import codec\n    codec.restore('16c')\n    \"\"\"", "\n", "from", "models", "import", "tfmodel", "\n", "return", "tfmodel", ".", "restore", "(", "dir_name", ",", "compression", ",", "key", "=", "'codec'", ",", "patch_size", "=", "patch_size", ",", "fetch_stats", "=", "fetch_stats", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_jpeg_df": [[23, 85], ["helpers.loading.discover_images", "helpers.loading.load_images", "numpy.arange", "os.path.join", "batch_x[].astype", "os.path.isfile", "loguru.logger.info", "pandas.read_csv", "pandas.DataFrame", "df.append.to_csv", "tqdm.tqdm", "enumerate", "os.path.join", "enumerate", "compression.jpeg_helpers.compress_batch", "df.append.append", "pbar.set_postfix", "pbar.update", "len", "len", "os.path.join", "os.path.join", "imageio.imwrite", "sewar.full_ref.msssim", "os.path.isdir", "os.makedirs", "skimage.measure.compare_ssim", "skimage.measure.compare_psnr", "os.path.splitext", "numpy.log10"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["def", "get_jpeg_df", "(", "directory", ",", "write_files", "=", "False", ",", "effective_bytes", "=", "True", ",", "force_calc", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute and return (as Pandas DF) the rate distortion curve for JPEG. The result is saved\n    as a CSV file in the source directory. If the file exists, the DF is loaded and returned.\n\n    Files are saved as JPEG using imageio.\n    \"\"\"", "\n", "\n", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "directory", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "directory", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "# Get trade-off for JPEG", "\n", "quality_levels", "=", "np", ".", "arange", "(", "95", ",", "5", ",", "-", "5", ")", "\n", "df_jpeg_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'jpeg.csv'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "df_jpeg_path", ")", "and", "not", "force_calc", ":", "\n", "        ", "logger", ".", "info", "(", "'Restoring JPEG stats from {}'", ".", "format", "(", "df_jpeg_path", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_jpeg_path", ",", "index_col", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'image_id'", ",", "'filename'", ",", "'codec'", ",", "'quality'", ",", "'ssim'", ",", "'psnr'", ",", "'msssim'", ",", "'msssim_db'", ",", "'bytes'", ",", "'bpp'", "]", ")", "\n", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "files", ")", "*", "len", "(", "quality_levels", ")", ",", "ncols", "=", "120", ",", "desc", "=", "'JPEG'", ")", "as", "pbar", ":", "\n", "\n", "            ", "for", "image_id", ",", "filename", "in", "enumerate", "(", "files", ")", ":", "\n", "\n", "# Read the original image", "\n", "                ", "image", "=", "batch_x", "[", "image_id", "]", "\n", "\n", "for", "qi", ",", "q", "in", "enumerate", "(", "quality_levels", ")", ":", "\n", "\n", "# Compress images and get effective bytes (only image data - no headers)", "\n", "                    ", "image_compressed", ",", "image_bytes", "=", "jpeg_helpers", ".", "compress_batch", "(", "image", ",", "q", ",", "effective", "=", "effective_bytes", ")", "\n", "\n", "if", "write_files", ":", "\n", "                        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'jpeg_q{:03d}.png'", ".", "format", "(", "q", ")", ")", "\n", "imageio", ".", "imwrite", "(", "image_path", ",", "(", "255", "*", "image_compressed", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "", "msssim_value", "=", "msssim", "(", "image", ",", "image_compressed", ",", "MAX", "=", "1", ")", ".", "real", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "'image_id'", ":", "image_id", ",", "\n", "'filename'", ":", "filename", ",", "\n", "'codec'", ":", "'jpeg'", ",", "\n", "'quality'", ":", "q", ",", "\n", "'ssim'", ":", "compare_ssim", "(", "image", ",", "image_compressed", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", ",", "\n", "'psnr'", ":", "compare_psnr", "(", "image", ",", "image_compressed", ",", "data_range", "=", "1", ")", ",", "\n", "'msssim'", ":", "msssim_value", ",", "\n", "'msssim_db'", ":", "-", "10", "*", "np", ".", "log10", "(", "1", "-", "msssim_value", ")", ",", "\n", "'bytes'", ":", "image_bytes", ",", "\n", "'bpp'", ":", "8", "*", "image_bytes", "/", "image", ".", "shape", "[", "0", "]", "/", "image", ".", "shape", "[", "1", "]", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "pbar", ".", "set_postfix", "(", "image_id", "=", "image_id", ",", "quality", "=", "q", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "", "df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'jpeg.csv'", ")", ",", "index", "=", "False", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_jpeg2k_df": [[87, 163], ["helpers.loading.discover_images", "helpers.loading.load_images", "numpy.arange", "os.path.join", "batch_x[].astype", "os.path.isfile", "loguru.logger.info", "pandas.read_csv", "pandas.DataFrame", "df.append.to_csv", "tqdm.tqdm", "enumerate", "enumerate", "glymur.Jp2k", "df.append.append", "pbar.set_postfix", "pbar.update", "len", "len", "compression.jpeg_helpers.jp2bytes", "os.path.getsize", "imageio.imread().astype", "os.path.join", "os.path.join", "imageio.imwrite", "sewar.full_ref.msssim", "os.path.isdir", "os.makedirs", "skimage.measure.compare_ssim", "skimage.measure.compare_psnr", "image.clip", "imageio.imread", "os.path.splitext", "numpy.log10"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jp2bytes"], ["", "def", "get_jpeg2k_df", "(", "directory", ",", "write_files", "=", "False", ",", "effective_bytes", "=", "True", ",", "force_calc", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute and return (as Pandas DF) the rate distortion curve for JPEG 2000. The result is saved\n    as a CSV file in the source directory. If the file exists, the DF is loaded and returned.\n\n    Files are saved as JPEG using glymur.\n    \"\"\"", "\n", "\n", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "directory", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "directory", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "# Get trade-off for JPEG", "\n", "quality_levels", "=", "np", ".", "arange", "(", "25", ",", "45", ",", "1", ")", "\n", "df_jpeg_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'jpeg2000.csv'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "df_jpeg_path", ")", "and", "not", "force_calc", ":", "\n", "        ", "logger", ".", "info", "(", "'Restoring JPEG 2000 stats from {}'", ".", "format", "(", "df_jpeg_path", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_jpeg_path", ",", "index_col", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'image_id'", ",", "'filename'", ",", "'codec'", ",", "'quality'", ",", "'ssim'", ",", "'psnr'", ",", "'msssim'", ",", "'msssim_db'", ",", "'bytes'", ",", "'bpp'", "]", ")", "\n", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "files", ")", "*", "len", "(", "quality_levels", ")", ",", "ncols", "=", "120", ",", "desc", "=", "'JP2k'", ")", "as", "pbar", ":", "\n", "\n", "            ", "for", "image_id", ",", "filename", "in", "enumerate", "(", "files", ")", ":", "\n", "\n", "# Read the original image", "\n", "                ", "image", "=", "batch_x", "[", "image_id", "]", "\n", "\n", "for", "qi", ",", "q", "in", "enumerate", "(", "quality_levels", ")", ":", "\n", "\n", "# TODO Use Glymur to save JPEG 2000 images to a temp file", "\n", "                    ", "image_np", "=", "(", "255", "*", "image", ".", "clip", "(", "0", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "glymur", ".", "Jp2k", "(", "'/tmp/image.jp2'", ",", "data", "=", "image_np", ",", "psnr", "=", "[", "q", "]", ")", "\n", "if", "effective_bytes", ":", "\n", "                        ", "image_bytes", "=", "jpeg_helpers", ".", "jp2bytes", "(", "'/tmp/image.jp2'", ")", "\n", "", "else", ":", "\n", "                        ", "image_bytes", "=", "os", ".", "path", ".", "getsize", "(", "'/tmp/image.jp2'", ")", "\n", "", "image_compressed", "=", "imageio", ".", "imread", "(", "'/tmp/image.jp2'", ")", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "# TODO Use Pillow to save JPEG 2000 images to a memory buffer", "\n", "# TODO This has been disabled = their implementation seems to be invalid", "\n", "# with io.BytesIO() as output:", "\n", "#     image_pillow = PIL.Image.fromarray((255*image.clip(0, 1)).astype(np.uint8))", "\n", "#     image_pillow.save(output, format='jpeg2000', quality_layers=[q])", "\n", "#     image_compressed = imageio.imread(output.getvalue()).astype(np.float) / (2**8 - 1)", "\n", "#     image_bytes = len(output.getvalue())", "\n", "\n", "if", "write_files", ":", "\n", "                        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'jp2_q{:.1f}dB.png'", ".", "format", "(", "q", ")", ")", "\n", "imageio", ".", "imwrite", "(", "image_path", ",", "(", "255", "*", "image_compressed", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "", "msssim_value", "=", "msssim", "(", "image", ",", "image_compressed", ",", "MAX", "=", "1", ")", ".", "real", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "'image_id'", ":", "image_id", ",", "\n", "'filename'", ":", "filename", ",", "\n", "'codec'", ":", "'jpeg2000'", ",", "\n", "'quality'", ":", "q", ",", "\n", "'ssim'", ":", "compare_ssim", "(", "image", ",", "image_compressed", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", ",", "\n", "'psnr'", ":", "compare_psnr", "(", "image", ",", "image_compressed", ",", "data_range", "=", "1", ")", ",", "\n", "'msssim'", ":", "msssim_value", ",", "\n", "'msssim_db'", ":", "-", "10", "*", "np", ".", "log10", "(", "1", "-", "msssim_value", ")", ",", "\n", "'bytes'", ":", "image_bytes", ",", "\n", "'bpp'", ":", "8", "*", "image_bytes", "/", "image", ".", "shape", "[", "0", "]", "/", "image", ".", "shape", "[", "1", "]", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "pbar", ".", "set_postfix", "(", "image_id", "=", "image_id", ",", "quality", "=", "q", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "", "df", ".", "to_csv", "(", "df_jpeg_path", ",", "index", "=", "False", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_bpg_df": [[165, 236], ["helpers.loading.discover_images", "helpers.loading.load_images", "numpy.arange", "os.path.join", "batch_x[].astypre", "os.path.isfile", "loguru.logger.info", "pandas.read_csv", "pandas.DataFrame", "df.append.to_csv", "tqdm.tqdm", "enumerate", "enumerate", "imageio.imwrite", "compression.bpg_helpers.bpg_compress", "df.append.append", "pbar.set_postfix", "pbar.update", "len", "len", "imageio.imread().astype", "compression.bpg_helpers.bpp_of_bpg_image", "round", "os.path.join", "os.path.join", "imageio.imwrite", "sewar.full_ref.msssim", "os.stat", "os.path.isdir", "os.makedirs", "skimage.measure.compare_ssim", "skimage.measure.compare_psnr", "imageio.imread", "os.path.splitext", "numpy.log10", "compression.bpg_helpers.decode_bpg_to_png"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpg_compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpp_of_bpg_image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.decode_bpg_to_png"], ["", "def", "get_bpg_df", "(", "directory", ",", "write_files", "=", "False", ",", "effective_bytes", "=", "True", ",", "force_calc", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute and return (as Pandas DF) the rate distortion curve for BPG. The result is saved\n    as a CSV file in the source directory. If the file exists, the DF is loaded and returned.\n\n    The files are saved using the reference codec: https://bellard.org/bpg/\n    \"\"\"", "\n", "\n", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "directory", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "directory", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astypre", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "quality_levels", "=", "np", ".", "arange", "(", "10", ",", "40", ",", "1", ")", "\n", "df_jpeg_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'bpg.csv'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "df_jpeg_path", ")", "and", "not", "force_calc", ":", "\n", "        ", "logger", ".", "info", "(", "'Restoring BPG stats from {}'", ".", "format", "(", "df_jpeg_path", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_jpeg_path", ",", "index_col", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'image_id'", ",", "'filename'", ",", "'codec'", ",", "'quality'", ",", "'ssim'", ",", "'psnr'", ",", "'msssim'", ",", "'msssim_db'", ",", "'bytes'", ",", "'bpp'", "]", ")", "\n", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "files", ")", "*", "len", "(", "quality_levels", ")", ",", "ncols", "=", "120", ",", "desc", "=", "'BPG'", ")", "as", "pbar", ":", "\n", "\n", "            ", "for", "image_id", ",", "filename", "in", "enumerate", "(", "files", ")", ":", "\n", "\n", "# Read the original image", "\n", "                ", "image", "=", "batch_x", "[", "image_id", "]", "\n", "\n", "for", "qi", ",", "q", "in", "enumerate", "(", "quality_levels", ")", ":", "\n", "\n", "# Compress to BPG", "\n", "# Save as temporary file", "\n", "                    ", "imageio", ".", "imwrite", "(", "'/tmp/image.png'", ",", "(", "255", "*", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "bpp_path", "=", "bpg_helpers", ".", "bpg_compress", "(", "'/tmp/image.png'", ",", "q", ",", "'/tmp'", ")", "\n", "image_compressed", "=", "imageio", ".", "imread", "(", "bpg_helpers", ".", "decode_bpg_to_png", "(", "bpp_path", ")", ")", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "if", "effective_bytes", ":", "\n", "                        ", "bpp", "=", "bpg_helpers", ".", "bpp_of_bpg_image", "(", "bpp_path", ")", "\n", "image_bytes", "=", "round", "(", "bpp", "*", "image", ".", "shape", "[", "0", "]", "*", "image", ".", "shape", "[", "1", "]", "/", "8", ")", "\n", "", "else", ":", "\n", "                        ", "image_bytes", "=", "os", ".", "stat", "(", "bpp_path", ")", ".", "st_size", "\n", "bpp", "=", "8", "*", "image_bytes", "/", "image", ".", "shape", "[", "0", "]", "/", "image", ".", "shape", "[", "1", "]", "\n", "\n", "", "if", "write_files", ":", "\n", "                        ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'bpg_q{:03d}.png'", ".", "format", "(", "q", ")", ")", "\n", "imageio", ".", "imwrite", "(", "image_path", ",", "(", "255", "*", "image_compressed", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "", "msssim_value", "=", "msssim", "(", "image", ",", "image_compressed", ",", "MAX", "=", "1", ")", ".", "real", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "'image_id'", ":", "image_id", ",", "\n", "'filename'", ":", "filename", ",", "\n", "'codec'", ":", "'bpg'", ",", "\n", "'quality'", ":", "q", ",", "\n", "'ssim'", ":", "compare_ssim", "(", "image", ",", "image_compressed", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", ",", "\n", "'psnr'", ":", "compare_psnr", "(", "image", ",", "image_compressed", ",", "data_range", "=", "1", ")", ",", "\n", "'msssim'", ":", "msssim_value", ",", "\n", "'msssim_db'", ":", "-", "10", "*", "np", ".", "log10", "(", "1", "-", "msssim_value", ")", ",", "\n", "'bytes'", ":", "image_bytes", ",", "\n", "'bpp'", ":", "bpp", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "pbar", ".", "set_postfix", "(", "image_id", "=", "image_id", ",", "quality", "=", "q", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "", "df", ".", "to_csv", "(", "df_jpeg_path", ",", "index", "=", "False", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.get_dcn_df": [[238, 313], ["helpers.loading.discover_images", "helpers.loading.load_images", "pandas.DataFrame", "list", "loguru.logger.info", "os.path.join", "batch_x[].astype", "pathlib.Path().glob", "os.path.isfile", "loguru.logger.info", "pandas.read_csv", "df.append.to_csv", "len", "loguru.logger.info", "compression.codec.restore", "enumerate", "pathlib.Path", "df.append.append", "os.path.split", "compression.codec.simulate_compression", "codec.restore.compress", "helpers.stats.entropy", "helpers.stats.entropy", "os.path.join", "os.path.join", "imageio.imwrite", "sewar.full_ref.msssim", "helpers.fsutil.split", "str", "codec.restore.get_codebook", "loguru.logger.error", "os.path.isdir", "os.makedirs", "os.path.relpath().replace", "skimage.measure.compare_ssim", "skimage.measure.compare_psnr", "len", "os.path.splitext", "codec.restore.model_code.replace", "numpy.log10", "os.path.relpath", "os.path.split", "str"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.codec.simulate_compression", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "get_dcn_df", "(", "directory", ",", "model_directory", ",", "write_files", "=", "False", ",", "force_calc", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Compute and return (as Pandas DF) the rate distortion curve for the learned DCN codec.\n    The result is saved as a CSV file in the source directory. If the file exists, the DF\n    is loaded and returned.\n    \"\"\"", "\n", "\n", "# Discover test files", "\n", "files", ",", "_", "=", "loading", ".", "discover_images", "(", "directory", ",", "n_images", "=", "-", "1", ",", "v_images", "=", "0", ")", "\n", "batch_x", "=", "loading", ".", "load_images", "(", "files", ",", "directory", ",", "load", "=", "'y'", ")", "\n", "batch_x", "=", "batch_x", "[", "'y'", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "# Create a new table for the DCN", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "columns", "=", "[", "'image_id'", ",", "'filename'", ",", "'model_dir'", ",", "'codec'", ",", "'ssim'", ",", "'psnr'", ",", "'msssim'", ",", "'msssim_db'", ",", "'entropy'", ",", "'bytes'", ",", "'bpp'", ",", "'layers'", ",", "'quantization'", ",", "'entropy_reg'", ",", "'codebook'", ",", "'latent'", ",", "'latent_shape'", ",", "'n_features'", "]", ")", "\n", "\n", "# Discover available models", "\n", "model_dirs", "=", "list", "(", "Path", "(", "model_directory", ")", ".", "glob", "(", "'**/progress.json'", ")", ")", "\n", "logger", ".", "info", "(", "'Found {} models'", ".", "format", "(", "len", "(", "model_dirs", ")", ")", ")", "\n", "\n", "df_path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'dcn-{}.csv'", ".", "format", "(", "[", "x", "for", "x", "in", "fsutil", ".", "split", "(", "model_directory", ")", "if", "len", "(", "x", ")", ">", "0", "]", "[", "-", "1", "]", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "df_path", ")", "and", "not", "force_calc", ":", "\n", "        ", "logger", ".", "info", "(", "'Restoring DCN stats from {}'", ".", "format", "(", "df_path", ")", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "df_path", ",", "index_col", "=", "False", ")", "\n", "", "else", ":", "\n", "\n", "        ", "for", "model_dir", "in", "model_dirs", ":", "\n", "            ", "logger", ".", "info", "(", "'Processing model dir: {}'", ".", "format", "(", "model_dir", ")", ")", "\n", "dcn", "=", "codec", ".", "restore", "(", "os", ".", "path", ".", "split", "(", "str", "(", "model_dir", ")", ")", "[", "0", "]", ",", "batch_x", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# Dump compressed images", "\n", "for", "image_id", ",", "filename", "in", "enumerate", "(", "files", ")", ":", "\n", "\n", "                ", "try", ":", "\n", "                    ", "batch_y", ",", "image_bytes", "=", "codec", ".", "simulate_compression", "(", "batch_x", "[", "image_id", ":", "image_id", "+", "1", "]", ",", "dcn", ")", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", "[", "image_id", ":", "image_id", "+", "1", "]", ")", "\n", "entropy", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "dcn", ".", "get_codebook", "(", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "logger", ".", "error", "(", "'Error while processing {} with {} : {}'", ".", "format", "(", "filename", ",", "dcn", ".", "model_code", ",", "e", ")", ")", "\n", "raise", "e", "\n", "\n", "", "if", "write_files", ":", "\n", "                    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "image_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "dcn", ".", "model_code", ".", "replace", "(", "'/'", ",", "'-'", ")", "+", "'.png'", ")", "\n", "imageio", ".", "imwrite", "(", "image_path", ",", "(", "255", "*", "batch_y", "[", "0", "]", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "", "msssim_value", "=", "msssim", "(", "batch_x", "[", "image_id", "]", ",", "batch_y", "[", "0", "]", ",", "MAX", "=", "1", ")", ".", "real", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "'image_id'", ":", "image_id", ",", "\n", "'filename'", ":", "filename", ",", "\n", "'model_dir'", ":", "os", ".", "path", ".", "relpath", "(", "os", ".", "path", ".", "split", "(", "str", "(", "model_dir", ")", ")", "[", "0", "]", ",", "model_directory", ")", ".", "replace", "(", "dcn", ".", "scoped_name", ",", "''", ")", ",", "\n", "'codec'", ":", "dcn", ".", "model_code", ",", "\n", "'ssim'", ":", "compare_ssim", "(", "batch_x", "[", "image_id", "]", ",", "batch_y", "[", "0", "]", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", ",", "\n", "'psnr'", ":", "compare_psnr", "(", "batch_x", "[", "image_id", "]", ",", "batch_y", "[", "0", "]", ",", "data_range", "=", "1", ")", ",", "\n", "'msssim'", ":", "msssim_value", ",", "\n", "'msssim_db'", ":", "-", "10", "*", "np", ".", "log10", "(", "1", "-", "msssim_value", ")", ",", "\n", "'entropy'", ":", "entropy", ",", "\n", "'bytes'", ":", "image_bytes", ",", "\n", "'bpp'", ":", "8", "*", "image_bytes", "/", "batch_x", "[", "image_id", "]", ".", "shape", "[", "0", "]", "/", "batch_x", "[", "image_id", "]", ".", "shape", "[", "1", "]", ",", "\n", "'layers'", ":", "dcn", ".", "n_layers", "if", "'n_layers'", "in", "dcn", ".", "_h", "else", "None", ",", "\n", "'quantization'", ":", "'{}-{:.0f}bpf'", ".", "format", "(", "dcn", ".", "_h", ".", "rounding", ",", "dcn", ".", "latent_bpf", ")", ",", "\n", "'entropy_reg'", ":", "dcn", ".", "entropy_weight", ",", "\n", "'codebook'", ":", "dcn", ".", "_h", ".", "rounding", ",", "\n", "'latent'", ":", "dcn", ".", "n_latent", ",", "\n", "'latent_shape'", ":", "'{}x{}x{}'", ".", "format", "(", "*", "dcn", ".", "latent_shape", "[", "1", ":", "]", ")", ",", "\n", "'n_features'", ":", "dcn", ".", "latent_shape", "[", "-", "1", "]", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "df", ".", "to_csv", "(", "df_path", ",", "index", "=", "False", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.load_data": [[315, 364], ["isinstance", "isinstance", "labels.append", "pandas.read_csv", "selectors.items", "df_all.append", "plots.items", "ValueError", "os.path.join", "len", "ValueError", "labels.append", "pandas.read_csv", "selectors.items", "df_all.append", "os.path.splitext", "isinstance", "os.path.join", "len", "ValueError", "isinstance", "df[].str.match", "df[].str.match"], "function", ["None"], ["", "def", "load_data", "(", "plots", ",", "dirname", ")", ":", "\n", "    ", "\"\"\"\n    Returns data frames with numerical results for specified codecs [and settings]\n\n    Example definition (can be both a list or a dictionary):\n\n    plots = OrderedDict()\n    plots['jpg'] = ('jpeg.csv', {})\n    plots['jp2'] = ('jpeg2000.csv', {})\n    plots['bpg'] = ('bpg.csv', {})\n    plots['dcn'] = ('dcn-7-raw.csv', {'model_dir': '.*basic/'})\n\n    Tuple structure: (filename, data filtering conditions - dict {column: value})\n\n    \"\"\"", "\n", "\n", "# Load all needed tables and setup legend labels", "\n", "labels", "=", "[", "]", "\n", "df_all", "=", "[", "]", "\n", "\n", "if", "isinstance", "(", "plots", ",", "list", ")", ":", "\n", "        ", "for", "filename", ",", "selectors", "in", "plots", ":", "\n", "            ", "labels", ".", "append", "(", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "0", "]", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "filename", ")", ",", "index_col", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "selectors", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "str", ")", "and", "'*'", "in", "v", ":", "\n", "                    ", "df", "=", "df", "[", "df", "[", "k", "]", ".", "str", ".", "match", "(", "v", ")", "]", "\n", "", "else", ":", "\n", "                    ", "df", "=", "df", "[", "df", "[", "k", "]", "==", "v", "]", "\n", "", "", "if", "len", "(", "df", ")", "==", "0", ":", "\n", "                ", "raise", "(", "ValueError", "(", "'No rows matched for column {}'", ".", "format", "(", "k", ")", ")", ")", "\n", "", "df_all", ".", "append", "(", "df", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "plots", ",", "dict", ")", ":", "\n", "        ", "for", "key", ",", "(", "filename", ",", "selectors", ")", "in", "plots", ".", "items", "(", ")", ":", "\n", "            ", "labels", ".", "append", "(", "key", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "filename", ")", ",", "index_col", "=", "False", ")", "\n", "for", "k", ",", "v", "in", "selectors", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "str", ")", "and", "'*'", "in", "v", ":", "\n", "                    ", "df", "=", "df", "[", "df", "[", "k", "]", ".", "str", ".", "match", "(", "v", ")", "]", "\n", "", "else", ":", "\n", "                    ", "df", "=", "df", "[", "df", "[", "k", "]", "==", "v", "]", "\n", "", "", "if", "len", "(", "df", ")", "==", "0", ":", "\n", "                ", "raise", "(", "ValueError", "(", "'No rows matched for column {}'", ".", "format", "(", "k", ")", ")", ")", "\n", "", "df_all", ".", "append", "(", "df", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported plot definition!'", ")", "\n", "\n", "", "return", "df_all", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_plot": [[366, 390], ["ValueError"], "function", ["None"], ["", "def", "setup_plot", "(", "metric", ")", ":", "\n", "    ", "if", "metric", "==", "'psnr'", ":", "\n", "        ", "y_min", "=", "25", "\n", "y_max", "=", "45", "\n", "metric_label", "=", "'PSNR [dB]'", "\n", "\n", "", "elif", "metric", "==", "'msssim_db'", ":", "\n", "        ", "y_min", "=", "10", "\n", "y_max", "=", "32", "\n", "metric_label", "=", "'MS-SSIM [dB]'", "\n", "\n", "", "elif", "metric", "==", "'ssim'", ":", "\n", "        ", "y_min", "=", "0.8", "\n", "y_max", "=", "1", "\n", "metric_label", "=", "'SSIM'", "\n", "\n", "", "elif", "metric", "==", "'msssim'", ":", "\n", "        ", "y_min", "=", "0.9", "\n", "y_max", "=", "1", "\n", "metric_label", "=", "'MS-SSIM'", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported metric!'", ")", "\n", "\n", "", "return", "y_min", ",", "y_max", ",", "metric_label", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_fit": [[392, 412], ["numpy.log", "numpy.clip", "numpy.exp"], "function", ["None"], ["", "def", "setup_fit", "(", "metric", ")", ":", "\n", "# Define a parametric model for the trade-off curve", "\n", "    ", "if", "metric", "in", "{", "'ssim'", ",", "'msssim'", "}", ":", "\n", "# These bounds work well for baseline fitting", "\n", "        ", "fit_bounds", "=", "(", "[", "1e-4", ",", "1e-2", ",", "-", "3", ",", "-", "0.5", "]", ",", "[", "5", ",", "15", ",", "5", ",", "0.5", "]", ")", "\n", "# These bounds work better for optimized DCN codecs - there are some weird outliers in the data", "\n", "# fit_bounds = ([0.1, 1e-5, -1, 0], [3, 10, 7, 0.1])", "\n", "\n", "def", "func", "(", "x", ",", "a", ",", "b", ",", "c", ",", "d", ")", ":", "\n", "            ", "return", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "b", "*", "x", "**", "a", "+", "c", ")", ")", "-", "d", "\n", "", "", "else", ":", "\n", "# These bounds work well for baseline fitting", "\n", "        ", "fit_bounds", "=", "(", "[", "1e-4", ",", "1e-5", ",", "1e-2", ",", "-", "50", "]", ",", "[", "100", ",", "100", ",", "3", ",", "50", "]", ")", "\n", "# These bounds work better for optimized DCN codecs - there are some weird outliers in the data", "\n", "# fit_bounds = ([1e-4, 1, 1e-2, -20], [20, 50, 1, 20])", "\n", "\n", "def", "func", "(", "x", ",", "a", ",", "b", ",", "c", ",", "d", ")", ":", "\n", "            ", "return", "a", "*", "np", ".", "log", "(", "np", ".", "clip", "(", "b", "*", "x", "**", "c", "+", "d", ",", "a_min", "=", "1e-9", ",", "a_max", "=", "1e9", ")", ")", "\n", "\n", "", "", "return", "func", ",", "fit_bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.plot_curve": [[414, 563], ["helpers.utils.match_option", "helpers.utils.match_option", "ratedistortion.load_data", "ratedistortion.setup_fit", "ratedistortion.setup_plot", "enumerate", "len", "axes.set_xlim", "axes.set_ylim", "axes.set_title", "axes.set_xlabel", "axes.set_ylabel", "len", "[].unique().tolist", "numpy.linspace", "dfc.loc[].unique", "len", "len", "dfc[].apply", "max", "min", "numpy.zeros", "enumerate", "numpy.nanmean", "axes.plot", "[].replace", "axes.legend", "t.set_text", "[].unique", "ratedistortion.setup_fit.func", "len", "loguru.logger.info", "min", "axes.plot", "seaborn.scatterplot", "axes.plot", "os.path.split", "t.get_text().replace", "len", "len", "numpy.abs().reshape", "numpy.ones_like().reshape", "scipy.optimize.curve_fit", "ratedistortion.setup_fit.func", "numpy.mean", "mse_l.append", "dfa.groupby", "dfa.groupby", "min", "ValueError", "x.min", "x.max", "numpy.power", "loguru.logger.warning", "loguru.logger.error", "numpy.mean", "numpy.max", "min", "dfa.groupby.mean", "dfa.groupby.mean", "len", "len", "len", "dfc.loc[].unique", "t.get_text", "numpy.abs", "numpy.ones_like", "min", "dfc[].unique", "dfc[].unique", "dfc[].unique", "sum"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.load_data", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_fit", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_plot", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "plot_curve", "(", "plots", ",", "axes", ",", "\n", "dirname", "=", "'./data/rgb/clic256'", ",", "\n", "images", "=", "[", "]", ",", "\n", "plot", "=", "'fit'", ",", "\n", "draw_markers", "=", "None", ",", "\n", "metric", "=", "'ssim'", ",", "\n", "title", "=", "None", ",", "\n", "add_legend", "=", "True", ",", "\n", "marker_legend", "=", "True", ",", "\n", "baseline_count", "=", "3", ",", "\n", "update_ylim", "=", "False", ")", ":", "\n", "\n", "# Parse input parameters", "\n", "    ", "draw_markers", "=", "draw_markers", "if", "draw_markers", "is", "not", "None", "else", "len", "(", "images", ")", "==", "1", "\n", "plot", "=", "helpers", ".", "utils", ".", "match_option", "(", "plot", ",", "[", "'fit'", ",", "'aggregate'", "]", ")", "\n", "\n", "df_all", ",", "labels", "=", "load_data", "(", "plots", ",", "dirname", ")", "\n", "\n", "if", "len", "(", "images", ")", "==", "0", ":", "\n", "        ", "images", "=", "df_all", "[", "0", "]", "[", "'image_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Plot setup", "\n", "", "func", ",", "fit_bounds", "=", "setup_fit", "(", "metric", ")", "\n", "y_min", ",", "y_max", ",", "metric_label", "=", "setup_plot", "(", "metric", ")", "\n", "\n", "# Select measurements for specific images, if specified", "\n", "for", "dfc", "in", "df_all", ":", "\n", "        ", "if", "len", "(", "images", ")", ">", "0", ":", "\n", "            ", "dfc", "[", "'selected'", "]", "=", "dfc", "[", "'image_id'", "]", ".", "apply", "(", "lambda", "x", ":", "x", "in", "images", ")", "\n", "", "else", ":", "\n", "            ", "dfc", "[", "'selected'", "]", "=", "True", "\n", "\n", "# Setup drawing styles", "\n", "", "", "styles", "=", "[", "[", "'r-'", ",", "'rx'", "]", ",", "[", "'b--'", ",", "'b+'", "]", ",", "[", "'k:'", ",", "'k2'", "]", ",", "[", "'g-'", ",", "'gx'", "]", ",", "[", "'m-'", ",", "'gx'", "]", ",", "[", "'m--'", ",", "'gx'", "]", ",", "[", "'m-.'", ",", "'gx'", "]", ",", "[", "'m:'", ",", "'gx'", "]", "]", "\n", "avg_markers", "=", "[", "''", ",", "''", ",", "''", ",", "'o'", ",", "'o'", ",", "'2'", ",", "'+'", ",", "'x'", ",", "'^'", ",", "'.'", "]", "\n", "\n", "# To retain consistent styles across plots, adjust the lists based on the number of baseline methods", "\n", "if", "baseline_count", "<", "3", ":", "\n", "        ", "styles", "=", "styles", "[", "(", "3", "-", "baseline_count", ")", ":", "]", "\n", "avg_markers", "=", "avg_markers", "[", "(", "3", "-", "baseline_count", ")", ":", "]", "\n", "\n", "# Iterate over defined plots and draw data accordingly", "\n", "", "for", "index", ",", "dfc", "in", "enumerate", "(", "df_all", ")", ":", "\n", "\n", "        ", "x", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "metric", "]", ".", "values", "\n", "\n", "X", "=", "np", ".", "linspace", "(", "max", "(", "[", "0", ",", "x", ".", "min", "(", ")", "*", "0.9", "]", ")", ",", "min", "(", "[", "5", ",", "x", ".", "max", "(", ")", "*", "1.1", "]", ")", ",", "256", ")", "\n", "\n", "if", "plot", "==", "'fit'", ":", "\n", "# Fit individual images to a curve, then average the curves", "\n", "\n", "            ", "Y", "=", "np", ".", "zeros", "(", "(", "len", "(", "images", ")", ",", "len", "(", "X", ")", ")", ")", "\n", "mse_l", "=", "[", "]", "\n", "\n", "for", "image_no", ",", "image_id", "in", "enumerate", "(", "images", ")", ":", "\n", "\n", "                ", "x", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "&", "(", "dfc", "[", "'image_id'", "]", "==", "image_id", ")", ",", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "&", "(", "dfc", "[", "'image_id'", "]", "==", "image_id", ")", ",", "metric", "]", ".", "values", "\n", "\n", "# Allow for larger errors for lower SSIM values", "\n", "if", "metric", "in", "[", "'ssim'", ",", "'msssim'", "]", ":", "\n", "                    ", "sigma", "=", "np", ".", "abs", "(", "1", "-", "y", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "", "else", ":", "\n", "                    ", "sigma", "=", "np", ".", "ones_like", "(", "y", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "\n", "", "try", ":", "\n", "                    ", "popt", ",", "pcov", "=", "curve_fit", "(", "func", ",", "x", ",", "y", ",", "bounds", "=", "fit_bounds", ",", "maxfev", "=", "10000", ",", "sigma", "=", "sigma", ")", "\n", "y_est", "=", "func", "(", "x", ",", "*", "popt", ")", "\n", "mse", "=", "np", ".", "mean", "(", "np", ".", "power", "(", "y", "-", "y_est", ",", "2", ")", ")", "\n", "mse_l", ".", "append", "(", "mse", ")", "\n", "if", "mse", ">", "0.5", ":", "\n", "                        ", "logger", ".", "warning", "(", "'WARNING Large MSE for {}:{} = {:.2f}'", ".", "format", "(", "labels", "[", "index", "]", ",", "image_no", ",", "mse", ")", ")", "\n", "\n", "", "", "except", "RuntimeError", ":", "\n", "                    ", "logger", ".", "error", "(", "f'{labels[index]} image ={image_id}, bpp ={x} y ={y}'", ")", "\n", "\n", "", "Y", "[", "image_no", "]", "=", "func", "(", "X", ",", "*", "popt", ")", "\n", "\n", "", "if", "len", "(", "images", ")", ">", "1", ":", "\n", "                ", "logger", ".", "info", "(", "'Fit summary - MSE for {} av={:.2f} max={:.2f}'", ".", "format", "(", "labels", "[", "index", "]", ",", "np", ".", "mean", "(", "mse_l", ")", ",", "np", ".", "max", "(", "mse_l", ")", ")", ")", "\n", "\n", "", "yy", "=", "np", ".", "nanmean", "(", "Y", ",", "axis", "=", "0", ")", "\n", "axes", ".", "plot", "(", "X", ",", "yy", ",", "styles", "[", "index", "]", "[", "0", "]", ",", "label", "=", "labels", "[", "index", "]", "if", "add_legend", "else", "None", ")", "\n", "y_min", "=", "min", "(", "[", "y_min", ",", "min", "(", "yy", ")", "]", ")", "if", "update_ylim", "else", "y_min", "\n", "\n", "", "elif", "plot", "==", "'aggregate'", ":", "\n", "# For each quality level (QF, #channels) find the average quality level", "\n", "            ", "dfa", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "]", "\n", "\n", "if", "'n_features'", "in", "dfa", ":", "\n", "                ", "dfg", "=", "dfa", ".", "groupby", "(", "'n_features'", ")", "\n", "", "else", ":", "\n", "                ", "dfg", "=", "dfa", ".", "groupby", "(", "'quality'", ")", "\n", "\n", "", "x", "=", "dfg", ".", "mean", "(", ")", "[", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfg", ".", "mean", "(", ")", "[", "metric", "]", ".", "values", "\n", "\n", "axes", ".", "plot", "(", "x", ",", "y", ",", "styles", "[", "index", "]", "[", "0", "]", ",", "label", "=", "labels", "[", "index", "]", "if", "add_legend", "else", "None", ",", "marker", "=", "avg_markers", "[", "index", "]", ",", "alpha", "=", "0.65", ")", "\n", "y_min", "=", "min", "(", "[", "y_min", ",", "min", "(", "y", ")", "]", ")", "if", "update_ylim", "else", "y_min", "\n", "\n", "", "elif", "plot", "==", "'none'", ":", "\n", "            ", "pass", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported plot type!'", ")", "\n", "\n", "", "if", "draw_markers", ":", "\n", "\n", "            ", "if", "'entropy_reg'", "in", "dfc", ":", "\n", "\n", "# No need to draw legend if multiple DCNs are plotted", "\n", "                ", "detailed_legend", "=", "'full'", "if", "marker_legend", "and", "index", "==", "baseline_count", "else", "False", "\n", "\n", "style_mapping", "=", "{", "}", "\n", "\n", "if", "'n_features'", "in", "dfc", "and", "len", "(", "dfc", "[", "'n_features'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                    ", "style_mapping", "[", "'hue'", "]", "=", "'n_features'", "\n", "\n", "", "if", "'entropy_reg'", "in", "dfc", "and", "len", "(", "dfc", "[", "'entropy_reg'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                    ", "style_mapping", "[", "'size'", "]", "=", "'entropy_reg'", "\n", "\n", "", "if", "'quantization'", "in", "dfc", "and", "len", "(", "dfc", "[", "'quantization'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                    ", "style_mapping", "[", "'style'", "]", "=", "'quantization'", "\n", "\n", "", "sns", ".", "scatterplot", "(", "data", "=", "dfc", "[", "dfc", "[", "'selected'", "]", "]", ",", "x", "=", "'bpp'", ",", "y", "=", "metric", ",", "\n", "palette", "=", "\"Set2\"", ",", "ax", "=", "axes", ",", "legend", "=", "detailed_legend", ",", "\n", "**", "style_mapping", ")", "\n", "\n", "", "else", ":", "\n", "                ", "axes", ".", "plot", "(", "x", ",", "y", ",", "styles", "[", "index", "]", "[", "1", "]", ",", "alpha", "=", "10", "/", "(", "sum", "(", "dfc", "[", "'selected'", "]", ")", ")", ")", "\n", "\n", "", "", "", "n_images", "=", "len", "(", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'image_id'", "]", ".", "unique", "(", ")", ")", "\n", "\n", "title", "=", "'{} : {}'", ".", "format", "(", "\n", "title", "if", "title", "is", "not", "None", "else", "os", ".", "path", ".", "split", "(", "dirname", ")", "[", "-", "1", "]", ",", "\n", "'{} images'", ".", "format", "(", "n_images", ")", "if", "n_images", ">", "1", "else", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'filename'", "]", ".", "unique", "(", ")", "[", "0", "]", ".", "replace", "(", "'.png'", ",", "''", ")", "\n", ")", "\n", "\n", "# Fixes problems with rendering using the LaTeX backend", "\n", "if", "add_legend", ":", "\n", "        ", "for", "t", "in", "axes", ".", "legend", "(", ")", ".", "texts", ":", "\n", "            ", "t", ".", "set_text", "(", "t", ".", "get_text", "(", ")", ".", "replace", "(", "'_'", ",", "'-'", ")", ")", "\n", "\n", "", "", "axes", ".", "set_xlim", "(", "[", "-", "0.1", ",", "3.1", "]", ")", "\n", "axes", ".", "set_ylim", "(", "[", "y_min", "*", "0.99", ",", "y_max", "]", ")", "\n", "axes", ".", "set_title", "(", "title", ")", "\n", "axes", ".", "set_xlabel", "(", "'Effective bpp'", ")", "\n", "axes", ".", "set_ylabel", "(", "metric_label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.plot_bulk": [[565, 748], ["helpers.utils.match_option", "helpers.utils.match_option", "ratedistortion.load_data", "loguru.logger.info", "int", "int", "ratedistortion.setup_fit", "ratedistortion.setup_plot", "matplotlib.subplots", "fig.set_size_inches", "hasattr", "enumerate", "dirname.endswith", "dirname.endswith", "numpy.ceil", "numpy.ceil", "axes.axis", "enumerate", "len", "axes.set_xlim", "axes.set_ylim", "axes.legend", "axes.set_title", "len", "df_all[].image_id.unique().tolist", "numpy.sqrt", "axes.axis", "numpy.linspace", "dfc.loc[].unique", "axes.set_xlabel", "axes.set_ylabel", "len", "len", "dfc[].apply", "max", "min", "numpy.zeros", "enumerate", "numpy.mean", "numpy.nanmean", "axes.plot", "[].replace", "axes.legend", "t.set_text", "df_all[].image_id.unique", "dfc.image_id.unique", "ratedistortion.setup_fit.func", "loguru.logger.info", "min", "axes.plot", "os.path.split", "t.get_text().replace", "len", "len", "numpy.abs().reshape", "numpy.ones_like().reshape", "scipy.optimize.curve_fit", "ratedistortion.setup_fit.func", "numpy.mean", "mse_l.append", "dfa.groupby", "dfa.groupby", "min", "ValueError", "seaborn.scatterplot", "axes.plot", "x.min", "x.max", "numpy.power", "loguru.logger.warning", "loguru.logger.error", "numpy.mean", "numpy.max", "min", "dfa.groupby.mean", "dfa.groupby.mean", "dfc.loc[].unique", "t.get_text", "numpy.abs", "numpy.ones_like", "min", "len", "len", "len", "dfc[].unique", "dfc[].unique", "dfc[].unique"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.load_data", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_fit", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.ratedistortion.setup_plot", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "plot_bulk", "(", "plots", ",", "dirname", ",", "plot_images", ",", "metric", ",", "plot", ",", "baseline_count", "=", "3", ",", "add_legend", "=", "True", ",", "max_bpp", "=", "5", ",", "\n", "draw_markers", "=", "1", ")", ":", "\n", "    ", "plot", "=", "helpers", ".", "utils", ".", "match_option", "(", "plot", ",", "[", "'fit'", ",", "'aggregate'", "]", ")", "\n", "if", "dirname", ".", "endswith", "(", "'/'", ")", "or", "dirname", ".", "endswith", "(", "'\\\\'", ")", ":", "\n", "        ", "dirname", "=", "dirname", "[", ":", "-", "1", "]", "\n", "\n", "# Load data and select images for plotting", "\n", "", "df_all", ",", "labels", "=", "load_data", "(", "plots", ",", "dirname", ")", "\n", "plot_images", "=", "plot_images", "if", "len", "(", "plot_images", ")", ">", "0", "else", "[", "-", "1", "]", "+", "df_all", "[", "0", "]", ".", "image_id", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "logger", ".", "info", "(", "f'Selected images: {plot_images}'", ")", "\n", "\n", "images_x", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "len", "(", "plot_images", ")", ")", ")", ")", "\n", "images_y", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "plot_images", ")", "/", "images_x", ")", ")", "\n", "\n", "update_ylim", "=", "False", "\n", "marker_legend", "=", "False", "\n", "\n", "# Plot setup", "\n", "func", ",", "fit_bounds", "=", "setup_fit", "(", "metric", ")", "\n", "y_min", ",", "y_max", ",", "metric_label", "=", "setup_plot", "(", "metric", ")", "\n", "\n", "# Setup drawing styles", "\n", "styles", "=", "[", "[", "'r-'", ",", "'rx'", "]", ",", "[", "'b--'", ",", "'b+'", "]", ",", "[", "'k:'", ",", "'k2'", "]", ",", "[", "'g-'", ",", "'gx'", "]", ",", "[", "'m-'", ",", "'gx'", "]", ",", "[", "'m--'", ",", "'gx'", "]", ",", "[", "'m-.'", ",", "'gx'", "]", ",", "\n", "[", "'m:'", ",", "'gx'", "]", "]", "\n", "avg_markers", "=", "[", "''", ",", "''", ",", "''", ",", "'o'", ",", "'o'", ",", "'2'", ",", "'+'", ",", "'X'", ",", "'^'", ",", "'.'", "]", "\n", "\n", "# To retain consistent styles across plots, adjust the lists based on the number of baseline methods", "\n", "if", "baseline_count", "<", "3", ":", "\n", "        ", "styles", "=", "styles", "[", "(", "3", "-", "baseline_count", ")", ":", "]", "\n", "avg_markers", "=", "avg_markers", "[", "(", "3", "-", "baseline_count", ")", ":", "]", "\n", "\n", "", "mse_labels", "=", "{", "}", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "images_y", ",", "images_x", ",", "sharex", "=", "True", ",", "sharey", "=", "True", ")", "\n", "fig", ".", "set_size_inches", "(", "(", "images_x", "*", "6", ",", "images_y", "*", "4", ")", ")", "\n", "\n", "if", "hasattr", "(", "ax", ",", "'flat'", ")", ":", "\n", "        ", "for", "axes", "in", "ax", ".", "flat", ":", "\n", "            ", "axes", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "", "for", "ax_id", ",", "image_id", "in", "enumerate", "(", "plot_images", ")", ":", "\n", "\n", "        ", "if", "images_y", ">", "1", ":", "\n", "            ", "axes", "=", "ax", "[", "ax_id", "//", "images_x", ",", "ax_id", "%", "images_x", "]", "\n", "", "elif", "images_x", ">", "1", ":", "\n", "            ", "axes", "=", "ax", "[", "ax_id", "%", "images_x", "]", "\n", "", "else", ":", "\n", "            ", "axes", "=", "ax", "\n", "\n", "", "axes", ".", "axis", "(", "'on'", ")", "\n", "\n", "# Select measurements for a specific image, if specified", "\n", "for", "dfc", "in", "df_all", ":", "\n", "            ", "if", "image_id", ">=", "0", ":", "\n", "                ", "dfc", "[", "'selected'", "]", "=", "dfc", "[", "'image_id'", "]", ".", "apply", "(", "lambda", "x", ":", "x", "==", "image_id", ")", "\n", "", "else", ":", "\n", "                ", "dfc", "[", "'selected'", "]", "=", "True", "\n", "\n", "", "", "for", "index", ",", "dfc", "in", "enumerate", "(", "df_all", ")", ":", "\n", "\n", "            ", "x", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "metric", "]", ".", "values", "\n", "\n", "X", "=", "np", ".", "linspace", "(", "max", "(", "[", "0", ",", "x", ".", "min", "(", ")", "*", "0.9", "]", ")", ",", "min", "(", "[", "5", ",", "x", ".", "max", "(", ")", "*", "1.1", "]", ")", ",", "256", ")", "\n", "\n", "if", "plot", "==", "'fit'", ":", "\n", "# Fit individual images to a curve, then average the curves", "\n", "\n", "                ", "if", "image_id", ">=", "0", ":", "\n", "                    ", "images", "=", "[", "image_id", "]", "\n", "", "else", ":", "\n", "                    ", "images", "=", "dfc", ".", "image_id", ".", "unique", "(", ")", "\n", "\n", "", "Y", "=", "np", ".", "zeros", "(", "(", "len", "(", "images", ")", ",", "len", "(", "X", ")", ")", ")", "\n", "mse_l", "=", "[", "]", "\n", "\n", "for", "image_no", ",", "imid", "in", "enumerate", "(", "images", ")", ":", "\n", "\n", "                    ", "x", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "&", "(", "dfc", "[", "'image_id'", "]", "==", "imid", ")", ",", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "&", "(", "dfc", "[", "'image_id'", "]", "==", "imid", ")", ",", "metric", "]", ".", "values", "\n", "\n", "# Allow for larger errors for lower SSIM values", "\n", "if", "metric", "in", "[", "'ssim'", ",", "'msssim'", "]", ":", "\n", "                        ", "sigma", "=", "np", ".", "abs", "(", "1", "-", "y", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "", "else", ":", "\n", "                        ", "sigma", "=", "np", ".", "ones_like", "(", "y", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "\n", "", "try", ":", "\n", "                        ", "popt", ",", "pcov", "=", "curve_fit", "(", "func", ",", "x", ",", "y", ",", "bounds", "=", "fit_bounds", ",", "sigma", "=", "sigma", ",", "maxfev", "=", "100000", ")", "\n", "y_est", "=", "func", "(", "x", ",", "*", "popt", ")", "\n", "mse", "=", "np", ".", "mean", "(", "np", ".", "power", "(", "y", "-", "y_est", ",", "2", ")", ")", "\n", "mse_l", ".", "append", "(", "mse", ")", "\n", "if", "mse", ">", "0.1", ":", "\n", "                            ", "logger", ".", "warning", "(", "'WARNING Large MSE for {} img=#{} = {:.2f}'", ".", "format", "(", "labels", "[", "index", "]", ",", "image_no", ",", "mse", ")", ")", "\n", "\n", "", "", "except", "RuntimeError", "as", "err", ":", "\n", "                        ", "logger", ".", "error", "(", "f'{labels[index]} image ={imid} bpp={x} y ={y} err ={err}'", ")", "\n", "\n", "", "Y", "[", "image_no", "]", "=", "func", "(", "X", ",", "*", "popt", ")", "\n", "\n", "", "if", "image_id", "<", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "'Fit summary - MSE for {} av={:.2f} max={:.2f}'", ".", "format", "(", "labels", "[", "index", "]", ",", "np", ".", "mean", "(", "mse_l", ")", ",", "\n", "np", ".", "max", "(", "mse_l", ")", ")", ")", "\n", "", "mse_labels", "[", "labels", "[", "index", "]", "]", "=", "np", ".", "mean", "(", "mse_l", ")", "\n", "\n", "yy", "=", "np", ".", "nanmean", "(", "Y", ",", "axis", "=", "0", ")", "\n", "axes", ".", "plot", "(", "X", ",", "yy", ",", "styles", "[", "index", "]", "[", "0", "]", ",", "\n", "label", "=", "'{} ({:.3f})'", ".", "format", "(", "labels", "[", "index", "]", ",", "mse_labels", "[", "labels", "[", "index", "]", "]", ")", "if", "add_legend", "else", "None", ")", "\n", "y_min", "=", "min", "(", "[", "y_min", ",", "min", "(", "yy", ")", "]", ")", "if", "update_ylim", "else", "y_min", "\n", "\n", "", "elif", "plot", "==", "'aggregate'", ":", "\n", "# For each quality level (QF, #channels) find the average quality level", "\n", "                ", "dfa", "=", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", "]", "\n", "\n", "if", "'n_features'", "in", "dfa", ":", "\n", "                    ", "dfg", "=", "dfa", ".", "groupby", "(", "'n_features'", ")", "\n", "", "else", ":", "\n", "                    ", "dfg", "=", "dfa", ".", "groupby", "(", "'quality'", ")", "\n", "\n", "", "x", "=", "dfg", ".", "mean", "(", ")", "[", "'bpp'", "]", ".", "values", "\n", "y", "=", "dfg", ".", "mean", "(", ")", "[", "metric", "]", ".", "values", "\n", "\n", "axes", ".", "plot", "(", "x", ",", "y", ",", "styles", "[", "index", "]", "[", "0", "]", ",", "label", "=", "labels", "[", "index", "]", "if", "add_legend", "else", "None", ",", "\n", "marker", "=", "avg_markers", "[", "index", "]", ",", "alpha", "=", "0.65", ")", "\n", "y_min", "=", "min", "(", "[", "y_min", ",", "min", "(", "y", ")", "]", ")", "if", "update_ylim", "else", "y_min", "\n", "\n", "", "elif", "plot", "==", "'none'", ":", "\n", "                ", "pass", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unsupported plot type!'", ")", "\n", "\n", "", "if", "draw_markers", ">", "0", ":", "\n", "\n", "                ", "if", "'entropy_reg'", "in", "dfc", ":", "\n", "\n", "                    ", "if", "image_id", ">=", "0", "or", "draw_markers", ">=", "2", ":", "\n", "\n", "# No need to draw legend if multiple DCNs are plotted", "\n", "                        ", "detailed_legend", "=", "'full'", "if", "marker_legend", "and", "index", "==", "baseline_count", "else", "False", "\n", "\n", "style_mapping", "=", "{", "}", "\n", "\n", "if", "'n_features'", "in", "dfc", "and", "len", "(", "dfc", "[", "'n_features'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                            ", "style_mapping", "[", "'hue'", "]", "=", "'n_features'", "\n", "\n", "", "if", "'entropy_reg'", "in", "dfc", "and", "len", "(", "dfc", "[", "'entropy_reg'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                            ", "style_mapping", "[", "'size'", "]", "=", "'entropy_reg'", "\n", "\n", "", "if", "'quantization'", "in", "dfc", "and", "len", "(", "dfc", "[", "'quantization'", "]", ".", "unique", "(", ")", ")", ">", "1", ":", "\n", "                            ", "style_mapping", "[", "'style'", "]", "=", "'quantization'", "\n", "\n", "", "sns", ".", "scatterplot", "(", "data", "=", "dfc", "[", "dfc", "[", "'selected'", "]", "]", ",", "x", "=", "'bpp'", ",", "y", "=", "metric", ",", "\n", "palette", "=", "\"Set2\"", ",", "ax", "=", "axes", ",", "legend", "=", "detailed_legend", ",", "\n", "**", "style_mapping", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "                    ", "if", "image_id", ">=", "0", ":", "\n", "                        ", "axes", ".", "plot", "(", "x", ",", "y", ",", "styles", "[", "index", "]", "[", "1", "]", ",", "alpha", "=", "0.65", ")", "\n", "\n", "# Setup title", "\n", "", "", "", "", "n_images", "=", "len", "(", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'image_id'", "]", ".", "unique", "(", ")", ")", "\n", "if", "n_images", ">", "1", ":", "\n", "            ", "title", "=", "'{} for {} images ({})'", ".", "format", "(", "plot", ",", "n_images", ",", "os", ".", "path", ".", "split", "(", "dirname", ")", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "title", "=", "'\\#{} : {}'", ".", "format", "(", "image_id", ",", "dfc", ".", "loc", "[", "dfc", "[", "'selected'", "]", ",", "'filename'", "]", ".", "unique", "(", ")", "[", "0", "]", ".", "replace", "(", "'.png'", ",", "''", ")", ")", "\n", "\n", "# Fixes problems with rendering using the LaTeX backend", "\n", "", "if", "add_legend", ":", "\n", "            ", "for", "t", "in", "axes", ".", "legend", "(", ")", ".", "texts", ":", "\n", "                ", "t", ".", "set_text", "(", "t", ".", "get_text", "(", ")", ".", "replace", "(", "'_'", ",", "'-'", ")", ")", "\n", "\n", "", "", "axes", ".", "set_xlim", "(", "[", "-", "0.1", ",", "max_bpp", "+", "0.1", "]", ")", "\n", "axes", ".", "set_ylim", "(", "[", "y_min", "*", "0.95", ",", "y_max", "]", ")", "\n", "axes", ".", "legend", "(", "loc", "=", "'lower right'", ")", "\n", "axes", ".", "set_title", "(", "title", ")", "\n", "if", "image_id", "//", "images_x", "==", "images_y", "-", "1", ":", "\n", "            ", "axes", ".", "set_xlabel", "(", "'Effective bpp'", ")", "\n", "", "if", "image_id", "%", "images_x", "==", "0", ":", "\n", "            ", "axes", ".", "set_ylabel", "(", "metric_label", ")", "\n", "\n", "", "", "return", "fig", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.__init__": [[138, 158], ["collections.OrderedDict", "jpeg_helpers.JPEGMarkerStats._process", "type", "imageio.imread", "open", "f.read", "type", "ValueError"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process"], ["def", "__init__", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"\n        Get JPEG marker stats for an image.\n        :param image: filename or bytes\n        \"\"\"", "\n", "self", ".", "l_decode", "=", "0", "\n", "self", ".", "len_chunk", "=", "0", "\n", "self", ".", "blocks", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "type", "(", "image", ")", "is", "str", ":", "\n", "            ", "with", "open", "(", "image", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "image", "=", "f", ".", "read", "(", ")", "\n", "", "", "elif", "type", "(", "image", ")", "is", "bytes", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Image not supported! Supported: str, bytes'", ")", "\n", "\n", "", "self", ".", "_quantization_tables", "=", "{", "}", "\n", "self", ".", "_process", "(", "image", ")", "\n", "self", ".", "shape", "=", "imageio", ".", "imread", "(", "image", ")", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process_quantization_tables": [[159, 169], ["len", "struct.unpack", "[].reshape", "numpy.frombuffer", "zigzag().ravel", "jpeg_helpers.zigzag"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.zigzag"], ["", "def", "_process_quantization_tables", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Extracts the quantization tables and updates the marker stats. \"\"\"", "\n", "while", "len", "(", "data", ")", ">", "0", ":", "\n", "# get the ID of the table [Luma(0), Chroma(1)]", "\n", "            ", "marker", ",", "=", "unpack", "(", "\"B\"", ",", "data", "[", "0", ":", "1", "]", ")", "\n", "# get the complete table of 64 elements in one go", "\n", "self", ".", "blocks", "[", "'DQT:{}'", ".", "format", "(", "marker", "&", "0xf", ")", "]", "=", "self", ".", "l_decode", "\n", "self", ".", "_quantization_tables", "[", "marker", "&", "0xf", "]", "=", "np", ".", "frombuffer", "(", "data", "[", "1", ":", "65", "]", ",", "np", ".", "uint8", ")", "[", "zigzag", "(", "8", ")", ".", "ravel", "(", ")", "]", ".", "reshape", "(", "(", "8", ",", "8", ")", ")", "\n", "# remove the quantization table chunk", "\n", "data", "=", "data", "[", "65", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process_huffman_tables": [[170, 179], ["len", "struct.unpack", "jpeg_helpers.get_byte_array"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.get_byte_array"], ["", "", "def", "_process_huffman_tables", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Extracts the Huffman tables and updates the marker stats. \"\"\"", "\n", "while", "len", "(", "data", ")", ">", "0", ":", "\n", "            ", "id", ",", "=", "unpack", "(", "\"B\"", ",", "data", "[", "0", ":", "1", "]", ")", "\n", "lengths", "=", "get_byte_array", "(", "data", "[", "1", ":", "17", "]", ")", "\n", "data", "=", "data", "[", "17", ":", "]", "\n", "for", "i", "in", "lengths", ":", "\n", "                ", "data", "=", "data", "[", "i", ":", "]", "\n", "", "self", ".", "blocks", "[", "'DHT:{}'", ".", "format", "(", "id", ")", "]", "=", "self", ".", "l_decode", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process": [[180, 239], ["len", "struct.unpack", "IOError", "struct.unpack", "jpeg_helpers.JPEGMarkerStats._process_quantization_tables", "print", "NotImplementedError", "jpeg_helpers.JPEGMarkerStats._process_huffman_tables", "struct.unpack", "len"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process_quantization_tables", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats._process_huffman_tables", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack"], ["", "", "def", "_process", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Parse the JPEG bit-stream and find the locations of markers. Returns  \"\"\"", "\n", "temp_data", "=", "data", "\n", "rst_marker_index", "=", "0", "\n", "app_marker_index", "=", "0", "\n", "self", ".", "blocks", "[", "'SOI'", "]", "=", "0", "\n", "try", ":", "\n", "            ", "while", "len", "(", "data", ")", ">", "0", ":", "\n", "# unpacking big endian hexadecimal marker", "\n", "                ", "marker", ",", "=", "unpack", "(", "\">H\"", ",", "data", "[", "0", ":", "2", "]", ")", "\n", "# start of image", "\n", "if", "marker", "==", "0xffd8", ":", "\n", "                    ", "self", ".", "len_chunk", "=", "2", "\n", "self", ".", "l_decode", "=", "2", "\n", "# end of image", "\n", "", "elif", "marker", "==", "0xffd9", ":", "\n", "                    ", "self", ".", "l_decode", "+=", "2", "\n", "self", ".", "blocks", "[", "'EOI'", "]", "=", "self", ".", "l_decode", "\n", "return", "self", ".", "blocks", "\n", "", "else", ":", "\n", "# decode the image chunk by chunk", "\n", "                    ", "self", ".", "len_chunk", ",", "=", "unpack", "(", "\">H\"", ",", "data", "[", "2", ":", "4", "]", ")", "\n", "# add the length of the 2 bytes marker", "\n", "self", ".", "len_chunk", "+=", "2", "\n", "# get the chunk after removing marker and length bytes", "\n", "chunk", "=", "data", "[", "4", ":", "self", ".", "len_chunk", "]", "\n", "if", "marker", "==", "0xffdb", ":", "\n", "                        ", "self", ".", "_process_quantization_tables", "(", "chunk", ")", "\n", "", "elif", "marker", "==", "0xffc0", ":", "\n", "                        ", "self", ".", "blocks", "[", "'DCT'", "]", "=", "self", ".", "l_decode", "\n", "", "elif", "marker", "==", "0xffc2", ":", "\n", "                        ", "print", "(", "\"Skipping progressive mode fragments\"", ")", "\n", "raise", "NotImplementedError", "(", "'Progressive JPEG images not supported yet'", ")", "\n", "", "elif", "marker", "==", "0xffc4", ":", "\n", "                        ", "self", ".", "_process_huffman_tables", "(", "chunk", ")", "\n", "", "elif", "marker", "==", "0xffda", ":", "\n", "# assuming valid JPEG", "\n", "                        ", "self", ".", "blocks", "[", "'SOS'", "]", "=", "self", ".", "l_decode", "\n", "self", ".", "len_chunk", ",", "=", "unpack", "(", "\">H\"", ",", "data", "[", "2", ":", "4", "]", ")", "\n", "self", ".", "len_chunk", "+=", "2", "\n", "self", ".", "l_decode", "+=", "self", ".", "len_chunk", "\n", "data", "=", "data", "[", "self", ".", "len_chunk", ":", "]", "\n", "self", ".", "len_chunk", "=", "len", "(", "temp_data", ")", "-", "self", ".", "l_decode", "-", "2", "\n", "self", ".", "blocks", "[", "'ECD'", "]", "=", "self", ".", "l_decode", "\n", "", "elif", "marker", "in", "app_markers", ":", "\n", "# suppose header contains two app markers then for ex, ffed -> app_13_0 and ffe0 -> app_0_1", "\n", "                        ", "self", ".", "blocks", "[", "'APP:{}/{}'", ".", "format", "(", "0xf", "&", "marker", ",", "app_marker_index", ")", "]", "=", "self", ".", "l_decode", "\n", "app_marker_index", "+=", "1", "\n", "", "elif", "marker", "in", "(", "0xfffe", ",", "0xffdd", ")", ":", "\n", "                        ", "self", ".", "blocks", "[", "'RST'", "]", "=", "self", ".", "l_decode", "\n", "rst_marker_index", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "break", "\n", "", "self", ".", "l_decode", "+=", "self", ".", "len_chunk", "\n", "", "data", "=", "data", "[", "self", ".", "len_chunk", ":", "]", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "IOError", "(", "'Parsing error: {}'", ".", "format", "(", "e", ")", ")", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_bytes": [[240, 242], ["None"], "methods", ["None"], ["", "def", "get_bytes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "blocks", "[", "'EOI'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_effective_bytes": [[243, 245], ["None"], "methods", ["None"], ["", "def", "get_effective_bytes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "blocks", "[", "'EOI'", "]", "-", "self", ".", "blocks", "[", "'DHT:0'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_effective_bpp": [[246, 248], ["jpeg_helpers.JPEGMarkerStats.get_effective_bytes"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_effective_bytes"], ["", "def", "get_effective_bpp", "(", "self", ")", ":", "\n", "        ", "return", "8", "*", "self", ".", "get_effective_bytes", "(", ")", "/", "self", ".", "shape", "[", "0", "]", "/", "self", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_bpp": [[249, 251], ["None"], "methods", ["None"], ["", "def", "get_bpp", "(", "self", ")", ":", "\n", "        ", "return", "8", "*", "self", ".", "blocks", "[", "'EOI'", "]", "/", "self", ".", "shape", "[", "0", "]", "/", "self", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.match_quality": [[26, 80], ["fun", "fun", "[].squeeze", "helpers.metrics.ssim", "int", "fun", "jpeg_helpers.compress_batch", "ValueError", "ValueError", "abs", "abs", "jpeg_helpers.compress_batch", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch"], ["def", "match_quality", "(", "image", ",", "target", "=", "0.95", ",", "match", "=", "'ssim'", ",", "subsampling", "=", "'4:4:4'", ")", ":", "\n", "    ", "\"\"\"\n    Find JPEG quality level which matches a given SSIM or bpp target.\n    :param image:\n    :param target: target value of ssim / bpp\n    :param match: string 'ssim' or 'bpp'\n    :param subsampling: chrominance sub-sampling, 4:4:4, 4:2:2, 4:2:0\n    :return: jpeg quality level (integer from 1 to 95)\n    \"\"\"", "\n", "\n", "assert", "image", ".", "ndim", "==", "3", ",", "'Only RGB images supported'", "\n", "\n", "def", "get_ssim", "(", "q", ")", ":", "\n", "        ", "image_j", "=", "compress_batch", "(", "image", ",", "q", ",", "subsampling", "=", "subsampling", ")", "[", "0", "]", ".", "squeeze", "(", ")", "\n", "c_ssim", "=", "metrics", ".", "ssim", "(", "image", ",", "image_j", ")", "\n", "return", "c_ssim", "-", "target", "\n", "\n", "", "def", "get_bpp", "(", "q", ")", ":", "\n", "        ", "bytes_arr", "=", "compress_batch", "(", "image", ",", "q", ",", "subsampling", "=", "subsampling", ")", "[", "1", "]", "\n", "bpp", "=", "8", "*", "np", ".", "mean", "(", "bytes_arr", ")", "/", "image", ".", "shape", "[", "0", "]", "/", "image", ".", "shape", "[", "1", "]", "\n", "return", "bpp", "-", "target", "\n", "\n", "", "if", "match", "==", "'ssim'", ":", "\n", "        ", "fun", "=", "get_ssim", "\n", "", "elif", "match", "==", "'bpp'", ":", "\n", "        ", "fun", "=", "get_bpp", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid argument: match'", ")", "\n", "\n", "", "low", "=", "1", "\n", "high", "=", "95", "\n", "low_obj", "=", "fun", "(", "low", ")", "\n", "high_obj", "=", "fun", "(", "high", ")", "\n", "\n", "while", "True", ":", "\n", "\n", "        ", "if", "high", "-", "low", "<=", "1", ":", "\n", "            ", "if", "abs", "(", "high_obj", ")", ">", "abs", "(", "low_obj", ")", ":", "\n", "                ", "return", "low", "\n", "", "else", ":", "\n", "                ", "return", "high", "\n", "\n", "", "", "if", "low_obj", "*", "high_obj", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Same deviation for both end-points {} - {}'", ".", "format", "(", "low", ",", "high", ")", ")", "\n", "\n", "", "mid", "=", "int", "(", "(", "low", "+", "high", ")", "/", "2", ")", "\n", "mid_obj", "=", "fun", "(", "mid", ")", "\n", "\n", "if", "mid_obj", "*", "high_obj", ">", "0", ":", "\n", "            ", "high", "=", "mid", "\n", "high_obj", "=", "mid_obj", "\n", "", "else", ":", "\n", "            ", "low", "=", "mid", "\n", "low_obj", "=", "mid_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch": [[82, 115], ["batch_x.max", "io.BytesIO", "imageio.imsave", "imageio.imread", "batch_x.astype", "io.BytesIO.getvalue", "len", "jpeg_helpers.JPEGMarkerStats.get_effective_bytes", "numpy.zeros_like", "range", "io.BytesIO.getvalue", "io.BytesIO", "imageio.imsave", "imageio.imread", "bytes_arr.append", "jpeg_helpers.JPEGMarkerStats", "io.BytesIO.getvalue", "imageio.imread.astype", "len", "jpeg_helpers.JPEGMarkerStats.get_effective_bytes", "io.BytesIO.getvalue", "io.BytesIO.getvalue", "jpeg_helpers.JPEGMarkerStats", "io.BytesIO.getvalue"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_effective_bytes", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.JPEGMarkerStats.get_effective_bytes"], ["", "", "", "def", "compress_batch", "(", "batch_x", ",", "jpeg_quality", ",", "effective", "=", "False", ",", "subsampling", "=", "'4:4:4'", ")", ":", "\n", "    ", "\"\"\"\n    Compress an image batch with the standard JPEG codec. Returns compressed images and their sizes in bytes.\n    :param batch_x: numpy array (n, h, w, 3)\n    :param jpeg_quality: quality level (integer from 1 to 95); For some reason levels 95 - 100 return the same results\n    :param effective: whether to return the entire file size or only the coded image data (w. Huffman tables)\n    :param subsampling: chrominance sub-sampling, 4:4:4, 4:2:2, 4:2:0\n    :return: tuple with a batch of compressed images, and their corresponding sizes in bytes\n    \"\"\"", "\n", "\n", "if", "batch_x", ".", "max", "(", ")", ">", "1", ":", "\n", "        ", "batch_x", "=", "batch_x", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "", "if", "batch_x", ".", "ndim", "==", "3", ":", "\n", "        ", "s", "=", "io", ".", "BytesIO", "(", ")", "\n", "imageio", ".", "imsave", "(", "s", ",", "(", "255", "*", "batch_x", ")", ".", "astype", "(", "np", ".", "uint8", ")", ".", "squeeze", "(", ")", ",", "format", "=", "'jpg'", ",", "quality", "=", "jpeg_quality", ",", "subsampling", "=", "subsampling", ")", "\n", "image_compressed", "=", "imageio", ".", "imread", "(", "s", ".", "getvalue", "(", ")", ")", "\n", "image_bytes", "=", "len", "(", "s", ".", "getvalue", "(", ")", ")", "if", "not", "effective", "else", "JPEGMarkerStats", "(", "s", ".", "getvalue", "(", ")", ")", ".", "get_effective_bytes", "(", ")", "\n", "\n", "return", "image_compressed", "/", "(", "2", "**", "8", "-", "1", ")", ",", "image_bytes", "\n", "\n", "", "elif", "batch_x", ".", "ndim", "==", "4", ":", "\n", "        ", "batch_j", "=", "np", ".", "zeros_like", "(", "batch_x", ")", "\n", "bytes_arr", "=", "[", "]", "\n", "for", "r", "in", "range", "(", "batch_x", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "s", "=", "io", ".", "BytesIO", "(", ")", "\n", "imageio", ".", "imsave", "(", "s", ",", "(", "255", "*", "batch_x", "[", "r", "]", ")", ".", "astype", "(", "np", ".", "uint8", ")", ".", "squeeze", "(", ")", ",", "format", "=", "'jpg'", ",", "quality", "=", "jpeg_quality", ",", "subsampling", "=", "subsampling", ")", "\n", "image_compressed", "=", "imageio", ".", "imread", "(", "s", ".", "getvalue", "(", ")", ")", "\n", "batch_j", "[", "r", "]", "=", "image_compressed", ".", "astype", "(", "np", ".", "float32", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "image_bytes", "=", "len", "(", "s", ".", "getvalue", "(", ")", ")", "if", "not", "effective", "else", "JPEGMarkerStats", "(", "s", ".", "getvalue", "(", ")", ")", ".", "get_effective_bytes", "(", ")", "\n", "bytes_arr", ".", "append", "(", "image_bytes", ")", "\n", "\n", "", "return", "batch_j", ",", "bytes_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jp2bytes": [[117, 126], ["jpylyzer.jpylyzer.checkOneFile().toxml", "sum", "int", "len", "RuntimeError", "jpylyzer.jpylyzer.checkOneFile", "re.findall", "jpylyzer.checkOneFile().toxml.decode"], "function", ["None"], ["", "", "def", "jp2bytes", "(", "filename", ")", ":", "\n", "    ", "\"\"\" Gets JPEG 2000 payload size in bytes (using jpylyzer). Not thoroughly tested. Should sum all tiles. \"\"\"", "\n", "out", "=", "jpylyzer", ".", "checkOneFile", "(", "filename", ")", ".", "toxml", "(", ")", "\n", "data_length", "=", "[", "int", "(", "x", ")", "for", "x", "in", "re", ".", "findall", "(", "r'\\<psot\\>([0-9]+)\\</psot\\>'", ",", "out", ".", "decode", "(", "'utf8'", ")", ")", "]", "\n", "\n", "if", "len", "(", "data_length", ")", "==", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Error running jpylyzer {}'", ".", "format", "(", "filename", ")", ")", "\n", "\n", "", "return", "sum", "(", "data_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.get_byte_array": [[128, 131], ["list", "struct.unpack", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack"], ["", "def", "get_byte_array", "(", "chunk", ")", ":", "\n", "    ", "\"\"\" Convert a chunk of bytes to a corresponding array \"\"\"", "\n", "return", "list", "(", "unpack", "(", "\"B\"", "*", "len", "(", "chunk", ")", ",", "chunk", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.zigzag": [[253, 262], ["range", "numpy.zeros", "enumerate", "sorted"], "function", ["None"], ["", "", "def", "zigzag", "(", "n", ")", ":", "\n", "    ", "def", "compare", "(", "xy", ")", ":", "\n", "        ", "x", ",", "y", "=", "xy", "\n", "return", "(", "x", "+", "y", ",", "-", "y", "if", "(", "x", "+", "y", ")", "%", "2", "else", "y", ")", "\n", "", "xs", "=", "range", "(", "n", ")", "\n", "zz", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "for", "n", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "sorted", "(", "(", "(", "x", ",", "y", ")", "for", "x", "in", "xs", "for", "y", "in", "xs", ")", ",", "key", "=", "compare", ")", ")", ":", "\n", "        ", "zz", "[", "x", ",", "y", "]", "=", "n", "\n", "", "return", "zz", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable": [[264, 306], ["numpy.maximum", "numpy.floor", "numpy.minimum", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "jpeg_qtable", "(", "quality", ",", "channel", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Return a DCT quantization matrix for a given quality level.\n    :param quality: JPEG quality level (1-100)\n    :param channel: 0 for luminance, >0 for chrominance channels\n    \"\"\"", "\n", "\n", "# Sanitize", "\n", "quality", "=", "np", ".", "maximum", "(", "np", ".", "minimum", "(", "100", ",", "quality", ")", ",", "1", ")", "\n", "\n", "# Convert to linear quality scale", "\n", "quality", "=", "5000", "/", "quality", "if", "quality", "<", "50", "else", "200", "-", "quality", "*", "2", "\n", "\n", "if", "channel", "==", "0", ":", "\n", "# This is table 0 (the luminance table):", "\n", "        ", "t", "=", "[", "[", "16", ",", "11", ",", "10", ",", "16", ",", "24", ",", "40", ",", "51", ",", "61", "]", ",", "\n", "[", "12", ",", "12", ",", "14", ",", "19", ",", "26", ",", "58", ",", "60", ",", "55", "]", ",", "\n", "[", "14", ",", "13", ",", "16", ",", "24", ",", "40", ",", "57", ",", "69", ",", "56", "]", ",", "\n", "[", "14", ",", "17", ",", "22", ",", "29", ",", "51", ",", "87", ",", "80", ",", "62", "]", ",", "\n", "[", "18", ",", "22", ",", "37", ",", "56", ",", "68", ",", "109", ",", "103", ",", "77", "]", ",", "\n", "[", "24", ",", "35", ",", "55", ",", "64", ",", "81", ",", "104", ",", "113", ",", "92", "]", ",", "\n", "[", "49", ",", "64", ",", "78", ",", "87", ",", "103", ",", "121", ",", "120", ",", "101", "]", ",", "\n", "[", "72", ",", "92", ",", "95", ",", "98", ",", "112", ",", "100", ",", "103", ",", "99", "]", "]", "\n", "t", "=", "np", ".", "array", "(", "t", ",", "np", ".", "float32", ")", "\n", "\n", "", "else", ":", "\n", "# This is table 1 (the chrominance table):", "\n", "        ", "t", "=", "[", "[", "17", ",", "18", ",", "24", ",", "47", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "18", ",", "21", ",", "26", ",", "66", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "24", ",", "26", ",", "56", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "47", ",", "66", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", ",", "\n", "[", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", ",", "99", "]", "]", "\n", "t", "=", "np", ".", "array", "(", "t", ",", "np", ".", "float32", ")", "\n", "\n", "", "t", "=", "np", ".", "floor", "(", "(", "t", "*", "quality", "+", "50", ")", "/", "100", ")", "\n", "t", "[", "t", "<", "1", "]", "=", "1", "\n", "t", "[", "t", ">", "255", "]", "=", "255", "\n", "\n", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qf_estimation": [[308, 311], ["numpy.mean", "numpy.argmin", "numpy.abs", "range", "jpeg_helpers.jpeg_qtable"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable"], ["", "def", "jpeg_qf_estimation", "(", "q_mtx", ",", "channel", "=", "0", ")", ":", "\n", "    ", "errors", "=", "[", "np", ".", "mean", "(", "np", ".", "abs", "(", "jpeg_qtable", "(", "qf", ",", "channel", ")", "-", "q_mtx", ")", ")", "for", "qf", "in", "range", "(", "1", ",", "101", ")", "]", "\n", "return", "np", ".", "argmin", "(", "errors", ")", "+", "1", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.BPGImageInfo.__init__": [[35, 40], ["float"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "width", ",", "height", ",", "num_bytes_for_picture", ")", ":", "\n", "        ", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "num_bytes_for_picture", "=", "num_bytes_for_picture", "\n", "self", ".", "bpp", "=", "num_bytes_for_picture", "*", "8", "/", "float", "(", "width", "*", "height", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpg_compress": [[12, 22], ["subprocess.call", "os.path.basename", "os.path.join().replace", "input_image_p.replace", "str", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.DifferentiableJPEG.call"], ["def", "bpg_compress", "(", "input_image_p", ",", "q", ",", "tmp_dir", "=", "None", ",", "chroma_fmt", "=", "'444'", ")", ":", "\n", "    ", "\"\"\" Int -> image_out_path :: str \"\"\"", "\n", "assert", "'png'", "in", "input_image_p", "\n", "if", "tmp_dir", ":", "\n", "        ", "input_image_name", "=", "os", ".", "path", ".", "basename", "(", "input_image_p", ")", "\n", "output_image_bpg_p", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "input_image_name", ")", ".", "replace", "(", "'.png'", ",", "'_tmp_bpg.bpg'", ")", "\n", "", "else", ":", "\n", "        ", "output_image_bpg_p", "=", "input_image_p", ".", "replace", "(", "'.png'", ",", "'_tmp_bpg.bpg'", ")", "\n", "", "subprocess", ".", "call", "(", "[", "BPGENC", ",", "'-q'", ",", "str", "(", "q", ")", ",", "input_image_p", ",", "'-o'", ",", "output_image_bpg_p", ",", "'-f'", ",", "chroma_fmt", "]", ")", "\n", "return", "output_image_bpg_p", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.decode_bpg_to_png": [[24, 28], ["bpg_p.replace", "subprocess.call"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.DifferentiableJPEG.call"], ["", "def", "decode_bpg_to_png", "(", "bpg_p", ")", ":", "# really fast", "\n", "    ", "png_p", "=", "bpg_p", ".", "replace", "(", "'.bpg'", ",", "'_as_png.png'", ")", "\n", "subprocess", ".", "call", "(", "[", "'bpgdec'", ",", "'-o'", ",", "png_p", ",", "bpg_p", "]", ")", "\n", "return", "png_p", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpp_of_bpg_image": [[30, 32], ["bpg_helpers.bpg_image_info"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpg_image_info"], ["", "def", "bpp_of_bpg_image", "(", "bpg_p", ")", ":", "\n", "    ", "return", "bpg_image_info", "(", "bpg_p", ")", ".", "bpp", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers.bpg_image_info": [[42, 61], ["open", "f.read", "bytearray.fromhex", "f.read", "bpg_helpers._read_ue7", "bpg_helpers._read_ue7", "bpg_helpers._read_ue7", "bpg_helpers.BPGImageInfo", "bpg_helpers._number_of_bytes_until_eof"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._read_ue7", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._read_ue7", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._read_ue7", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._number_of_bytes_until_eof"], ["", "", "def", "bpg_image_info", "(", "p", ")", ":", "\n", "    ", "\"\"\"\n    Relevant format spec:\n    magic number          4 bytes\n    header stuff          2 bytes\n    width                 variable, ue7\n    height                variable, ue7\n    picture_data_length   variable, ue7. If zero: remaining data is image\n    \"\"\"", "\n", "with", "open", "(", "p", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "magic", "=", "f", ".", "read", "(", "4", ")", "\n", "expected_magic", "=", "bytearray", ".", "fromhex", "(", "'425047fb'", ")", "\n", "assert", "magic", "==", "expected_magic", ",", "'Not a BPG file it seems: {}'", ".", "format", "(", "p", ")", "\n", "header_info", "=", "f", ".", "read", "(", "2", ")", "\n", "width", "=", "_read_ue7", "(", "f", ")", "\n", "height", "=", "_read_ue7", "(", "f", ")", "\n", "picture_data_length", "=", "_read_ue7", "(", "f", ")", "\n", "num_bytes_for_picture", "=", "_number_of_bytes_until_eof", "(", "f", ")", "if", "picture_data_length", "==", "0", "else", "picture_data_length", "\n", "return", "BPGImageInfo", "(", "width", ",", "height", ",", "num_bytes_for_picture", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._read_ue7": [[63, 83], ["int", "bpg_helpers._byte_generator"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._byte_generator"], ["", "", "def", "_read_ue7", "(", "f", ")", ":", "\n", "    ", "\"\"\"\n    ue7 means it's a bunch of bytes all starting with a 1 until one byte starts\n    with 0. from all those bytes you take all bits except the first one and\n    merge them. E.G.\n\n    some ue7-encoded number:      10001001 01000010\n    take all bits except first ->  0001001  1000010 \n    merge ->                            10011000010 = 1218\n    \"\"\"", "\n", "bits", "=", "0", "\n", "first_bit_mask", "=", "1", "<<", "7", "\n", "value_holding_bits_mask", "=", "int", "(", "7", "*", "'1'", ",", "2", ")", "\n", "for", "byte", "in", "_byte_generator", "(", "f", ")", ":", "\n", "        ", "byte_as_int", "=", "byte", "[", "0", "]", "\n", "more_bits_are_coming", "=", "byte_as_int", "&", "first_bit_mask", "\n", "bits_from_this_byte", "=", "byte_as_int", "&", "value_holding_bits_mask", "\n", "bits", "=", "(", "bits", "<<", "7", ")", "|", "bits_from_this_byte", "\n", "if", "not", "more_bits_are_coming", ":", "\n", "            ", "return", "bits", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._number_of_bytes_until_eof": [[85, 87], ["sum", "bpg_helpers._byte_generator"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._byte_generator"], ["", "", "", "def", "_number_of_bytes_until_eof", "(", "f", ")", ":", "\n", "    ", "return", "sum", "(", "1", "for", "_", "in", "_byte_generator", "(", "f", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.bpg_helpers._byte_generator": [[89, 95], ["f.read"], "function", ["None"], ["", "def", "_byte_generator", "(", "f", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "byte", "=", "f", ".", "read", "(", "1", ")", "\n", "if", "byte", "==", "b\"\"", ":", "\n", "            ", "break", "\n", "", "yield", "byte", "\n", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.__init__": [[33, 52], ["models.tfmodel.TFModel.__init__", "tensorflow.keras.Input", "pipelines.NIPModel.construct_model", "pipelines.NIPModel._has_attributes", "pipelines.NIPModel.construct_loss", "tensorflow.keras.optimizers.Adam"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.TwitterDCN.construct_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._has_attributes", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.construct_loss"], ["def", "__init__", "(", "self", ",", "loss_metric", "=", "'L2'", ",", "patch_size", "=", "None", ",", "in_channels", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Base constructor with common setup.\n\n        :param loss_metric: loss metric for NIP optimization (L2, L1, SSIM)\n        :param patch_size: Optionally patch size can be given to fix placeholder dimensions (can be None)\n        :param in_channels: number of channels in the input RAW image (defaults to 4 for RGGB)\n        :param kwargs: Additional arguments for specific NIP implementations\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "x", "=", "tf", ".", "keras", ".", "Input", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "patch_size", ",", "patch_size", ",", "in_channels", ")", ",", "name", "=", "'x'", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "construct_model", "(", "**", "kwargs", ")", "\n", "self", ".", "_has_attributes", "(", "[", "'y'", ",", "'_model'", "]", ")", "\n", "\n", "# Configure loss and model optimization", "\n", "self", ".", "loss_metric", "=", "loss_metric", "\n", "self", ".", "construct_loss", "(", "loss_metric", ")", "\n", "self", ".", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.construct_loss": [[53, 64], ["ValueError"], "methods", ["None"], ["", "def", "construct_loss", "(", "self", ",", "loss_metric", ")", ":", "\n", "        ", "if", "loss_metric", "==", "'L2'", ":", "\n", "            ", "self", ".", "loss", "=", "tf_helpers", ".", "mse", "\n", "", "elif", "loss_metric", "==", "'L1'", ":", "\n", "            ", "self", ".", "loss", "=", "tf_helpers", ".", "mae", "\n", "", "elif", "loss_metric", "==", "'SSIM'", ":", "\n", "            ", "self", ".", "loss", "=", "tf_helpers", ".", "ssim_loss", "\n", "", "elif", "loss_metric", "==", "'MS-SSIM'", ":", "\n", "            ", "self", ".", "loss", "=", "tf_helpers", ".", "msssim_loss", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported loss metric!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.construct_model": [[65, 76], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "construct_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Constructs the NIP model. The model should be a tf.keras.Model instance available via the\n        self._model attribute. The method should use self.x as RAW image input, and set self.y as \n        the model output. The output is expected to be clipped to [0,1]. For better optimization \n        stability, it's better not to backpropagate through clipping:\n\n        self.y = tf.stop_gradient(tf.clip_by_value(y, 0, 1) - y) + y\n        self._model = tf.keras.Model(inputs=[self.x], outputs=[self.y])\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.training_step": [[77, 91], ["tape.gradient", "pipelines.NIPModel.optimizer.apply_gradients", "tensorflow.GradientTape", "pipelines.NIPModel._model", "pipelines.NIPModel.loss", "pipelines.NIPModel.optimizer.lr.assign", "zip"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "training_step", "(", "self", ",", "batch_x", ",", "batch_y", ",", "learning_rate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Make a single training step and return the loss.\n        \"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "            ", "batch_Y", "=", "self", ".", "_model", "(", "batch_x", ")", "\n", "loss", "=", "self", ".", "loss", "(", "batch_Y", ",", "batch_y", ")", "\n", "\n", "", "if", "learning_rate", "is", "not", "None", ":", "self", ".", "optimizer", ".", "lr", ".", "assign", "(", "learning_rate", ")", "\n", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "_model", ".", "trainable_weights", ")", "\n", "self", ".", "optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "self", ".", "_model", ".", "trainable_weights", ")", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.process": [[92, 100], ["pipelines.NIPModel._model", "numpy.expand_dims"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "batch_x", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Develop RAW input and return RGB image.\n        \"\"\"", "\n", "if", "batch_x", ".", "ndim", "==", "3", ":", "\n", "            ", "batch_x", "=", "np", ".", "expand_dims", "(", "batch_x", ",", "0", ")", "\n", "\n", "", "return", "self", ".", "_model", "(", "batch_x", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.reset_performance_stats": [[101, 106], ["None"], "methods", ["None"], ["", "def", "reset_performance_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "performance", "=", "{", "\n", "'loss'", ":", "{", "'training'", ":", "[", "]", ",", "'validation'", ":", "[", "]", "}", ",", "\n", "'psnr'", ":", "{", "'validation'", ":", "[", "]", "}", ",", "\n", "'ssim'", ":", "{", "'validation'", ":", "[", "]", "}", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.get_hyperparameters": [[108, 113], ["hasattr", "p.update", "pipelines.NIPModel._h.to_json"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json"], ["", "def", "get_hyperparameters", "(", "self", ")", ":", "\n", "        ", "p", "=", "{", "'in_channels'", ":", "self", ".", "in_channels", "}", "\n", "if", "hasattr", "(", "self", ",", "'_h'", ")", ":", "\n", "            ", "p", ".", "update", "(", "self", ".", "_h", ".", "to_json", "(", ")", ")", "\n", "", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel._input_description": [[114, 117], ["helpers.utils.format_patch_shape"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_patch_shape"], ["", "@", "property", "\n", "def", "_input_description", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "format_patch_shape", "(", "self", ".", "patch_size_raw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel._output_description": [[118, 121], ["helpers.utils.format_patch_shape"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_patch_shape"], ["", "@", "property", "\n", "def", "_output_description", "(", "self", ")", ":", "\n", "        ", "return", "utils", ".", "format_patch_shape", "(", "self", ".", "patch_size_rgb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.patch_size_raw": [[122, 125], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "patch_size_raw", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "x", ".", "shape", "[", "1", ":", "]", "if", "hasattr", "(", "self", ".", "y", ",", "'shape'", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.patch_size_rgb": [[126, 129], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "patch_size_rgb", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "y", ".", "shape", "[", "1", ":", "]", "if", "hasattr", "(", "self", ".", "y", ",", "'shape'", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.summary": [[130, 132], ["super().summary"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "return", "'{:s} : {} -> {}'", ".", "format", "(", "super", "(", ")", ".", "summary", "(", ")", ",", "self", ".", "_input_description", ",", "self", ".", "_output_description", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.load_model": [[133, 137], ["super().load_model", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model"], ["", "def", "load_model", "(", "self", ",", "dirname", ")", ":", "\n", "        ", "if", "'/'", "not", "in", "dirname", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "join", "(", "'data/models/nip'", ",", "dirname", ")", "\n", "", "super", "(", ")", ".", "load_model", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.save_model": [[138, 142], ["super().save_model", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model"], ["", "def", "save_model", "(", "self", ",", "dirname", ",", "epoch", "=", "0", ",", "quiet", "=", "False", ")", ":", "\n", "        ", "if", "'/'", "not", "in", "dirname", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "join", "(", "'data/models/nip'", ",", "dirname", ")", "\n", "", "super", "(", ")", ".", "save_model", "(", "dirname", ",", "epoch", "=", "epoch", ",", "quiet", "=", "quiet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.NIPModel.process_fingerprint": [[143, 167], ["helpers.raw.merge_bayer", "ValueError", "pipelines.NIPModel._model._demosaicing().numpy", "helpers.raw.merge_bayer.sum", "pipelines.NIPModel._model._demosaicing", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.merge_bayer"], ["", "def", "process_fingerprint", "(", "self", ",", "k0", ",", "demosaicing", "=", "True", ",", "cfa_pattern", "=", "None", ")", ":", "\n", "        ", "\"\"\" \n        Map a RAW-level camera fingerprint to RGB space either via (1) CFA-informed pixel mapping or (2) demosaicing.\n        \n        (2) will be more suitable for standard PRNU detection, while (1) may be more applicable for further processing,\n        e.g., in CNN-based models. \n        \"\"\"", "\n", "\n", "try", ":", "\n", "            ", "default_cfa", "=", "self", ".", "_h", ".", "cfa_pattern", "\n", "", "except", ":", "\n", "            ", "default_cfa", "=", "None", "\n", "\n", "", "cfa_pattern", "=", "cfa_pattern", "or", "default_cfa", "\n", "\n", "if", "cfa_pattern", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'This ISP is not aware of the CFA! Set the CFA explicitly or make sure \"._h.cfa_pattern\" is accessible!'", ")", "\n", "\n", "", "k0m", "=", "helpers", ".", "raw", ".", "merge_bayer", "(", "k0", ",", "cfa_pattern", ")", "\n", "\n", "if", "demosaicing", ":", "\n", "            ", "return", "self", ".", "_model", ".", "_demosaicing", "(", "np", ".", "expand_dims", "(", "k0m", ",", "axis", "=", "0", ")", ",", "clip", "=", "False", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "k0m", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.UNet.construct_model": [[175, 227], ["helpers.paramspec.ParamSpec", "pipelines.UNet._h.update", "collections.OrderedDict", "collections.OrderedDict", "range", "range", "tensorflow.keras.layers.Conv2D", "tensorflow.nn.depth_to_space", "tensorflow.keras.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.stop_gradient", "tensorflow.keras.layers.MaxPool2D", "set", "tensorflow.clip_by_value", "helpers.tf_helpers.activation_mapping.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["def", "construct_model", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# Define and validate hyper-parameters", "\n", "        ", "self", ".", "_h", "=", "paramspec", ".", "ParamSpec", "(", "{", "\n", "'n_steps'", ":", "(", "5", ",", "int", ",", "(", "2", ",", "6", ")", ")", ",", "\n", "'activation'", ":", "(", "'leaky_relu'", ",", "str", ",", "set", "(", "tf_helpers", ".", "activation_mapping", ".", "keys", "(", ")", ")", ")", "\n", "}", ")", "\n", "\n", "self", ".", "_h", ".", "update", "(", "**", "kwargs", ")", "\n", "lrelu", "=", "tf_helpers", ".", "activation_mapping", "[", "self", ".", "_h", ".", "activation", "]", "\n", "\n", "_layers", "=", "OrderedDict", "(", ")", "\n", "_tensors", "=", "OrderedDict", "(", ")", "\n", "_tensors", "[", "'ep0'", "]", "=", "self", ".", "x", "\n", "\n", "# Construct the encoder", "\n", "for", "n", "in", "range", "(", "1", ",", "self", ".", "_h", ".", "n_steps", "+", "1", ")", ":", "\n", "            ", "_layers", "[", "'ec{}1'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "32", "*", "2", "**", "(", "n", "-", "1", ")", ",", "[", "3", ",", "3", "]", ",", "activation", "=", "lrelu", ",", "padding", "=", "'SAME'", ")", "\n", "_layers", "[", "'ec{}2'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "32", "*", "2", "**", "(", "n", "-", "1", ")", ",", "[", "3", ",", "3", "]", ",", "activation", "=", "lrelu", ",", "padding", "=", "'SAME'", ")", "\n", "_tensors", "[", "'ec{}1'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'ec{}1'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'ep{}'", ".", "format", "(", "n", "-", "1", ")", "]", ")", "\n", "_tensors", "[", "'ec{}2'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'ec{}2'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'ec{}1'", ".", "format", "(", "n", ")", "]", ")", "\n", "\n", "if", "n", "<", "self", ".", "_h", ".", "n_steps", ":", "\n", "                ", "_layers", "[", "'ep{}'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPool2D", "(", "[", "2", ",", "2", "]", ",", "padding", "=", "'SAME'", ")", "\n", "_tensors", "[", "'ep{}'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'ep{}'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'ec{}2'", ".", "format", "(", "n", ")", "]", ")", "\n", "\n", "# Easy access to encoder output via a recursive relation", "\n", "", "", "_tensors", "[", "'dc02'", "]", "=", "_tensors", "[", "'ec{}2'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", ")", "]", "\n", "\n", "# Construct the decoder", "\n", "for", "n", "in", "range", "(", "1", ",", "self", ".", "_h", ".", "n_steps", ")", ":", "\n", "            ", "_layers", "[", "'dct{}'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "32", "*", "2", "**", "(", "self", ".", "_h", ".", "n_steps", "-", "n", "-", "1", ")", ",", "[", "2", ",", "2", "]", ",", "[", "2", ",", "2", "]", ",", "padding", "=", "'SAME'", ")", "\n", "_layers", "[", "'dcat{}'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Concatenate", "(", ")", "\n", "_layers", "[", "'dc{}1'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "32", "*", "2", "**", "(", "self", ".", "_h", ".", "n_steps", "-", "n", "-", "1", ")", ",", "[", "3", ",", "3", "]", ",", "activation", "=", "lrelu", ",", "padding", "=", "'SAME'", ")", "\n", "_layers", "[", "'dc{}2'", ".", "format", "(", "n", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "32", "*", "2", "**", "(", "self", ".", "_h", ".", "n_steps", "-", "n", "-", "1", ")", ",", "[", "3", ",", "3", "]", ",", "activation", "=", "lrelu", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "_tensors", "[", "'dct{}'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'dct{}'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'dc{}2'", ".", "format", "(", "n", "-", "1", ")", "]", ")", "\n", "_tensors", "[", "'dcat{}'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'dcat{}'", ".", "format", "(", "n", ")", "]", "(", "[", "_tensors", "[", "'dct{}'", ".", "format", "(", "n", ")", "]", ",", "_tensors", "[", "'ec{}2'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", "-", "n", ")", "]", "]", ")", "\n", "_tensors", "[", "'dc{}1'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'dc{}1'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'dcat{}'", ".", "format", "(", "n", ")", "]", ")", "\n", "_tensors", "[", "'dc{}2'", ".", "format", "(", "n", ")", "]", "=", "_layers", "[", "'dc{}2'", ".", "format", "(", "n", ")", "]", "(", "_tensors", "[", "'dc{}1'", ".", "format", "(", "n", ")", "]", ")", "\n", "\n", "# Final step to render the RGB image", "\n", "", "_layers", "[", "'dc{}'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", ")", "]", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "12", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'SAME'", ")", "\n", "_tensors", "[", "'dc{}'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", ")", "]", "=", "_layers", "[", "'dc{}'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", ")", "]", "(", "_tensors", "[", "'dc{}2'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", "-", "1", ")", "]", ")", "\n", "_tensors", "[", "'dts'", "]", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "_tensors", "[", "'dc{}'", ".", "format", "(", "self", ".", "_h", ".", "n_steps", ")", "]", ",", "2", ")", "\n", "\n", "# Add NIP outputs", "\n", "y", "=", "_tensors", "[", "'dts'", "]", "\n", "# self.y = tf.clip_by_value(_tensors['dts'], 0, 1)", "\n", "self", ".", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "\n", "# Construct the Keras model", "\n", "self", ".", "_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "[", "self", ".", "x", "]", ",", "outputs", "=", "[", "self", ".", "y", "]", ",", "name", "=", "'unet'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.UNet.model_code": [[228, 231], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_code", "(", "self", ")", ":", "\n", "        ", "return", "f'{self.class_name}_{self._h.n_steps}'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.INet.construct_model": [[238, 291], ["helpers.paramspec.ParamSpec", "locals", "pipelines.INet._h.update", "helpers.kernels.upsampling_kernel", "tensorflow.nn.depth_to_space", "tensorflow.pad", "tensorflow.keras.Model", "numpy.random.normal", "numpy.random.normal", "numpy.zeros", "numpy.random.normal", "numpy.zeros", "numpy.eye", "helpers.kernels.bilin_kernel", "helpers.kernels.gamma_kernels", "numpy.array().transpose", "tensorflow.keras.layers.Conv2D", "tensorflow.constant", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.stop_gradient", "numpy.array", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.clip_by_value", "pipelines.INet._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.bilin_kernel", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.gamma_kernels", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["def", "construct_model", "(", "self", ",", "random_init", "=", "False", ",", "kernel", "=", "5", ",", "trainable_upsampling", "=", "False", ",", "cfa_pattern", "=", "'gbrg'", ")", ":", "\n", "\n", "        ", "self", ".", "_h", "=", "paramspec", ".", "ParamSpec", "(", "{", "\n", "'random_init'", ":", "(", "False", ",", "bool", ",", "None", ")", ",", "\n", "'kernel'", ":", "(", "5", ",", "int", ",", "(", "3", ",", "11", ")", ")", ",", "\n", "'trainable_upsampling'", ":", "(", "False", ",", "bool", ",", "None", ")", ",", "\n", "'cfa_pattern'", ":", "(", "'gbrg'", ",", "str", ",", "{", "'gbrg'", ",", "'rggb'", ",", "'bggr'", "}", ")", "\n", "}", ")", "\n", "params", "=", "locals", "(", ")", "\n", "self", ".", "_h", ".", "update", "(", "**", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "self", ".", "_h", ".", "keys", "(", ")", "if", "k", "in", "params", "}", ")", "\n", "\n", "# Initialize the upsampling kernel", "\n", "upk", "=", "upsampling_kernel", "(", "self", ".", "_h", ".", "cfa_pattern", ")", "\n", "\n", "if", "self", ".", "_h", ".", "random_init", ":", "\n", "# upk = np.random.normal(0, 0.1, (4, 12))", "\n", "            ", "dmf", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "0.1", ",", "(", "self", ".", "_h", ".", "kernel", ",", "self", ".", "_h", ".", "kernel", ",", "3", ",", "3", ")", ")", "\n", "gamma_d1k", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "0.1", ",", "(", "3", ",", "12", ")", ")", "\n", "gamma_d1b", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ")", "\n", "gamma_d2k", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "0.1", ",", "(", "12", ",", "3", ")", ")", "\n", "gamma_d2b", "=", "np", ".", "zeros", "(", "(", "3", ",", ")", ")", "\n", "srgbk", "=", "np", ".", "eye", "(", "3", ")", "\n", "", "else", ":", "\n", "# Prepare demosaicing kernels (bilinear)", "\n", "            ", "dmf", "=", "bilin_kernel", "(", "self", ".", "_h", ".", "kernel", ")", "\n", "\n", "# Prepare gamma correction kernels (obtained from a pre-trained toy model)", "\n", "gamma_d1k", ",", "gamma_d1b", ",", "gamma_d2k", ",", "gamma_d2b", "=", "gamma_kernels", "(", ")", "\n", "\n", "# Example sRGB conversion table", "\n", "srgbk", "=", "np", ".", "array", "(", "[", "[", "1.82691061", ",", "-", "0.65497452", ",", "-", "0.17193617", "]", ",", "\n", "[", "-", "0.00683982", ",", "1.33216381", ",", "-", "0.32532394", "]", ",", "\n", "[", "0.06269717", ",", "-", "0.40055895", ",", "1.33786178", "]", "]", ")", ".", "transpose", "(", ")", "\n", "\n", "# Up-sample the input back the full resolution", "\n", "", "h12", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "12", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "upk", ")", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ",", "trainable", "=", "self", ".", "_h", ".", "trainable_upsampling", ")", "(", "self", ".", "x", ")", "\n", "\n", "# Demosaicing", "\n", "pad", "=", "(", "self", ".", "_h", ".", "kernel", "-", "1", ")", "//", "2", "\n", "bayer", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "h12", ",", "2", ")", "\n", "bayer", "=", "tf", ".", "pad", "(", "bayer", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "'REFLECT'", ")", "\n", "rgb", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "self", ".", "_h", ".", "kernel", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "dmf", ")", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ",", "padding", "=", "'VALID'", ")", "(", "bayer", ")", "\n", "\n", "# Color space conversion", "\n", "srgb", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "srgbk", ")", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ")", "(", "rgb", ",", ")", "\n", "\n", "# Gamma correction", "\n", "rgb_g0", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "12", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "gamma_d1k", ")", ",", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "gamma_d1b", ")", ",", "use_bias", "=", "True", ",", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "tanh", ")", "(", "srgb", ")", "\n", "y", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "gamma_d2k", ")", ",", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "gamma_d2b", ")", ",", "use_bias", "=", "True", ",", "activation", "=", "None", ")", "(", "rgb_g0", ")", "\n", "\n", "# self.y = tf.clip_by_value(self.yy, 0, 1, name='{}/y'.format(self.scoped_name))", "\n", "self", ".", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "self", ".", "_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "[", "self", ".", "x", "]", ",", "outputs", "=", "[", "self", ".", "y", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.INet.model_code": [[292, 296], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_code", "(", "self", ")", ":", "\n", "        ", "return", "'{c}_{cfa}{tu}{r}_{k}x{k}'", ".", "format", "(", "c", "=", "self", ".", "class_name", ",", "cfa", "=", "self", ".", "_h", ".", "cfa_pattern", ",", "k", "=", "self", ".", "_h", ".", "kernel", ",", "\n", "tu", "=", "'T'", "if", "self", ".", "_h", ".", "trainable_upsampling", "else", "''", ",", "r", "=", "'R'", "if", "self", ".", "_h", ".", "random_init", "else", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.DNet.construct_model": [[304, 346], ["helpers.paramspec.ParamSpec", "locals", "pipelines.DNet._h.update", "helpers.kernels.upsampling_kernel", "range", "tensorflow.nn.depth_to_space", "tensorflow.nn.depth_to_space", "tensorflow.concat", "tensorflow.pad", "tensorflow.keras.Model", "tensorflow.pad", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.constant", "tensorflow.keras.layers.Conv2D", "tensorflow.stop_gradient", "tensorflow.keras.layers.Conv2D", "tensorflow.constant", "tensorflow.constant_initializer", "tensorflow.clip_by_value", "pipelines.DNet._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["def", "construct_model", "(", "self", ",", "n_layers", "=", "15", ",", "kernel", "=", "3", ",", "n_features", "=", "64", ")", ":", "\n", "\n", "        ", "self", ".", "_h", "=", "paramspec", ".", "ParamSpec", "(", "{", "\n", "'n_layers'", ":", "(", "15", ",", "int", ",", "(", "1", ",", "32", ")", ")", ",", "\n", "'kernel'", ":", "(", "3", ",", "int", ",", "(", "3", ",", "11", ")", ")", ",", "\n", "'n_features'", ":", "(", "64", ",", "int", ",", "(", "4", ",", "128", ")", ")", ",", "\n", "}", ")", "\n", "params", "=", "locals", "(", ")", "\n", "self", ".", "_h", ".", "update", "(", "**", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "self", ".", "_h", ".", "keys", "(", ")", "if", "k", "in", "params", "}", ")", "\n", "\n", "k_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "\n", "\n", "# Initialize the upsampling kernel", "\n", "upk", "=", "upsampling_kernel", "(", ")", "\n", "\n", "# Padding size", "\n", "pad", "=", "(", "self", ".", "_h", ".", "kernel", "-", "1", ")", "//", "2", "\n", "\n", "# Convolutions on the sub-sampled input tensor", "\n", "deep_x", "=", "self", ".", "x", "\n", "for", "r", "in", "range", "(", "self", ".", "_h", ".", "n_layers", ")", ":", "\n", "            ", "deep_y", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "12", "if", "r", "==", "self", ".", "_h", ".", "n_layers", "-", "1", "else", "self", ".", "_h", ".", "n_features", ",", "self", ".", "_h", ".", "kernel", ",", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "relu", ",", "padding", "=", "'VALID'", ",", "kernel_initializer", "=", "k_initializer", ")", "(", "deep_x", ")", "\n", "deep_x", "=", "tf", ".", "pad", "(", "deep_y", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "'REFLECT'", ")", "\n", "\n", "# Up-sample the input", "\n", "", "h12", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "12", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "upk", ")", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ",", "trainable", "=", "False", ")", "(", "self", ".", "x", ")", "\n", "bayer", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "h12", ",", "2", ")", "\n", "\n", "# Upscale the conv. features and concatenate with the input RGB channels", "\n", "features", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "deep_x", ",", "2", ")", "\n", "bayer_features", "=", "tf", ".", "concat", "(", "(", "features", ",", "bayer", ")", ",", "axis", "=", "3", ")", "\n", "\n", "# Project the concatenated 6-D features (R G B bayer from input + 3 channels from convolutions)", "\n", "pu", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "self", ".", "_h", ".", "n_features", ",", "self", ".", "_h", ".", "kernel", ",", "kernel_initializer", "=", "k_initializer", ",", "use_bias", "=", "True", ",", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "relu", ",", "padding", "=", "'VALID'", ",", "bias_initializer", "=", "tf", ".", "zeros_initializer", ")", "(", "bayer_features", ")", "\n", "\n", "# Final 1x1 conv to project each 64-D feature vector into the RGB colorspace", "\n", "pu", "=", "tf", ".", "pad", "(", "pu", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "'REFLECT'", ")", "\n", "\n", "y", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "ones_initializer", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ",", "padding", "=", "'VALID'", ")", "(", "pu", ")", "\n", "# self.y = tf.clip_by_value(self.yy, 0, 1, name='{}/y'.format(self.scoped_name))", "\n", "self", ".", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "self", ".", "_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "[", "self", ".", "x", "]", ",", "outputs", "=", "[", "self", ".", "y", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.DNet.model_code": [[347, 351], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_code", "(", "self", ")", ":", "\n", "        ", "return", "'{c}_{k}x{k}_{l}x{f}f'", ".", "format", "(", "c", "=", "self", ".", "class_name", ",", "k", "=", "self", ".", "_h", ".", "kernel", ",", "\n", "f", "=", "self", ".", "_h", ".", "n_features", ",", "l", "=", "self", ".", "_h", ".", "n_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ONet.construct_model": [[358, 363], ["tensorflow.keras.Input", "tensorflow.identity", "tensorflow.keras.Model"], "methods", ["None"], ["def", "construct_model", "(", "self", ")", ":", "\n", "        ", "patch_size", "=", "2", "*", "self", ".", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "x", "=", "tf", ".", "keras", ".", "Input", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "patch_size", ",", "patch_size", ",", "3", ")", ")", "\n", "self", ".", "y", "=", "tf", ".", "identity", "(", "self", ".", "x", ")", "\n", "self", ".", "_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "self", ".", "x", ",", "outputs", "=", "self", ".", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.__TensorISP.process": [[372, 413], ["helpers.kernels.upsampling_kernel().reshape", "helpers.kernels.bilin_kernel", "numpy.eye.T.reshape", "tensorflow.nn.conv2d", "tensorflow.nn.depth_to_space", "tensorflow.pad", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "tensorflow.pow", "numpy.eye", "tensorflow.constant", "tensorflow.stop_gradient", "helpers.kernels.upsampling_kernel", "numpy.percentile", "numpy.percentile", "ValueError", "tensorflow.clip_by_value", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.bilin_kernel", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel"], ["def", "process", "(", "self", ",", "x", ",", "srgb_mat", "=", "None", ",", "cfa_pattern", "=", "'gbrg'", ",", "brightness", "=", "'percentile'", ")", ":", "\n", "\n", "        ", "kernel", "=", "5", "\n", "\n", "# Initialize upsampling and demosaicing kernels", "\n", "upk", "=", "upsampling_kernel", "(", "cfa_pattern", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "4", ",", "12", ")", ")", "\n", "dmf", "=", "bilin_kernel", "(", "kernel", ")", "\n", "\n", "# Setup sRGB color conversion", "\n", "if", "srgb_mat", "is", "None", ":", "\n", "            ", "srgb_mat", "=", "np", ".", "eye", "(", "3", ")", "\n", "", "srgb_mat", "=", "srgb_mat", ".", "T", ".", "reshape", "(", "(", "1", ",", "1", ",", "3", ",", "3", ")", ")", "\n", "\n", "# Demosaicing & color space conversion", "\n", "pad", "=", "(", "kernel", "-", "1", ")", "//", "2", "\n", "h12", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "upk", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "bayer", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "h12", ",", "2", ")", "\n", "bayer", "=", "tf", ".", "pad", "(", "bayer", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "'REFLECT'", ")", "\n", "rgb", "=", "tf", ".", "nn", ".", "conv2d", "(", "bayer", ",", "dmf", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n", "# RGB -> sRGB", "\n", "rgb", "=", "tf", ".", "nn", ".", "conv2d", "(", "rgb", ",", "srgb_mat", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "\n", "# Brightness correction", "\n", "if", "brightness", "is", "not", "None", ":", "\n", "            ", "if", "brightness", "==", "'percentile'", ":", "\n", "                ", "percentile", "=", "0.5", "\n", "rgb", "-=", "np", ".", "percentile", "(", "rgb", ",", "percentile", ")", "\n", "rgb", "/=", "np", ".", "percentile", "(", "rgb", ",", "100", "-", "percentile", ")", "\n", "", "elif", "brightness", "==", "'shift'", ":", "\n", "                ", "mult", "=", "0.25", "/", "tf", ".", "reduce_mean", "(", "rgb", ")", "\n", "rgb", "*=", "mult", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Brightness normalization not recognized!'", ")", "\n", "\n", "# Gamma correction", "\n", "", "", "y", "=", "rgb", "\n", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "y", "=", "tf", ".", "pow", "(", "y", ",", "1", "/", "2.2", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines._ClassicISP.__init__": [[420, 432], ["super().__init__", "helpers.kernels.upsampling_kernel().reshape().astype", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "models.layers.DemosaicingLayer", "numpy.eye", "numpy.eye.T.reshape", "helpers.kernels.upsampling_kernel().reshape", "helpers.kernels.upsampling_kernel"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel"], ["def", "__init__", "(", "self", ",", "srgb_mat", "=", "None", ",", "kernel", "=", "5", ",", "c_filters", "=", "(", "3", ",", ")", ",", "cfa_pattern", "=", "'gbrg'", ",", "residual", "=", "False", ",", "brightness", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "up", "=", "upsampling_kernel", "(", "cfa_pattern", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "4", ",", "12", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_upsampling_kernel", "=", "tf", ".", "convert_to_tensor", "(", "up", ")", "\n", "\n", "if", "srgb_mat", "is", "None", ":", "\n", "            ", "srgb_mat", "=", "np", ".", "eye", "(", "3", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "self", ".", "_srgb_mat", "=", "tf", ".", "convert_to_tensor", "(", "srgb_mat", ".", "T", ".", "reshape", "(", "(", "1", ",", "1", ",", "3", ",", "3", ")", ")", ")", "\n", "self", ".", "_demosaicing", "=", "layers", ".", "DemosaicingLayer", "(", "c_filters", ",", "kernel", ",", "'leaky_relu'", ",", "residual", ")", "\n", "self", ".", "_brightness", "=", "brightness", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines._ClassicISP.call": [[433, 454], ["tensorflow.nn.conv2d", "tensorflow.nn.depth_to_space", "pipelines._ClassicISP._demosaicing", "tensorflow.nn.conv2d", "tensorflow.pow", "numpy.percentile", "numpy.percentile", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "h12", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "self", ".", "_upsampling_kernel", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "bayer", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "h12", ",", "2", ")", "\n", "\n", "rgb", "=", "self", ".", "_demosaicing", "(", "bayer", ")", "\n", "rgb", "=", "tf", ".", "nn", ".", "conv2d", "(", "rgb", ",", "self", ".", "_srgb_mat", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "\n", "# Brightness correction", "\n", "if", "self", ".", "_brightness", "==", "'percentile'", ":", "\n", "            ", "percentile", "=", "0.5", "\n", "rgb", "-=", "np", ".", "percentile", "(", "rgb", ",", "percentile", ")", "\n", "rgb", "/=", "np", ".", "percentile", "(", "rgb", ",", "100", "-", "percentile", ")", "\n", "", "elif", "self", ".", "_brightness", "==", "'shift'", ":", "\n", "            ", "mult", "=", "0.25", "/", "tf", ".", "reduce_mean", "(", "rgb", ")", "\n", "rgb", "*=", "mult", "\n", "\n", "# Gamma correction", "\n", "", "y", "=", "rgb", "\n", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "1.0", "/", "255", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "y", "=", "tf", ".", "pow", "(", "y", ",", "1", "/", "2.2", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.construct_model": [[470, 482], ["helpers.paramspec.ParamSpec", "locals", "pipelines.ClassicISP._h.update", "pipelines._ClassicISP", "pipelines.ClassicISP._h.to_dict", "helpers.paramspec.numbers_in_range", "pipelines.ClassicISP._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.numbers_in_range", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["def", "construct_model", "(", "self", ",", "srgb_mat", "=", "None", ",", "kernel", "=", "5", ",", "c_filters", "=", "(", ")", ",", "cfa_pattern", "=", "'gbrg'", ",", "residual", "=", "True", ",", "brightness", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "_h", "=", "paramspec", ".", "ParamSpec", "(", "{", "\n", "'kernel'", ":", "(", "5", ",", "int", ",", "(", "3", ",", "11", ")", ")", ",", "\n", "'c_filters'", ":", "(", "(", ")", ",", "tuple", ",", "paramspec", ".", "numbers_in_range", "(", "int", ",", "1", ",", "1024", ")", ")", ",", "\n", "'cfa_pattern'", ":", "(", "'gbrg'", ",", "str", ",", "{", "'gbrg'", ",", "'rggb'", ",", "'bggr'", "}", ")", ",", "\n", "'residual'", ":", "(", "True", ",", "bool", ",", "None", ")", "\n", "}", ")", "\n", "params", "=", "locals", "(", ")", "\n", "self", ".", "_h", ".", "update", "(", "**", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "self", ".", "_h", ".", "keys", "(", ")", "if", "k", "in", "params", "}", ")", "\n", "self", ".", "_model", "=", "_ClassicISP", "(", "**", "self", ".", "_h", ".", "to_dict", "(", ")", ")", "\n", "self", ".", "y", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern": [[483, 489], ["cfa_pattern.lower.lower.lower", "helpers.kernels.upsampling_kernel().reshape().astype", "tensorflow.convert_to_tensor", "pipelines.ClassicISP._h.update", "helpers.kernels.upsampling_kernel().reshape", "helpers.kernels.upsampling_kernel"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel"], ["", "def", "set_cfa_pattern", "(", "self", ",", "cfa_pattern", ")", ":", "\n", "        ", "if", "cfa_pattern", "is", "not", "None", ":", "\n", "            ", "cfa_pattern", "=", "cfa_pattern", ".", "lower", "(", ")", "\n", "up", "=", "upsampling_kernel", "(", "cfa_pattern", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "4", ",", "12", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_model", ".", "_upsampling_kernel", "=", "tf", ".", "convert_to_tensor", "(", "up", ")", "\n", "self", ".", "_h", ".", "update", "(", "cfa_pattern", "=", "cfa_pattern", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion": [[490, 494], ["srgb_mat.T.reshape().astype", "tensorflow.convert_to_tensor", "srgb_mat.T.reshape"], "methods", ["None"], ["", "", "def", "set_srgb_conversion", "(", "self", ",", "srgb_mat", ")", ":", "\n", "        ", "if", "srgb_mat", "is", "not", "None", ":", "\n", "            ", "srgb", "=", "srgb_mat", ".", "T", ".", "reshape", "(", "(", "1", ",", "1", ",", "3", ",", "3", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_model", ".", "_srgb_mat", "=", "tf", ".", "convert_to_tensor", "(", "srgb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.process": [[495, 502], ["pipelines.ClassicISP.set_cfa_pattern", "pipelines.ClassicISP.set_srgb_conversion", "pipelines.ClassicISP._model", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion"], ["", "", "def", "process", "(", "self", ",", "batch_x", ",", "training", "=", "False", ",", "cfa_pattern", "=", "None", ",", "srgb_mat", "=", "None", ")", ":", "\n", "        ", "if", "batch_x", ".", "ndim", "==", "3", ":", "\n", "            ", "batch_x", "=", "np", ".", "expand_dims", "(", "batch_x", ",", "0", ")", "\n", "\n", "", "self", ".", "set_cfa_pattern", "(", "cfa_pattern", ")", "\n", "self", ".", "set_srgb_conversion", "(", "srgb_mat", ")", "\n", "return", "self", ".", "_model", "(", "batch_x", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.model_code": [[503, 506], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_code", "(", "self", ")", ":", "\n", "        ", "return", "'ClassicISP_{cfa}_{k}x{k}_{fs}-{of}{r}'", ".", "format", "(", "fs", "=", "'-'", ".", "join", "(", "[", "'{:d}'", ".", "format", "(", "x", ")", "for", "x", "in", "self", ".", "_h", ".", "c_filters", "]", ")", ",", "of", "=", "3", ",", "k", "=", "self", ".", "_h", ".", "kernel", ",", "cfa", "=", "self", ".", "_h", ".", "cfa_pattern", ",", "r", "=", "'R'", "if", "self", ".", "_h", ".", "residual", "else", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_camera": [[507, 513], ["pipelines.ClassicISP.set_cfa_pattern", "pipelines.ClassicISP.set_srgb_conversion", "open", "json.load", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "def", "set_camera", "(", "self", ",", "camera", ")", ":", "\n", "        ", "\"\"\" Sets both CFA and sRGB based on camera presets from 'config/cameras.json' \"\"\"", "\n", "with", "open", "(", "'config/cameras.json'", ")", "as", "f", ":", "\n", "            ", "cameras", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "set_cfa_pattern", "(", "cameras", "[", "camera", "]", "[", "'cfa'", "]", ")", "\n", "self", ".", "set_srgb_conversion", "(", "np", ".", "array", "(", "cameras", "[", "camera", "]", "[", "'srgb'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.restore": [[514, 528], ["super().restore", "super().restore.set_camera", "super().restore.set_cfa_pattern", "super().restore.set_srgb_conversion"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_camera", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_cfa_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.set_srgb_conversion"], ["", "@", "classmethod", "\n", "def", "restore", "(", "cls", ",", "dir_name", "=", "'data/models/isp/ClassicISP_auto_3x3_32-32-32-32-3R/'", ",", "*", ",", "camera", "=", "None", ",", "cfa", "=", "None", ",", "srgb", "=", "None", ",", "patch_size", "=", "128", ")", ":", "\n", "        ", "isp", "=", "super", "(", ")", ".", "restore", "(", "dir_name", ")", "\n", "\n", "if", "camera", "is", "not", "None", ":", "\n", "            ", "isp", ".", "set_camera", "(", "camera", ")", "\n", "\n", "", "if", "cfa", "is", "not", "None", ":", "\n", "            ", "isp", ".", "set_cfa_pattern", "(", "cfa", ")", "\n", "\n", "", "if", "srgb", "is", "not", "None", ":", "\n", "            ", "isp", ".", "set_srgb_conversion", "(", "cfa", ")", "\n", "\n", "", "return", "isp", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.summary": [[529, 534], ["len", "len", "set"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "nf", "=", "len", "(", "self", ".", "_h", ".", "c_filters", ")", "\n", "fs", "=", "self", ".", "_h", ".", "c_filters", "[", "0", "]", "if", "len", "(", "set", "(", "self", ".", "_h", ".", "c_filters", ")", ")", "==", "1", "else", "'*'", "\n", "k", "=", "self", ".", "_h", ".", "kernel", "\n", "return", "f'{self.class_name}[{self._h.cfa_pattern}] + CNN demosaicing [{nf}+1 layers : {k}x{k}x{fs} -> 1x1x3]'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.pipelines.ClassicISP.summary_compact": [[535, 540], ["len", "len", "set"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set"], ["", "def", "summary_compact", "(", "self", ")", ":", "\n", "        ", "nf", "=", "len", "(", "self", ".", "_h", ".", "c_filters", ")", "\n", "fs", "=", "self", ".", "_h", ".", "c_filters", "[", "0", "]", "if", "len", "(", "set", "(", "self", ".", "_h", ".", "c_filters", ")", ")", "==", "1", "else", "'*'", "\n", "k", "=", "self", ".", "_h", ".", "kernel", "\n", "return", "f'{self.class_name}[{self._h.cfa_pattern}, {nf}+1 conv2D {k}x{k}x{fs} > 1x1x3]'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.__init__": [[29, 95], ["models.tfmodel.TFModel.__init__", "helpers.paramspec.ParamSpec", "locals", "forensics.FAN._h.update", "tensorflow.keras.Input", "range", "range", "tensorflow.keras.Model", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.losses.SparseCategoricalCrossentropy", "models.layers.ConstrainedConv2D", "int", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.MaxPool2D", "int", "tensorflow.keras.layers.GlobalAveragePooling2D", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "set", "tensorflow.keras.layers.Dropout", "helpers.tf_helpers.activation_mapping.keys", "forensics.FAN._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["def", "__init__", "(", "self", ",", "n_classes", ",", "patch_size", "=", "None", ",", "n_filters", "=", "32", ",", "n_fscale", "=", "2", ",", "n_convolutions", "=", "4", ",", "kernel", "=", "5", ",", "dropout", "=", "0.0", ",", "use_gap", "=", "True", ",", "n_dense", "=", "0", ",", "activation", "=", "'leaky_relu'", ")", ":", "\n", "        ", "\"\"\"\n        Creates a forensic analysis network (see class docstring for details).\n\n        :param n_classes: the number of output classes\n        :param patch_size: input patch size\n        :param n_filters: number of output features for the first conv layer\n        :param n_fscale: multiplier for the number of output features in successive conv layers\n        :param n_convolutions: the number of standard conv layers\n        :param kernel: conv kernel size\n        :param dropout: dropout rate for fully connected layers\n        :param use_gap: whether to use a GAP or to reshape the final conv tensor\n        :param activation: activation function (see helpers.tf_helpers.activation_mapping for available activations)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Set-up and validate hyper-parameters            ", "\n", "self", ".", "_h", "=", "paramspec", ".", "ParamSpec", "(", "{", "\n", "'n_classes'", ":", "(", "7", ",", "int", ",", "(", "2", ",", "256", ")", ")", ",", "\n", "'n_filters'", ":", "(", "32", ",", "int", ",", "(", "4", ",", "128", ")", ")", ",", "\n", "'n_fscale'", ":", "(", "2", ",", "float", ",", "(", "0.25", ",", "4", ")", ")", ",", "\n", "'n_convolutions'", ":", "(", "4", ",", "int", ",", "(", "1", ",", "32", ")", ")", ",", "\n", "'kernel'", ":", "(", "5", ",", "int", ",", "(", "3", ",", "11", ")", ")", ",", "\n", "'dropout'", ":", "(", "0", ",", "float", ",", "(", "0", ",", "1", ")", ")", ",", "\n", "'use_gap'", ":", "(", "False", ",", "bool", ",", "None", ")", ",", "\n", "'n_dense'", ":", "(", "2", ",", "int", ",", "(", "0", ",", "16", ")", ")", ",", "\n", "'activation'", ":", "(", "'leaky_relu'", ",", "str", ",", "set", "(", "tf_helpers", ".", "activation_mapping", ".", "keys", "(", ")", ")", ")", "\n", "}", ")", "\n", "params", "=", "locals", "(", ")", "\n", "self", ".", "_h", ".", "update", "(", "**", "{", "k", ":", "params", "[", "k", "]", "for", "k", "in", "self", ".", "_h", ".", "keys", "(", ")", "}", ")", "\n", "activation", "=", "tf_helpers", ".", "activation_mapping", "[", "self", ".", "_h", ".", "activation", "]", "\n", "\n", "# Setup network input", "\n", "self", ".", "x", "=", "tf", ".", "keras", ".", "Input", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "(", "patch_size", ",", "patch_size", ",", "3", ")", ")", "\n", "\n", "# Constrained convolution with a learned residual filter", "\n", "net", "=", "ConstrainedConv2D", "(", ")", "(", "self", ".", "x", ")", "\n", "\n", "# Standard convolutional layers", "\n", "for", "_", "in", "range", "(", "self", ".", "_h", ".", "n_convolutions", ")", ":", "\n", "            ", "net", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "n_filters", ",", "[", "self", ".", "_h", ".", "kernel", ",", "self", ".", "_h", ".", "kernel", "]", ",", "padding", "=", "'same'", ",", "activation", "=", "activation", ")", "(", "net", ")", "\n", "net", "=", "tf", ".", "keras", ".", "layers", ".", "MaxPool2D", "(", "[", "2", ",", "2", "]", ")", "(", "net", ")", "\n", "n_filters", "=", "int", "(", "n_filters", "*", "self", ".", "_h", ".", "n_fscale", ")", "\n", "\n", "", "n_filters", "=", "n_filters", "//", "n_fscale", "\n", "\n", "# Final 1 x 1 convolution", "\n", "net", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "int", "(", "n_filters", ")", ",", "[", "1", ",", "1", "]", ",", "activation", "=", "activation", ")", "(", "net", ")", "\n", "\n", "# GAP / Feature formation", "\n", "if", "use_gap", ":", "\n", "            ", "net", "=", "tf", ".", "keras", ".", "layers", ".", "GlobalAveragePooling2D", "(", ")", "(", "net", ")", "\n", "", "else", ":", "\n", "            ", "net", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "net", ")", "\n", "\n", "# Fully-connected classifier", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_h", ".", "n_dense", ")", ":", "\n", "            ", "n_filters", "=", "n_filters", "//", "n_fscale", "\n", "net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "n_filters", ",", "activation", "=", "activation", ")", "(", "net", ")", "\n", "if", "dropout", ">", "0", ":", "net", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "(", "net", ")", "\n", "\n", "", "self", ".", "y", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "n_classes", ",", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "softmax", ")", "(", "net", ")", "\n", "\n", "self", ".", "_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "self", ".", "x", ",", "outputs", "=", "self", ".", "y", ")", "\n", "self", ".", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", ")", "\n", "self", ".", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "SparseCategoricalCrossentropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.reset_performance_stats": [[96, 101], ["None"], "methods", ["None"], ["", "def", "reset_performance_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "performance", "=", "{", "\n", "'loss'", ":", "{", "'training'", ":", "[", "]", ",", "'validation'", ":", "[", "]", "}", ",", "\n", "'accuracy'", ":", "{", "'validation'", ":", "[", "]", "}", ",", "\n", "'confusion'", ":", "[", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.process": [[103, 106], ["forensics.FAN._model"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "batch_x", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\" Returns class probabilities for an image batch (NHWC:rgb). \"\"\"", "\n", "return", "self", ".", "_model", "(", "batch_x", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.process_and_decide": [[107, 115], ["forensics.FAN._model", "forensics.FAN.numpy().argmax", "forensics.FAN.numpy().argmax", "forensics.FAN.numpy().max", "forensics.FAN.numpy", "forensics.FAN.numpy", "forensics.FAN.numpy"], "methods", ["None"], ["", "def", "process_and_decide", "(", "self", ",", "batch_x", ",", "with_confidence", "=", "False", ")", ":", "\n", "        ", "\"\"\" Returns the predicted class (and optionally its confidence) for an image batch (NHWC:rgb).  \"\"\"", "\n", "probs", "=", "self", ".", "_model", "(", "batch_x", ")", "\n", "\n", "if", "with_confidence", ":", "\n", "            ", "return", "probs", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", ",", "probs", ".", "numpy", "(", ")", ".", "max", "(", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "probs", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.training_step": [[116, 126], ["tape.gradient", "forensics.FAN.optimizer.apply_gradients", "tensorflow.GradientTape", "forensics.FAN._model", "forensics.FAN.loss", "forensics.FAN.optimizer.lr.assign", "zip"], "methods", ["None"], ["", "", "def", "training_step", "(", "self", ",", "batch_x", ",", "target_labels", ",", "learning_rate", "=", "None", ")", ":", "\n", "        ", "\"\"\" Make a single training step and return the current loss. (Use class numbers for target labels.) \"\"\"", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "            ", "class_probabilities", "=", "self", ".", "_model", "(", "batch_x", ")", "\n", "loss", "=", "self", ".", "loss", "(", "target_labels", ",", "class_probabilities", ")", "\n", "\n", "", "if", "learning_rate", "is", "not", "None", ":", "self", ".", "optimizer", ".", "lr", ".", "assign", "(", "learning_rate", ")", "\n", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "_model", ".", "trainable_weights", ")", "\n", "self", ".", "optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "self", ".", "_model", ".", "trainable_weights", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.forensics.FAN.summary": [[127, 134], ["forensics.FAN.count_parameters"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "return", "'{kernel}x{kernel} CNN: 1+{conv}+1 conv layers {gap}+ {fc} fc layers [{params:,} parameters]'", ".", "format", "(", "\n", "kernel", "=", "self", ".", "_h", ".", "kernel", ",", "\n", "conv", "=", "self", ".", "_h", ".", "n_convolutions", ",", "\n", "fc", "=", "self", ".", "_h", ".", "n_dense", ",", "\n", "gap", "=", "'+ (GAP) '", "if", "self", ".", "_h", ".", "use_gap", "else", "''", ",", "\n", "params", "=", "self", ".", "count_parameters", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.__init__": [[49, 100], ["models.tfmodel.TFModel.__init__", "helpers.paramspec.ParamSpec", "locals", "compression.DCN._h.update", "tensorflow.keras.Input", "models.layers.DiscreteLatent", "compression.DCN.construct_model", "compression.DCN._has_attributes", "tensorflow.keras.optimizers.Adam", "tensorflow.reduce_mean", "NotImplementedError", "tensorflow.image.ssim", "tensorflow.nn.l2_loss", "compression.DCN._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.TwitterDCN.construct_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._has_attributes", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["", "histogram", "=", "dcn", ".", "sess", ".", "run", "(", "dcn", ".", "histogram", ",", "feed_dict", "=", "feed_dict", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "histogram", "=", "histogram", "/", "histogram", ".", "max", "(", ")", "\n", "histogram", "=", "histogram", ".", "reshape", "(", "(", "-", "1", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# Create a dense version of the quantization bins", "\n", "bin_centers", "=", "np", ".", "arange", "(", "qmin", "-", "1", ",", "qmax", "+", "1", ",", "0.1", ")", "\n", "bin_boundaries", "=", "np", ".", "convolve", "(", "bin_centers", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "bin_centers", "=", "bin_centers", "[", "1", ":", "-", "1", "]", "\n", "\n", "# Compute empirical histogram based on latent representation", "\n", "hist", "=", "np", ".", "histogram", "(", "batch_z", ",", "bins", "=", "bin_boundaries", ",", "density", "=", "True", ")", "[", "0", "]", "\n", "hist", "=", "hist", "/", "hist", ".", "max", "(", ")", "\n", "\n", "entropy", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "codebook", ")", "\n", "\n", "ticks", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "np", ".", "percentile", "(", "batch_z", ",", "[", "1", ",", "5", ",", "25", ",", "50", ",", "75", ",", "95", ",", "99", "]", ")", ")", ")", "\n", "\n", "if", "ax", "is", "None", ":", "\n", "        ", "fig", "=", "Figure", "(", "figsize", "=", "(", "10", ",", "2", ")", ")", "\n", "ax", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "", "ax", ".", "set_xlim", "(", "[", "qmin", "-", "1", ",", "qmax", "+", "1", "]", ")", "\n", "ax", ".", "set_xticks", "(", "ticks", ")", "\n", "ax", ".", "stem", "(", "bin_centers", ",", "hist", ",", "linefmt", "=", "'r:'", ",", "markerfmt", "=", "'r.'", ")", "# width=bin_centers[1] - bin_centers[0]", "\n", "ax", ".", "bar", "(", "codebook", ",", "histogram", ",", "width", "=", "(", "codebook", "[", "1", "]", "-", "codebook", "[", "0", "]", ")", "/", "2", ",", "color", "=", "'b'", ",", "alpha", "=", "0.5", ")", "\n", "ax", ".", "set_title", "(", "'{}QLR histogram (H={:.1f})'", ".", "format", "(", "title", ",", "entropy", ")", ")", "\n", "ax", ".", "legend", "(", "[", "'Quantized values'", ",", "'Soft estimate'", "]", ",", "loc", "=", "'upper right'", ")", "\n", "\n", "# Render the plot as a PNG image and return a bitmap array", "\n", "return", "ax", ".", "figure", "\n", "\n", "\n", "", "def", "visualize_codebook", "(", "dcn", ")", ":", "\n", "    ", "qmin", "=", "-", "2", "**", "(", "dcn", ".", "latent_bpf", "-", "1", ")", "+", "1", "\n", "qmax", "=", "2", "**", "(", "dcn", ".", "latent_bpf", "-", "1", ")", "\n", "\n", "uniform_cbook", "=", "np", ".", "arange", "(", "qmin", ",", "qmax", "+", "1", ")", "\n", "codebook", "=", "dcn", ".", "get_codebook", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "10", ",", "1", ")", ")", "\n", "\n", "for", "x1", ",", "x2", "in", "zip", "(", "codebook", ",", "uniform_cbook", ")", ":", "\n", "        ", "fig", ".", "gca", "(", ")", ".", "plot", "(", "[", "x1", ",", "x2", "]", ",", "[", "0", ",", "1", "]", ",", "'k:'", ")", "\n", "\n", "", "fig", ".", "gca", "(", ")", ".", "plot", "(", "codebook", ",", "np", ".", "zeros_like", "(", "codebook", ")", ",", "'x'", ")", "\n", "fig", ".", "gca", "(", ")", ".", "plot", "(", "uniform_cbook", ",", "np", ".", "ones_like", "(", "uniform_cbook", ")", ",", "'ro'", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_ylim", "(", "[", "-", "1", ",", "2", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_xlim", "(", "[", "qmin", "-", "1", ",", "qmax", "+", "1", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_yticks", "(", "[", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_xticks", "(", "uniform_cbook", ")", "\n", "\n", "# Render the plot as a PNG image and return a bitmap array", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.construct_model": [[101, 103], ["NotImplementedError"], "methods", ["None"], ["return", "fig", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.reset_performance_stats": [[104, 106], ["compression.DCN._reset_performance"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._reset_performance"], ["", "def", "save_progress", "(", "dcn", ",", "data", ",", "training", ",", "out_dir", ")", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'progress.json'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compress": [[107, 110], ["compression.DCN._encoder", "numpy.expand_dims"], "methods", ["None"], ["output_stats", "=", "{", "\n", "'training_spec'", ":", "training", ",", "\n", "'data'", ":", "data", ".", "summary", "(", ")", ",", "\n", "'codec'", ":", "{", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.decompress": [[111, 114], ["compression.DCN._decoder", "numpy.expand_dims"], "methods", ["None"], ["'model'", ":", "dcn", ".", "class_name", ",", "\n", "'init'", ":", "repr", "(", "dcn", ")", ",", "\n", "'args'", ":", "dcn", ".", "get_hyperparameters", "(", ")", ",", "\n", "'codebook'", ":", "dcn", ".", "get_codebook", "(", ")", ".", "tolist", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.process": [[115, 122], ["compression.DCN._model"], "methods", ["None"], ["'performance'", ":", "dcn", ".", "performance", ",", "\n", "}", ",", "\n", "}", "\n", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output_stats", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.training_step": [[123, 138], ["compression.DCN.ssim", "tape.gradient", "compression.DCN.optimizer.apply_gradients", "tensorflow.GradientTape", "compression.DCN._model", "compression.DCN.loss", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "compression.DCN.optimizer.lr.assign", "zip", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim"], ["", "", "def", "train_dcn", "(", "dcn", ",", "training", ",", "data", ",", "directory", "=", "'./data/models/dcn/playground/'", ",", "overwrite", "=", "False", ",", "tensorboard", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    training {\n\n        'augmentation_probs': {\n            'resize': 0.0,\n            'flip_h': 0.5,\n            'flip_v': 0.5\n        }\n    }\n\n    \"\"\"", "\n", "# Compute the number of available batches", "\n", "n_batches", "=", "data", "[", "'training'", "]", "[", "'y'", "]", ".", "shape", "[", "0", "]", "//", "training", "[", "'batch_size'", "]", "\n", "v_batches", "=", "data", "[", "'validation'", "]", "[", "'y'", "]", ".", "shape", "[", "0", "]", "//", "training", "[", "'batch_size'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.compression_stats": [[140, 165], ["ValueError"], "methods", ["None"], ["perf", "=", "dcn", ".", "performance", "\n", "\n", "caches", "=", "{", "\n", "'loss'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", ",", "\n", "'entropy'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", ",", "\n", "'ssim'", ":", "{", "'training'", ":", "deque", "(", "maxlen", "=", "n_batches", ")", ",", "'validation'", ":", "deque", "(", "maxlen", "=", "v_batches", ")", "}", "\n", "}", "\n", "\n", "n_tail", "=", "5", "\n", "learning_rate", "=", "training", "[", "'learning_rate'", "]", "\n", "model_output_dirname", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "dcn", ".", "model_code", ",", "dcn", ".", "scoped_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "model_output_dirname", ")", "and", "not", "overwrite", ":", "\n", "        ", "print", "(", "'WARNING Directory {} exists, skipping... (use overwrite=True)'", ".", "format", "(", "model_output_dirname", ")", ")", "\n", "return", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_dirname", ")", "\n", "\n", "", "print", "(", "'Output directory: {}'", ".", "format", "(", "model_output_dirname", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Create a summary writer and create the necessary directories", "\n", "if", "tensorboard", ":", "\n", "        ", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "model_output_dirname", ")", "\n", "\n", "", "with", "tqdm", ".", "tqdm", "(", "total", "=", "training", "[", "'n_epochs'", "]", ",", "ncols", "=", "160", ",", "desc", "=", "dcn", ".", "model_code", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "as", "pbar", ":", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.summary": [[167, 172], ["compression.DCN.count_parameters", "str"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters"], ["        ", "for", "epoch", "in", "range", "(", "0", ",", "training", "[", "'n_epochs'", "]", ")", ":", "\n", "\n", "            ", "training", "[", "'current_epoch'", "]", "=", "epoch", "\n", "\n", "if", "epoch", ">", "0", "and", "epoch", "%", "training", "[", "'learning_rate_reduction_schedule'", "]", "==", "0", ":", "\n", "                ", "learning_rate", "*=", "training", "[", "'learning_rate_reduction_factor'", "]", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.summary_compact": [[173, 175], ["None"], "methods", ["None"], ["\n", "# Iterate through batches of the training data", "\n", "", "for", "batch_id", "in", "range", "(", "n_batches", ")", ":", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.model_code": [[176, 182], ["hasattr", "ValueError", "type"], "methods", ["None"], ["\n", "# Pick random patch size - will be resized later for augmentation", "\n", "                ", "current_patch", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "training", "[", "'patch_size'", "]", ",", "2", "*", "training", "[", "'patch_size'", "]", ")", ",", "\n", "1", ")", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "\n", "'resize'", "]", "else", "training", "[", "'patch_size'", "]", "\n", "\n", "# Sample next batch", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.DCN.get_codebook": [[183, 185], ["compression.DCN.discrete_latent.quantization.codebook.numpy().reshape", "compression.DCN.discrete_latent.quantization.codebook.numpy"], "methods", ["None"], ["batch_x", "=", "data", ".", "next_training_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ",", "current_patch", ")", "\n", "\n", "# If rescaling needed, apply", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.TwitterDCN.construct_model": [[197, 280], ["compression.TwitterDCN._h.add", "locals", "compression.TwitterDCN._h.update", "tensorflow.nn.leaky_relu", "tensorflow.add", "tensorflow.add", "tensorflow.add", "compression.TwitterDCN.discrete_latent", "tensorflow.keras.Input", "tensorflow.nn.depth_to_space", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.nn.depth_to_space", "tensorflow.nn.depth_to_space", "tensorflow.keras.Model", "tensorflow.keras.Model", "compression.TwitterDCN._encoder", "tensorflow.keras.Model", "int", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.stop_gradient", "numpy.prod", "set", "tensorflow.clip_by_value", "compression.TwitterDCN._decoder", "helpers.tf_helpers.activation_mapping.keys", "compression.TwitterDCN._h.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["if", "np", ".", "random", ".", "uniform", "(", ")", "<", "training", "[", "'augmentation_probs'", "]", "[", "'gamma'", "]", ":", "batch_x", "=", "helpers", ".", "image", ".", "batch_gamma", "(", "batch_x", ")", "\n", "\n", "# Make a training step", "\n", "values", "=", "dcn", ".", "training_step", "(", "batch_x", ",", "learning_rate", ")", "\n", "\n", "for", "key", ",", "value", "in", "values", ".", "items", "(", ")", ":", "\n", "                    ", "caches", "[", "key", "]", "[", "'training'", "]", ".", "append", "(", "value", ")", "\n", "\n", "# Record average values for the whole epoch", "\n", "", "", "for", "key", "in", "[", "'loss'", ",", "'ssim'", ",", "'entropy'", "]", ":", "\n", "                ", "perf", "[", "key", "]", "[", "'training'", "]", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "caches", "[", "key", "]", "[", "'training'", "]", ")", ")", ")", "\n", "\n", "# Get some extra stats", "\n", "", "if", "dcn", ".", "_h", ".", "scale_latent", ":", "\n", "                ", "scaling", "=", "dcn", ".", "discrete_latent", ".", "scaling_factor", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "scaling", "=", "np", ".", "nan", "\n", "\n", "", "codebook", "=", "dcn", ".", "get_codebook", "(", ")", "\n", "\n", "# Iterate through batches of the validation data", "\n", "if", "epoch", "%", "training", "[", "'validation_schedule'", "]", "==", "0", ":", "\n", "\n", "                ", "for", "batch_id", "in", "range", "(", "v_batches", ")", ":", "\n", "                    ", "batch_x", "=", "data", ".", "next_validation_batch", "(", "batch_id", ",", "training", "[", "'batch_size'", "]", ")", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", ".", "numpy", "(", ")", "\n", "batch_y", "=", "dcn", ".", "decompress", "(", "batch_z", ")", ".", "numpy", "(", ")", "\n", "\n", "# Compute loss", "\n", "loss_value", "=", "np", ".", "linalg", ".", "norm", "(", "batch_x", "-", "batch_y", ")", "\n", "caches", "[", "'loss'", "]", "[", "'validation'", "]", ".", "append", "(", "loss_value", ")", "\n", "\n", "# Compute SSIM", "\n", "ssim_value", "=", "metrics", ".", "batch", "(", "batch_x", ",", "batch_y", ",", "metrics", ".", "ssim", ")", "\n", "caches", "[", "'ssim'", "]", "[", "'validation'", "]", ".", "append", "(", "ssim_value", ")", "\n", "\n", "# Entropy", "\n", "entropy_value", "=", "helpers", ".", "stats", ".", "entropy", "(", "batch_z", ",", "codebook", ")", "\n", "caches", "[", "'entropy'", "]", "[", "'validation'", "]", ".", "append", "(", "entropy_value", ")", "\n", "\n", "", "for", "key", "in", "[", "'loss'", ",", "'ssim'", ",", "'entropy'", "]", ":", "\n", "                    ", "perf", "[", "key", "]", "[", "'validation'", "]", ".", "append", "(", "float", "(", "np", ".", "mean", "(", "caches", "[", "key", "]", "[", "'validation'", "]", ")", ")", ")", "\n", "\n", "# Save current snapshot", "\n", "", "indices", "=", "np", ".", "argsort", "(", "np", ".", "var", "(", "batch_x", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "thumbs_pairs_all", "=", "np", ".", "concatenate", "(", "(", "batch_x", "[", "indices", "[", ":", ":", "2", "]", "]", ",", "batch_y", "[", "indices", "[", ":", ":", "2", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "thumbs", "=", "(", "255", "*", "plots", ".", "thumbnails", "(", "thumbs_pairs_all", ",", "ncols", "=", "training", "[", "'batch_size'", "]", "//", "2", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "os", ".", "path", ".", "join", "(", "model_output_dirname", ",", "'thumbnails-{:05d}.png'", ".", "format", "(", "epoch", ")", ")", ",", "thumbs", ")", "\n", "\n", "# Save summaries to TB", "\n", "if", "tensorboard", ":", "\n", "\n", "                    ", "thumbs_pairs_few", "=", "np", ".", "concatenate", "(", "(", "batch_x", "[", "indices", "[", ":", "5", "]", "]", ",", "batch_y", "[", "indices", "[", ":", "5", "]", "]", ")", ",", "axis", "=", "0", ")", "\n", "thumbs_few", "=", "(", "255", "*", "plots", ".", "thumbnails", "(", "thumbs_pairs_few", ",", "ncols", "=", "5", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "# Sample latent space", "\n", "batch_z", "=", "dcn", ".", "compress", "(", "batch_x", ")", "\n", "\n", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "                        ", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "epoch", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss/validation'", ",", "perf", "[", "'loss'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss/training'", ",", "perf", "[", "'loss'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'ssim/validation'", ",", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'ssim/training'", ",", "perf", "[", "'ssim'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'entropy/training'", ",", "perf", "[", "'entropy'", "]", "[", "'training'", "]", "[", "-", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'scaling'", ",", "scaling", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'images/reconstructed'", ",", "np", ".", "expand_dims", "(", "thumbs_few", ",", "axis", "=", "0", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "'histograms/latent'", ",", "batch_z", ")", "\n", "# tf.summary.image('histograms/latent_approx', np.expand_dims(visualize_distribution(dcn, data), axis=0))", "\n", "\n", "if", "dcn", ".", "_h", ".", "train_codebook", ":", "\n", "                            ", "tf", ".", "summary", ".", "scalar", "(", "'codebook/min'", ",", "codebook", ".", "min", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/max'", ",", "codebook", ".", "max", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/mean'", ",", "codebook", ".", "mean", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'codebook/diff_variance'", ",", "np", ".", "var", "(", "np", ".", "convolve", "(", "codebook", ",", "[", "-", "1", ",", "1", "]", ",", "mode", "=", "'valid'", ")", ")", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'codebook/centroids'", ",", "np", ".", "expand_dims", "(", "visualize_codebook", "(", "dcn", ")", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Save stats to a JSON log", "\n", "", "save_progress", "(", "dcn", ",", "data", ",", "training", ",", "model_output_dirname", ")", "\n", "\n", "# Save current checkpoint", "\n", "dcn", ".", "save_model", "(", "model_output_dirname", ",", "epoch", ",", "quiet", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.compression.TwitterDCN.model_code": [[281, 292], ["parameter_summary.append", "parameter_summary.append", "parameter_summary.append", "parameter_summary.append"], "methods", ["None"], ["\n", "# Check for convergence or model deterioration", "\n", "if", "len", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", ")", ">", "5", ":", "\n", "                    ", "current", "=", "np", ".", "mean", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "n_tail", ":", "]", ")", "\n", "previous", "=", "np", ".", "mean", "(", "perf", "[", "'ssim'", "]", "[", "'validation'", "]", "[", "-", "(", "n_tail", "+", "1", ")", ":", "-", "1", "]", ")", "\n", "perf_change", "=", "abs", "(", "(", "current", "-", "previous", ")", "/", "previous", ")", "\n", "\n", "if", "perf_change", "<", "training", "[", "'convergence_threshold'", "]", ":", "\n", "                        ", "print", "(", "'Early stopping - the model converged, validation SSIM change {:.4f}'", ".", "format", "(", "perf_change", ")", ")", "\n", "break", "\n", "\n", "", "if", "current", "<", "0.9", "*", "previous", ":", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.ConstrainedConv2D.__init__": [[36, 44], ["super().__init__", "numpy.array", "layers.ConstrainedConv2D.add_weight", "tensorflow.constant_initializer", "helpers.kernels.repeat_2dfilter"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.repeat_2dfilter"], ["def", "__init__", "(", "self", ",", "filter_strength", "=", "100", ",", "trainable", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filter_strength", "=", "filter_strength", "\n", "\n", "f", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "-", "1", ",", "-", "2", ",", "-", "1", ",", "0", "]", ",", "[", "0", ",", "-", "2", ",", "12", ",", "-", "2", ",", "0", "]", ",", "[", "0", ",", "-", "1", ",", "-", "2", ",", "-", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "]", ")", "\n", "self", ".", "kernel", "=", "self", ".", "add_weight", "(", "\"kernel\"", ",", "shape", "=", "(", "5", ",", "5", ",", "3", ",", "3", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "helpers", ".", "kernels", ".", "repeat_2dfilter", "(", "f", ",", "3", ")", ")", ",", "\n", "trainable", "=", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.ConstrainedConv2D.call": [[45, 58], ["tensorflow.constant", "tensorflow.tile", "tensorflow.pad", "tensorflow.nn.conv2d", "helpers.kernels.center_mask_2dfilter", "tensorflow.reshape", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.center_mask_2dfilter"], ["", "def", "call", "(", "self", ",", "input", ")", ":", "\n", "# Mask for normalizing the residual filter", "\n", "        ", "tf_ind", "=", "tf", ".", "constant", "(", "helpers", ".", "kernels", ".", "center_mask_2dfilter", "(", "5", ",", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Normalize the residual filter", "\n", "nf", "=", "self", ".", "kernel", "*", "(", "1", "-", "tf_ind", ")", "\n", "df", "=", "tf", ".", "tile", "(", "tf", ".", "reshape", "(", "tf", ".", "reduce_sum", "(", "nf", ",", "axis", "=", "(", "0", ",", "1", ",", "2", ")", ")", ",", "[", "1", ",", "1", ",", "1", ",", "3", "]", ")", ",", "[", "5", ",", "5", ",", "3", ",", "1", "]", ")", "\n", "nf", "=", "self", ".", "filter_strength", "*", "nf", "/", "df", "\n", "nf", "=", "nf", "-", "self", ".", "filter_strength", "*", "tf_ind", "\n", "\n", "# Convolution with the residual filter", "\n", "xp", "=", "tf", ".", "pad", "(", "input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "2", ",", "2", "]", ",", "[", "2", ",", "2", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'SYMMETRIC'", ")", "\n", "return", "tf", ".", "nn", ".", "conv2d", "(", "xp", ",", "nf", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.Quantization.__init__": [[78, 117], ["super().__init__", "ValueError", "layers.Quantization.add_weight", "tensorflow.constant", "numpy.arange", "tensorflow.constant_initializer", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__"], ["def", "__init__", "(", "self", ",", "rounding", "=", "'soft'", ",", "v", "=", "50", ",", "gamma", "=", "25", ",", "latent_bpf", "=", "4", ",", "trainable", "=", "False", ",", "taylor_terms", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Note that not all parameters are applicable to all approximation modes.\n\n        :param rounding: method of rounding approximation\n\n        # Soft-codebook approximation\n\n        :param v: degrees of freedom for the distance kernel (0 -> Gaussian, >0 -> t-Student)\n        :param gamma: controls the scale of the kernel\n        :param latent_bpf: range of the of the quantization codebook - specified in bits/feature\n        :param trainable: option to make the codebook trainable (not tested)\n\n        # Harmonic approximation\n\n        :param taylor_terms: number of terms for the harmonic Taylor approximation\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "rounding", "not", "in", "{", "'round'", ",", "'sin'", ",", "'soft'", ",", "'identity'", ",", "'harmonic'", ",", "'soft-codebook'", "}", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported quantization: {}'", ".", "format", "(", "rounding", ")", ")", "\n", "\n", "", "self", ".", "rounding", "=", "rounding", "\n", "self", ".", "taylor_terms", "=", "taylor_terms", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "latent_bpf", "=", "latent_bpf", "\n", "self", ".", "trainable", "=", "trainable", "\n", "\n", "# Setup codebook", "\n", "# Even if the codebook is not used for quantization, it may be used for entropy estimation somewhere else", "\n", "# TODO Seemingly unnecessary codebook init (should this be moved/fixed?)", "\n", "qmin", "=", "-", "2", "**", "(", "self", ".", "latent_bpf", "-", "1", ")", "+", "1", "\n", "qmax", "=", "2", "**", "(", "self", ".", "latent_bpf", "-", "1", ")", "\n", "\n", "if", "self", ".", "trainable", ":", "\n", "            ", "self", ".", "codebook", "=", "self", ".", "add_weight", "(", "initializer", "=", "tf", ".", "constant_initializer", "(", "np", ".", "arange", "(", "qmin", ",", "qmax", "+", "1", ")", ")", ",", "shape", "=", "(", "1", ",", "2", "**", "self", ".", "latent_bpf", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "codebook", "=", "tf", ".", "constant", "(", "np", ".", "arange", "(", "qmin", ",", "qmax", "+", "1", ")", ",", "shape", "=", "(", "1", ",", "2", "**", "self", ".", "latent_bpf", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.Quantization.call": [[118, 173], ["tensorflow.round", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.add", "tensorflow.sin", "tensorflow.stop_gradient", "range", "tensorflow.sin", "tensorflow.round", "tensorflow.sin", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.cast", "tensorflow.reshape", "tensorflow.gather", "tensorflow.reshape", "tensorflow.identity", "tensorflow.pow", "tensorflow.sin", "tensorflow.exp", "tensorflow.pow", "tensorflow.reduce_sum", "numpy.prod", "tensorflow.matmul", "tensorflow.shape", "tensorflow.argmax", "tensorflow.shape", "tensorflow.stop_gradient", "tensorflow.cast", "tensorflow.cast", "tensorflow.transpose", "tensorflow.pow", "tensorflow.cast", "tensorflow.pow", "tensorflow.cast", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add"], ["", "", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "self", ".", "rounding", "==", "'round'", ":", "\n", "            ", "x", "=", "tf", ".", "round", "(", "x", ")", "\n", "\n", "", "elif", "self", ".", "rounding", "==", "'sin'", ":", "\n", "            ", "x", "=", "tf", ".", "subtract", "(", "x", ",", "tf", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "x", ")", "/", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "\n", "", "elif", "self", ".", "rounding", "==", "'soft'", ":", "\n", "            ", "x_", "=", "tf", ".", "subtract", "(", "x", ",", "tf", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "x", ")", "/", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "x", "=", "tf", ".", "add", "(", "tf", ".", "stop_gradient", "(", "tf", ".", "round", "(", "x", ")", "-", "x_", ")", ",", "x_", ")", "\n", "\n", "", "elif", "self", ".", "rounding", "==", "'harmonic'", ":", "\n", "            ", "xa", "=", "x", "-", "tf", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "x", ")", "/", "np", ".", "pi", "\n", "for", "k", "in", "range", "(", "2", ",", "self", ".", "taylor_terms", ")", ":", "\n", "                ", "xa", "+=", "tf", ".", "pow", "(", "-", "1.0", ",", "k", ")", "*", "tf", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "k", "*", "x", ")", "/", "(", "k", "*", "np", ".", "pi", ")", "\n", "", "x", "=", "xa", "\n", "\n", "", "elif", "self", ".", "rounding", "==", "'identity'", ":", "\n", "            ", "x", "=", "x", "\n", "\n", "", "elif", "self", ".", "rounding", "==", "'soft-codebook'", ":", "\n", "\n", "            ", "prec_dtype", "=", "tf", ".", "float64", "\n", "eps", "=", "1e-72", "\n", "\n", "assert", "(", "self", ".", "codebook", ".", "shape", "[", "0", "]", "==", "1", ")", "\n", "assert", "(", "self", ".", "codebook", ".", "shape", "[", "1", "]", ">", "1", ")", "\n", "\n", "values", "=", "tf", ".", "reshape", "(", "x", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "v", "<=", "0", ":", "\n", "# Gaussian soft quantization", "\n", "                ", "weights", "=", "tf", ".", "exp", "(", "-", "self", ".", "gamma", "*", "tf", ".", "pow", "(", "tf", ".", "cast", "(", "values", ",", "dtype", "=", "prec_dtype", ")", "-", "tf", ".", "cast", "(", "self", ".", "codebook", ",", "dtype", "=", "prec_dtype", ")", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "# t-Student soft quantization", "\n", "                ", "dff", "=", "tf", ".", "cast", "(", "values", ",", "dtype", "=", "prec_dtype", ")", "-", "tf", ".", "cast", "(", "self", ".", "codebook", ",", "dtype", "=", "prec_dtype", ")", "\n", "dff", "=", "self", ".", "gamma", "*", "dff", "\n", "weights", "=", "tf", ".", "pow", "(", "(", "1", "+", "tf", ".", "pow", "(", "dff", ",", "2", ")", "/", "self", ".", "v", ")", ",", "-", "(", "self", ".", "v", "+", "1", ")", "/", "2", ")", "\n", "\n", "", "weights", "=", "(", "weights", "+", "eps", ")", "/", "(", "tf", ".", "reduce_sum", "(", "weights", "+", "eps", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "assert", "(", "weights", ".", "shape", "[", "1", "]", "==", "np", ".", "prod", "(", "self", ".", "codebook", ".", "shape", ")", ")", "\n", "\n", "soft", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "matmul", "(", "weights", ",", "tf", ".", "transpose", "(", "tf", ".", "cast", "(", "self", ".", "codebook", ",", "dtype", "=", "prec_dtype", ")", ")", ")", ",", "axis", "=", "1", ")", "\n", "soft", "=", "tf", ".", "cast", "(", "soft", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "soft", "=", "tf", ".", "reshape", "(", "soft", ",", "tf", ".", "shape", "(", "x", ")", ")", "\n", "\n", "hard", "=", "tf", ".", "gather", "(", "self", ".", "codebook", ",", "tf", ".", "argmax", "(", "weights", ",", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", "\n", "hard", "=", "tf", ".", "reshape", "(", "hard", ",", "tf", ".", "shape", "(", "x", ")", ")", "\n", "\n", "x", "=", "tf", ".", "stop_gradient", "(", "hard", "-", "soft", ")", "+", "soft", "\n", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.DiscreteLatent.__init__": [[183, 194], ["super().__init__", "layers.Quantization", "layers.DiscreteLatent.add_weight", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__"], ["def", "__init__", "(", "self", ",", "rounding", "=", "'soft'", ",", "v", "=", "50", ",", "gamma", "=", "25", ",", "latent_bpf", "=", "4", ",", "trainable_codebook", "=", "False", ",", "trainable_scale", "=", "True", ")", ":", "\n", "        ", "super", "(", "DiscreteLatent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "trainable_scale", "=", "trainable_scale", "\n", "self", ".", "rounding", "=", "rounding", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "latent_bpf", "=", "latent_bpf", "\n", "self", ".", "trainable_codebook", "=", "trainable_codebook", "\n", "if", "self", ".", "trainable_scale", ":", "\n", "            ", "self", ".", "scaling_factor", "=", "self", ".", "add_weight", "(", "shape", "=", "(", ")", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1", ")", ",", "name", "=", "'latent_scaling'", ")", "\n", "", "self", ".", "quantization", "=", "Quantization", "(", "rounding", ",", "v", ",", "gamma", ",", "latent_bpf", ",", "trainable_codebook", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.DiscreteLatent.call": [[195, 204], ["layers.DiscreteLatent.quantization", "helpers.tf_helpers.entropy"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "latent", "=", "inputs", "\n", "if", "self", ".", "trainable_scale", ":", "\n", "            ", "latent", "=", "latent", "*", "self", ".", "scaling_factor", "\n", "\n", "", "latent", "=", "self", ".", "quantization", "(", "latent", ")", "\n", "entropy_", "=", "tf_helpers", ".", "entropy", "(", "latent", ",", "self", ".", "quantization", ".", "codebook", ",", "self", ".", "v", ",", "self", ".", "gamma", ")", "[", "0", "]", "\n", "\n", "return", "latent", ",", "entropy_", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.DemosaicingLayer.__init__": [[208, 234], ["super().__init__", "layers.DemosaicingLayer._layers.append", "helpers.kernels.bilin_kernel", "tensorflow.keras.layers.Conv2D", "layers.DemosaicingLayer.add_weight", "layers.DemosaicingLayer._layers.append", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.bilin_kernel"], ["    ", "def", "__init__", "(", "self", ",", "c_filters", ",", "kernel", ",", "activation", ",", "residual", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param c_filters: a tuple with the numbers of filters for initial conv layers\n        :param io_filters: the number of filters in the final 1x1 convolution\n        :param kernel: kernel size for the initial convolutions\n        :param activation: activation function (string, see tf_helpers.activation_mapping)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "activation", "=", "tf_helpers", ".", "activation_mapping", "[", "activation", "]", "\n", "if", "residual", ":", "\n", "            ", "self", ".", "_bilinear_kernel", "=", "helpers", ".", "kernels", ".", "bilin_kernel", "(", "kernel", ")", "\n", "self", ".", "_pad", "=", "(", "kernel", "-", "1", ")", "//", "2", "\n", "self", ".", "_bilinear", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "kernel", ",", "kernel_initializer", "=", "tf", ".", "constant_initializer", "(", "self", ".", "_bilinear_kernel", ")", ",", "use_bias", "=", "False", ",", "activation", "=", "None", ",", "padding", "=", "'VALID'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_alpha", "=", "self", ".", "add_weight", "(", "\"alpha\"", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_bilinear", "=", "None", "\n", "\n", "", "self", ".", "_layers", "=", "[", "]", "\n", "\n", "# Setup conv layers", "\n", "for", "n_filters", "in", "c_filters", ":", "\n", "            ", "self", ".", "_layers", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "n_filters", ",", "kernel", ",", "1", ",", "'same'", ",", "activation", "=", "activation", ")", ")", "\n", "\n", "# Final 1x1 conv to project all features to the RGB color space", "\n", "", "self", ".", "_layers", ".", "append", "(", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "3", ",", "1", ",", "1", ",", "'same'", ",", "\n", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "tanh", "if", "residual", "else", "tf", ".", "keras", ".", "activations", ".", "sigmoid", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.layers.DemosaicingLayer.call": [[235, 259], ["tensorflow.pad", "layers.DemosaicingLayer._bilinear", "l", "tensorflow.constant", "len", "tensorflow.stop_gradient", "l", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "clip", "=", "True", ")", ":", "\n", "# Learn the RGB output directly", "\n", "        ", "if", "self", ".", "_bilinear", "is", "None", ":", "\n", "            ", "f", "=", "inputs", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "                ", "f", "=", "l", "(", "f", ")", "\n", "", "y", "=", "f", "\n", "\n", "# Learn a residual wrt a bilinear filter", "\n", "", "else", ":", "\n", "            ", "bayer", "=", "tf", ".", "pad", "(", "inputs", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "self", ".", "_pad", ",", "self", ".", "_pad", "]", ",", "[", "self", ".", "_pad", ",", "self", ".", "_pad", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "'REFLECT'", ")", "\n", "x", "=", "self", ".", "_bilinear", "(", "bayer", ")", "\n", "if", "len", "(", "self", ".", "_layers", ")", ">", "1", ":", "\n", "                ", "f", "=", "inputs", "\n", "for", "l", "in", "self", ".", "_layers", ":", "\n", "                    ", "f", "=", "l", "(", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "f", "=", "0", "\n", "", "y", "=", "x", "-", "self", ".", "_alpha", "*", "f", "\n", "\n", "", "if", "clip", ":", "\n", "            ", "y", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "-", "y", ")", "+", "y", "\n", "\n", "", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.DifferentiableJPEG.__init__": [[47, 90], ["super().__init__", "numpy.array", "numpy.array", "numpy.array", "numpy.transpose", "models.layers.Quantization", "ValueError", "ValueError", "jpeg.DifferentiableJPEG.add_weight", "jpeg.DifferentiableJPEG.add_weight", "jpeg.is_valid_quality", "numpy.ones", "compression.jpeg_helpers.jpeg_qtable", "numpy.ones", "compression.jpeg_helpers.jpeg_qtable", "numpy.ones", "compression.jpeg_helpers.jpeg_qtable", "numpy.ones", "compression.jpeg_helpers.jpeg_qtable", "helpers.utils.is_number", "helpers.utils.is_number", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "helpers.utils.is_number", "helpers.utils.is_number"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.is_valid_quality", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["    ", "def", "__init__", "(", "self", ",", "quality", "=", "None", ",", "rounding_approximation", "=", "'sin'", ",", "rounding_approximation_steps", "=", "5", ",", "trainable", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "self", ")", "\n", "\n", "if", "quality", "is", "not", "None", "and", "not", "is_valid_quality", "(", "quality", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid JPEG quality: requires int in [1,100] or an iterable with least 2 such numbers'", ")", "\n", "\n", "# Sanitize inputs", "\n", "", "if", "rounding_approximation", "is", "not", "None", "and", "rounding_approximation", "not", "in", "[", "'sin'", ",", "'harmonic'", ",", "'soft'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported rounding approximation: {}'", ".", "format", "(", "rounding_approximation", ")", ")", "\n", "\n", "# Quantization tables", "\n", "", "if", "trainable", ":", "\n", "            ", "q_mtx_luma_init", "=", "np", ".", "ones", "(", "(", "8", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "not", "is_number", "(", "quality", ")", "else", "jpeg_qtable", "(", "quality", ",", "0", ")", "\n", "q_mtx_chroma_init", "=", "np", ".", "ones", "(", "(", "8", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "not", "is_number", "(", "quality", ")", "else", "jpeg_qtable", "(", "quality", ",", "1", ")", "\n", "self", ".", "_q_mtx_luma", "=", "self", ".", "add_weight", "(", "'Q_mtx_luma'", ",", "[", "8", ",", "8", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "q_mtx_luma_init", ")", ")", "\n", "self", ".", "_q_mtx_chroma", "=", "self", ".", "add_weight", "(", "'Q_mtx_chroma'", ",", "[", "8", ",", "8", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "q_mtx_chroma_init", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_q_mtx_luma", "=", "np", ".", "ones", "(", "(", "8", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "not", "is_number", "(", "quality", ")", "else", "jpeg_qtable", "(", "quality", ",", "0", ")", "\n", "self", ".", "_q_mtx_chroma", "=", "np", ".", "ones", "(", "(", "8", ",", "8", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "not", "is_number", "(", "quality", ")", "else", "jpeg_qtable", "(", "quality", ",", "1", ")", "\n", "\n", "# Parameters", "\n", "", "self", ".", "quality", "=", "quality", "\n", "self", ".", "trainable", "=", "trainable", "\n", "self", ".", "rounding_approximation", "=", "rounding_approximation", "\n", "self", ".", "rounding_approximation_steps", "=", "rounding_approximation_steps", "\n", "\n", "# RGB to YCbCr conversion", "\n", "self", ".", "_color_F", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0.299", ",", "0.587", ",", "0.114", "]", ",", "[", "128", ",", "-", "0.168736", ",", "-", "0.331264", ",", "0.5", "]", ",", "[", "128", ",", "0.5", ",", "-", "0.418688", ",", "-", "0.081312", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_color_I", "=", "np", ".", "array", "(", "[", "[", "-", "1.402", "*", "128", ",", "1", ",", "0", ",", "1.402", "]", ",", "[", "1.058272", "*", "128", ",", "1", ",", "-", "0.344136", ",", "-", "0.714136", "]", ",", "[", "-", "1.772", "*", "128", ",", "1", ",", "1.772", ",", "0", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# DCT", "\n", "self", ".", "_dct_F", "=", "np", ".", "array", "(", "[", "[", "0.3536", ",", "0.3536", ",", "0.3536", ",", "0.3536", ",", "0.3536", ",", "0.3536", ",", "0.3536", ",", "0.3536", "]", ",", "\n", "[", "0.4904", ",", "0.4157", ",", "0.2778", ",", "0.0975", ",", "-", "0.0975", ",", "-", "0.2778", ",", "-", "0.4157", ",", "-", "0.4904", "]", ",", "\n", "[", "0.4619", ",", "0.1913", ",", "-", "0.1913", ",", "-", "0.4619", ",", "-", "0.4619", ",", "-", "0.1913", ",", "0.1913", ",", "0.4619", "]", ",", "\n", "[", "0.4157", ",", "-", "0.0975", ",", "-", "0.4904", ",", "-", "0.2778", ",", "0.2778", ",", "0.4904", ",", "0.0975", ",", "-", "0.4157", "]", ",", "\n", "[", "0.3536", ",", "-", "0.3536", ",", "-", "0.3536", ",", "0.3536", ",", "0.3536", ",", "-", "0.3536", ",", "-", "0.3536", ",", "0.3536", "]", ",", "\n", "[", "0.2778", ",", "-", "0.4904", ",", "0.0975", ",", "0.4157", ",", "-", "0.4157", ",", "-", "0.0975", ",", "0.4904", ",", "-", "0.2778", "]", ",", "\n", "[", "0.1913", ",", "-", "0.4619", ",", "0.4619", ",", "-", "0.1913", ",", "-", "0.1913", ",", "0.4619", ",", "-", "0.4619", ",", "0.1913", "]", ",", "\n", "[", "0.0975", ",", "-", "0.2778", ",", "0.4157", ",", "-", "0.4904", ",", "0.4904", ",", "-", "0.4157", ",", "0.2778", ",", "-", "0.0975", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_dct_I", "=", "np", ".", "transpose", "(", "self", ".", "_dct_F", ")", "\n", "\n", "# Quantization layer", "\n", "self", ".", "quantization", "=", "Quantization", "(", "self", ".", "rounding_approximation", ",", "self", ".", "rounding_approximation_steps", ",", "latent_bpf", "=", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.DifferentiableJPEG.call": [[91, 160], ["tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.pad", "tensorflow.nn.conv2d", "tensorflow.name_scope", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.nn.space_to_depth", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.tile", "tensorflow.tile", "tensorflow.concat", "tensorflow.tile", "jpeg.DifferentiableJPEG.quantization", "tensorflow.name_scope", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.nn.depth_to_space", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.name_scope", "tensorflow.pad", "tensorflow.nn.conv2d", "tensorflow.clip_by_value", "tensorflow.reshape", "tensorflow.tile", "tensorflow.tile", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.transpose", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "block_size", "=", "8", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'jpeg'", ")", ":", "\n", "\n", "# Color conversion (RGB -> YCbCr)", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'rgb_to_ycbcr'", ")", ":", "\n", "\n", "                ", "xc", "=", "tf", ".", "pad", "(", "255.0", "*", "inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", "]", ",", "'CONSTANT'", ",", "constant_values", "=", "1", ")", "\n", "ycbcr", "=", "tf", ".", "nn", ".", "conv2d", "(", "xc", ",", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "self", ".", "_color_F", ")", ",", "[", "1", ",", "1", ",", "4", ",", "3", "]", ")", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'blocking'", ")", ":", "\n", "# Re-organize to get non-overlapping blocks in the following form", "\n", "# (n_examples * 3, block_size, block_size, n_blocks)", "\n", "                ", "p", "=", "tf", ".", "transpose", "(", "ycbcr", "-", "127", ",", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "p", ")", "[", "2", "]", ",", "tf", ".", "shape", "(", "p", ")", "[", "3", "]", "]", ")", "\n", "p", "=", "tf", ".", "expand_dims", "(", "p", ",", "axis", "=", "3", ")", "\n", "p", "=", "tf", ".", "nn", ".", "space_to_depth", "(", "p", ",", "block_size", ")", "\n", "p", "=", "tf", ".", "transpose", "(", "p", ",", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "block_size", ",", "block_size", ",", "tf", ".", "shape", "(", "p", ")", "[", "2", "]", "*", "tf", ".", "shape", "(", "p", ")", "[", "3", "]", "]", ")", "\n", "\n", "# Reorganize to move n_blocks to the first dimension", "\n", "r", "=", "tf", ".", "transpose", "(", "p", ",", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "r", "=", "tf", ".", "reshape", "(", "r", ",", "[", "-", "1", ",", "r", ".", "shape", "[", "2", "]", ",", "r", ".", "shape", "[", "3", "]", "]", ")", "\n", "\n", "# Forward DCT transform", "\n", "", "with", "tf", ".", "name_scope", "(", "'dct'", ")", ":", "\n", "                ", "Xi", "=", "tf", ".", "matmul", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_dct_F", ",", "axis", "=", "0", ")", ",", "[", "tf", ".", "shape", "(", "r", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "r", ")", "\n", "X", "=", "tf", ".", "matmul", "(", "Xi", ",", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_dct_I", ",", "axis", "=", "0", ")", ",", "[", "tf", ".", "shape", "(", "r", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", ")", "\n", "\n", "# Approximate quantization", "\n", "", "with", "tf", ".", "name_scope", "(", "'quantization'", ")", ":", "\n", "# Tile quantization values for successive channels: ", "\n", "# image_0 [R .. R G .. G B .. B] ... image_N [R .. R G .. G B .. B]", "\n", "                ", "Ql", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_q_mtx_luma", ",", "axis", "=", "0", ")", ",", "[", "1", "*", "(", "tf", ".", "shape", "(", "p", ")", "[", "-", "1", "]", ")", ",", "1", ",", "1", "]", ")", "\n", "Qc", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_q_mtx_chroma", ",", "axis", "=", "0", ")", ",", "[", "2", "*", "(", "tf", ".", "shape", "(", "p", ")", "[", "-", "1", "]", ")", ",", "1", ",", "1", "]", ")", "\n", "Q", "=", "tf", ".", "concat", "(", "(", "Ql", ",", "Qc", ")", ",", "axis", "=", "0", ")", "\n", "Q", "=", "tf", ".", "tile", "(", "Q", ",", "[", "(", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", ")", ",", "1", ",", "1", "]", ")", "\n", "X", "=", "X", "/", "Q", "\n", "X", "=", "self", ".", "quantization", "(", "X", ")", "\n", "X", "=", "X", "*", "Q", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'idct'", ")", ":", "\n", "# Inverse DCT transform", "\n", "                ", "xi", "=", "tf", ".", "matmul", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_dct_I", ",", "axis", "=", "0", ")", ",", "[", "tf", ".", "shape", "(", "r", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", ",", "X", ")", "\n", "xi", "=", "tf", ".", "matmul", "(", "xi", ",", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "_dct_F", ",", "axis", "=", "0", ")", ",", "[", "tf", ".", "shape", "(", "r", ")", "[", "0", "]", ",", "1", ",", "1", "]", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'rev-blocking'", ")", ":", "\n", "# Reorganize data back to", "\n", "                ", "xi", "=", "tf", ".", "reshape", "(", "xi", ",", "[", "3", "*", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", ",", "-", "1", ",", "xi", ".", "shape", "[", "1", "]", ",", "xi", ".", "shape", "[", "2", "]", "]", ")", "\n", "xi", "=", "tf", ".", "transpose", "(", "xi", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "# Backward re-organization from blocks", "\n", "# (n_examples * 3, block, block, n_blocks) -> (n_examples, w, h, 3)", "\n", "q", "=", "tf", ".", "reshape", "(", "xi", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "xi", ")", "[", "1", "]", "*", "tf", ".", "shape", "(", "xi", ")", "[", "2", "]", ",", "tf", ".", "shape", "(", "inputs", ")", "[", "1", "]", "//", "block_size", ",", "\n", "tf", ".", "shape", "(", "inputs", ")", "[", "2", "]", "//", "block_size", "]", ")", "\n", "q", "=", "tf", ".", "transpose", "(", "q", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "q", "=", "tf", ".", "nn", ".", "depth_to_space", "(", "q", ",", "block_size", ")", "\n", "q", "=", "tf", ".", "reshape", "(", "q", ",", "[", "-", "1", ",", "3", ",", "tf", ".", "shape", "(", "q", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "q", ")", "[", "2", "]", "]", ")", "\n", "q", "=", "tf", ".", "transpose", "(", "q", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "# Color conversion (YCbCr-> RGB)", "\n", "", "with", "tf", ".", "name_scope", "(", "'ycbcr_to_rgb'", ")", ":", "\n", "                ", "qc", "=", "tf", ".", "pad", "(", "q", "+", "127", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", "]", ",", "'CONSTANT'", ",", "constant_values", "=", "1", ")", "\n", "y", "=", "tf", ".", "nn", ".", "conv2d", "(", "qc", ",", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "self", ".", "_color_I", ")", ",", "[", "1", ",", "1", ",", "4", ",", "3", "]", ")", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "y", "=", "y", "/", "255.0", "\n", "y", "=", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "\n", "\n", "", "", "return", "y", ",", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.__init__": [[177, 198], ["models.tfmodel.TFModel.__init__", "tensorflow.keras.losses.MeanSquaredError", "ValueError", "jpeg.DifferentiableJPEG"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__"], ["def", "__init__", "(", "self", ",", "quality", "=", "None", ",", "codec", "=", "'soft'", ",", "trainable", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param quality: JPEG quality level or None (can be specified later)\n        :param codec: 'libjpeg', 'soft', 'sin', 'harmonic'\n        :param trainable: set true to make the quantization tables trainable (under development)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Sanitize inputs", "\n", "if", "codec", "is", "not", "None", "and", "codec", "not", "in", "[", "'libjpeg'", ",", "'soft'", ",", "'sin'", ",", "'harmonic'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported codec version: {}'", ".", "format", "(", "codec", ")", ")", "\n", "\n", "", "if", "codec", "==", "'libjpeg'", ":", "\n", "            ", "self", ".", "_model", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "_model", "=", "DifferentiableJPEG", "(", "quality", ",", "codec", ",", "trainable", "=", "trainable", ")", "\n", "\n", "# Remember settings", "\n", "", "self", ".", "codec", "=", "codec", "\n", "self", ".", "quality", "=", "quality", "\n", "self", ".", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "MeanSquaredError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.reset_performance_stats": [[199, 201], ["jpeg.JPEG._reset_performance"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._reset_performance"], ["", "def", "reset_performance_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "_reset_performance", "(", "[", "'entropy'", ",", "'ssim'", ",", "'psnr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.process": [[202, 252], ["jpeg.is_valid_quality", "ValueError", "hasattr", "int", "jpeg.JPEG._model", "len", "numpy.random.choice", "hasattr", "numpy.random.randint", "isinstance", "batch_x.numpy.numpy.numpy", "compression.jpeg_helpers.jpeg_qtable", "compression.jpeg_helpers.jpeg_qtable", "len", "helpers.utils.is_number", "int", "ValueError", "compression.jpeg_helpers.compress_batch", "compression.jpeg_helpers.compress_batch"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.is_valid_quality", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qtable", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.compress_batch"], ["", "def", "process", "(", "self", ",", "batch_x", ",", "quality", "=", "None", ",", "return_entropy", "=", "False", ")", ":", "\n", "        ", "\"\"\" Compress a batch of images (NHW3:rgb) with a given quality factor:\n\n        - if quality is a number - use this quality level\n        - if quality is an iterable with 2 numbers - use a random integer from that range\n        - if quality is an iterable with >2 numbers - use a random value from that set\n        \"\"\"", "\n", "\n", "quality", "=", "self", ".", "quality", "if", "quality", "is", "None", "else", "quality", "\n", "\n", "if", "not", "is_valid_quality", "(", "quality", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid or unspecified JPEG quality!'", ")", "\n", "\n", "", "if", "hasattr", "(", "quality", ",", "'__getitem__'", ")", "and", "len", "(", "quality", ")", ">", "2", ":", "\n", "            ", "quality", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "quality", ")", ")", "\n", "\n", "", "elif", "hasattr", "(", "quality", ",", "'__getitem__'", ")", "and", "len", "(", "quality", ")", "==", "2", ":", "\n", "            ", "quality", "=", "np", ".", "random", ".", "randint", "(", "quality", "[", "0", "]", ",", "quality", "[", "1", "]", ")", "\n", "\n", "", "elif", "is_number", "(", "quality", ")", "and", "quality", ">=", "1", "and", "quality", "<=", "100", ":", "\n", "            ", "quality", "=", "int", "(", "quality", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid quality! {}'", ".", "format", "(", "quality", ")", ")", "\n", "\n", "", "if", "self", ".", "_model", "is", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "batch_x", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "batch_x", "=", "batch_x", ".", "numpy", "(", ")", "\n", "", "if", "return_entropy", ":", "\n", "                ", "return", "jpeg_helpers", ".", "compress_batch", "(", "batch_x", ",", "quality", ")", "[", "0", "]", ",", "np", ".", "nan", "\n", "", "else", ":", "\n", "                ", "return", "jpeg_helpers", ".", "compress_batch", "(", "batch_x", ",", "quality", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "quality", "!=", "self", ".", "quality", ":", "\n", "                ", "old_q_luma", ",", "old_q_chroma", "=", "self", ".", "_model", ".", "_q_mtx_luma", ",", "self", ".", "_model", ".", "_q_mtx_chroma", "\n", "self", ".", "_model", ".", "_q_mtx_luma", "=", "jpeg_qtable", "(", "quality", ",", "0", ")", "\n", "self", ".", "_model", ".", "_q_mtx_chroma", "=", "jpeg_qtable", "(", "quality", ",", "1", ")", "\n", "\n", "", "y", ",", "X", "=", "self", ".", "_model", "(", "batch_x", ")", "\n", "\n", "if", "quality", "!=", "self", ".", "quality", ":", "\n", "                ", "self", ".", "_model", ".", "_q_mtx_luma", ",", "self", ".", "_model", ".", "_q_mtx_chroma", "=", "old_q_luma", ",", "old_q_chroma", "\n", "\n", "", "if", "return_entropy", ":", "\n", "# TODO This currently takes too much memory", "\n", "# entropy = tf_helpers.entropy(X, self._model.quantization.codebook)[0]", "\n", "                ", "entropy", "=", "np", ".", "nan", "\n", "return", "y", ",", "entropy", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.__repr__": [[253, 258], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_model", "is", "not", "None", ":", "\n", "            ", "return", "'JPEG(quality={},codec=\"{}\",trainable={})'", ".", "format", "(", "self", ".", "quality", ",", "self", ".", "codec", ",", "self", ".", "_model", ".", "trainable", ")", "\n", "", "else", ":", "\n", "            ", "return", "'JPEG(quality={},codec=\"{}\")'", ".", "format", "(", "self", ".", "quality", ",", "self", ".", "codec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.summary": [[259, 261], ["jpeg.JPEG._quality_mode"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG._quality_mode"], ["", "", "def", "summary", "(", "self", ",", "quality", "=", "None", ")", ":", "\n", "        ", "return", "f'JPEG ({self.codec}) {self._quality_mode(quality)}'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.summary_compact": [[262, 264], ["jpeg.JPEG._quality_mode"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG._quality_mode"], ["", "def", "summary_compact", "(", "self", ",", "quality", "=", "None", ")", ":", "\n", "        ", "return", "f'JPEG ({self.codec}) {self._quality_mode(quality)}'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG.estimate_qf": [[265, 270], ["compression.jpeg_helpers.jpeg_qf_estimation"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qf_estimation"], ["", "def", "estimate_qf", "(", "self", ",", "channel", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Estimate current JPEG quality factor (smallest difference wrt IJG tables) using luma (channel=0) or chroma (1) tables.\n        \"\"\"", "\n", "return", "jpeg_qf_estimation", "(", "self", ".", "_model", ".", "_q_mtx_luma", ",", "channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.JPEG._quality_mode": [[271, 287], ["helpers.utils.is_number", "compression.jpeg_helpers.jpeg_qf_estimation", "compression.jpeg_helpers.jpeg_qf_estimation", "hasattr", "len", "hasattr", "len", "str"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qf_estimation", "home.repos.pwc.inspect_result.pkorus_neural-imaging.compression.jpeg_helpers.jpeg_qf_estimation"], ["", "def", "_quality_mode", "(", "self", ",", "quality", "=", "None", ")", ":", "\n", "        ", "\"\"\" Human-readable assessment of the current JPEG quality settings. \"\"\"", "\n", "quality", "=", "quality", "or", "self", ".", "quality", "\n", "if", "self", ".", "_model", "is", "not", "None", "and", "self", ".", "_model", ".", "trainable", ":", "\n", "            ", "return", "'trainable QF~{}/{}'", ".", "format", "(", "\n", "jpeg_qf_estimation", "(", "self", ".", "_model", ".", "_q_mtx_luma", ",", "0", ")", ",", "\n", "jpeg_qf_estimation", "(", "self", ".", "_model", ".", "_q_mtx_chroma", ",", "1", ")", "\n", ")", "\n", "", "elif", "is_number", "(", "quality", ")", ":", "\n", "            ", "return", "'QF={}'", ".", "format", "(", "quality", ")", "\n", "", "elif", "hasattr", "(", "quality", ",", "'__getitem__'", ")", "and", "len", "(", "quality", ")", "==", "2", ":", "\n", "            ", "return", "'QF~[{},{}]'", ".", "format", "(", "*", "quality", ")", "\n", "", "elif", "hasattr", "(", "quality", ",", "'__getitem__'", ")", "and", "len", "(", "quality", ")", ">", "2", ":", "\n", "            ", "return", "'QF~{{{}}}'", ".", "format", "(", "','", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "quality", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "'QF=?'", "", "", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.is_valid_quality": [[30, 36], ["helpers.utils.is_number", "hasattr", "all", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["def", "is_valid_quality", "(", "quality", ")", ":", "\n", "    ", "if", "is_number", "(", "quality", ")", "and", "1", "<=", "quality", "<=", "100", ":", "\n", "        ", "return", "True", "\n", "", "elif", "hasattr", "(", "quality", ",", "'__getitem__'", ")", "and", "len", "(", "quality", ")", ">", "1", "and", "all", "(", "(", "1", "<=", "x", "<=", "100", ")", "for", "x", "in", "quality", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.jpeg.differentiable_jpeg": [[38, 43], ["jpeg.JPEG.process", "jpeg.JPEG"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "differentiable_jpeg", "(", "x", ",", "quality", ")", ":", "\n", "    ", "global", "_common_codec", "\n", "if", "_common_codec", "is", "None", ":", "\n", "        ", "_common_codec", "=", "JPEG", "(", "None", ",", "'soft'", ")", "\n", "", "return", "_common_codec", ".", "process", "(", "x", ",", "quality", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.__init__": [[110, 113], ["tfmodel.TFModel.reset_performance_stats"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.reset_performance_stats"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_model", "=", "None", "\n", "self", ".", "reset_performance_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._reset_performance": [[114, 117], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reset_performance", "(", "metrics", ")", ":", "\n", "        ", "return", "{", "k", ":", "{", "'training'", ":", "[", "]", ",", "'validation'", ":", "[", "]", "}", "for", "k", "in", "metrics", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.reset_performance_stats": [[118, 120], ["tfmodel.TFModel._reset_performance"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._reset_performance"], ["", "def", "reset_performance_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "performance", "=", "self", ".", "_reset_performance", "(", "[", "'loss'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.log_metric": [[121, 129], ["[].append", "helpers.utils.is_number", "float", "float", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["", "def", "log_metric", "(", "self", ",", "metric", ",", "scope", ",", "value", ",", "raw", "=", "False", ")", ":", "\n", "        ", "if", "not", "raw", ":", "\n", "            ", "if", "utils", ".", "is_number", "(", "value", ")", ":", "\n", "                ", "value", "=", "float", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "value", "=", "float", "(", "np", ".", "mean", "(", "value", ")", ")", "\n", "\n", "", "", "self", ".", "performance", "[", "metric", "]", "[", "scope", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.pop_metric": [[130, 132], ["None"], "methods", ["None"], ["", "def", "pop_metric", "(", "self", ",", "metric", ",", "scope", ")", ":", "\n", "        ", "return", "self", ".", "performance", "[", "metric", "]", "[", "scope", "]", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.parameters": [[133, 136], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", ".", "trainable_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.variables": [[137, 140], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "variables", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_model", ".", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters": [[141, 143], ["numpy.sum", "numpy.prod", "tv.shape.as_list"], "methods", ["None"], ["", "def", "count_parameters", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "tv", ".", "shape", ".", "as_list", "(", ")", ")", "for", "tv", "in", "self", ".", "parameters", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters_breakdown": [[144, 149], ["tfmodel.TFModel.count_parameters", "pd.DataFrame", "numpy.prod", "round", "tv.shape.as_list", "numpy.prod", "tv.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters"], ["", "def", "count_parameters_breakdown", "(", "self", ")", ":", "\n", "        ", "import", "pandas", "as", "pd", "\n", "total", "=", "self", ".", "count_parameters", "(", ")", "\n", "data", "=", "[", "(", "tv", ".", "name", ",", "tv", ".", "shape", ",", "np", ".", "prod", "(", "tv", ".", "shape", ".", "as_list", "(", ")", ")", ",", "round", "(", "100", "*", "np", ".", "prod", "(", "tv", ".", "shape", ".", "as_list", "(", ")", ")", "/", "total", ",", "1", ")", ")", "for", "tv", "in", "self", ".", "parameters", "]", "\n", "return", "pd", ".", "DataFrame", "(", "data", ",", "columns", "=", "[", "'name'", ",", "'shape'", ",", "'parameters'", ",", "'total'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.save_model": [[150, 167], ["tfmodel.TFModel._model.save_weights", "os.path.join.endswith", "os.path.join", "os.path.exists", "os.makedirs", "loguru.logger.info", "os.path.join", "open", "json.dump", "os.path.join", "os.path.join", "tfmodel.TFModel.class_name.lower", "tfmodel.TFModel.get_hyperparameters", "tfmodel.TFModel.class_name.lower", "tfmodel.TFModel.class_name.lower"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.get_hyperparameters"], ["", "def", "save_model", "(", "self", ",", "dirname", ",", "epoch", "=", "0", ",", "save_args", "=", "False", ",", "quiet", "=", "False", ")", ":", "\n", "        ", "if", "not", "dirname", ".", "endswith", "(", "self", ".", "scoped_name", ")", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "self", ".", "scoped_name", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n", "", "if", "not", "quiet", ":", "\n", "            ", "logger", ".", "info", "(", "f'> {self.class_name} --> {os.path.join(dirname, self.class_name.lower())} {\"JSON\" if save_args else \"\"}'", ")", "\n", "", "self", ".", "_model", ".", "save_weights", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "f'{self.class_name.lower()}.h5'", ")", ",", "save_format", "=", "'h5'", ")", "\n", "\n", "if", "save_args", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "f'{self.class_name.lower()}.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "{", "\n", "'model'", ":", "self", ".", "class_name", ",", "\n", "'args'", ":", "self", ".", "get_hyperparameters", "(", ")", "\n", "}", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model": [[168, 183], ["os.path.join", "tfmodel.TFModel._model.load_weights", "tfmodel.TFModel.reset_performance_stats", "os.path.join.endswith", "os.path.join", "os.path.isfile", "os.path.join", "loguru.logger.info", "tfmodel.TFModel.class_name.lower", "tfmodel.TFModel.class_name.lower"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.reset_performance_stats"], ["", "", "", "def", "load_model", "(", "self", ",", "dirname", ",", "quiet", "=", "False", ")", ":", "\n", "        ", "if", "not", "dirname", ".", "endswith", "(", "self", ".", "scoped_name", ")", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "self", ".", "scoped_name", ")", "\n", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "f'{self.class_name.lower()}.h5'", ")", "\n", "\n", "# If the h5 model does not exist, try the TF snapshot", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "filename", ")", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "self", ".", "class_name", ".", "lower", "(", ")", ")", "\n", "\n", "", "if", "not", "quiet", ":", "\n", "            ", "logger", ".", "info", "(", "f'> {self.class_name} <-- {filename}'", ")", "\n", "\n", "", "self", ".", "_model", ".", "load_weights", "(", "filename", ")", "\n", "self", ".", "reset_performance_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.migrate_model": [[184, 224], ["tfmodel.TFModel.reset_performance_stats", "os.path.join.endswith", "os.path.join", "loguru.logger.info", "enumerate", "loguru.logger.info", "enumerate", "tensorflow.train.list_variables", "tensorflow.train.load_variable", "hasattr", "loguru.logger.info", "tensorflow.train.load_variable.name.replace", "tensorflow.train.load_variable", "loguru.logger.info", "tensorflow.train.load_variable.assign", "loguru.logger.info", "loguru.logger.info", "loguru.logger.warning", "type"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.reset_performance_stats"], ["", "def", "migrate_model", "(", "self", ",", "dirname", ",", "mapping", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Migrate a pre-trained model from a TF checkpoint. Example cases when this arises include\n        changed TF version or changed variable names. The function loads specific variables from\n        the checkpoint and uses their values for new weights. The mapping is defined in the\n        'mapping' dictionary. The new model can later be saved using 'save_model'.\n\n        Hint: It may be useful to use tf.keras.backend.clear_session() to make sure variable \n        names are not changing during the migration.\n\n        :param dirname: directory with a saved TF checkpoint\n        :param mapping: dict {'new name' : 'old name'}\n        :param verbose: self explanatory\n        \"\"\"", "\n", "if", "not", "dirname", ".", "endswith", "(", "self", ".", "scoped_name", ")", ":", "\n", "            ", "dirname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "self", ".", "scoped_name", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "'# Variables found in the checkpoint: {}'", ".", "format", "(", "dirname", ")", ")", "\n", "for", "i", ",", "(", "var_name", ",", "_", ")", "in", "enumerate", "(", "tf", ".", "train", ".", "list_variables", "(", "dirname", ")", ")", ":", "\n", "                ", "var", "=", "tf", ".", "train", ".", "load_variable", "(", "dirname", ",", "var_name", ")", "\n", "if", "hasattr", "(", "var", ",", "'shape'", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "'{0:3d}.  {1:70s} -> tensor {2.shape}'", ".", "format", "(", "i", ",", "var_name", ",", "var", ")", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "info", "(", "'{0:3d}.  {1:70s} -> {2}'", ".", "format", "(", "i", ",", "var_name", ",", "type", "(", "var", ")", ")", ")", "\n", "", "", "logger", ".", "info", "(", "'\\n# Model variables: {}'", ".", "format", "(", "self", ".", "class_name", ")", ")", "\n", "for", "i", ",", "var", "in", "enumerate", "(", "self", ".", "_model", ".", "trainable_variables", ")", ":", "\n", "                ", "logger", ".", "info", "(", "'{0:3d}.  {1.name:70s} -> tensor {1.shape}'", ".", "format", "(", "i", ",", "var", ")", ")", "\n", "\n", "", "", "if", "mapping", "is", "not", "None", ":", "\n", "            ", "for", "var", "in", "self", ".", "_model", ".", "trainable_variables", ":", "\n", "                ", "var_name", "=", "var", ".", "name", ".", "replace", "(", "':0'", ",", "''", ")", "\n", "if", "var_name", "not", "in", "mapping", ":", "\n", "                    ", "logger", ".", "warning", "(", "'mapping for {} = {} not found'", ".", "format", "(", "var", ".", "name", ",", "var_name", ")", ")", "\n", "continue", "\n", "", "var_value", "=", "tf", ".", "train", ".", "load_variable", "(", "dirname", ",", "mapping", "[", "var_name", "]", ")", "\n", "logger", ".", "info", "(", "'{} = {} {} <- {} {}'", ".", "format", "(", "var", ".", "name", ",", "var_name", ",", "var", ".", "shape", ",", "mapping", "[", "var_name", "]", ",", "var_value", ".", "shape", ")", ")", "\n", "var", ".", "assign", "(", "var_value", ")", "\n", "\n", "", "", "self", ".", "reset_performance_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.class_name": [[225, 228], ["type"], "methods", ["None"], ["", "@", "property", "\n", "def", "class_name", "(", "self", ")", ":", "\n", "        ", "return", "type", "(", "self", ")", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.summary": [[229, 231], ["tfmodel.TFModel.count_parameters"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.count_parameters"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "return", "'{} model [{:,.0f} parameters]'", ".", "format", "(", "self", ".", "class_name", ",", "self", ".", "count_parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.summary_compact": [[232, 234], ["None"], "methods", ["None"], ["", "def", "summary_compact", "(", "self", ")", ":", "\n", "        ", "return", "'{}'", ".", "format", "(", "self", ".", "class_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.model_code": [[235, 238], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "model_code", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.scoped_name": [[239, 242], ["type().__name__.lower", "type"], "methods", ["None"], ["", "@", "property", "\n", "def", "scoped_name", "(", "self", ")", ":", "\n", "        ", "return", "'{}'", ".", "format", "(", "type", "(", "self", ")", ".", "__name__", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.get_hyperparameters": [[243, 248], ["hasattr", "tfmodel.TFModel._h.to_json"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json"], ["", "def", "get_hyperparameters", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'_h'", ")", ":", "\n", "            ", "return", "self", ".", "_h", ".", "to_json", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.__repr__": [[249, 255], ["helpers.utils.join_args", "tfmodel.TFModel._h.changed_params"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.join_args", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.changed_params"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "extra_params", "=", "utils", ".", "join_args", "(", "self", ".", "_h", ".", "changed_params", "(", ")", ")", "\n", "", "except", ":", "\n", "            ", "extra_params", "=", "''", "\n", "", "return", "f'{self.class_name}({extra_params})'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel._has_attributes": [[256, 260], ["hasattr", "all", "NotImplementedError", "setup_status.values", "message.format", "setup_status.items"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "def", "_has_attributes", "(", "self", ",", "attrs", ",", "message", "=", "'Expected attributes not found: {}'", ")", ":", "\n", "        ", "setup_status", "=", "{", "key", ":", "hasattr", "(", "self", ",", "key", ")", "for", "key", "in", "attrs", "}", "\n", "if", "not", "all", "(", "setup_status", ".", "values", "(", ")", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "message", ".", "format", "(", "[", "key", "for", "key", ",", "value", "in", "setup_status", ".", "items", "(", ")", "if", "not", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.restore": [[261, 288], ["list", "parameters.items", "cls", "cls.load_model", "pathlib.Path().glob", "str", "FileNotFoundError", "open", "json.load", "os.path.isfile", "isinstance", "eval", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "", "@", "classmethod", "\n", "def", "restore", "(", "cls", ",", "dir_name", ",", "*", ",", "key", "=", "None", ",", "patch_size", "=", "None", ")", ":", "\n", "\n", "        ", "candidates", "=", "list", "(", "Path", "(", "dir_name", ")", ".", "glob", "(", "'**/*.json'", ")", ")", "\n", "training_log_path", "=", "str", "(", "candidates", "[", "0", "]", ")", "if", "candidates", "else", "None", "\n", "\n", "if", "training_log_path", "is", "None", "or", "not", "os", ".", "path", ".", "isfile", "(", "training_log_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "'Could not find a training log (JSON file) in {}'", ".", "format", "(", "dir_name", ")", ")", "\n", "\n", "", "with", "open", "(", "training_log_path", ")", "as", "f", ":", "\n", "            ", "training_log", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "key", "is", "not", "None", ":", "\n", "            ", "training_log", "=", "training_log", "[", "key", "]", "\n", "\n", "", "parameters", "=", "training_log", "[", "'args'", "]", "\n", "if", "patch_size", "is", "not", "None", ":", "parameters", "[", "'patch_size'", "]", "=", "patch_size", "\n", "\n", "# JSON does not allow to store tuples, so they are stored as string", "\n", "for", "key", ",", "value", "in", "parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "value", ",", "str", ")", "and", "value", "[", "0", "]", "==", "'('", "and", "value", "[", "-", "1", "]", "==", "')'", ":", "\n", "                ", "parameters", "[", "key", "]", "=", "eval", "(", "value", ")", "\n", "\n", "", "", "instance", "=", "cls", "(", "**", "parameters", ")", "\n", "instance", ".", "load_model", "(", "dir_name", ")", "\n", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.process": [[289, 291], ["tfmodel.TFModel._model"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "x", ",", "training", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "_model", "(", "x", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.deploy_model": [[292, 295], ["NotImplementedError"], "methods", ["None"], ["", "def", "deploy_model", "(", "self", ",", "dirname", ")", ":", "\n", "# TODO Need to implement model deployment - need to set input shape & self._model.save(dirname)", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore": [[16, 84], ["pathlib.Path().glob", "parameters.items", "model.load_model", "loguru.logger.info", "ValueError", "os.path.exists", "loguru.logger.info", "os.path.isfile", "str", "FileNotFoundError", "open", "json.load", "getattr", "model.performance.items", "ValueError", "pathlib.Path", "isinstance", "eval", "open", "json.load", "loguru.logger.info", "ValueError", "numpy.round", "module.__name__.split", "module.__name__.split", "len", "numpy.round", "len", "module.__name__.split"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["def", "restore", "(", "dir_name", ",", "module", ",", "key", "=", "None", ",", "patch_size", "=", "None", ",", "restore_perf", "=", "False", ",", "fetch_stats", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Utility function to restore pre-trained models from a training directory. \n\n    :param dir_name: directory with a trained model (*.json + checkpoint data)\n    :param module: Python module where classes should be looked up\n    :param key: JSON key which describes which model to look up in the training log\n    :param patch_size: input patch size (scalar)\n    :param restore_perf: also loads training/validation metrics\n    :param fetch_stats: return a tuple (model, training_stats)\n    \"\"\"", "\n", "training_log_path", "=", "None", "\n", "\n", "if", "dir_name", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'dcn directory cannot be None'", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "# If not explicit directory, check for presets", "\n", "        ", "logger", ".", "info", "(", "'config/presets/{}.json'", ".", "format", "(", "module", ".", "__name__", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ")", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "'config/presets/{}.json'", ".", "format", "(", "module", ".", "__name__", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ")", ")", ":", "\n", "            ", "with", "open", "(", "'config/presets/{}.json'", ".", "format", "(", "module", ".", "__name__", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ")", ")", "as", "f", ":", "\n", "                ", "presets", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "dir_name", "in", "presets", ":", "\n", "                ", "logger", ".", "info", "(", "'Found {} in presets: {}'", ".", "format", "(", "dir_name", ",", "presets", "[", "dir_name", "]", ")", ")", "\n", "dir_name", "=", "presets", "[", "dir_name", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Directory {} does not exist & key not found in presets (config/presets/*)!'", ".", "format", "(", "dir_name", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Directory {} does not exist (presets not available)!'", ".", "format", "(", "dir_name", ")", ")", "\n", "\n", "", "", "for", "filename", "in", "Path", "(", "dir_name", ")", ".", "glob", "(", "'**/*.json'", ")", ":", "\n", "        ", "training_log_path", "=", "str", "(", "filename", ")", "\n", "\n", "", "if", "training_log_path", "is", "None", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "'Could not find a training log (JSON file) in {}'", ".", "format", "(", "dir_name", ")", ")", "\n", "\n", "", "with", "open", "(", "training_log_path", ")", "as", "f", ":", "\n", "        ", "training_log", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "key", "is", "not", "None", ":", "\n", "        ", "training_log", "=", "training_log", "[", "key", "]", "\n", "\n", "", "parameters", "=", "training_log", "[", "'args'", "]", "\n", "parameters", "[", "'patch_size'", "]", "=", "patch_size", "\n", "\n", "# TODO JSON Does not allow to store tuples, so they are stored as string", "\n", "for", "key", ",", "value", "in", "parameters", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "str", ")", "and", "value", "[", "0", "]", "==", "'('", "and", "value", "[", "-", "1", "]", "==", "')'", ":", "\n", "            ", "parameters", "[", "key", "]", "=", "eval", "(", "value", ")", "\n", "\n", "", "", "model", "=", "getattr", "(", "module", ",", "training_log", "[", "'model'", "]", ")", "(", "**", "parameters", ")", "\n", "model", ".", "load_model", "(", "dir_name", ")", "\n", "logger", ".", "info", "(", "'Restored model: {} <- {}'", ".", "format", "(", "model", ".", "model_code", ",", "training_log_path", ")", ")", "\n", "\n", "if", "restore_perf", ":", "\n", "        ", "model", ".", "performance", "=", "training_log", "[", "'performance'", "]", "\n", "\n", "", "if", "fetch_stats", ":", "\n", "        ", "stats", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "model", ".", "performance", ".", "items", "(", ")", ":", "\n", "            ", "if", "'validation'", "in", "v", "and", "len", "(", "v", "[", "'validation'", "]", ")", ">", "0", ":", "\n", "                ", "stats", "[", "k", "]", "=", "np", ".", "round", "(", "v", "[", "'validation'", "]", "[", "-", "1", "]", ",", "3", ")", "\n", "", "elif", "'training'", "in", "v", "and", "len", "(", "v", "[", "'training'", "]", ")", ">", "0", ":", "\n", "                ", "stats", "[", "k", "]", "=", "np", ".", "round", "(", "v", "[", "'training'", "]", "[", "-", "1", "]", ",", "3", ")", "\n", "\n", "", "", "return", "model", ",", "stats", "\n", "", "else", ":", "\n", "        ", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.__init__": [[14, 157], ["manipulation_classification.ManipulationClassification._trainable.add", "models.forensics.FAN", "manipulation_classification.ManipulationClassification._parameters.extend", "tensorflow.keras.optimizers.Adam", "ValueError", "set", "set", "manipulation_classification.ManipulationClassification._distribution.update", "nip_model.split", "loguru.logger.warning", "issubclass", "ValueError", "ValueError", "getattr", "manipulation_classification.ManipulationClassification.nip.load_model", "loguru.logger.info", "tensorflow.name_scope", "set", "any", "collections.OrderedDict", "models.jpeg.JPEG", "ValueError", "manipulation_classification.ManipulationClassification._parameters.extend", "manipulation_classification.ManipulationClassification._parameters.extend", "getattr", "m.split", "set.add", "ValueError", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "manipulation_classification.ManipulationClassification._forensics_classes.append", "len", "compression.codec.restore", "len", "len", "float", "helpers.tf_helpers.manipulation_sharpen", "helpers.tf_helpers.manipulation_resample", "helpers.tf_helpers.manipulation_gaussian", "helpers.tf_helpers.manipulation_awgn", "helpers.tf_helpers.manipulation_gamma", "helpers.tf_helpers.manipulation_median", "manipulation_classification.ManipulationClassification._strengths.keys", "manipulation_classification.ManipulationClassification._strengths.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.TFModel.load_model", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.models.tfmodel.restore", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_sharpen", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_resample", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_gaussian", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_awgn", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_gamma", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_median", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["    ", "def", "__init__", "(", "self", ",", "nip_model", ",", "manipulations", "=", "None", ",", "distribution", "=", "None", ",", "fan_args", "=", "None", ",", "trainable", "=", "None", ",", "\n", "raw_patch_size", "=", "128", ",", "loss_metric", "=", "'L2'", ")", ":", "\n", "        ", "\"\"\"\n        Setup the model of the entire acquisition and distribution workflow with photo manipulation classification:\n\n        raw -> (nip) -> rgb -> (N manipulations) -> [(downsample) ->] (compression) -> (forensics) -> manipulation classes' probabilities\n\n        :param nip_model: '<nip class>[:dirname]' name of the NIP class + dirname to load a pretrained model\n        :param manipulations: list of included manipulations ['<manipulation>[:strength]'], e.g., ['sharpen:1', 'resample', 'gaussian:3', 'jpeg:85']\n        :param distribution: definition of the distribution channel (set to None for the default down+jpeg(50))\n            {\n                'downsampling'        : '<method>[:factor]' - e.g., 'pool:2'\n                'compression'         : {'jpeg', 'dcn'},\n                'compression_params'  : dict with (codec, quality) for jpeg and (dirname) for dcn\n            }\n        :param trainable: iterable with components that should be fine-tuned, e.g., {'nip'}. The FAN is always fine-tuned.\n        :param raw_patch_size: patch size for manipulation training (raw patch - rgb patches may be bigger)\n        :param loss_metric: NIP loss metric: L2, L1 or SSIM\n        \"\"\"", "\n", "# Sanitize inputs", "\n", "if", "raw_patch_size", "<", "16", "or", "raw_patch_size", ">", "512", ":", "\n", "            ", "raise", "ValueError", "(", "'The patch size ({}) looks incorrect, typical values should be >= 16 and <= 512'", ".", "format", "(", "raw_patch_size", ")", ")", "\n", "\n", "", "self", ".", "_trainable", "=", "set", "(", ")", "if", "trainable", "is", "None", "else", "set", "(", "trainable", ")", "\n", "self", ".", "_trainable", ".", "add", "(", "'fan'", ")", "\n", "\n", "# Setup a default distribution channel", "\n", "if", "distribution", "is", "None", ":", "\n", "            ", "self", ".", "_distribution", "=", "{", "\n", "'downsampling'", ":", "'pool:2'", ",", "\n", "'compression'", ":", "'jpeg'", ",", "\n", "'compression_params'", ":", "{", "\n", "'quality'", ":", "50", ",", "\n", "'codec'", ":", "'soft'", "\n", "}", "\n", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "_distribution", "=", "{", "}", "\n", "self", ".", "_distribution", ".", "update", "(", "distribution", ")", "\n", "\n", "", "if", "':'", "in", "nip_model", ":", "\n", "            ", "nip_model", ",", "nip_pretrained_dirname", "=", "nip_model", ".", "split", "(", "':'", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "'NIP model weights not specified - no model was loaded during workflow setup!'", ")", "\n", "nip_pretrained_dirname", "=", "None", "\n", "\n", "", "if", "not", "issubclass", "(", "getattr", "(", "pipelines", ",", "nip_model", ")", ",", "pipelines", ".", "NIPModel", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid NIP model ({nip_model})! Available NIPs: ({pipelines.supported_models})'", ")", "\n", "\n", "", "if", "loss_metric", "not", "in", "[", "'L2'", ",", "'L1'", ",", "'SSIM'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid loss metric ({loss_metric})!'", ")", "\n", "\n", "# The pipeline -------------------------------------------------------------------------------------------------", "\n", "\n", "", "self", ".", "nip", "=", "getattr", "(", "pipelines", ",", "nip_model", ")", "(", "loss_metric", "=", "loss_metric", ",", "patch_size", "=", "raw_patch_size", ")", "\n", "\n", "if", "nip_pretrained_dirname", "is", "not", "None", ":", "\n", "            ", "self", ".", "nip", ".", "load_model", "(", "nip_pretrained_dirname", ")", "\n", "logger", ".", "info", "(", "'Loaded NIP weights from {}'", ".", "format", "(", "nip_pretrained_dirname", ")", ")", "\n", "\n", "# Several paths for post-processing ----------------------------------------------------------------------------", "\n", "", "with", "tf", ".", "name_scope", "(", "'distribution'", ")", ":", "\n", "\n", "# Parse manipulation specs", "\n", "            ", "manipulations", "=", "manipulations", "or", "[", "'sharpen'", ",", "'resample'", ",", "'gaussian'", ",", "'jpeg'", "]", "\n", "\n", "self", ".", "_strengths", "=", "{", "'sharpen'", ":", "1", ",", "'resample'", ":", "50", ",", "'gaussian'", ":", "0.83", ",", "'jpeg'", ":", "80", ",", "'awgn'", ":", "5.1", ",", "'gamma'", ":", "3", ",", "'median'", ":", "3", "}", "\n", "\n", "self", ".", "_strengths_range", "=", "{", "\n", "'sharpen'", ":", "(", "0.25", ",", "1.5", ")", ",", "\n", "'resample'", ":", "(", "40", ",", "90", ")", ",", "\n", "'gaussian'", ":", "(", "0.5", ",", "7", ")", ",", "\n", "'jpeg'", ":", "(", "50", ",", "90", ")", ",", "\n", "'awgn'", ":", "(", "1", ",", "5", ")", ",", "\n", "'gamma'", ":", "(", "1", ",", "5", ")", ",", "\n", "'median'", ":", "(", "3", ",", "9", ")", "\n", "}", "\n", "\n", "manipulations_set", "=", "set", "(", ")", "\n", "for", "m", "in", "manipulations", ":", "\n", "                ", "spec", "=", "m", ".", "split", "(", "':'", ")", "\n", "manipulations_set", ".", "add", "(", "spec", "[", "0", "]", ")", "\n", "if", "len", "(", "spec", ")", ">", "1", ":", "\n", "                    ", "self", ".", "_strengths", "[", "spec", "[", "0", "]", "]", "=", "float", "(", "spec", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "any", "(", "x", "not", "in", "self", ".", "_strengths", ".", "keys", "(", ")", "for", "x", "in", "manipulations_set", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Unsupported manipulation requested! Available: {}'", ".", "format", "(", "self", ".", "_strengths", ".", "keys", "(", ")", ")", ")", "\n", "\n", "", "self", ".", "_operations", "=", "OrderedDict", "(", ")", "\n", "self", ".", "_forensics_classes", "=", "[", "'native'", "]", "\n", "\n", "if", "'sharpen'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'sharpen'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_sharpen", "(", "x", ",", "strength", ",", "hsv", "=", "True", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'sharpen:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'sharpen'", "]", ")", ")", "\n", "\n", "", "if", "'resample'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'resample'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_resample", "(", "x", ",", "strength", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'resample:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'resample'", "]", ")", ")", "\n", "\n", "", "if", "'gaussian'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'gaussian'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_gaussian", "(", "x", ",", "5", ",", "strength", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'gaussian:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'gaussian'", "]", ")", ")", "\n", "\n", "", "if", "'jpeg'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'jpeg'", "]", "=", "jpeg", ".", "differentiable_jpeg", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'jpeg:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'jpeg'", "]", ")", ")", "\n", "\n", "", "if", "'awgn'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'awgn'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_awgn", "(", "x", ",", "strength", "/", "255", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'awgn:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'awgn'", "]", ")", ")", "\n", "\n", "", "if", "'gamma'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'gamma'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_gamma", "(", "x", ",", "strength", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'gamma:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'gamma'", "]", ")", ")", "\n", "\n", "", "if", "'median'", "in", "manipulations_set", ":", "\n", "                ", "self", ".", "_operations", "[", "'median'", "]", "=", "lambda", "x", ",", "strength", ":", "tf_helpers", ".", "manipulation_median", "(", "x", ",", "strength", ")", "\n", "self", ".", "_forensics_classes", ".", "append", "(", "'median:{}'", ".", "format", "(", "self", ".", "_strengths", "[", "'median'", "]", ")", ")", "\n", "\n", "", "assert", "len", "(", "self", ".", "_forensics_classes", ")", "==", "self", ".", "n_classes", "\n", "\n", "# Configure compression", "\n", "", "if", "distribution", "[", "'compression'", "]", "==", "'jpeg'", ":", "\n", "            ", "self", ".", "codec", "=", "jpeg", ".", "JPEG", "(", "**", "distribution", "[", "'compression_params'", "]", ")", "\n", "", "elif", "distribution", "[", "'compression'", "]", "==", "'dcn'", ":", "\n", "            ", "self", ".", "codec", "=", "codec", ".", "restore", "(", "distribution", "[", "'compression_params'", "]", "[", "'dirname'", "]", ")", "\n", "\n", "", "if", "'dcn'", "in", "trainable", "and", "len", "(", "self", ".", "codec", ".", "parameters", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'The current codec does not appear to be trainable: {}!'", ".", "format", "(", "self", ".", "codec", ".", "class_name", ")", ")", "\n", "\n", "# Add forensic analysis", "\n", "", "fan_input_patch", "=", "2", "*", "raw_patch_size", "//", "self", ".", "downsampling_factor", "\n", "self", ".", "fan", "=", "forensics", ".", "FAN", "(", "n_classes", "=", "self", ".", "n_classes", ",", "patch_size", "=", "fan_input_patch", ",", "**", "fan_args", ")", "\n", "\n", "# List parameters that need to be optimized", "\n", "self", ".", "_parameters", "=", "[", "]", "\n", "self", ".", "_parameters", ".", "extend", "(", "self", ".", "fan", ".", "parameters", ")", "\n", "if", "'nip'", "in", "trainable", ":", "\n", "            ", "self", ".", "_parameters", ".", "extend", "(", "self", ".", "nip", ".", "parameters", ")", "\n", "", "if", "'dcn'", "in", "trainable", ":", "\n", "            ", "self", ".", "_parameters", ".", "extend", "(", "self", ".", "codec", ".", "parameters", ")", "\n", "\n", "", "self", ".", "_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.n_classes": [[158, 161], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_operations", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_workflow": [[162, 177], ["manipulation_classification.ManipulationClassification.nip.process", "manipulation_classification.ManipulationClassification.run_manipulations", "manipulation_classification.ManipulationClassification.run_downsampling", "manipulation_classification.ManipulationClassification.run_compression", "manipulation_classification.ManipulationClassification.fan.process"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_manipulations", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_downsampling", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_compression", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "run_workflow", "(", "self", ",", "batch_x", ",", "augment", "=", "False", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Runs the entire workflow from RAW images to FAN predictions:\n\n        raw --> [isp] -> [manipulations] -> [downsample] -> [compression] -> [fan] -> class probabilities\n\n        Returns: batch_Y, batch_c, batch_C, entropy, probabilities\n        \"\"\"", "\n", "batch_Y", "=", "self", ".", "nip", ".", "process", "(", "batch_x", ")", "\n", "batch_m", "=", "self", ".", "run_manipulations", "(", "batch_Y", ",", "augment", ")", "\n", "batch_c", "=", "self", ".", "run_downsampling", "(", "batch_m", ")", "\n", "batch_C", ",", "entropy", "=", "self", ".", "run_compression", "(", "batch_c", ",", "True", ")", "\n", "probabilities", "=", "self", ".", "fan", ".", "process", "(", "batch_C", ")", "\n", "\n", "return", "batch_Y", ",", "batch_c", ",", "batch_C", ",", "entropy", ",", "probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_workflow_to_decisions": [[178, 181], ["prob.numpy().argmax", "manipulation_classification.ManipulationClassification.run_workflow", "prob.numpy"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_workflow"], ["", "def", "run_workflow_to_decisions", "(", "self", ",", "batch_x", ")", ":", "\n", "        ", "prob", "=", "self", ".", "run_workflow", "(", "batch_x", ")", "[", "-", "1", "]", "\n", "return", "prob", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_rgb_to_fan": [[182, 189], ["manipulation_classification.ManipulationClassification.run_manipulations", "manipulation_classification.ManipulationClassification.run_downsampling", "manipulation_classification.ManipulationClassification.run_compression", "isinstance", "batch_C.numpy.numpy.numpy"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_manipulations", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_downsampling", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_compression"], ["", "def", "run_rgb_to_fan", "(", "self", ",", "batch_Y", ")", ":", "\n", "        ", "batch_m", "=", "self", ".", "run_manipulations", "(", "batch_Y", ")", "\n", "batch_c", "=", "self", ".", "run_downsampling", "(", "batch_m", ")", "\n", "batch_C", "=", "self", ".", "run_compression", "(", "batch_c", ")", "\n", "if", "not", "isinstance", "(", "batch_C", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "batch_C", "=", "batch_C", ".", "numpy", "(", ")", "\n", "", "return", "batch_C", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_rgb_to_probabilities": [[190, 198], ["manipulation_classification.ManipulationClassification.run_manipulations", "manipulation_classification.ManipulationClassification.run_downsampling", "manipulation_classification.ManipulationClassification.run_compression", "manipulation_classification.ManipulationClassification.fan.process", "hasattr", "probabilities.numpy.numpy.numpy", "isinstance"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_manipulations", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_downsampling", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_compression", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "run_rgb_to_probabilities", "(", "self", ",", "batch_Y", ")", ":", "\n", "        ", "batch_m", "=", "self", ".", "run_manipulations", "(", "batch_Y", ")", "\n", "batch_c", "=", "self", ".", "run_downsampling", "(", "batch_m", ")", "\n", "batch_C", "=", "self", ".", "run_compression", "(", "batch_c", ")", "\n", "probabilities", "=", "self", ".", "fan", ".", "process", "(", "batch_C", ")", "\n", "if", "not", "isinstance", "(", "probabilities", ",", "np", ".", "ndarray", ")", "and", "hasattr", "(", "probabilities", ",", "'numpy'", ")", ":", "\n", "            ", "probabilities", "=", "probabilities", ".", "numpy", "(", ")", "\n", "", "return", "probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_manipulations": [[199, 209], ["manipulation_classification.ManipulationClassification._operations.items", "tensorflow.concat", "y_list.append", "numpy.random.uniform", "op"], "methods", ["None"], ["", "def", "run_manipulations", "(", "self", ",", "batch_y", ",", "randomize", "=", "False", ",", "override", "=", "None", ")", ":", "\n", "        ", "y_list", "=", "[", "batch_y", "]", "\n", "\n", "override", "=", "override", "if", "override", "is", "not", "None", "else", "self", ".", "_strengths", "\n", "\n", "for", "name", ",", "op", "in", "self", ".", "_operations", ".", "items", "(", ")", ":", "\n", "            ", "s", "=", "override", "[", "name", "]", "if", "not", "randomize", "else", "np", ".", "random", ".", "uniform", "(", "*", "self", ".", "_strengths_range", "[", "name", "]", ")", "\n", "y_list", ".", "append", "(", "op", "(", "batch_y", ",", "s", ")", ")", "\n", "\n", "", "return", "tf", ".", "concat", "(", "y_list", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.manipulations_timing": [[210, 221], ["manipulation_classification.ManipulationClassification._operations.items", "datetime.now", "y_list.append", "op", "datetime.now"], "methods", ["None"], ["", "def", "manipulations_timing", "(", "self", ",", "batch_y", ")", ":", "\n", "        ", "from", "datetime", "import", "datetime", "\n", "y_list", "=", "[", "batch_y", "]", "\n", "times", "=", "{", "}", "\n", "\n", "for", "name", ",", "op", "in", "self", ".", "_operations", ".", "items", "(", ")", ":", "\n", "            ", "d1", "=", "datetime", ".", "now", "(", ")", "\n", "y_list", ".", "append", "(", "op", "(", "batch_y", ",", "self", ".", "_strengths", "[", "name", "]", ")", ")", "\n", "times", "[", "name", "]", "=", "(", "datetime", ".", "now", "(", ")", "-", "d1", ")", ".", "total_seconds", "(", ")", "\n", "\n", "", "return", "times", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.downsampling_factor": [[222, 230], ["int", "manipulation_classification.ManipulationClassification._distribution[].split"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "@", "property", "\n", "def", "downsampling_factor", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_distribution", "[", "'downsampling'", "]", "==", "'none'", ":", "\n", "            ", "return", "1", "\n", "", "elif", "':'", "in", "self", ".", "_distribution", "[", "'downsampling'", "]", ":", "\n", "            ", "return", "int", "(", "self", ".", "_distribution", "[", "'downsampling'", "]", ".", "split", "(", "':'", ")", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_downsampling": [[231, 246], ["manipulation_classification.ManipulationClassification._distribution[].startswith", "tensorflow.nn.avg_pool", "tensorflow.image.resize", "ValueError", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "run_downsampling", "(", "self", ",", "batch_y", ")", ":", "\n", "        ", "factor", "=", "self", ".", "downsampling_factor", "\n", "\n", "if", "self", ".", "_distribution", "[", "'downsampling'", "]", ".", "startswith", "(", "'pool'", ")", ":", "\n", "            ", "imb_down", "=", "tf", ".", "nn", ".", "avg_pool", "(", "batch_y", ",", "[", "1", ",", "factor", ",", "factor", ",", "1", "]", ",", "[", "1", ",", "factor", ",", "factor", ",", "1", "]", ",", "'SAME'", ")", "\n", "\n", "", "elif", "self", ".", "_distribution", "[", "'downsampling'", "]", "==", "'bilinear'", ":", "\n", "            ", "imb_down", "=", "tf", ".", "image", ".", "resize", "(", "batch_y", ",", "[", "tf", ".", "shape", "(", "batch_y", ")", "[", "1", "]", "//", "factor", ",", "tf", ".", "shape", "(", "batch_y", ")", "[", "1", "]", "//", "factor", "]", ",", "method", "=", "'bilinear'", ")", "\n", "\n", "", "elif", "self", ".", "_distribution", "[", "'downsampling'", "]", "==", "'none'", ":", "\n", "            ", "imb_down", "=", "batch_y", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported channel down-sampling {}'", ".", "format", "(", "self", ".", "_distribution", "[", "'downsampling'", "]", ")", ")", "\n", "\n", "", "return", "imb_down", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_compression": [[247, 256], ["manipulation_classification.ManipulationClassification.codec.process", "manipulation_classification.ManipulationClassification.codec.process", "ValueError"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "def", "run_compression", "(", "self", ",", "batch_y", ",", "return_entropy", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "_distribution", "[", "'compression'", "]", "==", "'jpeg'", ":", "\n", "            ", "return", "self", ".", "codec", ".", "process", "(", "batch_y", ",", "return_entropy", "=", "return_entropy", ")", "\n", "", "elif", "self", ".", "_distribution", "[", "'compression'", "]", "==", "'dcn'", ":", "\n", "            ", "return", "self", ".", "codec", ".", "process", "(", "batch_y", ",", "return_entropy", "=", "return_entropy", ")", "\n", "", "elif", "self", ".", "_distribution", "[", "'compression'", "]", "==", "'none'", ":", "\n", "            ", "return", "batch_y", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported channel compression {}'", ".", "format", "(", "self", ".", "_distribution", "[", "'compression'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification._batch_labels": [[257, 259], ["numpy.concatenate", "numpy.ones", "range"], "methods", ["None"], ["", "", "def", "_batch_labels", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "[", "x", "*", "np", ".", "ones", "(", "(", "batch_size", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "for", "x", "in", "range", "(", "self", ".", "n_classes", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.training_step": [[260, 286], ["manipulation_classification.ManipulationClassification._optimizer.lr.assign", "tape.gradient", "any", "manipulation_classification.ManipulationClassification._optimizer.apply_gradients", "tensorflow.GradientTape", "manipulation_classification.ManipulationClassification.run_workflow", "manipulation_classification.ManipulationClassification.fan.loss", "manipulation_classification.ManipulationClassification.nip.loss", "manipulation_classification.ManipulationClassification.codec.loss", "RuntimeError", "zip", "manipulation_classification.ManipulationClassification._batch_labels", "numpy.sum", "numpy.isnan", "numpy.mean", "numpy.isnan", "zip"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.run_workflow", "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification._batch_labels"], ["", "def", "training_step", "(", "self", ",", "batch_x", ",", "batch_y", ",", "lambda_nip", "=", "0", ",", "lambda_dcn", "=", "0", ",", "augment", "=", "False", ",", "learning_rate", "=", "1e-4", ")", ":", "\n", "        ", "batch_size", "=", "batch_x", ".", "shape", "[", "0", "]", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "\n", "            ", "batch_Y", ",", "batch_c", ",", "batch_C", ",", "entropy", ",", "probabilities", "=", "self", ".", "run_workflow", "(", "batch_x", ",", "augment", ",", "training", "=", "True", ")", "\n", "\n", "# Compute the loss", "\n", "loss_ce", "=", "self", ".", "fan", ".", "loss", "(", "self", ".", "_batch_labels", "(", "batch_size", ")", ",", "probabilities", ")", "\n", "loss_nip", "=", "self", ".", "nip", ".", "loss", "(", "batch_y", ",", "batch_Y", ")", "\n", "loss_dcn", "=", "self", ".", "codec", ".", "loss", "(", "batch_c", ",", "batch_C", ",", "entropy", ")", "\n", "\n", "loss", "=", "loss_ce", "\n", "\n", "if", "'nip'", "in", "self", ".", "_trainable", ":", "\n", "                ", "loss", "+=", "lambda_nip", "*", "loss_nip", "\n", "\n", "", "if", "'dcn'", "in", "self", ".", "_trainable", ":", "\n", "                ", "loss", "+=", "lambda_dcn", "*", "loss_dcn", "\n", "\n", "", "", "self", ".", "_optimizer", ".", "lr", ".", "assign", "(", "learning_rate", ")", "\n", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "self", ".", "_parameters", ")", "\n", "if", "any", "(", "np", ".", "sum", "(", "np", ".", "isnan", "(", "x", ")", ")", ">", "0", "for", "x", "in", "grads", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'\u2207 NaNs: {}'", ".", "format", "(", "{", "p", ".", "name", ":", "np", ".", "mean", "(", "np", ".", "isnan", "(", "x", ")", ")", "for", "x", ",", "p", "in", "zip", "(", "grads", ",", "self", ".", "_parameters", ")", "}", ")", ")", "\n", "", "self", ".", "_optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "self", ".", "_parameters", ")", ")", "\n", "\n", "return", "loss", ",", "{", "'ce'", ":", "loss_ce", ",", "'nip'", ":", "loss_nip", ",", "'dcn'", ":", "loss_dcn", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.summary_compact": [[287, 297], ["type", "manipulation_classification.ManipulationClassification.codec.summary_compact"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.summary_compact"], ["", "def", "summary_compact", "(", "self", ")", ":", "\n", "        ", "return", "'{class_name}[{trainables}]: {nip} -> [{manips}] {pool}{codec}-> {fan}'", ".", "format", "(", "\n", "class_name", "=", "type", "(", "self", ")", ".", "__name__", ",", "\n", "nip", "=", "self", ".", "nip", ".", "class_name", ",", "\n", "manips", "=", "''", ".", "join", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "_forensics_classes", "]", ")", ",", "\n", "trainables", "=", "''", ".", "join", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "trainable_models", "]", ")", ",", "\n", "pool", "=", "''", "if", "self", ".", "_distribution", "[", "'downsampling'", "]", "==", "'none'", "else", "'-> {} '", ".", "format", "(", "\n", "self", ".", "_distribution", "[", "'downsampling'", "]", ")", ",", "\n", "codec", "=", "''", "if", "self", ".", "codec", "is", "None", "else", "'-> {} '", ".", "format", "(", "self", ".", "codec", ".", "summary_compact", "(", ")", ")", ",", "\n", "fan", "=", "'FAN'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.summary": [[299, 310], ["type", "manipulation_classification.ManipulationClassification.codec.summary_compact"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.summary_compact"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "return", "'{class_name}[opt={trainables}]: {input} -> {nip} -> {n_ops} manipulations [{manips}] {pool}{codec}-> {fan}'", ".", "format", "(", "\n", "class_name", "=", "type", "(", "self", ")", ".", "__name__", ",", "\n", "input", "=", "'(rgb)'", "if", "self", ".", "nip", ".", "x", ".", "shape", "[", "-", "1", "]", "==", "3", "else", "'(raw)'", ",", "\n", "nip", "=", "self", ".", "nip", ".", "class_name", ",", "\n", "n_ops", "=", "self", ".", "n_classes", "-", "1", ",", "\n", "manips", "=", "''", ".", "join", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "_forensics_classes", "]", ")", ",", "\n", "trainables", "=", "''", ".", "join", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "trainable_models", "]", ")", ",", "\n", "pool", "=", "''", "if", "self", ".", "_distribution", "[", "'downsampling'", "]", "==", "'none'", "else", "'-> {} '", ".", "format", "(", "self", ".", "_distribution", "[", "'downsampling'", "]", ")", ",", "\n", "codec", "=", "''", "if", "self", ".", "codec", "is", "None", "else", "'-> {} '", ".", "format", "(", "self", ".", "codec", ".", "summary_compact", "(", ")", ")", ",", "\n", "fan", "=", "f'FAN -> (prob. {self.n_classes} classes)'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.details": [[312, 322], ["out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "manipulation_classification.ManipulationClassification.summary", "manipulation_classification.ManipulationClassification.nip.summary", "manipulation_classification.ManipulationClassification.fan.summary", "manipulation_classification.ManipulationClassification.codec.summary"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary"], ["", "def", "details", "(", "self", ")", ":", "\n", "        ", "out", "=", "[", "self", ".", "summary", "(", ")", "]", "\n", "out", ".", "append", "(", "'Input         : {} {}'", ".", "format", "(", "self", ".", "nip", ".", "x", ".", "shape", ",", "'(rgb)'", "if", "self", ".", "nip", ".", "x", ".", "shape", "[", "-", "1", "]", "==", "3", "else", "'(raw)'", ")", ")", "\n", "out", ".", "append", "(", "'Camera ISP    : {}'", ".", "format", "(", "self", ".", "nip", ".", "summary", "(", ")", ")", ")", "\n", "out", ".", "append", "(", "'Manipulations : {} -> {}'", ".", "format", "(", "self", ".", "n_classes", ",", "self", ".", "_forensics_classes", ")", ")", "\n", "out", ".", "append", "(", "'Downsampling  : {}'", ".", "format", "(", "self", ".", "_distribution", "[", "'downsampling'", "]", ")", ")", "\n", "out", ".", "append", "(", "'Codec         : {}'", ".", "format", "(", "''", "if", "self", ".", "codec", "is", "None", "else", "self", ".", "codec", ".", "summary", "(", ")", ")", ")", "\n", "out", ".", "append", "(", "'Forensics     : {}'", ".", "format", "(", "self", ".", "fan", ".", "summary", "(", ")", ")", ")", "\n", "out", ".", "append", "(", "'Output        : {}'", ".", "format", "(", "self", ".", "fan", ".", "y", ".", "shape", ")", ")", "\n", "return", "'\\n'", ".", "join", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.is_trainable": [[323, 325], ["None"], "methods", ["None"], ["", "def", "is_trainable", "(", "self", ",", "model", ")", ":", "\n", "        ", "return", "model", "in", "self", ".", "_trainable", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.workflows.manipulation_classification.ManipulationClassification.trainable_models": [[326, 329], ["tuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_models", "(", "self", ")", ":", "\n", "        ", "return", "tuple", "(", "x", "for", "x", "in", "self", ".", "_trainable", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.configure": [[37, 62], ["rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "rc", "mpl.rcParams.update"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["def", "configure", "(", "profile", "=", "None", ")", ":", "\n", "\n", "    ", "if", "profile", "==", "'tex'", ":", "\n", "        ", "from", "matplotlib", "import", "rc", "\n", "rc", "(", "'font'", ",", "**", "{", "'family'", ":", "'serif'", ",", "'serif'", ":", "[", "'Computer Modern'", "]", "}", ")", "\n", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "rc", "(", "'axes'", ",", "titlesize", "=", "14", ")", "\n", "rc", "(", "'axes'", ",", "labelsize", "=", "14", ")", "\n", "rc", "(", "'xtick'", ",", "labelsize", "=", "8", ")", "\n", "rc", "(", "'ytick'", ",", "labelsize", "=", "8", ")", "\n", "rc", "(", "'legend'", ",", "fontsize", "=", "10", ")", "\n", "rc", "(", "'figure'", ",", "titlesize", "=", "14", ")", "\n", "", "if", "profile", "==", "\"big\"", ":", "\n", "        ", "from", "matplotlib", "import", "rc", "\n", "# rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})", "\n", "rc", "(", "'text'", ",", "usetex", "=", "False", ")", "\n", "rc", "(", "'axes'", ",", "titlesize", "=", "14", ")", "\n", "rc", "(", "'axes'", ",", "labelsize", "=", "14", ")", "\n", "rc", "(", "'xtick'", ",", "labelsize", "=", "12", ")", "\n", "rc", "(", "'ytick'", ",", "labelsize", "=", "12", ")", "\n", "rc", "(", "'legend'", ",", "fontsize", "=", "12", ")", "\n", "rc", "(", "'figure'", ",", "titlesize", "=", "14", ")", "\n", "", "else", ":", "\n", "        ", "import", "matplotlib", "as", "mpl", "\n", "mpl", ".", "rcParams", ".", "update", "(", "mpl", ".", "rcParamsDefault", ")", "\n", "# import seaborn as sns", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.thumbnails": [[67, 112], ["int", "numpy.zeros", "range", "type", "int", "numpy.ceil", "int", "int", "images[].squeeze", "len", "list.append", "len", "list", "numpy.ceil", "numpy.floor", "int", "int", "skimage.transform.resize", "len", "numpy.expand_dims", "type", "type", "len", "list.append", "numpy.sqrt", "numpy.floor"], "function", ["None"], ["", "", "def", "thumbnails", "(", "images", ",", "ncols", "=", "0", ",", "columnwise", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return a numpy array with image thumbnails.\n    \"\"\"", "\n", "\n", "if", "type", "(", "images", ")", "is", "np", ".", "ndarray", ":", "\n", "\n", "        ", "n_images", "=", "images", ".", "shape", "[", "0", "]", "\n", "n_channels", "=", "images", ".", "shape", "[", "-", "1", "]", "\n", "img_size", "=", "images", ".", "shape", "[", "1", ":", "]", "\n", "\n", "if", "len", "(", "img_size", ")", "==", "2", ":", "\n", "            ", "img_size", ".", "append", "(", "1", ")", "\n", "\n", "", "", "elif", "type", "(", "images", ")", "is", "list", "or", "type", "(", "images", ")", "is", "tuple", ":", "\n", "\n", "        ", "n_images", "=", "len", "(", "images", ")", "\n", "n_channels", "=", "images", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "img_size", "=", "list", "(", "images", "[", "0", "]", ".", "shape", ")", "\n", "\n", "if", "len", "(", "img_size", ")", "==", "2", ":", "\n", "            ", "img_size", ".", "append", "(", "1", ")", "\n", "\n", "", "", "ncols", "=", "ncols", "if", "ncols", ">", "0", "else", "n_images", "\n", "images_x", "=", "ncols", "or", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_images", ")", ")", ")", "\n", "images_y", "=", "int", "(", "np", ".", "ceil", "(", "n_images", "/", "images_x", ")", ")", "\n", "size", "=", "(", "images_y", ",", "images_x", ")", "\n", "\n", "# Allocate space for the thumbnails", "\n", "output", "=", "np", ".", "zeros", "(", "(", "size", "[", "0", "]", "*", "img_size", "[", "0", "]", ",", "size", "[", "1", "]", "*", "img_size", "[", "1", "]", ",", "img_size", "[", "2", "]", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "n_images", ")", ":", "\n", "        ", "bx", "=", "int", "(", "r", "%", "images_x", ")", "\n", "by", "=", "int", "(", "np", ".", "floor", "(", "r", "/", "images_x", ")", ")", "\n", "if", "columnwise", ":", "\n", "            ", "by", "=", "int", "(", "r", "%", "images_y", ")", "\n", "bx", "=", "int", "(", "np", ".", "floor", "(", "r", "/", "images_y", ")", ")", "\n", "", "current", "=", "images", "[", "r", "]", ".", "squeeze", "(", ")", "\n", "if", "current", ".", "shape", "[", "0", "]", "!=", "img_size", "[", "0", "]", "or", "current", ".", "shape", "[", "1", "]", "!=", "img_size", "[", "1", "]", ":", "\n", "            ", "current", "=", "resize", "(", "current", ",", "img_size", "[", ":", "-", "1", "]", ",", "anti_aliasing", "=", "True", ")", "\n", "", "if", "len", "(", "current", ".", "shape", ")", "==", "2", ":", "\n", "            ", "current", "=", "np", ".", "expand_dims", "(", "current", ",", "axis", "=", "2", ")", "\n", "", "output", "[", "by", "*", "img_size", "[", "0", "]", ":", "(", "by", "+", "1", ")", "*", "img_size", "[", "0", "]", ",", "bx", "*", "img_size", "[", "1", "]", ":", "(", "bx", "+", "1", ")", "*", "img_size", "[", "1", "]", ",", ":", "]", "=", "current", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots._imarray": [[114, 147], ["int", "range", "RuntimeError", "int", "numpy.ceil", "ValueError", "ValueError", "matplotlib.figure.Figure", "fig.add_subplot", "plots.image", "numpy.ceil", "len", "type", "len", "fetch_hook", "fig.add_subplot.set_ylabel", "numpy.sqrt", "abs", "range", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image"], ["", "def", "_imarray", "(", "img", ",", "n_images", ",", "fetch_hook", ",", "titles", ",", "figwidth", "=", "4", ",", "cmap", "=", "'gray'", ",", "ncols", "=", "0", ",", "fig", "=", "None", ",", "rowlabels", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Function for plotting arrays of images. Not intended to be used directly. See 'images' for typical use cases.\n    \"\"\"", "\n", "if", "n_images", ">", "128", ":", "\n", "        ", "raise", "RuntimeError", "(", "'The number of subplots exceeds reasonable limits ({})!'", ".", "format", "(", "n_images", ")", ")", "\n", "\n", "", "if", "ncols", "==", "0", ":", "\n", "        ", "ncols", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_images", ")", ")", ")", "\n", "", "elif", "ncols", "<", "0", ":", "\n", "        ", "ncols", "=", "n_images", "//", "abs", "(", "ncols", ")", "\n", "\n", "", "subplot_x", "=", "ncols", "\n", "subplot_y", "=", "int", "(", "np", ".", "ceil", "(", "n_images", "/", "subplot_x", ")", ")", "\n", "\n", "if", "rowlabels", "is", "not", "None", "and", "len", "(", "rowlabels", ")", "!=", "subplot_y", ":", "\n", "        ", "raise", "ValueError", "(", "'The number of rows does not match the provided labels!'", ")", "\n", "\n", "", "if", "titles", "is", "not", "None", "and", "type", "(", "titles", ")", "is", "str", ":", "\n", "        ", "titles", "=", "[", "titles", "for", "x", "in", "range", "(", "n_images", ")", "]", "\n", "\n", "", "if", "titles", "is", "not", "None", "and", "len", "(", "titles", ")", "!=", "n_images", ":", "\n", "        ", "raise", "ValueError", "(", "'Provided titles ({}) do not match the number of images ({})!'", ".", "format", "(", "len", "(", "titles", ")", ",", "n_images", ")", ")", "\n", "\n", "", "fig", "=", "fig", "or", "Figure", "(", "figsize", "=", "(", "figwidth", "*", "subplot_x", ",", "figwidth", "*", "subplot_y", ")", ")", "\n", "\n", "for", "n", "in", "range", "(", "n_images", ")", ":", "\n", "        ", "ax", "=", "fig", ".", "add_subplot", "(", "subplot_y", ",", "subplot_x", ",", "n", "+", "1", ")", "\n", "image", "(", "fetch_hook", "(", "img", ",", "n", ")", ",", "titles", "[", "n", "]", "if", "titles", "is", "not", "None", "else", "None", ",", "axes", "=", "ax", ",", "cmap", "=", "cmap", ")", "\n", "if", "rowlabels", "is", "not", "None", "and", "n", "%", "subplot_x", "==", "0", ":", "\n", "            ", "ax", ".", "set_ylabel", "(", "rowlabels", "[", "n", "//", "subplot_x", "]", ")", "\n", "\n", "", "", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.images": [[149, 223], ["len", "plots._imarray", "type", "type", "type", "plots._imarray", "ValueError", "plots.image", "matplotlib.figure.Figure", "type", "fig.gca", "numpy.moveaxis", "ValueError"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots._imarray", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots._imarray", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image"], ["", "def", "images", "(", "imgs", ",", "titles", "=", "None", ",", "figwidth", "=", "4", ",", "cmap", "=", "'gray'", ",", "ncols", "=", "0", ",", "fig", "=", "None", ",", "rowlabels", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Plot a series of images (in various structures). Not thoroughly tested, but should work with:\n\n    - np.ndarray of size (h,w,3) or (h,w)\n    - lists or tuples of np.ndarray of size (h,w,3) or (h,w)    \n    - np.ndarray of size (h,w,channels) -> channels shown separately\n    - np.ndarray of size (1, h, w, channels)\n    - np.ndarray of size (N, h, w, 3) and (N, h, w, 1)\n    \n    CAUTION: This function creates new figures without a canvas manager - this prevents memory leaks but makes it more\n    difficult to plot figures in interactive notebooks. In case of trouble, you can supply a target figure created by\n    a managed matplotlib interface - use fig=plt.figure().\n\n    :param imgs: input image structure (see details above)\n    :param titles: a single string or a list of strings matching the number of images in the structure\n    :param figwidth: width of a single image in the figure\n    :param cmap: color map\n    :param ncols: number of columns or: 0 for sqrt(#images) cols; use negative to set the number of rows\n    :param fig: specify the target figure for plotting\n    \"\"\"", "\n", "\n", "if", "type", "(", "imgs", ")", "is", "list", "or", "type", "(", "imgs", ")", "is", "tuple", ":", "\n", "\n", "        ", "n_images", "=", "len", "(", "imgs", ")", "\n", "\n", "def", "fetch_example", "(", "image", ",", "n", ")", ":", "\n", "            ", "return", "image", "[", "n", "]", "\n", "\n", "", "return", "_imarray", "(", "imgs", ",", "n_images", ",", "fetch_example", ",", "titles", ",", "figwidth", ",", "cmap", ",", "ncols", ",", "fig", ",", "rowlabels", ")", "\n", "\n", "", "elif", "type", "(", "imgs", ")", "in", "[", "np", ".", "ndarray", ",", "imageio", ".", "core", ".", "util", ".", "Image", "]", ":", "\n", "\n", "        ", "if", "imgs", ".", "ndim", "==", "2", "or", "(", "imgs", ".", "ndim", "==", "3", "and", "imgs", ".", "shape", "[", "-", "1", "]", "==", "3", ")", ":", "\n", "\n", "            ", "fig", "=", "fig", "or", "Figure", "(", "tight_layout", "=", "True", ",", "figsize", "=", "(", "figwidth", ",", "figwidth", ")", ")", "\n", "image", "(", "imgs", ",", "titles", ",", "axes", "=", "fig", ".", "gca", "(", ")", ",", "cmap", "=", "cmap", ")", "\n", "\n", "return", "fig", "\n", "\n", "", "elif", "imgs", ".", "ndim", "==", "3", "and", "imgs", ".", "shape", "[", "-", "1", "]", "!=", "3", ":", "\n", "\n", "            ", "def", "fetch_example", "(", "im", ",", "n", ")", ":", "\n", "                ", "return", "im", "[", "...", ",", "n", "]", "\n", "\n", "", "n_images", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "n_images", ">", "100", ":", "\n", "                ", "imgs", "=", "np", ".", "moveaxis", "(", "imgs", ",", "0", ",", "-", "1", ")", "\n", "n_images", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "", "elif", "imgs", ".", "ndim", "==", "4", "and", "(", "imgs", ".", "shape", "[", "-", "1", "]", "==", "3", "or", "imgs", ".", "shape", "[", "-", "1", "]", "==", "1", ")", ":", "\n", "\n", "            ", "n_images", "=", "imgs", ".", "shape", "[", "0", "]", "\n", "\n", "def", "fetch_example", "(", "im", ",", "n", ")", ":", "\n", "                ", "return", "im", "[", "n", "]", "\n", "\n", "", "", "elif", "imgs", ".", "ndim", "==", "4", "and", "imgs", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "\n", "            ", "n_images", "=", "imgs", ".", "shape", "[", "-", "1", "]", "\n", "\n", "def", "fetch_example", "(", "im", ",", "n", ")", ":", "\n", "                ", "return", "im", "[", "...", ",", "n", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported array dimensions {}!'", ".", "format", "(", "imgs", ".", "shape", ")", ")", "\n", "\n", "", "return", "_imarray", "(", "imgs", ",", "n_images", ",", "fetch_example", ",", "titles", ",", "figwidth", ",", "cmap", ",", "ncols", ",", "fig", ",", "rowlabels", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported array type {}!'", ".", "format", "(", "type", "(", "imgs", ")", ")", ")", "\n", "\n", "", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image": [[225, 256], ["x.squeeze.squeeze", "any", "fig.gca.imshow", "fig.gca.set_xticks", "fig.gca.set_yticks", "label.replace.replace", "label.replace.replace", "label.replace.replace", "label.replace.replace", "matplotlib.figure.Figure", "matplotlib.figure.Figure.gca", "len", "fig.gca.set_title", "locals", "numpy.min", "numpy.max", "numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "image", "(", "x", ",", "label", "=", "None", ",", "*", ",", "axes", "=", "None", ",", "cmap", "=", "'gray'", ")", ":", "\n", "    ", "\"\"\"\n    Plot a single image, hide ticks & add a formatted title with patterns replaced as follows:\n    - '()' -> '(height x width)'\n    - '[]' -> '[min - max]'\n    - '{}' -> '(height x width) / [min - max]'\n    - '<>' -> 'avg \u00b1 std'\n    \"\"\"", "\n", "\n", "label", "=", "label", "if", "label", "is", "not", "None", "else", "'{}'", "\n", "\n", "x", "=", "x", ".", "squeeze", "(", ")", "\n", "\n", "if", "any", "(", "ptn", "in", "label", "for", "ptn", "in", "[", "'{}'", ",", "'()'", ",", "'[]'", ",", "'<>'", "]", ")", ":", "\n", "        ", "label", "=", "label", ".", "replace", "(", "'{}'", ",", "'() / []'", ")", "\n", "label", "=", "label", ".", "replace", "(", "'()'", ",", "'({}x{})'", ".", "format", "(", "*", "x", ".", "shape", "[", "0", ":", "2", "]", ")", ")", "\n", "label", "=", "label", ".", "replace", "(", "'[]'", ",", "'[{:.2f} - {:.2f}]'", ".", "format", "(", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ")", ")", "\n", "label", "=", "label", ".", "replace", "(", "'<>'", ",", "'{:.2f} \u00b1 {:.2f}'", ".", "format", "(", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n", "", "if", "axes", "is", "None", ":", "\n", "        ", "fig", "=", "Figure", "(", ")", "\n", "axes", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "", "axes", ".", "imshow", "(", "x", ",", "cmap", "=", "cmap", ")", "\n", "if", "len", "(", "label", ")", ">", "0", ":", "\n", "        ", "axes", ".", "set_title", "(", "label", ")", "\n", "", "axes", ".", "set_xticks", "(", "[", "]", ")", "\n", "axes", ".", "set_yticks", "(", "[", "]", ")", "\n", "\n", "if", "'fig'", "in", "locals", "(", ")", ":", "\n", "        ", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub": [[258, 314], ["int", "fig.subplots", "int", "int", "numpy.ceil", "matplotlib.figure.Figure", "hasattr", "hasattr", "numpy.ceil", "numpy.ceil", "numpy.sqrt", "abs", "numpy.sqrt", "len", "axes_flat.append", "ax.remove", "product", "len", "axes_flat.append", "a.remove", "range", "range"], "function", ["None"], ["", "", "def", "sub", "(", "n_plots", ",", "figwidth", "=", "6", ",", "figheight", "=", "None", ",", "ncols", "=", "-", "1", ",", "fig", "=", "None", ",", "transpose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a figure and split it into subplots. Provides more consistent behavior than matplotlib. Key features:\n    - the returned axes are always a list\n    - automatically choose number of rows/columns based on the total number of plots\n    - the extra subplots will be turned off\n    - axes traversal order can be changed (column/row-wise)\n\n    :param n_plots:\n    :param figwidth:\n    :param figheight:\n    :param ncols:\n    :param fig:\n    :param transpose:\n    :return:\n    \"\"\"", "\n", "\n", "if", "ncols", "==", "0", ":", "\n", "        ", "ncols", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_plots", ")", ")", ")", "\n", "", "elif", "ncols", "<", "0", ":", "\n", "        ", "ncols", "=", "n_plots", "//", "abs", "(", "ncols", ")", "\n", "\n", "", "figheight", "=", "figheight", "or", "figwidth", "\n", "\n", "subplot_x", "=", "ncols", "or", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_plots", ")", ")", ")", "\n", "subplot_y", "=", "int", "(", "np", ".", "ceil", "(", "n_plots", "/", "subplot_x", ")", ")", "\n", "\n", "if", "transpose", ":", "\n", "        ", "subplot_x", ",", "subplot_y", "=", "subplot_y", ",", "subplot_x", "\n", "\n", "", "fig", "=", "fig", "or", "Figure", "(", "tight_layout", "=", "True", ",", "figsize", "=", "(", "figwidth", "*", "subplot_x", ",", "subplot_y", "*", "(", "figheight", "or", "figwidth", "*", "(", "subplot_y", "/", "subplot_x", ")", ")", ")", ")", "\n", "axes", "=", "fig", ".", "subplots", "(", "nrows", "=", "subplot_y", ",", "ncols", "=", "subplot_x", ")", "\n", "axes_flat", "=", "[", "]", "\n", "\n", "if", "not", "hasattr", "(", "axes", ",", "'__iter__'", ")", ":", "\n", "        ", "axes", "=", "[", "axes", "]", "\n", "\n", "", "for", "ax", "in", "axes", ":", "\n", "\n", "        ", "if", "hasattr", "(", "ax", ",", "'__iter__'", ")", ":", "\n", "            ", "for", "a", "in", "ax", ":", "\n", "                ", "if", "len", "(", "axes_flat", ")", "<", "n_plots", ":", "\n", "                    ", "axes_flat", ".", "append", "(", "a", ")", "\n", "", "else", ":", "\n", "                    ", "a", ".", "remove", "(", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "len", "(", "axes_flat", ")", "<", "n_plots", ":", "\n", "                ", "axes_flat", ".", "append", "(", "ax", ")", "\n", "", "else", ":", "\n", "                ", "ax", ".", "remove", "(", ")", "\n", "\n", "", "", "", "if", "transpose", ":", "\n", "        ", "from", "itertools", "import", "product", "\n", "axes_flat", "=", "[", "axes_flat", "[", "j", "*", "subplot_x", "+", "i", "]", "for", "i", ",", "j", "in", "product", "(", "range", "(", "subplot_x", ")", ",", "range", "(", "subplot_y", ")", ")", "]", "\n", "\n", "", "return", "fig", ",", "axes_flat", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.progress": [[316, 332], ["enumerate", "axes.set_title", "axes.plot", "axes.plot", "axes.set_xlabel", "axes.legend", "len", "len", "numpy.linspace", "helpers.stats.ma_exp", "axes.set_yscale", "len", "len", "isinstance", "numpy.std", "max", "min"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_exp"], ["", "def", "progress", "(", "k", ",", "v", ",", "results", "=", "(", "'training'", ",", "'validation'", ")", ",", "log", "=", "'auto'", ",", "axes", "=", "None", ",", "start", "=", "0", ",", "alpha", "=", "0.8", ")", ":", "\n", "    ", "active", "=", "False", "\n", "markers", "=", "'.os^'", "[", ":", "len", "(", "results", ")", "]", "\n", "for", "ri", ",", "r", "in", "enumerate", "(", "results", ")", ":", "\n", "        ", "if", "r", "not", "in", "v", "or", "len", "(", "v", "[", "r", "]", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "n_hist", "=", "len", "(", "v", "[", "r", "]", ")", "//", "2", "\n", "active", "=", "True", "\n", "xr", "=", "start", "+", "np", ".", "linspace", "(", "0", ",", "100", ",", "len", "(", "v", "[", "r", "]", ")", ")", "\n", "axes", ".", "set_title", "(", "k", ")", "\n", "axes", ".", "plot", "(", "xr", ",", "v", "[", "r", "]", ",", "f'C{ri}{markers[ri]}'", ",", "alpha", "=", "0.5", ")", "\n", "axes", ".", "plot", "(", "xr", ",", "stats", ".", "ma_exp", "(", "v", "[", "r", "]", ",", "alpha", ")", ",", "f'C{ri}-'", ",", "label", "=", "'{} ({:.3f})'", ".", "format", "(", "r", ",", "v", "[", "r", "]", "[", "-", "1", "]", ")", ")", "\n", "if", "(", "log", "==", "'auto'", "and", "np", ".", "std", "(", "v", "[", "r", "]", "[", "-", "n_hist", ":", "]", ")", "/", "(", "max", "(", "v", "[", "r", "]", ")", "-", "min", "(", "v", "[", "r", "]", ")", ")", "<", "0.02", ")", "or", "(", "isinstance", "(", "log", ",", "bool", ")", "and", "log", ")", ":", "\n", "            ", "axes", ".", "set_yscale", "(", "'log'", ")", "\n", "", "axes", ".", "set_xlabel", "(", "'Training progress [%]'", ")", "\n", "", "if", "active", ":", "axes", ".", "legend", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.perf": [[334, 377], ["isinstance", "any", "enumerate", "plots.sub", "fig.set_size_inches", "enumerate", "training_progress.update", "training_progress.items", "len", "ValueError", "len", "plots.progress", "all", "active.append", "isinstance", "training_progress.values", "training_progress.items", "isinstance", "len", "v.keys", "training_progress.items", "helpers.utils.is_vector", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.progress", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_vector"], ["", "def", "perf", "(", "training_progress", ",", "results", "=", "None", ",", "figwidth", "=", "5", ",", "log", "=", "'auto'", ",", "fig", "=", "None", ",", "alpha", "=", "0.25", ")", ":", "\n", "    ", "\"\"\"\n    Plots training performance stats organized into a dictionary with the following structure:\n     - {metric}/{training,validation} -> [values]\n     - {metric} -> [values]\n\n    :param training_progress: dictionary with training progress\n    :param results: tuple or string, specifies which results to show, e.g., ('training', 'validation') or 'training'\n    :param figwidth: width of a single subplot\n    :param log: whether to use log scale\n    :param fig: handle to matplotlib figure\n    :param alpha: parameter for the exponential moving average\n    :return: figure handle\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "results", ",", "str", ")", ":", "\n", "        ", "results", "=", "(", "results", ",", ")", "\n", "\n", "# If the data is not formatted as {metric: {training: [values], validation: [values]}} but rather {metric: [values]}", "\n", "# convert to the expected structure", "\n", "", "if", "any", "(", "not", "isinstance", "(", "v", ",", "dict", ")", "for", "v", "in", "training_progress", ".", "values", "(", ")", ")", ":", "\n", "        ", "training_progress", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "training_progress", ".", "items", "(", ")", "if", "isinstance", "(", "v", ",", "dict", ")", "}", "\n", "training_progress", ".", "update", "(", "{", "k", ":", "{", "'auto'", ":", "v", "}", "for", "k", ",", "v", "in", "training_progress", ".", "items", "(", ")", "if", "utils", ".", "is_vector", "(", "v", ")", "}", ")", "\n", "\n", "# Find the number of metrics with available data", "\n", "", "active", "=", "[", "]", "\n", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "training_progress", ".", "items", "(", ")", ")", ":", "\n", "# Check if all training metrics have all requested sets of results", "\n", "        ", "if", "results", "is", "None", "or", "all", "(", "r", "in", "v", "and", "len", "(", "v", "[", "r", "]", ")", ">", "0", "for", "r", "in", "results", ")", ":", "\n", "            ", "active", ".", "append", "(", "k", ")", "\n", "\n", "", "", "if", "len", "(", "active", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'No valid plots! Missing training/validation data? Use results=[\"training\"] to select.'", ")", "\n", "\n", "", "fig", ",", "axes", "=", "sub", "(", "len", "(", "active", ")", ",", "ncols", "=", "-", "1", ",", "fig", "=", "fig", ")", "\n", "fig", ".", "set_size_inches", "(", "(", "len", "(", "active", ")", "*", "figwidth", ",", "figwidth", "*", "0.75", ")", ")", "\n", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "active", ")", ":", "\n", "        ", "v", "=", "training_progress", "[", "k", "]", "\n", "progress", "(", "k", ",", "v", ",", "results", "or", "v", ".", "keys", "(", ")", ",", "log", ",", "axes", "[", "i", "]", ",", "alpha", "=", "alpha", ")", "\n", "\n", "", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.detection": [[379, 438], ["numpy.min", "numpy.max", "numpy.linspace", "helpers.stats.detection_accuracy", "helpers.stats.true_positive_rate", "numpy.percentile", "numpy.percentile", "helpers.stats.bin_edges", "fig.gca.hist", "fig.gca.hist", "fig.gca.set_title", "fig.gca.set_ylim", "fig.gca.legend", "numpy.max", "numpy.min", "matplotlib.figure.Figure", "matplotlib.figure.Figure.gca", "positive.ravel", "negative.ravel", "fig.gca.hist", "max", "fig.gca.plot", "fig.gca.plot", "fig.gca.plot", "title.replace", "fig.gca.set_xlim", "locals", "positive.min", "negative.min", "positive.max", "negative.max", "reference.ravel", "numpy.max", "numpy.max", "fig.gca.plot", "reference.max", "reference.min", "max"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.detection_accuracy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.true_positive_rate", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.bin_edges", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist"], ["", "def", "detection", "(", "positive", ",", "negative", ",", "bins", "=", "200", ",", "axes", "=", "None", ",", "title", "=", "'()'", ",", "scale", "=", "True", ",", "reference", "=", "None", ",", "guides", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Plot histograms of positive & negative detection scores.\n\n    :param positive: positive detection scores (numpy array)\n    :param negative: positive detection scores (numpy array)\n    :param bins: number of histogram bins\n    :param axes: matplotlib axes' handle\n    :param title: plot title, '()' will be replaced with accuracy and tpr stats\n    :param scale: boolean flag to auto select x limits\n    :param reference: additional scores to be plotted as a reference (shown in gray)\n    :param guides: draw lines as guides: 0 (no lines), 1 (best accuracy threshold), 2 (threshold + percentiles)\n    :return: figure handle (if created here)\n    \"\"\"", "\n", "\n", "cc_min", "=", "np", ".", "min", "(", "[", "positive", ".", "min", "(", ")", ",", "negative", ".", "min", "(", ")", "]", ")", "\n", "cc_max", "=", "np", ".", "max", "(", "[", "positive", ".", "max", "(", ")", ",", "negative", ".", "max", "(", ")", "]", ")", "\n", "\n", "if", "reference", "is", "not", "None", ":", "\n", "        ", "cc_max", "=", "np", ".", "max", "(", "[", "cc_max", ",", "reference", ".", "max", "(", ")", "]", ")", "\n", "cc_min", "=", "np", ".", "min", "(", "[", "cc_min", ",", "reference", ".", "min", "(", ")", "]", ")", "\n", "\n", "", "cc", "=", "np", ".", "linspace", "(", "cc_min", ",", "cc_max", ",", "bins", ")", "\n", "bin_accuracy", ",", "thr_id", "=", "stats", ".", "detection_accuracy", "(", "positive", ",", "negative", ",", "cc", ",", "return_index", "=", "True", ")", "\n", "tpr", "=", "stats", ".", "true_positive_rate", "(", "positive", ",", "negative", ")", "\n", "\n", "v_no_match_min", "=", "np", ".", "percentile", "(", "negative", ",", "99", ")", "\n", "v_do_match_max", "=", "np", ".", "percentile", "(", "positive", ",", "1", ")", "\n", "\n", "if", "axes", "is", "None", ":", "\n", "        ", "fig", "=", "Figure", "(", ")", "\n", "axes", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "# From bin centers, convert to bin edges for histogram computation", "\n", "", "h_bins", "=", "stats", ".", "bin_edges", "(", "cc", ")", "\n", "\n", "h1", "=", "axes", ".", "hist", "(", "positive", ".", "ravel", "(", ")", ",", "h_bins", ",", "color", "=", "'g'", ",", "alpha", "=", "0.4", ",", "density", "=", "True", ",", "label", "=", "'positive'", ")", "\n", "h2", "=", "axes", ".", "hist", "(", "negative", ".", "ravel", "(", ")", ",", "h_bins", ",", "color", "=", "'r'", ",", "alpha", "=", "0.4", ",", "density", "=", "True", ",", "label", "=", "'negative'", ")", "\n", "if", "reference", "is", "not", "None", ":", "\n", "        ", "h3", "=", "axes", ".", "hist", "(", "reference", ".", "ravel", "(", ")", ",", "h_bins", ",", "color", "=", "'gray'", ",", "alpha", "=", "0.4", ",", "density", "=", "True", ",", "label", "=", "'reference'", ")", "\n", "\n", "", "h_max", "=", "1.05", "*", "max", "(", "np", ".", "max", "(", "h1", "[", "0", "]", ")", ",", "np", ".", "max", "(", "h2", "[", "0", "]", ")", ")", "\n", "if", "guides", "==", "2", ":", "\n", "        ", "axes", ".", "plot", "(", "[", "v_do_match_max", ",", "v_do_match_max", "]", ",", "[", "0", ",", "h_max", "]", ",", "'g--'", ")", "\n", "axes", ".", "plot", "(", "[", "v_no_match_min", ",", "v_no_match_min", "]", ",", "[", "0", ",", "h_max", "]", ",", "'r--'", ")", "\n", "axes", ".", "plot", "(", "[", "cc", "[", "thr_id", "]", ",", "cc", "[", "thr_id", "]", "]", ",", "[", "0", ",", "max", "(", "h1", "[", "0", "]", "[", "thr_id", "]", ",", "0.05", "*", "h_max", ")", "]", ",", "'k:'", ")", "\n", "", "elif", "guides", "==", "1", ":", "\n", "        ", "axes", ".", "plot", "(", "[", "cc", "[", "thr_id", "]", ",", "cc", "[", "thr_id", "]", "]", ",", "[", "0", ",", "h_max", "]", ",", "'k:'", ")", "\n", "\n", "", "axes", ".", "set_title", "(", "title", ".", "replace", "(", "'()'", ",", "f'acc. {bin_accuracy:.2f}, tpr @ 1\\\\%far={tpr:.2f}'", ")", ")", "\n", "\n", "if", "scale", ":", "\n", "        ", "axes", ".", "set_xlim", "(", "[", "1.1", "*", "cc_min", "if", "cc_min", "<", "0", "else", "0.9", "*", "cc_min", ",", "1.1", "*", "cc_max", "]", ")", "\n", "\n", "", "axes", ".", "set_ylim", "(", "[", "0", ",", "h_max", "]", ")", "\n", "axes", ".", "legend", "(", ")", "\n", "\n", "if", "'fig'", "in", "locals", "(", ")", ":", "\n", "        ", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.roc": [[440, 464], ["helpers.stats.roc", "helpers.stats.true_positive_rate", "helpers.stats.auc", "fig.gca.plot", "fig.gca.set_xlim", "fig.gca.set_ylim", "fig.gca.set_xlabel", "fig.gca.set_ylabel", "matplotlib.figure.Figure", "matplotlib.figure.Figure.gca", "fig.gca.plot", "fig.gca.plot", "fig.gca.plot", "fig.gca.legend", "locals"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.roc", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.true_positive_rate", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.auc"], ["", "", "def", "roc", "(", "matching", ",", "non_matching", ",", "bins", "=", "100", ",", "axes", "=", "None", ",", "label", "=", "None", ",", "plot_guides", "=", "True", ")", ":", "\n", "\n", "    ", "tpr", ",", "fpr", "=", "stats", ".", "roc", "(", "matching", ",", "non_matching", ",", "bins", ")", "\n", "tpr_at_1pp_fpr", "=", "stats", ".", "true_positive_rate", "(", "matching", ",", "non_matching", ",", "0.01", ")", "\n", "auc", "=", "stats", ".", "auc", "(", "matching", ",", "non_matching", ")", "\n", "\n", "if", "axes", "is", "None", ":", "\n", "        ", "fig", "=", "Figure", "(", ")", "\n", "axes", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "", "label", "=", "f'{label} : tpr={tpr_at_1pp_fpr:.2f} auc={auc:.2f}'", "if", "label", "is", "not", "None", "else", "None", "\n", "axes", ".", "plot", "(", "fpr", ",", "tpr", ",", "'-'", ",", "label", "=", "label", ")", "\n", "if", "plot_guides", ":", "\n", "        ", "axes", ".", "plot", "(", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ",", "'k--'", ",", "alpha", "=", "0.2", ")", "\n", "axes", ".", "plot", "(", "[", "0.01", ",", "0.01", "]", ",", "[", "0", ",", "tpr_at_1pp_fpr", "]", ",", "'k:'", ",", "alpha", "=", "0.25", ")", "\n", "axes", ".", "plot", "(", "[", "0.01", ",", "1", "]", ",", "[", "tpr_at_1pp_fpr", ",", "tpr_at_1pp_fpr", "]", ",", "'k:'", ",", "alpha", "=", "0.25", ")", "\n", "", "axes", ".", "set_xlim", "(", "[", "-", "0.02", ",", "1.02", "]", ")", "\n", "axes", ".", "set_ylim", "(", "[", "-", "0.02", ",", "1.02", "]", ")", "\n", "axes", ".", "set_xlabel", "(", "'false positive rate'", ")", "\n", "axes", ".", "set_ylabel", "(", "'true positive rate'", ")", "\n", "if", "label", "is", "not", "None", ":", "axes", ".", "legend", "(", ")", "\n", "\n", "if", "'fig'", "in", "locals", "(", ")", ":", "\n", "        ", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.intervals_bulk": [[466, 481], ["plots.sub", "fig.set_size_inches", "enumerate", "len", "sorted", "y.items", "axes[].plot", "axes[].fill_between", "axes[].set_ylabel", "axes[].set_xlabel", "x.keys", "numpy.percentile", "numpy.percentile", "numpy.percentile", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["", "", "def", "intervals_bulk", "(", "x", ",", "y", ",", "p", "=", "10", ")", ":", "\n", "# fig, axes = plt.subplots(nrows=1, ncols=len(y), sharex=True)", "\n", "    ", "fig", ",", "axes", "=", "sub", "(", "len", "(", "y", ")", ",", "ncols", "=", "-", "1", ")", "\n", "fig", ".", "set_size_inches", "(", "(", "6", "*", "len", "(", "y", ")", ",", "3", ")", ")", "\n", "\n", "xl", "=", "sorted", "(", "x", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "xv", "=", "x", "[", "xl", "]", "\n", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "y", ".", "items", "(", ")", ")", ":", "\n", "        ", "axes", "[", "i", "]", ".", "plot", "(", "xv", ",", "np", ".", "percentile", "(", "v", ",", "50", ",", "axis", "=", "0", ")", ")", "\n", "axes", "[", "i", "]", ".", "fill_between", "(", "xv", ",", "np", ".", "percentile", "(", "v", ",", "p", ",", "axis", "=", "0", ")", ",", "np", ".", "percentile", "(", "v", ",", "100", "-", "p", ",", "axis", "=", "0", ")", ",", "alpha", "=", "0.2", ",", "edgecolor", "=", "'#1B2ACC'", ",", "facecolor", "=", "'#089FFF'", ",", ")", "\n", "axes", "[", "i", "]", ".", "set_ylabel", "(", "k", ")", "\n", "axes", "[", "i", "]", ".", "set_xlabel", "(", "xl", ")", "\n", "\n", "", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.intervals": [[483, 488], ["axes.plot", "axes.fill_between", "numpy.percentile", "numpy.percentile", "numpy.percentile", "axes.set_ylabel", "axes.set_xlabel"], "function", ["None"], ["", "def", "intervals", "(", "x", ",", "y", ",", "p", "=", "10", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "style", "=", "'.-'", ",", "axes", "=", "None", ")", ":", "\n", "    ", "axes", ".", "plot", "(", "x", ",", "np", ".", "percentile", "(", "y", ",", "50", ",", "axis", "=", "0", ")", ",", "style", ")", "\n", "axes", ".", "fill_between", "(", "x", ",", "np", ".", "percentile", "(", "y", ",", "p", ",", "axis", "=", "0", ")", ",", "np", ".", "percentile", "(", "y", ",", "100", "-", "p", ",", "axis", "=", "0", ")", ",", "alpha", "=", "0.2", ",", "edgecolor", "=", "'#1B2ACC'", ",", "facecolor", "=", "'#089FFF'", ",", ")", "\n", "if", "ylabel", "is", "not", "None", ":", "axes", ".", "set_ylabel", "(", "ylabel", ")", "\n", "if", "xlabel", "is", "not", "None", ":", "axes", ".", "set_xlabel", "(", "xlabel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.correlation": [[490, 505], ["helpers.stats.corrcoeff", "helpers.stats.rsquared", "axes.plot", "axes.set_title", "x.ravel", "y.ravel", "x.ravel", "y.ravel", "x.ravel", "y.ravel", "axes.plot", "axes.set_xlabel", "axes.set_ylabel", "axes.get_xlim", "axes.get_ylim"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.corrcoeff", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.rsquared"], ["", "def", "correlation", "(", "x", ",", "y", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "title", "=", "None", ",", "axes", "=", "None", ",", "alpha", "=", "0.1", ",", "guide", "=", "False", ")", ":", "\n", "\n", "    ", "title", "=", "'{} : '", ".", "format", "(", "title", ")", "if", "title", "is", "not", "None", "else", "''", "\n", "\n", "cc", "=", "stats", ".", "corrcoeff", "(", "x", ".", "ravel", "(", ")", ",", "y", ".", "ravel", "(", ")", ")", "\n", "r2", "=", "stats", ".", "rsquared", "(", "x", ".", "ravel", "(", ")", ",", "y", ".", "ravel", "(", ")", ")", "\n", "\n", "axes", ".", "plot", "(", "x", ".", "ravel", "(", ")", ",", "y", ".", "ravel", "(", ")", ",", "'.'", ",", "alpha", "=", "alpha", ")", "\n", "axes", ".", "set_title", "(", "'{}corr {:.2f} / R2 {:.2f}'", ".", "format", "(", "title", ",", "cc", ",", "r2", ")", ")", "\n", "\n", "if", "guide", ":", "\n", "        ", "axes", ".", "plot", "(", "axes", ".", "get_xlim", "(", ")", ",", "axes", ".", "get_ylim", "(", ")", ",", "'k:'", ",", "alpha", "=", "0.2", ")", "\n", "\n", "", "if", "xlabel", "is", "not", "None", ":", "axes", ".", "set_xlabel", "(", "xlabel", ")", "\n", "if", "ylabel", "is", "not", "None", ":", "axes", ".", "set_ylabel", "(", "ylabel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.scatter_hex": [[507, 531], ["axes.hexbin", "axes.set_xticks", "axes.set_yticks", "axes.set_xlabel", "axes.set_ylabel", "numpy.histogram", "numpy.convolve", "axes.get_ylim", "axes.bar", "axes.set_ylim", "numpy.histogram", "numpy.convolve", "axes.get_xlim", "axes.barh", "axes.set_xlim", "x.reshape", "x_hist.max", "y.reshape", "y_hist.max", "numpy.abs", "numpy.abs"], "function", ["None"], ["", "def", "scatter_hex", "(", "x", ",", "y", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "axes", "=", "None", ",", "marginals", "=", "True", ",", "bins", "=", "30", ")", ":", "\n", "    ", "axes", ".", "hexbin", "(", "x", ",", "y", ",", "gridsize", "=", "50", ",", "bins", "=", "bins", ",", "cmap", "=", "'Blues'", ")", "\n", "axes", ".", "set_xticks", "(", "[", "]", ")", "\n", "axes", ".", "set_yticks", "(", "[", "]", ")", "\n", "\n", "if", "xlabel", "is", "not", "None", ":", "axes", ".", "set_xlabel", "(", "xlabel", ")", "\n", "if", "ylabel", "is", "not", "None", ":", "axes", ".", "set_ylabel", "(", "ylabel", ")", "\n", "\n", "if", "marginals", ":", "\n", "# X marginal", "\n", "        ", "x_hist", ",", "x_bins", "=", "np", ".", "histogram", "(", "x", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", ",", "bins", "=", "bins", ")", "\n", "x_bins", "=", "np", ".", "convolve", "(", "x_bins", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "x_hist", "=", "x_hist", "/", "x_hist", ".", "max", "(", ")", "\n", "yy", "=", "axes", ".", "get_ylim", "(", ")", "\n", "axes", ".", "bar", "(", "x_bins", ",", "bottom", "=", "yy", "[", "1", "]", ",", "height", "=", "0.1", "*", "np", ".", "abs", "(", "yy", "[", "1", "]", "-", "yy", "[", "0", "]", ")", "*", "x_hist", ",", "zorder", "=", "-", "1", ",", "clip_on", "=", "False", ",", "alpha", "=", "0.5", ",", "width", "=", "x_bins", "[", "1", "]", "-", "x_bins", "[", "0", "]", ")", "\n", "axes", ".", "set_ylim", "(", "yy", ")", "\n", "\n", "# Y marginal", "\n", "y_hist", ",", "y_bins", "=", "np", ".", "histogram", "(", "y", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", ",", "bins", "=", "bins", ")", "\n", "y_bins", "=", "np", ".", "convolve", "(", "y_bins", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "y_hist", "=", "y_hist", "/", "y_hist", ".", "max", "(", ")", "\n", "xx", "=", "axes", ".", "get_xlim", "(", ")", "\n", "axes", ".", "barh", "(", "y_bins", ",", "left", "=", "xx", "[", "1", "]", ",", "width", "=", "0.1", "*", "np", ".", "abs", "(", "xx", "[", "1", "]", "-", "xx", "[", "0", "]", ")", "*", "y_hist", ",", "zorder", "=", "-", "1", ",", "clip_on", "=", "False", ",", "alpha", "=", "0.5", ",", "height", "=", "y_bins", "[", "1", "]", "-", "y_bins", "[", "0", "]", ")", "\n", "axes", ".", "set_xlim", "(", "xx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.DefaultFormatter.__init__": [[36, 38], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "default", "=", "None", ")", ":", "\n", "        ", "self", ".", "default", "=", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.DefaultFormatter.get_value": [[39, 48], ["isinstance", "string.Formatter.get_value"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_value"], ["", "def", "get_value", "(", "self", ",", "key", ",", "args", ",", "kwds", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "key", ",", "str", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "kwds", "[", "key", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "return", "f'{{{key}}}'", "if", "self", ".", "default", "is", "None", "else", "self", ".", "default", "\n", "", "", "else", ":", "\n", "            ", "return", "Formatter", ".", "get_value", "(", "key", ",", "args", ",", "kwds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.__init__": [[571, 588], ["isinstance", "isinstance", "open", "json.load", "tuple"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["def", "__init__", "(", "self", ",", "pattern", ",", "prefix", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param pattern: a string (key to dict in config/result_patterns.json) or iterable (with filename pattern definition)\n        :param prefix: file path prefix (e.g., root directory where results are stored)\n        :param kwargs: keyword args to narrow down search results (more keywords can be supplied in query functions)\n\n        \"\"\"", "\n", "from", "collections", "import", "Iterable", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "_pattern", "=", "pattern", "\n", "if", "isinstance", "(", "pattern", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "'config/result_patterns.json'", ")", "as", "f", ":", "\n", "                ", "result_patterns", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "pattern", "=", "result_patterns", "[", "pattern", "]", "\n", "", "elif", "isinstance", "(", "pattern", ",", "Iterable", ")", ":", "\n", "            ", "self", ".", "pattern", "=", "tuple", "(", "pattern", ")", "\n", "", "self", ".", "kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set": [[589, 591], ["results_data.ResultCache.kwargs.update"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["", "def", "set", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "kwargs", ".", "update", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.unset": [[592, 598], ["isinstance"], "methods", ["None"], ["", "def", "unset", "(", "self", ",", "fields", ")", ":", "\n", "        ", "if", "isinstance", "(", "fields", ",", "str", ")", ":", "\n", "            ", "del", "self", ".", "kwargs", "[", "fields", "]", "\n", "", "else", ":", "\n", "            ", "for", "f", "in", "fields", ":", "\n", "                ", "del", "self", ".", "kwargs", "[", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.filename": [[599, 615], ["args.update", "os.path.join", "ValueError", "results_data.ResultCache._get_wildcard_pattern", "list", "len", "ValueError", "x.format", "str", "pathlib.Path().glob", "len", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache._get_wildcard_pattern", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "", "", "def", "filename", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Generate a unique filename for the current context. Raises exception if not unique. Add keyword args to narrow down. \"\"\"", "\n", "args", "=", "{", "**", "self", ".", "kwargs", "}", "\n", "args", ".", "update", "(", "kwargs", ")", "\n", "try", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "prefix", ",", "*", "[", "x", ".", "format", "(", "**", "args", ")", "for", "x", "in", "self", ".", "pattern", "]", ")", "\n", "if", "'*'", "in", "filename", ":", "\n", "                ", "raise", "ValueError", "(", "'Wildcards found - not a valid filename!'", ")", "\n", "", "return", "filename", "\n", "", "except", ":", "\n", "            ", "pattern", "=", "self", ".", "_get_wildcard_pattern", "(", "args", ")", "\n", "candidates", "=", "list", "(", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "'.'", ")", ".", "glob", "(", "pattern", ")", ")", "\n", "if", "len", "(", "candidates", ")", "==", "1", ":", "\n", "                ", "return", "candidates", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Current search pattern [{pattern}] must match 1 file but matches {len(candidates)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.load_all": [[616, 624], ["collections.OrderedDict", "results_data.ResultCache.find", "helpers.fsutil.strip_prefix", "zip", "results_data.ResultCache.load"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.find", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.strip_prefix", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "", "", "def", "load_all", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Load all results matching the current search pattern and return a dict indexed by representative filename sections \"\"\"", "\n", "results", "=", "OrderedDict", "(", ")", "\n", "filenames", "=", "self", ".", "find", "(", "**", "kwargs", ")", "\n", "labels", "=", "fsutil", ".", "strip_prefix", "(", "filenames", ")", "\n", "for", "l", ",", "f", "in", "zip", "(", "labels", ",", "filenames", ")", ":", "\n", "            ", "results", "[", "l", "]", "=", "load", "(", "f", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.load": [[625, 629], ["results_data.ResultCache.filename", "results_data.ResultCache.load"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.filename", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "def", "load", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Load results for a given context (use extra keyword args to narrow down) \"\"\"", "\n", "filename", "=", "self", ".", "filename", "(", "**", "kwargs", ")", "\n", "return", "load", "(", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.save": [[630, 636], ["results_data.ResultCache.filename", "results_data.ResultCache.save"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.filename", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.save"], ["", "def", "save", "(", "self", ",", "results", ",", "overwrite", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Save results for a given context (use extra keyword args to narrow down) \"\"\"", "\n", "filename", "=", "self", ".", "filename", "(", "**", "kwargs", ")", "\n", "if", "not", "overwrite", "and", "os", ".", "path", ".", "isfile", "(", "filename", ")", ":", "\n", "            ", "raise", "FileExistsError", "(", "f'File {filename} exists! Use overwrite=True if needed.'", ")", "\n", "", "save", "(", "results", ",", "filename", "=", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format": [[637, 647], ["isinstance", "os.path.join", "os.path.join", "open", "json.load", "x.format", "x.format"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "@", "staticmethod", "\n", "def", "format", "(", "pattern", ",", "prefix", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "pattern", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "'config/result_patterns.json'", ")", "as", "f", ":", "\n", "                ", "result_patterns", "=", "json", ".", "load", "(", "f", ")", "\n", "", "pattern", "=", "result_patterns", "[", "pattern", "]", "\n", "", "if", "prefix", "is", "not", "None", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "prefix", ",", "*", "[", "x", ".", "format", "(", "**", "kwargs", ")", "for", "x", "in", "pattern", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "os", ".", "path", ".", "join", "(", "*", "[", "x", ".", "format", "(", "**", "kwargs", ")", "for", "x", "in", "pattern", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache._get_wildcard_pattern": [[648, 652], ["results_data.DefaultFormatter", "os.path.join", "string.Formatter.format"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "", "def", "_get_wildcard_pattern", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\" Generate a wildcard pattern for the given context \"\"\"", "\n", "fmt", "=", "DefaultFormatter", "(", "'*'", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "prefix", ",", "*", "[", "fmt", ".", "format", "(", "x", ",", "**", "args", ")", "for", "x", "in", "self", ".", "pattern", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.find": [[653, 661], ["args.update", "results_data.DefaultFormatter", "os.path.join", "loguru.logger.info", "list", "str", "string.Formatter.format", "pathlib.Path().glob", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "def", "find", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Find all files matching the current context \"\"\"", "\n", "args", "=", "{", "**", "self", ".", "kwargs", "}", "\n", "args", ".", "update", "(", "kwargs", ")", "\n", "fmt", "=", "DefaultFormatter", "(", "'*'", ")", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "self", ".", "prefix", ",", "*", "[", "fmt", ".", "format", "(", "x", ",", "**", "args", ")", "for", "x", "in", "self", ".", "pattern", "]", ")", "\n", "logger", ".", "info", "(", "f'*> {pattern}'", ")", "\n", "return", "list", "(", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "'.'", ")", ".", "glob", "(", "pattern", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.__str__": [[662, 667], ["results_data.DefaultFormatter", "os.path.join", "string.Formatter.format"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.format"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmt", "=", "DefaultFormatter", "(", ")", "\n", "return", "'{} <- {}'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "prefix", ",", "*", "[", "fmt", ".", "format", "(", "x", ",", "**", "self", ".", "kwargs", ")", "for", "x", "in", "self", ".", "pattern", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.__repr__": [[669, 675], ["helpers.utils.join_args"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.join_args"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{}(\"{}\",\"{}\",{})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "_pattern", ",", "\n", "self", ".", "prefix", ",", "\n", "utils", ".", "join_args", "(", "self", ".", "kwargs", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.autodetect_cameras": [[50, 62], ["helpers.fsutil.listdir", "ValueError", "os.path.join", "os.path.exists", "os.path.split", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "", "", "def", "autodetect_cameras", "(", "dirname", ")", ":", "\n", "    ", "\"\"\" Returns a list of known cameras (based on available NIP). \"\"\"", "\n", "\n", "counter", "=", "5", "\n", "while", "counter", ">", "0", "and", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "'models'", ",", "'nip'", ")", ")", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "split", "(", "dirname", ")", "[", "0", "]", "\n", "counter", "-=", "1", "\n", "\n", "", "if", "counter", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'The {} directory does not seem to be a valid results directory'", ".", "format", "(", "dirname", ")", ")", "\n", "\n", "", "return", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "'models'", ",", "'nip'", ")", ",", "'.*'", ",", "dirs_only", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.nip_stats": [[64, 89], ["sorted", "pandas.DataFrame", "os.listdir", "sorted", "os.listdir", "df.append.append", "os.path.join", "open", "json.load", "os.path.join", "numpy.mean", "numpy.mean", "helpers.utils.get", "helpers.utils.get"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get"], ["", "def", "nip_stats", "(", "dirname", ",", "avg_last_n_runs", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dataframe with NIP training summary.\n    \"\"\"", "\n", "\n", "cameras", "=", "sorted", "(", "os", ".", "listdir", "(", "dirname", ")", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'pipeline'", ",", "'camera'", ",", "'psnr'", ",", "'ssim'", "]", ")", "\n", "\n", "for", "camera", "in", "cameras", ":", "\n", "        ", "pipelines", "=", "sorted", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "camera", ")", ")", ")", "\n", "\n", "for", "pipe", "in", "pipelines", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "camera", ",", "pipe", ",", "'progress.json'", ")", ")", "as", "f", ":", "\n", "                ", "ts", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "data", "=", "ts", "if", "'psnr'", "in", "ts", "else", "ts", "[", "'performance'", "]", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "\n", "'pipeline'", ":", "pipe", ",", "\n", "'camera'", ":", "camera", ",", "\n", "'psnr'", ":", "np", ".", "mean", "(", "utils", ".", "get", "(", "data", ",", "'psnr.validation'", ")", "[", "-", "avg_last_n_runs", ":", "]", ")", ",", "\n", "'ssim'", ":", "np", ".", "mean", "(", "utils", ".", "get", "(", "data", ",", "'ssim.validation'", ")", "[", "-", "avg_last_n_runs", ":", "]", ")", "\n", "}", ",", "ignore_index", "=", "True", ",", "sort", "=", "False", ")", "\n", "\n", "", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_metrics": [[91, 132], ["any", "pandas.DataFrame", "helpers.fsutil.listdir", "ValueError", "type", "helpers.fsutil.listdir", "os.path.join", "helpers.fsutil.listdir", "results_data.autodetect_cameras", "os.path.join", "os.path.join", "os.path.join", "sorted", "df.append.append", "str", "open", "json.load", "pathlib.Path().glob", "jf.replace().replace", "helpers.utils.get", "helpers.utils.get", "helpers.utils.get", "pathlib.Path", "jf.replace"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.autodetect_cameras", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get"], ["", "def", "manipulation_metrics", "(", "nip_models", ",", "cameras", ",", "root_dir", "=", "ROOT_DIRNAME", ")", ":", "\n", "    ", "\"\"\" \n    Returns a dataframe with aggregated metrics from manipulation classification (NIP-specific). \n    \"\"\"", "\n", "\n", "nip_models", "=", "[", "nip_models", "]", "if", "type", "(", "nip_models", ")", "is", "str", "else", "nip_models", "\n", "cameras", "=", "cameras", "or", "fsutil", ".", "listdir", "(", "root_dir", ",", "'.'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "if", "any", "(", "cam", "not", "in", "autodetect_cameras", "(", "root_dir", ")", "for", "cam", "in", "cameras", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The list of cameras does not match the auto-detected list of available models: {}'", ".", "format", "(", "cameras", ")", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'camera'", ",", "'nip'", ",", "'ln'", ",", "'source'", ",", "'psnr'", ",", "'ssim'", ",", "'accuracy'", "]", ")", "\n", "\n", "for", "camera", "in", "cameras", ":", "\n", "\n", "        ", "nip_models", "=", "nip_models", "or", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "camera", ")", ",", "'.'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "for", "nip", "in", "nip_models", ":", "\n", "\n", "            ", "find_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "camera", ",", "nip", ")", "\n", "experiment_dirs", "=", "fsutil", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "find_dir", ")", ",", "'.*'", ",", "dirs_only", "=", "True", ")", "\n", "\n", "for", "ed", "in", "experiment_dirs", ":", "\n", "\n", "                ", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "find_dir", ",", "ed", ")", "\n", "jsons_files", "=", "sorted", "(", "str", "(", "f", ")", "for", "f", "in", "Path", "(", "exp_dir", ")", ".", "glob", "(", "'**/training.json'", ")", ")", "\n", "\n", "for", "jf", "in", "jsons_files", ":", "\n", "                    ", "with", "open", "(", "jf", ")", "as", "f", ":", "\n", "                        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "df", "=", "df", ".", "append", "(", "{", "'camera'", ":", "camera", ",", "\n", "'nip'", ":", "nip", ",", "\n", "'ln'", ":", "ed", ",", "\n", "'source'", ":", "jf", ".", "replace", "(", "find_dir", ",", "''", ")", ".", "replace", "(", "'training.json'", ",", "''", ")", ",", "\n", "'psnr'", ":", "utils", ".", "get", "(", "data", ",", "'nip.performance.psnr.validation'", ")", "[", "-", "1", "]", ",", "\n", "'ssim'", ":", "utils", ".", "get", "(", "data", ",", "'nip.performance.ssim.validation'", ")", "[", "-", "1", "]", ",", "\n", "'accuracy'", ":", "utils", ".", "get", "(", "data", ",", "'forensics.performance.accuracy.validation'", ")", "[", "-", "1", "]", "\n", "}", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_progress": [[134, 195], ["pandas.DataFrame", "enumerate", "os.path.join", "labels.append", "helpers.utils.get", "helpers.utils.get", "helpers.utils.get", "df.append.append", "len", "RuntimeError", "os.path.isfile", "loguru.logger.warning", "open", "json.load", "range", "pandas.DataFrame", "len", "x.append", "len", "len", "len", "list", "results_data.manipulation_progress.match_length"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "def", "manipulation_progress", "(", "cases", ",", "root_dir", "=", "ROOT_DIRNAME", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dataframe with summarized classification training progress.\n    \"\"\"", "\n", "\n", "cases", "=", "cases", "or", "[", "(", "'Nikon D90'", ",", "'INet'", ",", "'lr-0.0000'", ",", "0", ")", "]", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'camera'", ",", "'nip'", ",", "'exp'", ",", "'rep'", ",", "'step'", ",", "'psnr'", ",", "'ssim'", ",", "'accuracy'", "]", ")", "\n", "labels", "=", "[", "]", "\n", "\n", "l_camera", ",", "l_nip_model", ",", "l_ed", ",", "l_rep", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "for", "i", ",", "(", "camera", ",", "nip_model", ",", "ed", ",", "rep", ")", "in", "enumerate", "(", "cases", ")", ":", "\n", "\n", "# If something is unspecified, use the last known value", "\n", "        ", "camera", "=", "camera", "or", "l_camera", "\n", "nip_model", "=", "nip_model", "or", "l_nip_model", "\n", "ed", "=", "ed", "or", "l_ed", "\n", "rep", "=", "rep", "if", "rep", "is", "not", "None", "else", "l_rep", "\n", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "camera", ",", "nip_model", ",", "ed", ",", "'{:03d}'", ".", "format", "(", "rep", ")", ",", "'training.json'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "filename", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "f'Could not find file {filename}'", ")", "\n", "continue", "\n", "\n", "", "labels", ".", "append", "(", "'{0} ({1}/{2}/{3})'", ".", "format", "(", "camera", ",", "nip_model", ",", "ed", ",", "rep", ")", ")", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "def", "match_length", "(", "y", ",", "x", ")", ":", "\n", "            ", "if", "len", "(", "x", ")", "==", "0", ":", "\n", "                ", "x", "=", "[", "np", ".", "nan", "]", "\n", "", "x", "=", "x", "[", ":", "len", "(", "y", ")", "]", "\n", "for", "_", "in", "range", "(", "len", "(", "y", ")", "-", "len", "(", "x", ")", ")", ":", "\n", "                ", "x", ".", "append", "(", "x", "[", "-", "1", "]", ")", "\n", "", "return", "x", "\n", "\n", "", "d_psnr", "=", "utils", ".", "get", "(", "data", ",", "'nip.performance.psnr.validation'", ")", "\n", "d_ssim", "=", "utils", ".", "get", "(", "data", ",", "'nip.performance.ssim.validation'", ")", "\n", "d_accuracy", "=", "utils", ".", "get", "(", "data", ",", "'forensics.performance.accuracy.validation'", ")", "\n", "\n", "df", "=", "df", ".", "append", "(", "pd", ".", "DataFrame", "(", "{", "\n", "'camera'", ":", "[", "camera", "]", "*", "len", "(", "d_accuracy", ")", ",", "\n", "'nip'", ":", "[", "nip_model", "]", "*", "len", "(", "d_accuracy", ")", ",", "\n", "'exp'", ":", "[", "ed", "]", "*", "len", "(", "d_accuracy", ")", ",", "\n", "'rep'", ":", "[", "rep", "]", "*", "len", "(", "d_accuracy", ")", ",", "\n", "'step'", ":", "list", "(", "range", "(", "len", "(", "d_accuracy", ")", ")", ")", ",", "\n", "'psnr'", ":", "match_length", "(", "d_accuracy", ",", "d_psnr", ")", ",", "\n", "'ssim'", ":", "match_length", "(", "d_accuracy", ",", "d_ssim", ")", ",", "\n", "'accuracy'", ":", "d_accuracy", "\n", "}", ")", ",", "ignore_index", "=", "True", ",", "sort", "=", "False", ")", "\n", "\n", "# Remember last used values for future iterations", "\n", "l_camera", ",", "l_nip_model", ",", "l_ed", ",", "l_rep", "=", "camera", ",", "nip_model", ",", "ed", ",", "rep", "\n", "\n", "", "if", "len", "(", "df", ")", "==", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Empty dataframe! Double check experimental scenario!'", ")", "\n", "\n", "", "return", "df", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.manipulation_summary": [[197, 226], ["pandas.DataFrame", "pathlib.Path().glob", "df.append.append", "pathlib.Path", "open", "json.load", "helpers.utils.get", "helpers.utils.get", "helpers.utils.get", "helpers.utils.get", "helpers.utils.get", "helpers.fsutil.split", "str", "os.path.relpath", "os.path.join", "int", "str"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "manipulation_summary", "(", "dirname", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dataframe with aggregated metrics from manipulation classification (generic). \n    \"\"\"", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "[", "'scenario'", ",", "'run'", ",", "'accuracy'", ",", "'nip_ssim'", ",", "'nip_psnr'", ",", "'dcn_ssim'", ",", "'dcn_entropy'", "]", ")", "\n", "for", "filename", "in", "Path", "(", "dirname", ")", ".", "glob", "(", "'**/training.json'", ")", ":", "\n", "        ", "with", "open", "(", "str", "(", "filename", ")", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "default", "=", "[", "np", ".", "nan", "]", "\n", "accuracy", "=", "utils", ".", "get", "(", "data", ",", "'forensics.validation.accuracy'", ")", "or", "default", "\n", "nip_ssim", "=", "utils", ".", "get", "(", "data", ",", "'nip.validation.ssim'", ")", "or", "default", "\n", "nip_psnr", "=", "utils", ".", "get", "(", "data", ",", "'nip.validation.psnr'", ")", "or", "default", "\n", "dcn_ssim", "=", "utils", ".", "get", "(", "data", ",", "'compression.validation.ssim'", ")", "or", "default", "\n", "dcn_entr", "=", "utils", ".", "get", "(", "data", ",", "'compression.validation.entropy'", ")", "or", "default", "\n", "\n", "path_components", "=", "fsutil", ".", "split", "(", "os", ".", "path", ".", "relpath", "(", "str", "(", "filename", ")", ",", "dirname", ")", ")", "[", ":", "-", "1", "]", "\n", "\n", "df", "=", "df", ".", "append", "(", "{", "\n", "'scenario'", ":", "os", ".", "path", ".", "join", "(", "*", "path_components", "[", ":", "-", "1", "]", ")", ",", "\n", "'run'", ":", "int", "(", "path_components", "[", "-", "1", "]", ")", ",", "\n", "'accuracy'", ":", "accuracy", "[", "-", "1", "]", ",", "\n", "'nip_ssim'", ":", "nip_ssim", "[", "-", "1", "]", ",", "\n", "'nip_psnr'", ":", "nip_psnr", "[", "-", "1", "]", ",", "\n", "'dcn_ssim'", ":", "dcn_ssim", "[", "-", "1", "]", ",", "\n", "'dcn_entropy'", ":", "dcn_entr", "[", "-", "1", "]", "\n", "}", ",", "ignore_index", "=", "True", ",", "sort", "=", "False", ")", "\n", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_data": [[228, 262], ["collections.OrderedDict", "sorted", "loguru.logger.info", "str", "open", "json.load", "numpy.array", "pathlib.Path().glob", "helpers.utils.get", "isinstance", "eval", "pathlib.Path", "os.path.relpath", "os.path.split"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "confusion_data", "(", "run", "=", "None", ",", "root_dir", "=", "ROOT_DIRNAME", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary of all confusion matrices found under a given directory (recursive):\n    \n    '{normalized-directory-path}' : {\n        'data': N x N confusion matrix,\n        'labels': names of the classes,\n    }\n\n    Note: assumes the directory structure has a 3-digit run number, e.g, /000/ in the path: \n    \"\"\"", "\n", "\n", "confusion", "=", "OrderedDict", "(", ")", "\n", "\n", "jsons_files", "=", "sorted", "(", "str", "(", "f", ")", "for", "f", "in", "Path", "(", "root_dir", ")", ".", "glob", "(", "'**/training.json'", ")", ")", "\n", "\n", "# Pre-filter only some run numbers", "\n", "if", "run", "is", "None", ":", "\n", "        ", "logger", ".", "info", "(", "'Using the first found repetition of the experiment'", ")", "\n", "run", "=", "0", "\n", "\n", "", "jsons_files", "=", "[", "jf", "for", "jf", "in", "jsons_files", "if", "'/{:03d}/'", ".", "format", "(", "run", ")", "in", "jf", "]", "\n", "\n", "for", "jf", "in", "jsons_files", ":", "\n", "\n", "        ", "with", "open", "(", "jf", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "confusion", "[", "'{}'", ".", "format", "(", "os", ".", "path", ".", "relpath", "(", "os", ".", "path", ".", "split", "(", "jf", ")", "[", "0", "]", ",", "root_dir", ")", ")", ".", "replace", "(", "'/{:03d}'", ".", "format", "(", "run", ")", ",", "''", ")", "]", "=", "{", "\n", "'data'", ":", "np", ".", "array", "(", "utils", ".", "get", "(", "data", ",", "'forensics.performance.confusion'", ")", ")", ",", "\n", "'labels'", ":", "data", "[", "'summary'", "]", "[", "'Classes'", "]", "if", "isinstance", "(", "data", "[", "'summary'", "]", "[", "'Classes'", "]", ",", "list", ")", "else", "eval", "(", "data", "[", "'summary'", "]", "[", "'Classes'", "]", ")", "\n", "}", "\n", "\n", "", "return", "confusion", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.confusion_to_text": [[264, 332], ["max", "isinstance", "numpy.array", "ValueError", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "range", "out.append", "out.append", "range", "out.append", "out.append", "out.append", "out.append", "len", "out.append", "out.append", "range", "out.append", "out.append", "out.append", "out.append", "range", "out.append", "range", "ValueError", "numpy.mean", "out.append", "out.append", "range", "out.append", "numpy.diag", "out.append", "numpy.mean", "out.append", "out.append", "out.append", "numpy.diag"], "function", ["None"], ["", "def", "confusion_to_text", "(", "conf", ",", "labels", ",", "title", "=", "'accuracy'", ",", "fmt", "=", "'txt'", ")", ":", "\n", "    ", "\"\"\"\n    Converts a confusion matrix and class labels into a human-readable format (txt or tex).\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "conf", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "conf", "=", "np", ".", "array", "(", "conf", ")", "\n", "\n", "", "if", "conf", ".", "ndim", "!=", "2", ":", "\n", "        ", "raise", "ValueError", "(", "'2D array expected!'", ")", "\n", "\n", "", "n", "=", "conf", ".", "shape", "[", "0", "]", "\n", "l", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "labels", "]", ")", "\n", "\n", "# Append the pre-amble", "\n", "out", "=", "[", "]", "\n", "\n", "if", "fmt", "==", "'tex'", ":", "\n", "        ", "out", ".", "append", "(", "'\\\\documentclass[preview]{standalone}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{booktabs}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{diagbox}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{graphicx}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{xcolor,colortbl}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{document}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{preview}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{{tabular}}{{l{0}}}\\n'", ".", "format", "(", "n", "*", "'r'", ")", ")", "\n", "out", ".", "append", "(", "'\\\\multicolumn{{{0}}}{{c}}{{{1} $\\\\rightarrow$ {2:.1f}\\\\%}} '", ".", "format", "(", "n", "+", "1", ",", "title", ",", "np", ".", "mean", "(", "np", ".", "diag", "(", "conf", ")", ")", ")", ")", "\n", "out", ".", "append", "(", "'\\\\tabularnewline\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\diagbox{\\\\textbf{True}}{\\\\textbf{Predicted}}'", ")", "\n", "\n", "# Fill the header with class names", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'& \\\\rotatebox{{90}}{{\\\\textbf{{{0}}}}}'", ".", "format", "(", "labels", "[", "i", "]", "[", ":", "3", "]", ")", ")", "\n", "", "out", ".", "append", "(", "' \\\\tabularnewline\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\toprule\\n'", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'\\\\textbf{{{0}}} '", ".", "format", "(", "labels", "[", "i", "]", ")", ")", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                ", "if", "conf", "[", "i", "]", "[", "j", "]", "==", "0", ":", "\n", "                    ", "out", ".", "append", "(", "'& '", ")", "\n", "", "elif", "conf", "[", "i", "]", "[", "j", "]", "<", "3", ":", "\n", "                    ", "out", ".", "append", "(", "'& *'", ")", "\n", "", "else", ":", "\n", "                    ", "out", ".", "append", "(", "'& \\\\cellcolor{{{0}!{1:.0f}}} {1:.0f}'", ".", "format", "(", "'lime'", "if", "i", "==", "j", "else", "'red'", ",", "conf", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "", "out", ".", "append", "(", "' \\\\tabularnewline\\n'", ")", "\n", "\n", "", "out", ".", "append", "(", "'\\\\bottomrule\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{tabular}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{preview}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{document}\\n'", ")", "\n", "\n", "", "elif", "fmt", "==", "'txt'", ":", "\n", "        ", "out", ".", "append", "(", "'# {} (acc={:.1f})'", ".", "format", "(", "title", ",", "np", ".", "mean", "(", "np", ".", "diag", "(", "conf", ")", ")", ")", ")", "\n", "out", ".", "append", "(", "'\\n'", ")", "\n", "out", ".", "append", "(", "' '", "*", "l", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'{:>4}'", ".", "format", "(", "labels", "[", "i", "]", "[", "0", "]", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "labels", "[", "i", "]", ",", "width", "=", "l", ")", ")", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                ", "out", ".", "append", "(", "'{:4.0f}'", ".", "format", "(", "conf", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid format! Only `tex` and `txt` are supported.'", ")", "\n", "\n", "", "return", "''", ".", "join", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.convert_table": [[334, 435], ["max", "isinstance", "numpy.array", "ValueError", "ValueError", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "range", "out.append", "out.append", "range", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "out.append", "range", "out.append", "out.append", "out.append", "range", "out.append", "range", "out.append", "out.append", "out.append", "range", "out.append", "out.append", "out.append", "range", "out.append", "range", "len", "dim_labels.split", "out.append", "out.append", "out.append", "out.append", "range", "out.append", "pandas.DataFrame", "ValueError", "out.append", "out.append", "out.append", "out.append", "np.array.round"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "convert_table", "(", "conf", ",", "labels", ",", "dim_labels", "=", "'c\\\\r'", ",", "title", "=", "None", ",", "fmt", "=", "'txt'", ",", "dec", "=", "0", ",", "color1", "=", "'cyan'", ",", "color0", "=", "'white'", ",", "labels_rows", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Converts a 2D array into a human-readable format (txt, tex, csv or dataframe [df]).\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "conf", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "conf", "=", "np", ".", "array", "(", "conf", ")", "\n", "\n", "", "if", "conf", ".", "ndim", "!=", "2", ":", "\n", "        ", "raise", "ValueError", "(", "'2D array expected!'", ")", "\n", "\n", "", "if", "'\\\\'", "not", "in", "dim_labels", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid label for array dimensions - need: a \\\\ b'", ")", "\n", "\n", "", "n", ",", "m", "=", "conf", ".", "shape", "\n", "l", "=", "max", "(", "[", "len", "(", "x", ")", "+", "2", "+", "dec", "for", "x", "in", "labels", "+", "[", "dim_labels", "]", "]", ")", "\n", "\n", "# If not provided, use the same labels for rows as for columns", "\n", "labels_rows", "=", "labels_rows", "or", "labels", "\n", "\n", "# Append the pre-amble", "\n", "out", "=", "[", "]", "\n", "\n", "if", "fmt", "==", "'tex'", ":", "\n", "        ", "out", ".", "append", "(", "'\\\\documentclass[preview]{standalone}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{booktabs}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{diagbox}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{graphicx}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\usepackage{xcolor,colortbl}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{document}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{preview}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\begin{{tabular}}{{l{0}}}\\n'", ".", "format", "(", "m", "*", "'r'", ")", ")", "\n", "if", "title", "is", "not", "None", ":", "\n", "            ", "out", ".", "append", "(", "'\\\\multicolumn{{{0}}}{{c}}{{{1}}} '", ".", "format", "(", "m", "+", "1", ",", "title", ")", ")", "\n", "out", ".", "append", "(", "'\\\\tabularnewline\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\toprule\\n'", ")", "\n", "# out.append('\\\\midrule\\n')/", "\n", "", "else", ":", "\n", "            ", "out", ".", "append", "(", "'\\\\toprule\\n'", ")", "\n", "", "out", ".", "append", "(", "'\\\\diagbox{{\\\\textbf{{{0}}}}}{{\\\\textbf{{{1}}}}}'", ".", "format", "(", "*", "dim_labels", ".", "split", "(", "'\\\\'", ")", ")", ")", "\n", "\n", "# Fill the header with class names", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "            ", "out", ".", "append", "(", "'& \\\\rotatebox{{90}}{{\\\\textbf{{{0}}}}}'", ".", "format", "(", "labels", "[", "i", "]", ")", ")", "\n", "", "out", ".", "append", "(", "' \\\\tabularnewline\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\toprule\\n'", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'\\\\textbf{{{0}}}'", ".", "format", "(", "labels_rows", "[", "i", "]", ")", ")", "\n", "for", "j", "in", "range", "(", "m", ")", ":", "\n", "                ", "if", "conf", "[", "i", "]", "[", "j", "]", "==", "0", ":", "\n", "                    ", "out", ".", "append", "(", "' & '", ")", "\n", "", "elif", "conf", "[", "i", "]", "[", "j", "]", "<", "3", ":", "\n", "                    ", "out", ".", "append", "(", "' & *'", ")", "\n", "", "else", ":", "\n", "                    ", "if", "color1", "is", "not", "None", "and", "color0", "is", "not", "None", ":", "\n", "                        ", "out", ".", "append", "(", "' & \\\\cellcolor{{{0}!{1:.0f}!{2}}} {1:.{dec}f}'", ".", "format", "(", "color1", ",", "conf", "[", "i", "]", "[", "j", "]", ",", "color0", ",", "dec", "=", "dec", ")", ")", "\n", "", "else", ":", "\n", "                        ", "out", ".", "append", "(", "' & {0:.{dec}f}'", ".", "format", "(", "conf", "[", "i", "]", "[", "j", "]", ",", "dec", "=", "dec", ")", ")", "\n", "", "", "", "out", ".", "append", "(", "' \\\\tabularnewline\\n'", ")", "\n", "\n", "", "out", ".", "append", "(", "'\\\\bottomrule\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{tabular}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{preview}\\n'", ")", "\n", "out", ".", "append", "(", "'\\\\end{document}\\n'", ")", "\n", "\n", "", "elif", "fmt", "==", "'txt'", ":", "\n", "        ", "out", ".", "append", "(", "'\\n'", ")", "\n", "if", "title", "is", "not", "None", ":", "\n", "            ", "out", ".", "append", "(", "'#{}\\n'", ".", "format", "(", "title", ")", ")", "\n", "", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "dim_labels", ",", "width", "=", "l", ")", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "            ", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "labels", "[", "i", "]", ",", "width", "=", "l", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "labels_rows", "[", "i", "]", ",", "width", "=", "l", ")", ")", "\n", "for", "j", "in", "range", "(", "m", ")", ":", "\n", "                ", "out", ".", "append", "(", "'{:{width}.{dec}f}'", ".", "format", "(", "conf", "[", "i", "]", "[", "j", "]", ",", "width", "=", "l", ",", "dec", "=", "dec", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "\n", "", "", "elif", "fmt", "==", "'csv'", ":", "\n", "        ", "l", "=", "0", "\n", "out", ".", "append", "(", "'\\n'", ")", "\n", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "dim_labels", ",", "width", "=", "l", ")", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "            ", "out", ".", "append", "(", "',{:>{width}}'", ".", "format", "(", "labels", "[", "i", "]", ",", "width", "=", "l", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "out", ".", "append", "(", "'{:>{width}}'", ".", "format", "(", "labels_rows", "[", "i", "]", ",", "width", "=", "l", ")", ")", "\n", "for", "j", "in", "range", "(", "m", ")", ":", "\n", "                ", "out", ".", "append", "(", "',{:{width}.{dec}f}'", ".", "format", "(", "conf", "[", "i", "]", "[", "j", "]", ",", "width", "=", "l", ",", "dec", "=", "dec", ")", ")", "\n", "", "out", ".", "append", "(", "'\\n'", ")", "\n", "\n", "", "", "elif", "fmt", "==", "'df'", ":", "\n", "        ", "import", "pandas", "as", "pd", "\n", "df", "=", "pd", ".", "DataFrame", "(", "data", "=", "conf", ".", "round", "(", "dec", ")", ",", "columns", "=", "labels", ",", "index", "=", "labels_rows", "[", "0", ":", "n", "]", ")", "\n", "return", "df", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown format: {}'", ".", "format", "(", "fmt", ")", ")", "\n", "\n", "", "return", "''", ".", "join", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.render_tex": [[437, 501], ["build_pdf", "filename.endswith", "filename.endswith", "open", "f.write", "convert_from_bytes", "imageio.imwrite", "numpy.array", "numpy.random.choice", "numpy.array", "Figure", "Figure.gca().imshow", "Figure.gca().set_xticks", "Figure.gca().set_yticks", "Figure.gca().axis", "ValueError", "list", "convert_from_bytes", "convert_from_bytes", "Figure.gca", "Figure.gca", "Figure.gca", "Figure.gca"], "function", ["None"], ["", "def", "render_tex", "(", "latex", ",", "format", "=", "'fig'", ",", "filename", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Renders a LaTeX snippet for display in a Jupyter notebook. \n\n    Output format:\n    - file  - saves the rendered document as PDF / PNG (depending on the extension);\n              if filename not provided, a random one will be generated.\n    - bytes - returns bytes of the rendered PDF\n    - array - returns a bitmap of a rendered PDF as numpy array\n    - fig   - returns a matplotlib figure with displayed bitmap\n    \"\"\"", "\n", "from", "latex", "import", "build_pdf", "\n", "\n", "if", "'documentclass'", "not", "in", "latex", ":", "\n", "        ", "latex", "=", "r\"\"\"\n        \\documentclass[preview]{standalone}\n        \\usepackage{booktabs}\n        \\usepackage{diagbox}\n        \\usepackage{graphicx}\n        \\usepackage{xcolor,colortbl}\n        \\begin{document}\n        \\begin{preview}\n        []\n        \\end{preview}\n        \\end{document}\n        \"\"\"", ".", "replace", "(", "'[]'", ",", "latex", ")", "\n", "\n", "", "pdf", "=", "build_pdf", "(", "latex", ")", "\n", "\n", "if", "format", "==", "'file'", ":", "\n", "        ", "filename", "=", "filename", "or", "'/tmp/{}.pdf'", ".", "format", "(", "''", ".", "join", "(", "np", ".", "random", ".", "choice", "(", "list", "(", "'abcdef'", ")", ",", "10", ",", "replace", "=", "True", ")", ")", ")", "\n", "\n", "if", "filename", ".", "endswith", "(", "'.pdf'", ")", ":", "\n", "            ", "with", "open", "(", "filename", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "pdf", ".", "data", ")", "\n", "\n", "", "", "elif", "filename", ".", "endswith", "(", "'.png'", ")", ":", "\n", "            ", "from", "pdf2image", "import", "convert_from_bytes", "\n", "image", "=", "convert_from_bytes", "(", "pdf", ".", "data", ")", "\n", "imageio", ".", "imwrite", "(", "filename", ",", "image", ")", "\n", "\n", "", "return", "filename", "\n", "\n", "", "elif", "format", "==", "'bytes'", ":", "\n", "        ", "return", "pdf", "\n", "\n", "", "elif", "format", "==", "'array'", ":", "\n", "        ", "from", "pdf2image", "import", "convert_from_bytes", "\n", "return", "np", ".", "array", "(", "convert_from_bytes", "(", "pdf", ".", "data", ")", "[", "0", "]", ")", "\n", "\n", "", "elif", "format", "==", "'fig'", ":", "\n", "        ", "from", "pdf2image", "import", "convert_from_bytes", "\n", "from", "matplotlib", ".", "figure", "import", "Figure", "\n", "dpi", ",", "scale", "=", "300", ",", "0.75", "\n", "image", "=", "np", ".", "array", "(", "convert_from_bytes", "(", "pdf", ".", "data", ",", "dpi", "=", "dpi", ")", "[", "0", "]", ")", "\n", "fig", "=", "Figure", "(", "figsize", "=", "(", "scale", "*", "image", ".", "shape", "[", "1", "]", "/", "dpi", ",", "scale", "*", "image", ".", "shape", "[", "0", "]", "/", "dpi", ")", ",", "dpi", "=", "dpi", ")", "\n", "fig", ".", "gca", "(", ")", ".", "imshow", "(", "image", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_xticks", "(", "[", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "set_yticks", "(", "[", "]", ")", "\n", "fig", ".", "gca", "(", ")", ".", "axis", "(", "'off'", ")", "\n", "return", "fig", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported format: {}'", ".", "format", "(", "format", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.save": [[503, 524], ["os.makedirs", "[].lower", "os.path.join", "numpy.savez", "os.path.split", "ValueError", "os.path.splitext", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "", "def", "save", "(", "results", ",", "*", ",", "filename", "=", "None", ",", "prefix", "=", "None", ")", ":", "\n", "    ", "\"\"\" Helper function to save dict-like results in either JSON or NPZ (zipped numpy objects) \"\"\"", "\n", "\n", "if", "filename", "is", "None", ":", "\n", "        ", "filename", "=", "results", "[", "'filename'", "]", "\n", "\n", "", "if", "prefix", "is", "not", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "prefix", ",", "filename", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "os", ".", "path", ".", "split", "(", "filename", ")", "[", "0", "]", ",", "exist_ok", "=", "True", ")", "\n", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "\n", "\n", "if", "extension", "==", "'.npz'", ":", "\n", "        ", "np", ".", "savez", "(", "filename", ",", "**", "results", ")", "\n", "\n", "", "elif", "extension", "==", "'.json'", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unsupported format: {extension}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load": [[526, 542], ["[].lower", "os.path.join", "numpy.load", "ValueError", "os.path.splitext", "data[].item", "np.load.keys", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "", "def", "load", "(", "filename", ",", "prefix", "=", "None", ")", ":", "\n", "    ", "\"\"\" Helper function to load results from JSON or NPZ (zipped numpy objects) \"\"\"", "\n", "\n", "if", "prefix", "is", "not", "None", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "prefix", ",", "filename", ")", "\n", "\n", "", "extension", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "\n", "\n", "if", "extension", "==", "'.npz'", ":", "\n", "        ", "data", "=", "np", ".", "load", "(", "filename", ",", "allow_pickle", "=", "True", ")", "\n", "return", "{", "k", ":", "data", "[", "k", "]", "if", "data", "[", "k", "]", ".", "ndim", ">", "0", "else", "data", "[", "k", "]", ".", "item", "(", ")", "for", "k", "in", "data", ".", "keys", "(", ")", "}", "\n", "", "elif", "extension", "==", "'.json'", ":", "\n", "        ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'Unsupported format: {extension}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_psutil": [[5, 14], ["psutil.Process", "os.getpid", "float", "psutil.Process.memory_info"], "function", ["None"], ["def", "memory_usage_psutil", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns memory usage [in MB] of the current interpreter (using the 'psutil' package)\n    \"\"\"", "\n", "import", "psutil", "\n", "process", "=", "psutil", ".", "Process", "(", "os", ".", "getpid", "(", ")", ")", "\n", "mem", "=", "process", ".", "memory_info", "(", ")", "[", "0", "]", "/", "float", "(", "2", "**", "20", ")", "\n", "\n", "return", "mem", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_resource": [[16, 29], ["resource.getrusage"], "function", ["None"], ["", "def", "memory_usage_resource", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns memory usage [in MB] of the current interpreter (using the 'resource' package)\n    \"\"\"", "\n", "import", "resource", "\n", "rusage_denom", "=", "1024.", "\n", "if", "sys", ".", "platform", "==", "'darwin'", ":", "\n", "# ... it seems that in OSX the output is different units ...", "\n", "        ", "rusage_denom", "=", "rusage_denom", "*", "rusage_denom", "\n", "\n", "", "mem", "=", "resource", ".", "getrusage", "(", "resource", ".", "RUSAGE_SELF", ")", ".", "ru_maxrss", "/", "rusage_denom", "\n", "\n", "return", "mem", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_ps": [[31, 42], ["[].split", "out[].split().index", "float", "out[].split", "subprocess.Popen().communicate", "out[].split", "subprocess.Popen", "str", "os.getpid"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "memory_usage_ps", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns memory usage [in MB] of the current interpreter (runs 'ps' in the background)\n    \"\"\"", "\n", "import", "subprocess", "\n", "out", "=", "subprocess", ".", "Popen", "(", "[", "'ps'", ",", "'v'", ",", "'-p'", ",", "str", "(", "os", ".", "getpid", "(", ")", ")", "]", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ")", ".", "communicate", "(", ")", "[", "0", "]", ".", "split", "(", "b'\\n'", ")", "\n", "vsz_index", "=", "out", "[", "0", "]", ".", "split", "(", ")", ".", "index", "(", "b'RSS'", ")", "\n", "mem", "=", "float", "(", "out", "[", "1", "]", ".", "split", "(", ")", "[", "vsz_index", "]", ")", "/", "1024", "\n", "\n", "return", "mem", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.memory_usage_proc": [[44, 53], ["open", "f.readlines", "line.startswith", "os.getpid", "[].split", "float", "line.split"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "memory_usage_proc", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns memory usage [in MB] of the current interpreter (reads VmRSS from /proc/<pid>/status)\n    \"\"\"", "\n", "with", "open", "(", "'/proc/{}/status'", ".", "format", "(", "os", ".", "getpid", "(", ")", ")", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "'VmRSS'", ")", ":", "\n", "                ", "memory", "=", "line", ".", "split", "(", "':'", ")", "[", "-", "1", "]", ".", "split", "(", ")", "[", "0", "]", "\n", "return", "float", "(", "memory", ")", "/", "1024", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.get_size": [[55, 77], ["sys.getsizeof", "id", "set.add", "isinstance", "set", "sum", "sum", "hasattr", "debugging.get_size", "debugging.get_size", "debugging.get_size", "hasattr", "sum", "obj.values", "obj.keys", "isinstance", "debugging.get_size"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.get_size", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.get_size", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.get_size", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.get_size"], ["", "", "", "", "def", "get_size", "(", "obj", ",", "seen", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Recursively finds size of objects\n    \"\"\"", "\n", "size", "=", "sys", ".", "getsizeof", "(", "obj", ")", "\n", "if", "seen", "is", "None", ":", "\n", "        ", "seen", "=", "set", "(", ")", "\n", "", "obj_id", "=", "id", "(", "obj", ")", "\n", "if", "obj_id", "in", "seen", ":", "\n", "        ", "return", "0", "\n", "\n", "# Important mark as seen *before* entering recursion to gracefully handle", "\n", "# self-referential objects", "\n", "", "seen", ".", "add", "(", "obj_id", ")", "\n", "if", "isinstance", "(", "obj", ",", "dict", ")", ":", "\n", "        ", "size", "+=", "sum", "(", "[", "get_size", "(", "v", ",", "seen", ")", "for", "v", "in", "obj", ".", "values", "(", ")", "]", ")", "\n", "size", "+=", "sum", "(", "[", "get_size", "(", "k", ",", "seen", ")", "for", "k", "in", "obj", ".", "keys", "(", ")", "]", ")", "\n", "", "elif", "hasattr", "(", "obj", ",", "'__dict__'", ")", ":", "\n", "        ", "size", "+=", "get_size", "(", "obj", ".", "__dict__", ",", "seen", ")", "\n", "", "elif", "hasattr", "(", "obj", ",", "'__iter__'", ")", "and", "not", "isinstance", "(", "obj", ",", "(", "str", ",", "bytes", ",", "bytearray", ")", ")", ":", "\n", "        ", "size", "+=", "sum", "(", "[", "get_size", "(", "i", ",", "seen", ")", "for", "i", "in", "obj", "]", ")", "\n", "", "return", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.debugging.mem": [[79, 92], ["ValueError"], "function", ["None"], ["", "def", "mem", "(", "x", ",", "unit", "=", "'G'", ")", ":", "\n", "    ", "\"\"\"\n    Returns memory needed by a numpy array.\n    \"\"\"", "\n", "if", "unit", "==", "'G'", ":", "\n", "        ", "p", "=", "3", "\n", "", "elif", "unit", "==", "'M'", ":", "\n", "        ", "p", "=", "2", "\n", "", "elif", "unit", "==", "'K'", ":", "\n", "        ", "p", "=", "1", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Supported units: G, M, K!'", ")", "\n", "", "return", "x", ".", "size", "*", "x", ".", "dtype", ".", "itemsize", "/", "(", "1024", "**", "p", ")", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim": [[9, 27], ["a.squeeze.squeeze", "b.squeeze.squeeze", "skimage.metrics.structural_similarity", "numpy.zeros", "range", "ValueError", "metrics.ssim"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim"], ["def", "ssim", "(", "a", ",", "b", ")", ":", "\n", "    ", "if", "a", ".", "ndim", "==", "4", "and", "a", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "a", "=", "a", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "b", ".", "ndim", "==", "4", "and", "b", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "b", "=", "b", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "a", ".", "ndim", "==", "3", "and", "b", ".", "ndim", "==", "3", ":", "\n", "        ", "return", "metrics", ".", "structural_similarity", "(", "a", ",", "b", ",", "multichannel", "=", "True", ",", "data_range", "=", "1", ")", "\n", "\n", "", "elif", "a", ".", "ndim", "==", "4", "and", "b", ".", "ndim", "==", "4", ":", "\n", "        ", "out", "=", "np", ".", "zeros", "(", "(", "a", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "a", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "ssim", "(", "a", "[", "i", "]", ",", "b", "[", "i", "]", ")", "\n", "", "return", "out", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Incompatible tensor shapes! {} and {}'", ".", "format", "(", "a", ".", "shape", ",", "b", ".", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr": [[29, 47], ["a.squeeze.squeeze", "b.squeeze.squeeze", "skimage.metrics.peak_signal_noise_ratio", "numpy.zeros", "range", "ValueError", "metrics.psnr"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr"], ["", "", "def", "psnr", "(", "a", ",", "b", ")", ":", "\n", "    ", "if", "a", ".", "ndim", "==", "4", "and", "a", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "a", "=", "a", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "b", ".", "ndim", "==", "4", "and", "b", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "b", "=", "b", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "a", ".", "ndim", "==", "3", "and", "b", ".", "ndim", "==", "3", ":", "\n", "        ", "return", "metrics", ".", "peak_signal_noise_ratio", "(", "a", ",", "b", ",", "data_range", "=", "1", ")", "\n", "\n", "", "elif", "a", ".", "ndim", "==", "4", "and", "b", ".", "ndim", "==", "4", ":", "\n", "        ", "out", "=", "np", ".", "zeros", "(", "(", "a", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "a", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "psnr", "(", "a", "[", "i", "]", ",", "b", "[", "i", "]", ")", "\n", "", "return", "out", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Incompatible tensor shapes! {} and {}'", ".", "format", "(", "a", ".", "shape", ",", "b", ".", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.mse": [[49, 69], ["skimage.metrics.mean_squared_error", "a.squeeze.squeeze", "b.squeeze.squeeze", "skimage.metrics.mean_squared_error", "a.squeeze.squeeze", "b.squeeze.squeeze", "numpy.zeros", "range", "ValueError", "metrics.mse"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mse"], ["", "", "def", "mse", "(", "a", ",", "b", ")", ":", "\n", "    ", "if", "a", ".", "ndim", "==", "4", "and", "a", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "a", "=", "a", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "b", ".", "ndim", "==", "4", "and", "b", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "b", "=", "b", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "a", ".", "ndim", "==", "3", "and", "b", ".", "ndim", "==", "3", ":", "\n", "        ", "return", "metrics", ".", "mean_squared_error", "(", "a", ",", "b", ")", "\n", "\n", "", "elif", "a", ".", "ndim", "==", "4", "and", "b", ".", "ndim", "==", "4", ":", "\n", "        ", "out", "=", "np", ".", "zeros", "(", "(", "a", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "a", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "mse", "(", "a", "[", "i", "]", ",", "b", "[", "i", "]", ")", "\n", "", "return", "out", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Incompatible tensor shapes! {} and {}'", ".", "format", "(", "a", ".", "shape", ",", "b", ".", "shape", ")", ")", "\n", "\n", "", "return", "metrics", ".", "mean_squared_error", "(", "a", ".", "squeeze", "(", ")", ",", "b", ".", "squeeze", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.mae": [[71, 89], ["a.squeeze.squeeze", "b.squeeze.squeeze", "numpy.mean", "numpy.abs", "numpy.zeros", "range", "ValueError", "metrics.mae"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mae"], ["", "def", "mae", "(", "a", ",", "b", ")", ":", "\n", "    ", "if", "a", ".", "ndim", "==", "4", "and", "a", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "a", "=", "a", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "b", ".", "ndim", "==", "4", "and", "b", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "b", "=", "b", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "a", ".", "ndim", "==", "3", "and", "b", ".", "ndim", "==", "3", ":", "\n", "        ", "return", "np", ".", "mean", "(", "np", ".", "abs", "(", "a", "-", "b", ")", ")", "\n", "\n", "", "elif", "a", ".", "ndim", "==", "4", "and", "b", ".", "ndim", "==", "4", ":", "\n", "        ", "out", "=", "np", ".", "zeros", "(", "(", "a", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "for", "i", "in", "range", "(", "a", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "mae", "(", "a", "[", "i", "]", ",", "b", "[", "i", "]", ")", "\n", "", "return", "out", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Incompatible tensor shapes! {} and {}'", ".", "format", "(", "a", ".", "shape", ",", "b", ".", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.batch": [[91, 95], ["numpy.mean", "len", "len", "metric", "range", "len"], "function", ["None"], ["", "", "def", "batch", "(", "a", ",", "b", ",", "metric", "=", "ssim", ")", ":", "\n", "    ", "assert", "a", ".", "ndim", "==", "4", "and", "b", ".", "ndim", "==", "4", ",", "'Input arrays need to be 4-dim: batch, height, width, channels'", "\n", "assert", "len", "(", "a", ")", "==", "len", "(", "b", ")", ",", "'Image batches must be of the same length'", "\n", "return", "np", ".", "mean", "(", "[", "metric", "(", "a", "[", "r", "]", ",", "b", "[", "r", "]", ")", "for", "r", "in", "range", "(", "len", "(", "a", ")", ")", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.upsampling_kernel": [[9, 44], ["cfa_pattern.upper.upper", "cfa_pattern.upper.upper", "numpy.array", "cfa_pattern.upper.upper", "numpy.array", "cfa_pattern.upper.upper", "numpy.array", "ValueError"], "function", ["None"], ["def", "upsampling_kernel", "(", "cfa_pattern", "=", "'gbrg'", ")", ":", "\n", "    ", "\"\"\"\n    Ideal initialization of up-sampling kernels for matching the 12-feature-layer format needed by depth-to-space.\n    :param cfa_pattern: CFA pattern, e.g., 'GBRG'\n    \"\"\"", "\n", "cfa_pattern", "=", "cfa_pattern", ".", "upper", "(", ")", "\n", "\n", "if", "cfa_pattern", ".", "upper", "(", ")", "==", "'GBRG'", ":", "\n", "#                R  G  B  R  G  B  R  G  B  R  G  B", "\n", "#                1  1  1  2  2  2  3  3  3  4  4  4", "\n", "        ", "upk", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "]", ")", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'RGGB'", ":", "\n", "#                R  G  B  R  G  B  R  G  B  R  G  B", "\n", "#                1  1  1  2  2  2  3  3  3  4  4  4", "\n", "        ", "upk", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'BGGR'", ":", "\n", "#                R  G  B  R  G  B  R  G  B  R  G  B", "\n", "#                1  1  1  2  2  2  3  3  3  4  4  4", "\n", "        ", "upk", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported CFA pattern: {}'", ".", "format", "(", "cfa_pattern", ")", ")", "\n", "\n", "", "return", "upk", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.gamma_kernels": [[46, 68], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range"], "function", ["None"], ["", "def", "gamma_kernels", "(", ")", ":", "\n", "    ", "\"\"\"\n    Pre-trained kernels of a toy neural network for approximation of gamma correction.\n    \"\"\"", "\n", "gamma_dense1_kernel", "=", "np", ".", "array", "(", "[", "2.9542332", ",", "17.780445", ",", "0.6280197", ",", "0.40384966", "]", ")", "\n", "gamma_dense1_bias", "=", "np", ".", "array", "(", "[", "0.4047071", ",", "1.1489044", ",", "-", "0.17624384", ",", "0.47826886", "]", ")", "\n", "\n", "gamma_dense2_kernel", "=", "np", ".", "array", "(", "[", "0.44949612", ",", "0.78081024", ",", "0.97692937", ",", "-", "0.24265033", "]", ")", "\n", "gamma_dense2_bias", "=", "np", ".", "array", "(", "[", "-", "0.4702738", "]", ")", "\n", "\n", "gamma_d1k", "=", "np", ".", "zeros", "(", "(", "3", ",", "12", ")", ")", "\n", "gamma_d1b", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ")", "\n", "gamma_d2k", "=", "np", ".", "zeros", "(", "(", "12", ",", "3", ")", ")", "\n", "gamma_d2b", "=", "np", ".", "zeros", "(", "(", "3", ",", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "3", ")", ":", "\n", "        ", "gamma_d1k", "[", "r", ",", "r", "*", "4", ":", "r", "*", "4", "+", "4", "]", "=", "gamma_dense1_kernel", "\n", "gamma_d1b", "[", "r", "*", "4", ":", "r", "*", "4", "+", "4", "]", "=", "gamma_dense1_bias", "\n", "gamma_d2k", "[", "r", "*", "4", ":", "r", "*", "4", "+", "4", ",", "r", "]", "=", "gamma_dense2_kernel", "\n", "gamma_d2b", "[", "r", "]", "=", "gamma_dense2_bias", "\n", "\n", "", "return", "gamma_d1k", ",", "gamma_d1b", ",", "gamma_d2k", ",", "gamma_d2b", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.bilin_kernel": [[70, 92], ["numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.stack", "numpy.pad"], "function", ["None"], ["", "def", "bilin_kernel", "(", "kernel", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Bilinear demosaicing kernel.\n    \"\"\"", "\n", "g_kern", "=", "np", ".", "array", "(", "[", "[", "0", ",", "1", "/", "4.", ",", "0", "]", ",", "[", "1", "/", "4.", ",", "1", ",", "1", "/", "4.", "]", ",", "[", "0", ",", "1", "/", "4.", ",", "0", "]", "]", ")", "\n", "rb_kern", "=", "np", ".", "array", "(", "[", "[", "1", "/", "4.", ",", "1", "/", "2.", ",", "1", "/", "4.", "]", ",", "[", "1", "/", "2.", ",", "1", ",", "1", "/", "2.", "]", ",", "[", "1", "/", "4.", ",", "1", "/", "2.", ",", "1", "/", "4.", "]", "]", ")", "\n", "\n", "G_kern", "=", "np", ".", "zeros", "(", "(", "3", ",", "3", ",", "3", ")", ",", "np", ".", "float32", ")", "\n", "G_kern", "[", ":", ",", ":", ",", "1", "]", "=", "g_kern", "\n", "\n", "R_kern", "=", "np", ".", "zeros", "(", "(", "3", ",", "3", ",", "3", ")", ",", "np", ".", "float32", ")", "\n", "R_kern", "[", ":", ",", ":", ",", "0", "]", "=", "rb_kern", "\n", "\n", "B_kern", "=", "np", ".", "zeros", "(", "(", "3", ",", "3", ",", "3", ")", ",", "np", ".", "float32", ")", "\n", "B_kern", "[", ":", ",", ":", ",", "2", "]", "=", "rb_kern", "\n", "\n", "dmf", "=", "np", ".", "stack", "(", "(", "R_kern", ",", "G_kern", ",", "B_kern", ")", ",", "axis", "=", "3", ")", "\n", "if", "kernel", ">", "3", ":", "\n", "        ", "pad", "=", "(", "kernel", "-", "3", ")", "//", "2", "\n", "dmf", "=", "np", ".", "pad", "(", "dmf", ",", "(", "(", "pad", ",", "pad", ")", ",", "(", "pad", ",", "pad", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ")", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n", "", "return", "dmf", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.gkern": [[94, 99], ["scipy.signal.gaussian", "numpy.outer", "np.outer.sum"], "function", ["None"], ["", "def", "gkern", "(", "kernlen", "=", "5", ",", "std", "=", "0.83", ")", ":", "\n", "    ", "\"\"\"Returns a 2D Gaussian kernel array.\"\"\"", "\n", "gkern1d", "=", "signal", ".", "gaussian", "(", "kernlen", ",", "std", "=", "std", ")", "\n", "gkern2d", "=", "np", ".", "outer", "(", "gkern1d", ",", "gkern1d", ")", "\n", "return", "gkern2d", "/", "gkern2d", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.repeat_2dfilter": [[101, 115], ["numpy.zeros", "range", "numpy.pad"], "function", ["None"], ["", "def", "repeat_2dfilter", "(", "f", ",", "channels", "=", "3", ",", "pad", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Repeat a 2D filter along channel dimensions (both input/output). Useful for kernel initialization in conv. layers.\n    :param f: 2d filter\n    :param channels: number of input/output channels\n    :param pad: optional padding (along the spatial dimension)\n    :return: valid conv 2d kernel (kernel, kernel, channels, channels)\n    \"\"\"", "\n", "rf", "=", "np", ".", "zeros", "(", "(", "f", ".", "shape", "[", "0", "]", "+", "2", "*", "pad", ",", "f", ".", "shape", "[", "1", "]", "+", "2", "*", "pad", ",", "channels", ",", "channels", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "channels", ")", ":", "\n", "        ", "rf", "[", ":", ",", ":", ",", "r", ",", "r", "]", "=", "np", ".", "pad", "(", "f", ",", "[", "pad", ",", "pad", "]", ",", "'constant'", ")", "\n", "\n", "", "return", "rf", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.center_mask_2dfilter": [[117, 124], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "center_mask_2dfilter", "(", "f_size", ",", "channels", ")", ":", "\n", "    ", "indicator", "=", "np", ".", "zeros", "(", "(", "f_size", ",", "f_size", ",", "channels", ",", "channels", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "channels", ")", ":", "\n", "        ", "indicator", "[", "f_size", "//", "2", ",", "f_size", "//", "2", ",", "r", ",", "r", "]", "=", "1", "\n", "\n", "", "return", "indicator", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.summaries.log_image": [[15, 23], ["io.BytesIO", "imageio.imsave", "tensorflow.Summary.Image", "io.BytesIO.getvalue"], "function", ["None"], ["def", "log_image", "(", "thumbs", ")", ":", "\n", "\n", "    ", "if", "thumbs", ".", "dtype", "==", "np", ".", "float", ":", "\n", "        ", "thumbs", "=", "(", "255", "*", "thumbs", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "", "s", "=", "io", ".", "BytesIO", "(", ")", "\n", "imageio", ".", "imsave", "(", "s", ",", "thumbs", ",", "format", "=", "'png'", ")", "\n", "return", "tf", ".", "Summary", ".", "Image", "(", "encoded_image_string", "=", "s", ".", "getvalue", "(", ")", ",", "height", "=", "thumbs", ".", "shape", "[", "0", "]", ",", "width", "=", "thumbs", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.summaries.log_plot": [[25, 30], ["io.BytesIO", "fig.savefig", "matplotlib.close", "summaries.log_image", "imageio.imread", "io.BytesIO.getvalue"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.summaries.log_image"], ["", "def", "log_plot", "(", "fig", ")", ":", "\n", "    ", "s", "=", "io", ".", "BytesIO", "(", ")", "\n", "fig", ".", "savefig", "(", "s", ",", "format", "=", "'png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "return", "log_image", "(", "imageio", ".", "imread", "(", "s", ".", "getvalue", "(", ")", ",", "pilmode", "=", "'RGB'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.summaries.log_histogram": [[32, 56], ["numpy.histogram", "tensorflow.HistogramProto", "float", "float", "int", "float", "float", "numpy.min", "numpy.max", "numpy.prod", "numpy.sum", "numpy.sum", "tf.HistogramProto.bucket_limit.append", "tf.HistogramProto.bucket.append"], "function", ["None"], ["", "def", "log_histogram", "(", "values", ",", "bins", "=", "50", ")", ":", "\n", "# Create histogram using numpy        ", "\n", "    ", "counts", ",", "bin_edges", "=", "np", ".", "histogram", "(", "values", ",", "bins", "=", "bins", ")", "\n", "\n", "# Fill fields of histogram proto", "\n", "hist", "=", "tf", ".", "HistogramProto", "(", ")", "\n", "hist", ".", "min", "=", "float", "(", "np", ".", "min", "(", "values", ")", ")", "\n", "hist", ".", "max", "=", "float", "(", "np", ".", "max", "(", "values", ")", ")", "\n", "hist", ".", "num", "=", "int", "(", "np", ".", "prod", "(", "values", ".", "shape", ")", ")", "\n", "hist", ".", "sum", "=", "float", "(", "np", ".", "sum", "(", "values", ")", ")", "\n", "hist", ".", "sum_squares", "=", "float", "(", "np", ".", "sum", "(", "values", "**", "2", ")", ")", "\n", "\n", "# Requires equal number as bins, where the first goes from -DBL_MAX to bin_edges[1]", "\n", "# See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/summary.proto#L30", "\n", "# Thus, we drop the start of the first bin", "\n", "bin_edges", "=", "bin_edges", "[", "1", ":", "]", "\n", "\n", "# Add bin edges and counts", "\n", "for", "edge", "in", "bin_edges", ":", "\n", "        ", "hist", ".", "bucket_limit", ".", "append", "(", "edge", ")", "\n", "", "for", "c", "in", "counts", ":", "\n", "        ", "hist", ".", "bucket", ".", "append", "(", "c", ")", "\n", "\n", "", "return", "hist", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.__init__": [[15, 82], ["helpers.loading.discover_images", "any", "ValueError", "os.path.isdir", "os.path.isdir", "helpers.loading.load_images", "helpers.loading.load_patches", "ValueError", "os.path.join", "os.path.join", "os.path.isdir", "os.path.join", "os.path.join", "ValueError"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_patches"], ["    ", "def", "__init__", "(", "self", ",", "data_directory", ",", "*", ",", "randomize", "=", "2468", ",", "load", "=", "'xy'", ",", "n_images", "=", "120", ",", "v_images", "=", "30", ",", "val_rgb_patch_size", "=", "128", ",", "\n", "val_n_patches", "=", "1", ",", "val_discard", "=", "'flat-aggressive'", ")", ":", "\n", "        ", "\"\"\"\n        Represents a [RAW-]RGB dataset for training imaging pipelines. The class preloads full resolution images and\n        samples from them when requesting training batches. (Validation images are sampled upon creation.) Patch\n        selection takes care of proper alignment between RAW images (represented as half-size 4-channel RGGB stacks) and\n        their corresponding rendered RGB versions. Selection can be controlled to prefer certain types of patches (not\n        strictly enforced). The following DISCARD modes are available:\n\n        - flat - attempts to discard flat patches based on patch variance (not strict)\n        - flat-aggressive - a more aggressive version that avoids patches with variance < 0.01\n        - dark-n-textured - avoid dark (mean < 0.35) and textured patches (variance > 0.005)\n\n        Usage examples:\n        ---------------\n\n        # Load a RAW -> RGB dataset\n        data = Dataset('data/raw/training_data/D90')\n        batch_raw, batch_rgb = data.next_training_batch(0, 10, 128, 'flat-aggressive')\n\n        # Load RGB only dataset\n        data = Dataset('data/rgb/native12k/', load='y')\n        batch_rgb = data.next_training_batch(0, 10, 128, 'flat-aggressive')\n\n        :param data_directory: directory path with RAW-RGB pairs (*.npy & *.png) or only RGB images (*.png)\n        :param randomize: randomization seed\n        :param load: what data to load: 'xy' load RAW+RGB, 'x' load RAW only, 'y' load RGB only\n        :param n_images: number of training images (full resolution)\n        :param v_images: number of validation images (patches sampled upon creation)\n        :param val_rgb_patch_size: validation patch size\n        :param val_n_patches: number of validation patches to load per full-resolution image\n        :param val_discard: patch discard mode (for validation data)\n        \"\"\"", "\n", "\n", "if", "not", "any", "(", "load", "==", "allowed", "for", "allowed", "in", "[", "'xy'", ",", "'x'", ",", "'y'", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid X/Y data requested!'", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "data_directory", ")", ":", "\n", "            ", "if", "'/'", "in", "data_directory", "or", "'\\\\'", "in", "data_directory", ":", "\n", "                ", "raise", "ValueError", "(", "f'Cannot find the data directory: {data_directory}'", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "'data/raw/training_data/'", ",", "data_directory", ")", ")", ":", "\n", "                ", "data_directory", "=", "os", ".", "path", ".", "join", "(", "'data/raw/training_data/'", ",", "data_directory", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "'data/rgb/'", ",", "data_directory", ")", ")", ":", "\n", "                ", "data_directory", "=", "os", ".", "path", ".", "join", "(", "'data/rgb/'", ",", "data_directory", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f'Cannot find the data directory: {data_directory}'", ")", "\n", "\n", "", "", "self", ".", "files", "=", "{", "}", "\n", "self", ".", "_loaded_data", "=", "load", "\n", "self", ".", "_data_directory", "=", "data_directory", "\n", "self", ".", "_counts", "=", "(", "n_images", ",", "v_images", ",", "val_n_patches", ")", "\n", "self", ".", "_val_discard", "=", "'flat-aggressive'", "\n", "self", ".", "files", "[", "'training'", "]", ",", "self", ".", "files", "[", "'validation'", "]", "=", "loading", ".", "discover_images", "(", "data_directory", ",", "randomize", "=", "randomize", ",", "\n", "n_images", "=", "n_images", ",", "v_images", "=", "v_images", ")", "\n", "\n", "self", ".", "data", "=", "{", "\n", "'training'", ":", "loading", ".", "load_images", "(", "self", ".", "files", "[", "'training'", "]", ",", "data_directory", ",", "load", "=", "load", ")", ",", "\n", "'validation'", ":", "loading", ".", "load_patches", "(", "self", ".", "files", "[", "'validation'", "]", ",", "data_directory", ",", "\n", "patch_size", "=", "val_rgb_patch_size", "//", "2", ",", "n_patches", "=", "val_n_patches", ",", "\n", "load", "=", "load", ",", "discard", "=", "val_discard", ")", "\n", "}", "\n", "\n", "if", "'y'", "in", "self", ".", "data", "[", "'training'", "]", ":", "\n", "            ", "self", ".", "H", ",", "self", ".", "W", "=", "self", ".", "data", "[", "'training'", "]", "[", "'y'", "]", ".", "shape", "[", "1", ":", "3", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "H", ",", "self", ".", "W", "=", "(", "2", "*", "dim", "for", "dim", "in", "self", ".", "data", "[", "'training'", "]", "[", "'x'", "]", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.__getitem__": [[83, 88], ["KeyError"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "key", "in", "[", "'training'", ",", "'validation'", "]", ":", "\n", "            ", "return", "self", ".", "data", "[", "key", "]", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "'Key: {} not found!'", ".", "format", "(", "key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch": [[89, 132], ["range", "ValueError", "len", "ValueError", "helpers.loading.sample_patch", "numpy.zeros", "numpy.zeros", "current_raw[].astype", "current_rgb[].astype"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.sample_patch"], ["", "", "def", "next_training_batch", "(", "self", ",", "batch_id", ",", "batch_size", ",", "rgb_patch_size", ",", "discard", "=", "'flat'", ",", "max_attempts", "=", "25", ")", ":", "\n", "        ", "\"\"\"\n        Sample a new batch of training patches.\n        :param batch_id: integer from 0 to (#training images // batch_size - 1)\n        :param batch_size: integer, self explanatory\n        :param rgb_patch_size: patch size (in full-resolution RGB coordinates; RAW patches [RGGB] have half the size)\n        :param discard: patch discard mode (for validation data)\n        :param max_attempts: maximum number of sampling attempts (if unsuccessful)\n        :return: tuple of np arrays (RAW, RGB) or np array (RGB)\n        \"\"\"", "\n", "\n", "if", "discard", "is", "not", "None", "and", "'y'", "not", "in", "self", ".", "data", "[", "'training'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Cannot discard patches if RGB data is not loaded.'", ")", "\n", "\n", "", "if", "(", "batch_id", "+", "1", ")", "*", "batch_size", ">", "len", "(", "self", ".", "files", "[", "'training'", "]", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Not enough images for the requested batch_id & batch_size'", ")", "\n", "\n", "", "raw_patch_size", "=", "rgb_patch_size", "//", "2", "\n", "\n", "# Allocate memory for the batch", "\n", "batch", "=", "{", "\n", "'x'", ":", "np", ".", "zeros", "(", "(", "batch_size", ",", "raw_patch_size", ",", "raw_patch_size", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "'x'", "in", "self", ".", "_loaded_data", "else", "None", ",", "\n", "'y'", ":", "np", ".", "zeros", "(", "(", "batch_size", ",", "rgb_patch_size", ",", "rgb_patch_size", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "'y'", "in", "self", ".", "_loaded_data", "else", "None", "\n", "}", "\n", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "bid", "=", "batch_id", "*", "batch_size", "+", "b", "\n", "current_rgb", "=", "self", ".", "data", "[", "'training'", "]", "[", "'y'", "]", "[", "bid", "]", "\n", "xx", ",", "yy", "=", "sample_patch", "(", "current_rgb", ",", "rgb_patch_size", ",", "discard", ",", "max_attempts", ")", "\n", "rx", ",", "ry", "=", "xx", "//", "2", ",", "yy", "//", "2", "\n", "\n", "if", "'x'", "in", "self", ".", "_loaded_data", ":", "\n", "                ", "current_raw", "=", "self", ".", "data", "[", "'training'", "]", "[", "'x'", "]", "[", "bid", "]", "\n", "batch", "[", "'x'", "]", "[", "b", "]", "=", "current_raw", "[", "ry", ":", "ry", "+", "raw_patch_size", ",", "rx", ":", "rx", "+", "raw_patch_size", "]", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "16", "-", "1", ")", "\n", "", "if", "'y'", "in", "self", ".", "_loaded_data", ":", "\n", "                ", "batch", "[", "'y'", "]", "[", "b", "]", "=", "current_rgb", "[", "yy", ":", "yy", "+", "rgb_patch_size", ",", "xx", ":", "xx", "+", "rgb_patch_size", "]", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "", "", "if", "self", ".", "_loaded_data", "==", "'xy'", ":", "\n", "            ", "return", "batch", "[", "'x'", "]", ",", "batch", "[", "'y'", "]", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'y'", ":", "\n", "            ", "return", "batch", "[", "'y'", "]", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'x'", ":", "\n", "            ", "return", "batch", "[", "'x'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch": [[133, 159], ["range", "numpy.zeros", "numpy.zeros", "[].astype", "[].astype"], "methods", ["None"], ["", "", "def", "next_validation_batch", "(", "self", ",", "batch_id", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Return a validation batch.\n        :param batch_id: integer from 0 to (#validation images // batch_size - 1)\n        :param batch_size: integer, self explanatory\n        :return: tuple of np arrays (RAW, RGB) or np array (RGB)\n        \"\"\"", "\n", "rgb_patch", "=", "self", ".", "rgb_patch_size", "\n", "\n", "batch", "=", "{", "\n", "'x'", ":", "np", ".", "zeros", "(", "(", "batch_size", ",", "rgb_patch", "//", "2", ",", "rgb_patch", "//", "2", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "'x'", "in", "self", ".", "_loaded_data", "else", "None", ",", "\n", "'y'", ":", "np", ".", "zeros", "(", "(", "batch_size", ",", "rgb_patch", ",", "rgb_patch", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "if", "'y'", "in", "self", ".", "_loaded_data", "else", "None", "\n", "}", "\n", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "'x'", "in", "self", ".", "_loaded_data", ":", "\n", "                ", "batch", "[", "'x'", "]", "[", "b", "]", "=", "self", ".", "data", "[", "'validation'", "]", "[", "'x'", "]", "[", "batch_id", "*", "batch_size", "+", "b", "]", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "16", "-", "1", ")", "\n", "", "if", "'y'", "in", "self", ".", "_loaded_data", ":", "\n", "                ", "batch", "[", "'y'", "]", "[", "b", "]", "=", "self", ".", "data", "[", "'validation'", "]", "[", "'y'", "]", "[", "batch_id", "*", "batch_size", "+", "b", "]", ".", "astype", "(", "np", ".", "float", ")", "/", "(", "2", "**", "8", "-", "1", ")", "\n", "\n", "", "", "if", "self", ".", "_loaded_data", "==", "'xy'", ":", "\n", "            ", "return", "batch", "[", "'x'", "]", ",", "batch", "[", "'y'", "]", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'y'", ":", "\n", "            ", "return", "batch", "[", "'y'", "]", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'x'", ":", "\n", "            ", "return", "batch", "[", "'x'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.is_raw_and_rgb": [[160, 162], ["len"], "methods", ["None"], ["", "", "def", "is_raw_and_rgb", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_loaded_data", ")", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.rgb_patch_size": [[163, 170], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "rgb_patch_size", "(", "self", ")", ":", "\n", "        ", "if", "'y'", "in", "self", ".", "_loaded_data", ":", "\n", "            ", "patch_size", "=", "self", ".", "data", "[", "'validation'", "]", "[", "'y'", "]", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "patch_size", "=", "2", "*", "self", ".", "data", "[", "'validation'", "]", "[", "'x'", "]", ".", "shape", "[", "1", "]", "\n", "", "return", "patch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.count_training": [[171, 175], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "count_training", "(", "self", ")", ":", "\n", "        ", "key", "=", "self", ".", "_loaded_data", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "'training'", "]", "[", "key", "]", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.count_validation": [[176, 180], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "count_validation", "(", "self", ")", ":", "\n", "        ", "key", "=", "self", ".", "_loaded_data", "[", "0", "]", "\n", "return", "self", ".", "data", "[", "'validation'", "]", "[", "key", "]", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.__repr__": [[181, 186], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "args", "=", "[", "f'\"{self._data_directory}\"'", ",", "f'load=\"{self._loaded_data}\"'", ",", "f'n_images={self._counts[0]}'", ",", "\n", "f'v_images={self._counts[1]}'", ",", "f'val_rgb_patch_size={self._counts[2]}'", ",", "\n", "f'val_rgb_patch_size={self.rgb_patch_size}'", ",", "f'discard=\"{self._val_discard}\"'", "]", "\n", "return", "f'Dataset({\", \".join(args)})'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.shapes": [[187, 197], ["None"], "methods", ["None"], ["", "def", "shapes", "(", "self", ")", ":", "\n", "        ", "stats", "=", "{", "\n", "'path'", ":", "self", ".", "_data_directory", ",", "\n", "}", "\n", "\n", "for", "k", "in", "self", ".", "_loaded_data", ":", "\n", "            ", "stats", "[", "'training/{}'", ".", "format", "(", "k", ")", "]", "=", "self", ".", "data", "[", "'training'", "]", "[", "k", "]", ".", "shape", "\n", "stats", "[", "'validation/{}'", ".", "format", "(", "k", ")", "]", "=", "self", ".", "data", "[", "'validation'", "]", "[", "k", "]", ".", "shape", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.loaded_data": [[198, 207], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "loaded_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_loaded_data", "==", "'xy'", ":", "\n", "            ", "db_type", "=", "'raw+rgb'", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'y'", ":", "\n", "            ", "db_type", "=", "'rgb'", "\n", "", "elif", "self", ".", "_loaded_data", "==", "'x'", ":", "\n", "            ", "db_type", "=", "'raw'", "\n", "", "return", "db_type", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary": [[208, 211], ["os.path.split"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "def", "summary", "(", "self", ")", ":", "\n", "        ", "valid_label", "=", "''", "if", "self", ".", "_val_discard", "is", "None", "else", "f', {self._val_discard}'", "\n", "return", "f'Dataset[{os.path.split(self._data_directory)[-1]},{self.loaded_data}] : {self.count_training} train. images + {self.count_validation} valid. patches ({self.rgb_patch_size} px{valid_label})'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.details": [[212, 220], ["zip", "dataset.Dataset.summary", "label.append"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.summary"], ["", "def", "details", "(", "self", ")", ":", "\n", "        ", "label", "=", "[", "self", ".", "summary", "(", ")", "]", "\n", "\n", "for", "k", ",", "l", "in", "zip", "(", "'xy'", ",", "[", "'RAW'", ",", "'RGB'", "]", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "_loaded_data", ":", "\n", "                ", "label", ".", "append", "(", "f'{l} -> training {self.data[\"training\"][k].shape} + validation {self.data[\"validation\"][k].shape}'", ")", "\n", "\n", "", "", "return", "'\\n'", ".", "join", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_training_generator": [[221, 233], ["range", "StopIteration", "dataset.Dataset.next_training_batch"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_training_batch"], ["", "def", "get_training_generator", "(", "self", ",", "batch_size", ",", "rgb_patch_size", ",", "discard", "=", "'flat'", ")", ":", "\n", "        ", "\"\"\"\n        Get a generator for training data. Can be used to construct a data pipeline:\n\n        dp = tf.data.Dataset.from_generator(lambda: data.get_training_generator(batch_size, rgb_patch_size, discard),\n            output_types=len(self._loaded_data) * (tf.float32, ))\n        \"\"\"", "\n", "\n", "for", "batch_id", "in", "range", "(", "self", ".", "count_training", "//", "batch_size", ")", ":", "\n", "            ", "yield", "self", ".", "next_training_batch", "(", "batch_id", ",", "batch_size", ",", "rgb_patch_size", ",", "discard", ")", "\n", "\n", "", "raise", "StopIteration", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_validation_generator": [[234, 246], ["range", "StopIteration", "dataset.Dataset.next_validation_batch"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.next_validation_batch"], ["", "def", "get_validation_generator", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Get a generator for validation data. Can be used to construct a data pipeline:\n\n        dp = tf.data.Dataset.from_generator(lambda: data.get_validation_generator(batch_size),\n            output_types=len(self._loaded_data) * (tf.float32, ))\n        \"\"\"", "\n", "\n", "for", "batch_id", "in", "range", "(", "self", ".", "count_validation", "//", "batch_size", ")", ":", "\n", "            ", "yield", "self", ".", "next_validation_batch", "(", "batch_id", ",", "batch_size", ")", "\n", "\n", "", "raise", "StopIteration", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_training_pipeline": [[247, 251], ["tf.data.Dataset.from_generator", "dataset.Dataset.get_training_generator", "len"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_training_generator"], ["", "def", "get_training_pipeline", "(", "self", ",", "batch_size", ",", "rgb_patch_size", ",", "discard", "=", "'flat'", ")", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "lambda", ":", "self", ".", "get_training_generator", "(", "batch_size", ",", "rgb_patch_size", ",", "discard", ")", ",", "\n", "output_types", "=", "len", "(", "self", ".", "_loaded_data", ")", "*", "(", "tf", ".", "float32", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_validation_pipeline": [[252, 256], ["tf.data.Dataset.from_generator", "dataset.Dataset.get_validation_generator", "len"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.dataset.Dataset.get_validation_generator"], ["", "def", "get_validation_pipeline", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "lambda", ":", "self", ".", "get_validation_generator", "(", "batch_size", ")", ",", "\n", "output_types", "=", "len", "(", "self", ".", "_loaded_data", ")", "*", "(", "tf", ".", "float32", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.discover_images": [[14, 44], ["helpers.fsutil.listdir", "loguru.logger.debug", "numpy.random.seed", "numpy.random.shuffle", "len", "len", "len", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir"], ["def", "discover_images", "(", "data_directory", ",", "n_images", "=", "120", ",", "v_images", "=", "30", ",", "extension", "=", "'png'", ",", "randomize", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Find available images and split them into training / validation sets.\n    :param data_directory: directory\n    :param n_images: number of training images\n    :param v_images: number of validation images\n    :param extension: file extension\n    :param randomize: whether to shuffle files before the split\n    \"\"\"", "\n", "\n", "files", "=", "fsutil", ".", "listdir", "(", "data_directory", ",", "'.*\\\\.{}$'", ".", "format", "(", "extension", ")", ")", "\n", "logger", ".", "debug", "(", "f'{data_directory}: in total {len(files)} files available'", ")", "\n", "\n", "if", "randomize", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "randomize", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "files", ")", "\n", "\n", "", "if", "n_images", "==", "0", "and", "v_images", "==", "-", "1", ":", "\n", "        ", "v_images", "=", "len", "(", "files", ")", "\n", "\n", "", "if", "n_images", "==", "-", "1", "and", "v_images", "==", "0", ":", "\n", "        ", "n_images", "=", "len", "(", "files", ")", "\n", "\n", "", "if", "len", "(", "files", ")", ">=", "n_images", "+", "v_images", ":", "\n", "        ", "val_files", "=", "files", "[", "n_images", ":", "(", "n_images", "+", "v_images", ")", "]", "\n", "files", "=", "files", "[", "0", ":", "n_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Not enough images!'", ")", "\n", "\n", "", "return", "files", ",", "val_files", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_images": [[46, 86], ["len", "imageio.imread", "loguru.logger.warning", "os.path.join", "numpy.zeros", "numpy.zeros", "tqdm.tqdm", "enumerate", "numpy.zeros", "file.replace", "pbar.update", "numpy.load", "imageio.imread", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load"], ["", "def", "load_images", "(", "files", ",", "data_directory", ",", "extension", "=", "'png'", ",", "load", "=", "'xy'", ")", ":", "\n", "    ", "\"\"\"\n    Load pairs of full-resolution images: (raw, rgb). Raw inputs are stored in *.npy files (see\n    train_prepare_training_set.py).\n    :param files: list of files to be loaded\n    :param data_directory: directory path\n    :param extension: file extension of rgb images\n    :param load: what data to load - string: 'xy' (load both raw and rgb), 'x' (load only raw) or 'y' (load only rgb)\n    \"\"\"", "\n", "n_images", "=", "len", "(", "files", ")", "\n", "\n", "if", "n_images", "==", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "'No images to load!'", ")", "\n", "return", "{", "k", ":", "np", ".", "zeros", "(", "shape", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ")", "for", "k", "in", "load", "}", "\n", "\n", "# Check image resolution", "\n", "", "image", "=", "imageio", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "data_directory", ",", "files", "[", "0", "]", ")", ")", "\n", "resolutions", "=", "(", "image", ".", "shape", "[", "0", "]", ">>", "1", ",", "image", ".", "shape", "[", "1", "]", ">>", "1", ")", "\n", "del", "image", "\n", "\n", "data", "=", "{", "}", "\n", "\n", "if", "'x'", "in", "load", ":", "\n", "        ", "data", "[", "'x'", "]", "=", "np", ".", "zeros", "(", "(", "n_images", ",", "*", "resolutions", ",", "4", ")", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "", "if", "'y'", "in", "load", ":", "\n", "        ", "data", "[", "'y'", "]", "=", "np", ".", "zeros", "(", "(", "n_images", ",", "2", "*", "resolutions", "[", "0", "]", ",", "2", "*", "resolutions", "[", "1", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "", "with", "tqdm", ".", "tqdm", "(", "total", "=", "n_images", ",", "ncols", "=", "100", ",", "desc", "=", "'Loading images'", ")", "as", "pbar", ":", "\n", "\n", "        ", "for", "i", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "            ", "npy_file", "=", "file", ".", "replace", "(", "'.{}'", ".", "format", "(", "extension", ")", ",", "'.npy'", ")", "\n", "\n", "if", "'x'", "in", "data", ":", "\n", "                ", "data", "[", "'x'", "]", "[", "i", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_directory", ",", "npy_file", ")", ")", "\n", "", "if", "'y'", "in", "data", ":", "\n", "                ", "data", "[", "'y'", "]", "[", "i", "]", "=", "imageio", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "data_directory", ",", "file", ")", ",", "pilmode", "=", "'RGB'", ")", "\n", "\n", "", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.load_patches": [[88, 130], ["len", "numpy.zeros", "numpy.zeros", "tqdm.tqdm", "enumerate", "file.replace", "range", "numpy.load", "imageio.imread", "loading.sample_patch", "pbar.update", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.load", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.sample_patch", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["", "", "def", "load_patches", "(", "files", ",", "data_directory", ",", "patch_size", "=", "128", ",", "n_patches", "=", "100", ",", "discard", "=", "'flat-aggressive'", ",", "extension", "=", "'png'", ",", "load", "=", "'xy'", ")", ":", "\n", "    ", "\"\"\"\n    Sample (raw, rgb) pairs or random patches from given images.\n\n    :param files: list of available images\n    :param data_directory: directory path\n    :param patch_size: patch size (in the raw image - rgb patches will be twice as big)\n    :param n_patches: number of patches per image\n    :param discard: strategy for discarding nonsuitable patches\n    :param extension: file extension of RGB images\n    :param load: what data to load - string: 'xy' (load both raw and rgb), 'x' (load only raw) or 'y' (load only rgb)\n    \"\"\"", "\n", "v_images", "=", "len", "(", "files", ")", "\n", "max_attempts", "=", "100", "\n", "discard_label", "=", "'(random)'", "if", "discard", "is", "None", "else", "'({})'", ".", "format", "(", "discard", ")", "\n", "data", "=", "{", "}", "\n", "\n", "if", "'x'", "in", "load", ":", "data", "[", "'x'", "]", "=", "np", ".", "zeros", "(", "(", "v_images", "*", "n_patches", ",", "patch_size", ",", "patch_size", ",", "4", ")", ",", "dtype", "=", "np", ".", "uint16", ")", "\n", "if", "'y'", "in", "load", ":", "data", "[", "'y'", "]", "=", "np", ".", "zeros", "(", "(", "v_images", "*", "n_patches", ",", "2", "*", "patch_size", ",", "2", "*", "patch_size", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "v_images", "*", "n_patches", ",", "ncols", "=", "100", ",", "desc", "=", "'Loading patches {}'", ".", "format", "(", "discard_label", ")", ")", "as", "pbar", ":", "\n", "\n", "        ", "for", "i", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "            ", "npy_file", "=", "file", ".", "replace", "(", "'.{}'", ".", "format", "(", "extension", ")", ",", "'.npy'", ")", "\n", "\n", "if", "'x'", "in", "data", ":", "image_x", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "data_directory", ",", "npy_file", ")", ")", "\n", "if", "'y'", "in", "data", ":", "image_y", "=", "imageio", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "data_directory", ",", "file", ")", ",", "pilmode", "=", "'RGB'", ")", "\n", "\n", "# Sample random patches", "\n", "for", "b", "in", "range", "(", "n_patches", ")", ":", "\n", "\n", "                ", "xx", ",", "yy", "=", "sample_patch", "(", "image_y", ",", "2", "*", "patch_size", ",", "discard", ",", "max_attempts", ")", "\n", "rx", ",", "ry", "=", "xx", "//", "2", ",", "yy", "//", "2", "\n", "\n", "if", "'x'", "in", "data", ":", "\n", "                    ", "data", "[", "'x'", "]", "[", "i", "*", "n_patches", "+", "b", "]", "=", "image_x", "[", "ry", ":", "ry", "+", "patch_size", ",", "rx", ":", "rx", "+", "patch_size", ",", ":", "]", "\n", "", "if", "'y'", "in", "data", ":", "\n", "                    ", "data", "[", "'y'", "]", "[", "i", "*", "n_patches", "+", "b", "]", "=", "image_y", "[", "yy", ":", "yy", "+", "2", "*", "patch_size", ",", "xx", ":", "xx", "+", "2", "*", "patch_size", ",", ":", "]", "\n", "\n", "", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.loading.sample_patch": [[132, 212], ["numpy.var", "numpy.mean", "rgb_image[].astype", "numpy.random.randint", "numpy.random.randint", "numpy.random.uniform", "ValueError"], "function", ["None"], ["", "", "def", "sample_patch", "(", "rgb_image", ",", "rgb_patch_size", "=", "128", ",", "discard", "=", "None", ",", "max_attempts", "=", "25", ")", ":", "\n", "    ", "\"\"\"\n    Sample a single patch from a full-resolution image. Sampling can be fully random or can follow a discarding policy.\n    The following DISCARD modes are available:\n\n        - flat - attempts to discard flat patches based on patch variance (not strict)\n        - flat-aggressive - a more aggressive version that avoids patches with variance < 0.01\n        - dark-n-textured - avoid dark (mean < 0.35) and textured patches (variance > 0.005)\n\n    :param rgb_image: full resolution RGB image\n    :param rgb_patch_size: integer, self-explanatory\n    :param discard: discard policy\n    :param max_attempts: maximum number of sampling attempts (if unsuccessful)\n    :return: a tuple with (x, y) coordinates\n    \"\"\"", "\n", "xx", ",", "yy", "=", "0", ",", "0", "\n", "\n", "max_x", "=", "rgb_image", ".", "shape", "[", "1", "]", "-", "rgb_patch_size", "\n", "max_y", "=", "rgb_image", ".", "shape", "[", "0", "]", "-", "rgb_patch_size", "\n", "\n", "if", "max_x", ">", "0", "or", "max_y", ">", "0", ":", "\n", "        ", "found", "=", "False", "\n", "panic_counter", "=", "max_attempts", "\n", "\n", "while", "not", "found", ":", "\n", "# Sample a random patch - the number needs to be even to ensure proper Bayer alignment", "\n", "            ", "xx", "=", "2", "*", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "max_x", ")", "//", "2", ")", "if", "max_x", ">", "0", "else", "0", "\n", "yy", "=", "2", "*", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "max_y", ")", "//", "2", ")", "if", "max_y", ">", "0", "else", "0", "\n", "\n", "if", "not", "discard", ":", "\n", "                ", "found", "=", "True", "\n", "continue", "\n", "\n", "", "patch", "=", "rgb_image", "[", "yy", ":", "yy", "+", "rgb_patch_size", ",", "xx", ":", "xx", "+", "rgb_patch_size", "]", ".", "astype", "(", "np", ".", "float", ")", "/", "255", "\n", "patch_variance", "=", "np", ".", "var", "(", "patch", ")", "\n", "patch_intensity", "=", "np", ".", "mean", "(", "patch", ")", "\n", "\n", "# Check if the sampled patch is acceptable", "\n", "if", "discard", "==", "'flat'", ":", "\n", "\n", "                ", "if", "patch_variance", "<", "0.005", ":", "\n", "                    ", "panic_counter", "-=", "1", "\n", "found", "=", "False", "if", "panic_counter", ">", "0", "else", "True", "\n", "", "elif", "patch_variance", "<", "0.01", ":", "\n", "                    ", "found", "=", "np", ".", "random", ".", "uniform", "(", ")", ">", "0.5", "\n", "", "else", ":", "\n", "                    ", "found", "=", "True", "\n", "\n", "", "", "elif", "discard", "==", "'flat-aggressive'", ":", "\n", "\n", "                ", "if", "patch_variance", "<", "0.02", ":", "\n", "                    ", "if", "panic_counter", "==", "max_attempts", "or", "patch_variance", ">", "best_patch", "[", "-", "1", "]", ":", "\n", "                        ", "best_patch", "=", "(", "xx", ",", "yy", ",", "patch_variance", ")", "\n", "", "panic_counter", "-=", "1", "\n", "found", "=", "False", "if", "panic_counter", ">", "0", "else", "True", "\n", "if", "found", ":", "\n", "                        ", "xx", ",", "yy", ",", "patch_variance", "=", "best_patch", "\n", "", "", "else", ":", "\n", "                    ", "found", "=", "True", "\n", "\n", "", "", "elif", "discard", "==", "'dark-n-textured'", ":", "\n", "\n", "                ", "if", "0", "<", "patch_variance", "<", "0.005", "and", "0.35", "<", "patch_intensity", "<", "0.99", ":", "\n", "                    ", "found", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "panic_counter", "==", "max_attempts", "or", "(", "patch_variance", "<", "2", "*", "best_patch", "[", "-", "1", "]", "\n", "and", "patch_intensity", ">", "1.1", "*", "best_patch", "[", "-", "2", "]", ")", ":", "\n", "                        ", "best_patch", "=", "(", "xx", ",", "yy", ",", "patch_intensity", ",", "patch_variance", ")", "\n", "", "panic_counter", "-=", "1", "\n", "found", "=", "False", "if", "panic_counter", ">", "0", "else", "True", "\n", "if", "found", ":", "\n", "                        ", "xx", ",", "yy", ",", "patch_intensity", ",", "patch_variance", "=", "best_patch", "\n", "\n", "", "", "", "elif", "discard", "is", "None", ":", "\n", "                ", "found", "=", "True", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unrecognized discard mode: {}'", ".", "format", "(", "discard", ")", ")", "\n", "\n", "", "", "", "return", "xx", ",", "yy", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__init__": [[35, 39], ["paramspec.ParamSpec._validate_specs"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec._validate_specs"], ["    ", "def", "__init__", "(", "self", ",", "specs", ")", ":", "\n", "        ", "self", ".", "_validate_specs", "(", "specs", ")", "\n", "self", ".", "__dict__", "[", "'_specs'", "]", "=", "specs", "\n", "self", ".", "__dict__", "[", "'_values'", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec._validate_specs": [[40, 54], ["specs.items", "ValueError", "ValueError", "helpers.utils.is_numeric_type", "ValueError", "type", "len", "any", "any", "type", "type"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_numeric_type"], ["", "@", "staticmethod", "\n", "def", "_validate_specs", "(", "specs", ")", ":", "\n", "        ", "for", "key", ",", "spec", "in", "specs", ".", "items", "(", ")", ":", "\n", "            ", "if", "type", "(", "spec", ")", "is", "not", "tuple", "and", "len", "(", "spec", ")", "!=", "3", ":", "\n", "                ", "raise", "ValueError", "(", "'Invalid parameter specification for key {} - expected tuple of length 3'", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "if", "spec", "[", "2", "]", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "spec", "[", "1", "]", "is", "str", "and", "not", "any", "(", "type", "(", "spec", "[", "2", "]", ")", "is", "s", "for", "s", "in", "[", "str", ",", "set", ",", "types", ".", "FunctionType", "]", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'String data types can be validated by a regex (string), enum (set) or custom function'", ")", "\n", "\n", "", "if", "utils", ".", "is_numeric_type", "(", "spec", "[", "1", "]", ")", "and", "not", "any", "(", "type", "(", "spec", "[", "2", "]", ")", "is", "s", "for", "s", "in", "[", "tuple", ",", "set", "]", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Numeric data types can be validated by a range (2-elem tuple), or enum (set)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add": [[55, 58], ["paramspec.ParamSpec._validate_specs", "paramspec.ParamSpec._specs.update"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec._validate_specs", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["", "", "", "def", "add", "(", "self", ",", "specs", ")", ":", "\n", "        ", "self", ".", "_validate_specs", "(", "specs", ")", "\n", "self", ".", "_specs", ".", "update", "(", "specs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__getattr__": [[59, 66], ["KeyError"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "in", "self", ".", "_values", ":", "\n", "            ", "return", "self", ".", "_values", "[", "name", "]", "\n", "", "elif", "name", "in", "self", ".", "_specs", ":", "\n", "            ", "return", "self", ".", "_specs", "[", "name", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__setattr__": [[67, 69], ["ValueError"], "methods", ["None"], ["", "", "def", "__setattr__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Values cannot be set directly. Use the `update` method.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_dtype": [[70, 72], ["None"], "methods", ["None"], ["", "def", "get_dtype", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "_specs", "[", "name", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_default": [[73, 75], ["None"], "methods", ["None"], ["", "def", "get_default", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "_specs", "[", "name", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_value": [[76, 78], ["paramspec.ParamSpec.__getattr__"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__getattr__"], ["", "def", "get_value", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "__getattr__", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_min": [[79, 85], ["type", "len"], "methods", ["None"], ["", "def", "get_min", "(", "self", ",", "name", ")", ":", "\n", "        ", "validation", "=", "self", ".", "_specs", "[", "name", "]", "[", "2", "]", "\n", "if", "type", "(", "validation", ")", "is", "tuple", "and", "len", "(", "validation", ")", "==", "2", ":", "\n", "            ", "return", "validation", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_max": [[86, 92], ["type", "len"], "methods", ["None"], ["", "", "def", "get_max", "(", "self", ",", "name", ")", ":", "\n", "        ", "validation", "=", "self", ".", "_specs", "[", "name", "]", "[", "2", "]", "\n", "if", "type", "(", "validation", ")", "is", "tuple", "and", "len", "(", "validation", ")", "==", "2", ":", "\n", "            ", "return", "validation", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_enum": [[93, 99], ["type", "set"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.set"], ["", "", "def", "get_enum", "(", "self", ",", "name", ")", ":", "\n", "        ", "validation", "=", "self", ".", "_specs", "[", "name", "]", "[", "2", "]", "\n", "if", "type", "(", "validation", ")", "is", "set", ":", "\n", "            ", "return", "set", "(", "validation", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.get_regex": [[100, 106], ["type"], "methods", ["None"], ["", "", "def", "get_regex", "(", "self", ",", "name", ")", ":", "\n", "        ", "validation", "=", "self", ".", "_specs", "[", "name", "]", "[", "2", "]", "\n", "if", "type", "(", "validation", ")", "is", "str", ":", "\n", "            ", "return", "validation", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__repr__": [[107, 109], ["paramspec.ParamSpec.to_dict", "type"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{}({})'", ".", "format", "(", "type", "(", "self", ")", ".", "__name__", ",", "self", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict": [[110, 114], ["params.update", "paramspec.ParamSpec._specs.items"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "params", "=", "{", "key", ":", "spec", "[", "0", "]", "for", "key", ",", "spec", "in", "self", ".", "_specs", ".", "items", "(", ")", "}", "\n", "params", ".", "update", "(", "self", ".", "_values", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_json": [[115, 119], ["paramspec.ParamSpec.to_dict", "helpers.utils.is_number", "str", "paramspec.ParamSpec.items"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.to_dict", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "params", "=", "self", ".", "to_dict", "(", ")", "\n", "params", "=", "{", "k", ":", "v", "if", "utils", ".", "is_number", "(", "v", ")", "else", "str", "(", "v", ")", "for", "k", ",", "v", "in", "params", ".", "items", "(", ")", "}", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.__contains__": [[120, 122], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "item", "in", "self", ".", "_specs", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys": [[123, 125], ["paramspec.ParamSpec._specs.keys"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "return", "[", "key", "for", "key", "in", "self", ".", "_specs", ".", "keys", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.changed_params": [[126, 129], ["paramspec.ParamSpec._values.items"], "methods", ["None"], ["", "def", "changed_params", "(", "self", ")", ":", "\n", "        ", "params", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "self", ".", "_values", ".", "items", "(", ")", "if", "self", ".", "_specs", "[", "key", "]", "[", "0", "]", "!=", "value", "}", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.update": [[130, 179], ["params.items", "ValueError", "helpers.utils.is_number", "numpy.isnan", "ValueError", "dtype", "callable", "type", "type", "len", "ValueError", "ValueError", "ValueError", "type", "ValueError", "validation", "ValueError"], "methods", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["", "def", "update", "(", "self", ",", "**", "params", ")", ":", "\n", "\n", "# Iterate over submitted values", "\n", "        ", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "\n", "            ", "if", "key", "in", "self", ".", "_specs", ":", "\n", "# Get specification for the current parameter", "\n", "                ", "_", ",", "dtype", ",", "validation", "=", "self", ".", "_specs", "[", "key", "]", "\n", "\n", "# Accept the new value if it:", "\n", "#   is not None", "\n", "#   is not np.nan (for numerical types)", "\n", "#   passes validation checks", "\n", "if", "value", "is", "not", "None", ":", "\n", "\n", "                    ", "if", "utils", ".", "is_number", "(", "value", ")", "and", "np", ".", "isnan", "(", "value", ")", ":", "\n", "                        ", "raise", "ValueError", "(", "'Invalid value {} for attribute {}'", ".", "format", "(", "value", ",", "key", ")", ")", "\n", "\n", "", "candidate", "=", "value", "if", "dtype", "is", "None", "else", "dtype", "(", "value", ")", "\n", "\n", "# Validation checks", "\n", "if", "validation", "is", "not", "None", ":", "\n", "\n", "# 1. if tuple - treat as min and max values", "\n", "                        ", "if", "type", "(", "validation", ")", "==", "tuple", "and", "len", "(", "validation", ")", "==", "2", ":", "\n", "                            ", "if", "validation", "[", "0", "]", "is", "not", "None", "and", "candidate", "<", "validation", "[", "0", "]", ":", "\n", "                                ", "raise", "ValueError", "(", "'{}: {} fails minimum validation check >= {}!'", ".", "format", "(", "key", ",", "candidate", ",", "validation", "[", "0", "]", ")", ")", "\n", "", "if", "validation", "[", "1", "]", "is", "not", "None", "and", "candidate", ">", "validation", "[", "1", "]", ":", "\n", "                                ", "raise", "ValueError", "(", "'{}: {} fails maximum validation check (<= {})!'", ".", "format", "(", "key", ",", "candidate", ",", "validation", "[", "1", "]", ")", ")", "\n", "\n", "# 2. if set - treat as a set of valid values", "\n", "", "", "if", "type", "(", "validation", ")", "==", "set", ":", "\n", "                            ", "if", "candidate", "not", "in", "validation", ":", "\n", "                                ", "raise", "ValueError", "(", "'{}: {} is not an allowed value ({})!'", ".", "format", "(", "key", ",", "candidate", ",", "validation", ")", ")", "\n", "\n", "# 3. if both string - treat as a regular expression match", "\n", "", "", "if", "type", "(", "validation", ")", "==", "str", "and", "dtype", "==", "str", ":", "\n", "                            ", "if", "validation", "not", "in", "candidate", ":", "\n", "                                ", "raise", "ValueError", "(", "'{}: {} does not match regex ({})!'", ".", "format", "(", "key", ",", "candidate", ",", "validation", ")", ")", "\n", "\n", "# 4. if function - run custom validation code", "\n", "", "", "if", "callable", "(", "validation", ")", ":", "\n", "                            ", "if", "not", "validation", "(", "candidate", ")", ":", "\n", "                                ", "raise", "ValueError", "(", "'{}: {} failed custom validation check!'", ".", "format", "(", "key", ",", "candidate", ")", ")", "\n", "\n", "", "", "", "self", ".", "_values", "[", "key", "]", "=", "candidate", "\n", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unexpected parameter: {}!'", ".", "format", "(", "key", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.item_passes": [[11, 18], ["check"], "function", ["None"], ["def", "item_passes", "(", "check", ")", ":", "\n", "    ", "def", "wrapper", "(", "items", ")", ":", "\n", "        ", "for", "i", "in", "items", ":", "\n", "            ", "if", "not", "check", "(", "i", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.numbers_in_range": [[20, 31], ["isinstance"], "function", ["None"], ["", "def", "numbers_in_range", "(", "dtype", ",", "min_value", "=", "None", ",", "max_value", "=", "None", ")", ":", "\n", "    ", "def", "wrapper", "(", "items", ")", ":", "\n", "        ", "for", "i", "in", "items", ":", "\n", "            ", "if", "not", "isinstance", "(", "i", ",", "dtype", ")", ":", "\n", "                ", "return", "False", "\n", "", "if", "min_value", "is", "not", "None", "and", "i", "<", "min_value", ":", "\n", "                ", "return", "False", "\n", "", "if", "max_value", "is", "not", "None", "and", "i", ">", "max_value", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.detection_accuracy": [[9, 33], ["isinstance", "stats.span", "max", "numpy.argmax", "max", "numpy.mean", "numpy.mean", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.span"], ["def", "detection_accuracy", "(", "positive", ",", "negative", ",", "bins", "=", "100", ",", "return_index", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Estimate binary detection accuracy from response distributions for matching and missing samples. Uses a simple\n    threshold for decision and finds the best accuracy:\n\n        0.5 * (np.mean(H_match >= t) + np.mean(H_miss < t))\n\n    :param positive: positive detection scores (numpy array)\n    :param negative: negative detection scores (numpy array)\n    :param bins: number / list of candidate thresholds to consider (int or iterable)\n    :param return_index: flag to return the index of the threshold instead of the threshold itself\n\n    :returns tuple (best accuracy, threshold / index)\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "bins", ",", "int", ")", ":", "\n", "        ", "bins", "=", "span", "(", "negative", ",", "positive", ",", "bins", ")", "\n", "\n", "", "accuracies", "=", "[", "0.5", "*", "(", "np", ".", "mean", "(", "positive", ">=", "thresh", ")", "+", "np", ".", "mean", "(", "negative", "<", "thresh", ")", ")", "for", "thresh", "in", "bins", "]", "\n", "\n", "if", "return_index", ":", "\n", "        ", "return", "max", "(", "accuracies", ")", ",", "np", ".", "argmax", "(", "accuracies", ")", "\n", "", "else", ":", "\n", "        ", "return", "max", "(", "accuracies", ")", ",", "bins", "[", "np", ".", "argmax", "(", "accuracies", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.true_positive_rate": [[35, 45], ["numpy.percentile", "numpy.mean"], "function", ["None"], ["", "", "def", "true_positive_rate", "(", "positive", ",", "negative", ",", "fpr", "=", "0.01", ")", ":", "\n", "    ", "\"\"\"\n    Estimate true positive rate at a fixed false positive rate threshold.\n    :param positive: positive detection scores (numpy array)\n    :param negative: negative detection scores (numpy array)\n    :param fpr: false positive rate (0-1)\n    :return:\n    \"\"\"", "\n", "thresh", "=", "np", ".", "percentile", "(", "negative", ",", "100", "*", "(", "1", "-", "fpr", ")", ")", "\n", "return", "np", ".", "mean", "(", "positive", ">=", "thresh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.roc": [[47, 59], ["stats.span", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.span"], ["", "def", "roc", "(", "positive", ",", "negative", ",", "bins", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    Returns tpr, fpr coordinates along an ROC curve.\n    :param positive: positive detection scores (numpy array)\n    :param negative: negative detection scores (numpy array)\n    :param bins: number of candidate thresholds to consider (int)\n    :return: tuple of arrays (tpr, fpr)\n    \"\"\"", "\n", "cc", "=", "span", "(", "negative", ",", "positive", ",", "bins", ")", "\n", "tpr", "=", "[", "np", ".", "mean", "(", "positive", ">=", "t", ")", "for", "t", "in", "cc", "]", "[", ":", ":", "-", "1", "]", "\n", "fpr", "=", "[", "np", ".", "mean", "(", "negative", ">=", "t", ")", "for", "t", "in", "cc", "]", "[", ":", ":", "-", "1", "]", "\n", "return", "tpr", ",", "fpr", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.auc": [[61, 79], ["stats.roc", "numpy.trapz", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.roc"], ["", "def", "auc", "(", "positive", ",", "negative", ",", "bins", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    Returns an approximate AUC (trapezoid ROC integration).\n\n    :param positive: positive detection scores (numpy array)\n    :param negative: negative detection scores (numpy array)\n    :param bins: number of candidate thresholds to consider (int)\n    :return: auc\n    \"\"\"", "\n", "tpr", ",", "fpr", "=", "roc", "(", "positive", ",", "negative", ",", "bins", ")", "\n", "\n", "if", "tpr", "[", "0", "]", "!=", "0", "or", "fpr", "[", "0", "]", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'The ROC should start at (0, 0) - double check the detection threshold sweep'", ")", "\n", "\n", "", "if", "tpr", "[", "-", "1", "]", "!=", "1", "or", "fpr", "[", "-", "1", "]", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'The ROC should end at (1, 1) - double check the detection threshold sweep'", ")", "\n", "\n", "", "return", "np", ".", "trapz", "(", "tpr", ",", "fpr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.inlier_rate": [[81, 90], ["numpy.mean", "numpy.percentile", "numpy.percentile"], "function", ["None"], ["", "def", "inlier_rate", "(", "candidates", ",", "reference", ",", "perc", "=", "0.05", ")", ":", "\n", "    ", "\"\"\"\n    Counts the ratio of candidate points that fall within the bottom and top percentiles of a reference distribution.\n    :param candidates: samples from the candidate distribution (numpy array)\n    :param reference: samples from the reference distribution (numpy array)\n    :param perc: percentile (0-1)\n    :return: fraction of candidate points (float in 0-1)\n    \"\"\"", "\n", "return", "np", ".", "mean", "(", "(", "candidates", ">", "np", ".", "percentile", "(", "reference", ",", "100", "*", "perc", ")", ")", "*", "(", "candidates", "<", "np", ".", "percentile", "(", "reference", ",", "100", "*", "(", "1", "-", "perc", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.corrcoeff": [[92, 97], ["numpy.mean", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "corrcoeff", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\" Returns the normalized correlation coefficient between two arrays \"\"\"", "\n", "a", "=", "(", "a", "-", "np", ".", "mean", "(", "a", ")", ")", "/", "(", "1e-9", "+", "np", ".", "std", "(", "a", ")", ")", "\n", "b", "=", "(", "b", "-", "np", ".", "mean", "(", "b", ")", ")", "/", "(", "1e-9", "+", "np", ".", "std", "(", "b", ")", ")", "\n", "return", "np", ".", "mean", "(", "a", "*", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.rsquared": [[99, 105], ["r2_score", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "rsquared", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\" Returns the coefficient of determination (R^2) between two arrays (normalized) \"\"\"", "\n", "from", "sklearn", ".", "metrics", "import", "r2_score", "\n", "a", "=", "(", "a", "-", "np", ".", "mean", "(", "a", ")", ")", "/", "(", "1e-9", "+", "np", ".", "std", "(", "a", ")", ")", "\n", "b", "=", "(", "b", "-", "np", ".", "mean", "(", "b", ")", ")", "/", "(", "1e-9", "+", "np", ".", "std", "(", "b", ")", ")", "\n", "return", "r2_score", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist": [[107, 117], ["numpy.histogram", "values.ravel", "f.sum", "stats.bin_edges"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.bin_edges"], ["", "def", "hist", "(", "values", ",", "code_book", ",", "density", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Returns a histogram of values quantized to given centroids (as opposed to numpy which uses bin edges).\n    :param values: values to be quantized\n    :param code_book: quantization code-book (centroids)\n    :param density:\n    :return:\n    \"\"\"", "\n", "f", "=", "np", ".", "histogram", "(", "values", ".", "ravel", "(", ")", ",", "bins", "=", "bin_edges", "(", "code_book", ")", ",", "density", "=", "density", ")", "[", "0", "]", "\n", "return", "f", "if", "not", "density", "else", "f", "/", "f", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.entropy": [[119, 132], ["stats.hist", "counts.clip.clip", "numpy.arange().reshape", "counts.clip.sum", "numpy.sum", "numpy.arange", "numpy.log2"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist"], ["", "def", "entropy", "(", "samples", ",", "code_book", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Estimate entropy of the samples quantized to given centroids.\n    :param samples: data samples\n    :param code_book: quantization code-book (centroids)\n    :return: entropy\n    \"\"\"", "\n", "if", "code_book", "is", "None", ":", "\n", "        ", "code_book", "=", "np", ".", "arange", "(", "-", "255", ",", "255", ",", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "", "counts", "=", "hist", "(", "samples", ",", "code_book", ")", "\n", "counts", "=", "counts", ".", "clip", "(", "min", "=", "1", ")", "\n", "probs", "=", "counts", "/", "counts", ".", "sum", "(", ")", "\n", "return", "-", "np", ".", "sum", "(", "probs", "*", "np", ".", "log2", "(", "probs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.bin_edges": [[134, 139], ["numpy.convolve", "numpy.concatenate", "numpy.abs().max", "numpy.array", "numpy.abs", "numpy.array"], "function", ["None"], ["", "def", "bin_edges", "(", "code_book", ")", ":", "\n", "    ", "max_float", "=", "np", ".", "abs", "(", "code_book", ")", ".", "max", "(", ")", "*", "2", "\n", "code_book_edges", "=", "np", ".", "convolve", "(", "code_book", ",", "[", "0.5", ",", "0.5", "]", ",", "mode", "=", "'valid'", ")", "\n", "code_book_edges", "=", "np", ".", "concatenate", "(", "(", "-", "np", ".", "array", "(", "[", "max_float", "]", ")", ",", "code_book_edges", ",", "np", ".", "array", "(", "[", "max_float", "]", ")", ")", ",", "axis", "=", "0", ")", "\n", "return", "code_book_edges", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.kld_discrete": [[141, 148], ["stats.span", "hist().clip", "hist().clip", "scipy.stats.entropy", "stats.hist", "stats.hist"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.span", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.hist"], ["", "def", "kld_discrete", "(", "samples_a", ",", "samples_b", ",", "bins", "=", "25", ")", ":", "\n", "    ", "cc", "=", "span", "(", "samples_a", ",", "samples_b", ",", "bins", ")", "\n", "\n", "p1", "=", "hist", "(", "samples_a", ",", "cc", ",", "density", "=", "True", ")", ".", "clip", "(", "min", "=", "1e-16", ")", "\n", "p2", "=", "hist", "(", "samples_b", ",", "cc", ",", "density", "=", "True", ")", ".", "clip", "(", "min", "=", "1e-16", ")", "\n", "\n", "return", "stats", ".", "entropy", "(", "p1", ",", "p2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.span": [[150, 154], ["numpy.linspace", "numpy.min", "numpy.max", "positive.min", "negative.min", "positive.max", "negative.max"], "function", ["None"], ["", "def", "span", "(", "negative", ",", "positive", ",", "bins", "=", "100", ")", ":", "\n", "    ", "bins", "=", "np", ".", "linspace", "(", "np", ".", "min", "(", "[", "positive", ".", "min", "(", ")", ",", "negative", ".", "min", "(", ")", "]", ")", "-", "1e-6", ",", "\n", "np", ".", "max", "(", "[", "positive", ".", "max", "(", ")", ",", "negative", ".", "max", "(", ")", "]", ")", "+", "1e-6", ",", "bins", ")", "\n", "return", "bins", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_gaussian": [[156, 171], ["numpy.zeros", "range", "numpy.arange", "len", "len", "stats.ma_gaussian.gaussian"], "function", ["None"], ["", "def", "ma_gaussian", "(", "x", ",", "y", ",", "step_size", "=", "0.05", ",", "width", "=", "10", ")", ":", "\n", "    ", "\"\"\"Moving average with Gaussian averaging\"\"\"", "\n", "bin_centers", "=", "np", ".", "arange", "(", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", "-", "0.5", "*", "step_size", ",", "step_size", ")", "+", "0.5", "*", "step_size", "\n", "bin_avg", "=", "np", ".", "zeros", "(", "len", "(", "bin_centers", ")", ")", "\n", "\n", "# We're going to weight with a Gaussian function", "\n", "def", "gaussian", "(", "x", ",", "amp", "=", "1", ",", "mean", "=", "0", ",", "sigma", "=", "1", ")", ":", "\n", "        ", "return", "amp", "*", "np", ".", "exp", "(", "-", "(", "x", "-", "mean", ")", "**", "2", "/", "(", "2", "*", "sigma", "**", "2", ")", ")", "\n", "\n", "", "for", "index", "in", "range", "(", "0", ",", "len", "(", "bin_centers", ")", ")", ":", "\n", "        ", "bin_center", "=", "bin_centers", "[", "index", "]", "\n", "weights", "=", "gaussian", "(", "x", ",", "mean", "=", "bin_center", ",", "sigma", "=", "width", ")", "\n", "bin_avg", "[", "index", "]", "=", "np", ".", "average", "(", "y", ",", "weights", "=", "weights", ")", "\n", "\n", "", "return", "bin_centers", ",", "bin_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_conv": [[173, 185], ["numpy.convolve", "len", "numpy.array", "numpy.pad", "len", "numpy.ones"], "function", ["None"], ["", "def", "ma_conv", "(", "x", ",", "n", "=", "10", ")", ":", "\n", "    ", "\"\"\"Moving average with a simple box filter.\"\"\"", "\n", "\n", "if", "len", "(", "x", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "if", "n", "==", "0", ":", "\n", "        ", "n", "=", "(", "len", "(", "x", ")", "//", "10", ")", "\n", "\n", "", "fn", "=", "2", "*", "n", "+", "1", "\n", "\n", "return", "np", ".", "convolve", "(", "np", ".", "pad", "(", "x", ",", "n", ",", "'edge'", ")", ",", "np", ".", "ones", "(", "(", "fn", ",", ")", ")", "/", "fn", ",", "mode", "=", "'valid'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.stats.ma_exp": [[187, 198], ["numpy.zeros_like", "range", "isinstance", "numpy.array"], "function", ["None"], ["", "def", "ma_exp", "(", "x", ",", "alpha", "=", "0.1", ")", ":", "\n", "    ", "\"\"\" Exponential moving average \"\"\"", "\n", "if", "not", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "x", "=", "np", ".", "array", "(", "x", ")", "\n", "\n", "", "y", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "y", "[", "0", "]", "=", "x", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "y", "[", "i", "]", "=", "alpha", "*", "x", "[", "i", "]", "+", "(", "1", "-", "alpha", ")", "*", "y", "[", "i", "-", "1", "]", "\n", "\n", "", "return", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process": [[10, 108], ["ValueError", "ValueError", "rawkit.raw.Raw", "raw.unpack", "numpy.array", "image_raw.clip.astype", "numpy.clip", "numpy.array", "image_raw.clip.clip", "np.rot90.clip", "numpy.expand_dims", "raw.raw_image", "colour_demosaicing.demosaicing_CFA_Bayer_Menon2007", "cam2srgb.dot", "cam2srgb.dot.T.reshape", "np.rot90.clip", "numpy.percentile", "numpy.percentile", "numpy.power", "numpy.rot90", "colour_demosaicing.demosaicing_CFA_Bayer_bilinear", "numpy.array().reshape", "np.rot90.reshape", "numpy.rot90", "numpy.mean", "numpy.array"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack"], ["def", "process", "(", "filename", ",", "use_srgb", "=", "True", ",", "use_gamma", "=", "True", ",", "brightness", "=", "'percentile'", ",", "demosaicing", "=", "'menon'", ",", "expand", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A simple imaging pipeline implemented from scratch.\n    :param filename: input RAW image\n    :param use_srgb: set to False to disable camera RGB to sRGB conversion\n    :param use_gamma: set to False to disable gamma correction\n    :param brightness: global brightness correction method (percentile, shift or None)\n    :param demosaicing: demosaicing method (menon, bilinear)\n    \"\"\"", "\n", "\n", "# Sanity checks", "\n", "if", "brightness", "not", "in", "[", "'percentile'", ",", "'shift'", ",", "None", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported brightness correction mode!'", ")", "\n", "\n", "", "if", "demosaicing", "not", "in", "[", "'menon'", ",", "'bilinear'", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported demosaicing method!'", ")", "\n", "\n", "", "with", "Raw", "(", "filename", ")", "as", "raw", ":", "\n", "        ", "raw", ".", "unpack", "(", ")", "\n", "image_raw", "=", "np", ".", "array", "(", "raw", ".", "raw_image", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# Normalization and calibration", "\n", "black", "=", "raw", ".", "data", ".", "contents", ".", "color", ".", "black", "\n", "saturation", "=", "raw", ".", "data", ".", "contents", ".", "color", ".", "maximum", "\n", "\n", "image_raw", "=", "image_raw", ".", "astype", "(", "np", ".", "float32", ")", "\n", "image_raw", "-=", "black", "\n", "\n", "uint14_max", "=", "1", "\n", "image_raw", "*=", "uint14_max", "/", "(", "saturation", "-", "black", ")", "\n", "image_raw", "=", "np", ".", "clip", "(", "image_raw", ",", "0", ",", "uint14_max", ")", "\n", "\n", "# White balancing", "\n", "cam_mul", "=", "np", ".", "array", "(", "raw", ".", "data", ".", "contents", ".", "color", ".", "cam_mul", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "cam_mul", "/=", "cam_mul", "[", "1", "]", "# Set the multiplier for G to be 1", "\n", "\n", "cfa_pattern", "=", "''", ".", "join", "(", "[", "''", ".", "join", "(", "x", ")", "for", "x", "in", "raw", ".", "color_filter_array", "]", ")", "\n", "\n", "if", "cfa_pattern", "==", "'GBRG'", ":", "\n", "            ", "image_raw", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "", "elif", "cfa_pattern", "==", "'RGGB'", ":", "\n", "            ", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "", "elif", "cfa_pattern", "==", "'BGGR'", ":", "\n", "            ", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "\n", "", "image_raw", "=", "image_raw", ".", "clip", "(", "0", ",", "uint14_max", ")", "\n", "\n", "# Demosaicing", "\n", "if", "demosaicing", "==", "'menon'", ":", "\n", "            ", "image_rgb", "=", "colour_demosaicing", ".", "demosaicing_CFA_Bayer_Menon2007", "(", "image_raw", ",", "pattern", "=", "cfa_pattern", ")", "\n", "", "elif", "demosaicing", "==", "'bilinear'", ":", "\n", "            ", "image_rgb", "=", "colour_demosaicing", ".", "demosaicing_CFA_Bayer_bilinear", "(", "image_raw", ",", "pattern", "=", "cfa_pattern", ")", "\n", "\n", "# Color space conversion", "\n", "", "if", "use_srgb", ":", "\n", "            ", "cam2srgb", "=", "np", ".", "array", "(", "raw", ".", "data", ".", "contents", ".", "color", ".", "rgb_cam", ",", "dtype", "=", "np", ".", "float", ")", ".", "reshape", "(", "(", "3", ",", "4", ")", ")", "[", ":", ",", "0", ":", "3", "]", "\n", "\n", "shape", "=", "image_rgb", ".", "shape", "\n", "pixels", "=", "image_rgb", ".", "reshape", "(", "-", "1", ",", "3", ")", ".", "T", "\n", "pixels", "=", "cam2srgb", ".", "dot", "(", "pixels", ")", "\n", "\n", "image_rgb", "=", "pixels", ".", "T", ".", "reshape", "(", "shape", ")", "\n", "image_rgb", "=", "image_rgb", ".", "clip", "(", "0", ",", "uint14_max", ")", "\n", "\n", "# Deallocate", "\n", "del", "pixels", "\n", "\n", "# Brightness correction", "\n", "", "if", "brightness", "==", "'percentile'", ":", "\n", "            ", "percentile", "=", "0.5", "\n", "image_rgb", "-=", "np", ".", "percentile", "(", "image_rgb", ",", "percentile", ")", "\n", "image_rgb", "/=", "np", ".", "percentile", "(", "image_rgb", ",", "100", "-", "percentile", ")", "\n", "", "elif", "brightness", "==", "'shift'", ":", "\n", "            ", "mult", "=", "0.25", "/", "np", ".", "mean", "(", "image_rgb", ")", "\n", "image_rgb", "*=", "mult", "\n", "\n", "", "image_rgb", "=", "image_rgb", ".", "clip", "(", "0", ",", "1", ")", "\n", "\n", "# Gamma correction", "\n", "if", "use_gamma", ":", "\n", "            ", "image_rgb", "=", "np", ".", "power", "(", "image_rgb", ",", "1", "/", "2.2", ")", "\n", "\n", "# Clip invisible pixels", "\n", "", "image_rgb", "=", "image_rgb", "[", "0", ":", "raw", ".", "metadata", ".", "height", ",", "0", ":", "raw", ".", "metadata", ".", "width", ",", ":", "]", "\n", "\n", "# Clip & rotate canvas, if needed", "\n", "if", "raw", ".", "metadata", ".", "orientation", "==", "5", ":", "\n", "            ", "image_rgb", "=", "np", ".", "rot90", "(", "image_rgb", ")", "\n", "", "elif", "raw", ".", "metadata", ".", "orientation", "==", "6", ":", "\n", "            ", "image_rgb", "=", "np", ".", "rot90", "(", "image_rgb", ",", "3", ")", "\n", "\n", "", "", "if", "expand", ":", "\n", "        ", "image_rgb", "=", "np", ".", "expand_dims", "(", "image_rgb", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "image_rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack": [[110, 182], ["rawkit.raw.Raw", "raw.unpack", "numpy.array", "np.expand_dims.astype", "numpy.clip", "numpy.array", "np.expand_dims.clip", "raw.raw_image", "numpy.array().reshape", "numpy.dstack().clip", "numpy.expand_dims", "numpy.array", "numpy.dstack", "ValueError"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack"], ["", "def", "unpack", "(", "filename", ",", "stack", "=", "True", ",", "use_wb", "=", "True", ",", "expand", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Reads a RAW image and return a raw pixel array (either in native resolution or as a RGGB Bayer stack),\n    and basic RAW parameters needed for processing (CFA pattern, sRGB conversion tables, and photo white\n    balance multipliers).\n\n    :param filename: input RAW image\n    :param stack: set to False to return the standard 1-channel RAW instead of the RGGB stack\n    :param use_wb: set to False to disable white balancing based on image meta-data\n    \"\"\"", "\n", "\n", "with", "Raw", "(", "filename", ")", "as", "raw", ":", "\n", "        ", "raw", ".", "unpack", "(", ")", "\n", "image_raw", "=", "np", ".", "array", "(", "raw", ".", "raw_image", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# Normalization and calibration", "\n", "black", "=", "raw", ".", "data", ".", "contents", ".", "color", ".", "black", "\n", "saturation", "=", "raw", ".", "data", ".", "contents", ".", "color", ".", "maximum", "\n", "\n", "image_raw", "=", "image_raw", ".", "astype", "(", "np", ".", "float32", ")", "\n", "image_raw", "-=", "black", "\n", "\n", "uint14_max", "=", "1", "\n", "image_raw", "*=", "uint14_max", "/", "(", "saturation", "-", "black", ")", "\n", "image_raw", "=", "np", ".", "clip", "(", "image_raw", ",", "0", ",", "uint14_max", ")", "\n", "\n", "cfa_pattern", "=", "''", ".", "join", "(", "[", "''", ".", "join", "(", "x", ")", "for", "x", "in", "raw", ".", "color_filter_array", "]", ")", ".", "upper", "(", ")", "\n", "cam_mul", "=", "np", ".", "array", "(", "raw", ".", "data", ".", "contents", ".", "color", ".", "cam_mul", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "cam_mul", "/=", "cam_mul", "[", "1", "]", "# Set the multiplier for G to be 1", "\n", "\n", "# White balancing", "\n", "if", "use_wb", ":", "\n", "            ", "if", "cfa_pattern", "==", "'GBRG'", ":", "\n", "                ", "image_raw", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "", "elif", "cfa_pattern", "==", "'RGGB'", ":", "\n", "                ", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "", "elif", "cfa_pattern", "==", "'BGGR'", ":", "\n", "                ", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "*=", "cam_mul", "[", "0", "]", "\n", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "*=", "cam_mul", "[", "2", "]", "\n", "\n", "", "", "image_raw", "=", "image_raw", ".", "clip", "(", "0", ",", "uint14_max", ")", "\n", "cam2srgb", "=", "np", ".", "array", "(", "raw", ".", "data", ".", "contents", ".", "color", ".", "rgb_cam", ",", "dtype", "=", "np", ".", "float", ")", ".", "reshape", "(", "(", "3", ",", "4", ")", ")", "[", ":", ",", "0", ":", "3", "]", "\n", "\n", "if", "stack", ":", "\n", "            ", "if", "cfa_pattern", "==", "'GBRG'", ":", "\n", "                ", "r", "=", "image_raw", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "g1", "=", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "g2", "=", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "b", "=", "image_raw", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", "==", "'RGGB'", ":", "\n", "                ", "r", "=", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "g1", "=", "image_raw", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "g2", "=", "image_raw", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "b", "=", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", "==", "'BGGR'", ":", "\n", "                ", "r", "=", "image_raw", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "g1", "=", "image_raw", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "\n", "g2", "=", "image_raw", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "b", "=", "image_raw", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unsupported CFA pattern: {}'", ".", "format", "(", "cfa_pattern", ")", ")", "\n", "\n", "", "image_raw", "=", "np", ".", "dstack", "(", "[", "r", ",", "g1", ",", "g2", ",", "b", "]", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "\n", "", "if", "expand", ":", "\n", "            ", "image_raw", "=", "np", ".", "expand_dims", "(", "image_raw", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "image_raw", ",", "cfa_pattern", ",", "cam2srgb", ",", "cam_mul", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process_auto": [[184, 202], ["rawkit.raw.Raw", "raw.unpack", "raw.process", "raw.to_buffer", "numpy.frombuffer", "image.reshape.reshape", "image.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.unpack", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.process"], ["", "", "def", "process_auto", "(", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Process a RAW image using libRAW with default settings.\n    :param filename: input RAW image\n    \"\"\"", "\n", "with", "Raw", "(", "filename", "=", "filename", ")", "as", "raw", ":", "\n", "        ", "raw", ".", "unpack", "(", ")", "\n", "raw", ".", "process", "(", ")", "\n", "image", "=", "raw", ".", "to_buffer", "(", ")", "\n", "\n", "image", "=", "np", ".", "frombuffer", "(", "image", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "if", "raw", ".", "metadata", ".", "orientation", "==", "5", ":", "\n", "            ", "image", "=", "image", ".", "reshape", "(", "(", "raw", ".", "metadata", ".", "width", ",", "raw", ".", "metadata", ".", "height", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "            ", "image", "=", "image", ".", "reshape", "(", "(", "raw", ".", "metadata", ".", "height", ",", "raw", ".", "metadata", ".", "width", ",", "3", ")", ")", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.stack_bayer": [[204, 234], ["cfa_pattern.upper.upper", "numpy.dstack", "cfa_pattern.upper.upper", "cfa_pattern.upper.upper", "cfa_pattern.upper.upper", "ValueError"], "function", ["None"], ["", "", "def", "stack_bayer", "(", "image_rgb", ",", "cfa_pattern", ")", ":", "\n", "    ", "\"\"\"\n    Return a RGGB Bayer stack sampled from a RGB image according to a given CFA configuration.\n    :param image_rgb: 3-D numpy array (h, w, 3:rgb)\n    :param cfa_pattern: 'GBRG', 'RGGB' or 'BGGR'\n    \"\"\"", "\n", "cfa_pattern", "=", "cfa_pattern", ".", "upper", "(", ")", "\n", "\n", "if", "cfa_pattern", ".", "upper", "(", ")", "==", "'GBRG'", ":", "\n", "        ", "r", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "\n", "g1", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "g2", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "b", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'RGGB'", ":", "\n", "        ", "r", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "\n", "g1", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "g2", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "b", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'BGGR'", ":", "\n", "        ", "r", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "0", "]", "\n", "g1", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "g2", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "b", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unsupported CFA pattern: {cfa_pattern}\"", ")", "\n", "\n", "", "return", "np", ".", "dstack", "(", "[", "r", ",", "g1", ",", "g2", ",", "b", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.simulate_bayer": [[236, 275], ["numpy.zeros_like", "cfa_pattern.upper.upper", "cfa_pattern.upper.upper", "range", "ValueError", "cfa_pattern.upper.upper", "len", "raw.simulate_bayer", "cfa_pattern.upper.upper", "ValueError"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.simulate_bayer"], ["", "def", "simulate_bayer", "(", "image_rgb", ",", "cfa_pattern", ")", ":", "\n", "    ", "\"\"\"\n    Simulate a Bayer image from full RGB image.\n    :param image_rgb: 3-D numpy array (h, w, 3:rgb) or 4-D image batch\n    :param cfa_pattern: 'GBRG', 'RGGB' or 'BGGR'\n    \"\"\"", "\n", "image_bayer", "=", "np", ".", "zeros_like", "(", "image_rgb", ")", "\n", "cfa_pattern", "=", "cfa_pattern", ".", "upper", "(", ")", "\n", "\n", "if", "image_rgb", ".", "ndim", "==", "3", ":", "\n", "\n", "        ", "if", "cfa_pattern", ".", "upper", "(", ")", "==", "'GBRG'", ":", "\n", "            ", "image_bayer", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "\n", "image_bayer", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'RGGB'", ":", "\n", "            ", "image_bayer", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "\n", "image_bayer", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "\n", "\n", "", "elif", "cfa_pattern", ".", "upper", "(", ")", "==", "'BGGR'", ":", "\n", "            ", "image_bayer", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "0", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "0", "]", "\n", "image_bayer", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "\n", "image_bayer", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "2", "]", "=", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "2", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unsupported CFA pattern: {cfa_pattern}\"", ")", "\n", "\n", "", "", "elif", "image_rgb", ".", "ndim", "==", "4", ":", "\n", "        ", "for", "n", "in", "range", "(", "len", "(", "image_rgb", ")", ")", ":", "\n", "            ", "image_bayer", "[", "n", "]", "=", "simulate_bayer", "(", "image_rgb", "[", "n", "]", ",", "cfa_pattern", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported array shape!'", ")", "\n", "\n", "", "return", "image_bayer", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.raw.merge_bayer": [[277, 320], ["cfa_pattern.upper.upper", "numpy.zeros", "ValueError", "ValueError"], "function", ["None"], ["", "def", "merge_bayer", "(", "bayer_stack", ",", "cfa_pattern", ")", ":", "\n", "    ", "\"\"\"\n    Merge a RGGB Bayer stack into a RGB image.\n    :param bayer_stack: a 3-D numpy array (h/2, w/2, 4:rggb)\n    :param cfa_pattern: 'GBRG', 'RGGB' or 'BGGR'\n    \"\"\"", "\n", "if", "bayer_stack", ".", "ndim", "==", "4", ":", "\n", "\n", "        ", "if", "bayer_stack", ".", "shape", "[", "0", "]", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'4-D arrays are not supported!'", ")", "\n", "\n", "", "bayer_stack", "=", "bayer_stack", "[", "0", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "", "cfa_pattern", "=", "cfa_pattern", ".", "upper", "(", ")", "\n", "\n", "assert", "bayer_stack", ".", "ndim", "==", "3", "\n", "\n", "h", ",", "w", "=", "bayer_stack", ".", "shape", "[", "0", ":", "2", "]", "\n", "\n", "image_rgb", "=", "np", ".", "zeros", "(", "(", "2", "*", "h", ",", "2", "*", "w", ",", "3", ")", ",", "dtype", "=", "bayer_stack", ".", "dtype", ")", "\n", "\n", "if", "cfa_pattern", "==", "'GBRG'", ":", "\n", "        ", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "0", "]", "\n", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "1", "]", "\n", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "2", "]", "\n", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "3", "]", "\n", "\n", "", "elif", "cfa_pattern", "==", "'RGGB'", ":", "\n", "        ", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "0", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "0", "]", "\n", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "1", "]", "\n", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "2", "]", "\n", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "2", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "3", "]", "\n", "\n", "", "elif", "cfa_pattern", "==", "'BGGR'", ":", "\n", "        ", "image_rgb", "[", "1", ":", ":", "2", ",", "1", ":", ":", "2", ",", "0", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "0", "]", "\n", "image_rgb", "[", "0", ":", ":", "2", ",", "1", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "1", "]", "\n", "image_rgb", "[", "1", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "2", "]", "\n", "image_rgb", "[", "0", ":", ":", "2", ",", "0", ":", ":", "2", ",", "1", "]", "=", "bayer_stack", "[", ":", ",", ":", ",", "3", "]", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unsupported CFA pattern: {cfa_pattern}\"", ")", "\n", "\n", "", "return", "image_rgb", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mse": [[31, 33], ["tensorflow.reduce_mean", "tensorflow.math.pow"], "function", ["None"], ["def", "mse", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "math", ".", "pow", "(", "255", "*", "a", "-", "255", "*", "b", ",", "2.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.mae": [[35, 37], ["tensorflow.reduce_mean", "tensorflow.math.abs"], "function", ["None"], ["", "def", "mae", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "math", ".", "abs", "(", "255", "*", "a", "-", "255", "*", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.ssim_loss": [[39, 41], ["tensorflow.reduce_mean", "tensorflow.image.ssim"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim"], ["", "def", "ssim_loss", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "255", "*", "(", "1", "-", "tf", ".", "image", ".", "ssim", "(", "a", ",", "b", ",", "1.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.msssim_loss": [[43, 45], ["tensorflow.reduce_mean", "tensorflow.image.ssim_multiscale"], "function", ["None"], ["", "def", "msssim_loss", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "255", "*", "(", "1", "-", "tf", ".", "image", ".", "ssim_multiscale", "(", "a", ",", "b", ",", "1.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.corr": [[47, 52], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "tensorflow.reduce_mean", "tensorflow.math.reduce_std"], "function", ["None"], ["", "def", "corr", "(", "a", ",", "b", ")", ":", "\n", "    ", "a", "=", "(", "a", "-", "tf", ".", "reduce_mean", "(", "a", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ",", "keepdims", "=", "True", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "a", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ",", "keepdims", "=", "True", ")", ")", "\n", "b", "=", "(", "b", "-", "tf", ".", "reduce_mean", "(", "b", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ",", "keepdims", "=", "True", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "b", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ",", "keepdims", "=", "True", ")", ")", "\n", "c", "=", "tf", ".", "reduce_mean", "(", "a", "*", "b", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.corrcoeff": [[54, 59], ["tensorflow.reduce_mean", "tf.reduce_mean.numpy", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "tensorflow.reduce_mean", "tensorflow.math.reduce_std"], "function", ["None"], ["", "def", "corrcoeff", "(", "a", ",", "b", ")", ":", "\n", "    ", "a", "=", "(", "a", "-", "tf", ".", "reduce_mean", "(", "a", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "a", ")", ")", "\n", "b", "=", "(", "b", "-", "tf", ".", "reduce_mean", "(", "b", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "b", ")", ")", "\n", "c", "=", "tf", ".", "reduce_mean", "(", "a", "*", "b", ")", "\n", "return", "c", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.rsquared": [[61, 66], ["r2_score", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "tensorflow.reduce_mean", "tensorflow.math.reduce_std"], "function", ["None"], ["", "def", "rsquared", "(", "a", ",", "b", ")", ":", "\n", "    ", "from", "sklearn", ".", "metrics", "import", "r2_score", "\n", "a", "=", "(", "a", "-", "tf", ".", "reduce_mean", "(", "a", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "a", ")", ")", "\n", "b", "=", "(", "b", "-", "tf", ".", "reduce_mean", "(", "b", ")", ")", "/", "(", "1e-9", "+", "tf", ".", "math", ".", "reduce_std", "(", "b", ")", ")", "\n", "return", "r2_score", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_resample": [[68, 77], ["tensorflow.image.resize", "tensorflow.image.resize", "int", "int", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "manipulation_resample", "(", "x", ",", "factor", "=", "50", ",", "method", "=", "'bilinear'", ")", ":", "\n", "\n", "    ", "if", "0", "<", "factor", "<=", "1", ":", "\n", "        ", "factor", "=", "100", "*", "factor", "\n", "\n", "", "output_shape", "=", "[", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "*", "int", "(", "factor", ")", "//", "100", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "*", "int", "(", "factor", ")", "//", "100", "]", "\n", "\n", "im_res", "=", "tf", ".", "image", ".", "resize", "(", "x", ",", "output_shape", ",", "method", "=", "method", ")", "\n", "return", "tf", ".", "image", ".", "resize", "(", "im_res", ",", "[", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", "]", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_awgn": [[79, 83], ["tf_helpers.soft_quantization", "tensorflow.clip_by_value", "tensorflow.random.normal", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.soft_quantization"], ["", "def", "manipulation_awgn", "(", "x", ",", "strength", "=", "0.025", ")", ":", "\n", "    ", "im_awgn", "=", "x", "+", "strength", "*", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "x", ")", ")", "\n", "im_awgn", "=", "soft_quantization", "(", "im_awgn", ")", "\n", "return", "tf", ".", "clip_by_value", "(", "im_awgn", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_gamma": [[85, 89], ["tensorflow.pow", "tf_helpers.soft_quantization", "tensorflow.pow", "tensorflow.clip_by_value"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.soft_quantization"], ["", "def", "manipulation_gamma", "(", "x", ",", "strength", "=", "2.0", ")", ":", "\n", "    ", "im_gamma", "=", "tf", ".", "pow", "(", "x", ",", "strength", ")", "\n", "im_gamma", "=", "soft_quantization", "(", "im_gamma", ")", "\n", "return", "tf", ".", "pow", "(", "tf", ".", "clip_by_value", "(", "im_gamma", ",", "1.0", "/", "255", ",", "1", ")", ",", "1", "/", "strength", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_median": [[91, 111], ["int", "max", "tensorflow.pad", "tensorflow.image.extract_patches", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.nn.top_k", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["None"], ["", "def", "manipulation_median", "(", "x", ",", "kernel", "=", "3", ")", ":", "\n", "    ", "kernel", "=", "int", "(", "kernel", ")", "\n", "if", "kernel", "%", "2", "==", "0", ":", "\n", "        ", "kernel", "+=", "1", "\n", "", "kernel", "=", "max", "(", "kernel", ",", "1", ")", "\n", "\n", "xp", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'REFLECT'", ")", "\n", "patches", "=", "tf", ".", "image", ".", "extract_patches", "(", "xp", ",", "[", "1", ",", "kernel", ",", "kernel", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "4", "*", "[", "1", "]", ",", "'VALID'", ")", "\n", "patches", "=", "tf", ".", "reshape", "(", "patches", ",", "[", "tf", ".", "shape", "(", "patches", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "patches", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "patches", ")", "[", "2", "]", ",", "tf", ".", "shape", "(", "patches", ")", "[", "3", "]", "//", "3", ",", "3", "]", ")", "\n", "patches", "=", "tf", ".", "transpose", "(", "patches", ",", "[", "0", ",", "1", ",", "2", ",", "4", ",", "3", "]", ")", "\n", "\n", "area", "=", "kernel", "**", "2", "\n", "floor", "=", "(", "area", "+", "1", ")", "//", "2", "\n", "ceil", "=", "area", "//", "2", "+", "1", "\n", "\n", "top", "=", "tf", ".", "nn", ".", "top_k", "(", "patches", ",", "k", "=", "ceil", ")", ".", "values", "\n", "# The area will always be odd if kernel is odd", "\n", "median", "=", "top", "[", ":", ",", ":", ",", ":", ",", ":", ",", "floor", "-", "1", "]", "\n", "\n", "return", "median", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_gaussian": [[113, 126], ["int", "helpers.kernels.gkern", "numpy.zeros", "range", "tensorflow.constant", "tensorflow.pad", "tensorflow.nn.conv2d", "tensorflow.clip_by_value"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.gkern"], ["", "def", "manipulation_gaussian", "(", "x", ",", "kernel", ",", "std", ",", "skip_clip", "=", "False", ")", ":", "\n", "    ", "kernel", "=", "int", "(", "kernel", ")", "\n", "gk", "=", "gkern", "(", "kernel", ",", "std", ")", "\n", "gfilter", "=", "np", ".", "zeros", "(", "(", "kernel", ",", "kernel", ",", "3", ",", "3", ")", ")", "\n", "for", "r", "in", "range", "(", "3", ")", ":", "\n", "        ", "gfilter", "[", ":", ",", ":", ",", "r", ",", "r", "]", "=", "gk", "\n", "", "gkk", "=", "tf", ".", "constant", "(", "gfilter", ",", "tf", ".", "float32", ")", "\n", "xp", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'REFLECT'", ")", "\n", "y", "=", "tf", ".", "nn", ".", "conv2d", "(", "xp", ",", "gkk", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'VALID'", ")", "\n", "if", "skip_clip", ":", "\n", "        ", "return", "y", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.residual": [[187, 213], ["numpy.array", "helpers.kernels.repeat_2dfilter", "tensorflow.constant", "tensorflow.pad", "tensorflow.nn.conv2d", "ValueError", "tensorflow.image.rgb_to_hsv", "tensorflow.image.hsv_to_rgb"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.repeat_2dfilter"], ["", "def", "residual", "(", "x", ",", "hsv", "=", "False", ")", ":", "\n", "# Prepare the sharpening filter", "\n", "    ", "gk", "=", "np", ".", "array", "(", "[", "[", "-", "0.0833", ",", "-", "0.1667", ",", "-", "0.0833", "]", ",", "[", "-", "0.1667", ",", "1", ",", "-", "0.1667", "]", ",", "[", "-", "0.0833", ",", "-", "0.1667", ",", "-", "0.0833", "]", "]", ")", "\n", "\n", "if", "gk", "is", "None", "or", "gk", ".", "ndim", "!=", "2", "or", "gk", ".", "shape", "[", "0", "]", "!=", "gk", ".", "shape", "[", "1", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid filter! {}'", ".", "format", "(", "gk", ")", ")", "\n", "\n", "", "kernel", "=", "gk", ".", "shape", "[", "0", "]", "\n", "gfilter", "=", "repeat_2dfilter", "(", "gk", ",", "3", ")", "\n", "if", "hsv", ":", "\n", "        ", "gfilter", "[", ":", ",", ":", ",", "1", ":", "2", ",", "1", ":", "2", "]", "=", "0", "\n", "gfilter", "[", "2", ",", "2", ",", "1", ":", "2", ",", "1", ":", "2", "]", "=", "1", "\n", "\n", "", "gkk", "=", "tf", ".", "constant", "(", "gfilter", ",", "tf", ".", "float32", ")", "\n", "\n", "y", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "2", "*", "[", "kernel", "//", "2", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'REFLECT'", ")", "\n", "\n", "if", "hsv", ":", "\n", "        ", "y", "=", "tf", ".", "image", ".", "rgb_to_hsv", "(", "y", ")", "\n", "\n", "", "y", "=", "tf", ".", "nn", ".", "conv2d", "(", "y", ",", "gkk", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n", "if", "hsv", ":", "\n", "        ", "y", "=", "tf", ".", "image", ".", "hsv_to_rgb", "(", "y", ")", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.manipulation_sharpen": [[156, 185], ["numpy.array", "helpers.kernels.repeat_2dfilter", "tensorflow.constant", "tensorflow.pad", "tensorflow.nn.conv2d", "tensorflow.clip_by_value", "numpy.abs", "ValueError", "tensorflow.image.rgb_to_hsv", "tensorflow.image.hsv_to_rgb", "np.array.sum"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.kernels.repeat_2dfilter"], ["", "", "def", "manipulation_sharpen", "(", "x", ",", "strength", "=", "1", ",", "hsv", "=", "True", ")", ":", "\n", "# Prepare the sharpening filter", "\n", "    ", "gk", "=", "np", ".", "array", "(", "[", "[", "-", "0.0833", ",", "-", "0.1667", ",", "-", "0.0833", "]", ",", "[", "-", "0.1667", ",", "0", ",", "-", "0.1667", "]", ",", "[", "-", "0.0833", ",", "-", "0.1667", ",", "-", "0.0833", "]", "]", ")", "\n", "gk", "=", "strength", "*", "gk", "/", "np", ".", "abs", "(", "gk", ".", "sum", "(", ")", ")", "\n", "gk", "[", "1", ",", "1", "]", "=", "strength", "+", "1", "\n", "\n", "if", "gk", "is", "None", "or", "gk", ".", "ndim", "!=", "2", "or", "gk", ".", "shape", "[", "0", "]", "!=", "gk", ".", "shape", "[", "1", "]", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid filter! {}'", ".", "format", "(", "gk", ")", ")", "\n", "\n", "", "kernel", "=", "gk", ".", "shape", "[", "0", "]", "\n", "gfilter", "=", "repeat_2dfilter", "(", "gk", ",", "3", ")", "\n", "if", "hsv", ":", "\n", "        ", "gfilter", "[", ":", ",", ":", ",", "1", ":", "2", ",", "1", ":", "2", "]", "=", "0", "\n", "gfilter", "[", "2", ",", "2", ",", "1", ":", "2", ",", "1", ":", "2", "]", "=", "1", "\n", "\n", "", "gkk", "=", "tf", ".", "constant", "(", "gfilter", ",", "tf", ".", "float32", ")", "\n", "pad", "=", "kernel", "//", "2", "\n", "\n", "y", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", "]", ",", "'SYMMETRIC'", ")", "\n", "\n", "if", "hsv", ":", "\n", "        ", "y", "=", "tf", ".", "image", ".", "rgb_to_hsv", "(", "y", ")", "\n", "\n", "", "y", "=", "tf", ".", "nn", ".", "conv2d", "(", "y", ",", "gkk", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n", "if", "hsv", ":", "\n", "        ", "y", "=", "tf", ".", "image", ".", "hsv_to_rgb", "(", "y", ")", "\n", "\n", "", "return", "tf", ".", "clip_by_value", "(", "y", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers._strip_consts": [[215, 227], ["tensorflow.compat.v1.GraphDef", "tf.compat.v1.GraphDef.node.add", "strip_def.node.add.MergeFrom", "len", "bytes"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add"], ["", "def", "_strip_consts", "(", "graph_def", ",", "max_const_size", "=", "32", ")", ":", "\n", "    ", "\"\"\"Strip large constant values from graph_def.\"\"\"", "\n", "strip_def", "=", "tf", ".", "compat", ".", "v1", ".", "GraphDef", "(", ")", "\n", "for", "n0", "in", "graph_def", ".", "node", ":", "\n", "        ", "n", "=", "strip_def", ".", "node", ".", "add", "(", ")", "\n", "n", ".", "MergeFrom", "(", "n0", ")", "\n", "if", "n", ".", "op", "==", "'Const'", ":", "\n", "            ", "tensor", "=", "n", ".", "attr", "[", "'value'", "]", ".", "tensor", "\n", "size", "=", "len", "(", "tensor", ".", "tensor_content", ")", "\n", "if", "size", ">", "max_const_size", ":", "\n", "                ", "tensor", ".", "tensor_content", "=", "bytes", "(", "\"<stripped %d bytes>\"", "%", "size", ",", "'ascii'", ")", "\n", "", "", "", "return", "strip_def", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.show_model": [[229, 232], ["tensorflow.keras.utils.plot_model"], "function", ["None"], ["", "def", "show_model", "(", "model", ",", "show_shapes", "=", "True", ",", "expand_nested", "=", "False", ")", ":", "\n", "    ", "\"\"\" Generate a static diagram of a tf.keras.Model. \"\"\"", "\n", "return", "tf", ".", "keras", ".", "utils", ".", "plot_model", "(", "model", ",", "show_shapes", "=", "show_shapes", ",", "expand_nested", "=", "expand_nested", ",", "dpi", "=", "72", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.show_graph": [[234, 269], ["isinstance", "hasattr", "tf_helpers._strip_consts", "str", "IPython.display.display", "graph_def.as_graph_def.inputs[].graph.as_graph_def", "tensorflow.compat.v1.get_default_graph().as_graph_def", "graph_def.as_graph_def.as_graph_def", "data.replace.replace", "code.replace", "IPython.display.HTML", "repr", "tensorflow.compat.v1.get_default_graph", "str", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers._strip_consts"], ["", "def", "show_graph", "(", "graph_def", "=", "None", ",", "width", "=", "1200", ",", "height", "=", "800", ",", "max_const_size", "=", "32", ",", "ungroup_gradients", "=", "False", ")", ":", "\n", "    ", "\"\"\" Generate a dynamic visualization of a tf.keras.Model using Tensorboard. \"\"\"", "\n", "\n", "if", "isinstance", "(", "graph_def", ",", "tf", ".", "keras", ".", "Model", ")", ":", "\n", "        ", "graph_def", "=", "graph_def", ".", "inputs", "[", "0", "]", ".", "graph", ".", "as_graph_def", "(", ")", "\n", "\n", "", "if", "not", "graph_def", ":", "\n", "        ", "graph_def", "=", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ".", "as_graph_def", "(", ")", "\n", "\n", "", "\"\"\"Visualize TensorFlow graph.\"\"\"", "\n", "if", "hasattr", "(", "graph_def", ",", "'as_graph_def'", ")", ":", "\n", "        ", "graph_def", "=", "graph_def", ".", "as_graph_def", "(", ")", "\n", "\n", "", "strip_def", "=", "_strip_consts", "(", "graph_def", ",", "max_const_size", "=", "max_const_size", ")", "\n", "data", "=", "str", "(", "strip_def", ")", "\n", "\n", "if", "ungroup_gradients", ":", "\n", "        ", "data", "=", "data", ".", "replace", "(", "'\"gradients/'", ",", "'\"b_'", ")", "\n", "\n", "", "code", "=", "\"\"\"\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        </script>\n        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:{height}px\">\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n        </div>\n    \"\"\"", ".", "format", "(", "data", "=", "repr", "(", "data", ")", ",", "height", "=", "height", ",", "id", "=", "'graph'", "+", "str", "(", "np", ".", "random", ".", "rand", "(", ")", ")", ")", "\n", "\n", "iframe", "=", "\"\"\"\n        <iframe seamless style=\"width:{}px;height:{}px;border:0\" srcdoc=\"{}\"></iframe>\n    \"\"\"", ".", "format", "(", "width", ",", "height", ",", "code", ".", "replace", "(", "'\"'", ",", "'&quot;'", ")", ")", "\n", "display", "(", "HTML", "(", "iframe", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.soft_quantization": [[271, 278], ["tensorflow.subtract", "tensorflow.add", "tensorflow.sin", "tensorflow.stop_gradient", "tensorflow.round"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.add"], ["", "def", "soft_quantization", "(", "x", ",", "alpha", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n     Quantizes a float image with values in [0,1] to simulate uint8 representation.\n    \"\"\"", "\n", "x", "=", "alpha", "*", "x", "\n", "x_", "=", "tf", ".", "subtract", "(", "x", ",", "tf", ".", "sin", "(", "2", "*", "np", ".", "pi", "*", "x", ")", "/", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "return", "tf", ".", "add", "(", "tf", ".", "stop_gradient", "(", "tf", ".", "round", "(", "x", ")", "-", "x_", ")", ",", "x_", ")", "/", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.quantize_and_clip": [[280, 288], ["tensorflow.clip_by_value", "tf_helpers.soft_quantization"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.soft_quantization"], ["", "def", "quantize_and_clip", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Pixel intensity rounding and clipping:\n    1. Quantizes a float image with values in [0,1] to simulate uint8 representation.\n    2. Clip values to [0, 1].\n    :param x: image tensor\n    \"\"\"", "\n", "return", "tf", ".", "clip_by_value", "(", "soft_quantization", "(", "x", ")", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.entropy": [[290, 334], ["tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.exp", "tensorflow.pow", "tensorflow.reduce_sum", "numpy.prod", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.pow", "tensorflow.pow", "tensorflow.math.log"], "function", ["None"], ["", "def", "entropy", "(", "values", ",", "codebook", ",", "v", "=", "50", ",", "gamma", "=", "25", ")", ":", "\n", "    ", "\"\"\"\n    Differentiable entropy approximation. Estimates the entropy of values quantized according to a given codebook.\n    See: https://openreview.net/forum?id=HyxG3p4twS\n\n    :param values: values to be quantized\n    :param codebook: quantization code-book\n    :param v: degrees of freedom for the t-Student kernel; or 0 for the Gaussian kernel\n    :param gamma: gamma parameter of the kernel\n    :return:\n    \"\"\"", "\n", "# For Gaussian, the best parameters are v=0 and gamma=5", "\n", "# for t-Student, the best parameters are v=50 and gamma=25", "\n", "\n", "# t-Student degrees of freedom", "\n", "eps", "=", "1e-72", "\n", "prec_dtype", "=", "tf", ".", "float64", "\n", "\n", "assert", "(", "codebook", ".", "shape", "[", "0", "]", "==", "1", ")", "\n", "assert", "(", "codebook", ".", "shape", "[", "1", "]", ">", "1", ")", "\n", "\n", "values", "=", "tf", ".", "reshape", "(", "values", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "# Compute soft-quantization", "\n", "if", "v", "<=", "0", ":", "\n", "        ", "dff", "=", "tf", ".", "cast", "(", "values", ",", "dtype", "=", "prec_dtype", ")", "-", "tf", ".", "cast", "(", "codebook", ",", "dtype", "=", "prec_dtype", ")", "\n", "weights", "=", "tf", ".", "exp", "(", "-", "gamma", "*", "tf", ".", "pow", "(", "dff", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "# t-Student-like distance measure with heavy tails", "\n", "        ", "dff", "=", "tf", ".", "cast", "(", "values", ",", "dtype", "=", "prec_dtype", ")", "-", "tf", ".", "cast", "(", "codebook", ",", "dtype", "=", "prec_dtype", ")", "\n", "dff", "=", "gamma", "*", "dff", "\n", "weights", "=", "tf", ".", "pow", "(", "(", "1", "+", "tf", ".", "pow", "(", "dff", ",", "2", ")", "/", "v", ")", ",", "-", "(", "v", "+", "1", ")", "/", "2", ")", "\n", "\n", "", "weights", "=", "(", "weights", "+", "eps", ")", "/", "(", "tf", ".", "reduce_sum", "(", "weights", "+", "eps", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "assert", "(", "weights", ".", "shape", "[", "1", "]", "==", "np", ".", "prod", "(", "codebook", ".", "shape", ")", ")", "\n", "\n", "# Compute soft histogram", "\n", "histogram", "=", "tf", ".", "reduce_mean", "(", "weights", ",", "axis", "=", "0", ")", "\n", "histogram", "=", "tf", ".", "clip_by_value", "(", "histogram", ",", "1e-9", ",", "tf", ".", "float32", ".", "max", ")", "\n", "histogram", "=", "histogram", "/", "tf", ".", "reduce_sum", "(", "histogram", ")", "\n", "entropy", "=", "-", "tf", ".", "reduce_sum", "(", "histogram", "*", "tf", ".", "math", ".", "log", "(", "histogram", ")", ")", "/", "0.6931", "# 0.6931 - log(2)", "\n", "entropy", "=", "tf", ".", "cast", "(", "entropy", ",", "tf", ".", "float32", ")", "\n", "\n", "return", "entropy", ",", "histogram", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.print_versions": [[336, 339], ["print", "print", "tensorflow.config.list_physical_devices"], "function", ["None"], ["", "def", "print_versions", "(", ")", ":", "\n", "    ", "print", "(", "'Tensorflow:'", ",", "tf", ".", "__version__", ")", "\n", "print", "(", "'GPUs:'", ",", "tf", ".", "config", ".", "list_physical_devices", "(", "'GPU'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.disable_warnings": [[340, 342], ["None"], "function", ["None"], ["", "def", "disable_warnings", "(", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'TF_CPP_MIN_LOG_LEVEL'", "]", "=", "'3'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.tf_helpers.disable_gpu": [[343, 345], ["tensorflow.config.set_visible_devices"], "function", ["None"], ["", "def", "disable_gpu", "(", ")", ":", "\n", "    ", "tf", ".", "config", ".", "set_visible_devices", "(", "[", "]", ",", "'GPU'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.imdiff.compare_images_ab_ref": [[11, 68], ["img_a.squeeze.squeeze", "img_b.squeeze.squeeze", "img_ref.squeeze.squeeze", "helpers.plots.sub", "helpers.plots.image", "helpers.plots.image", "helpers.plots.image", "axes[].get_shared_x_axes().join", "axes[].get_shared_x_axes().join", "axes[].get_shared_y_axes().join", "axes[].get_shared_y_axes().join", "numpy.abs", "image.normalize.mean", "helpers.image.normalize", "numpy.abs", "image.normalize.mean", "helpers.image.normalize", "numpy.abs", "image.normalize.mean", "helpers.image.normalize", "helpers.plots.image", "helpers.plots.image", "helpers.plots.image", "helpers.image.fft_log_norm", "helpers.image.fft_log_norm", "helpers.image.normalize", "helpers.plots.image", "helpers.plots.image", "helpers.plots.image", "helpers.metrics.psnr", "helpers.metrics.ssim", "helpers.metrics.psnr", "helpers.metrics.ssim", "numpy.abs", "axes[].get_shared_x_axes", "axes[].get_shared_x_axes", "axes[].get_shared_y_axes", "axes[].get_shared_y_axes", "helpers.image.fft_log_norm", "helpers.image.fft_log_norm"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.fft_log_norm", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.fft_log_norm", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.fft_log_norm", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.fft_log_norm"], ["def", "compare_images_ab_ref", "(", "img_ref", ",", "img_a", ",", "img_b", ",", "labels", "=", "None", ",", "extras", "=", "False", ",", "fig", "=", "None", ")", ":", "\n", "\n", "    ", "labels", "=", "labels", "or", "[", "'target'", ",", "''", ",", "''", "]", "\n", "\n", "img_a", "=", "img_a", ".", "squeeze", "(", ")", "\n", "img_b", "=", "img_b", ".", "squeeze", "(", ")", "\n", "img_ref", "=", "img_ref", ".", "squeeze", "(", ")", "\n", "\n", "fig", ",", "axes", "=", "plots", ".", "sub", "(", "9", "if", "extras", "else", "3", ",", "ncols", "=", "3", ",", "fig", "=", "fig", ")", "\n", "# Index of the last axes ", "\n", "j", "=", "3", "if", "extras", "else", "2", "\n", "\n", "plots", ".", "image", "(", "img_ref", ",", "'(T) {}'", ".", "format", "(", "labels", "[", "0", "]", ")", ",", "axes", "=", "axes", "[", "0", "]", ")", "\n", "\n", "label_a", "=", "'(A) {}: {:.1f} dB / {:.3f}'", ".", "format", "(", "labels", "[", "1", "]", ",", "metrics", ".", "psnr", "(", "img_ref", ",", "img_a", ")", ",", "metrics", ".", "ssim", "(", "img_ref", ",", "img_a", ")", ")", "\n", "plots", ".", "image", "(", "img_a", ",", "label_a", ",", "axes", "=", "axes", "[", "1", "]", ")", "\n", "\n", "label_b", "=", "'(B) {}: {:.1f} dB / {:.3f}'", ".", "format", "(", "labels", "[", "2", "]", ",", "metrics", ".", "psnr", "(", "img_ref", ",", "img_b", ")", ",", "metrics", ".", "ssim", "(", "img_ref", ",", "img_b", ")", ")", "\n", "plots", ".", "image", "(", "img_b", ",", "label_b", ",", "axes", "=", "axes", "[", "j", "]", ")", "\n", "\n", "# A hack to allow image axes to zoom together", "\n", "axes", "[", "1", "]", ".", "get_shared_x_axes", "(", ")", ".", "join", "(", "axes", "[", "0", "]", ",", "axes", "[", "1", "]", ")", "\n", "axes", "[", "j", "]", ".", "get_shared_x_axes", "(", ")", ".", "join", "(", "axes", "[", "0", "]", ",", "axes", "[", "j", "]", ")", "\n", "axes", "[", "1", "]", ".", "get_shared_y_axes", "(", ")", ".", "join", "(", "axes", "[", "0", "]", ",", "axes", "[", "1", "]", ")", "\n", "axes", "[", "j", "]", ".", "get_shared_y_axes", "(", ")", ".", "join", "(", "axes", "[", "0", "]", ",", "axes", "[", "j", "]", ")", "\n", "\n", "if", "not", "extras", ":", "\n", "        ", "return", "fig", "\n", "\n", "# Compute and plot difference images", "\n", "", "diff_a", "=", "np", ".", "abs", "(", "img_a", "-", "img_ref", ")", "\n", "diff_a_mean", "=", "diff_a", ".", "mean", "(", ")", "\n", "diff_a", "=", "image", ".", "normalize", "(", "diff_a", ",", "0.1", ")", "\n", "\n", "diff_b", "=", "np", ".", "abs", "(", "img_b", "-", "img_ref", ")", "\n", "diff_b_mean", "=", "diff_b", ".", "mean", "(", ")", "\n", "diff_b", "=", "image", ".", "normalize", "(", "diff_b", ",", "0.1", ")", "\n", "\n", "diff_ab", "=", "np", ".", "abs", "(", "img_b", "-", "img_a", ")", "\n", "diff_ab_mean", "=", "diff_ab", ".", "mean", "(", ")", "\n", "diff_ab", "=", "image", ".", "normalize", "(", "diff_ab", ",", "0.1", ")", "\n", "\n", "plots", ".", "image", "(", "diff_a", ",", "'T - A: mean abs {:.3f}'", ".", "format", "(", "diff_a_mean", ")", ",", "axes", "=", "axes", "[", "2", "]", ")", "\n", "plots", ".", "image", "(", "diff_b", ",", "'T - B: mean abs {:.3f}'", ".", "format", "(", "diff_b_mean", ")", ",", "axes", "=", "axes", "[", "6", "]", ")", "\n", "plots", ".", "image", "(", "diff_ab", ",", "'A - B: mean abs {:.3f}'", ".", "format", "(", "diff_ab_mean", ")", ",", "axes", "=", "axes", "[", "4", "]", ")", "\n", "\n", "# Compute and plot spectra", "\n", "fft_a", "=", "fft_log_norm", "(", "diff_a", ")", "\n", "fft_b", "=", "fft_log_norm", "(", "diff_b", ")", "\n", "\n", "# fft_ab = utils.normalize(np.abs(fft_a - fft_b))", "\n", "fft_ab", "=", "image", ".", "normalize", "(", "np", ".", "abs", "(", "fft_log_norm", "(", "img_b", ")", "-", "fft_log_norm", "(", "img_a", ")", ")", ",", "0.01", ")", "\n", "plots", ".", "image", "(", "fft_a", ",", "'FFT(T - A)'", ",", "axes", "=", "axes", "[", "5", "]", ")", "\n", "plots", ".", "image", "(", "fft_b", ",", "'FFT(T - B)'", ",", "axes", "=", "axes", "[", "7", "]", ")", "\n", "plots", ".", "image", "(", "fft_ab", ",", "'FFT(A) - FFT(B)'", ",", "axes", "=", "axes", "[", "8", "]", ")", "\n", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.imdiff.compare_batches": [[70, 99], ["min", "helpers.plots.sub", "enumerate", "len", "len", "zip", "helpers.plots.image", "helpers.metrics.psnr", "helpers.metrics.ssim", "helpers.plots.image", "numpy.abs", "diff_ab.mean", "helpers.plots.image", "helpers.plots.image", "helpers.image.normalize", "helpers.image.normalize"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.psnr", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.metrics.ssim", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.image", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize"], ["", "def", "compare_batches", "(", "batch_a", ",", "batch_b", ",", "labels", "=", "None", ",", "fig", "=", "None", ",", "figwidth", "=", "4", ",", "nrows", "=", "3", ",", "transpose", "=", "False", ")", ":", "\n", "\n", "    ", "n_images", "=", "min", "(", "len", "(", "batch_a", ")", ",", "len", "(", "batch_b", ")", ")", "\n", "\n", "labels", "=", "labels", "or", "[", "''", ",", "''", "]", "\n", "\n", "fig", ",", "axes", "=", "plots", ".", "sub", "(", "n_images", "*", "nrows", ",", "figwidth", ",", "ncols", "=", "n_images", ",", "fig", "=", "fig", ",", "transpose", "=", "transpose", ")", "\n", "\n", "for", "i", ",", "(", "img_a", ",", "img_b", ")", "in", "enumerate", "(", "zip", "(", "batch_a", ",", "batch_b", ")", ")", ":", "\n", "\n", "        ", "label_a", "=", "f'(A) {labels[0]}'", "\n", "plots", ".", "image", "(", "img_a", ",", "label_a", ",", "axes", "=", "axes", "[", "i", "+", "n_images", "*", "0", "]", ")", "\n", "\n", "psnr", "=", "metrics", ".", "psnr", "(", "img_a", ",", "img_b", ")", "\n", "ssim", "=", "metrics", ".", "ssim", "(", "img_a", ",", "img_b", ")", "\n", "label_b", "=", "f'(B) {labels[1]}: {psnr:.1f} dB / {ssim:.3f}'", "\n", "plots", ".", "image", "(", "img_b", ",", "label_b", ",", "axes", "=", "axes", "[", "i", "+", "n_images", "*", "1", "]", ")", "\n", "\n", "diff_ab", "=", "img_b", "-", "img_a", "\n", "diff_abs", "=", "np", ".", "abs", "(", "img_b", "-", "img_a", ")", "\n", "diff_mean", "=", "diff_ab", ".", "mean", "(", ")", "\n", "\n", "if", "nrows", ">", "2", ":", "\n", "            ", "plots", ".", "image", "(", "image", ".", "normalize", "(", "diff_ab", ")", ",", "f'A - B: mean abs {diff_mean:.3f}'", ",", "axes", "=", "axes", "[", "i", "+", "n_images", "*", "2", "]", ")", "\n", "\n", "", "if", "nrows", ">", "3", ":", "\n", "            ", "plots", ".", "image", "(", "image", ".", "normalize", "(", "diff_abs", ",", "0.1", ")", ",", "f'|A - B|: mean abs {diff_mean:.3f}'", ",", "axes", "=", "axes", "[", "i", "+", "n_images", "*", "3", "]", ")", "\n", "\n", "", "", "return", "fig", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir": [[13, 24], ["os.path.expanduser", "sorted", "os.listdir", "re.match", "os.path.isdir", "os.path.join"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.listdir"], ["def", "listdir", "(", "path", ",", "regex", "=", "'.*\\..*'", ",", "dirs_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Returns a list of filenames in a directory matching a given regex.\n    Example: listdir('~/datasets/raise/', '.*\\.NEF$')\n    \"\"\"", "\n", "path", "=", "os", ".", "path", ".", "expanduser", "(", "path", ")", "\n", "candidates", "=", "sorted", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "path", ")", "if", "re", ".", "match", "(", "regex", ",", "f", ",", "re", ".", "IGNORECASE", ")", "]", ")", "\n", "if", "not", "dirs_only", ":", "\n", "        ", "return", "candidates", "\n", "", "else", ":", "\n", "        ", "return", "[", "f", "for", "f", "in", "candidates", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split": [[26, 41], ["os.path.split", "allparts.insert", "allparts.insert", "allparts.insert"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split"], ["", "", "def", "split", "(", "path", ")", ":", "\n", "    ", "\"\"\" Split path to individual directories: '/home/user/dir' ->  ['/', 'home', 'user', 'dir'] \"\"\"", "\n", "allparts", "=", "[", "]", "\n", "while", "1", ":", "\n", "        ", "parts", "=", "os", ".", "path", ".", "split", "(", "path", ")", "\n", "if", "parts", "[", "0", "]", "==", "path", ":", "# sentinel for absolute paths", "\n", "            ", "allparts", ".", "insert", "(", "0", ",", "parts", "[", "0", "]", ")", "\n", "break", "\n", "", "elif", "parts", "[", "1", "]", "==", "path", ":", "# sentinel for relative paths", "\n", "            ", "allparts", ".", "insert", "(", "0", ",", "parts", "[", "1", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "            ", "path", "=", "parts", "[", "0", "]", "\n", "allparts", ".", "insert", "(", "0", ",", "parts", "[", "1", "]", ")", "\n", "", "", "return", "allparts", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.strip_prefix": [[43, 55], ["os.path.commonprefix", "os.path.commonprefix", "os.path.commonprefix.endswith", "postfix.startswith", "x.replace().replace", "x.replace", "os.path.commonprefix.rfind", "postfix.find"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.results_data.ResultCache.find"], ["", "def", "strip_prefix", "(", "names", ")", ":", "\n", "    ", "\"\"\" Removes common pre-fixes and post-fixes from a list of strings. \"\"\"", "\n", "prefix", "=", "os", ".", "path", ".", "commonprefix", "(", "names", ")", "\n", "postfix", "=", "os", ".", "path", ".", "commonprefix", "(", "[", "x", "[", ":", ":", "-", "1", "]", "for", "x", "in", "names", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "if", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "\n", "        ", "prefix", "=", "prefix", "[", ":", "prefix", ".", "rfind", "(", "'/'", ")", "+", "1", "]", "\n", "\n", "", "if", "not", "postfix", ".", "startswith", "(", "'/'", ")", ":", "\n", "        ", "postfix", "=", "postfix", "[", "postfix", ".", "find", "(", "'/'", ")", "+", "1", ":", "]", "\n", "\n", "", "return", "[", "x", ".", "replace", "(", "prefix", ",", "''", ")", ".", "replace", "(", "postfix", ",", "''", ")", "for", "x", "in", "names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.sanitize": [[57, 59], ["re.sub().strip", "re.sub"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.sub"], ["", "def", "sanitize", "(", "name", ",", "sub", "=", "'_'", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "'[ ~*!+#@\":\"!<>\\[\\]]+'", ",", "sub", ",", "name", ")", ".", "strip", "(", "sub", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.setup_logging": [[30, 52], ["loguru.logger.configure", "config[].append"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.plots.configure"], ["def", "setup_logging", "(", "filename", "=", "None", ",", "long_date", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Configure the logger to a compact format.\n    :param filename: add an additional sink to the given file\n    :param long_date: flag to choose a full or compact date format\n    \"\"\"", "\n", "\n", "if", "long_date", ":", "\n", "        ", "log_format", "=", "'{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}'", "\n", "", "else", ":", "\n", "        ", "log_format", "=", "'{time:HH:mm:ss} | {level} | {message}'", "\n", "\n", "", "config", "=", "{", "\n", "\"handlers\"", ":", "[", "\n", "{", "\"sink\"", ":", "sys", ".", "stderr", ",", "\"format\"", ":", "log_format", "}", "\n", "]", ",", "\n", "}", "\n", "\n", "if", "filename", "is", "not", "None", ":", "\n", "        ", "config", "[", "'handlers'", "]", ".", "append", "(", "{", "\"sink\"", ":", "\"file.log\"", ",", "\"serialize\"", ":", "True", "}", ")", "\n", "\n", "", "logger", ".", "configure", "(", "**", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number": [[54, 56], ["type"], "function", ["None"], ["", "def", "is_number", "(", "value", ")", ":", "\n", "    ", "return", "type", "(", "value", ")", "in", "_numeric_types", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_numeric_type": [[58, 60], ["None"], "function", ["None"], ["", "def", "is_numeric_type", "(", "t", ")", ":", "\n", "    ", "return", "t", "in", "_numeric_types", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_nan": [[62, 70], ["utils.is_number", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["", "def", "is_nan", "(", "value", ")", ":", "\n", "    ", "if", "value", "is", "None", ":", "\n", "        ", "return", "True", "\n", "\n", "", "if", "is_number", "(", "value", ")", ":", "\n", "        ", "return", "np", ".", "isnan", "(", "value", ")", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_vector": [[72, 80], ["isinstance", "all", "isinstance", "utils.is_number"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_number"], ["", "def", "is_vector", "(", "data", ")", ":", "\n", "\n", "    ", "if", "isinstance", "(", "data", ",", "list", ")", "and", "all", "(", "is_number", "(", "x", ")", "for", "x", "in", "data", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", "and", "data", ".", "ndim", "==", "1", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number_order": [[82, 87], ["float", "max", "min", "int", "len", "numpy.floor", "numpy.log10", "abs"], "function", ["None"], ["", "", "def", "format_number_order", "(", "n", ")", ":", "\n", "    ", "n", "=", "float", "(", "n", ")", "\n", "suffix", "=", "(", "''", ",", "'k'", ",", "'M'", ",", "'B'", ",", "'T'", ")", "\n", "idx", "=", "max", "(", "0", ",", "min", "(", "len", "(", "suffix", ")", "-", "1", ",", "int", "(", "np", ".", "floor", "(", "0", "if", "n", "==", "0", "else", "np", ".", "log10", "(", "abs", "(", "n", ")", ")", "/", "3", ")", ")", ")", ")", "\n", "return", "f'{n / 10**(3 * idx):.0f}{suffix[idx]}'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number": [[89, 105], ["numpy.isnan", "numpy.isinf", "isinstance", "max", "max", "int", "numpy.floor", "numpy.int", "numpy.log10", "numpy.floor", "numpy.abs", "numpy.log10", "numpy.abs"], "function", ["None"], ["", "def", "format_number", "(", "x", ",", "digits", "=", "3", ")", ":", "\n", "    ", "if", "np", ".", "isnan", "(", "x", ")", ":", "\n", "        ", "return", "'nan'", "\n", "\n", "", "if", "np", ".", "isinf", "(", "x", ")", ":", "\n", "        ", "return", "'\u221e'", "\n", "\n", "", "try", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", "and", "x", "!=", "0", ":", "\n", "            ", "w", "=", "max", "(", "0", ",", "int", "(", "np", ".", "floor", "(", "np", ".", "log10", "(", "np", ".", "abs", "(", "x", ")", ")", ")", ")", ")", "+", "(", "digits", "-", "1", ")", "\n", "p", "=", "max", "(", "0", ",", "-", "np", ".", "int", "(", "np", ".", "floor", "(", "np", ".", "log10", "(", "np", ".", "abs", "(", "x", ")", ")", ")", ")", ")", "+", "(", "digits", "-", "1", ")", "\n", "return", "f'{x:{w}.{p}f}'", "\n", "", "else", ":", "\n", "            ", "return", "f'{x}'", "\n", "", "", "except", ":", "\n", "        ", "return", "'?'", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.match_option": [[107, 124], ["len", "ValueError", "sum", "re.match", "y.startswith", "x.startswith", "Levenshtein.distance", "start_match.index", "distances.index", "min"], "function", ["None"], ["", "", "def", "match_option", "(", "x", ",", "options", ",", "regexp", "=", "False", ")", ":", "\n", "\n", "    ", "if", "regexp", ":", "\n", "        ", "matches", "=", "[", "y", "for", "y", "in", "options", "if", "re", ".", "match", "(", "x", ",", "y", ")", "]", "\n", "if", "len", "(", "matches", ")", "==", "1", ":", "\n", "            ", "return", "matches", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'No regexp match: \"{x}\" to any of {options}!'", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "start_match", "=", "[", "y", ".", "startswith", "(", "x", ")", "or", "x", ".", "startswith", "(", "y", ")", "for", "y", "in", "options", "]", "\n", "\n", "if", "sum", "(", "start_match", ")", "==", "1", ":", "\n", "            ", "return", "options", "[", "start_match", ".", "index", "(", "True", ")", "]", "\n", "", "else", ":", "\n", "            ", "distances", "=", "[", "Levenshtein", ".", "distance", "(", "x", ",", "y", ")", "for", "y", "in", "options", "]", "\n", "return", "options", "[", "distances", ".", "index", "(", "min", "(", "distances", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.logCall": [[126, 151], ["list", "print", "func", "zip", "list.append", "list.append", "len", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "logCall", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Decorator to print function call details - parameters names and effective values\n    \"\"\"", "\n", "def", "wrapper", "(", "*", "func_args", ",", "**", "func_kwargs", ")", ":", "\n", "        ", "arg_names", "=", "func", ".", "__code__", ".", "co_varnames", "[", ":", "func", ".", "__code__", ".", "co_argcount", "]", "\n", "args", "=", "func_args", "[", ":", "len", "(", "arg_names", ")", "]", "\n", "defaults", "=", "func", ".", "__defaults__", "or", "(", ")", "\n", "args", "=", "args", "+", "defaults", "[", "len", "(", "defaults", ")", "-", "(", "func", ".", "__code__", ".", "co_argcount", "-", "len", "(", "args", ")", ")", ":", "]", "\n", "params", "=", "list", "(", "zip", "(", "arg_names", ",", "args", ")", ")", "\n", "args", "=", "func_args", "[", "len", "(", "arg_names", ")", ":", "]", "\n", "\n", "if", "args", ":", "\n", "            ", "params", ".", "append", "(", "(", "'args'", ",", "args", ")", ")", "\n", "\n", "", "if", "func_kwargs", ":", "\n", "            ", "params", ".", "append", "(", "(", "'kwargs'", ",", "func_kwargs", ")", ")", "\n", "\n", "# Print function call", "\n", "", "print", "(", "'@> '", "+", "func", ".", "__name__", "+", "' ('", "+", "', '", ".", "join", "(", "'%s = %r'", "%", "p", "for", "p", "in", "params", ")", "+", "' )'", ")", "\n", "\n", "# Actual function call", "\n", "return", "func", "(", "*", "func_args", ",", "**", "func_kwargs", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.mockCall": [[153, 175], ["list", "print", "zip", "list.append", "list.append", "len", "len", "len", "len"], "function", ["None"], ["", "def", "mockCall", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Decorator to print function call details but skip the actual call.\n    \"\"\"", "\n", "def", "wrapper", "(", "*", "func_args", ",", "**", "func_kwargs", ")", ":", "\n", "        ", "arg_names", "=", "func", ".", "__code__", ".", "co_varnames", "[", ":", "func", ".", "__code__", ".", "co_argcount", "]", "\n", "args", "=", "func_args", "[", ":", "len", "(", "arg_names", ")", "]", "\n", "defaults", "=", "func", ".", "__defaults__", "or", "(", ")", "\n", "args", "=", "args", "+", "defaults", "[", "len", "(", "defaults", ")", "-", "(", "func", ".", "__code__", ".", "co_argcount", "-", "len", "(", "args", ")", ")", ":", "]", "\n", "params", "=", "list", "(", "zip", "(", "arg_names", ",", "args", ")", ")", "\n", "args", "=", "func_args", "[", "len", "(", "arg_names", ")", ":", "]", "\n", "\n", "if", "args", ":", "\n", "            ", "params", ".", "append", "(", "(", "'args'", ",", "args", ")", ")", "\n", "\n", "", "if", "func_kwargs", ":", "\n", "            ", "params", ".", "append", "(", "(", "'kwargs'", ",", "func_kwargs", ")", ")", "\n", "\n", "# Print function call", "\n", "", "print", "(", "'@! '", "+", "func", ".", "__name__", "+", "' ('", "+", "', '", ".", "join", "(", "'%s = %r'", "%", "p", "for", "p", "in", "params", ")", "+", "' )'", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.is_interactive": [[177, 187], ["hasattr"], "function", ["None"], ["", "def", "is_interactive", "(", ")", ":", "\n", "    ", "\"\"\"\n    Checks whether you're working in an interactive terminal (e.g., Jupyter notebook)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "__IPYTHON__", "\n", "return", "True", "\n", "", "except", ":", "\n", "        ", "import", "__main__", "as", "main", "\n", "return", "not", "hasattr", "(", "main", ",", "'__file__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get": [[189, 194], ["functools.reduce", "key.split", "c.get"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.fsutil.split", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.get"], ["", "", "def", "get", "(", "data", ",", "key", ",", "default", "=", "None", ",", "sep", "=", "'.'", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "reduce", "(", "lambda", "c", ",", "k", ":", "c", ".", "get", "(", "k", ",", "{", "}", ")", ",", "key", ".", "split", "(", "sep", ")", ",", "data", ")", "\n", "", "except", "KeyError", ":", "\n", "        ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.join_args": [[196, 198], ["sep.join", "args.items", "isinstance"], "function", ["None"], ["", "", "def", "join_args", "(", "args", ",", "sep", "=", "','", ")", ":", "\n", "    ", "return", "sep", ".", "join", "(", "'{}={}'", ".", "format", "(", "k", ",", "'\"{}\"'", ".", "format", "(", "v", ")", "if", "isinstance", "(", "v", ",", "str", ")", "else", "v", ")", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.printd": [[200, 255], ["print", "max", "any", "d.items", "print", "print", "len", "print", "print", "isinstance", "len", "isinstance", "print", "print", "utils.printd", "hasattr", "d.keys", "d.keys", "isinstance", "print", "print", "isinstance", "len", "print", "print", "isinstance", "len", "print", "print", "len", "print", "print", "isinstance", "isinstance", "print", "print", "v.min", "v.max", "utils.format_number", "len", "utils.format_number", "utils.format_number", "len", "utils.format_number", "utils.format_number"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.printd", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.paramspec.ParamSpec.keys", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number", "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_number"], ["", "def", "printd", "(", "d", ",", "indent", "=", "2", ",", "level", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prints a concise summary of a dict-like object (arrays/tensors are not displayed - only their shape) \"\"\"", "\n", "if", "len", "(", "d", ")", "==", "0", ":", "\n", "        ", "print", "(", "'{}'", ")", "\n", "return", "\n", "\n", "", "print", "(", "'{'", ")", "\n", "\n", "width", "=", "max", "(", "[", "len", "(", "f'{k}'", ")", "for", "k", "in", "d", ".", "keys", "(", ")", "]", ")", "\n", "has_dicts", "=", "any", "(", "[", "isinstance", "(", "d", "[", "k", "]", ",", "dict", ")", "for", "k", "in", "d", ".", "keys", "(", ")", "]", ")", "\n", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "\n", "# Print the key (align to the left if there are nested dicts, otherwise to the right)", "\n", "        ", "print", "(", "(", "indent", "*", "level", ")", "*", "' '", ",", "end", "=", "''", ")", "\n", "if", "has_dicts", ":", "\n", "            ", "print", "(", "f'{k:<{width}}: '", ",", "end", "=", "''", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f'{k:>{width}}: '", ",", "end", "=", "''", ")", "\n", "\n", "# Print the values, depending on their type", "\n", "", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "            ", "printd", "(", "v", ",", "indent", "=", "indent", ",", "level", "=", "level", "+", "1", ")", "\n", "\n", "", "elif", "hasattr", "(", "v", ",", "'shape'", ")", ":", "\n", "            ", "if", "v", ".", "ndim", "==", "0", ":", "\n", "                ", "print", "(", "f'{v:.3f} (0-d array)'", ")", "\n", "", "elif", "len", "(", "v", ")", "==", "0", ":", "\n", "                ", "print", "(", "f'empty array'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f'array {v.shape} \u2208 [{v.min():.3f}, {v.max():.3f}]'", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "v", ",", "str", ")", ":", "\n", "            ", "print", "(", "'\"{}\"'", ".", "format", "(", "v", ")", ")", "\n", "\n", "", "elif", "isinstance", "(", "v", ",", "list", ")", ":", "\n", "            ", "if", "len", "(", "v", ")", "<", "5", ":", "\n", "                ", "print", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f'list of {len(v)} items: [{format_number(v[0])}, ..., {format_number(v[-1])}]'", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "v", ",", "tuple", ")", ":", "\n", "            ", "if", "len", "(", "v", ")", "<", "5", ":", "\n", "                ", "print", "(", "v", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f'tuple of {len(v)} items: ({format_number(v[0])}, ..., {format_number(v[-1])})'", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "float", ")", "or", "isinstance", "(", "v", ",", "int", ")", ":", "\n", "                ", "print", "(", "format_number", "(", "v", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "v", ")", "\n", "\n", "", "", "", "print", "(", "(", "indent", "*", "(", "level", "-", "1", ")", ")", "*", "' '", ",", "end", "=", "''", ")", "\n", "print", "(", "'}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.format_patch_shape": [[257, 264], ["any", "str"], "function", ["None"], ["", "def", "format_patch_shape", "(", "patch_size", ")", ":", "\n", "    ", "if", "patch_size", "is", "None", ":", "\n", "        ", "return", "'?'", "\n", "", "elif", "any", "(", "x", "is", "None", "for", "x", "in", "patch_size", ")", ":", "\n", "        ", "return", "'(rgb)'", "if", "patch_size", "[", "-", "1", "]", "==", "3", "else", "'(raw)'", "\n", "", "else", ":", "\n", "        ", "return", "'\u00d7'", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "patch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.utils.shell": [[266, 298], ["subprocess.Popen.communicate", "subprocess.Popen.wait", "loguru.logger.info", "subprocess.Popen", "subprocess.Popen", "open", "outs.decode().splitlines", "open", "errs.decode().replace().splitlines", "print", "print", "print", "fo.write", "fe.write", "outs.decode", "errs.decode().replace", "errs.decode"], "function", ["None"], ["", "", "def", "shell", "(", "command", ",", "log", "=", "None", ",", "verbosity", "=", "2", ")", ":", "\n", "\n", "    ", "if", "verbosity", "==", "2", ":", "\n", "        ", "logger", ".", "info", "(", "f'>> {command}'", ")", "\n", "", "elif", "verbosity", "==", "1", ":", "\n", "        ", "if", "log", "is", "not", "None", ":", "\n", "            ", "print", "(", "f'\\n>> {command} \\\\'", ")", "\n", "print", "(", "f'   1> {log}.stdout 2> {log}.stderr'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f'\\n>> {command}\\n'", ")", "\n", "\n", "", "", "if", "log", "is", "None", ":", "\n", "        ", "p", "=", "subprocess", ".", "Popen", "(", "command", ",", "shell", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "p", "=", "subprocess", ".", "Popen", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "\n", "", "outs", ",", "errs", "=", "p", ".", "communicate", "(", ")", "\n", "\n", "if", "log", "is", "not", "None", ":", "\n", "\n", "        ", "assert", "outs", "is", "not", "None", ",", "'The output from the sub-process is null'", "\n", "\n", "with", "open", "(", "f'{log}.stdout'", ",", "'w'", ")", "as", "fo", ":", "\n", "            ", "for", "line", "in", "outs", ".", "decode", "(", "'utf-8'", ")", ".", "splitlines", "(", ")", ":", "\n", "                ", "fo", ".", "write", "(", "f'{line}\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "f'{log}.stderr'", ",", "'w'", ")", "as", "fe", ":", "\n", "            ", "for", "line", "in", "errs", ".", "decode", "(", "'utf-8'", ")", ".", "replace", "(", "'\\r'", ",", "'\\n'", ")", ".", "splitlines", "(", ")", ":", "\n", "                ", "fe", ".", "write", "(", "f'{line}\\n'", ")", "\n", "\n", "", "", "", "p", ".", "wait", "(", ")", "\n", "return", "p", ".", "returncode", "\n", "", ""]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.sliding_window": [[9, 20], ["numpy.zeros", "range", "ValueError", "range"], "function", ["None"], ["def", "sliding_window", "(", "arr", ",", "window", ")", ":", "\n", "    ", "if", "arr", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "'The input array needs to be 3-D - (h,w,c)!'", ")", "\n", "", "n_windows", "=", "(", "arr", ".", "shape", "[", "0", "]", "//", "window", ")", "*", "(", "arr", ".", "shape", "[", "1", "]", "//", "window", ")", "\n", "batch", "=", "np", ".", "zeros", "(", "(", "n_windows", ",", "window", ",", "window", ",", "arr", ".", "shape", "[", "-", "1", "]", ")", ",", "dtype", "=", "arr", ".", "dtype", ")", "\n", "window_id", "=", "0", "\n", "for", "x", "in", "range", "(", "arr", ".", "shape", "[", "1", "]", "//", "window", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "arr", ".", "shape", "[", "0", "]", "//", "window", ")", ":", "\n", "            ", "batch", "[", "window_id", "]", "=", "arr", "[", "y", "*", "window", ":", "(", "y", "+", "1", ")", "*", "window", ",", "x", "*", "window", ":", "(", "x", "+", "1", ")", "*", "window", ",", ":", "]", "\n", "window_id", "+=", "1", "\n", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.batch_gamma": [[22, 29], ["numpy.power().clip", "numpy.array", "numpy.random.uniform", "type", "numpy.power", "numpy.ones", "len", "len"], "function", ["None"], ["", "def", "batch_gamma", "(", "batch_p", ",", "gamma", "=", "None", ")", ":", "\n", "    ", "if", "gamma", "is", "None", ":", "\n", "        ", "gamma", "=", "np", ".", "array", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.25", ",", "high", "=", "3", ",", "size", "=", "(", "len", "(", "batch_p", ")", ",", "1", ",", "1", ",", "1", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "elif", "type", "(", "gamma", ")", "is", "float", ":", "\n", "        ", "gamma", "=", "gamma", "*", "np", ".", "ones", "(", "(", "len", "(", "batch_p", ")", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "\n", "", "return", "np", ".", "power", "(", "batch_p", ",", "1", "/", "gamma", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.crop_middle": [[31, 43], ["image.squeeze.squeeze", "ValueError"], "function", ["None"], ["", "def", "crop_middle", "(", "image", ",", "patch", "=", "128", ")", ":", "\n", "    ", "image", "=", "image", ".", "squeeze", "(", ")", "\n", "\n", "xx", "=", "(", "image", ".", "shape", "[", "0", "]", "-", "patch", ")", "//", "2", "\n", "yy", "=", "(", "image", ".", "shape", "[", "1", "]", "-", "patch", ")", "//", "2", "\n", "\n", "if", "image", ".", "ndim", "==", "2", ":", "\n", "        ", "return", "image", "[", "xx", ":", "(", "xx", "+", "patch", ")", ",", "yy", ":", "(", "yy", "+", "patch", ")", "]", "\n", "", "elif", "image", ".", "ndim", "==", "3", ":", "\n", "        ", "return", "image", "[", "xx", ":", "(", "xx", "+", "patch", ")", ",", "yy", ":", "(", "yy", "+", "patch", ")", ",", ":", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid image size!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.fft_log_norm": [[45, 56], ["x.squeeze.squeeze", "numpy.zeros_like", "range", "ValueError", "numpy.abs", "scipy.fftpack.fftshift", "numpy.log", "image.normalize", "scipy.fftpack.fft2"], "function", ["home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize"], ["", "", "def", "fft_log_norm", "(", "x", ",", "boost", "=", "10", ",", "perc", "=", "0", ")", ":", "\n", "    ", "x", "=", "x", ".", "squeeze", "(", ")", "\n", "if", "x", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "'Only single images can be accepted as input.'", ")", "\n", "", "y", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "        ", "y", "[", ":", ",", ":", ",", "i", "]", "=", "np", ".", "abs", "(", "sfft", ".", "fft2", "(", "x", "[", ":", ",", ":", ",", "i", "]", ")", ")", "\n", "y", "[", ":", ",", ":", ",", "i", "]", "=", "sfft", ".", "fftshift", "(", "y", "[", ":", ",", ":", ",", "i", "]", ")", "\n", "y", "[", ":", ",", ":", ",", "i", "]", "=", "np", ".", "log", "(", "boost", "+", "y", "[", ":", ",", ":", ",", "i", "]", ")", "\n", "y", "[", ":", ",", ":", ",", "i", "]", "=", "normalize", "(", "y", "[", ":", ",", ":", ",", "i", "]", ",", "perc", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.cati": [[58, 85], ["enumerate", "numpy.concatenate", "isinstance", "arrays.append", "np.concatenate.squeeze", "numpy.concatenate", "numpy.expand_dims", "ValueError", "item.squeeze.squeeze", "ValueError", "numpy.expand_dims"], "function", ["None"], ["", "def", "cati", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Concatenate arrays along the image dimension. Should handle various combinations of arrays / lists.\n    \"\"\"", "\n", "\n", "arrays", "=", "[", "]", "\n", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "args", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "item", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "if", "item", ".", "ndim", "==", "3", ":", "\n", "                ", "item", "=", "np", ".", "expand_dims", "(", "item", ",", "0", ")", "\n", "\n", "", "if", "item", ".", "ndim", "!=", "4", ":", "\n", "                ", "raise", "ValueError", "(", "f'Shape of element {i} ({item.shape}) is not supported!'", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "item", "=", "np", ".", "concatenate", "(", "[", "x", "if", "x", ".", "ndim", "==", "4", "else", "np", ".", "expand_dims", "(", "x", ",", "axis", "=", "0", ")", "for", "x", "in", "item", "]", ")", "\n", "if", "item", ".", "ndim", "!=", "4", ":", "\n", "                ", "item", "=", "item", ".", "squeeze", "(", ")", "\n", "", "if", "item", ".", "ndim", "!=", "4", ":", "\n", "                ", "raise", "ValueError", "(", "f'Shape of element {i} ({item.shape}) is not supported!'", ")", "\n", "\n", "", "", "arrays", ".", "append", "(", "item", ")", "\n", "\n", "", "out", "=", "np", ".", "concatenate", "(", "arrays", ",", "axis", "=", "0", ")", "\n", "return", "out", "if", "out", ".", "ndim", "==", "4", "else", "out", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.catc": [[87, 89], ["numpy.concatenate"], "function", ["None"], ["", "def", "catc", "(", "*", "args", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "args", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pkorus_neural-imaging.helpers.image.normalize": [[91, 101], ["numpy.percentile", "numpy.percentile", "numpy.min", "numpy.max", "numpy.min"], "function", ["None"], ["", "def", "normalize", "(", "x", ",", "perc", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Normalize the input array to [0, 1]. Optionally, cut top and bottom outliers (based on percentiles).\n    \"\"\"", "\n", "if", "perc", "==", "0", ":", "\n", "        ", "return", "(", "(", "x", "-", "np", ".", "min", "(", "x", ")", ")", "/", "(", "np", ".", "max", "(", "x", ")", "-", "np", ".", "min", "(", "x", ")", "+", "1e-9", ")", ")", ".", "clip", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "mn", "=", "np", ".", "percentile", "(", "x", ",", "perc", ")", "\n", "mx", "=", "np", ".", "percentile", "(", "x", ",", "100", "-", "perc", ")", "\n", "return", "(", "(", "x", "-", "mn", ")", "/", "(", "mx", "-", "mn", "+", "1e-9", ")", ")", ".", "clip", "(", "0", ",", "1", ")", "", "", "", ""]]}