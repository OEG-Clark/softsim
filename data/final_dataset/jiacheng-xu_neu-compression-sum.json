{"home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.convert_lapata_to_mine.convertion": [[1, 3], ["None"], "function", ["None"], ["def", "convertion", "(", "singleoracle", ",", "doc", ",", "highlights", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.convert_lapata_to_mine.read_single_oracles": [[5, 20], ["l.replace.split", "open", "fd.read().splitlines", "l.replace.replace", "i.split", "int", "fd.read", "enumerate"], "function", ["None"], ["", "def", "read_single_oracles", "(", "path_to_singleoracle", ",", "name", "=", "[", "'cnn'", ",", "'dailymail'", "]", ")", ":", "\n", "    ", "with", "open", "(", "path_to_singleoracle", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "l", "=", "' '", ".", "join", "(", "lines", ")", "\n", "for", "n", "in", "name", ":", "\n", "        ", "l", "=", "l", ".", "replace", "(", "'  '", "+", "n", ",", "'\\n'", "+", "n", ")", "\n", "", "l", "=", "l", ".", "split", "(", "'\\n'", ")", "\n", "dict", "=", "{", "}", "\n", "for", "i", "in", "l", ":", "\n", "        ", "everything", "=", "i", ".", "split", "(", ")", "\n", "sample_name", "=", "everything", "[", "0", "]", "\n", "sample_oracle", "=", "[", "int", "(", "x", ")", "for", "x", "in", "everything", "[", "1", ":", "]", "]", "\n", "sample_oracle_idx", "=", "[", "idx", "for", "idx", ",", "j", "in", "enumerate", "(", "sample_oracle", ")", "if", "j", "==", "1", "]", "\n", "dict", "[", "sample_name", "]", "=", "sample_oracle_idx", "\n", "", "return", "dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.convert_lapata_to_mine.read_multiple_oracles": [[22, 24], ["None"], "function", ["None"], ["", "def", "read_multiple_oracles", "(", "path_to_mo", ",", "sent_idx_limit", "=", "30", ",", "sent_num_limit", "=", "3", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.convert_lapata_to_mine.read_doc_or_abs": [[26, 77], ["print", "print", "print", "open", "fd.read().splitlines", "open", "fd.read().splitlines", "dict_vocab.append", "l.startswith", "all_doc.append", "d[].startswith", "len", "_buff.append", "span_info.append", "span_info.append", "len", "fd.read", "fd.read", "all_doc.append", "len", "_buff.append", "c.split", "len", "int"], "function", ["None"], ["", "def", "read_doc_or_abs", "(", "path_to_doc", ",", "\n", "path_to_vocab", "=", "\"/backup2/jcxu/exComp/data/vocab_list.txt\"", ",", "enable_span", "=", "True", ")", ":", "\n", "    ", "with", "open", "(", "path_to_doc", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "with", "open", "(", "path_to_vocab", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "vocab_lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "dict_vocab", "=", "[", "]", "\n", "for", "vl", "in", "vocab_lines", ":", "\n", "        ", "dict_vocab", ".", "append", "(", "vl", ")", "\n", "\n", "", "all_doc", "=", "[", "]", "\n", "_buff", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "if", "l", ".", "startswith", "(", "\"cnn\"", ")", ":", "\n", "            ", "if", "_buff", "!=", "[", "]", ":", "\n", "                ", "all_doc", ".", "append", "(", "_buff", ")", "\n", "", "_buff", "=", "[", "]", "\n", "_buff", ".", "append", "(", "l", ")", "\n", "", "elif", "len", "(", "l", ")", ">=", "1", ":", "\n", "            ", "_buff", ".", "append", "(", "l", ")", "\n", "# if len(l) < 1 and len(_buff) > 1:", "\n", "#     all_doc.append(_buff)", "\n", "#     _buff = []", "\n", "# else:", "\n", "#     if len(l) >= 1:", "\n", "#         _buff.append(l)", "\n", "", "", "if", "_buff", "!=", "[", "]", ":", "\n", "        ", "all_doc", ".", "append", "(", "_buff", ")", "\n", "", "for", "d", "in", "all_doc", ":", "\n", "        ", "assert", "d", "[", "0", "]", ".", "startswith", "(", "'cnn'", ")", "\n", "", "print", "(", "len", "(", "all_doc", ")", ")", "\n", "print", "(", "all_doc", "[", "0", "]", ")", "\n", "print", "(", "all_doc", "[", "-", "1", "]", ")", "\n", "BAG", "=", "{", "}", "\n", "for", "d", "in", "all_doc", ":", "\n", "        ", "name", "=", "d", "[", "0", "]", "\n", "content", "=", "d", "[", "1", ":", "]", "\n", "span_info", "=", "[", "]", "\n", "marker", "=", "0", "\n", "_rt_doc", "=", "[", "]", "\n", "\n", "for", "c", "in", "content", ":", "\n", "            ", "_seq", "=", "[", "dict_vocab", "[", "int", "(", "x", ")", "]", "for", "x", "in", "c", ".", "split", "(", ")", "]", "+", "[", "\"@@SS@@\"", "]", "\n", "span_info", ".", "append", "(", "marker", ")", "\n", "span_info", ".", "append", "(", "marker", "+", "len", "(", "_seq", ")", "-", "1", ")", "\n", "marker", "+=", "len", "(", "_seq", ")", "\n", "_rt_doc", "+=", "_seq", "\n", "", "_d", "=", "{", "\"name\"", ":", "name", ",", "\"span\"", ":", "span_info", ",", "\"txt\"", ":", "_rt_doc", "}", "\n", "BAG", "[", "name", "]", "=", "_d", "\n", "", "return", "BAG", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.convert_lapata_to_mine.merge_doc_abs_oracle": [[79, 96], ["dict_doc.items", "open", "fd.write", "wt_bag.append", "print", "str", "str"], "function", ["None"], ["", "def", "merge_doc_abs_oracle", "(", "domain", ",", "dict_doc", ",", "dict_abs", ",", "dict_oracle", ")", ":", "\n", "    ", "wt_bag", "=", "[", "]", "\n", "for", "k", ",", "doc", "in", "dict_doc", ".", "items", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "oracle", "=", "dict_oracle", "[", "k", "]", "\n", "abst", "=", "dict_abs", "[", "k", "]", "\n", "\n", "doc_txt", "=", "' '", ".", "join", "(", "doc", "[", "'txt'", "]", ")", "\n", "abs_txt", "=", "' '", ".", "join", "(", "abst", "[", "'txt'", "]", ")", "\n", "span", "=", "' '", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "doc", "[", "'span'", "]", "]", ")", "\n", "ora", "=", "' '", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "oracle", "]", ")", "\n", "rt", "=", "'\\t'", ".", "join", "(", "[", "k", ",", "doc_txt", ",", "abs_txt", ",", "span", ",", "ora", "]", ")", "\n", "wt_bag", ".", "append", "(", "rt", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "print", "(", "\"Key Error: {}\"", ".", "format", "(", "k", ")", ")", "\n", "", "", "with", "open", "(", "\"/backup2/jcxu/data/cnn-lapata/\"", "+", "domain", "+", "'.txt'", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "'\\n'", ".", "join", "(", "wt_bag", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.summa_predictor.Seq2IdxPredictor.__init__": [[13, 15], ["allennlp.predictors.predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.summa_predictor.Seq2IdxPredictor.predict": [[16, 18], ["summa_predictor.Seq2IdxPredictor.predict_json", "json.loads"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "jsonline", ":", "str", ")", "->", "JsonDict", ":", "\n", "        ", "return", "self", ".", "predict_json", "(", "json", ".", "loads", "(", "jsonline", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.__init__": [[28, 30], ["allennlp_cont_parser.ConstPredictor.init_predtor"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.init_predtor"], ["    ", "def", "__init__", "(", "self", ",", "cudaid", ":", "int", "=", "2", ",", "use_cuda", ":", "bool", "=", "True", ")", ":", "\n", "        ", "self", ".", "init_predtor", "(", "cudaid", ",", "use_cuda", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.init_predtor": [[31, 42], ["print", "torch.device", "print", "Predictor.from_path", "Predictor.from_path._model.to", "print"], "methods", ["None"], ["", "def", "init_predtor", "(", "self", ",", "cudaid", ":", "int", "=", "2", ",", "use_cuda", "=", "True", ")", ":", "\n", "        ", "print", "(", "\"AllenNLP\"", ",", "allennlp", ".", "__version__", ")", "\n", "from", "allennlp", ".", "predictors", ".", "predictor", "import", "Predictor", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "cudaid", ")", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "print", "(", "\"Running on {}\"", ".", "format", "(", "device", ")", ")", "\n", "predictor", "=", "Predictor", ".", "from_path", "(", "\n", "\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\"", ")", "\n", "predictor", ".", "_model", ".", "to", "(", "device", ")", "\n", "self", ".", "predictor", "=", "predictor", "\n", "print", "(", "\"Finish loading\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.const_parse_batch": [[43, 55], ["allennlp_cont_parser.ConstPredictor.predictor.predict_batch_json"], "methods", ["None"], ["", "def", "const_parse_batch", "(", "self", ",", "sentences", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "sent_list_dict", "=", "[", "{", "\"sentence\"", ":", "x", "}", "for", "x", "in", "sentences", "]", "\n", "output", "=", "self", ".", "predictor", ".", "predict_batch_json", "(", "sent_list_dict", ")", "\n", "\n", "output", "=", "[", "{", "\"text\"", ":", "o", "[", "\"hierplane_tree\"", "]", "[", "\"text\"", "]", ",", "\n", "\"tokens\"", ":", "o", "[", "\"tokens\"", "]", ",", "\n", "\"pos_tags\"", ":", "o", "[", "\"pos_tags\"", "]", ",", "\n", "\"tree\"", ":", "o", "[", "\"hierplane_tree\"", "]", "[", "\"root\"", "]", "}", "\n", "for", "o", "in", "output", "]", "\n", "# json_output = [json.dumps(o) for o in output]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.load_database_and_parse": [[56, 92], ["time.time", "enumerate", "print", "os.path.isfile", "name_buff.append", "len_buff.append", "allennlp_cont_parser.ConstPredictor.const_parse_batch", "enumerate", "len", "sum", "print", "print", "allennlp_cont_parser.ConstPredictor.const_parse_batch", "enumerate", "json.dumps", "json.dumps", "open", "fd.write", "open", "fd.write", "time.time"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.const_parse_batch", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.ConstPredictor.const_parse_batch"], ["", "def", "load_database_and_parse", "(", "self", ",", "database", ":", "List", "[", "Dict", "]", ")", ":", "\n", "        ", "lines_buff", "=", "[", "]", "\n", "name_buff", "=", "[", "]", "\n", "len_buff", "=", "[", "]", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "kdx", ",", "d", "in", "enumerate", "(", "database", ")", ":", "\n", "# runtime check:", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "d", "[", "\"f_doc\"", "]", "+", "'.tree'", ")", ":", "\n", "                ", "continue", "\n", "", "name_buff", ".", "append", "(", "d", "[", "\"f_doc\"", "]", ")", "\n", "lines_buff", "+=", "d", "[", "\"lines\"", "]", "\n", "len_buff", ".", "append", "(", "len", "(", "d", "[", "\"lines\"", "]", ")", ")", "\n", "if", "sum", "(", "len_buff", ")", ">", "LB_SENT_NUM", ":", "\n", "                ", "print", "(", "\"Parsing & Writing!\"", ")", "\n", "print", "(", "\"Idx: {} Time: {}\"", ".", "format", "(", "kdx", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "output", "=", "self", ".", "const_parse_batch", "(", "lines_buff", ")", "\n", "cur", "=", "0", "\n", "for", "j", ",", "l", "in", "enumerate", "(", "len_buff", ")", ":", "\n", "                    ", "parse", "=", "output", "[", "cur", ":", "cur", "+", "l", "]", "\n", "parse", "=", "json", ".", "dumps", "(", "parse", ")", "\n", "with", "open", "(", "name_buff", "[", "j", "]", "+", "'.tree'", ",", "'w'", ")", "as", "fd", ":", "\n", "                        ", "fd", ".", "write", "(", "parse", ")", "\n", "", "cur", "+=", "l", "\n", "", "lines_buff", "=", "[", "]", "\n", "name_buff", "=", "[", "]", "\n", "len_buff", "=", "[", "]", "\n", "", "", "print", "(", "\"Final batch\"", ")", "\n", "if", "len_buff", "!=", "[", "]", ":", "\n", "            ", "output", "=", "self", ".", "const_parse_batch", "(", "lines_buff", ")", "\n", "cur", "=", "0", "\n", "for", "j", ",", "l", "in", "enumerate", "(", "len_buff", ")", ":", "\n", "                ", "parse", "=", "output", "[", "cur", ":", "cur", "+", "l", "]", "\n", "parse", "=", "json", ".", "dumps", "(", "parse", ")", "\n", "with", "open", "(", "name_buff", "[", "j", "]", "+", "'.tree'", ",", "'w'", ")", "as", "fd", ":", "\n", "                    ", "fd", ".", "write", "(", "parse", ")", "\n", "", "cur", "+=", "l", "\n", "# {\"f_doc\": f_doc, \"lines\": lines}", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.allennlp_cont_parser.read_files": [[16, 24], ["os.path.join", "os.path.join", "os.path.isfile", "open", "fd.read().splitlines", "fd.read"], "function", ["None"], ["def", "read_files", "(", "path", ",", "fname", ")", ":", "\n", "    ", "f_doc", "=", "os", ".", "path", ".", "join", "(", "path", ",", "fname", "+", "'.doc'", ")", "\n", "f_doc_tree", "=", "os", ".", "path", ".", "join", "(", "path", ",", "fname", "+", "'.doc.tree'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "f_doc_tree", ")", ":", "\n", "        ", "return", "None", "\n", "", "with", "open", "(", "f_doc", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "return", "{", "\"f_doc\"", ":", "f_doc", ",", "\"lines\"", ":", "lines", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.cnndm_dataset_reader_flex.SummarizationDatasetReader.__init__": [[76, 87], ["allennlp.data.dataset_readers.DatasetReader.__init__", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "source_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "# word token indexer", "\n", "lazy", ":", "bool", "=", "False", ",", "\n", "single_oracle", "=", "True", ",", "\n", "fix_edu_num", "=", "None", ",", "\n", "trim_oracle", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "word_token_indexers", "=", "source_token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "single_oracle", "=", "single_oracle", "\n", "self", ".", "fix_edu_num", "=", "fix_edu_num", "\n", "self", ".", "trim_oracle", "=", "trim_oracle", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.cnndm_dataset_reader_flex.SummarizationDatasetReader._read": [[88, 125], ["open", "json.loads", "allennlp.data.tokenizers.Token", "cnndm_dataset_reader_flex.filter_oracle_label", "cnndm_dataset_reader_flex.filter_oracle_label", "cnndm_dataset_reader_flex.SummarizationDatasetReader.text_to_instance", "doc_str.split"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.filter_oracle_label", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.filter_oracle_label", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader.text_to_instance"], ["", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "for", "line", "in", "fd", ":", "\n", "                ", "data_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "name", "=", "data_dict", "[", "'name'", "]", "\n", "doc_str", "=", "data_dict", "[", "'token'", "]", "\n", "abs_str", "=", "data_dict", "[", "'abs'", "]", "\n", "span_pairs", "=", "data_dict", "[", "'span'", "]", "\n", "doc_list", "=", "data_dict", "[", "'token_list'", "]", "\n", "abs_list", "=", "data_dict", "[", "'abs_token'", "]", "\n", "sentences", "=", "data_dict", "[", "'sentences'", "]", "\n", "sent_oracle", "=", "data_dict", "[", "'sent_oracle'", "]", "\n", "sent_oracle_trim", "=", "data_dict", "[", "'sent_oracle_trim'", "]", "\n", "\n", "allen_token_word_in_doc", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "doc_str", ".", "split", "(", ")", "]", "\n", "\n", "# word_in_abs = [Token(word) for word in abst.split()]# TODO", "\n", "# assert int(span_info.split()[-1]) + 1 == len(word_in_doc)", "\n", "# span_info = [int(w) for w in span_info.split()]", "\n", "# assert len(span_info) % 2 == 0", "\n", "# idx_in_span = list(zip(span_info[0::2], span_info[1::2]))", "\n", "\n", "if", "self", ".", "trim_oracle", ":", "\n", "                    ", "sent_label_list", ",", "sent_rouge_list", "=", "filter_oracle_label", "(", "self", ".", "single_oracle", ",", "\n", "self", ".", "fix_edu_num", ",", "sent_oracle_trim", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "sent_label_list", ",", "sent_rouge_list", "=", "filter_oracle_label", "(", "self", ".", "single_oracle", ",", "\n", "self", ".", "fix_edu_num", ",", "sent_oracle", ")", "\n", "\n", "", "yield", "self", ".", "text_to_instance", "(", "name", ",", "allen_token_word_in_doc", ",", "\n", "doc_list", ",", "\n", "abs_list", ",", "\n", "doc_str", ",", "\n", "abs_str", ",", "\n", "sentences", ",", "\n", "span_pairs", ",", "sent_label_list", ",", "sent_rouge_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.cnndm_dataset_reader_flex.SummarizationDatasetReader.text_to_instance": [[128, 192], ["allennlp.data.fields.TextField", "allennlp.data.fields.ListField", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "max", "enumerate", "numpy.asarray", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "cnndm_dataset_reader_flex.SummarizationDatasetReader.text_to_instance.edit_label_rouge"], "methods", ["None"], ["", "", "", "def", "text_to_instance", "(", "self", ",", "name", ":", "str", ",", "\n", "allen_token_word_in_doc", ":", "List", "[", "Token", "]", ",", "\n", "doc_list", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "abs_list", ":", "List", "[", "List", "[", "str", "]", "]", ",", "\n", "doc_str", ":", "str", ",", "\n", "abs_str", ":", "str", ",", "\n", "sentences", ":", "List", "[", "dict", "]", ",", "\n", "span_pairs", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "sent_label_list", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "sent_rouge_list", ":", "List", "[", "float", "]", "\n", "# word_in_doc_in_list: List,", "\n", "# word_in_abs_in_list: List,", "\n", "# document: List[Token],", "\n", "# abstract: List[Token],", "\n", "# span: List[Tuple[int, int]],", "\n", "# label_list: List = None,", "\n", "# rouge_list: List = None,", "\n", "# name: str = None,", "\n", "# _max_len: int = 5", "\n", ")", "->", "Instance", ":", "\n", "        ", "instance_fields", "=", "{", "}", "\n", "doc_text_field", "=", "TextField", "(", "allen_token_word_in_doc", ",", "self", ".", "word_token_indexers", ")", "\n", "# print(doc_text_field.sequence_length())", "\n", "instance_fields", "[", "\"text\"", "]", "=", "doc_text_field", "\n", "\n", "def", "edit_label_rouge", "(", "_label_list", ",", "_rouge_list", ")", ":", "\n", "            ", "_label_list", "=", "[", "x", "+", "[", "0", "]", "for", "x", "in", "_label_list", "]", "\n", "_max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "_label_list", "]", ")", "\n", "for", "idx", ",", "label", "in", "enumerate", "(", "_label_list", ")", ":", "\n", "                ", "if", "len", "(", "label", ")", "<", "_max_len", ":", "\n", "                    ", "_label_list", "[", "idx", "]", "=", "_label_list", "[", "idx", "]", "+", "[", "-", "1", "]", "*", "(", "_max_len", "-", "len", "(", "label", ")", ")", "\n", "", "", "np_gold_label", "=", "np", ".", "asarray", "(", "_label_list", ",", "dtype", "=", "np", ".", "int", ")", "\n", "f", "=", "ArrayField", "(", "array", "=", "np_gold_label", ",", "padding_value", "=", "-", "1", ")", "\n", "r", "=", "ArrayField", "(", "np", ".", "asarray", "(", "_rouge_list", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "return", "f", ",", "r", "\n", "\n", "", "if", "sent_label_list", "and", "sent_rouge_list", ":", "\n", "            ", "label", ",", "rouge", "=", "edit_label_rouge", "(", "_label_list", "=", "sent_label_list", ",", "\n", "_rouge_list", "=", "sent_rouge_list", ")", "\n", "instance_fields", "[", "\"label\"", "]", "=", "label", "\n", "instance_fields", "[", "\"rouge\"", "]", "=", "rouge", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "spans", "=", "[", "]", "\n", "# print(span)", "\n", "for", "s", "in", "span_pairs", ":", "\n", "            ", "_sf", "=", "SpanField", "(", "span_start", "=", "s", "[", "0", "]", ",", "span_end", "=", "s", "[", "1", "]", ",", "\n", "sequence_field", "=", "doc_text_field", ")", "\n", "spans", ".", "append", "(", "_sf", ")", "\n", "", "span_field", "=", "ListField", "(", "spans", ")", "\n", "instance_fields", "[", "\"spans\"", "]", "=", "span_field", "\n", "\n", "instance_fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "\n", "{", "\n", "\"doc_list\"", ":", "doc_list", ",", "\n", "\"abs_list\"", ":", "abs_list", ",", "\n", "\"name\"", ":", "name", ",", "\n", "\"sentences\"", ":", "sentences", ",", "\n", "# \"label\": label,", "\n", "# \"rouge\": rouge", "\n", "}", "\n", ")", "\n", "return", "Instance", "(", "instance_fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.cnndm_dataset_reader_flex.filter_oracle_label": [[18, 69], ["cur_data.items", "labels.items", "rt_data.append", "rt_rouge.append", "data.items", "rt_data.append", "rt_rouge.append", "sorted", "range", "range", "str", "enumerate", "len", "len"], "function", ["None"], ["def", "filter_oracle_label", "(", "single_oracle", ",", "fix_edu_num", ",", "labels", ":", "Dict", ")", ":", "\n", "    ", "\"\"\"\n\n    :param single_oracle:\n    :param fix_edu_num:\n    :param labels:\n    :return: List[List], List[float]\n    \"\"\"", "\n", "if", "single_oracle", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# if fix_edu_num:", "\n", "#     cur_label = labels[str(fix_edu_num)]", "\n", "#     l = cur_label[\"best\"]", "\n", "#     if l:", "\n", "#         return [l[\"label\"]], [l[\"R\"]]", "\n", "#     else:", "\n", "#         return [[1] * fix_edu_num], [0.1]  # TODO", "\n", "# else:", "\n", "#     _best_label = []", "\n", "#     _best_rouge = 0", "\n", "#     for k, v in labels.items():", "\n", "#         if v[\"best\"]:", "\n", "#             if v[\"best\"][\"R\"] > _best_rouge:", "\n", "#                 _best_label = v[\"best\"][\"label\"]", "\n", "#                 _best_rouge = v[\"best\"][\"R\"]", "\n", "#     if _best_rouge == 0:", "\n", "#         return [[1] * 2], [0.1]", "\n", "#     else:", "\n", "#         return [_best_label], [_best_rouge]", "\n", "", "else", ":", "\n", "        ", "if", "fix_edu_num", ":", "\n", "            ", "rt_data", ",", "rt_rouge", "=", "[", "]", ",", "[", "]", "\n", "cur_data", "=", "labels", "[", "str", "(", "fix_edu_num", ")", "]", "[", "'data'", "]", "\n", "for", "k", ",", "v", "in", "cur_data", ".", "items", "(", ")", ":", "\n", "                ", "rt_data", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "rt_rouge", ".", "append", "(", "v", "[", "'R1'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "fix_edu_num", "=", "2", "# just in case", "\n", "rt_data", ",", "rt_rouge", "=", "[", "]", ",", "[", "]", "\n", "for", "n", ",", "lab", "in", "labels", ".", "items", "(", ")", ":", "\n", "                ", "data", "=", "lab", "[", "'data'", "]", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "                    ", "rt_data", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "rt_rouge", ".", "append", "(", "v", "[", "'R1'", "]", ")", "\n", "", "", "", "if", "not", "rt_rouge", ":", "\n", "            ", "return", "[", "[", "1", "]", "*", "fix_edu_num", "]", ",", "[", "0.1", "]", "\n", "", "else", ":", "\n", "            ", "sort_idx", "=", "[", "i", "[", "0", "]", "for", "i", "in", "sorted", "(", "enumerate", "(", "rt_rouge", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "sort_rt_data", "=", "[", "rt_data", "[", "sort_idx", "[", "idx", "]", "]", "for", "idx", "in", "range", "(", "len", "(", "rt_data", ")", ")", "]", "\n", "sort_rt_rouge", "=", "[", "rt_rouge", "[", "sort_idx", "[", "idx", "]", "]", "for", "idx", "in", "range", "(", "len", "(", "rt_rouge", ")", ")", "]", "\n", "return", "sort_rt_data", ",", "sort_rt_rouge", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.cnndm_dataset_reader_flex.read_sent_object": [[71, 73], ["None"], "function", ["None"], ["", "", "", "def", "read_sent_object", "(", "sentence", ":", "dict", ")", ":", "\n", "    ", "token", "=", "sentence", "[", "'token'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.archive.comp_num_seg_out_of_p_sent": [[1, 54], ["zip", "len", "list", "list", "assemble_doc_list_from_idx", "inp_doc.append", "len", "get_rouge_est_str_2gram", "out.append", "list", "n_comb_original.sort", "assemble_doc_list_from_idx", "rouge_protocol", "sorted", "range", "itertools.combinations", "sorted", "int", "_comb_bag.keys", "len", "range", "enumerate", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.rouge_protocol"], ["def", "comp_num_seg_out_of_p_sent", "(", "_filtered_doc_list", ",", "\n", "_num_edu", ",", "\n", "_absas_read_str", ",", "\n", "abs_as_read_list", ",", "\n", "map_from_new_to_ori_idx", ")", ":", "\n", "    ", "combs", "=", "[", "]", "\n", "if", "len", "(", "_filtered_doc_list", ")", "<", "_num_edu", ":", "\n", "        ", "combs", "+=", "list", "(", "range", "(", "len", "(", "_filtered_doc_list", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "combs", "+=", "list", "(", "itertools", ".", "combinations", "(", "range", "(", "len", "(", "_filtered_doc_list", ")", ")", ",", "_num_edu", ")", ")", "\n", "\n", "", "inp_doc", "=", "[", "]", "\n", "for", "comb", "in", "combs", ":", "\n", "        ", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "comb", ")", "\n", "inp_doc", ".", "append", "(", "'\\n'", ".", "join", "(", "_tmp", ")", ")", "\n", "", "inp_abs", "=", "[", "_absas_read_str", "]", "*", "len", "(", "combs", ")", "\n", "\n", "out", "=", "[", "]", "\n", "for", "inp_d", ",", "inp_a", "in", "zip", "(", "inp_doc", ",", "inp_abs", ")", ":", "\n", "        ", "o", "=", "get_rouge_est_str_2gram", "(", "inp_a", ",", "inp_d", ")", "\n", "out", ".", "append", "(", "o", ")", "\n", "# out_sort = sorted(out, key=itemgetter(2), reverse=True)", "\n", "", "sorted_idx", "=", "[", "i", "[", "0", "]", "for", "i", "in", "sorted", "(", "enumerate", "(", "out", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "[", "0", "]", ",", "reverse", "=", "True", ")", "]", "\n", "\n", "# Write oracle to a string like: 0.4 0.3 0.4", "\n", "_comb_bag", "=", "{", "}", "\n", "for", "top_n_idx", "in", "sorted_idx", "[", ":", "top_k_combo", "]", ":", "\n", "        ", "n_comb", "=", "list", "(", "combs", "[", "top_n_idx", "]", ")", "\n", "n_comb_original", "=", "[", "map_from_new_to_ori_idx", "[", "a", "]", "for", "a", "in", "n_comb", "]", "\n", "n_comb_original", ".", "sort", "(", ")", "# json label", "\n", "n_comb_original", "=", "[", "int", "(", "x", ")", "for", "x", "in", "n_comb_original", "]", "\n", "# print(n_comb_original)", "\n", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "combs", "[", "top_n_idx", "]", ")", "\n", "\n", "score", "=", "rouge_protocol", "(", "[", "[", "_tmp", "]", "]", ",", "[", "[", "abs_as_read_list", "]", "]", ")", "\n", "f1", "=", "score", "[", "'ROUGE-1-F'", "]", "\n", "f2", "=", "score", "[", "'ROUGE-2-F'", "]", "\n", "fl", "=", "score", "[", "'ROUGE-L-F'", "]", "\n", "f_avg", "=", "(", "f1", "+", "f2", "+", "fl", ")", "/", "3", "\n", "_comb_bag", "[", "f_avg", "]", "=", "{", "\"label\"", ":", "n_comb_original", ",", "\n", "\"R1\"", ":", "f1", ",", "\n", "\"R2\"", ":", "f2", ",", "\n", "\"RL\"", ":", "fl", ",", "\n", "\"R\"", ":", "f_avg", ",", "\n", "\"nlabel\"", ":", "_num_edu", "}", "\n", "# print(_comb_bag)", "\n", "# print(len(_comb_bag))", "\n", "", "best_key", "=", "sorted", "(", "_comb_bag", ".", "keys", "(", ")", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "rt_dict", "=", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "_comb_bag", ",", "\n", "\"best\"", ":", "_comb_bag", "[", "best_key", "]", "\n", "}", "\n", "return", "rt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.archive.random_compression": [[57, 96], ["len", "enumerate", "len", "get_rouge_est_str_2gram", "texts.append", "compressions.append", "set", "random.sample", "random.sample", "range", "set", "assemble_text_and_bit", "len", "list_of_compressions.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit"], ["", "def", "random_compression", "(", "sent_del_spans", ",", "\n", "abs_str", ":", "str", ",", "\n", "num_of_compression", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Randomly drop num_of_compression compressions in sent_del_spans\n    :param sent_del_spans:\n    :param abs_str:\n    :param num_of_compression:\n    :return: rouge val after drop\n    \"\"\"", "\n", "texts", "=", "[", "]", "\n", "compressions", "=", "[", "]", "\n", "for", "unit", "in", "sent_del_spans", ":", "\n", "        ", "texts", ".", "append", "(", "unit", "[", "0", "]", ".", "text", ")", "\n", "compressions", ".", "append", "(", "unit", "[", "1", "]", ")", "\n", "", "sent_num", "=", "len", "(", "sent_del_spans", ")", "\n", "text_bits", "=", "[", "set", "(", "range", "(", "len", "(", "x", ")", ")", ")", "for", "x", "in", "texts", "]", "\n", "list_of_compressions", "=", "[", "]", "\n", "for", "sent_idx", ",", "comp", "in", "enumerate", "(", "compressions", ")", ":", "\n", "        ", "for", "one_comp_option", "in", "comp", ":", "\n", "            ", "if", "one_comp_option", "[", "'node'", "]", "!=", "\"BASELINE\"", ":", "\n", "                ", "list_of_compressions", ".", "append", "(", "[", "sent_idx", ",", "one_comp_option", "]", ")", "\n", "", "", "", "total_len", "=", "len", "(", "list_of_compressions", ")", "\n", "if", "num_of_compression", "<", "total_len", ":", "\n", "        ", "sample", "=", "random", ".", "sample", "(", "list_of_compressions", ",", "num_of_compression", ")", "\n", "", "else", ":", "\n", "        ", "sample", "=", "random", ".", "sample", "(", "list_of_compressions", ",", "total_len", ")", "\n", "\n", "", "for", "samp", "in", "sample", ":", "\n", "        ", "sent_target", "=", "samp", "[", "0", "]", "\n", "compression_to_try", "=", "samp", "[", "1", "]", "[", "'selected_idx'", "]", "\n", "\n", "before", "=", "text_bits", "[", "sent_target", "]", "\n", "after", "=", "set", "(", "before", ")", "-", "compression_to_try", "\n", "text_bits", "[", "sent_target", "]", "=", "after", "\n", "\n", "", "new_rouge", "=", "get_rouge_est_str_2gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "\n", "assemble_text_and_bit", "(", "texts", ",", "text_bits", ")", ")", "\n", "return", "new_rouge", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.depricated.archive.multiple_compression_sentence": [[101, 209], ["len", "get_rouge_est_str_2gram", "texts.append", "compressions.append", "set", "range", "assemble_text_and_bit", "get_rouge_est_str_2gram", "range", "enumerate", "range", "sorted", "len", "flag.append", "text_bit_list.append", "val.append", "enumerate", "enumerate", "len", "range", "assemble_text_and_bit", "copy.deepcopy", "get_rouge_est_str_2gram", "range", "range", "range", "check_if_redundant", "copy.deepcopy", "check_if_empty_lists", "set", "refresh_compression[].append", "refresh_text_bits[].append", "refresh_rouge[].append", "finished_beam.append", "candidates.append", "finished_beam.append", "range", "range", "range", "assemble_text_and_bit", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.check_if_redundant", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.check_if_empty_lists", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit"], ["", "def", "multiple_compression_sentence", "(", "sent_del_spans", ",", "\n", "abs_str", ":", "str", ",", "topk", "=", "10", ")", ":", "\n", "    ", "finished_beam", "=", "[", "]", "\n", "texts", "=", "[", "]", "\n", "compressions", "=", "[", "]", "\n", "for", "unit", "in", "sent_del_spans", ":", "\n", "        ", "texts", ".", "append", "(", "unit", "[", "0", "]", ".", "text", ")", "\n", "compressions", ".", "append", "(", "unit", "[", "1", "]", ")", "\n", "", "sent_num", "=", "len", "(", "sent_del_spans", ")", "\n", "text_bits", "=", "[", "set", "(", "range", "(", "len", "(", "x", ")", ")", ")", "for", "x", "in", "texts", "]", "\n", "baseline_rouge", "=", "get_rouge_est_str_2gram", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "assemble_text_and_bit", "(", "texts", ",", "text_bits", ")", ")", "\n", "init_beam", "=", "{", "\"compressions\"", ":", "compressions", ",", "\n", "\"text_bits\"", ":", "text_bits", ",", "\n", "\"done\"", ":", "[", "]", "}", "\n", "B", "=", "[", "init_beam", "]", "\n", "\n", "while", "True", ":", "\n", "        ", "candidates", "=", "[", "]", "\n", "for", "b", "in", "B", ":", "\n", "# b = [texts, compressions]", "\n", "\n", "            ", "current_rouge", "=", "get_rouge_est_str_2gram", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "assemble_text_and_bit", "(", "texts", ",", "b", "[", "\"text_bits\"", "]", ")", ")", "\n", "\n", "flag", ",", "text_bit_list", ",", "val", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "b", "[", "'compressions'", "]", ":", "\n", "                ", "flag", ".", "append", "(", "[", "False", "for", "_", "in", "range", "(", "len", "(", "sent", ")", ")", "]", ")", "\n", "text_bit_list", ".", "append", "(", "[", "None", "for", "m", "in", "range", "(", "len", "(", "sent", ")", ")", "]", ")", "\n", "val", ".", "append", "(", "[", "0", "for", "m", "in", "range", "(", "len", "(", "sent", ")", ")", "]", ")", "\n", "# finish init", "\n", "\n", "", "for", "idx", "in", "range", "(", "sent_num", ")", ":", "\n", "                ", "compression_of_sent", "=", "b", "[", "'compressions'", "]", "[", "idx", "]", "\n", "for", "jdx", ",", "compress_of_ith_sent", "in", "enumerate", "(", "compression_of_sent", ")", ":", "\n", "                    ", "if", "b", "[", "\"compressions\"", "]", "[", "idx", "]", "[", "jdx", "]", "[", "\"node\"", "]", "==", "\"BASELINE\"", ":", "\n", "                        ", "continue", "\n", "", "tmp_text_bits", "=", "copy", ".", "deepcopy", "(", "b", "[", "\"text_bits\"", "]", ")", "\n", "\n", "compression_to_try", "=", "b", "[", "\"compressions\"", "]", "[", "idx", "]", "[", "jdx", "]", "[", "'selected_idx'", "]", "\n", "\n", "# which sent", "\n", "before", "=", "tmp_text_bits", "[", "idx", "]", "\n", "after", "=", "set", "(", "before", ")", "-", "compression_to_try", "\n", "tmp_text_bits", "[", "idx", "]", "=", "after", "\n", "new_rouge", "=", "get_rouge_est_str_2gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "\n", "assemble_text_and_bit", "(", "texts", ",", "tmp_text_bits", ")", ")", "\n", "\n", "if", "new_rouge", ">", "current_rouge", "*", "1.01", ":", "\n", "                        ", "flag", "[", "idx", "]", "[", "jdx", "]", "=", "True", "\n", "text_bit_list", "[", "idx", "]", "[", "jdx", "]", "=", "tmp_text_bits", "\n", "val", "[", "idx", "]", "[", "jdx", "]", "=", "new_rouge", "\n", "# according to flag and vals, remove invalid compressions", "\n", "", "", "", "refresh_compression", "=", "[", "[", "]", "for", "_", "in", "range", "(", "sent_num", ")", "]", "\n", "refresh_text_bits", "=", "[", "[", "]", "for", "_", "in", "range", "(", "sent_num", ")", "]", "\n", "refresh_rouge", "=", "[", "[", "]", "for", "_", "in", "range", "(", "sent_num", ")", "]", "\n", "for", "idx", ",", "ff", "in", "enumerate", "(", "flag", ")", ":", "\n", "                ", "for", "jdx", ",", "f", "in", "enumerate", "(", "ff", ")", ":", "\n", "                    ", "if", "f", ":", "\n", "                        ", "refresh_compression", "[", "idx", "]", ".", "append", "(", "b", "[", "\"compressions\"", "]", "[", "idx", "]", "[", "jdx", "]", ")", "\n", "refresh_text_bits", "[", "idx", "]", ".", "append", "(", "text_bit_list", "[", "idx", "]", "[", "jdx", "]", ")", "\n", "refresh_rouge", "[", "idx", "]", ".", "append", "(", "val", "[", "idx", "]", "[", "jdx", "]", ")", "\n", "# now we have trimmed version of compression and it's value.", "\n", "\n", "", "", "", "for", "sent_idx", "in", "range", "(", "sent_num", ")", ":", "\n", "                ", "comp_options", "=", "refresh_compression", "[", "sent_idx", "]", "\n", "_text_bits", "=", "refresh_text_bits", "[", "sent_idx", "]", "\n", "# _has_been_done = refresh_done[sent_idx]", "\n", "_has_been_done", "=", "b", "[", "\"done\"", "]", "\n", "num_of_options", "=", "len", "(", "comp_options", ")", "\n", "for", "comp_idx", "in", "range", "(", "num_of_options", ")", ":", "\n", "                    ", "this_comp_op", "=", "comp_options", "[", "comp_idx", "]", "\n", "# done record", "\n", "done_record", "=", "_has_been_done", "+", "[", "[", "sent_idx", ",", "this_comp_op", "]", "]", "\n", "this_text_bit", "=", "_text_bits", "[", "comp_idx", "]", "\n", "this_rouge", "=", "refresh_rouge", "[", "sent_idx", "]", "[", "comp_idx", "]", "\n", "if", "check_if_redundant", "(", "text_bit", "=", "this_text_bit", ",", "pool", "=", "candidates", "+", "finished_beam", ")", ":", "\n", "                        ", "continue", "# redundant!!!!!", "\n", "", "copy_of_compression", "=", "copy", ".", "deepcopy", "(", "refresh_compression", ")", "\n", "del", "copy_of_compression", "[", "sent_idx", "]", "[", "comp_idx", "]", "\n", "if", "check_if_empty_lists", "(", "copy_of_compression", ")", ":", "\n", "                        ", "finished_beam", ".", "append", "(", "{", "\n", "\"compressions\"", ":", "copy_of_compression", ",", "\n", "\"text_bits\"", ":", "this_text_bit", ",", "\n", "\"done\"", ":", "done_record", ",", "\n", "\"rouge\"", ":", "this_rouge", "\n", "}", ")", "\n", "", "else", ":", "\n", "                        ", "candidates", ".", "append", "(", "{", "\n", "\"compressions\"", ":", "copy_of_compression", ",", "\n", "\"text_bits\"", ":", "this_text_bit", ",", "\n", "\"done\"", ":", "done_record", ",", "\n", "\"rouge\"", ":", "this_rouge", "\n", "}", ")", "\n", "finished_beam", ".", "append", "(", "{", "\n", "\"compressions\"", ":", "copy_of_compression", ",", "\n", "\"text_bits\"", ":", "this_text_bit", ",", "\n", "\"done\"", ":", "done_record", ",", "\n", "\"rouge\"", ":", "this_rouge", "\n", "}", ")", "\n", "\n", "# how to end loop", "\n", "", "", "", "", "finished_beam", "=", "sorted", "(", "finished_beam", ",", "key", "=", "lambda", "x", ":", "x", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "[", ":", "topk", "]", "\n", "B", "=", "candidates", "\n", "if", "B", "==", "[", "]", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "finished_beam", ",", "baseline_rouge", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.ILP_protocol": [[13, 149], ["reference_summary.split", "set", "set.intersection", "list", "len", "range", "sent_unit.split", "cvxpy.Constant", "sum", "set", "set", "set.intersection_update", "fined_txt_tokens.append", "enumerate", "enumerate", "zip", "sum", "cvxpy.Maximize", "cvxpy.Problem", "cp.Problem.solve", "enumerate", "pred_index_list.sort", "len", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "numpy.int_", "list", "cvxpy.Variable", "len", "cvxpy.Variable", "cvxpy_ilp.check_every_sent", "cvxpy.sum", "random.random", "print", "print", "str", "len", "range", "range", "range", "print", "print", "print", "print", "exit", "pred_index_list.append", "enumerate", "str", "len", "cvxpy.Constant", "str", "numpy.int_", "str"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.check_every_sent"], ["def", "ILP_protocol", "(", "reference_summary", ":", "str", ",", "sent_units", ":", "List", "[", "str", "]", ",", "\n", "min_word_limit", "=", "30", ",", "max_word_limit", "=", "180", ",", "step", "=", "5", ")", ":", "\n", "    ", "result_bag", "=", "{", "}", "\n", "# \"nlabel\": num of sent picked,", "\n", "# \"data\": {0.2539969834087481: {'label': [1, 13, 16], 'R1': 0.2539969834087481, 'nlabel': 3}, ...},", "\n", "# \"best\": None", "\n", "\n", "best_score", "=", "0", "\n", "early_stop_cnt_down", "=", "0", "\n", "\n", "# raw_ref_token = word_tokenize(reference_summary)", "\n", "raw_ref_token", "=", "reference_summary", ".", "split", "(", "\" \"", ")", "\n", "\n", "raw_txt_tokens", "=", "[", "sent_unit", ".", "split", "(", "\" \"", ")", "for", "sent_unit", "in", "sent_units", "]", "\n", "\n", "# keep track of len of text units", "\n", "txt_lens", "=", "[", "cp", ".", "Constant", "(", "np", ".", "int_", "(", "len", "(", "raw_txt_token", ")", ")", ")", "for", "raw_txt_token", "in", "\n", "raw_txt_tokens", "]", "# for constraint computation", "\n", "\n", "raw_txt_token_set", "=", "set", "(", "sum", "(", "raw_txt_tokens", ",", "[", "]", ")", ")", "\n", "fined_ref_token_set", "=", "raw_txt_token_set", ".", "intersection", "(", "set", "(", "raw_ref_token", ")", ")", "\n", "\n", "fined_txt_tokens", "=", "[", "]", "\n", "for", "sent_unit", "in", "raw_txt_tokens", ":", "\n", "        ", "set_sent_unit", "=", "set", "(", "sent_unit", ")", "\n", "set_sent_unit", ".", "intersection_update", "(", "fined_ref_token_set", ")", "\n", "fined_txt_tokens", ".", "append", "(", "list", "(", "set_sent_unit", ")", ")", "\n", "# remove oov words in texts w.r.t. ref", "\n", "\n", "# remove redundancy in ref summary", "\n", "", "ref_tok", "=", "list", "(", "fined_ref_token_set", ")", "\n", "ref_len", "=", "len", "(", "ref_tok", ")", "\n", "\n", "for", "max_len", "in", "range", "(", "min_word_limit", ",", "max_word_limit", ",", "step", ")", ":", "\n", "# print(max_len)", "\n", "        ", "all_of_constraints", "=", "[", "]", "\n", "# Reference tok indicator. r_i. objective = sum(r_i)", "\n", "ref_gram_var", "=", "[", "cp", ".", "Variable", "(", "boolean", "=", "True", ")", "for", "_", "in", "range", "(", "ref_len", ")", "]", "\n", "# ref_gram_var = cp.Variable(shape=ref_len, boolean=True)", "\n", "\n", "# sum( s_i ) - sum(compression) >=  ref_occurance_constraint", "\n", "ref_occurance_constraints", "=", "[", "None", "for", "_", "in", "range", "(", "ref_len", ")", "]", "\n", "\n", "assert", "len", "(", "sent_units", ")", ">", "1", "\n", "# sent_vars = cp.Variable(shape=(len(sent_units)), boolean=True)", "\n", "sent_var_list", "=", "[", "cp", ".", "Variable", "(", "boolean", "=", "True", ")", "for", "_", "in", "range", "(", "len", "(", "sent_units", ")", ")", "]", "\n", "for", "sent_idx", ",", "txt_tok", "in", "enumerate", "(", "fined_txt_tokens", ")", ":", "\n", "# txt_tok is a list of str", "\n", "            ", "check_every_sent", "(", "txt_tok", ",", "ref_tok", ",", "ref_occurance_constraints", ",", "\n", "sent_var_list", "[", "sent_idx", "]", ")", "\n", "# ref_occurance_constraints = check_every_sent(txt_tok, ref_tok, ref_occurance_constraints,", "\n", "# sent_vars[sent_idx])", "\n", "#", "\n", "# print(ref_occurance_constraints)", "\n", "", "for", "idx", ",", "x", "in", "enumerate", "(", "ref_occurance_constraints", ")", ":", "\n", "            ", "all_of_constraints", "=", "all_of_constraints", "+", "[", "\n", "ref_occurance_constraints", "[", "idx", "]", "<=", "-", "ref_gram_var", "[", "idx", "]", "]", "\n", "\n", "# length restriction", "\n", "", "length_r", "=", "None", "\n", "for", "l", ",", "v", "in", "zip", "(", "txt_lens", ",", "sent_var_list", ")", ":", "\n", "            ", "if", "length_r", ":", "\n", "                ", "length_r", "=", "length_r", "+", "v", "*", "l", "\n", "", "else", ":", "\n", "                ", "length_r", "=", "v", "\n", "", "", "len_restrict", "=", "length_r", "\n", "# len_restrict = cp.sum([l * v for l, v in zip(txt_lens, sent_var_list)])", "\n", "# cp_lens = cp.Constant(txt_lens)", "\n", "# len_restrict = cp.sum(cp.multiply(cp_lens, sent_vars))", "\n", "\n", "constraints_with_length", "=", "all_of_constraints", "+", "[", "len_restrict", "<=", "cp", ".", "Constant", "(", "np", ".", "int_", "(", "max_len", ")", ")", "]", "\n", "# constraints_with_length = all_of_constraints", "\n", "# all_of_constraints.append(len_restrict <= max_len)", "\n", "# constraints_with_length.append(1 + cp.min(sent_vars) >= 1)", "\n", "# obj = None", "\n", "# for ref_v in ref_gram_var:", "\n", "#     if obj:", "\n", "#         obj = obj + ref_v", "\n", "#     else:", "\n", "#         obj = ref_v", "\n", "# obj_var = obj", "\n", "#", "\n", "obj_var", "=", "sum", "(", "ref_gram_var", ")", "\n", "\n", "obj", "=", "cp", ".", "Maximize", "(", "cp", ".", "sum", "(", "obj_var", ")", ")", "\n", "prob", "=", "cp", ".", "Problem", "(", "obj", ",", "constraints_with_length", ")", "\n", "\n", "prob", ".", "solve", "(", "solver", "=", "cp", ".", "GLPK_MI", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "0.001", ":", "\n", "            ", "print", "(", "prob", ")", "\n", "print", "(", "prob", ".", "value", ")", "\n", "# print(prob.value)", "\n", "# try:", "\n", "# print(sent_var_list)", "\n", "", "pred_index_list", "=", "[", "]", "\n", "for", "pred_idx", ",", "var", "in", "enumerate", "(", "sent_var_list", ")", ":", "\n", "            ", "if", "var", ".", "value", "==", "None", ":", "\n", "                ", "print", "(", "'-'", "*", "100", ")", "\n", "print", "(", "prob", ".", "status", ")", "\n", "print", "(", "sent_var_list", ")", "\n", "\n", "print", "(", "sent_units", ")", "\n", "exit", "(", ")", "\n", "", "if", "var", ".", "value", ">", "0.001", ":", "\n", "                ", "pred_index_list", ".", "append", "(", "pred_idx", ")", "\n", "\n", "# print(fname_without_suffix)", "\n", "", "", "pred_index_list", ".", "sort", "(", ")", "\n", "num_sent_sel", "=", "len", "(", "pred_index_list", ")", "\n", "selected_sents_str", "=", "[", "sent", "for", "idx", ",", "sent", "in", "enumerate", "(", "sent_units", ")", "if", "idx", "in", "pred_index_list", "]", "\n", "selected_sents_str", "=", "\"\\n\"", ".", "join", "(", "selected_sents_str", ")", "\n", "score", "=", "get_rouge_est_str_2gram_smart", "(", "gold", "=", "reference_summary", ",", "pred", "=", "selected_sents_str", ")", "\n", "# print(score)", "\n", "\n", "if", "str", "(", "num_sent_sel", ")", "not", "in", "result_bag", ":", "\n", "            ", "result_bag", "[", "str", "(", "num_sent_sel", ")", "]", "=", "{", "\n", "\"nlabel\"", ":", "num_sent_sel", ",", "\n", "\"data\"", ":", "{", "}", "\n", "}", "\n", "", "result_bag", "[", "str", "(", "num_sent_sel", ")", "]", "[", "\"data\"", "]", "[", "str", "(", "score", ")", "]", "=", "{", "'label'", ":", "pred_index_list", ",", "'R1'", ":", "score", ",", "\n", "'nlabel'", ":", "num_sent_sel", ",", "\n", "# 'sent': selected_sents_str", "\n", "}", "\n", "early_stop_cnt_down", "+=", "1", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "early_stop_cnt_down", "=", "0", "\n", "best_score", "=", "score", "\n", "", "if", "early_stop_cnt_down", ">=", "5", ":", "\n", "            ", "break", "\n", "", "del", "ref_gram_var", "\n", "del", "len_restrict", "\n", "del", "sent_var_list", "\n", "del", "ref_occurance_constraints", "\n", "del", "all_of_constraints", ",", "prob", ",", "obj", "\n", "# print(result_bag)", "\n", "", "return", "result_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.compression_of_one_sentence": [[151, 153], ["None"], "function", ["None"], ["", "def", "compression_of_one_sentence", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.ILP_protocol_w_compression": [[155, 180], ["print", "reference_summary.split", "list", "len", "cvxpy.Variable", "len", "cvxpy.Variable", "cvxpy.Constant", "constraint_list.append", "cvxpy.Maximize", "cvxpy.Problem", "print", "cp.Problem.solve", "print", "print", "print", "print", "exit", "x.lower", "set", "cvxpy.sum", "len"], "function", ["None"], ["", "def", "ILP_protocol_w_compression", "(", "reference_summary", ":", "str", ",", "sent_units", ":", "List", "[", "str", "]", ",", "compression", ":", "List", "[", "dict", "]", ",", "\n", "min_word_limit", "=", "30", ",", "max_word_limit", "=", "40", ",", "step", "=", "3", ")", ":", "\n", "    ", "print", "(", "\"Compression\"", ")", "\n", "constraint_list", "=", "[", "]", "\n", "ref_toks", "=", "reference_summary", ".", "split", "(", "\" \"", ")", "\n", "ref_toks", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "ref_toks", "]", "\n", "ref_toks_set", "=", "list", "(", "set", "(", "ref_toks", ")", ")", "\n", "uniq_tok_num", "=", "len", "(", "ref_toks_set", ")", "\n", "y_tok", "=", "cp", ".", "Variable", "(", "shape", "=", "(", "uniq_tok_num", ")", ",", "boolean", "=", "True", ")", "\n", "\n", "len_doc", "=", "len", "(", "sent_units", ")", "\n", "sent_var", "=", "cp", ".", "Variable", "(", "shape", "=", "len_doc", ",", "boolean", "=", "True", ")", "\n", "len_of_each_sentence", "=", "cp", ".", "Constant", "(", "[", "len", "(", "x", ")", "for", "x", "in", "sent_units", "]", ")", "\n", "length_constraint_sents", "=", "sent_var", "*", "len_of_each_sentence", "\n", "constraint_list", ".", "append", "(", "length_constraint_sents", "<=", "max_word_limit", ")", "\n", "obj", "=", "cp", ".", "Maximize", "(", "cp", ".", "sum", "(", "ref_toks", ")", ")", "\n", "prob", "=", "cp", ".", "Problem", "(", "obj", ",", "constraints", "=", "constraint_list", ")", "\n", "print", "(", "prob", ")", "\n", "# prob.solve(solver=cp.GLPK_MI)", "\n", "prob", ".", "solve", "(", ")", "\n", "print", "(", "prob", ".", "status", ")", "\n", "print", "(", "obj", ".", "value", ")", "\n", "print", "(", "y_tok", ".", "value", ")", "\n", "print", "(", "sent_var", ".", "value", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.check_every_sent": [[182, 197], ["ref_tok.index"], "function", ["None"], ["", "def", "check_every_sent", "(", "sent", ":", "List", "[", "str", "]", ",", "ref_tok", ":", "List", "[", "str", "]", ",", "ref_occurance_constraints", ",", "x_i", ")", ":", "\n", "# for every sent, check the ref_gram and find those overlapping.", "\n", "# x_i = cp.Variable(boolean=True)  # the indicator of the inclusion of the current text unit", "\n", "# const_bag = []", "\n", "# sent_gram = word_tokenize(sent)", "\n", "# l = len(sent_gram)", "\n", "# sent_gram = list(set(sent_gram))", "\n", "    ", "for", "gram", "in", "sent", ":", "\n", "# if gram not in ref_gram:", "\n", "#     continue", "\n", "        ", "idx", "=", "ref_tok", ".", "index", "(", "gram", ")", "\n", "if", "ref_occurance_constraints", "[", "idx", "]", ":", "\n", "            ", "ref_occurance_constraints", "[", "idx", "]", "=", "ref_occurance_constraints", "[", "idx", "]", "-", "x_i", "\n", "", "else", ":", "\n", "            ", "ref_occurance_constraints", "[", "idx", "]", "=", "-", "x_i", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.analysis.easy_post_processing": [[5, 17], ["inp.strip.strip", "inp.strip.replace", "inp_str.replace.replace", "inp_str[].islower", "len", "inp_str[].upper"], "function", ["None"], ["def", "easy_post_processing", "(", "inp", ":", "str", ")", ":", "\n", "    ", "if", "len", "(", "inp", ")", "<=", "1", ":", "\n", "        ", "return", "\"\"", "\n", "", "inp", "=", "inp", ".", "strip", "(", ")", "\n", "if", "inp", "[", "0", "]", "in", "[", "','", ",", "':'", ",", "';'", ",", "'.'", ",", "'?'", ",", "'!'", "]", ":", "\n", "        ", "inp", "=", "inp", "[", "1", ":", "]", "\n", "\n", "", "inp_str", "=", "inp", ".", "replace", "(", "\", ,\"", ",", "\"\"", ")", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "inp_str", "[", "0", "]", ".", "islower", "(", ")", ":", "\n", "        ", "inp_str", "=", "inp_str", "[", "0", "]", ".", "upper", "(", ")", "+", "inp_str", "[", "1", ":", "]", "\n", "", "return", "inp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.analysis.__remove__": [[19, 37], ["input.replace.replace", "input.replace.split", "zip", "after.split", "u.startswith", "u.endswith", "label.append", "label.append", "after.append", "analysis.easy_post_processing"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing"], ["", "def", "__remove__", "(", "input", ":", "str", ")", ":", "\n", "    ", "input", "=", "input", ".", "replace", "(", "\"Visual:\"", ",", "\"\"", ")", "\n", "units", "=", "input", ".", "split", "(", "\" \"", ")", "\n", "label", "=", "[", "]", "\n", "for", "u", "in", "units", ":", "\n", "        ", "if", "(", "u", ".", "startswith", "(", "\"_\"", ")", "and", "u", ".", "endswith", "(", "\"_\"", ")", ")", ":", "\n", "            ", "label", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "            ", "label", ".", "append", "(", "False", ")", "\n", "", "", "after", "=", "[", "]", "\n", "for", "u", ",", "l", "in", "zip", "(", "units", ",", "label", ")", ":", "\n", "        ", "if", "not", "l", ":", "\n", "            ", "after", ".", "append", "(", "u", ")", "\n", "\n", "", "", "after", "=", "\" \"", ".", "join", "(", "after", ")", "\n", "sents", "=", "after", ".", "split", "(", "\"|\"", ")", "\n", "sents", "=", "\"|\"", ".", "join", "(", "[", "easy_post_processing", "(", "s", ")", "for", "s", "in", "sents", "]", ")", "\n", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.analysis.test": [[39, 45], ["print", "print", "open", "fd.read().splitlines", "analysis.__remove__", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.analysis.__remove__"], ["", "def", "test", "(", ")", ":", "\n", "    ", "print", "(", "\"test\"", ")", "\n", "with", "open", "(", "file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "after_lines", "=", "[", "__remove__", "(", "l", ")", "for", "l", "in", "lines", "]", "\n", "print", "(", "\"\\n\"", ".", "join", "(", "after_lines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.comparison.read_story": [[7, 16], ["open", "fd.read().splitlines", "l.split", "abs.split", "fd.read"], "function", ["None"], ["def", "read_story", "(", "file", ")", ":", "\n", "    ", "with", "open", "(", "file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "liens", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "d", "=", "{", "}", "\n", "for", "l", "in", "liens", ":", "\n", "        ", "part", ",", "uid", ",", "doc", ",", "abs", "=", "l", ".", "split", "(", "\"\\t\"", ")", "\n", "abs_list", "=", "abs", ".", "split", "(", "\"<SPLIT>\"", ")", "\n", "d", "[", "uid", "]", "=", "abs_list", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.comparison.test_xxz": [[18, 47], ["print", "r.get_metric", "comparison.read_story", "comparison.read_story", "comparison.read_story", "f.split", "len", "os.path.join", "os.path.join", "os.path.join", "remain.split", "open", "fd.read().splitlines", "r", "os.listdir", "os.listdir", "x.startswith", "os.path.join", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.comparison.read_story", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.comparison.read_story", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.comparison.read_story"], ["", "def", "test_xxz", "(", ")", ":", "\n", "    ", "test", "=", "\"dm\"", "\n", "\n", "root", "=", "\"/backup3/jcxu/data\"", "\n", "\n", "xxz", "=", "root", "+", "\"/xxz-latent/xxz-output\"", "\n", "\n", "if", "test", "==", "'cnndm'", ":", "\n", "        ", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "xxz", ")", "]", "\n", "d_abs_cnn", "=", "read_story", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"sent_cnn.txt\"", ")", ")", "\n", "d_abs_dm", "=", "read_story", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"sent_dm.txt\"", ")", ")", "\n", "d_abs", "=", "{", "**", "d_abs_cnn", ",", "**", "d_abs_dm", "}", "\n", "", "else", ":", "\n", "\n", "        ", "data_name", "=", "test", "\n", "fname", "=", "\"sent_{}.txt\"", ".", "format", "(", "data_name", ")", "\n", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "xxz", ")", "if", "x", ".", "startswith", "(", "data_name", ")", "]", "\n", "d_abs", "=", "read_story", "(", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", ")", "\n", "\n", "", "for", "f", "in", "files", ":", "\n", "        ", "part", ",", "remain", "=", "f", ".", "split", "(", "\"-\"", ")", "\n", "uid", "=", "remain", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "abs", "=", "d_abs", "[", "uid", "]", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "xxz", ",", "f", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "p", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "r", "(", "pred", "=", "p", ",", "ref", "=", "[", "abs", "]", ")", "\n", "", "", "print", "(", "len", "(", "r", ".", "pred_str_bag", ")", ")", "\n", "r", ".", "get_metric", "(", "reset", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.data_feeder": [[9, 16], ["open", "pickle.load", "os.path.join"], "function", ["None"], ["def", "data_feeder", "(", "path", ",", "flist", ":", "List", "[", "str", "]", ")", ":", "\n", "# flist = ['test.pkl.cnn.00', 'test.pkl.dm.02', 'test.pkl.dm.01', 'test.pkl.dm.00']", "\n", "    ", "for", "f", "in", "flist", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ",", "'rb'", ")", "as", "fd", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "fd", ")", "\n", "for", "instance_fields", "in", "data", ":", "\n", "                ", "yield", "instance_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.show_ratio": [[18, 41], ["enumerate", "math.floor", "str", "d.items", "exit", "print", "int"], "function", ["None"], ["", "", "", "", "def", "show_ratio", "(", "iter", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "d", "=", "{", "}", "\n", "import", "math", "\n", "for", "inst", "in", "iter", ":", "\n", "        ", "ratio", "=", "inst", "[", "'comp_rouge_ratio'", "]", ".", "field_list", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "ratio", ")", ":", "\n", "            ", "if", "idx", ">=", "3", ":", "\n", "                ", "break", "\n", "", "x", "=", "x", ".", "array", "\n", "for", "y", "in", "x", ":", "\n", "                ", "if", "y", ">", "0.001", ":", "\n", "                    ", "cat", "=", "math", ".", "floor", "(", "y", "*", "20", ")", "\n", "key", "=", "str", "(", "cat", ")", "\n", "if", "key", "in", "d", ":", "\n", "                        ", "d", "[", "key", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "d", "[", "key", "]", "=", "1", "\n", "", "cnt", "+=", "1", "\n", "", "if", "cnt", ">", "10000", ":", "\n", "                    ", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "                        ", "print", "(", "\"{}\\t{}\"", ".", "format", "(", "int", "(", "k", ")", "/", "20", ",", "v", ")", ")", "\n", "", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.inspect_every_node_type": [[46, 61], ["len", "collections.Counter", "collections.Counter.most_common", "sum", "len", "len", "len", "len"], "function", ["None"], ["def", "inspect_every_node_type", "(", "name", ",", "lis", ":", "List", ")", ":", "\n", "    ", "l", "=", "len", "(", "lis", ")", "\n", "txts", "=", "[", "x", "[", "0", "]", "for", "x", "in", "lis", "]", "# [ [a,v,c], [asd,asd,asd]///", "\n", "\n", "average_txt_len", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "txts", "]", ")", "/", "len", "(", "txts", ")", "\n", "c", "=", "Counter", "(", ")", "\n", "for", "t", "in", "txts", ":", "\n", "        ", "for", "e", "in", "t", ":", "\n", "            ", "c", "[", "e", "]", "+=", "1", "\n", "# print(c)", "\n", "", "", "populart", "=", "c", ".", "most_common", "(", "10", ")", "\n", "ratio", "=", "[", "x", "[", "2", "]", "for", "x", "in", "lis", "]", "\n", "pos", "=", "[", "x", "for", "x", "in", "ratio", "if", "x", ">=", "1.00", "]", "\n", "pos_rate", "=", "len", "(", "pos", ")", "/", "len", "(", "ratio", ")", "\n", "return", "l", ",", "(", "\"{}\\t{}\\t{}\\t{}\\t{}\"", ".", "format", "(", "name", ",", "l", ",", "average_txt_len", ",", "pos_rate", ",", "populart", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.inspect": [[63, 82], ["len", "collections.Counter", "collections.Counter.most_common", "len", "len", "len", "len", "sum", "len", "len"], "function", ["None"], ["", "def", "inspect", "(", "name", ",", "lis", ")", ":", "\n", "    ", "l", "=", "len", "(", "lis", ")", "\n", "ratio", "=", "[", "x", "[", "2", "]", "for", "x", "in", "lis", "]", "\n", "pos", "=", "[", "x", "for", "x", "in", "ratio", "if", "x", ">=", "1.00", "]", "\n", "pos_rate", "=", "len", "(", "pos", ")", "/", "len", "(", "ratio", ")", "\n", "\n", "act", "=", "[", "x", "[", "1", "]", "for", "x", "in", "lis", "]", "\n", "act_pos", "=", "[", "x", "for", "x", "in", "act", "if", "x", ">", "0.99", "]", "\n", "act_rate", "=", "len", "(", "act_pos", ")", "/", "len", "(", "act", ")", "\n", "\n", "txts", "=", "[", "x", "[", "3", "]", "for", "x", "in", "lis", "]", "\n", "average_txt_len", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "txts", "]", ")", "/", "len", "(", "txts", ")", "\n", "c", "=", "Counter", "(", ")", "\n", "for", "t", "in", "txts", ":", "\n", "        ", "for", "e", "in", "t", ":", "\n", "            ", "c", "[", "e", "]", "+=", "1", "\n", "# print(c)", "\n", "", "", "populart", "=", "c", ".", "most_common", "(", "10", ")", "\n", "return", "l", ",", "(", "\"{}\\t{}\\t{}\\t{}\\t{}\\t{}\"", ".", "format", "(", "name", ",", "l", ",", "average_txt_len", ",", "pos_rate", ",", "populart", ",", "act_rate", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.compression_real_insight": [[87, 117], ["print", "d.items", "open", "fd.read().splitlines", "json.loads", "insight.inspect", "print", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.inspect"], ["def", "compression_real_insight", "(", "iter", ")", ":", "\n", "    ", "f", "=", "\"/scratch/cluster/jcxu/exComp/dmTrue1.0-1True3\"", "\n", "with", "open", "(", "f", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "x", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "x", "=", "x", "[", "1400", ":", "1500", "]", "\n", "d", "=", "{", "}", "\n", "cnt", "=", "0", "\n", "for", "s", "in", "x", ":", "\n", "        ", "y", "=", "json", ".", "loads", "(", "s", ")", "\n", "l", "=", "y", "[", "11", "]", "\n", "for", "unit", "in", "l", ":", "\n", "            ", "node_type", "=", "unit", "[", "'type'", "]", "\n", "leng", "=", "unit", "[", "'len'", "]", "\n", "active", "=", "unit", "[", "'active'", "]", "\n", "word", "=", "unit", "[", "'word'", "]", "\n", "ratio", "=", "unit", "[", "'ratio'", "]", "\n", "cnt", "+=", "1", "\n", "if", "node_type", "in", "d", ":", "\n", "                ", "d", "[", "node_type", "]", "=", "d", "[", "node_type", "]", "+", "[", "[", "leng", ",", "active", ",", "ratio", ",", "word", "]", "]", "\n", "", "else", ":", "\n", "                ", "d", "[", "node_type", "]", "=", "[", "[", "leng", ",", "active", ",", "ratio", ",", "word", "]", "]", "\n", "\n", "", "", "", "bag", "=", "{", "}", "\n", "print", "(", "cnt", ")", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "count", ",", "s", "=", "inspect", "(", "k", ",", "v", ")", "\n", "bag", "[", "\"{}\"", ".", "format", "(", "count", ")", "]", "=", "s", "\n", "# print(s)", "\n", "if", "count", "/", "cnt", ">=", "0.04", ":", "\n", "            ", "print", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.compression_raw_insight": [[119, 152], ["zip", "d.items", "exit", "insight.inspect_every_node_type", "print", "enumerate"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.inspect_every_node_type"], ["", "", "", "def", "compression_raw_insight", "(", "iter", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "d", "=", "{", "}", "\n", "for", "inst", "in", "iter", ":", "\n", "        ", "cp_meta", "=", "inst", "[", "'comp_meta'", "]", ".", "field_list", "\n", "doc_list", "=", "inst", "[", "'metadata'", "]", ".", "metadata", "[", "'doc_list'", "]", "\n", "start", "=", "0", "\n", "for", "cpm", ",", "doc", "in", "zip", "(", "cp_meta", ",", "doc_list", ")", ":", "\n", "# cpm one MetadataField", "\n", "# doc is a list of str", "\n", "            ", "start", "+=", "1", "\n", "if", "start", ">=", "5", ":", "\n", "                ", "break", "\n", "", "for", "compressions", "in", "cpm", ":", "\n", "\n", "                ", "node_type", ",", "sel_idx", ",", "rouge", ",", "ratio", "=", "compressions", "\n", "if", "node_type", "==", "'BASELINE'", "or", "ratio", "<", "0.01", ":", "\n", "                    ", "continue", "\n", "", "cnt", "+=", "1", "\n", "txt", "=", "[", "w", "for", "idx", ",", "w", "in", "enumerate", "(", "doc", ")", "if", "idx", "in", "sel_idx", "]", "\n", "if", "node_type", "in", "d", ":", "\n", "                    ", "d", "[", "node_type", "]", "=", "d", "[", "node_type", "]", "+", "[", "[", "txt", ",", "rouge", ",", "ratio", "]", "]", "\n", "", "else", ":", "\n", "                    ", "d", "[", "node_type", "]", "=", "[", "[", "txt", ",", "rouge", ",", "ratio", "]", "]", "\n", "", "", "", "if", "cnt", ">=", "10000", ":", "\n", "            ", "bag", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "count", ",", "s", "=", "inspect_every_node_type", "(", "k", ",", "v", ")", "\n", "bag", "[", "\"{}\"", ".", "format", "(", "count", ")", "]", "=", "s", "\n", "if", "count", "/", "cnt", ">=", "0.8", ":", "\n", "                    ", "print", "(", "s", ")", "\n", "\n", "", "", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.oracle_to_trim_oracle": [[154, 170], ["ori_bag.append", "comp_bag.append", "print", "print", "exit", "sum", "len", "sum", "len"], "function", ["None"], ["", "", "", "def", "oracle_to_trim_oracle", "(", "iter", ",", "num", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "ori_bag", ",", "comp_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "inst", "in", "iter", ":", "\n", "        ", "try", ":", "\n", "            ", "original", "=", "inst", "[", "'_non_compression_sent_oracle'", "]", "[", "'{}'", ".", "format", "(", "num", ")", "]", "[", "'best'", "]", "[", "'R1'", "]", "\n", "compression", "=", "inst", "[", "'_sent_oracle'", "]", "[", "\"{}\"", ".", "format", "(", "num", ")", "]", "[", "'best'", "]", "[", "'R1'", "]", "\n", "ori_bag", ".", "append", "(", "original", ")", "\n", "comp_bag", ".", "append", "(", "compression", ")", "\n", "cnt", "+=", "1", "\n", "if", "cnt", ">=", "1000", ":", "\n", "                ", "print", "(", "sum", "(", "ori_bag", ")", "/", "len", "(", "ori_bag", ")", ")", "\n", "print", "(", "sum", "(", "comp_bag", ")", "/", "len", "(", "comp_bag", ")", ")", "\n", "exit", "(", ")", "\n", "", "", "except", "TypeError", ":", "\n", "            ", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.insight_compression_raw": [[173, 182], ["insight.data_feeder", "insight.compression_raw_insight"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.data_feeder", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.compression_raw_insight"], ["", "", "", "def", "insight_compression_raw", "(", "data", ",", "path", ":", "str", ",", "\n", "flist", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "iter", "=", "data_feeder", "(", "path", ",", "flist", ")", "\n", "leadn", "=", "3", "\n", "if", "data", "==", "'nyt'", ":", "\n", "        ", "leadn", "=", "5", "\n", "\n", "# oracle_to_trim_oracle(iter, leadn)", "\n", "", "compression_raw_insight", "(", "iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.neusum.insight.read_cp_decision": [[184, 186], ["None"], "function", ["None"], ["", "def", "read_cp_decision", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.training.build_trainer_seq2idx.build_trainer": [[8, 73], ["logging.info", "allennlp.data.iterators.BucketIterator", "allennlp.data.iterators.BucketIterator.index_with", "allennlp.data.iterators.BasicIterator", "allennlp.data.iterators.BasicIterator.index_with", "logging.info", "optim_option.lower", "torch.Adam", "allennlp.training.Trainer", "model.parameters", "optim_option.lower", "torch.SGD", "model.__repr__", "allennlp.training.Trainer", "model.parameters"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.TreeNode.__repr__"], ["def", "build_trainer", "(", "train_data", ",", "\n", "dev_data", ",", "\n", "test_data", ",", "\n", "vocab", ",", "\n", "device_id", ":", "int", ",", "\n", "model", ",", "\n", "optim_option", ":", "str", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "batch_size", ":", "int", "=", "30", ",", "\n", "eval_batch_size", ":", "int", "=", "30", ",", "\n", "lr", ":", "float", "=", "0.0001", ",", "\n", "patience", ":", "int", "=", "30", ",", "\n", "nepo", ":", "int", "=", "30", ",", "\n", "grad_clipping", ":", "float", "=", "0.5", ",", "\n", "validation_metric", ":", "str", "=", "\"+cp-1\"", ",", "\n", "validation_interval", ":", "int", "=", "200", "\n", ")", ":", "\n", "    ", "if", "optim_option", ".", "lower", "(", ")", "==", "\"adam\"", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "", "elif", "optim_option", ".", "lower", "(", ")", "==", "\"sgd\"", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "logging", ".", "info", "(", "'Model Parameters: '", "+", "model", ".", "__repr__", "(", ")", ")", "\n", "training_iterator", "=", "BucketIterator", "(", "batch_size", "=", "batch_size", ",", "sorting_keys", "=", "[", "(", "\"text\"", ",", "\"num_fields\"", ")", "]", ")", "\n", "# training_iterator = BasicIterator(batch_size=batch_size)", "\n", "training_iterator", ".", "index_with", "(", "vocab", ")", "\n", "\n", "eval_iterator", "=", "BasicIterator", "(", "batch_size", "=", "eval_batch_size", ")", "\n", "eval_iterator", ".", "index_with", "(", "vocab", ")", "\n", "logging", ".", "info", "(", "\"validation_metric: {}\"", ".", "format", "(", "validation_metric", ")", ")", "\n", "try", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "3", ",", "\n", "iterator", "=", "training_iterator", ",", "\n", "validation_iterator", "=", "eval_iterator", ",", "\n", "train_dataset", "=", "train_data", ",", "\n", "validation_dataset", "=", "dev_data", ",", "\n", "test_dataset", "=", "test_data", ",", "\n", "patience", "=", "patience", ",", "\n", "num_epochs", "=", "nepo", ",", "\n", "cuda_device", "=", "device_id", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", "validation_interval", "=", "validation_interval", ",", "\n", ")", "\n", "", "except", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "num_serialized_models_to_keep", "=", "3", ",", "\n", "iterator", "=", "training_iterator", ",", "\n", "validation_iterator", "=", "eval_iterator", ",", "\n", "train_dataset", "=", "train_data", ",", "\n", "validation_dataset", "=", "test_data", ",", "\n", "patience", "=", "patience", ",", "\n", "num_epochs", "=", "nepo", ",", "\n", "cuda_device", "=", "device_id", ",", "\n", "grad_clipping", "=", "grad_clipping", ",", "\n", "validation_metric", "=", "validation_metric", ",", "\n", ")", "\n", "", "return", "trainer", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service._para_get_metric": [[14, 21], ["metric.get_metric", "len", "metric.get_metric.keys", "x.endswith"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric"], ["def", "_para_get_metric", "(", "metric", ":", "RougeStrEvaluation", ",", "key", ",", "note", ")", ":", "\n", "    ", "current_metrics", "=", "metric", ".", "get_metric", "(", "reset", "=", "True", ",", "note", "=", "note", ")", "\n", "current_best_cp_A", "=", "[", "x", "for", "x", "in", "current_metrics", ".", "keys", "(", ")", "if", "x", ".", "endswith", "(", "\"_A\"", ")", "]", "\n", "assert", "len", "(", "current_best_cp_A", ")", "==", "1", "\n", "current_best_cp_A", "=", "current_best_cp_A", "[", "0", "]", "\n", "cp_A_val", "=", "current_metrics", "[", "current_best_cp_A", "]", "\n", "return", "current_metrics", ",", "cp_A_val", ",", "metric", ",", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service._para_get_metric_reset_false": [[23, 30], ["metric.get_metric", "len", "metric.get_metric.keys", "x.endswith"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric"], ["", "def", "_para_get_metric_reset_false", "(", "metric", ":", "RougeStrEvaluation", ",", "key", ",", "note", ")", ":", "\n", "    ", "current_metrics", "=", "metric", ".", "get_metric", "(", "reset", "=", "False", ",", "note", "=", "note", ")", "\n", "current_best_cp_A", "=", "[", "x", "for", "x", "in", "current_metrics", ".", "keys", "(", ")", "if", "x", ".", "endswith", "(", "\"_A\"", ")", "]", "\n", "assert", "len", "(", "current_best_cp_A", ")", "==", "1", "\n", "current_best_cp_A", "=", "current_best_cp_A", "[", "0", "]", "\n", "cp_A_val", "=", "current_metrics", "[", "current_best_cp_A", "]", "\n", "return", "current_metrics", ",", "cp_A_val", ",", "metric", ",", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.para_get_metric": [[35, 58], ["list", "list", "len", "multiprocessing.Pool", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "enumerate", "dict_of_rouge.values", "dict_of_rouge.keys", "multiprocessing.Pool.starmap", "multiprocessing.Pool.starmap", "max", "zip", "zip"], "function", ["None"], ["def", "para_get_metric", "(", "dict_of_rouge", ":", "OrderedDict", ",", "reset", ",", "note", "=", "\"\"", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "dict_of_rouge_func", "=", "list", "(", "dict_of_rouge", ".", "values", "(", ")", ")", "# this is only the copy!!!", "\n", "list_rouge_dict_key", "=", "list", "(", "dict_of_rouge", ".", "keys", "(", ")", ")", "\n", "l", "=", "len", "(", "dict_of_rouge_func", ")", "\n", "\n", "cnt", "=", "5", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "if", "reset", ":", "\n", "        ", "out", "=", "pool", ".", "starmap", "(", "_para_get_metric", ",", "zip", "(", "dict_of_rouge_func", ",", "list_rouge_dict_key", ",", "[", "note", "]", "*", "l", ")", ")", "\n", "", "else", ":", "\n", "        ", "out", "=", "pool", ".", "starmap", "(", "_para_get_metric_reset_false", ",", "zip", "(", "dict_of_rouge_func", ",", "list_rouge_dict_key", ",", "[", "note", "]", "*", "l", ")", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "best_cp_A", "=", "0", "\n", "for", "idx", ",", "it", "in", "enumerate", "(", "out", ")", ":", "\n", "        ", "met", ",", "cp_a", ",", "met_write_to_dictofrouge", ",", "key", "=", "it", "\n", "dict_of_rouge", "[", "key", "]", "=", "met_write_to_dictofrouge", "\n", "best_cp_A", "=", "max", "(", "best_cp_A", ",", "cp_a", ")", "\n", "new_dict", "=", "{", "**", "new_dict", ",", "**", "met", "}", "\n", "", "new_dict", "[", "\"cp_A\"", "]", "=", "best_cp_A", "\n", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.multilabel_margin_loss": [[60, 64], ["torch.nn.MultiLabelMarginLoss", "torch.nn.MultiLabelMarginLoss."], "function", ["None"], ["", "def", "multilabel_margin_loss", "(", "inp", ",", "tgt", ")", ":", "\n", "    ", "loss_func", "=", "torch", ".", "nn", ".", "MultiLabelMarginLoss", "(", "reduction", "=", "'none'", ")", "\n", "out", "=", "loss_func", "(", "inp", ",", "tgt", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.print_tensor": [[66, 69], ["inp.cpu().data.numpy", "print", "inp.cpu"], "function", ["None"], ["", "def", "print_tensor", "(", "inp", ")", ":", "\n", "    ", "ts", "=", "inp", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "print", "(", "ts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.flip_first_two_dim": [[71, 76], ["len", "inp.permute().contiguous", "inp.size", "len", "inp.permute().contiguous", "inp.permute", "inp.size", "inp.permute"], "function", ["None"], ["", "def", "flip_first_two_dim", "(", "inp", ")", ":", "\n", "    ", "if", "len", "(", "inp", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "return", "inp", ".", "permute", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "", "elif", "len", "(", "inp", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "        ", "return", "inp", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.clear_dir": [[78, 82], ["os.path.isdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["", "", "def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.meta_str_surgery": [[84, 91], ["basic_service.surgery_on_quotes", "basic_service.surgery_on_quotes"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.surgery_on_quotes", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.surgery_on_quotes"], ["", "def", "meta_str_surgery", "(", "inp_str", ":", "str", ")", ":", "\n", "# if found . '' before the last 15 chars, change it to , ''", "\n", "# if found , '' in the last 15 chars, change it to . ''", "\n", "    ", "loc", "=", "10", "\n", "inp_str", "=", "surgery_on_quotes", "(", "inp_str", ",", "\". ''\"", ",", "\", ''\"", ",", "beg", "=", "0", ",", "end", "=", "-", "loc", ")", "\n", "inp_str", "=", "surgery_on_quotes", "(", "inp_str", ",", "\", ''\"", ",", "\". ''\"", ",", "beg", "=", "-", "loc", ",", "end", "=", "None", ")", "\n", "return", "inp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.surgery_on_quotes": [[93, 117], ["len", "inp_str.find", "inp_str.find"], "function", ["None"], ["", "def", "surgery_on_quotes", "(", "inp_str", ":", "str", ",", "match_str", ":", "str", ",", "replace_with", ":", "str", ",", "beg", ":", "int", ",", "end", ":", "int", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    In region beg to end of inp_str, if find match_str, replace it with replace_with\n    :param inp_str:\n    :param match_str:\n    :param replace_with:\n    :param beg:\n    :param end:\n    :return:\n    \"\"\"", "\n", "\n", "if", "end", "==", "None", ":", "\n", "        ", "fd", "=", "inp_str", ".", "find", "(", "match_str", ",", "beg", ")", "\n", "", "else", ":", "\n", "        ", "fd", "=", "inp_str", ".", "find", "(", "match_str", ",", "beg", ",", "end", ")", "\n", "", "if", "fd", "==", "-", "1", ":", "\n", "        ", "return", "inp_str", "\n", "", "l", "=", "len", "(", "match_str", ")", "\n", "left", "=", "inp_str", "[", ":", "fd", "]", "\n", "right", "=", "inp_str", "[", "fd", "+", "l", ":", "]", "\n", "# print(left)", "\n", "# print(right)", "\n", "new_str", "=", "left", "+", "replace_with", "+", "right", "\n", "return", "new_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing": [[119, 159], ["inp.strip.strip", "inp.strip.replace", "inp_str.replace.replace", "inp_str.replace.replace", "inp_str[].islower", "inp_str.replace.strip", "inp_str.replace.replace", "inp_str.replace.find", "inp_str.replace.find", "len", "len", "inp_str[].upper"], "function", ["None"], ["", "def", "easy_post_processing", "(", "inp", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Given a string from the compression model, 1) remove first ,:;.?!\n    2) remove redundant 3) upper case first char.\n    :param inp:\n    :return:\n    \"\"\"", "\n", "\n", "inp", "=", "inp", ".", "strip", "(", ")", "\n", "\n", "# remove first punctuation", "\n", "while", "True", ":", "\n", "        ", "if", "len", "(", "inp", ")", "<=", "1", ":", "\n", "            ", "return", "\"\"", "\n", "", "if", "inp", "[", "0", "]", "in", "\",.!:;?\"", ":", "\n", "            ", "inp", "=", "inp", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "inp_str", "=", "inp", ".", "replace", "(", "\"` '\"", ",", "\"\"", ")", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\", ,\"", ",", "\"\"", ")", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "# replace , '' if occurs at the end", "\n", "if", "inp_str", ".", "find", "(", "\", ''\"", ",", "-", "13", ")", ">", "0", ":", "\n", "        ", "loc", "=", "inp_str", ".", "find", "(", "\", ''\"", ",", "-", "13", ")", "\n", "inp_str", "=", "inp_str", "[", ":", "loc", "]", "+", "\". ''\"", "+", "inp_str", "[", "loc", "+", "4", ":", "]", "\n", "\n", "# inp_str = inp_str.replace(\", ''\", \". ''\")", "\n", "\n", "# Captulize the first char", "\n", "", "if", "inp_str", "[", "0", "]", ".", "islower", "(", ")", ":", "\n", "        ", "inp_str", "=", "inp_str", "[", "0", "]", ".", "upper", "(", ")", "+", "inp_str", "[", "1", ":", "]", "\n", "\n", "", "inp_str", "=", "inp_str", ".", "strip", "(", ")", "\n", "if", "inp_str", "[", "-", "1", "]", "not", "in", "punc", ":", "\n", "        ", "inp_str", "=", "inp_str", "+", "'.'", "\n", "", "inp_str", "=", "inp_str", ".", "replace", "(", "\", .\"", ",", "\".\"", ")", "\n", "if", "len", "(", "inp_str", ")", "<", "4", ":", "\n", "        ", "return", "\"\"", "\n", "", "return", "inp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.prepare_global_logger": [[161, 173], ["logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.getLogger().addHandler", "os.path.isfile", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.getLogger().addHandler", "logging.getLogger().setLevel", "logging.getLogger", "os.remove", "logging.getLogger", "logging.getLogger", "logging.getLogger"], "function", ["None"], ["", "def", "prepare_global_logger", "(", "stdout_file_name", ",", "\n", "level", "=", "logging", ".", "DEBUG", ")", ":", "\n", "    ", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "level", "+", "10", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "ch", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "stdout_file_name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "stdout_file_name", ")", "\n", "", "stdout_handler", "=", "logging", ".", "FileHandler", "(", "stdout_file_name", ")", "\n", "stdout_handler", ".", "setLevel", "(", "level", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "stdout_handler", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "setLevel", "(", "level", ")", "\n", "return", "logging", ".", "getLogger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.prepare_file_name": [[178, 187], ["random.randrange", "_tmp.append", "list", "str", "kwargs.items", "_tmp.append", "len"], "function", ["None"], ["def", "prepare_file_name", "(", "**", "kwargs", ")", ":", "\n", "    ", "_tmp", "=", "[", "]", "\n", "rand_id", "=", "random", ".", "randrange", "(", "1000", ")", "\n", "_tmp", ".", "append", "(", "str", "(", "rand_id", ")", ")", "\n", "for", "k", ",", "v", "in", "list", "(", "kwargs", ".", "items", "(", ")", ")", ":", "\n", "        ", "_tmp", ".", "append", "(", "'{}_{}'", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "if", "len", "(", "_tmp", ")", ">", "10", ":", "\n", "            ", "break", "\n", "", "", "return", "'-'", ".", "join", "(", "_tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.convert_list_to_paragraph": [[189, 206], ["bag.append", "buff.append", "bag.append"], "function", ["None"], ["", "def", "convert_list_to_paragraph", "(", "inp", ",", "split_token", "=", "'@@SS@@'", ")", ":", "\n", "# ['Gauk-Roger', 'contributed','@@SS@@', 'to', 'this', 'report', '.', '@@SS@@']", "\n", "# => [\"Gauk-Roger contributed\", \"to this report .\"]", "\n", "    ", "bag", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "for", "x", "in", "inp", ":", "\n", "        ", "if", "(", "x", "==", "''", ")", "or", "(", "x", "==", "' '", ")", ":", "\n", "            ", "continue", "\n", "", "if", "x", "!=", "split_token", ":", "\n", "            ", "buff", ".", "append", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "if", "buff", "is", "not", "[", "]", ":", "\n", "                ", "bag", ".", "append", "(", "' '", ".", "join", "(", "buff", ")", ")", "\n", "buff", "=", "[", "]", "\n", "", "", "", "if", "buff", "is", "not", "[", "]", ":", "\n", "        ", "bag", ".", "append", "(", "' '", ".", "join", "(", "buff", ")", ")", "\n", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_predict_example": [[208, 221], ["logging.getLogger", "logging.getLogger.info", "random.random", "print"], "function", ["None"], ["", "def", "log_predict_example", "(", "name", ",", "pred_label", ",", "gold_label", ",", "pred_abs", ",", "gold_abs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "\"\\nName: {}\\t~~Logit: {}\\t~~Label: {}\"", "\n", "\"\\n--Pred: {}\\n--Ref: {}\\n\"", ".", "format", "(", "name", ",", "\n", "pred_label", ",", "gold_label", ",", "\n", "' | '", ".", "join", "(", "pred_abs", ")", ",", "\n", "' | '", ".", "join", "(", "gold_abs", ")", ")", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "0.02", ":", "\n", "        ", "print", "(", "\"\\nName: {}\\t~~Logit: {}\\t~~Label: {}\"", "\n", "\"\\n--Pred: {}\\n--Ref: {}\\n\"", ".", "format", "(", "name", ",", "\n", "pred_label", ",", "gold_label", ",", "\n", "' | '", ".", "join", "(", "pred_abs", ")", ",", "\n", "' | '", ".", "join", "(", "gold_abs", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_compression_example": [[223, 234], ["logging.getLogger", "zip", "logging.getLogger.info", "len", "len", "len", "len", "s.append"], "function", ["None"], ["", "", "def", "log_compression_example", "(", "name", ",", "pred_sent", ",", "pred_rouge", ",", "potential_oracle_sent", ",", "potential_rouge", ",", "abs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "assert", "len", "(", "pred_sent", ")", "==", "len", "(", "pred_rouge", ")", "==", "len", "(", "potential_oracle_sent", ")", "==", "len", "(", "potential_rouge", ")", "\n", "s", "=", "[", "]", "\n", "for", "a", ",", "b", ",", "c", ",", "d", ",", "in", "zip", "(", "pred_sent", ",", "pred_rouge", ",", "potential_oracle_sent", ",", "potential_rouge", ")", ":", "\n", "        ", "s", ".", "append", "(", "\"=-\\t{0}\\t{1:.2f}\\t{2}\\t{3:.2f}\"", ".", "format", "(", "a", ",", "b", ",", "c", ",", "d", ")", ")", "\n", "", "s", "=", "\"\\n\"", ".", "join", "(", "s", ")", "\n", "logger", ".", "info", "(", "\"=-Name: {}\\t=-Pred_Sent\\t=-Potential\\n{}\"", "\n", "\"\\n--Ref: {}\\n\"", ".", "format", "(", "name", ",", "\n", "s", ",", "\n", "' | '", ".", "join", "(", "abs", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_universal": [[239, 253], ["logging.getLogger", "kwargs.items", "logging.getLogger.info", "type", "pr.append", "type", "pr.append", "type", "pr.append", "pr.append"], "function", ["None"], ["def", "log_universal", "(", "**", "kwargs", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "pr", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "        ", "if", "type", "(", "value", ")", "==", "str", ":", "\n", "            ", "pr", ".", "append", "(", "\"{}: {}\"", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "", "elif", "type", "(", "value", ")", "==", "float", ":", "\n", "            ", "pr", ".", "append", "(", "\"{0}: {1:.2f}\"", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "", "elif", "type", "(", "value", ")", "==", "List", ":", "\n", "            ", "for", "ele", "in", "value", ":", "\n", "                ", "pr", ".", "append", "(", "\"{}: {}\"", ".", "format", "(", "key", ",", "ele", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "pr", ".", "append", "(", "\"{}: {}\"", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "", "", "logger", ".", "info", "(", "\"\\n\"", ".", "join", "(", "pr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_a_string": [[255, 258], ["logging.getLogger", "logging.getLogger.info"], "function", ["None"], ["", "def", "log_a_string", "(", "inp", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.isnan": [[260, 262], ["None"], "function", ["None"], ["", "def", "isnan", "(", "x", ")", ":", "\n", "    ", "return", "x", "!=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.checkNaN": [[264, 275], ["torch.isinf", "torch.sum", "print", "KeyError", "exit", "torch.sum", "print", "KeyError", "exit"], "function", ["None"], ["", "def", "checkNaN", "(", "inp", ")", ":", "\n", "    ", "x", "=", "(", "inp", "!=", "inp", ")", "\n", "indicator", "=", "torch", ".", "isinf", "(", "inp", ")", "\n", "if", "torch", ".", "sum", "(", "indicator", ")", ">", "0", ":", "\n", "        ", "print", "(", "indicator", ")", "\n", "raise", "KeyError", "(", "\"Inf\"", ")", "\n", "exit", "(", ")", "\n", "", "if", "torch", ".", "sum", "(", "x", ")", ">", "0", ":", "\n", "        ", "print", "(", "inp", ")", "\n", "raise", "KeyError", "(", "\"NaN\"", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_span": [[277, 305], ["open", "fd.read().splitlines", "span_sent_idx.append", "span_txt.append", "len", "txt_buff.append", "l.split", "fd.read", "int", "int", "span_sent_idx.append", "span_txt.append", "txt_buff.append"], "function", ["None"], ["", "", "def", "read_merge_span", "(", "fpath", ")", ":", "\n", "    ", "span_txt", "=", "[", "]", "\n", "span_sent_idx", "=", "[", "]", "\n", "\n", "txt_buff", "=", "[", "]", "\n", "sent_idx_buff", "=", "0", "\n", "current_span_idx", "=", "1", "\n", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "for", "l", "in", "lines", ":", "\n", "        ", "if", "len", "(", "l", ")", "<", "2", ":", "\n", "            ", "txt_buff", ".", "append", "(", "'@@SS@@'", ")", "\n", "", "else", ":", "\n", "            ", "tabs", "=", "l", ".", "split", "(", "'\\t'", ")", "\n", "sent_idx", ",", "word", ",", "edu_idx", "=", "int", "(", "tabs", "[", "0", "]", ")", ",", "tabs", "[", "2", "]", ",", "int", "(", "tabs", "[", "-", "1", "]", ")", "\n", "\n", "if", "edu_idx", "!=", "current_span_idx", ":", "\n", "                ", "span_sent_idx", ".", "append", "(", "sent_idx_buff", ")", "\n", "sent_idx_buff", "=", "sent_idx", "\n", "span_txt", ".", "append", "(", "' '", ".", "join", "(", "txt_buff", ")", ")", "\n", "txt_buff", "=", "[", "word", "]", "\n", "current_span_idx", "=", "edu_idx", "\n", "", "else", ":", "\n", "                ", "txt_buff", ".", "append", "(", "word", ")", "\n", "", "", "", "if", "txt_buff", "!=", "[", "]", ":", "\n", "        ", "span_sent_idx", ".", "append", "(", "sent_idx_buff", ")", "\n", "span_txt", ".", "append", "(", "' '", ".", "join", "(", "txt_buff", ")", ")", "\n", "", "return", "span_txt", ",", "span_sent_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.batch_extraction_from_dict": [[307, 309], ["None"], "function", ["None"], ["", "def", "batch_extraction_from_dict", "(", "batch_data", ",", "key_name", ")", ":", "\n", "    ", "return", "[", "d", "[", "key_name", "]", "for", "d", "in", "batch_data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.convert_msk_to_span_indices": [[311, 325], ["mask_matrix.get_device", "torch.zeros", "enumerate", "mask_matrix.size", "torch.sum", "torch.device"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device"], ["", "def", "convert_msk_to_span_indices", "(", "mask_matrix", ")", ":", "\n", "    ", "\"\"\"\n    mask_matrix: batchsz, seq_len       float tensor\n    :return: # (batch_size, num_spans=1, 2)\n    \"\"\"", "\n", "device_id", "=", "mask_matrix", ".", "get_device", "(", ")", "\n", "batchsz", "=", "mask_matrix", ".", "size", "(", ")", "[", "0", "]", "\n", "# print(device_id)", "\n", "len_info", "=", "torch", ".", "sum", "(", "mask_matrix", ",", "dim", "=", "1", ")", ".", "data", "\n", "span", "=", "torch", ".", "zeros", "(", "[", "batchsz", ",", "1", ",", "2", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "device_id", ")", ")", ")", "\n", "for", "idx", ",", "l", "in", "enumerate", "(", "len_info", ")", ":", "\n", "        ", "span", "[", "idx", ",", "0", ",", "1", "]", "=", "l", "-", "1", "\n", "# print(span)", "\n", "", "return", "span", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_simple": [[327, 338], ["open", "fd.read().splitlines", "fd.read", "len", "bag.append", "bag.append", "l.split"], "function", ["None"], ["", "def", "read_merge_simple", "(", "fpath", ")", ":", "\n", "    ", "\"\"\"Only return the words as a string\"\"\"", "\n", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "bag", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "            ", "if", "len", "(", "l", ")", "<", "2", ":", "\n", "                ", "bag", ".", "append", "(", "'\\n'", ")", "\n", "", "else", ":", "\n", "                ", "bag", ".", "append", "(", "l", ".", "split", "(", "'\\t'", ")", "[", "2", "]", ")", "\n", "", "", "", "return", "' '", ".", "join", "(", "bag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.print_size": [[340, 345], ["enumerate", "print", "print", "x.size", "v.size"], "function", ["None"], ["", "def", "print_size", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "x", "in", "args", ":", "\n", "        ", "print", "(", "x", ".", "size", "(", ")", ")", "\n", "", "for", "k", ",", "v", "in", "enumerate", "(", "kwargs", ")", ":", "\n", "        ", "print", "(", "\"K :{}\"", ".", "format", "(", "v", ".", "size", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_board_file": [[350, 390], ["datetime.datetime.now", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "rt_list.append", "str", "os.path.isfile", "open", "file.write", "k.startswith", "k.startswith", "rt_list.append", "rt_list.append", "open", "fd.write"], "function", ["None"], ["def", "log_board_file", "(", "fpath", ",", "args", ",", "metrics", ":", "dict", ")", ":", "\n", "    ", "rt_list", "=", "[", "]", "\n", "if", "args", ".", "dbg", ":", "\n", "        ", "return", "\n", "", "time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "rt_list", ".", "append", "(", "\"Time: {}\"", ".", "format", "(", "time", ")", ")", "\n", "\n", "rt_list", ".", "append", "(", "\"Data Name\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "data_name", ")", "\n", "rt_list", ".", "append", "(", "\"Compression\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "compression", ")", "\n", "rt_list", ".", "append", "(", "\"aggressive_compression\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "aggressive_compression", ")", "\n", "rt_list", ".", "append", "(", "\"alpha\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "alpha", ")", "\n", "rt_list", ".", "append", "(", "\"fix_edu_num\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "fix_edu_num", ")", "\n", "rt_list", ".", "append", "(", "\"schedule\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "schedule", ")", "\n", "rt_list", ".", "append", "(", "\"compress_leadn\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "compress_leadn", ")", "\n", "\n", "for", "k", "in", "metrics", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "\"validation_\"", ")", "or", "k", ".", "startswith", "(", "\"best_test_\"", ")", "or", "(", "k", "==", "\"training_epochs\"", ")", "or", "(", "\n", "k", "==", "\"training_loss\"", ")", "or", "(", "k", "==", "\"validation_loss\"", ")", ":", "\n", "            ", "rt_list", ".", "append", "(", "k", ")", "\n", "rt_list", ".", "append", "(", "metrics", "[", "k", "]", ")", "\n", "", "", "rt_list", ".", "append", "(", "\"FileName\"", ")", "\n", "rt_list", ".", "append", "(", "args", ".", "fname", ")", "\n", "# log all validation_", "\n", "# log all best_test_", "\n", "# log training_epochs training_loss validation_loss", "\n", "rt_list", "=", "[", "str", "(", "x", ")", "for", "x", "in", "rt_list", "]", "\n", "rt", "=", "\"\\t\"", ".", "join", "(", "rt_list", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "        ", "with", "open", "(", "fpath", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "with", "open", "(", "fpath", ",", "'a'", ")", "as", "file", ":", "\n", "        ", "file", ".", "write", "(", "\"\\n\"", "+", "rt", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.argparser.parse_arg_interface": [[4, 111], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_arg_interface", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch Summarization Model'", ")", "\n", "# Mode", "\n", "parser", ".", "add_argument", "(", "'--dbg'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"debug mode or not. If dbg, load less data and no pre-training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "\"train or test\"", ")", "\n", "# Meta", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "default", "=", "'cnn'", ",", "\n", "help", "=", "'cnn or dailymail or cnn-dailymail; name of the data corpus'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "2019", ",", "help", "=", "'random seed'", ")", "\n", "# Dir", "\n", "parser", ".", "add_argument", "(", "'--abs_dir_root'", ",", "action", "=", "'store'", ",", "type", "=", "str", "\n", ",", "default", "=", "'/backup2/jcxu/exComp'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--abs_board_file'", ",", "action", "=", "'store'", "\n", "# , default='/backup2/jcxu/exComp/board.txt', type=str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--abs_dir_exp'", ",", "action", "=", "'store'", "\n", ",", "default", "=", "''", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--abs_dir_log'", ",", "action", "=", "'store'", "\n", "# , default='/backup2/jcxu/exComp/log'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--abs_dir_data'", ",", "action", "=", "'store'", ",", "default", "=", "'/backup2/jcxu/data/read_ready-grammarTrue-miniTrue'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_embedding'", ",", "action", "=", "'store'", ")", "\n", "# Hyper param about MODEL", "\n", "parser", ".", "add_argument", "(", "'--elmo'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Use ELMO'", ")", "\n", "parser", ".", "add_argument", "(", "'--elmo_num_output_representations'", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--hid_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'number of hidden units per layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'size of word embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dec_step'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"Default value for the max decoding steps\"", ")", "\n", "parser", ".", "add_argument", "(", "'--min_dec_step'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout_emb'", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "'--span_encoder_type'", ",", "default", "=", "'self_attentive'", ")", "\n", "parser", ".", "add_argument", "(", "'--nenc_lay'", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "'--attn_type'", ",", "default", "=", "'general'", ",", "help", "=", "'general or dot'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--compression'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--aggressive_compression'", ",", "default", "=", "-", "1", ",", "action", "=", "'store'", ",", "\n", "type", "=", "int", ",", "help", "=", "\"specify the num of deletion: -1=independent classifier,\"", "\n", "\"1, 2, 3... means num of deletion.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--subsentence'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "\"Subsentence level selection\"", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "action", "=", "'store'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"sent loss + alpha * compression loss\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lazy'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "\"Data loading\"", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_alpha'", ",", "action", "=", "'store'", ",", "default", "=", "0.00001", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--bias_alpha'", ",", "action", "=", "'store'", ",", "default", "=", "0.00001", ",", "type", "=", "float", ")", "\n", "# EDU", "\n", "parser", ".", "add_argument", "(", "'--train_fname'", ",", "type", "=", "str", ",", "default", "=", "\"train.pkl\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_fname'", ",", "type", "=", "str", ",", "default", "=", "\"dev.pkl\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_fname'", ",", "type", "=", "str", ",", "default", "=", "\"test.pkl\"", ")", "\n", "parser", ".", "add_argument", "(", "'--single_oracle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_edu_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--mult_orac_sampling'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--trim_sent_oracle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "# Hyper param about training", "\n", "parser", ".", "add_argument", "(", "'--schedule'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "help", "=", "\"schedule_ratio_from_ground_truth\"", ")", "# TODO", "\n", "parser", ".", "add_argument", "(", "'--eval_batch_size'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "'evaluation batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "metavar", "=", "'N'", ",", "help", "=", "'batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "5.0", ",", "\n", "help", "=", "'gradient clipping'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "70", ",", "\n", "help", "=", "'upper epoch limit'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "help", "=", "'sgd or adam'", ")", "\n", "# Device", "\n", "parser", ".", "add_argument", "(", "'--device_use_cpu'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--device_cuda_id'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--validation_interval'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "# new", "\n", "parser", ".", "add_argument", "(", "'--compress_leadn'", ",", "default", "=", "-", "1", ",", "action", "=", "'store'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dec_avd_trigram_rep'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--keep_threshold'", ",", "default", "=", "1.", ",", "action", "=", "'store'", ",", "type", "=", "float", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gather'", ",", "type", "=", "str", ",", "default", "=", "'sum'", ",", "help", "=", "'mean or sum or attn'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_saved_model'", ",", "type", "=", "str", ")", "\n", "\"\"\"\n    # Absolute path\n    parser.add_argument('--exp_path', type=str, default='/backup2/jcxu/summa_log', help=\"Absolute path of experiments\")\n\n    # Relative path to root\n    parser.add_argument('--root_path', type=str, default='/backup2/jcxu/exComp')\n    parser.add_argument('--log_path', type=str, default='log', help=\"relative location of the log path given root path\")\n\n    parser.add_argument('--data_pretrain_emb', type=str,\n                        default='data/1-billion-word-language-modeling-benchmark-r13output.word2vec.vec')\n\n    parser.add_argument('--dict_sz', type=int, default=40000, help=\"The size of the dict\")\n\n    parser.add_argument('--num_sample_rollout', type=int, default=20)\n\n    parser.add_argument('--tmp_directory', type=str, default='')\n    parser.add_argument('--gold_summary_directory', action='store',\n                        type=str, default='data/Baseline-Gold-Models')\n\n    parser.add_argument('--rouge_reweighted', action='store_true', default=False,\n                        help=\"Using Rouge value to reweight the loss\")\n\n    # Sequence to Sequence\n    parser.add_argument('--enc', type=str, default='lstm', help='lstm or gru or bow')\n\n\n    \"\"\"", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.test_surgery_on_quotes.TestSurgery_on_quotes.test_surgery_on_quotes": [[7, 14], ["neusum.service.basic_service.meta_str_surgery", "print", "neusum.service.basic_service.meta_str_surgery", "print"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.meta_str_surgery", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.meta_str_surgery"], ["    ", "def", "test_surgery_on_quotes", "(", "self", ")", ":", "\n", "        ", "inp_str", "=", "\"asd , ''hghghghghghghg\"", "\n", "out", "=", "meta_str_surgery", "(", "inp_str", ")", "\n", "print", "(", "\"---\"", "+", "out", ")", "\n", "inp_str", "=", "\"asd . ''hghghghghghghg\"", "\n", "out", "=", "meta_str_surgery", "(", "inp_str", ")", "\n", "print", "(", "\"---\"", "+", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device": [[6, 8], ["None"], "function", ["None"], ["def", "get_device", "(", ")", ":", "\n", "    ", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device_id": [[10, 12], ["None"], "function", ["None"], ["", "def", "get_device_id", "(", ")", ":", "\n", "    ", "return", "device_id", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.set_device_id": [[14, 17], ["None"], "function", ["None"], ["", "def", "set_device_id", "(", "x", ")", ":", "\n", "    ", "global", "device_id", "\n", "device_id", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.set_device": [[19, 22], ["None"], "function", ["None"], ["", "def", "set_device", "(", "x", ")", ":", "\n", "    ", "global", "device", "\n", "device", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_vocab": [[24, 26], ["None"], "function", ["None"], ["", "def", "get_vocab", "(", ")", ":", "\n", "    ", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.set_vocab": [[28, 31], ["None"], "function", ["None"], ["", "def", "set_vocab", "(", "x", ")", ":", "\n", "    ", "global", "vocab", "\n", "vocab", "=", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.test_easy_post_processing.TestEasy_post_processing.test_easy_post_processing": [[6, 16], ["neusum.service.basic_service.easy_post_processing", "print"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing"], ["    ", "def", "test_easy_post_processing", "(", "self", ")", ":", "\n", "        ", "inp", "=", "[", "\n", "\"In two years ' time , the Scandinavian nation is slated to become the first in the world to phase out radio entirely .\"", ",", "\n", "\"Digitally , there are four times that number .\"", ",", "\n", "\"Frum : Ukrainians want to enter EU and lessen dependence on Russia ; Putin fighting to stop it .\"", ",", "\n", "\"-LRB- CNN -RRB- He might have just won one of sport 's most prestigious events , but it was n't long before Jordan Spieth 's thoughts turned to his autistic sister in the glow of victory . \"", "\n", "]", "\n", "for", "x", "in", "inp", ":", "\n", "            ", "y", "=", "easy_post_processing", "(", "x", ")", "\n", "print", "(", "y", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.nn_services.ptr_network_index_select": [[4, 18], ["context.size", "torch.from_numpy().to", "context.view", "torch.index_select", "select_idx.size", "torch.from_numpy", "np.linspace"], "function", ["None"], ["def", "ptr_network_index_select", "(", "device", ",", "context", ",", "select_idx", ")", ":", "\n", "# context: batch, seq, dim", "\n", "# selec_idx: batch", "\n", "    ", "batch", ",", "seq", ",", "dim", "=", "context", ".", "size", "(", ")", "\n", "batch_", "=", "select_idx", ".", "size", "(", ")", "[", "0", "]", "\n", "assert", "batch", "==", "batch_", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "linspace", "(", "start", "=", "0", ",", "stop", "=", "batch", "*", "seq", ",", "num", "=", "batch", ",", "endpoint", "=", "False", ",", "dtype", "=", "np", ".", "int", ")", ")", ".", "to", "(", "device", ")", "\n", "select_idx", "=", "select_idx", "+", "mask", "\n", "\n", "flatten_context", "=", "context", ".", "view", "(", "batch", "*", "seq", ",", "dim", ")", "\n", "# print(flatten_context.size())", "\n", "output", "=", "torch", ".", "index_select", "(", "flatten_context", ",", "0", ",", "select_idx", ")", "\n", "# print(\"output\",output.size())", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.iterator": [[6, 8], ["None"], "function", ["None"], ["def", "iterator", "(", "bag", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.dropword": [[14, 19], ["inp_str.split", "random.sample", "range", "int", "len", "enumerate", "len"], "function", ["None"], ["def", "dropword", "(", "inp_str", ":", "str", ")", ":", "\n", "    ", "inp_list", "=", "inp_str", ".", "split", "(", "\" \"", ")", "\n", "indc", "=", "random", ".", "sample", "(", "range", "(", "0", ",", "len", "(", "inp_list", ")", ")", ",", "int", "(", "len", "(", "inp_list", ")", "/", "10", ")", ")", "\n", "inp_list", "=", "[", "x", "for", "idx", ",", "x", "in", "enumerate", "(", "inp_list", ")", "if", "idx", "not", "in", "indc", "]", "\n", "return", "\" \"", ".", "join", "(", "inp_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.replace_lrbrrb": [[21, 25], ["inp_str.replace.replace", "inp_str.replace.replace"], "function", ["None"], ["", "def", "replace_lrbrrb", "(", "inp_str", ":", "str", ")", ":", "\n", "    ", "inp_str", "=", "inp_str", ".", "replace", "(", "\"-LRB-\"", ",", "'('", ")", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"-RRB-\"", ",", "')'", ")", "\n", "return", "inp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.assign_task": [[30, 48], ["zip", "list", "random.shuffle", "range", "cells.append", "range", "range", "int", "int"], "function", ["None"], ["def", "assign_task", "(", "ext_bag", ",", "ext_dp_bag", ",", "model_bag", ",", "see_bag", ")", ":", "\n", "    ", "cells", "=", "[", "]", "\n", "num_of_unit", "=", "4", "\n", "for", "ext", ",", "extdp", ",", "model", ",", "see", "in", "zip", "(", "ext_bag", ",", "ext_dp_bag", ",", "model_bag", ",", "see_bag", ")", ":", "\n", "        ", "_tmp", "=", "[", "None", "for", "_", "in", "range", "(", "2", "*", "num_of_unit", ")", "]", "\n", "lis", "=", "[", "ext", ",", "extdp", ",", "model", ",", "see", "]", "\n", "nam", "=", "[", "'ext'", ",", "'extdp'", ",", "'model'", ",", "'see'", "]", "\n", "idx", "=", "list", "(", "range", "(", "num_of_unit", ")", ")", "\n", "shuffle", "(", "idx", ")", "\n", "for", "m", "in", "range", "(", "num_of_unit", ")", ":", "\n", "            ", "_tmp", "[", "int", "(", "2", "*", "m", ")", "]", "=", "lis", "[", "idx", "[", "m", "]", "]", "\n", "_tmp", "[", "int", "(", "2", "*", "m", "+", "1", ")", "]", "=", "nam", "[", "idx", "[", "m", "]", "]", "\n", "# _tmp[2] = lis[idx[1]]", "\n", "# _tmp[3] = nam[idx[1]]", "\n", "# _tmp[4] = lis[idx[2]]", "\n", "# _tmp[5] = nam[idx[2]]", "\n", "", "cells", ".", "append", "(", "_tmp", ")", "\n", "", "return", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.detok": [[55, 58], ["inp_str.split", "d.detokenize"], "function", ["None"], ["def", "detok", "(", "inp_str", ")", ":", "\n", "    ", "inp_list", "=", "inp_str", ".", "split", "(", "\" \"", ")", "\n", "return", "d", ".", "detokenize", "(", "inp_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.read_abigail_output": [[60, 69], ["os.listdir", "open", "fd.read().splitlines", "os.path.join", "human_eval.detok", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.detok"], ["", "def", "read_abigail_output", "(", "path", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "bag", "=", "[", "]", "\n", "for", "fname", "in", "files", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "fname", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "lines", "=", "[", "detok", "(", "l", ")", "for", "l", "in", "lines", "]", "\n", "bag", "+=", "lines", "\n", "", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.rm_head_cnn": [[71, 76], ["inp_str.find", "inp_str.find"], "function", ["None"], ["", "def", "rm_head_cnn", "(", "inp_str", ":", "str", ")", ":", "\n", "    ", "if", "inp_str", ".", "find", "(", "\"CNN -RRB-\"", ",", "0", ",", "50", ")", ">", "0", ":", "\n", "        ", "where", "=", "inp_str", ".", "find", "(", "\"CNN -RRB-\"", ",", "0", ",", "50", ")", "\n", "inp_str", "=", "inp_str", "[", "where", "+", "9", ":", "]", "\n", "", "return", "inp_str", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.insight.human_eval.fix_vowel": [[78, 91], ["inp_str.split", "len", "range"], "function", ["None"], ["", "def", "fix_vowel", "(", "inp_str", ")", ":", "\n", "    ", "lis", "=", "inp_str", ".", "split", "(", "\" \"", ")", "\n", "v", "=", "\"aeio\"", "\n", "len_of_seq", "=", "len", "(", "lis", ")", "\n", "for", "idx", "in", "range", "(", "len_of_seq", "-", "1", ")", ":", "\n", "        ", "word", "=", "lis", "[", "idx", "]", "\n", "if", "word", "==", "\"a\"", "or", "word", "==", "\"an\"", ":", "\n", "            ", "nex_w", ":", "str", "=", "lis", "[", "idx", "+", "1", "]", "\n", "if", "nex_w", "[", "0", "]", "in", "v", ":", "\n", "                ", "lis", "[", "idx", "]", "=", "\"an\"", "\n", "", "else", ":", "\n", "                ", "lis", "[", "idx", "]", "=", "\"a\"", "\n", "", "", "", "return", "\" \"", ".", "join", "(", "lis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.build_seq2idx.build_model": [[12, 77], ["neusum.models.seq2idx.Seq2IdxSum", "neusum.service.shared_asset.get_device", "model.to.to", "model.to.load_state_dict", "allennlp.nn.regularizers.RegularizerApplicator", "torch.load", "neusum.service.shared_asset.get_device", "allennlp.nn.regularizers.L2Regularizer", "allennlp.nn.regularizers.L1Regularizer"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device"], ["def", "build_model", "(", "\n", "vocab", ",", "embed_dim", ":", "int", "=", "100", ",", "\n", "hid_dim", ":", "int", "=", "100", ",", "\n", "min_dec_step", ":", "int", "=", "2", ",", "\n", "max_decoding_steps", ":", "int", "=", "3", ",", "\n", "fix_edu_num", ":", "int", "=", "-", "1", ",", "\n", "use_elmo", ":", "bool", "=", "False", ",", "\n", "dropout", "=", "0.5", ",", "\n", "dropout_emb", "=", "0.2", ",", "span_encoder_type", "=", "'self_attentive'", ",", "\n", "attn_type", "=", "'dot'", ",", "\n", "schedule_ratio_from_ground_truth", "=", "0.7", ",", "\n", "pretrain_embedding", "=", "None", ",", "\n", "nenc_lay", ":", "int", "=", "1", ",", "\n", "mult_orac_sampling", ":", "bool", "=", "True", ",", "\n", "compression", ":", "bool", "=", "True", ",", "\n", "word_token_indexers", "=", "None", ",", "\n", "alpha", ":", "float", "=", "1.0", ",", "\n", "dbg", ":", "bool", "=", "False", ",", "\n", "dec_avd_trigram_rep", ":", "bool", "=", "True", ",", "\n", "aggressive_compression", ":", "int", "=", "-", "1", ",", "\n", "keep_threshold", ":", "float", "=", "0.5", ",", "\n", "weight_alpha", "=", "0.0", ",", "\n", "bias_alpha", "=", "0.0", ",", "\n", "abs_board_file", ":", "str", "=", "\"/home/cc/exComp/board.txt\"", ",", "\n", "compress_leadn", "=", "-", "1", ",", "\n", "gather", "=", "'mean'", ",", "\n", "abs_dir_root", ":", "str", "=", "\"/scratch/cluster/jcxu\"", ",", "\n", "serilization_name", "=", "\"\"", ",", "\n", "load_save_model", ":", "str", "=", "None", "\n", ")", ":", "\n", "    ", "model", "=", "Seq2IdxSum", "(", "\n", "vocab", "=", "vocab", ",", "\n", "word_embedding_dim", "=", "embed_dim", ",", "\n", "hidden_dim", "=", "hid_dim", ",", "min_dec_step", "=", "min_dec_step", ",", "\n", "max_decoding_steps", "=", "max_decoding_steps", ",", "\n", "fix_edu_num", "=", "fix_edu_num", ",", "\n", "use_elmo", "=", "use_elmo", ",", "span_encoder_type", "=", "span_encoder_type", ",", "\n", "dropout", "=", "dropout", ",", "dropout_emb", "=", "dropout_emb", ",", "\n", "attn_type", "=", "attn_type", ",", "\n", "schedule_ratio_from_ground_truth", "=", "schedule_ratio_from_ground_truth", ",", "\n", "pretrain_embedding_file", "=", "pretrain_embedding", ",", "\n", "nenc_lay", "=", "nenc_lay", ",", "\n", "mult_orac_sampling", "=", "mult_orac_sampling", ",", "\n", "word_token_indexers", "=", "word_token_indexers", ",", "\n", "compression", "=", "compression", ",", "alpha", "=", "alpha", ",", "\n", "dbg", "=", "dbg", ",", "\n", "dec_avd_trigram_rep", "=", "dec_avd_trigram_rep", ",", "\n", "aggressive_compression", "=", "aggressive_compression", ",", "\n", "keep_threshold", "=", "keep_threshold", ",", "\n", "regularizer", "=", "RegularizerApplicator", "(", "[", "(", "\"weight\"", ",", "L2Regularizer", "(", "weight_alpha", ")", ")", ",", "\n", "(", "\"bias\"", ",", "L1Regularizer", "(", "bias_alpha", ")", ")", "]", ")", ",", "\n", "abs_board_file", "=", "abs_board_file", ",", "\n", "gather", "=", "gather", ",", "\n", "compress_leadn", "=", "compress_leadn", ",", "\n", "abs_dir_root", "=", "abs_dir_root", ",", "\n", "serilization_name", "=", "serilization_name", "\n", ")", "\n", "if", "load_save_model", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "load_save_model", ",", "map_location", "=", "get_device", "(", ")", ")", ")", "\n", "#         `` model.load_state_dict(torch.load(\"/path/to/model/weights.th\"))``", "\n", "\n", "# model = torch.nn.DataParallel(model)", "\n", "", "device", "=", "get_device", "(", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.__init__": [[32, 173], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "os.path.join", "neusum.service.shared_asset.get_device", "neusum.nn_modules.enc.enc_doc.EncDoc", "neusum.nn_modules.sent_dec.SentRNNDecoder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "torch.nn.Dropout", "initializer", "neusum.nn_modules.compression_decoder.CompressDecoder", "allennlp.modules.elmo.Elmo", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "logging.getLogger", "logging.getLogger.info", "allennlp.modules.token_embedders.Embedding.from_params", "regularizer", "seq2idx.Seq2IdxSum.enc_doc.get_output_dim", "seq2idx.Seq2IdxSum.enc_doc.get_output_dim", "torch.nn.LSTM", "torch.nn.LSTM", "vocab.get_vocab_size", "allennlp.common.params.Params", "seq2idx.Seq2IdxSum.elmo.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "\n", "\n", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", "\n", "\n", "word_embedding_dim", ":", "int", "=", "200", ",", "\n", "hidden_dim", ":", "int", "=", "200", ",", "\n", "dropout_emb", ":", "float", "=", "0.5", ",", "\n", "min_dec_step", ":", "int", "=", "2", ",", "\n", "max_decoding_steps", "=", "3", ",", "\n", "fix_edu_num", "=", "-", "1", ",", "\n", "dropout", ":", "float", "=", "0.5", ",", "\n", "alpha", ":", "float", "=", "0.5", ",", "\n", "span_encoder_type", "=", "'self_attentive'", ",", "\n", "use_elmo", ":", "bool", "=", "True", ",", "\n", "attn_type", ":", "str", "=", "'general'", ",", "\n", "schedule_ratio_from_ground_truth", ":", "float", "=", "0.8", ",", "\n", "pretrain_embedding_file", "=", "None", ",", "\n", "nenc_lay", ":", "int", "=", "2", ",", "\n", "mult_orac_sampling", ":", "bool", "=", "False", ",", "\n", "word_token_indexers", "=", "None", ",", "\n", "compression", ":", "bool", "=", "True", ",", "\n", "dbg", ":", "bool", "=", "False", ",", "\n", "dec_avd_trigram_rep", ":", "bool", "=", "True", ",", "\n", "aggressive_compression", ":", "int", "=", "-", "1", ",", "\n", "compress_leadn", ":", "int", "=", "-", "1", ",", "\n", "subsentence", ":", "bool", "=", "False", ",", "\n", "gather", "=", "'mean'", ",", "\n", "keep_threshold", ":", "float", "=", "0.5", ",", "\n", "abs_board_file", ":", "str", "=", "\"/home/cc/exComp/board.txt\"", ",", "\n", "abs_dir_root", ":", "str", "=", "\"/scratch/cluster/jcxu\"", ",", "\n", "serilization_name", ":", "str", "=", "\"\"", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", "Seq2IdxSum", ",", "self", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "self", ".", "text_field_embedder", "=", "text_field_embedder", "\n", "\n", "elmo_weight", "=", "os", ".", "path", ".", "join", "(", "abs_dir_root", ",", "\n", "\"elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"", ")", "\n", "# if not os.path.isfile(elmo_weight):", "\n", "#     import subprocess", "\n", "#     x = \"wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5 -P {}\".format(abs_dir_root)", "\n", "#     subprocess.run(x.split(\" \"))", "\n", "\n", "self", ".", "device", "=", "get_device", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "dbg", "=", "dbg", "\n", "self", ".", "loss_thres", "=", "keep_threshold", "\n", "self", ".", "compression", "=", "compression", "\n", "self", ".", "comp_leadn", "=", "compress_leadn", "\n", "# Just encode the whole document without looking at compression options", "\n", "self", ".", "enc_doc", "=", "EncDoc", "(", "inp_dim", "=", "word_embedding_dim", ",", "hid_dim", "=", "hidden_dim", ",", "\n", "vocab", "=", "vocab", ",", "dropout", "=", "dropout", ",", "dropout_emb", "=", "dropout_emb", ",", "\n", "pretrain_embedding_file", "=", "pretrain_embedding_file", ",", "\n", "gather", "=", "gather", "\n", ")", "\n", "\n", "self", ".", "sent_dec", "=", "SentRNNDecoder", "(", "rnn_type", "=", "'lstm'", ",", "\n", "dec_hidden_size", "=", "self", ".", "enc_doc", ".", "get_output_dim", "(", ")", ",", "\n", "dec_input_size", "=", "self", ".", "enc_doc", ".", "get_output_dim", "(", ")", ",", "\n", "dropout", "=", "dropout", ",", "\n", "fixed_dec_step", "=", "fix_edu_num", ",", "\n", "max_dec_steps", "=", "max_decoding_steps", ",", "\n", "min_dec_steps", "=", "min_dec_step", ",", "\n", "schedule_ratio_from_ground_truth", "=", "schedule_ratio_from_ground_truth", ",", "\n", "dec_avd_trigram_rep", "=", "dec_avd_trigram_rep", ",", "\n", "mult_orac_sample_one", "=", "mult_orac_sampling", ",", "\n", "abs_board_file", "=", "abs_board_file", ",", "\n", "valid_tmp_path", "=", "abs_dir_root", ",", "\n", "serilization_name", "=", "serilization_name", "\n", ")", "\n", "if", "compression", ":", "\n", "            ", "self", ".", "compression_dec", "=", "CompressDecoder", "(", "context_dim", "=", "hidden_dim", "*", "2", ",", "\n", "dec_state_dim", "=", "hidden_dim", "*", "2", ",", "\n", "enc_hid_dim", "=", "hidden_dim", ",", "\n", "text_field_embedder", "=", "self", ".", "enc_doc", ".", "_text_field_embedder", ",", "\n", "aggressive_compression", "=", "aggressive_compression", ",", "\n", "keep_threshold", "=", "keep_threshold", ",", "\n", "abs_board_file", "=", "abs_board_file", ",", "\n", "gather", "=", "gather", ",", "\n", "dropout", "=", "dropout", ",", "\n", "dropout_emb", "=", "dropout_emb", ",", "\n", "valid_tmp_path", "=", "abs_dir_root", ",", "\n", "serilization_name", "=", "serilization_name", ",", "\n", "vocab", "=", "vocab", ",", "\n", "elmo", "=", "use_elmo", ",", "\n", "elmo_weight", "=", "elmo_weight", ")", "\n", "self", ".", "aggressive_compression", "=", "aggressive_compression", "\n", "\n", "", "self", ".", "use_elmo", "=", "use_elmo", "\n", "if", "use_elmo", ":", "\n", "            ", "options_file", "=", "\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"", "\n", "weight_file", "=", "\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"", "\n", "self", ".", "elmo", "=", "Elmo", "(", "options_file", ",", "weight_file", ",", "1", ",", "dropout", "=", "0", ")", "\n", "# print(self.elmo.get_output_dim())", "\n", "self", ".", "_context_layer", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", "+", "self", ".", "elmo", ".", "get_output_dim", "(", ")", ",", "hidden_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "\n", "            ", "self", ".", "_context_layer", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "word_embedding_dim", ",", "hidden_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", ")", "\n", "\n", "", "token_embedding", "=", "Embedding", "(", "num_embeddings", "=", "vocab", ".", "get_vocab_size", "(", "'tokens'", ")", ",", "\n", "embedding_dim", "=", "word_embedding_dim", ")", "\n", "if", "pretrain_embedding_file", "is", "not", "None", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "\"Loading word embedding: {}\"", ".", "format", "(", "pretrain_embedding_file", ")", ")", "\n", "token_embedding", ".", "from_params", "(", "vocab", "=", "vocab", ",", "\n", "params", "=", "Params", "(", "{", "\"pretrained_file\"", ":", "pretrain_embedding_file", ",", "\n", "\"embedding_dim\"", ":", "word_embedding_dim", "}", ")", "\n", ")", "\n", "", "self", ".", "_text_field_embedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedding", "}", ")", "\n", "\n", "# if span_encoder_type == 'self_attentive':", "\n", "#     self._span_encoder = SelfAttentiveSpanExtractor(", "\n", "#         self._context_layer.get_output_dim()", "\n", "#     )", "\n", "# else:", "\n", "#     raise NotImplementedError", "\n", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "_max_decoding_steps", "=", "max_decoding_steps", "\n", "self", ".", "_fix_edu_num", "=", "fix_edu_num", "\n", "if", "compression", ":", "\n", "            ", "pass", "\n", "# self.rouge_metrics_compression = self.compression_dec.rouge_metrics_compression", "\n", "# self.rouge_metrics_compression_upper_bound = self.compression_dec.rouge_metrics_compression_best_possible", "\n", "", "self", ".", "rouge_metrics_sent", "=", "self", ".", "sent_dec", ".", "rouge_metrics_sent", "\n", "self", ".", "mult_orac_sampling", "=", "mult_orac_sampling", "\n", "self", ".", "alpha", "=", "alpha", "\n", "initializer", "(", "self", ")", "\n", "if", "regularizer", "is", "not", "None", ":", "\n", "            ", "regularizer", "(", "self", ")", "\n", "", "self", ".", "counter", "=", "0", "# used for controlling compression and extraction", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.forward": [[174, 312], ["text[].size", "sent_label.size", "sent_rouge.size", "comp_rouge.size", "comp_msk.size", "comp_seq_label.size", "allennlp.nn.util.get_text_field_mask().float", "seq2idx.Seq2IdxSum.enc_doc.forward", "neusum.service.basic_service.flip_first_two_dim", "seq2idx.Seq2IdxSum.sent_dec.comp_loss", "seq2idx.Seq2IdxSum.refine_sent_selection", "seq2idx.Seq2IdxSum.sent_dec.forward", "seq2idx.Seq2IdxSum.sent_dec.forward", "sent_emission.detach.detach.detach", "seq2idx.Seq2IdxSum.compression_dec.forward_parallel", "allennlp.nn.util.get_text_field_mask", "seq2idx.Seq2IdxSum.compression_dec.comp_loss", "random.random", "print", "sent_emission.detach.detach.size", "seq2idx.Seq2IdxSum.compression_dec.indep_compression_judger", "seq2idx.Seq2IdxSum.compression_dec.comp_loss_inf_deletion", "seq2idx.Seq2IdxSum.compression_dec.decode", "span_score.detach.detach.detach", "seq2idx.Seq2IdxSum.compression_dec.decode_inf_deletion"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.flip_first_two_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.comp_loss", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.refine_sent_selection", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.forward_parallel", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.comp_loss", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.indep_compression_judger", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.comp_loss_inf_deletion", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.decode", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.decode_inf_deletion"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "\n", "text", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "\n", "sent_label", ",", "\n", "sent_rouge", ",", "\n", "\n", "comp_rouge", ",", "\n", "comp_msk", ",", "\n", "comp_meta", ",", "\n", "comp_rouge_ratio", ",", "\n", "comp_seq_label", ",", "\n", "\n", "metadata", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        :param text: input words. [batch, max_sent, max_word]  0 for padding bit\n        :param sent_label: [batchsize, n_oracles, max_decoding_step] [1,3,6,-1,-1] sorted descendingly by rouge\n        :param sent_rouge: [batchsize, n_oracles]\n        :param comp_rouge: [batchsize, max_sent, max_num_compression] padding with 0\n        :param comp_msk: [batchsize, max_sent, max_num_compression, max_word] deletion mask of compression.\n        :param comp_meta: ScatterableList\n        :param comp_rouge_ratio: [batchsize, max_sent, max_num_compression] after-compression-rouge / baseline rouge\n        :param comp_seq_label: [batchsize, max_sent] index of best compression. padded with -1.\n        :param metadata: ScatterableList\n        :return:\n        \"\"\"", "\n", "\n", "batch", ",", "sent_num", ",", "max_word_num", "=", "text", "[", "'tokens'", "]", ".", "size", "(", ")", "\n", "batch_", ",", "nora", ",", "_max_dec", "=", "sent_label", ".", "size", "(", ")", "\n", "batchsz", ",", "ora_", "=", "sent_rouge", ".", "size", "(", ")", "\n", "batchsize", ",", "max_sent", ",", "max_compre", "=", "comp_rouge", ".", "size", "(", ")", "\n", "batchsize_", ",", "_max_sent", ",", "_max_compre", ",", "_max_word_num", "=", "comp_msk", ".", "size", "(", ")", "\n", "bz", ",", "max_s", "=", "comp_seq_label", ".", "size", "(", ")", "\n", "assert", "batchsize", "==", "bz", "==", "batchsize_", "==", "batch_", "==", "batch", "==", "batchsz", "\n", "assert", "sent_num", "==", "max_sent", "==", "max_s", "\n", "assert", "_max_word_num", "==", "max_word_num", "\n", "text_mask", "=", "util", ".", "get_text_field_mask", "(", "text", ",", "num_wrapping_dims", "=", "1", ")", ".", "float", "(", ")", "\n", "sent_blstm_output", ",", "document_rep", "=", "self", ".", "enc_doc", ".", "forward", "(", "inp", "=", "text", ",", "context_msk", "=", "text_mask", ")", "\n", "# sent_blstm_output: [batch, sent_num, hdim*2]", "\n", "# document_rep: [batch, hdim*2]", "\n", "sent_mask", "=", "text_mask", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "decoder_outputs_logit", ",", "decoder_outputs_prob", ",", "[", "decoder_states_h", ",", "decoder_states_c", "]", "=", "self", ".", "sent_dec", ".", "forward", "(", "context", "=", "sent_blstm_output", ",", "\n", "context_mask", "=", "sent_mask", ",", "# batch size, enc sent num; [1,0]", "\n", "last_state", "=", "document_rep", ",", "# batch size, dim;", "\n", "tgt", "=", "sent_label", ")", "\n", "", "else", ":", "\n", "            ", "decoder_outputs_logit", ",", "decoder_outputs_prob", ",", "[", "decoder_states_h", ",", "decoder_states_c", "]", "=", "self", ".", "sent_dec", ".", "forward", "(", "context", "=", "sent_blstm_output", ",", "\n", "context_mask", "=", "sent_mask", ",", "# batch size, enc sent num; [1,0]", "\n", "last_state", "=", "document_rep", ",", "# batch size, dim;", "\n", "tgt", "=", "None", ")", "\n", "# Compute sent loss", "\n", "", "decoder_outputs_prob", "=", "flip_first_two_dim", "(", "decoder_outputs_prob", ")", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "sent_label", "=", "sent_label", "[", ":", ",", ":", ",", ":", "self", ".", "sent_dec", ".", "max_dec_steps", "]", "\n", "", "sent_loss", ",", "ori_loss", "=", "self", ".", "sent_dec", ".", "comp_loss", "(", "decoder_outputs_prob", "=", "decoder_outputs_prob", ",", "\n", "oracles", "=", "sent_label", ",", "\n", "rouge", "=", "sent_rouge", ")", "\n", "\n", "# comp subsentence model", "\n", "# refine_subsent_selection() default is root        --subsentence", "\n", "sent_emission", "=", "self", ".", "refine_sent_selection", "(", "batchsz", ",", "self", ".", "comp_leadn", ",", "decoder_outputs_logit", ",", "sent_label", ",", "\n", "decoder_outputs_prob", ",", "metadata", ")", "\n", "# run compression module", "\n", "if", "self", ".", "compression", ":", "\n", "# sent_label or decoder_outputs_logit: batch, t", "\n", "\n", "            ", "sent_emission", "=", "sent_emission", ".", "detach", "(", ")", "\n", "####", "\n", "#  sent_emission: t, batch_sz. [4, 13, 0, -1, -1]...", "\n", "####", "\n", "\n", "assert", "sent_emission", ".", "size", "(", ")", "[", "1", "]", "==", "batch_", "\n", "\n", "all_attn_dist", ",", "all_scores", ",", "all_reps", "=", "self", ".", "compression_dec", ".", "forward_parallel", "(", "\n", "sent_decoder_states", "=", "decoder_states_h", ",", "\n", "sent_decoder_outputs_logit", "=", "sent_emission", ",", "\n", "document_rep", "=", "document_rep", ",", "\n", "text", "=", "text", ",", "\n", "text_msk", "=", "text_mask", ",", "\n", "span", "=", "comp_msk", ")", "\n", "# all_reps: t, batch_size_, max_span_num, self.concat_size", "\n", "\n", "if", "self", ".", "aggressive_compression", ">", "0", ":", "\n", "                ", "compression_loss", "=", "self", ".", "compression_dec", ".", "comp_loss", "(", "sent_emission", ",", "all_scores", ",", "\n", "comp_seq_label", ",", "comp_rouge", ",", "\n", "comp_rouge_ratio", ")", "\n", "", "elif", "self", ".", "aggressive_compression", "<", "0", ":", "\n", "# Independent Classifier", "\n", "                ", "span_score", "=", "self", ".", "compression_dec", ".", "indep_compression_judger", "(", "all_reps", ")", "\n", "# span_prob: t, batch, max_span_num, 2", "\n", "compression_loss", "=", "self", ".", "compression_dec", ".", "comp_loss_inf_deletion", "(", "\n", "sent_emission", ",", "comp_rouge", ",", "span_score", ",", "comp_rouge_ratio", ",", "self", ".", "loss_thres", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "            ", "compression_loss", "=", "0", "\n", "# Decoding:", "\n", "", "if", "(", "self", ".", "dbg", "is", "True", ")", "or", "(", "self", ".", "training", "is", "False", ")", ":", "\n", "\n", "            ", "if", "self", ".", "compression", ":", "\n", "                ", "if", "self", ".", "aggressive_compression", ">", "0", ":", "\n", "                    ", "self", ".", "compression_dec", ".", "decode", "(", "decoder_outputs_logit", "=", "sent_emission", ",", "\n", "span_score", "=", "all_scores", ",", "\n", "metadata", "=", "metadata", ",", "\n", "span_meta", "=", "comp_meta", ",", "span_seq_label", "=", "comp_seq_label", ",", "\n", "span_rouge", "=", "comp_rouge", ",", "\n", "compress_num", "=", "self", ".", "aggressive_compression", "\n", ")", "\n", "", "elif", "self", ".", "aggressive_compression", "<", "0", ":", "\n", "# for thres in self.compression_dec.keep_thres:", "\n", "                    ", "span_score", "=", "span_score", ".", "detach", "(", ")", "\n", "self", ".", "compression_dec", ".", "decode_inf_deletion", "(", "sent_decoder_outputs_logit", "=", "sent_emission", ",", "\n", "span_prob", "=", "span_score", ",", "\n", "metadata", "=", "metadata", ",", "\n", "span_meta", "=", "comp_meta", ",", "\n", "span_rouge", "=", "comp_rouge", ",", "\n", "keep_threshold", "=", "self", ".", "compression_dec", ".", "keep_thres", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "", "", "if", "self", ".", "compression", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "0.002", ":", "\n", "                ", "print", "(", "\"Comp loss: {}\"", ".", "format", "(", "compression_loss", ")", ")", "\n", "", "if", "self", ".", "comp_leadn", ">", "0", ":", "\n", "                ", "return", "{", "\"loss\"", ":", "compression_loss", "}", "\n", "", "else", ":", "\n", "# print(\"sent: {}\\tcomp: {}\".format(sent_loss, compression_loss))", "\n", "                ", "return", "{", "\"loss\"", ":", "sent_loss", "+", "self", ".", "alpha", "*", "compression_loss", ",", "\"sent_loss\"", ":", "sent_loss", ",", "\n", "\"compression_loss\"", ":", "compression_loss", "}", "\n", "", "", "else", ":", "\n", "            ", "return", "{", "\"loss\"", ":", "sent_loss", ",", "\"sent_loss\"", ":", "ori_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.get_metrics": [[313, 327], ["seq2idx.Seq2IdxSum.rouge_metrics_sent.get_metric", "neusum.service.basic_service.para_get_metric"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.para_get_metric"], ["", "", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ",", "note", "=", "\"\"", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "# ROUGE", "\n", "        ", "_rouge_met_sent", "=", "self", ".", "rouge_metrics_sent", ".", "get_metric", "(", "reset", "=", "reset", ",", "note", "=", "note", ")", "\n", "if", "self", ".", "compression", ":", "\n", "# _rouge_met_compression_ub = self.rouge_metrics_compression_upper_bound.get_metric(reset, note=note)", "\n", "            ", "if", "self", ".", "aggressive_compression", "<", "0", ":", "\n", "                ", "dic", "=", "self", ".", "compression_dec", ".", "rouge_metrics_compression_dict", "\n", "new_dict", "=", "para_get_metric", "(", "dic", ",", "reset", ",", "note", ")", "\n", "return", "{", "**", "new_dict", ",", "**", "_rouge_met_sent", "}", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "# _rouge_met_compression = self.rouge_metrics_compression.get_metric(reset=reset, note=note)", "\n", "", "", "else", ":", "\n", "            ", "return", "_rouge_met_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.decode": [[328, 405], ["output_logit.cpu().numpy.cpu().numpy.cpu().numpy", "len", "enumerate", "neusum.service.basic_service.convert_list_to_paragraph", "seq2idx.Seq2IdxSum.rouge_metrics", "output_logit.cpu().numpy.cpu().numpy.cpu", "torch.argmax", "torch.argmax.cpu().numpy", "torch.argmax", "torch.argmax.cpu().numpy", "torch.argmax", "torch.argmax.cpu().numpy", "enumerate", "random.random", "neusum.service.basic_service.log_predict_example", "torch.argmax.cpu", "int", "int", "_pred.append", "torch.argmax.cpu", "torch.argmax.cpu", "int", "int", "_pred.append", "[].item", "[].item", "logging.error", "abs", "abs", "[].item", "[].item", "logging.error"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.convert_list_to_paragraph", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_predict_example"], ["", "", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "max_decoding_steps", ":", "int", "=", "6", ",", "\n", "fix_edu_num", ":", "int", "=", "-", "1", ",", "\n", "min_step_decoding", "=", "2", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n\n        :param output_dict: [\"decoder_outputs_logit\", \"decoder_outputs_prob\"\n            \"spans\", \"loss\", \"label\",\n            \"metadata\"[\"doc_list\", \"abs_list\"] ]\n        :param max_decoding_steps:\n        :return:\n        \"\"\"", "\n", "assert", "output_dict", "[", "\"loss\"", "]", "is", "not", "None", "\n", "meta", "=", "output_dict", "[", "\"metadata\"", "]", "\n", "output_logit", "=", "output_dict", "[", "\"decoder_outputs_logit\"", "]", "[", ":", "max_decoding_steps", ",", ":", "]", "\n", "output_logit", "=", "output_logit", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "output_prob", "=", "output_dict", "[", "\"decoder_outputs_prob\"", "]", "\n", "\n", "span_info", "=", "output_dict", "[", "\"spans\"", "]", "\n", "label", "=", "output_dict", "[", "\"label\"", "]", "\n", "\n", "batch_size", "=", "len", "(", "meta", ")", "\n", "for", "idx", ",", "m", "in", "enumerate", "(", "meta", ")", ":", "\n", "            ", "_label", "=", "label", "[", "idx", "]", "# label: batch, step", "\n", "logit", "=", "output_logit", "[", ":", ",", "idx", "]", "\n", "prob", "=", "output_prob", "[", ":", ",", "idx", ",", ":", "]", "# step, src_len", "\n", "sp", "=", "span_info", "[", "idx", "]", "\n", "name", "=", "m", "[", "\"name\"", "]", "\n", "formal_doc", "=", "m", "[", "'doc_list'", "]", "\n", "formal_abs", "=", "m", "[", "'abs_list'", "]", "\n", "abs_s", "=", "convert_list_to_paragraph", "(", "formal_abs", ")", "\n", "\n", "_pred", "=", "[", "]", "\n", "\n", "if", "fix_edu_num", ":", "\n", "                ", "prob", "=", "prob", "[", ":", "fix_edu_num", ",", ":", "]", "\n", "prob", "[", ":", ",", "0", "]", "=", "-", "1000", "\n", "max_idx", "=", "torch", ".", "argmax", "(", "prob", ",", "dim", "=", "1", ")", "\n", "# predict exactly fix_edu_num of stuff", "\n", "# if 0 or unreachable, use prob", "\n", "logit", "=", "max_idx", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "l", "in", "logit", ":", "\n", "                    ", "try", ":", "\n", "                        ", "start_idx", "=", "int", "(", "sp", "[", "l", "]", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "end_idx", "=", "int", "(", "sp", "[", "l", "]", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "words", "=", "formal_doc", "[", "start_idx", ":", "end_idx", "+", "1", "]", "# list", "\n", "_pred", ".", "append", "(", "' '", ".", "join", "(", "words", ")", ".", "replace", "(", "'@@SS@@'", ",", "''", ")", ")", "\n", "", "except", "IndexError", ":", "\n", "                        ", "logging", ".", "error", "(", "\"----Out of range-----\"", ")", "\n", "", "", "", "else", ":", "\n", "# reach minimum requirement (2) of edu num and follow the prediction", "\n", "                ", "max_idx", "=", "torch", ".", "argmax", "(", "prob", ",", "dim", "=", "1", ")", "\n", "logit", "=", "max_idx", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "prob", "[", ":", ",", "0", "]", "=", "-", "1000", "\n", "backup_max_idx", "=", "torch", ".", "argmax", "(", "prob", ",", "dim", "=", "1", ")", "\n", "backup_logit", "=", "backup_max_idx", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "t", ",", "l", "in", "enumerate", "(", "logit", ")", ":", "\n", "                    ", "if", "t", "<", "min_step_decoding", "and", "abs", "(", "l", ")", "<", "0.01", ":", "\n", "                        ", "l", "=", "backup_logit", "[", "t", "]", "\n", "", "elif", "abs", "(", "l", ")", "<", "0.01", ":", "\n", "                        ", "break", "\n", "", "try", ":", "\n", "                        ", "start_idx", "=", "int", "(", "sp", "[", "l", "]", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "end_idx", "=", "int", "(", "sp", "[", "l", "]", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "words", "=", "formal_doc", "[", "start_idx", ":", "end_idx", "+", "1", "]", "# list", "\n", "_pred", ".", "append", "(", "' '", ".", "join", "(", "words", ")", ".", "replace", "(", "'@@SS@@'", ",", "''", ")", ")", "\n", "", "except", "IndexError", ":", "\n", "                        ", "logging", ".", "error", "(", "\"----Out of range-----\"", ")", "\n", "\n", "", "", "", "if", "random", ".", "random", "(", ")", "<", "0.1", ":", "\n", "                ", "log_predict_example", "(", "name", "=", "name", ",", "pred_label", "=", "logit", ",", "\n", "gold_label", "=", "_label", ",", "pred_abs", "=", "_pred", ",", "gold_abs", "=", "abs_s", ")", "\n", "", "self", ".", "rouge_metrics", "(", "pred", "=", "_pred", ",", "ref", "=", "[", "abs_s", "]", ")", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.models.seq2idx.Seq2IdxSum.refine_sent_selection": [[406, 437], ["range", "random.random", "torch.ones_like", "decoder_outputs_logit.size", "neusum.service.basic_service.flip_first_two_dim", "seq2idx.Seq2IdxSum.sent_dec.decode", "decoder_outputs_logit.size", "neusum.service.basic_service.flip_first_two_dim.long"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.flip_first_two_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.decode"], ["", "def", "refine_sent_selection", "(", "self", ",", "batchsz", ",", "comp_leadn", ",", "\n", "decoder_outputs_logit", ",", "sent_label", ",", "decoder_outputs_prob", ",", "\n", "metadata", ")", ":", "\n", "\n", "        ", "if", "comp_leadn", ">", "0", ":", "\n", "            ", "part", "=", "metadata", "[", "0", "]", "[", "'part'", "]", "\n", "if", "part", "==", "'cnn'", ":", "\n", "                ", "comp_leadn", "-=", "1", "\n", "\n", "", "lead3", "=", "torch", ".", "ones_like", "(", "decoder_outputs_logit", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "*", "-", "1", "\n", "assert", "decoder_outputs_logit", ".", "size", "(", ")", "[", "1", "]", "==", "batchsz", "\n", "_t", "=", "decoder_outputs_logit", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "comp_leadn", ")", ":", "\n", "                ", "if", "_t", ">", "i", "and", "comp_leadn", ">=", "i", ":", "\n", "                    ", "lead3", "[", "i", ",", ":", "]", "=", "i", "\n", "\n", "", "", "sent_emission", "=", "lead3", "\n", "", "else", ":", "\n", "            ", "rand_num", "=", "random", ".", "random", "(", ")", "\n", "if", "self", ".", "training", "and", "(", "rand_num", "<", "0.9", ")", ":", "\n", "# use ground truth", "\n", "                ", "sent_emission", "=", "sent_label", "[", ":", ",", "0", ",", ":", "]", "\n", "sent_emission", "=", "flip_first_two_dim", "(", "sent_emission", ".", "long", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "sent_decoded", "=", "self", ".", "sent_dec", ".", "decode", "(", "decoder_outputs_prob", ",", "metadata", ",", "sent_label", ")", "\n", "sent_emission", "=", "sent_decoded", "\n", "# print(sent_emission.size()[0])", "\n", "# print(decoder_outputs_logit.size()[0])", "\n", "# assert sent_emission.size()[0] == decoder_outputs_logit.size()[0]", "\n", "", "", "return", "sent_emission", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.hashhex": [[8, 13], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.get_url_hashes": [[15, 22], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.read_one_file": [[24, 32], ["os.path.isfile", "open", "fd.read().splitlines", "len", "fd.read"], "function", ["None"], ["", "def", "read_one_file", "(", "fname", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "fname", "+", "'.data'", ")", ":", "\n", "        ", "with", "open", "(", "fname", "+", "'.data'", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "line", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "assert", "len", "(", "line", ")", "==", "1", "\n", "", "return", "line", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.move_file_to_dir_url": [[34, 52], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "open", "fd.read().splitlines", "creation_oracle.get_url_hashes", "print", "os.path.join", "open", "fd.write", "fd.read", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes"], ["", "", "def", "move_file_to_dir_url", "(", "url_file", ",", "path_read", ",", "file_to_write", ")", ":", "\n", "    ", "with", "open", "(", "url_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "\n", "", "url_names", "=", "[", "os", ".", "path", ".", "join", "(", "path_read", ",", "url", ")", "for", "url", "in", "url_names", "]", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "rt_bag", "=", "pool", ".", "map", "(", "read_one_file", ",", "url_names", ")", "\n", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "rt_bag", "=", "[", "x", "for", "x", "in", "rt_bag", "if", "x", "is", "not", "None", "]", "\n", "wt_string", "=", "\"\\n\"", ".", "join", "(", "rt_bag", ")", "\n", "with", "open", "(", "file_to_write", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "wt_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.split_data": [[54, 86], ["creation_oracle.move_file_to_dir_url", "creation_oracle.move_file_to_dir_url", "creation_oracle.move_file_to_dir_url", "random.shuffle", "len", "int", "int", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "os.path.join", "os.path.join", "os.path.join", "x.split", "os.listdir", "x.endswith", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name"], ["", "", "def", "split_data", "(", "root", ",", "full_dataname", ",", "read_path", ",", "tgt_path", ")", ":", "\n", "    ", "if", "(", "full_dataname", "==", "'cnn'", ")", "or", "(", "full_dataname", "==", "'dailymail'", ")", ":", "\n", "        ", "train_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_training_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "dev_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_validation_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "test_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "train_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "dev_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "test_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "full_dataname", "==", "'nyt'", ":", "\n", "        ", "files", "=", "[", "x", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "read_path", ")", "if", "x", ".", "endswith", "(", "\".data\"", ")", "]", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "total_len", "=", "len", "(", "files", ")", "\n", "train_len", "=", "int", "(", "total_len", "*", "0.8", ")", "\n", "dev_len", "=", "int", "(", "total_len", "*", "0.1", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", ":", "train_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", ":", "train_len", "+", "dev_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", "+", "dev_len", ":", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.stage_1": [[88, 101], ["clear_dir", "creation_oracle.wrap_creat_distributed_oracle", "clear_dir", "print", "creation_oracle.split_data"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.wrap_creat_distributed_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.split_data"], ["", "", "def", "stage_1", "(", ")", ":", "\n", "    ", "clear_dir", "(", "path_wt", ")", "\n", "\n", "# create_oracles  process_one_example", "\n", "# write down data to path_wt", "\n", "wrap_creat_distributed_oracle", "(", "dataname", "=", "data_name", ",", "path_read", "=", "path_read", ",", "path_wt_distributed", "=", "path_wt", ")", "\n", "\n", "clear_dir", "(", "path_wt_merge", ")", "\n", "print", "(", "path_wt_merge", ")", "\n", "# split data", "\n", "split_data", "(", "root", ",", "full_dataname", "=", "full_dataname", ",", "\n", "read_path", "=", "path_wt", ",", "\n", "tgt_path", "=", "path_wt_merge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.wrap_creat_distributed_oracle": [[103, 130], ["len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "zip", "i.split", "os.listdir", "i.endswith"], "function", ["None"], ["", "def", "wrap_creat_distributed_oracle", "(", "dataname", ",", "path_read", ",", "path_wt_distributed", ")", ":", "\n", "    ", "\"\"\"\n    Create Oracles, write individual json files to the disk.\n    If CNNDM,\n    :return:\n    \"\"\"", "\n", "\n", "files", "=", "[", "i", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "i", "in", "os", ".", "listdir", "(", "path_read", ")", "if", "i", ".", "endswith", "(", "'.doc.json'", ")", "]", "\n", "# files = files[:100]", "\n", "total_num", "=", "len", "(", "files", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "\n", "pool", ".", "starmap", "(", "process_one_example", ",", "zip", "(", "[", "path_read", "]", "*", "total_num", ",", "\n", "[", "path_wt_distributed", "]", "*", "total_num", ",", "\n", "files", ",", "\n", "[", "30", "]", "*", "total_num", ",", "\n", "[", "dataname", "]", "*", "total_num", ")", ")", "\n", "\n", "# pool.starmap(process_one_example_allen, zip([path_read] * total_num,", "\n", "#                                             [path_wt_distributed] * total_num,", "\n", "#                                             files,", "\n", "#                                             [35] * total_num,", "\n", "#                                             [dataname] * total_num))", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "print", "(", "\"finish creating oracles, and write down them to distributed folders.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.creation_oracle.process_one_example": [[132, 224], ["os.path.join", "os.path.join", "neusum.data.create_oracle.extract_parse", "neusum.data.create_oracle.extract_tokens", "neusum.data.create_oracle.extract_tokens", "enumerate", "enumerate", "neusum.orac.util.comp_document_oracle", "json.dumps", "json.loads", "json.loads", "len", "neusum.orac.oracle.process_one_sentence", "_rt_sentences.append", "sent_packs.append", "_del_span.sort", "doc_list_trimmed_for_oracle.append", "open", "fd.write", "os.path.isfile", "os.path.isfile", "neusum.orac.oracle.read_file_no_splitlines", "neusum.orac.oracle.read_file_no_splitlines", "print", "_formal_doc_parse.append", "_formal_doc_token.append", "list", "list.sort", "os.path.join", "list", "set", "set", "range", "list", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines"], ["", "def", "process_one_example", "(", "path_read", ":", "str", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "max_sent", "=", "40", ",", "\n", "data_name", ":", "str", "=", "'dm'", ")", ":", "\n", "    ", "\"\"\"\n    Given one snlp parse output (parse trees of one document),\n    produce json format data for production.\n    :param path_read:\n    :param path_write:\n    :param fname_without_suffix:\n    :param max_sent:\n    :return:\n    \"\"\"", "\n", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "try", ":", "\n", "        ", "doc_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "doc_file", ")", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "abs_file", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\n", "\n", "", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "doc_token", ",", "doc_str", "=", "extract_tokens", "(", "doc_dict", ")", "\n", "sent_packs", "=", "[", "]", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_parse", "=", "[", "]", "\n", "_formal_doc_token", "=", "[", "]", "\n", "for", "doc_idx", ",", "doc_t", "in", "enumerate", "(", "doc_token", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_t", ")", "\n", "if", "l", ">", "3", "and", "l", "<", "70", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_parse", ".", "append", "(", "doc_parse", "[", "doc_idx", "]", ")", "\n", "_formal_doc_token", ".", "append", "(", "doc_t", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_parse", "=", "_formal_doc_parse", "\n", "doc_token", "=", "_formal_doc_token", "\n", "\n", "# comp compression options and deletion based on every single sentence", "\n", "_rt_sentences", "=", "[", "]", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "doc_parse", ")", ":", "\n", "        ", "output", "=", "process_one_sentence", "(", "x", ",", "abs_str", ")", "\n", "_rt_sentences", ".", "append", "(", "output", ")", "\n", "# _rt_sentences = [process_one_sentence(x, abs_str,context_sent=) for x in doc_parse]", "\n", "# sent_tree, rt_del_spans, baselinve_rouge", "\n", "\n", "", "for", "rt_sent", "in", "_rt_sentences", ":", "\n", "        ", "_tmp", "=", "{", "\n", "\"token\"", ":", "rt_sent", "[", "0", "]", ".", "text", ",", "\n", "\"del_span\"", ":", "rt_sent", "[", "1", "]", ",", "\n", "\"baseline\"", ":", "rt_sent", "[", "2", "]", "\n", "# \"tree\": rt_sent[0]", "\n", "}", "\n", "sent_packs", ".", "append", "(", "_tmp", ")", "\n", "\n", "# comp document level sentence oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "sent_packs", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list", ",", "abs_str", ")", "\n", "\n", "# comp document level delete-one sentence oracle", "\n", "doc_list_trimmed_for_oracle", "=", "[", "]", "\n", "for", "x", "in", "sent_packs", ":", "\n", "        ", "_del_span", "=", "x", "[", "'del_span'", "]", "\n", "_del_span", ".", "sort", "(", "key", "=", "lambda", "y", ":", "y", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "try", ":", "\n", "            ", "del_idx", "=", "_del_span", "[", "0", "]", "[", "'selected_idx'", "]", "\n", "selected_set", "=", "list", "(", "set", "(", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", ")", "-", "set", "(", "del_idx", ")", ")", "\n", "selected_set", ".", "sort", "(", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "selected_set", "=", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", "\n", "", "doc_list_trimmed_for_oracle", ".", "append", "(", "\" \"", ".", "join", "(", "[", "x", "[", "'token'", "]", "[", "kdx", "]", "for", "kdx", "in", "selected_set", "]", ")", ")", "\n", "# trim_ora_json = comp_document_oracle(doc_list_trimmed_for_oracle, abs_str)", "\n", "", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "rt", "[", "'part'", "]", "=", "data_name", "\n", "# span_pairs = gen_span_segmentation([x['token'] for x in rt_sentences])", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_list\"", "]", "=", "abs_token", "\n", "rt", "[", "\"doc\"", "]", "=", "\" \"", ".", "join", "(", "doc_list", ")", "\n", "rt", "[", "\"doc_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "sent_packs", "]", "\n", "rt", "[", "\"sentences\"", "]", "=", "sent_packs", "\n", "\n", "# rt[\"sent_oracle\"] = trim_ora_json", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "sent_ora_json", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.remade.run.Seq2IdxSum.__init__": [[35, 45], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "\n", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "Seq2IdxSum", ",", "self", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.read_file": [[8, 12], ["open", "fd.read().splitlines", "fd.read"], "function", ["None"], ["def", "read_file", "(", "fpath", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "output", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.default_sent_as_sos": [[14, 22], ["None"], "function", ["None"], ["", "def", "default_sent_as_sos", "(", ")", ":", "\n", "    ", "dft", "=", "{", "\"sidx\"", ":", "0", ",", "'eidx'", ":", "1", ",", "'node'", ":", "\"BASELINE\"", ",", "'rouge'", ":", "0", ",", "'selected_idx'", ":", "[", "]", "}", "\n", "# <SOS> Used for pred the end of decoding", "\n", "# sent_sos_dict = SentDataWithOracle(token=[\"<SOS>\"],del_span= [dft],single_del=[dft],single_del_best=dft)", "\n", "sent_sos_dict", "=", "{", "'token'", ":", "[", "\"<SOS>\"", "]", ",", "\n", "'del_span'", ":", "[", "dft", "]", ",", "'single_del'", ":", "[", "dft", "]", ",", "\n", "'single_del_best'", ":", "dft", "}", "\n", "return", "sent_sos_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.process_one_sentence": [[27, 78], ["abs_str.split", "read_single_parse_tree", "len", "len", "neusum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words", "rt_del_spans.append", "abs_str.split", "set", "list", "list.sort", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words", "rt_del_spans.append", "len", "range", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words", "len", "list"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words"], ["def", "process_one_sentence", "(", "sent_parse", ":", "TreeNode", ",", "abs_str", ":", "str", "\n", ")", "->", "List", ":", "\n", "    ", "\"\"\"\n    Given the parse tree of a sentence and the gold summary,\n    get compression options and corresponding rouge value after performing this compression.\n    node: BASELINE  =  operation: delete last token; rouge: the whole sentence. trick for convinience\n    :param sent_parse:\n    :param abs_str:\n    :return: List[[sent_tree: TreeNode, rt_del_spans: List[{'node','rouge','selected_idx', 'ratio'}, {}], baselinve_rouge: float]]\n    \"\"\"", "\n", "abs_list", "=", "abs_str", ".", "split", "(", "\" \"", ")", "\n", "sent_tree", "=", "read_single_parse_tree", "(", "sent_parse", ")", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "abs_len", "=", "len", "(", "abs_str", ".", "split", "(", "\" \"", ")", ")", "\n", "# len_compensat_sent = length_compensation(doc=sent_tree.text, abs=abs_list)", "\n", "sent_str", "=", "\" \"", ".", "join", "(", "sent_tree", ".", "text", ")", "\n", "rt_del_spans", "=", "[", "]", "\n", "del_spans", "=", "find_deletable_span_rule_based_updated", "(", "sent_tree", ",", "root_len", "=", "tree_len", ",", "parent", "=", "None", ",", "grand_parent", "=", "None", ")", "\n", "baseline_rouge", "=", "get_rouge_est_str_2gram_smart_kick_stop_words", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", "\n", "# new_baseline_rouge = folding_rouge(abs_list, sent_str)", "\n", "if", "baseline_rouge", "<", "0.03", ":", "\n", "        ", "useless_baseline", "=", "True", "\n", "", "else", ":", "\n", "        ", "useless_baseline", "=", "False", "\n", "\n", "", "for", "del_sp", "in", "del_spans", ":", "\n", "        ", "if", "len", "(", "del_sp", "[", "'selected_idx'", "]", ")", "<", "1", ":", "\n", "            ", "continue", "\n", "", "full_set", "=", "set", "(", "range", "(", "len", "(", "sent_tree", ".", "text", ")", ")", ")", "\n", "remain_idx", "=", "list", "(", "full_set", "-", "del_sp", "[", "'selected_idx'", "]", ")", "\n", "remain_idx", ".", "sort", "(", ")", "\n", "_txt", "=", "\" \"", ".", "join", "(", "[", "sent_tree", ".", "text", "[", "idx", "]", "for", "idx", "in", "remain_idx", "]", ")", "\n", "# _txt = length_compensation(_txt, abs=abs_list)", "\n", "_rouge", "=", "get_rouge_est_str_2gram_smart_kick_stop_words", "(", "gold", "=", "abs_str", ",", "pred", "=", "_txt", ")", "\n", "\n", "rt_del_spans", ".", "append", "(", "\n", "{", "'node'", ":", "del_sp", "[", "\"node\"", "]", ",", "\n", "'rouge'", ":", "_rouge", ",", "\n", "'selected_idx'", ":", "list", "(", "del_sp", "[", "\"selected_idx\"", "]", ")", ",", "\n", "'ratio'", ":", "_rouge", "/", "baseline_rouge", "if", "not", "useless_baseline", "else", "1.0", ",", "\n", "'label'", ":", "-", "1", "}", "\n", ")", "\n", "", "rt_del_spans", ".", "append", "(", "{", "\n", "'node'", ":", "\"BASELINE\"", ",", "\n", "'rouge'", ":", "get_rouge_est_str_2gram_smart_kick_stop_words", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", ",", "\n", "'selected_idx'", ":", "[", "tree_len", "-", "1", "]", ",", "\n", "'ratio'", ":", "0.0", ",", "\n", "'label'", ":", "-", "1", "}", ")", "\n", "return", "[", "sent_tree", ",", "rt_del_spans", ",", "baseline_rouge", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.get_document_parse_tree_and_str": [[80, 88], ["read_single_parse_tree", "tree_bag.append", "str_bag.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree"], ["", "def", "get_document_parse_tree_and_str", "(", "inp", ":", "List", "[", "str", "]", ")", "->", "(", "List", "[", "TreeNode", "]", ",", "List", "[", "str", "]", ")", ":", "\n", "    ", "tree_bag", ",", "str_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "inp", ":", "\n", "        ", "out", "=", "read_single_parse_tree", "(", "sent", ")", "\n", "tree_bag", ".", "append", "(", "out", ")", "\n", "s", "=", "\" \"", ".", "join", "(", "out", ".", "text", ")", "\n", "str_bag", ".", "append", "(", "s", ")", "\n", "", "return", "tree_bag", ",", "str_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.read_file_no_splitlines": [[90, 94], ["open", "fd.read"], "function", ["None"], ["", "def", "read_file_no_splitlines", "(", "fpath", ")", ":", "\n", "    ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "output", "=", "fd", ".", "read", "(", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.process_one_example": [[99, 205], ["os.path.join", "os.path.join", "extract_parse", "extract_tokens", "extract_tokens", "enumerate", "enumerate", "depricated.ILP.cvxpy_ilp.ILP_protocol_w_compression", "depricated.ILP.cvxpy_ilp.ILP_protocol", "json.dumps", "json.loads", "json.loads", "len", "len", "print", "oracle_construction_ilp.process_one_sentence", "_rt_sentences.append", "sent_packs.append", "random.random", "print", "open", "fd.write", "os.path.isfile", "os.path.isfile", "oracle_construction_ilp.read_file_no_splitlines", "oracle_construction_ilp.read_file_no_splitlines", "print", "_formal_doc_parse.append", "_formal_doc_token.append", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.ILP_protocol_w_compression", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.ILP.cvxpy_ilp.ILP_protocol", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines"], ["def", "process_one_example", "(", "path_read", ":", "str", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "max_sent", "=", "40", ",", "\n", "data_name", ":", "str", "=", "'dm'", ")", ":", "\n", "    ", "\"\"\"\n    Given one snlp parse output (parse trees of one document),\n    produce json format data for production.\n    :param path_read:\n    :param path_write:\n    :param fname_without_suffix:\n    :param max_sent:\n    :return:\n    \"\"\"", "\n", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "try", ":", "\n", "        ", "doc_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "doc_file", ")", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "abs_file", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\n", "\n", "", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "doc_token", ",", "doc_str", "=", "extract_tokens", "(", "doc_dict", ")", "\n", "sent_packs", "=", "[", "]", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_parse", "=", "[", "]", "\n", "_formal_doc_token", "=", "[", "]", "\n", "for", "doc_idx", ",", "doc_t", "in", "enumerate", "(", "doc_token", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_t", ")", "\n", "if", "l", ">", "3", "and", "l", "<", "70", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_parse", ".", "append", "(", "doc_parse", "[", "doc_idx", "]", ")", "\n", "_formal_doc_token", ".", "append", "(", "doc_t", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_parse", "=", "_formal_doc_parse", "\n", "doc_token", "=", "_formal_doc_token", "\n", "\n", "if", "len", "(", "doc_parse", ")", "<", "2", ":", "\n", "        ", "print", "(", "\"forget {}\"", ".", "format", "(", "fname_without_suffix", ")", ")", "\n", "return", "\n", "# comp compression options and deletion based on every single sentence", "\n", "", "_rt_sentences", "=", "[", "]", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "doc_parse", ")", ":", "\n", "        ", "output", "=", "process_one_sentence", "(", "x", ",", "abs_str", ")", "\n", "_rt_sentences", ".", "append", "(", "output", ")", "\n", "# _rt_sentences = [process_one_sentence(x, abs_str,context_sent=) for x in doc_parse]", "\n", "# sent_tree, rt_del_spans, baselinve_rouge", "\n", "\n", "", "for", "rt_sent", "in", "_rt_sentences", ":", "\n", "        ", "_tmp", "=", "{", "\n", "\"token\"", ":", "rt_sent", "[", "0", "]", ".", "text", ",", "\n", "\"del_span\"", ":", "rt_sent", "[", "1", "]", ",", "\n", "\"baseline\"", ":", "rt_sent", "[", "2", "]", "\n", "# \"tree\": rt_sent[0]", "\n", "}", "\n", "sent_packs", ".", "append", "(", "_tmp", ")", "\n", "\n", "# comp document level sentence oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "sent_packs", "]", "\n", "\n", "# ILP for compression oracle: both sent label and compression label", "\n", "ILP_protocol_w_compression", "(", "reference_summary", "=", "abs_str", ",", "sent_units", "=", "doc_list", ",", "compression", "=", "sent_packs", ")", "\n", "\n", "# ILP for extractive oracle: only sent label", "\n", "sent_ora_json", "=", "ILP_protocol", "(", "reference_summary", "=", "abs_str", ",", "\n", "sent_units", "=", "doc_list", ")", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.001", ":", "\n", "        ", "print", "(", "sent_ora_json", ")", "\n", "\n", "\n", "# pass", "\n", "# # comp document level delete-one sentence oracle", "\n", "# doc_list_trimmed_for_oracle = []", "\n", "# for x in sent_packs:", "\n", "#     _del_span = x['del_span']", "\n", "#     _del_span.sort(key=lambda y: y['rouge'], reverse=True)", "\n", "#     try:", "\n", "#         del_idx = _del_span[0]['selected_idx']", "\n", "#         selected_set = list(set(list(range(len(x['token'])))) - set(del_idx))", "\n", "#         selected_set.sort()", "\n", "#     except IndexError:", "\n", "#         selected_set = list(range(len(x['token'])))", "\n", "#     doc_list_trimmed_for_oracle.append(\" \".join([x['token'][kdx] for kdx in selected_set]))", "\n", "# trim_ora_json = comp_document_oracle(doc_list_trimmed_for_oracle, abs_str)", "\n", "", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "rt", "[", "'part'", "]", "=", "data_name", "\n", "# span_pairs = gen_span_segmentation([x['token'] for x in rt_sentences])", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_list\"", "]", "=", "abs_token", "\n", "rt", "[", "\"doc\"", "]", "=", "\" \"", ".", "join", "(", "doc_list", ")", "\n", "rt", "[", "\"doc_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "sent_packs", "]", "\n", "rt", "[", "\"sentences\"", "]", "=", "sent_packs", "\n", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "sent_ora_json", "# TODO", "\n", "rt", "[", "\"non_compression_sent_oracle\"", "]", "=", "sent_ora_json", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.create_oracles_ilp": [[207, 228], ["len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "zip", "i.split", "os.listdir", "i.endswith"], "function", ["None"], ["", "", "def", "create_oracles_ilp", "(", "dataname", ",", "path_read", ",", "path_wt_distributed", ")", ":", "\n", "    ", "\"\"\"\n    Create Oracles, write individual json files to the disk.\n    If CNNDM,\n    :return:\n    \"\"\"", "\n", "\n", "files", "=", "[", "i", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "i", "in", "os", ".", "listdir", "(", "path_read", ")", "if", "i", ".", "endswith", "(", "'.doc.json'", ")", "]", "\n", "# files = files[:100]", "\n", "total_num", "=", "len", "(", "files", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "\n", "pool", ".", "starmap", "(", "process_one_example", ",", "zip", "(", "[", "path_read", "]", "*", "total_num", ",", "\n", "[", "path_wt_distributed", "]", "*", "total_num", ",", "\n", "files", ",", "\n", "[", "40", "]", "*", "total_num", ",", "\n", "[", "dataname", "]", "*", "total_num", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "print", "(", "\"finish creating oracles, and write down them to distributed folders.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.split_data": [[230, 264], ["move_file_to_dir_url", "move_file_to_dir_url", "move_file_to_dir_url", "random.shuffle", "len", "int", "int", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "os.path.join", "os.path.join", "os.path.join", "x.split", "os.listdir", "x.endswith", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name"], ["", "def", "split_data", "(", "root", ",", "full_dataname", ",", "read_path", ",", "tgt_path", ")", ":", "\n", "    ", "if", "(", "full_dataname", "==", "'cnn'", ")", "or", "(", "full_dataname", "==", "'dailymail'", ")", ":", "\n", "        ", "train_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_training_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "dev_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_validation_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "test_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "train_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "dev_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "test_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "full_dataname", "==", "'nyt'", ":", "\n", "# TODO exsisting loading", "\n", "        ", "raise", "NotImplementedError", "\n", "files", "=", "[", "x", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "read_path", ")", "if", "x", ".", "endswith", "(", "\".data\"", ")", "]", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "total_len", "=", "len", "(", "files", ")", "\n", "train_len", "=", "int", "(", "total_len", "*", "0.8", ")", "\n", "dev_len", "=", "int", "(", "total_len", "*", "0.1", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", ":", "train_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", ":", "train_len", "+", "dev_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", "+", "dev_len", ":", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.convert_json_to_pkl_local": [[266, 275], ["neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "print", "neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "print", "neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump"], ["", "", "def", "convert_json_to_pkl_local", "(", "root", ",", "_data_name", ")", ":", "\n", "    ", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"test\"", ",", "part", "=", "_data_name", ")", "\n", "print", "(", "\"Test done. Training start.\"", ")", "\n", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"train\"", ",", "part", "=", "_data_name", ")", "\n", "print", "(", "\"Test done. Training done. Dev start.\"", ")", "\n", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"dev\"", ",", "part", "=", "_data_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.stage_1": [[277, 290], ["neusum.service.basic_service.clear_dir", "oracle_construction_ilp.create_oracles_ilp", "neusum.service.basic_service.clear_dir", "print", "oracle_construction_ilp.split_data"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle_construction_ilp.create_oracles_ilp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.split_data"], ["", "def", "stage_1", "(", ")", ":", "\n", "    ", "clear_dir", "(", "path_wt", ")", "\n", "\n", "# create_oracles  process_one_example", "\n", "# write down data to path_wt", "\n", "create_oracles_ilp", "(", "dataname", "=", "data_name", ",", "path_read", "=", "path_read", ",", "path_wt_distributed", "=", "path_wt", ")", "\n", "\n", "clear_dir", "(", "path_wt_merge", ")", "\n", "print", "(", "path_wt_merge", ")", "\n", "# split data", "\n", "split_data", "(", "root", ",", "full_dataname", "=", "full_dataname", ",", "\n", "read_path", "=", "path_wt", ",", "\n", "tgt_path", "=", "path_wt_merge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file": [[20, 24], ["open", "fd.read().splitlines", "fd.read"], "function", ["None"], ["def", "read_file", "(", "fpath", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "output", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.default_sent_as_sos": [[26, 34], ["None"], "function", ["None"], ["", "def", "default_sent_as_sos", "(", ")", ":", "\n", "    ", "dft", "=", "{", "\"sidx\"", ":", "0", ",", "'eidx'", ":", "1", ",", "'node'", ":", "\"BASELINE\"", ",", "'rouge'", ":", "0", ",", "'selected_idx'", ":", "[", "]", "}", "\n", "# <SOS> Used for pred the end of decoding", "\n", "# sent_sos_dict = SentDataWithOracle(token=[\"<SOS>\"],del_span= [dft],single_del=[dft],single_del_best=dft)", "\n", "sent_sos_dict", "=", "{", "'token'", ":", "[", "\"<SOS>\"", "]", ",", "\n", "'del_span'", ":", "[", "dft", "]", ",", "'single_del'", ":", "[", "dft", "]", ",", "\n", "'single_del_best'", ":", "dft", "}", "\n", "return", "sent_sos_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence_allen": [[41, 99], ["len", "abs_str.split", "neusum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "neusum.orac.util.folding_rouge", "rt_del_spans.append", "set", "list", "list.sort", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "neusum.orac.util.folding_rouge", "rt_del_spans.append", "len", "range", "random.random", "print", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "len", "list"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.folding_rouge", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.folding_rouge", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart"], ["def", "process_one_sentence_allen", "(", "sent_tree", ":", "TreeNode", ",", "abs_str", ":", "str", "\n", ")", "->", "List", ":", "\n", "    ", "\"\"\"\n    Given the parse tree of a sentence and the gold summary,\n    get compression options and corresponding rouge value after performing this compression.\n    node: BASELINE  =  operation: delete last token; rouge: the whole sentence. trick for convinience\n    :param sent_parse:\n    :param abs_str:\n    :return: List[[sent_tree: TreeNode, rt_del_spans: List, baselinve_rouge: float]]\n    \"\"\"", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "# len_compensat_sent = length_compensation(doc=sent_tree.text, abs=abs_list)", "\n", "sent_str", "=", "\" \"", ".", "join", "(", "sent_tree", ".", "text", ")", "\n", "rt_del_spans", "=", "[", "]", "\n", "abs_list", "=", "abs_str", ".", "split", "(", "\" \"", ")", "\n", "del_spans", "=", "find_deletable_span_rule_based_updated", "(", "sent_tree", ",", "root_len", "=", "tree_len", ",", "parent", "=", "None", ",", "grand_parent", "=", "None", ")", "\n", "\n", "# standard", "\n", "baseline_rouge", "=", "get_rouge_est_str_2gram_smart", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", "\n", "\n", "# experimental", "\n", "new_baseline_rouge", "=", "folding_rouge", "(", "abs_list", ",", "sent_str", ")", "\n", "\n", "if", "baseline_rouge", "<", "0.03", ":", "\n", "        ", "useless_baseline", "=", "True", "\n", "", "else", ":", "\n", "        ", "useless_baseline", "=", "False", "\n", "\n", "", "for", "del_sp", "in", "del_spans", ":", "\n", "        ", "if", "len", "(", "del_sp", "[", "'selected_idx'", "]", ")", "<", "1", ":", "\n", "            ", "continue", "\n", "", "full_set", "=", "set", "(", "range", "(", "len", "(", "sent_tree", ".", "text", ")", ")", ")", "\n", "remain_idx", "=", "list", "(", "full_set", "-", "del_sp", "[", "'selected_idx'", "]", ")", "\n", "remain_idx", ".", "sort", "(", ")", "\n", "_txt", "=", "\" \"", ".", "join", "(", "[", "sent_tree", ".", "text", "[", "idx", "]", "for", "idx", "in", "remain_idx", "]", ")", "\n", "\n", "# Standard way", "\n", "_rouge", "=", "get_rouge_est_str_2gram_smart", "(", "gold", "=", "abs_str", ",", "pred", "=", "_txt", ")", "\n", "\n", "# experimental way", "\n", "new_rouge", "=", "folding_rouge", "(", "abs_list", ",", "_txt", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "0.01", ":", "\n", "            ", "print", "(", "\n", "\"{0}Before: {1:0.2f}\\tAfter: {2:0.2f}\"", ".", "format", "(", "new_rouge", "/", "new_baseline_rouge", ">", "_rouge", "/", "baseline_rouge", ",", "\n", "_rouge", "/", "baseline_rouge", ",", "new_rouge", "/", "new_baseline_rouge", ")", ")", "\n", "", "rt_del_spans", ".", "append", "(", "\n", "{", "'node'", ":", "del_sp", "[", "\"node\"", "]", ",", "'rouge'", ":", "new_rouge", ",", "\n", "'selected_idx'", ":", "list", "(", "del_sp", "[", "\"selected_idx\"", "]", ")", ",", "\n", "'ratio'", ":", "new_rouge", "/", "new_baseline_rouge", "if", "not", "useless_baseline", "else", "1.0", "}", "\n", ")", "\n", "", "rt_del_spans", ".", "append", "(", "{", "\n", "'node'", ":", "\"BASELINE\"", ",", "\n", "'rouge'", ":", "get_rouge_est_str_2gram_smart", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", ",", "\n", "'selected_idx'", ":", "[", "tree_len", "-", "1", "]", ",", "\n", "'ratio'", ":", "0.0", "}", ")", "\n", "return", "[", "sent_tree", ",", "rt_del_spans", ",", "baseline_rouge", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence": [[101, 163], ["abs_str.split", "read_single_parse_tree", "len", "len", "neusum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "rt_del_spans.append", "abs_str.split", "set", "list", "list.sort", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "rt_del_spans.append", "len", "range", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "len", "list"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart"], ["", "def", "process_one_sentence", "(", "sent_parse", ":", "TreeNode", ",", "abs_str", ":", "str", "\n", ")", "->", "List", ":", "\n", "    ", "\"\"\"\n    Given the parse tree of a sentence and the gold summary,\n    get compression options and corresponding rouge value after performing this compression.\n    node: BASELINE  =  operation: delete last token; rouge: the whole sentence. trick for convinience\n    :param sent_parse:\n    :param abs_str:\n    :return: List[[sent_tree: TreeNode, rt_del_spans: List, baselinve_rouge: float]]\n    \"\"\"", "\n", "abs_list", "=", "abs_str", ".", "split", "(", "\" \"", ")", "\n", "sent_tree", "=", "read_single_parse_tree", "(", "sent_parse", ")", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "abs_len", "=", "len", "(", "abs_str", ".", "split", "(", "\" \"", ")", ")", "\n", "# len_compensat_sent = length_compensation(doc=sent_tree.text, abs=abs_list)", "\n", "sent_str", "=", "\" \"", ".", "join", "(", "sent_tree", ".", "text", ")", "\n", "rt_del_spans", "=", "[", "]", "\n", "del_spans", "=", "find_deletable_span_rule_based_updated", "(", "sent_tree", ",", "root_len", "=", "tree_len", ",", "parent", "=", "None", ",", "grand_parent", "=", "None", ")", "\n", "baseline_rouge", "=", "get_rouge_est_str_2gram_smart", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", "\n", "# new_baseline_rouge = folding_rouge(abs_list, sent_str)", "\n", "if", "baseline_rouge", "<", "0.03", ":", "\n", "        ", "useless_baseline", "=", "True", "\n", "", "else", ":", "\n", "        ", "useless_baseline", "=", "False", "\n", "\n", "", "for", "del_sp", "in", "del_spans", ":", "\n", "        ", "if", "len", "(", "del_sp", "[", "'selected_idx'", "]", ")", "<", "1", ":", "\n", "            ", "continue", "\n", "", "full_set", "=", "set", "(", "range", "(", "len", "(", "sent_tree", ".", "text", ")", ")", ")", "\n", "remain_idx", "=", "list", "(", "full_set", "-", "del_sp", "[", "'selected_idx'", "]", ")", "\n", "remain_idx", ".", "sort", "(", ")", "\n", "_txt", "=", "\" \"", ".", "join", "(", "[", "sent_tree", ".", "text", "[", "idx", "]", "for", "idx", "in", "remain_idx", "]", ")", "\n", "# _txt = length_compensation(_txt, abs=abs_list)", "\n", "_rouge", "=", "get_rouge_est_str_2gram_smart", "(", "gold", "=", "abs_str", ",", "pred", "=", "_txt", ")", "\n", "\n", "# experimental way", "\n", "# new_rouge = folding_rouge(abs_list, _txt)", "\n", "# if random.random() < 0.01:", "\n", "#     if not useless_baseline:", "\n", "#         print(", "\n", "#             \"{0}Before: {1:0.2f}\\tAfter: {2:0.2f}\".format(", "\n", "#                 new_rouge / new_baseline_rouge >= _rouge / baseline_rouge,", "\n", "#                 _rouge / baseline_rouge, new_rouge / new_baseline_rouge))", "\n", "rt_del_spans", ".", "append", "(", "\n", "{", "'node'", ":", "del_sp", "[", "\"node\"", "]", ",", "'rouge'", ":", "_rouge", ",", "\n", "'selected_idx'", ":", "list", "(", "del_sp", "[", "\"selected_idx\"", "]", ")", ",", "\n", "'ratio'", ":", "_rouge", "/", "baseline_rouge", "if", "not", "useless_baseline", "else", "1.0", "}", "\n", ")", "\n", "\n", "# rt_del_spans.append(", "\n", "#     {'node': del_sp[\"node\"], 'rouge': _rouge,", "\n", "#      'selected_idx': list(del_sp[\"selected_idx\"]),", "\n", "#      'ratio': _rouge / baseline_rouge if not useless_baseline else 1.0}", "\n", "# )", "\n", "", "rt_del_spans", ".", "append", "(", "{", "\n", "'node'", ":", "\"BASELINE\"", ",", "\n", "'rouge'", ":", "get_rouge_est_str_2gram_smart", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "sent_str", ")", ",", "\n", "'selected_idx'", ":", "[", "tree_len", "-", "1", "]", ",", "\n", "'ratio'", ":", "0.0", "}", ")", "\n", "return", "[", "sent_tree", ",", "rt_del_spans", ",", "baseline_rouge", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_allen": [[165, 258], ["os.path.join", "os.path.join", "oracle.get_document_parse_tree_and_str", "oracle.get_document_parse_tree_and_str", "zip", "enumerate", "comp_document_oracle", "comp_document_oracle", "json.dumps", "oracle.read_file", "oracle.read_file", "len", "oracle.process_one_sentence_allen", "_rt_sentences.append", "sent_packs.append", "_del_span.sort", "doc_list_trimmed_for_oracle.append", "x.split", "open", "fd.write", "os.path.isfile", "os.path.isfile", "print", "_formal_doc_tree.append", "_formal_doc_str.append", "list", "list.sort", "os.path.join", "list", "set", "set", "range", "list", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.get_document_parse_tree_and_str", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.get_document_parse_tree_and_str", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence_allen"], ["", "def", "process_one_example_allen", "(", "path_read", ":", "str", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "max_sent", "=", "40", ",", "\n", "data_name", ":", "str", "=", "'dm'", ")", ":", "\n", "    ", "\"\"\"\n    Given one snlp parse output (parse trees of one document),\n    produce json format data for production.\n    :param path_read:\n    :param path_write:\n    :param fname_without_suffix:\n    :param max_sent:\n    :return:\n    \"\"\"", "\n", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "return", "\n", "", "try", ":", "\n", "        ", "doc_lines", "=", "read_file", "(", "doc_file", ")", "\n", "abs_lines", "=", "read_file", "(", "abs_file", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\n", "\n", "", "abs_trees", ",", "abs_strs", "=", "get_document_parse_tree_and_str", "(", "abs_lines", ")", "\n", "doc_trees", ",", "doc_strs", "=", "get_document_parse_tree_and_str", "(", "doc_lines", ")", "\n", "\n", "abs_str", "=", "\"\\n\"", ".", "join", "(", "abs_strs", ")", "\n", "\n", "sent_packs", "=", "[", "]", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_tree", "=", "[", "]", "\n", "_formal_doc_str", "=", "[", "]", "\n", "for", "doc_t", ",", "doc_s", "in", "zip", "(", "doc_trees", ",", "doc_strs", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_s", ")", "\n", "if", "l", ">", "20", "and", "l", "<", "400", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_tree", ".", "append", "(", "doc_t", ")", "\n", "_formal_doc_str", ".", "append", "(", "doc_s", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_trees", "=", "_formal_doc_tree", "\n", "doc_strs", "=", "_formal_doc_str", "\n", "# comp compression options and deletion based on every single sentence", "\n", "_rt_sentences", "=", "[", "]", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "doc_trees", ")", ":", "\n", "        ", "output", "=", "process_one_sentence_allen", "(", "x", ",", "abs_str", ")", "\n", "_rt_sentences", ".", "append", "(", "output", ")", "\n", "# _rt_sentences = [process_one_sentence(x, abs_str,context_sent=) for x in doc_parse]", "\n", "# sent_tree, rt_del_spans, baselinve_rouge", "\n", "\n", "", "for", "rt_sent", "in", "_rt_sentences", ":", "\n", "        ", "_tmp", "=", "{", "\n", "\"token\"", ":", "rt_sent", "[", "0", "]", ".", "text", ",", "\n", "\"del_span\"", ":", "rt_sent", "[", "1", "]", ",", "\n", "\"baseline\"", ":", "rt_sent", "[", "2", "]", "\n", "# \"tree\": rt_sent[0]", "\n", "}", "\n", "sent_packs", ".", "append", "(", "_tmp", ")", "\n", "\n", "# comp document level sentence oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "sent_packs", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list", ",", "abs_str", ")", "\n", "\n", "# comp document level delete-one sentence oracle", "\n", "doc_list_trimmed_for_oracle", "=", "[", "]", "\n", "for", "x", "in", "sent_packs", ":", "\n", "        ", "_del_span", "=", "x", "[", "'del_span'", "]", "\n", "_del_span", ".", "sort", "(", "key", "=", "lambda", "y", ":", "y", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "try", ":", "\n", "            ", "del_idx", "=", "_del_span", "[", "0", "]", "[", "'selected_idx'", "]", "\n", "selected_set", "=", "list", "(", "set", "(", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", ")", "-", "set", "(", "del_idx", ")", ")", "\n", "selected_set", ".", "sort", "(", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "selected_set", "=", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", "\n", "", "doc_list_trimmed_for_oracle", ".", "append", "(", "\" \"", ".", "join", "(", "[", "x", "[", "'token'", "]", "[", "kdx", "]", "for", "kdx", "in", "selected_set", "]", ")", ")", "\n", "", "trim_ora_json", "=", "comp_document_oracle", "(", "doc_list_trimmed_for_oracle", ",", "abs_str", ")", "\n", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "rt", "[", "'part'", "]", "=", "data_name", "\n", "# span_pairs = gen_span_segmentation([x['token'] for x in rt_sentences])", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_list\"", "]", "=", "[", "x", ".", "split", "(", "\" \"", ")", "for", "x", "in", "abs_strs", "]", "\n", "rt", "[", "\"doc\"", "]", "=", "\" \"", ".", "join", "(", "doc_list", ")", "\n", "rt", "[", "\"doc_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "sent_packs", "]", "\n", "rt", "[", "\"sentences\"", "]", "=", "sent_packs", "\n", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "trim_ora_json", "\n", "rt", "[", "\"non_compression_sent_oracle\"", "]", "=", "sent_ora_json", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.get_document_parse_tree_and_str": [[260, 268], ["read_single_parse_tree", "tree_bag.append", "str_bag.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree"], ["", "", "def", "get_document_parse_tree_and_str", "(", "inp", ":", "List", "[", "str", "]", ")", "->", "(", "List", "[", "TreeNode", "]", ",", "List", "[", "str", "]", ")", ":", "\n", "    ", "tree_bag", ",", "str_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "inp", ":", "\n", "        ", "out", "=", "read_single_parse_tree", "(", "sent", ")", "\n", "tree_bag", ".", "append", "(", "out", ")", "\n", "s", "=", "\" \"", ".", "join", "(", "out", ".", "text", ")", "\n", "str_bag", ".", "append", "(", "s", ")", "\n", "", "return", "tree_bag", ",", "str_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines": [[270, 274], ["open", "fd.read"], "function", ["None"], ["", "def", "read_file_no_splitlines", "(", "fpath", ")", ":", "\n", "    ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "output", "=", "fd", ".", "read", "(", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_with_ilp": [[278, 350], ["os.path.join", "os.path.join", "extract_parse", "extract_tokens", "extract_tokens", "enumerate", "enumerate", "comp_document_oracle", "oracle.process_one_example_with_ilp._pprint_dict"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle"], ["def", "process_one_example_with_ilp", "(", "path_read", ":", "str", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "max_sent", "=", "40", ",", "\n", "data_name", ":", "str", "=", "'dm'", ")", ":", "\n", "# compare the ILP oracle and beam search oracle", "\n", "    ", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "try", ":", "\n", "        ", "doc_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "doc_file", ")", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "abs_file", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\n", "\n", "", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "doc_token", ",", "doc_str", "=", "extract_tokens", "(", "doc_dict", ")", "\n", "sent_packs", "=", "[", "]", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_parse", "=", "[", "]", "\n", "_formal_doc_token", "=", "[", "]", "\n", "for", "doc_idx", ",", "doc_t", "in", "enumerate", "(", "doc_token", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_t", ")", "\n", "if", "l", ">", "3", "and", "l", "<", "70", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_parse", ".", "append", "(", "doc_parse", "[", "doc_idx", "]", ")", "\n", "_formal_doc_token", ".", "append", "(", "doc_t", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_parse", "=", "_formal_doc_parse", "\n", "doc_token", "=", "_formal_doc_token", "\n", "# comp compression options and deletion based on every single sentence", "\n", "_rt_sentences", "=", "[", "]", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "doc_parse", ")", ":", "\n", "        ", "output", "=", "process_one_sentence", "(", "x", ",", "abs_str", ")", "\n", "_rt_sentences", ".", "append", "(", "output", ")", "\n", "# _rt_sentences = [process_one_sentence(x, abs_str,context_sent=) for x in doc_parse]", "\n", "# sent_tree, rt_del_spans, baselinve_rouge", "\n", "\n", "", "for", "rt_sent", "in", "_rt_sentences", ":", "\n", "        ", "_tmp", "=", "{", "\n", "\"token\"", ":", "rt_sent", "[", "0", "]", ".", "text", ",", "\n", "\"del_span\"", ":", "rt_sent", "[", "1", "]", ",", "\n", "\"baseline\"", ":", "rt_sent", "[", "2", "]", "\n", "# \"tree\": rt_sent[0]", "\n", "}", "\n", "sent_packs", ".", "append", "(", "_tmp", ")", "\n", "\n", "# comp document level sentence oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "sent_packs", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list", ",", "abs_str", ")", "\n", "# print(sent_ora_json)", "\n", "\n", "def", "_pprint_dict", "(", "dic", ")", ":", "\n", "        ", "for", "key", ",", "value", "in", "dic", ".", "items", "(", ")", ":", "\n", "            ", "data", "=", "value", "[", "'data'", "]", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "                ", "label", "=", "v", "[", "'label'", "]", "\n", "label", ".", "sort", "(", ")", "\n", "val", "=", "v", "[", "'R1'", "]", "\n", "# print(\"{}\\t{}\\t{}\".format(label,val,v['sent']))", "\n", "print", "(", "\"{}\\t{}\"", ".", "format", "(", "label", ",", "val", ")", ")", "\n", "", "", "", "_pprint_dict", "(", "sent_ora_json", ")", "\n", "print", "(", "'-'", "*", "100", ")", "\n", "ILP_result", "=", "ILP_protocol", "(", "reference_summary", "=", "abs_str", ",", "\n", "sent_units", "=", "doc_list", "\n", ")", "\n", "_pprint_dict", "(", "ILP_result", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example": [[353, 444], ["os.path.join", "os.path.join", "extract_parse", "extract_tokens", "extract_tokens", "enumerate", "enumerate", "comp_document_oracle", "comp_document_oracle", "json.dumps", "json.loads", "json.loads", "len", "oracle.process_one_sentence", "_rt_sentences.append", "sent_packs.append", "_del_span.sort", "doc_list_trimmed_for_oracle.append", "open", "fd.write", "os.path.isfile", "os.path.isfile", "oracle.read_file_no_splitlines", "oracle.read_file_no_splitlines", "print", "_formal_doc_parse.append", "_formal_doc_token.append", "list", "list.sort", "os.path.join", "list", "set", "set", "range", "list", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_sentence", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.read_file_no_splitlines"], ["", "def", "process_one_example", "(", "path_read", ":", "str", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "max_sent", "=", "40", ",", "\n", "data_name", ":", "str", "=", "'dm'", ")", ":", "\n", "    ", "\"\"\"\n    Given one snlp parse output (parse trees of one document),\n    produce json format data for production.\n    :param path_read:\n    :param path_write:\n    :param fname_without_suffix:\n    :param max_sent:\n    :return:\n    \"\"\"", "\n", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "try", ":", "\n", "        ", "doc_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "doc_file", ")", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "read_file_no_splitlines", "(", "abs_file", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\n", "\n", "", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "doc_token", ",", "doc_str", "=", "extract_tokens", "(", "doc_dict", ")", "\n", "sent_packs", "=", "[", "]", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_parse", "=", "[", "]", "\n", "_formal_doc_token", "=", "[", "]", "\n", "for", "doc_idx", ",", "doc_t", "in", "enumerate", "(", "doc_token", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_t", ")", "\n", "if", "l", ">", "3", "and", "l", "<", "70", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_parse", ".", "append", "(", "doc_parse", "[", "doc_idx", "]", ")", "\n", "_formal_doc_token", ".", "append", "(", "doc_t", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_parse", "=", "_formal_doc_parse", "\n", "doc_token", "=", "_formal_doc_token", "\n", "# comp compression options and deletion based on every single sentence", "\n", "_rt_sentences", "=", "[", "]", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "doc_parse", ")", ":", "\n", "        ", "output", "=", "process_one_sentence", "(", "x", ",", "abs_str", ")", "\n", "_rt_sentences", ".", "append", "(", "output", ")", "\n", "# _rt_sentences = [process_one_sentence(x, abs_str,context_sent=) for x in doc_parse]", "\n", "# sent_tree, rt_del_spans, baselinve_rouge", "\n", "\n", "", "for", "rt_sent", "in", "_rt_sentences", ":", "\n", "        ", "_tmp", "=", "{", "\n", "\"token\"", ":", "rt_sent", "[", "0", "]", ".", "text", ",", "\n", "\"del_span\"", ":", "rt_sent", "[", "1", "]", ",", "\n", "\"baseline\"", ":", "rt_sent", "[", "2", "]", "\n", "# \"tree\": rt_sent[0]", "\n", "}", "\n", "sent_packs", ".", "append", "(", "_tmp", ")", "\n", "\n", "# comp document level sentence oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "sent_packs", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list", ",", "abs_str", ")", "\n", "\n", "# comp document level delete-one sentence oracle", "\n", "doc_list_trimmed_for_oracle", "=", "[", "]", "\n", "for", "x", "in", "sent_packs", ":", "\n", "        ", "_del_span", "=", "x", "[", "'del_span'", "]", "\n", "_del_span", ".", "sort", "(", "key", "=", "lambda", "y", ":", "y", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "try", ":", "\n", "            ", "del_idx", "=", "_del_span", "[", "0", "]", "[", "'selected_idx'", "]", "\n", "selected_set", "=", "list", "(", "set", "(", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", ")", "-", "set", "(", "del_idx", ")", ")", "\n", "selected_set", ".", "sort", "(", ")", "\n", "", "except", "IndexError", ":", "\n", "            ", "selected_set", "=", "list", "(", "range", "(", "len", "(", "x", "[", "'token'", "]", ")", ")", ")", "\n", "", "doc_list_trimmed_for_oracle", ".", "append", "(", "\" \"", ".", "join", "(", "[", "x", "[", "'token'", "]", "[", "kdx", "]", "for", "kdx", "in", "selected_set", "]", ")", ")", "\n", "", "trim_ora_json", "=", "comp_document_oracle", "(", "doc_list_trimmed_for_oracle", ",", "abs_str", ")", "\n", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "rt", "[", "'part'", "]", "=", "data_name", "\n", "# span_pairs = gen_span_segmentation([x['token'] for x in rt_sentences])", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_list\"", "]", "=", "abs_token", "\n", "rt", "[", "\"doc\"", "]", "=", "\" \"", ".", "join", "(", "doc_list", ")", "\n", "rt", "[", "\"doc_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "sent_packs", "]", "\n", "rt", "[", "\"sentences\"", "]", "=", "sent_packs", "\n", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "trim_ora_json", "\n", "rt", "[", "\"non_compression_sent_oracle\"", "]", "=", "sent_ora_json", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "# for rand_drop in range(8):", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.create_oracles_with_ilp": [[471, 480], ["oracle.process_one_example_with_ilp", "oracle.process_one_example_with_ilp", "oracle.process_one_example_with_ilp", "oracle.process_one_example_with_ilp"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_with_ilp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_with_ilp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_with_ilp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.process_one_example_with_ilp"], ["", "", "def", "create_oracles_with_ilp", "(", "dataname", ",", "path_read", ",", "path_wt_distributed", ")", ":", "\n", "# files = [i.split(\".\")[0] for i in os.listdir(path_read) if i.endswith('.doc.json')]", "\n", "# for fname in files:", "\n", "#     process_one_example_with_ilp(path_read, path_wt_distributed,fname,30,data_name)", "\n", "\n", "    ", "process_one_example_with_ilp", "(", "path_read", ",", "path_wt_distributed", ",", "'6b43f5e79b3cdf1c4a6debad958d5d70358f4269'", ",", "30", ",", "data_name", ")", "\n", "process_one_example_with_ilp", "(", "path_read", ",", "path_wt_distributed", ",", "'e1dc607107cc484c4bc1515cfa414a45088d4048'", ",", "30", ",", "data_name", ")", "\n", "process_one_example_with_ilp", "(", "path_read", ",", "path_wt_distributed", ",", "'b3f9fa06492bed4394ca521100b10e87431d0ddb'", ",", "30", ",", "data_name", ")", "\n", "process_one_example_with_ilp", "(", "path_read", ",", "path_wt_distributed", ",", "'8e03f1cc2061dbfb947d4e790395bddbf070db53'", ",", "30", ",", "data_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.create_oracles": [[481, 508], ["len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "zip", "i.split", "os.listdir", "i.endswith"], "function", ["None"], ["", "def", "create_oracles", "(", "dataname", ",", "path_read", ",", "path_wt_distributed", ")", ":", "\n", "    ", "\"\"\"\n    Create Oracles, write individual json files to the disk.\n    If CNNDM,\n    :return:\n    \"\"\"", "\n", "\n", "files", "=", "[", "i", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "i", "in", "os", ".", "listdir", "(", "path_read", ")", "if", "i", ".", "endswith", "(", "'.doc.json'", ")", "]", "\n", "# files = files[:100]", "\n", "total_num", "=", "len", "(", "files", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "\n", "pool", ".", "starmap", "(", "process_one_example", ",", "zip", "(", "[", "path_read", "]", "*", "total_num", ",", "\n", "[", "path_wt_distributed", "]", "*", "total_num", ",", "\n", "files", ",", "\n", "[", "30", "]", "*", "total_num", ",", "\n", "[", "dataname", "]", "*", "total_num", ")", ")", "\n", "\n", "# pool.starmap(process_one_example_allen, zip([path_read] * total_num,", "\n", "#                                             [path_wt_distributed] * total_num,", "\n", "#                                             files,", "\n", "#                                             [35] * total_num,", "\n", "#                                             [dataname] * total_num))", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "print", "(", "\"finish creating oracles, and write down them to distributed folders.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.split_data": [[510, 542], ["move_file_to_dir_url", "move_file_to_dir_url", "move_file_to_dir_url", "random.shuffle", "len", "int", "int", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "move_file_to_dir_file_name", "os.path.join", "os.path.join", "os.path.join", "x.split", "os.listdir", "x.endswith", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name"], ["", "def", "split_data", "(", "root", ",", "full_dataname", ",", "read_path", ",", "tgt_path", ")", ":", "\n", "    ", "if", "(", "full_dataname", "==", "'cnn'", ")", "or", "(", "full_dataname", "==", "'dailymail'", ")", ":", "\n", "        ", "train_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_training_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "dev_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_validation_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "test_urls", "=", "root", "+", "'/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "train_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "dev_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_url", "(", "url_file", "=", "test_urls", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "full_dataname", "==", "'nyt'", ":", "\n", "        ", "files", "=", "[", "x", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "read_path", ")", "if", "x", ".", "endswith", "(", "\".data\"", ")", "]", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "total_len", "=", "len", "(", "files", ")", "\n", "train_len", "=", "int", "(", "total_len", "*", "0.8", ")", "\n", "dev_len", "=", "int", "(", "total_len", "*", "0.1", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", ":", "train_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'train.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", ":", "train_len", "+", "dev_len", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'dev.txt'", ")", ")", "\n", "\n", "move_file_to_dir_file_name", "(", "file_list", "=", "files", "[", "train_len", "+", "dev_len", ":", "]", ",", "path_read", "=", "read_path", ",", "\n", "file_to_write", "=", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "'test.txt'", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.convert_json_to_pkl_local": [[544, 553], ["neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "print", "neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "print", "neusum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump"], ["", "", "def", "convert_json_to_pkl_local", "(", "root", ",", "_data_name", ")", ":", "\n", "    ", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"test\"", ",", "part", "=", "_data_name", ")", "\n", "print", "(", "\"Test done. Training start.\"", ")", "\n", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"train\"", ",", "part", "=", "_data_name", ")", "\n", "print", "(", "\"Test done. Training done. Dev start.\"", ")", "\n", "convert_json_file_to_pkl_dump", "(", "path", "=", "root", "+", "\"/2merge-{}\"", ".", "format", "(", "_data_name", ")", ",", "\n", "txt_fname", "=", "\"dev\"", ",", "part", "=", "_data_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.stage_1": [[555, 570], ["neusum.service.basic_service.clear_dir", "oracle.create_oracles", "neusum.service.basic_service.clear_dir", "print", "oracle.split_data"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.create_oracles", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.oracle.split_data"], ["", "def", "stage_1", "(", ")", ":", "\n", "    ", "clear_dir", "(", "path_wt", ")", "\n", "\n", "# create_oracles  process_one_example", "\n", "# write down data to path_wt", "\n", "create_oracles", "(", "dataname", "=", "data_name", ",", "path_read", "=", "path_read", ",", "path_wt_distributed", "=", "path_wt", ")", "\n", "#TODO swtich", "\n", "# create_oracles_with_ilp(dataname=data_name, path_read=path_read, path_wt_distributed=path_wt)", "\n", "\n", "clear_dir", "(", "path_wt_merge", ")", "\n", "print", "(", "path_wt_merge", ")", "\n", "# split data", "\n", "split_data", "(", "root", ",", "full_dataname", "=", "full_dataname", ",", "\n", "read_path", "=", "path_wt", ",", "\n", "tgt_path", "=", "path_wt_merge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.TreeNode.__init__": [[103, 110], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ":", "str", ",", "text", ",", "children", ":", "List", ",", "depth", ":", "int", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "children", "=", "children", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "start_idx", "=", "-", "1", "\n", "self", ".", "end_idx", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.TreeNode.__repr__": [[111, 113], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Text: {}\\tTag:{}\\tDepth:{}\"", ".", "format", "(", "\" \"", ".", "join", "(", "self", ".", "text", ")", ",", "self", ".", "tag", ",", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_one": [[27, 36], ["open", "json.loads", "allennlp.data.fields.TextField", "instances.append", "allennlp.data.instance.Instance", "allennlp.data.tokenizers.Token", "doc_str.split"], "function", ["None"], ["def", "read_one", "(", "file_path", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "data_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "doc_str", "=", "data_dict", "[", "'doc'", "]", "\n", "allen_token_word_in_doc", "=", "TextField", "(", "[", "Token", "(", "word", ")", "for", "word", "in", "doc_str", ".", "split", "(", ")", "]", ",", "word_token_indexers", ")", "\n", "instances", ".", "append", "(", "Instance", "(", "{", "\"text\"", ":", "allen_token_word_in_doc", "}", ")", ")", "\n", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.modify_sentences": [[38, 43], ["None"], "function", ["None"], ["", "def", "modify_sentences", "(", "sent_idx", ",", "text_bits", ",", "rm", ")", ":", "\n", "    ", "before", "=", "text_bits", "[", "sent_idx", "]", "\n", "after", "=", "before", "-", "rm", "\n", "text_bits", "[", "sent_idx", "]", "=", "after", "\n", "return", "text_bits", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.flip_exsisting_combination": [[45, 78], ["range", "len", "enumerate", "len", "random.sample", "get_rouge_est_str_2gram", "len", "texts.append", "compressions.append", "set", "util.modify_sentences", "util.modify_sentences", "random.random", "trim_done.append", "range", "util.assemble_text_and_bit", "len", "list_of_compressions.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.modify_sentences", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.modify_sentences", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit"], ["", "def", "flip_exsisting_combination", "(", "topk_combinations", ",", "sentences", ",", "abs_str", ",", "flip", "=", "0.2", ")", ":", "\n", "    ", "drop_num", "=", "0", "\n", "best_combi", "=", "topk_combinations", "[", "0", "]", "\n", "trim_done", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "best_combi", "[", "'done'", "]", ")", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "flip", ":", "\n", "            ", "drop_num", "+=", "1", "\n", "", "else", ":", "\n", "            ", "trim_done", ".", "append", "(", "best_combi", "[", "'done'", "]", "[", "i", "]", ")", "\n", "\n", "", "", "texts", "=", "[", "]", "\n", "compressions", "=", "[", "]", "\n", "for", "unit", "in", "sentences", ":", "\n", "        ", "texts", ".", "append", "(", "unit", "[", "0", "]", ".", "text", ")", "\n", "compressions", ".", "append", "(", "unit", "[", "1", "]", ")", "\n", "", "sent_num", "=", "len", "(", "sentences", ")", "\n", "text_bits", "=", "[", "set", "(", "range", "(", "len", "(", "x", ")", ")", ")", "for", "x", "in", "texts", "]", "\n", "list_of_compressions", "=", "[", "]", "\n", "for", "sent_idx", ",", "comp", "in", "enumerate", "(", "compressions", ")", ":", "\n", "        ", "for", "one_comp_option", "in", "comp", ":", "\n", "            ", "if", "one_comp_option", "[", "'node'", "]", "!=", "\"BASELINE\"", ":", "\n", "                ", "list_of_compressions", ".", "append", "(", "[", "sent_idx", ",", "one_comp_option", "]", ")", "\n", "", "", "", "total_len", "=", "len", "(", "list_of_compressions", ")", "\n", "\n", "replacement", "=", "random", ".", "sample", "(", "list_of_compressions", ",", "drop_num", ")", "\n", "\n", "for", "trim", "in", "trim_done", ":", "\n", "        ", "text_bits", "=", "modify_sentences", "(", "trim", "[", "0", "]", ",", "text_bits", ",", "rm", "=", "trim", "[", "1", "]", "[", "'selected_idx'", "]", ")", "\n", "", "for", "rep", "in", "replacement", ":", "\n", "        ", "text_bits", "=", "modify_sentences", "(", "rep", "[", "0", "]", ",", "text_bits", ",", "rm", "=", "rep", "[", "1", "]", "[", "'selected_idx'", "]", ")", "\n", "", "new_rouge", "=", "get_rouge_est_str_2gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "\n", "assemble_text_and_bit", "(", "texts", ",", "text_bits", ")", ")", "\n", "return", "new_rouge", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text": [[80, 85], ["bag.append"], "function", ["None"], ["", "def", "assemble_text", "(", "inp", ":", "List", "[", "List", "[", "str", "]", "]", ")", ":", "\n", "    ", "bag", "=", "[", "]", "\n", "for", "i", "in", "inp", ":", "\n", "        ", "bag", ".", "append", "(", "\" \"", ".", "join", "(", "i", ")", ")", "\n", "", "return", "\"\\n\"", ".", "join", "(", "bag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_doc_list_from_idx": [[87, 92], ["_tmp.append"], "function", ["None"], ["", "def", "assemble_doc_list_from_idx", "(", "doc", ",", "idxs", ")", ":", "\n", "    ", "_tmp", "=", "[", "]", "\n", "for", "i", "in", "idxs", ":", "\n", "        ", "_tmp", ".", "append", "(", "doc", "[", "i", "]", ")", "\n", "", "return", "_tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.assemble_text_and_bit": [[94, 100], ["zip", "tmp.append"], "function", ["None"], ["", "def", "assemble_text_and_bit", "(", "text", ",", "bit", ")", ":", "\n", "    ", "tmp", "=", "[", "]", "\n", "for", "tt", ",", "bb", "in", "zip", "(", "text", ",", "bit", ")", ":", "\n", "        ", "sent", "=", "[", "tt", "[", "b", "]", "for", "b", "in", "bb", "]", "\n", "tmp", ".", "append", "(", "\" \"", ".", "join", "(", "sent", ")", ")", "\n", "", "return", "\"\\n\"", ".", "join", "(", "tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_single_parse_tree": [[115, 130], ["re.sub.replace", "re.sub", "util.parse_subtree", "util.add_idx_of_tree", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "", "def", "read_single_parse_tree", "(", "inp_str", ")", "->", "TreeNode", ":", "\n", "    ", "\"\"\"\n    Given a string from stanfordnlp, convert to a tree.\n    :param inp_str: (ROOT\\n  (FRAG\\n    (NP (NN NEW))\\n ....\n    :return:\n    \"\"\"", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "# inp_str = re.split('\\(|\\)|\\s', inp_str)", "\n", "inp_str", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "inp_str", ")", "\n", "# inp = inp.split(\" \")", "\n", "# inp_str = inp_str.replace(\"-LRB- (\", \"-LRB- [\")", "\n", "# inp_str = inp_str.replace(\"-RRB- )\", \"-RRB- ]\")", "\n", "out", "=", "parse_subtree", "(", "inp_str", ",", "depth", "=", "0", ")", "\n", "out", "=", "add_idx_of_tree", "(", "out", ",", "start_idx", "=", "0", ",", "end_idx", "=", "len", "(", "out", ".", "text", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.extract_tokens_allen": [[132, 134], ["None"], "function", ["None"], ["", "def", "extract_tokens_allen", "(", "allen_lines", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.extract_tokens": [[136, 152], ["buff.append", "buff_str.append"], "function", ["None"], ["", "def", "extract_tokens", "(", "snlp_dict", ")", ":", "\n", "    ", "\"\"\"\n\n    :param snlp_dict:\n    :return: buff: List[List[str]]\n            string: a C B\\nD e f\\n...\n    \"\"\"", "\n", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff", "=", "[", "]", "\n", "buff_str", "=", "[", "]", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "tokens", "=", "s", "[", "\"tokens\"", "]", "\n", "tokens_list", "=", "[", "x", "[", "\"word\"", "]", "for", "x", "in", "tokens", "]", "\n", "buff", ".", "append", "(", "tokens_list", ")", "\n", "buff_str", ".", "append", "(", "\" \"", ".", "join", "(", "tokens_list", ")", ")", "\n", "", "return", "buff", ",", "\"\\n\"", ".", "join", "(", "buff_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_file": [[154, 158], ["open", "fd.read"], "function", ["None"], ["", "def", "read_file", "(", "fpath", ")", "->", "str", ":", "\n", "    ", "with", "open", "(", "fpath", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "output", "=", "fd", ".", "read", "(", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.extract_parse": [[160, 164], ["None"], "function", ["None"], ["", "def", "extract_parse", "(", "snlp_dict", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff_parse", "=", "[", "s", "[", "'parse'", "]", "for", "s", "in", "sentences", "]", "\n", "return", "buff_parse", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.add_idx_of_tree": [[166, 179], ["len", "new_children.append", "util.add_idx_of_tree"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "def", "add_idx_of_tree", "(", "tree", ":", "TreeNode", ",", "start_idx", ":", "int", ",", "end_idx", ":", "int", ")", ":", "\n", "    ", "tree", ".", "start_idx", "=", "start_idx", "\n", "tree", ".", "end_idx", "=", "end_idx", "\n", "if", "not", "tree", ".", "children", ":", "\n", "        ", "return", "tree", "\n", "", "cur_start", "=", "start_idx", "\n", "new_children", "=", "[", "]", "\n", "for", "child", "in", "tree", ".", "children", ":", "\n", "        ", "span_len", "=", "len", "(", "child", ".", "text", ")", "\n", "new_children", ".", "append", "(", "add_idx_of_tree", "(", "child", ",", "start_idx", "=", "cur_start", ",", "end_idx", "=", "cur_start", "+", "span_len", ")", ")", "\n", "cur_start", "+=", "span_len", "\n", "", "tree", ".", "children", "=", "new_children", "\n", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.return_childrens": [[181, 198], ["enumerate", "buff.append", "rt_list.append"], "function", ["None"], ["", "def", "return_childrens", "(", "inp", ":", "str", ")", "->", "List", ":", "\n", "    ", "dep", "=", "0", "\n", "rt_list", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "inp", ")", ":", "\n", "        ", "if", "c", "==", "'('", ":", "\n", "            ", "dep", "+=", "1", "\n", "", "elif", "c", "==", "')'", ":", "\n", "            ", "dep", "-=", "1", "\n", "", "if", "buff", "==", "[", "]", "and", "c", "==", "\" \"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "buff", ".", "append", "(", "c", ")", "\n", "", "if", "dep", "==", "0", "and", "buff", "!=", "[", "]", ":", "\n", "            ", "rt_list", ".", "append", "(", "\"\"", ".", "join", "(", "buff", ")", ")", "\n", "buff", "=", "[", "]", "\n", "", "", "return", "rt_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.parse_subtree": [[200, 219], ["inp_str.find", "inp_str.rfind", "inp_str.find", "util.TreeNode", "util.return_childrens", "util.parse_subtree", "child.strip"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.return_childrens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree"], ["", "def", "parse_subtree", "(", "inp_str", ":", "str", ",", "depth", ":", "int", ")", ":", "\n", "# print(inp_str)", "\n", "    ", "index_lb", "=", "inp_str", ".", "find", "(", "\"(\"", ")", "\n", "index_rb", "=", "inp_str", ".", "rfind", "(", "\")\"", ")", "\n", "idex_split_of_tag_children", "=", "inp_str", ".", "find", "(", "\" \"", ")", "\n", "tag", "=", "inp_str", "[", "index_lb", "+", "1", ":", "idex_split_of_tag_children", "]", "\n", "child", "=", "inp_str", "[", "idex_split_of_tag_children", "+", "1", ":", "index_rb", "]", "\n", "if", "\"(\"", "in", "child", ":", "\n", "        ", "children_list", "=", "return_childrens", "(", "child", ")", "# (NP   =>(x x) (x x) (x x)<=)", "\n", "children_node", "=", "[", "parse_subtree", "(", "x", ",", "depth", "+", "1", ")", "for", "x", "in", "children_list", "]", "\n", "txt_buff", "=", "[", "]", "\n", "for", "n", "in", "children_node", ":", "\n", "            ", "txt_buff", "+=", "n", ".", "text", "\n", "", "text", "=", "txt_buff", "\n", "", "else", ":", "\n", "# reach leaf node", "\n", "        ", "text", "=", "[", "child", ".", "strip", "(", ")", "]", "\n", "children_node", "=", "None", "\n", "", "return", "TreeNode", "(", "tag", "=", "tag", ",", "text", "=", "text", ",", "children", "=", "children_node", ",", "depth", "=", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.folding_rouge": [[221, 235], ["int", "int", "range", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "rouge_bag.append", "sum", "len", "len", "len", "len", "txt_str.split"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart"], ["", "def", "folding_rouge", "(", "abs_list", ",", "txt_str", ":", "str", ")", ":", "\n", "# experimental way", "\n", "    ", "n_fold", "=", "int", "(", "len", "(", "abs_list", ")", "/", "len", "(", "txt_str", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "num_word_one_fold", "=", "int", "(", "len", "(", "abs_list", ")", "/", "n_fold", ")", "\n", "rouge_bag", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n_fold", ")", ":", "\n", "        ", "if", "idx", "==", "n_fold", "-", "1", ":", "\n", "            ", "tmp_abs", "=", "abs_list", "[", "idx", "*", "num_word_one_fold", ":", "]", "\n", "", "else", ":", "\n", "            ", "tmp_abs", "=", "abs_list", "[", "idx", "*", "num_word_one_fold", ":", "(", "idx", "+", "1", ")", "*", "num_word_one_fold", "]", "\n", "", "r", "=", "get_rouge_est_str_2gram_smart", "(", "gold", "=", "\" \"", ".", "join", "(", "tmp_abs", ")", ",", "pred", "=", "txt_str", ")", "\n", "rouge_bag", ".", "append", "(", "r", ")", "\n", "", "new_rouge", "=", "sum", "(", "rouge_bag", ")", "/", "len", "(", "rouge_bag", ")", "\n", "return", "new_rouge", "\n", "# print(\"{}\\t{}\\t{}\".format(new_rouge >= _rouge, new_rouge, _rouge))", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.find_deletable_span_rule_based": [[238, 304], ["enumerate", "enumerate", "enumerate", "set", "util.find_deletable_span_rule_based", "util.find_deletable_span_rule_based", "len", "set", "range", "set", "range", "set", "set", "range", "set", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based"], ["", "def", "find_deletable_span_rule_based", "(", "tree", ":", "TreeNode", ",", "root_len", ":", "int", ",", "sibling", "=", "None", ",", "\n", "parent", "=", "None", "\n", ")", "->", "List", "[", "TreeNode", "]", ":", "\n", "    ", "\"\"\"\n    Extraction:\n    1. S (!= VP and len(S) > 8 words)\n        case: [S [NP county officials in Las Vegas] [VP appointed two women [S [VP to fill vacancies in the state Assembly]]] ]\n        When S=VP, it's not an individual sentence.\n\n    Compression:\n    1. PP\n    2. SBAR\n    3. ADVP\n    4. ADJP\n    5. S (== VP and left != [WHNP,IN]) because WHNP + S = SBAR\n        eg. in playing soccer\n    6. NP-TMP\n    7. -LRB-  ... ... -RRB-\n    \"\"\"", "\n", "# Rule is a list with TAG names", "\n", "# return a list of dict{\"node\", \"selected_idx\"} which are deletable", "\n", "tag", "=", "tree", ".", "tag", "\n", "deletable_bag", "=", "[", "]", "\n", "\n", "# Extraction", "\n", "if", "tree", ".", "tag", "==", "'S'", ":", "\n", "        ", "if", "tree", ".", "children", "[", "0", "]", "!=", "None", ":", "\n", "\n", "            ", "if", "(", "tree", ".", "children", "[", "0", "]", ".", "tag", "!=", "\"VP\"", ")", "and", "(", "len", "(", "tree", ".", "text", ")", ">", "5", ")", "and", "(", "tree", ".", "end_idx", "<", "root_len", ")", ":", "\n", "                ", "deletable_bag", "+=", "[", "{", "\"node\"", ":", "\"_S_\"", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "root_len", ")", ")", "-", "\n", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", "}", "]", "\n", "", "if", "(", "tree", ".", "children", "[", "0", "]", ".", "tag", "==", "\"VP\"", ")", "and", "(", "sibling", "is", "not", "None", ")", "and", "(", "sibling", ".", "tag", "not", "in", "[", "\"WHNP\"", ",", "\"IN\"", "]", ")", ":", "\n", "                ", "deletable_bag", "+=", "[", "{", "\"node\"", ":", "tree", ".", "tag", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", "}", "]", "\n", "\n", "", "", "", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "        ", "lrb", ",", "rrb", "=", "-", "1", ",", "-", "1", "\n", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "            ", "if", "child", ".", "tag", "==", "\"-LRB-\"", ":", "\n", "                ", "lrb", "=", "child", ".", "start_idx", "\n", "", "elif", "child", ".", "tag", "==", "'-RRB-'", ":", "\n", "                ", "rrb", "=", "child", ".", "end_idx", "\n", "", "", "if", "(", "lrb", ">=", "0", ")", "and", "(", "rrb", ">=", "0", ")", "and", "(", "lrb", "<", "rrb", ")", ":", "\n", "            ", "deletable_bag", "+=", "[", "{", "\"node\"", ":", "\"LRRB\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "lrb", ",", "rrb", ")", ")", "}", "]", "\n", "# print({\"par_text\":parent.text,\"text\":tree.children,\"node\": \"LRRB\", \"selected_idx\": set(range(lrb, rrb))})", "\n", "\n", "", "", "if", "tag", "in", "[", "\"PP\"", ",", "\"SBAR\"", ",", "\"ADVP\"", ",", "\"ADJP\"", ",", "\"NP-TMP\"", ",", "\"PRN\"", "]", ":", "\n", "        ", "deletable_bag", "+=", "[", "{", "\"node\"", ":", "tree", ".", "tag", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", "}", "]", "\n", "# if ' '.join(tree.text) == '-LRB- CNN -RRB-':", "\n", "#     deletable_bag += [{\"node\": \"PRN\", \"selected_idx\": set(range(tree.start_idx, tree.end_idx))}]", "\n", "\n", "", "if", "parent", "is", "not", "None", ":", "\n", "        ", "if", "(", "parent", ".", "tag", "==", "\"NP\"", ")", "and", "(", "tree", ".", "children", "is", "not", "None", ")", ":", "\n", "            ", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "                ", "if", "child", ".", "tag", "==", "'JJ'", ":", "\n", "                    ", "deletable_bag", "+=", "[", "{", "\"node\"", ":", "\"JJ\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "child", ".", "start_idx", ",", "child", ".", "end_idx", ")", ")", "}", "]", "\n", "# print({\"par_text\":parent.text,\"text\":child.text,\"node\": \"JJ\", \"selected_idx\": set(range(child.start_idx, child.end_idx))})", "\n", "", "", "", "", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "        ", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "deletable_bag", "+=", "find_deletable_span_rule_based", "(", "child", ",", "root_len", ",", "None", ",", "parent", "=", "tree", ")", "\n", "", "else", ":", "\n", "                ", "deletable_bag", "+=", "find_deletable_span_rule_based", "(", "child", ",", "root_len", ",", "tree", ".", "children", "[", "idx", "-", "1", "]", ",", "parent", "=", "tree", ")", "\n", "\n", "", "", "", "return", "deletable_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.check_if_redundant": [[306, 311], ["any"], "function", ["None"], ["", "def", "check_if_redundant", "(", "text_bit", ",", "pool", ")", ":", "\n", "    ", "if", "any", "(", "[", "True", "for", "p", "in", "pool", "if", "p", "[", "'text_bits'", "]", "==", "text_bit", "]", ")", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.check_if_empty_lists": [[313, 320], ["None"], "function", ["None"], ["", "", "def", "check_if_empty_lists", "(", "inp", ")", ":", "\n", "    ", "if", "inp", "==", "[", "]", ":", "\n", "        ", "return", "True", "\n", "", "for", "i", "in", "inp", ":", "\n", "        ", "if", "i", "!=", "[", "]", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.comp_document_oracle": [[338, 383], ["len", "range", "range", "d.strip", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "f_score_list.append", "numpy.argsort", "len", "filtered_doc_list.append", "map_from_new_to_ori_idx.append", "util.comp_num_seg_out_of_p_sent_beam", "abs_str.split"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam"], ["def", "comp_document_oracle", "(", "doc_list", ":", "List", ",", "abs_str", ",", "beam_sz", "=", "6", ")", ":", "\n", "    ", "\"\"\"\n    Given a document and the abstraction string, return the oracle set combination\n    :param doc_list: List of strings.\n    :param abs_str: a single string with \\n\n    :param name:\n    :return:\n    \"\"\"", "\n", "doc_list", "=", "[", "d", ".", "strip", "(", ")", "for", "d", "in", "doc_list", "]", "# trim", "\n", "# for d in doc_list:", "\n", "#     assert len(d) > 0", "\n", "len_of_doc", "=", "len", "(", "doc_list", ")", "\n", "doc_as_readable_list", "=", "doc_list", "\n", "abs_as_readable_list", "=", "[", "x", "for", "x", "in", "abs_str", ".", "split", "(", "\"\\n\"", ")", "if", "(", "x", "!=", "\"\"", ")", "and", "(", "x", "!=", "\" \"", ")", "]", "# no SS and \\n", "\n", "\n", "f_score_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len_of_doc", ")", ":", "\n", "        ", "f1", "=", "get_rouge_est_str_2gram_smart", "(", "gold", "=", "abs_str", ",", "pred", "=", "doc_as_readable_list", "[", "i", "]", ")", "\n", "# len_compensat_inp = length_compensation(doc=doc_as_readable_list[i], abs=abs_as_readable_list)", "\n", "# f1 = get_rouge_est_str_2gram(gold='\\n'.join(abs_as_readable_list),", "\n", "#                              pred=len_compensat_inp)", "\n", "\n", "f_score_list", ".", "append", "(", "f1", ")", "\n", "", "top_p_sent_idx", "=", "numpy", ".", "argsort", "(", "f_score_list", ")", "[", "-", "P_SENT", ":", "]", "\n", "\n", "map_from_new_to_ori_idx", "=", "[", "]", "\n", "# filter", "\n", "filtered_doc_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "top_p_sent_idx", ")", ")", ":", "\n", "        ", "filtered_doc_list", ".", "append", "(", "doc_as_readable_list", "[", "top_p_sent_idx", "[", "i", "]", "]", ")", "\n", "map_from_new_to_ori_idx", ".", "append", "(", "top_p_sent_idx", "[", "i", "]", ")", "\n", "\n", "# filter_doc_list stores filtered doc", "\n", "# map_from_new_to_ori_idx contains their original index", "\n", "", "combination_data_dict", "=", "{", "}", "\n", "for", "num_of_edu", "in", "NUM_EDU", ":", "\n", "        ", "combination_data", "=", "comp_num_seg_out_of_p_sent_beam", "(", "_filtered_doc_list", "=", "filtered_doc_list", ",", "\n", "_num_edu", "=", "num_of_edu", ",", "\n", "_absas_read_str", "=", "abs_str", ",", "\n", "abs_as_read_list", "=", "abs_as_readable_list", ",", "\n", "map_from_new_to_ori_idx", "=", "map_from_new_to_ori_idx", ",", "\n", "beam_sz", "=", "beam_sz", ")", "\n", "combination_data_dict", "[", "num_of_edu", "]", "=", "combination_data", "\n", "# json_str = json.dumps(combination_data_dict)", "\n", "", "return", "combination_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.comp_num_seg_out_of_p_sent_beam": [[385, 507], ["list", "beam.append", "range", "len", "range", "sorted", "n_comb.sort", "util.assemble_doc_list_from_idx", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "len", "len", "sorted", "int", "sorted", "util.assemble_doc_list_from_idx", "neusum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "sorted", "todo.copy", "todo.copy.remove", "global_board.append", "str", "beam_waitlist.append", "check_dict.append", "_comb_bag.keys", "sorted", "str"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart"], ["", "def", "comp_num_seg_out_of_p_sent_beam", "(", "_filtered_doc_list", ",", "\n", "_num_edu", ",", "\n", "_absas_read_str", ",", "\n", "abs_as_read_list", ",", "\n", "map_from_new_to_ori_idx", ",", "\n", "beam_sz", "=", "8", ")", ":", "\n", "    ", "beam", "=", "[", "]", "\n", "if", "len", "(", "_filtered_doc_list", ")", "<", "_num_edu", ":", "\n", "        ", "return", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "{", "}", ",", "\n", "\"best\"", ":", "None", "\n", "}", "\n", "\n", "", "combs", "=", "list", "(", "range", "(", "1", ",", "len", "(", "_filtered_doc_list", ")", ")", ")", "\n", "# _num_edu seq_len", "\n", "cur_beam", "=", "{", "\n", "\"in\"", ":", "[", "]", ",", "\n", "\"todo\"", ":", "combs", ",", "\n", "\"val\"", ":", "0", "\n", "}", "\n", "beam", ".", "append", "(", "cur_beam", ")", "\n", "for", "t", "in", "range", "(", "_num_edu", ")", ":", "\n", "        ", "dict_pattern", "=", "{", "}", "\n", "# compute top beam_sz for every beam", "\n", "global_board", "=", "[", "]", "\n", "for", "b", "in", "beam", ":", "\n", "            ", "already_in_beam", "=", "b", "[", "'in'", "]", "\n", "todo", "=", "b", "[", "'todo'", "]", "\n", "\n", "leaderboard", "=", "{", "}", "\n", "for", "to_add", "in", "todo", ":", "\n", "                ", "after_add", "=", "already_in_beam", "+", "[", "to_add", "]", "\n", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "after_add", ")", "\n", "_tmp", "=", "'\\n'", ".", "join", "(", "_tmp", ")", "\n", "average_f_score", "=", "get_rouge_est_str_2gram_smart", "(", "_absas_read_str", ",", "_tmp", ")", "\n", "# average_f_score = get_rouge_est_str_2gram(_absas_read_str, _tmp)", "\n", "\n", "leaderboard", "[", "to_add", "]", "=", "average_f_score", "\n", "", "sorted_beam", "=", "[", "(", "k", ",", "leaderboard", "[", "k", "]", ")", "for", "k", "in", "sorted", "(", "leaderboard", ",", "key", "=", "leaderboard", ".", "get", ",", "reverse", "=", "True", ")", "]", "\n", "\n", "for", "it", "in", "sorted_beam", ":", "\n", "                ", "new_in", "=", "already_in_beam", "+", "[", "it", "[", "0", "]", "]", "\n", "\n", "sorted_new_in", "=", "sorted", "(", "new_in", ")", "\n", "str_new_in", "=", "[", "str", "(", "x", ")", "for", "x", "in", "sorted_new_in", "]", "\n", "if", "'_'", ".", "join", "(", "str_new_in", ")", "in", "dict_pattern", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "dict_pattern", "[", "'_'", ".", "join", "(", "str_new_in", ")", "]", "=", "True", "\n", "", "new_list", "=", "todo", ".", "copy", "(", ")", "\n", "new_list", ".", "remove", "(", "it", "[", "0", "]", ")", "\n", "# rank_actual_idx = sort_idx_map[it[0]]", "\n", "# new list", "\n", "# if rank_actual_idx + 1 == len(_filtered_doc_list):", "\n", "#     continue", "\n", "# it[0] is the index in combs = index in filter_doc_list", "\n", "# sort_idx_map ====> the rank in original document", "\n", "# new_list only contains stuff have larger rank than rank_actual_idx", "\n", "# for _i, _rank in enumerate(sort_idx_map):", "\n", "#     if _rank > rank_actual_idx:", "\n", "#         new_list.append(combs[_i])", "\n", "# assert len(new_list) != 0", "\n", "_beam", "=", "{", "\n", "\"in\"", ":", "new_in", ",", "\n", "\"todo\"", ":", "new_list", ",", "\n", "\"val\"", ":", "it", "[", "1", "]", "\n", "}", "\n", "global_board", ".", "append", "(", "_beam", ")", "\n", "# merge and get the top beam_sz among all", "\n", "\n", "", "", "sorted_global_board", "=", "sorted", "(", "global_board", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"val\"", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "_cnt", "=", "0", "\n", "check_dict", "=", "[", "]", "\n", "beam_waitlist", "=", "[", "]", "\n", "for", "it", "in", "sorted_global_board", ":", "\n", "            ", "str_in", "=", "sorted", "(", "it", "[", "'in'", "]", ")", "\n", "str_in", "=", "[", "str", "(", "x", ")", "for", "x", "in", "str_in", "]", "\n", "_tmp_key", "=", "'_'", ".", "join", "(", "str_in", ")", "\n", "if", "_tmp_key", "in", "check_dict", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "beam_waitlist", ".", "append", "(", "it", ")", "\n", "check_dict", ".", "append", "(", "_tmp_key", ")", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", ">=", "beam_sz", ":", "\n", "                ", "break", "\n", "", "", "beam", "=", "beam_waitlist", "\n", "# if len(beam) < 2:", "\n", "#     print(len(_filtered_doc_list))", "\n", "#     print(_num_edu)", "\n", "# Write oracle to a string like: 0.4 0.3 0.4", "\n", "", "_comb_bag", "=", "{", "}", "\n", "for", "it", "in", "beam", ":", "\n", "        ", "n_comb", "=", "it", "[", "'in'", "]", "\n", "n_comb", ".", "sort", "(", ")", "\n", "n_comb_original", "=", "[", "map_from_new_to_ori_idx", "[", "a", "]", "for", "a", "in", "n_comb", "]", "\n", "# n_comb_original.sort()  # json label", "\n", "n_comb_original", "=", "[", "int", "(", "x", ")", "for", "x", "in", "n_comb_original", "]", "\n", "# print(n_comb_original)", "\n", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "n_comb", ")", "\n", "# score = rouge_protocol([[_tmp]], [[abs_as_read_list]])", "\n", "_tmp", "=", "'\\n'", ".", "join", "(", "_tmp", ")", "\n", "f1", "=", "get_rouge_est_str_2gram_smart", "(", "_absas_read_str", ",", "_tmp", ")", "\n", "\n", "_comb_bag", "[", "f1", "]", "=", "{", "\"label\"", ":", "n_comb_original", ",", "\n", "\"R1\"", ":", "f1", ",", "\n", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"sent\"", ":", "_tmp", "}", "\n", "# print(len(_comb_bag))", "\n", "", "if", "len", "(", "_comb_bag", ")", "==", "0", ":", "\n", "        ", "return", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "{", "}", ",", "\n", "\"best\"", ":", "None", "\n", "}", "\n", "", "else", ":", "\n", "        ", "best_key", "=", "sorted", "(", "_comb_bag", ".", "keys", "(", ")", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "rt_dict", "=", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "_comb_bag", ",", "\n", "\"best\"", ":", "_comb_bag", "[", "best_key", "]", "\n", "}", "\n", "return", "rt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.hashhex": [[512, 517], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.get_url_hashes": [[519, 526], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_url": [[528, 546], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "open", "fd.read().splitlines", "util.get_url_hashes", "print", "os.path.join", "open", "fd.write", "fd.read", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes"], ["", "def", "move_file_to_dir_url", "(", "url_file", ",", "path_read", ",", "file_to_write", ")", ":", "\n", "    ", "with", "open", "(", "url_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "\n", "", "url_names", "=", "[", "os", ".", "path", ".", "join", "(", "path_read", ",", "url", ")", "for", "url", "in", "url_names", "]", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "rt_bag", "=", "pool", ".", "map", "(", "read_one_file", ",", "url_names", ")", "\n", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "rt_bag", "=", "[", "x", "for", "x", "in", "rt_bag", "if", "x", "is", "not", "None", "]", "\n", "wt_string", "=", "\"\\n\"", ".", "join", "(", "rt_bag", ")", "\n", "with", "open", "(", "file_to_write", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "wt_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.move_file_to_dir_file_name": [[548, 566], ["print", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.join", "open", "fd.write", "len"], "function", ["None"], ["", "", "def", "move_file_to_dir_file_name", "(", "file_list", ",", "path_read", ",", "file_to_write", ")", ":", "\n", "# with open(url_file, 'r', encoding='utf-8') as fd:", "\n", "#     lines = fd.read().splitlines()", "\n", "#     url_names = get_url_hashes(lines)", "\n", "#     print(\"len of urls {}\".format(len(url_names)))", "\n", "    ", "print", "(", "\"Len of file list: {}\"", ".", "format", "(", "len", "(", "file_list", ")", ")", ")", "\n", "url_names", "=", "[", "os", ".", "path", ".", "join", "(", "path_read", ",", "url", ")", "for", "url", "in", "file_list", "]", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "rt_bag", "=", "pool", ".", "map", "(", "read_one_file", ",", "url_names", ")", "\n", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "rt_bag", "=", "[", "x", "for", "x", "in", "rt_bag", "if", "x", "is", "not", "None", "]", "\n", "wt_string", "=", "\"\\n\"", ".", "join", "(", "rt_bag", ")", "\n", "with", "open", "(", "file_to_write", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "wt_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_one_file": [[568, 576], ["os.path.isfile", "open", "fd.read().splitlines", "len", "fd.read"], "function", ["None"], ["", "", "def", "read_one_file", "(", "fname", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "fname", "+", "'.data'", ")", ":", "\n", "        ", "with", "open", "(", "fname", "+", "'.data'", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "line", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "assert", "len", "(", "line", ")", "==", "1", "\n", "", "return", "line", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.__init__": [[30, 50], ["os.path.join", "range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "span_meta", ",", "\n", "sent_idxs", ",", "# #t", "\n", "prediction_score", ",", "# t, # max_comp, 2", "\n", "abs_str", ":", "List", "[", "str", "]", ",", "\n", "name", ",", "doc_list", ",", "keep_threshold", ":", "List", "[", "float", "]", ",", "part", ":", "str", ",", "\n", "ser_fname", ",", "ser_dir", ")", ":", "\n", "        ", "self", ".", "abs_str", "=", "abs_str", "\n", "self", ".", "span_meta", "=", "span_meta", "\n", "self", ".", "sent_idxs", "=", "sent_idxs", "\n", "self", ".", "prediction_score", "=", "prediction_score", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "doc_list", "=", "doc_list", "\n", "self", ".", "keep_threshold", "=", "keep_threshold", "\n", "self", ".", "dec_sents", "=", "[", "]", "\n", "\n", "self", ".", "full_sents", "=", "[", "]", "\n", "self", ".", "compressions", ":", "List", "[", "OrderedDict", "]", "=", "[", "]", "\n", "self", ".", "del_record", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", "]", "\n", "self", ".", "part", "=", "part", "\n", "self", ".", "ser_fname", "=", "os", ".", "path", ".", "join", "(", "ser_dir", ",", "ser_fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.run": [[51, 112], ["compression_decoder.CompExecutor.read_sent_record_compressions", "compression_decoder.CompExecutor.del_under_threshold", "compression_decoder.CompExecutor.iterative_rep_del", "numpy.argsort", "numpy.argsort", "enumerate", "enumerate", "enumerate", "bag_pred_eval.append", "random.random", "range", "neusum.service.basic_service.easy_post_processing", "_tmp.append", "logging.getLogger", "logging.getLogger.info", "enumerate", "neusum.service.basic_service.log_universal", "range", "open", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "open.write", "open.write", "open.close", "len", "d.items", "len", "neusum.service.basic_service.log_universal", "logging.getLogger.info", "x.startswith", "x.startswith", "str"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.read_sent_record_compressions", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.del_under_threshold", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.iterative_rep_del", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_universal", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_universal"], ["", "def", "run", "(", "self", ")", "->", "(", "List", ",", "List", ",", "List", ",", "List", ")", ":", "\n", "# go through everything", "\n", "        ", "_pred", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", "]", "\n", "# _visuals = [[] for _ in range(len(self.keep_threshold))]", "\n", "\n", "# first keep all of the compressions in record", "\n", "self", ".", "read_sent_record_compressions", "(", "self", ".", "sent_idxs", ")", "\n", "\n", "# start diverging", "\n", "# delete those under threshold", "\n", "self", ".", "del_under_threshold", "(", ")", "# diverge!", "\n", "# iterate: delete those already covered in context", "\n", "processed_words", "=", "self", ".", "iterative_rep_del", "(", ")", "\n", "# reorder", "\n", "# sent_order: List[int]", "\n", "order", "=", "np", ".", "argsort", "(", "self", ".", "sort_order", ")", "\n", "# output", "\n", "for", "kepidx", ",", "kep", "in", "enumerate", "(", "self", ".", "keep_threshold", ")", ":", "\n", "            ", "processed_words", "[", "kepidx", "]", "=", "[", "processed_words", "[", "kepidx", "]", "[", "o", "]", "for", "o", "in", "order", "]", "\n", "\n", "# output something for evaluation", "\n", "# bag_pred_eval = [[] for _ in range(len(self.keep_threshold))]", "\n", "", "bag_pred_eval", "=", "[", "]", "\n", "for", "i", ",", "words", "in", "enumerate", "(", "processed_words", ")", ":", "\n", "            ", "_tmp", "=", "[", "]", "\n", "for", "j", ",", "sent", "in", "enumerate", "(", "words", ")", ":", "\n", "                ", "sent", "=", "[", "x", "for", "x", "in", "sent", "if", "(", "not", "x", ".", "startswith", "(", "sp_tok", ")", ")", "and", "(", "not", "x", ".", "startswith", "(", "sp_tok_rep", ")", ")", "]", "\n", "out", "=", "easy_post_processing", "(", "\" \"", ".", "join", "(", "sent", ")", ")", "\n", "_tmp", ".", "append", "(", "out", ")", "\n", "", "bag_pred_eval", ".", "append", "(", "_tmp", ")", "\n", "\n", "# (optional) visualization", "\n", "\n", "", "if", "random", ".", "random", "(", ")", "<", "0.005", ":", "\n", "            ", "try", ":", "\n", "                ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "\"Prob\\t\\tType\\t\\tRatio\\t\\tRouge\\t\\tLen\\t\\tContent\"", ")", "\n", "for", "idx", ",", "d", "in", "enumerate", "(", "self", ".", "compressions", ")", ":", "\n", "                    ", "for", "key", ",", "value", "in", "d", ".", "items", "(", ")", ":", "\n", "                        ", "wt", "=", "[", "value", "[", "'prob'", "]", ",", "value", "[", "'type'", "]", ",", "value", "[", "'ratio'", "]", ",", "value", "[", "'rouge'", "]", ",", "value", "[", "'len'", "]", ",", "key", "]", "\n", "wt", "=", "\"\\t\\t\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "wt", "]", ")", "\n", "logger", ".", "info", "(", "wt", ")", "\n", "", "", "log_universal", "(", "Partition", "=", "self", ".", "part", ",", "Name", "=", "self", ".", "name", ",", "\n", "Abs", "=", "self", ".", "abs_str", "\n", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", ":", "\n", "                    ", "lis", "=", "processed_words", "[", "idx", "]", "\n", "lis_out", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "lis", "]", "\n", "log_universal", "(", "Kep", "=", "self", ".", "keep_threshold", "[", "idx", "]", ",", "\n", "Visual", "=", "\" | \"", ".", "join", "(", "lis_out", ")", ")", "\n", "# write del_record to disk", "\n", "", "f", "=", "open", "(", "self", ".", "ser_fname", ",", "'a'", ")", "\n", "js", "=", "json", ".", "dumps", "(", "self", ".", "del_record", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "js", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "                ", "pass", "\n", "\n", "# return processed_words, self.del_record, self.compressions, self.full_sents, bag_pred_eval", "\n", "", "", "return", "bag_pred_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.del_under_threshold": [[113, 135], ["enumerate", "sent_stat_dict.items", "enumerate", "enumerate", "set().union", "compression_decoder.CompExecutor.del_record[].append", "set"], "methods", ["None"], ["", "def", "del_under_threshold", "(", "self", ")", ":", "\n", "        ", "for", "idx", ",", "sent_stat_dict", "in", "enumerate", "(", "self", ".", "compressions", ")", ":", "# idx is the num of sent", "\n", "            ", "for", "key", ",", "value", "in", "sent_stat_dict", ".", "items", "(", ")", ":", "\n", "                ", "p", "=", "value", "[", "'prob'", "]", "\n", "sel", "=", "value", "[", "'sel_idx'", "]", "\n", "word_sent", "=", "self", ".", "full_sents", "[", "idx", "]", "\n", "selected_words", "=", "[", "x", "for", "k", ",", "x", "in", "enumerate", "(", "word_sent", ")", "if", "k", "in", "sel", "]", "\n", "for", "th_idx", ",", "thres", "in", "enumerate", "(", "self", ".", "keep_threshold", ")", ":", "\n", "                    ", "if", "p", ">", "thres", ":", "\n", "                        ", "self", ".", "removal", "[", "th_idx", "]", "[", "idx", "]", "=", "set", "(", "value", "[", "'sel_idx'", "]", ")", ".", "union", "(", "self", ".", "removal", "[", "th_idx", "]", "[", "idx", "]", ")", "\n", "self", ".", "del_record", "[", "th_idx", "]", ".", "append", "(", "{", "'type'", ":", "value", "[", "'type'", "]", ",", "\n", "'len'", ":", "value", "[", "'len'", "]", ",", "\n", "'active'", ":", "1", ",", "\n", "'word'", ":", "selected_words", ",", "\n", "'ratio'", ":", "value", "[", "'ratio'", "]", ",", "'prob'", ":", "p", "}", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "consider", "[", "th_idx", "]", "[", "idx", "]", "+=", "[", "\n", "{", "'type'", ":", "value", "[", "'type'", "]", ",", "\n", "\"sel_word\"", ":", "selected_words", ",", "\n", "\"sel_idx\"", ":", "value", "[", "'sel_idx'", "]", ",", "\n", "\"len\"", ":", "value", "[", "'len'", "]", ",", "'ratio'", ":", "value", "[", "'ratio'", "]", ",", "\n", "'prob'", ":", "p", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.iterative_rep_del": [[139, 176], ["enumerate", "enumerate", "copy.deepcopy", "enumerate", "enumerate", "range", "list", "enumerate", "consider_of_sent.sort", "len", "collections.Counter", "list", "collections.Counter", "_tmp.append", "_tmp.append", "x.lower", "itertools.chain", "x.lower", "compression_decoder.CompExecutor.del_record[].append", "len", "len"], "methods", ["None"], ["", "", "", "", "", "def", "iterative_rep_del", "(", "self", ")", ":", "\n", "\n", "# apply self.removal", "\n", "        ", "curret_words", "=", "[", "copy", ".", "deepcopy", "(", "self", ".", "full_sents", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", "]", "\n", "for", "idx", ",", "rm", "in", "enumerate", "(", "self", ".", "removal", ")", ":", "# th first, then sent idx", "\n", "            ", "for", "sent_idx", ",", "rm_of_sent", "in", "enumerate", "(", "rm", ")", ":", "\n", "                ", "list_rm_of_sent", "=", "list", "(", "rm_of_sent", ")", "\n", "\n", "_tmp", "=", "[", "]", "\n", "for", "word_id", ",", "word", "in", "enumerate", "(", "curret_words", "[", "idx", "]", "[", "sent_idx", "]", ")", ":", "\n", "                    ", "if", "word_id", "not", "in", "list_rm_of_sent", ":", "\n", "                        ", "_tmp", ".", "append", "(", "word", ")", "\n", "", "else", ":", "\n", "                        ", "_tmp", ".", "append", "(", "sp_tok", "+", "word", "+", "sp_tok", ")", "\n", "", "", "curret_words", "[", "idx", "]", "[", "sent_idx", "]", "=", "_tmp", "\n", "\n", "", "", "for", "thidx", ",", "consider", "in", "enumerate", "(", "self", ".", "consider", ")", ":", "# List[th List[sent[ [dict, dict,..]]]", "\n", "            ", "for", "sent_idx", ",", "consider_of_sent", "in", "enumerate", "(", "consider", ")", ":", "\n", "                ", "consider_of_sent", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'len'", "]", ",", "reverse", "=", "True", ")", "\n", "for", "c", "in", "consider_of_sent", ":", "\n", "                    ", "c_words", "=", "c", "[", "'sel_word'", "]", "\n", "c_words", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "c_words", "]", "\n", "mini", "=", "Counter", "(", "c_words", ")", "\n", "current_full", "=", "list", "(", "itertools", ".", "chain", "(", "*", "curret_words", "[", "thidx", "]", ")", ")", "\n", "current_full", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "current_full", "]", "\n", "cnt", "=", "Counter", "(", "current_full", ")", "\n", "if", "(", "len", "(", "cnt", ")", "==", "len", "(", "cnt", "-", "mini", ")", ")", "and", "(", "cnt", "!=", "(", "cnt", "-", "mini", ")", ")", ":", "\n", "                        ", "self", ".", "del_record", "[", "thidx", "]", ".", "append", "(", "{", "'type'", ":", "c", "[", "'type'", "]", ",", "\n", "'len'", ":", "c", "[", "'len'", "]", ",", "\n", "'active'", ":", "0", ",", "\n", "'word'", ":", "c", "[", "'sel_word'", "]", ",", "\n", "'ratio'", ":", "c", "[", "'ratio'", "]", ",", "'prob'", ":", "c", "[", "'prob'", "]", "}", ")", "\n", "todo", "=", "c", "[", "'sel_idx'", "]", "\n", "for", "t", "in", "todo", ":", "\n", "                            ", "curret_words", "[", "thidx", "]", "[", "sent_idx", "]", "[", "t", "]", "=", "sp_tok_rep", "+", "curret_words", "[", "thidx", "]", "[", "sent_idx", "]", "[", "\n", "t", "]", "+", "sp_tok_rep", "\n", "", "", "", "", "", "return", "curret_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.read_sent_record_compressions": [[177, 213], ["enumerate", "sort_order.append", "compression_decoder.CompExecutor.full_sents.append", "enumerate", "collections.OrderedDict", "compression_decoder.CompExecutor.compressions.append", "len", "int", "sorted", "set", "range", "range", "stat_compression.items", "range", "len", "range", "len", "float", "float", "float", "len", "len", "len", "enumerate"], "methods", ["None"], ["", "def", "read_sent_record_compressions", "(", "self", ",", "sent_idxs", ")", ":", "\n", "# shared by all of the kepth", "\n", "        ", "sort_order", "=", "[", "]", "# the original order of sent_idx   # siez=t", "\n", "for", "j", ",", "sent_idx", "in", "enumerate", "(", "sent_idxs", ")", ":", "\n", "            ", "if", "sent_idx", "<", "0", ":", "\n", "                ", "continue", "\n", "", "if", "len", "(", "self", ".", "doc_list", ")", "<=", "sent_idx", ":", "\n", "                ", "continue", "# lead3 not enough", "\n", "", "sort_order", ".", "append", "(", "int", "(", "sent_idx", ")", ")", "\n", "pred_score", "=", "self", ".", "prediction_score", "[", "j", ",", ":", ",", ":", "]", "# max_comp, 2", "\n", "sp_meta", "=", "self", ".", "span_meta", "[", "sent_idx", "]", "\n", "word_sent", ":", "List", "[", "str", "]", "=", "self", ".", "doc_list", "[", "sent_idx", "]", "\n", "self", ".", "full_sents", ".", "append", "(", "word_sent", ")", "\n", "# Show all of the compression spans", "\n", "stat_compression", "=", "{", "}", "\n", "for", "comp_idx", ",", "comp_meta", "in", "enumerate", "(", "sp_meta", ")", ":", "\n", "                ", "p", "=", "pred_score", "[", "comp_idx", "]", "[", "1", "]", "\n", "node_type", ",", "sel_idx", ",", "rouge", ",", "ratio", "=", "comp_meta", "\n", "if", "node_type", "!=", "\"BASELINE\"", ":", "\n", "                    ", "selected_words", "=", "[", "x", "for", "idx", ",", "x", "in", "enumerate", "(", "word_sent", ")", "if", "idx", "in", "sel_idx", "]", "\n", "selected_words_str", "=", "\"_\"", ".", "join", "(", "selected_words", ")", "\n", "stat_compression", "[", "\"{}\"", ".", "format", "(", "selected_words_str", ")", "]", "=", "{", "\n", "\"prob\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "p", ")", ")", ",", "# float(\"{0:.2f}\".format())", "\n", "\"type\"", ":", "node_type", ",", "\n", "\"rouge\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "rouge", ")", ")", ",", "\n", "\"ratio\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "ratio", ")", ")", ",", "\n", "\"sel_idx\"", ":", "sel_idx", ",", "\n", "\"len\"", ":", "len", "(", "sel_idx", ")", "\n", "}", "\n", "", "", "stat_compression_order", "=", "OrderedDict", "(", "\n", "sorted", "(", "stat_compression", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", "[", "\"prob\"", "]", ",", "reverse", "=", "True", ")", ")", "# Python 3", "\n", "self", ".", "compressions", ".", "append", "(", "stat_compression_order", ")", "\n", "", "self", ".", "sort_order", "=", "sort_order", "\n", "self", ".", "removal", "=", "[", "[", "set", "(", ")", "for", "_", "in", "range", "(", "len", "(", "sort_order", ")", ")", "]", "for", "_", "in", "\n", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", "]", "# thresholds,t", "\n", "self", ".", "consider", "=", "[", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "sort_order", ")", ")", "]", "for", "_", "in", "range", "(", "len", "(", "self", ".", "keep_threshold", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.__init__": [[259, 335], ["super().__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "neusum.service.shared_asset.get_device", "neusum.nn_modules.enc.enc_compression.EncCompression", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "neusum.nn_modules.attention.NewAttention", "Elmo", "compression_decoder.CompressDecoder.elmo.get_output_dim", "text_field_embedder.get_output_dim", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "allennlp.modules.feedforward.FeedForward", "collections.OrderedDict", "compression_decoder.CompressDecoder.enc.get_output_dim", "compression_decoder.CompressDecoder.enc.get_output_dim", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation", "compression_decoder.CompressDecoder.enc.get_output_dim_unit", "compression_decoder.CompressDecoder.enc.get_output_dim_unit", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.get_output_dim_unit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.get_output_dim_unit"], ["    ", "def", "__init__", "(", "self", ",", "\n", "context_dim", ",", "\n", "dec_state_dim", ",", "\n", "enc_hid_dim", ",", "\n", "text_field_embedder", ",", "\n", "aggressive_compression", ":", "int", "=", "-", "1", ",", "\n", "keep_threshold", ":", "float", "=", "0.5", ",", "\n", "abs_board_file", "=", "\"/home/cc/exComp/board.txt\"", ",", "\n", "gather", "=", "'mean'", ",", "\n", "dropout", "=", "0.5", ",", "\n", "dropout_emb", "=", "0.2", ",", "\n", "valid_tmp_path", "=", "'/scratch/cluster/jcxu/exComp'", ",", "\n", "serilization_name", ":", "str", "=", "\"\"", ",", "\n", "vocab", "=", "None", ",", "\n", "elmo", ":", "bool", "=", "False", ",", "\n", "elmo_weight", ":", "str", "=", "\"elmo_2x1024_128_2048cnn_1xhighway_weights.hdf5\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_elmo", "=", "elmo", "\n", "self", ".", "serilization_name", "=", "serilization_name", "\n", "if", "elmo", ":", "\n", "            ", "from", "allennlp", ".", "modules", ".", "elmo", "import", "Elmo", ",", "batch_to_ids", "\n", "from", "allennlp", ".", "modules", ".", "seq2seq_encoders", "import", "Seq2SeqEncoder", ",", "PytorchSeq2SeqWrapper", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "options_file", "=", "\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x1024_128_2048cnn_1xhighway/elmo_2x1024_128_2048cnn_1xhighway_options.json\"", "\n", "weight_file", "=", "elmo_weight", "\n", "self", ".", "elmo", "=", "Elmo", "(", "options_file", ",", "weight_file", ",", "1", ",", "dropout", "=", "dropout_emb", ")", "\n", "# print(self.elmo.get_output_dim())", "\n", "# self.word_emb_dim = text_field_embedder.get_output_dim()", "\n", "# self._context_layer = PytorchSeq2SeqWrapper(", "\n", "#     torch.nn.LSTM(self.word_emb_dim + self.elmo.get_output_dim(), self.word_emb_dim,", "\n", "#                   batch_first=True, bidirectional=True))", "\n", "self", ".", "word_emb_dim", "=", "self", ".", "elmo", ".", "get_output_dim", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "word_emb_dim", "=", "text_field_embedder", ".", "get_output_dim", "(", ")", "\n", "\n", "", "self", ".", "XEloss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "self", ".", "device", "=", "get_device", "(", ")", "\n", "\n", "# self.rouge_metrics_compression = RougeStrEvaluation(name='cp', path_to_valid=valid_tmp_path,", "\n", "#                                                     writting_address=valid_tmp_path,", "\n", "#                                                     serilization_name=serilization_name)", "\n", "# self.rouge_metrics_compression_best_possible = RougeStrEvaluation(name='cp_ub', path_to_valid=valid_tmp_path,", "\n", "#                                                                   writting_address=valid_tmp_path,", "\n", "#                                                                   serilization_name=serilization_name)", "\n", "self", ".", "enc", "=", "EncCompression", "(", "inp_dim", "=", "self", ".", "word_emb_dim", ",", "hid_dim", "=", "enc_hid_dim", ",", "gather", "=", "gather", ")", "# TODO dropout", "\n", "\n", "self", ".", "aggressive_compression", "=", "aggressive_compression", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "attn", "=", "NewAttention", "(", "enc_dim", "=", "self", ".", "enc", ".", "get_output_dim", "(", ")", ",", "\n", "dec_dim", "=", "self", ".", "enc", ".", "get_output_dim_unit", "(", ")", "*", "2", "+", "dec_state_dim", ")", "\n", "\n", "self", ".", "concat_size", "=", "self", ".", "enc", ".", "get_output_dim", "(", ")", "+", "self", ".", "enc", ".", "get_output_dim_unit", "(", ")", "*", "2", "+", "dec_state_dim", "\n", "self", ".", "valid_tmp_path", "=", "valid_tmp_path", "\n", "if", "self", ".", "aggressive_compression", "<", "0", ":", "\n", "            ", "self", ".", "XELoss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ",", "ignore_index", "=", "-", "1", ")", "\n", "# self.nn_lin = torch.nn.Linear(self.concat_size, self.concat_size)", "\n", "# self.nn_lin2 = torch.nn.Linear(self.concat_size, 2)", "\n", "\n", "self", ".", "ff", "=", "FeedForward", "(", "input_dim", "=", "self", ".", "concat_size", ",", "num_layers", "=", "3", ",", "\n", "hidden_dims", "=", "[", "self", ".", "concat_size", ",", "self", ".", "concat_size", ",", "2", "]", ",", "\n", "activations", "=", "[", "torch", ".", "nn", ".", "Tanh", "(", ")", ",", "torch", ".", "nn", ".", "Tanh", "(", ")", ",", "lambda", "x", ":", "x", "]", ",", "\n", "dropout", "=", "dropout", "\n", ")", "\n", "# Keep thresold", "\n", "\n", "# self.keep_thres = list(np.arange(start=0.2, stop=0.6, step=0.075))", "\n", "self", ".", "keep_thres", "=", "[", "0.0", ",", "0.2", ",", "0.25", ",", "0.3", ",", "0.35", ",", "0.4", ",", "0.45", ",", "0.5", ",", "0.55", ",", "0.6", ",", "0.65", ",", "0.7", ",", "0.75", ",", "0.8", ",", "1.0", "]", "\n", "self", ".", "rouge_metrics_compression_dict", "=", "OrderedDict", "(", ")", "\n", "for", "thres", "in", "self", ".", "keep_thres", ":", "\n", "                ", "self", ".", "rouge_metrics_compression_dict", "[", "\"{}\"", ".", "format", "(", "thres", ")", "]", "=", "RougeStrEvaluation", "(", "name", "=", "'cp_{}'", ".", "format", "(", "thres", ")", ",", "\n", "path_to_valid", "=", "valid_tmp_path", ",", "\n", "writting_address", "=", "valid_tmp_path", ",", "\n", "serilization_name", "=", "serilization_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.encode_sent_and_span_paral": [[336, 371], ["compression_decoder.two_dim_index_select", "compression_decoder.CompressDecoder.size", "compression_decoder.two_dim_index_select", "compression_decoder.two_dim_index_select", "compression_decoder.CompressDecoder.enc.forward", "two_dim_index_select.tolist", "batch_to_ids().to", "compression_decoder.CompressDecoder.elmo", "compression_decoder.CompressDecoder._text_field_embedder", "sent_idx.size", "text_str_list.append", "compression_decoder.CompressDecoder.vocab.get_token_from_index", "batch_to_ids"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.two_dim_index_select", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.two_dim_index_select", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.two_dim_index_select", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "", "", "def", "encode_sent_and_span_paral", "(", "self", ",", "text", ",", "# batch, max_sent, max_word", "\n", "text_msk", ",", "# batch, max_sent, max_word", "\n", "span", ",", "# batch, max_sent_num, max_span_num, max_word", "\n", "sent_idx", "# batch size", "\n", ")", ":", "\n", "        ", "this_text", "=", "two_dim_index_select", "(", "text", "[", "'tokens'", "]", ",", "sent_idx", ")", "# batch, max_word", "\n", "from", "allennlp", ".", "modules", ".", "elmo", "import", "batch_to_ids", "\n", "if", "self", ".", "use_elmo", ":", "\n", "            ", "this_text_list", ":", "List", "=", "this_text", ".", "tolist", "(", ")", "\n", "text_str_list", "=", "[", "]", "\n", "for", "sample", "in", "this_text_list", ":", "\n", "                ", "s", "=", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "x", ")", "for", "x", "in", "sample", "]", "\n", "text_str_list", ".", "append", "(", "s", ")", "\n", "", "character_ids", "=", "batch_to_ids", "(", "text_str_list", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "this_context", "=", "self", ".", "elmo", "(", "character_ids", ")", "\n", "# print(this_context['elmo_representations'][0].size())", "\n", "this_context", "=", "this_context", "[", "'elmo_representations'", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "this_text", "=", "{", "'tokens'", ":", "this_text", "}", "\n", "this_context", "=", "self", ".", "_text_field_embedder", "(", "this_text", ")", "\n", "\n", "", "num_doc", ",", "max_word", ",", "inp_dim", "=", "this_context", ".", "size", "(", ")", "\n", "batch_size", "=", "sent_idx", ".", "size", "(", ")", "[", "0", "]", "\n", "assert", "batch_size", "==", "num_doc", "\n", "\n", "# text is the original text of the selected sentence.", "\n", "# this_context = two_dim_index_select(context, sent_idx)  # batch, max_word, hdim", "\n", "this_context_mask", "=", "two_dim_index_select", "(", "text_msk", ",", "sent_idx", ")", "# batch, max_word", "\n", "this_span", "=", "two_dim_index_select", "(", "span", ",", "sent_idx", ")", "# batch , nspan, max_word", "\n", "\n", "concat_rep_of_compression", ",", "span_msk", ",", "original_sent_rep", "=", "self", ".", "enc", ".", "forward", "(", "word_emb", "=", "this_context", ",", "\n", "word_emb_msk", "=", "this_context_mask", ",", "\n", "span", "=", "this_span", ")", "\n", "return", "concat_rep_of_compression", ",", "span_msk", ",", "original_sent_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.encode_sent_and_span": [[372, 387], ["compression_decoder.CompressDecoder._text_field_embedder", "compression_decoder.CompressDecoder.size", "context[].unsqueeze", "span[].unsqueeze", "text_msk[].unsqueeze", "compression_decoder.CompressDecoder.enc.forward", "span.size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "encode_sent_and_span", "(", "self", ",", "text", ",", "text_msk", ",", "span", ",", "batch_idx", ",", "sent_idx", ")", ":", "\n", "        ", "context", "=", "self", ".", "_text_field_embedder", "(", "text", ")", "\n", "num_doc", ",", "max_sent", ",", "max_word", ",", "inp_dim", "=", "context", ".", "size", "(", ")", "\n", "num_doc_", ",", "max_sent_", ",", "nspan", "=", "span", ".", "size", "(", ")", "[", "0", ":", "-", "1", "]", "\n", "assert", "num_doc", "==", "num_doc_", "\n", "assert", "max_sent", "==", "max_sent_", "\n", "this_context", "=", "context", "[", "batch_idx", ",", "sent_idx", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "this_span", "=", "span", "[", "batch_idx", ",", "sent_idx", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "this_context_mask", "=", "text_msk", "[", "batch_idx", ",", "sent_idx", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "flattened_enc", ",", "attn_dist", ",", "spans_rep", ",", "span_msk", ",", "score", "=", "self", ".", "enc", ".", "forward", "(", "word_emb", "=", "this_context", ",", "\n", "word_emb_msk", "=", "this_context_mask", ",", "\n", "span", "=", "this_span", ")", "\n", "return", "flattened_enc", ",", "spans_rep", ",", "span_msk", "\n", "# 1, hid*2      1, span num, hid        1, span num", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.indep_compression_judger": [[389, 399], ["reps.size", "compression_decoder.CompressDecoder.ff.forward", "random.random", "print"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "indep_compression_judger", "(", "self", ",", "reps", ")", ":", "\n", "# t, batch_size_, max_span_num,self.concat_size", "\n", "        ", "timestep", ",", "batch_size", ",", "max_span_num", ",", "dim", "=", "reps", ".", "size", "(", ")", "\n", "score", "=", "self", ".", "ff", ".", "forward", "(", "reps", ")", "\n", "# lin_out = self.nn_lin(reps)", "\n", "# activated = torch.sigmoid(lin_out)", "\n", "# score = self.nn_lin2(activated)", "\n", "if", "random", ".", "random", "(", ")", "<", "0.005", ":", "\n", "            ", "print", "(", "\"score: {}\"", ".", "format", "(", "score", "[", "0", "]", ")", ")", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.get_out_dim": [[400, 402], ["None"], "methods", ["None"], ["", "def", "get_out_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "concat_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.forward_parallel": [[403, 456], ["sent_decoder_states.size", "sent_decoder_outputs_logit.size", "span.size", "min", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "compression_decoder.CompressDecoder.relu().long", "compression_decoder.CompressDecoder.encode_sent_and_span_paral", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.unsqueeze().expand", "torch.cat.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "compression_decoder.CompressDecoder.attn.forward_one_step", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "compression_decoder.CompressDecoder.relu", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "logit.float", "span_msk_t.float"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.encode_sent_and_span_paral", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.forward_one_step"], ["", "def", "forward_parallel", "(", "self", ",", "sent_decoder_states", ",", "# t, batch, hdim", "\n", "sent_decoder_outputs_logit", ",", "# t, batch", "\n", "document_rep", ",", "# batch, hdim", "\n", "text", ",", "# batch, max_sent, max_word", "\n", "text_msk", ",", "# batch, max_sent, max_word", "\n", "span", ")", ":", "# batch, max_sent_num, max_span_num, max_word", "\n", "# Encode compression options given sent emission.", "\n", "# output scores, attn dist, ...", "\n", "        ", "t", ",", "batch_size", ",", "hdim", "=", "sent_decoder_states", ".", "size", "(", ")", "\n", "t_", ",", "batch_size_", "=", "sent_decoder_outputs_logit", ".", "size", "(", ")", "# invalid bits are -1", "\n", "batch", ",", "max_sent", ",", "max_span_num", ",", "max_word", "=", "span", ".", "size", "(", ")", "\n", "# assert t == t_", "\n", "t", "=", "min", "(", "t", ",", "t_", ")", "\n", "assert", "batch_size", "==", "batch", "==", "batch_size_", "\n", "if", "self", ".", "aggressive_compression", ">", "0", ":", "\n", "            ", "all_attn_dist", "=", "torch", ".", "zeros", "(", "(", "t", ",", "batch_size", ",", "max_span_num", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "all_scores", "=", "torch", ".", "ones", "(", "(", "t", ",", "batch_size", ",", "max_span_num", ")", ")", ".", "to", "(", "self", ".", "device", ")", "*", "-", "100", "\n", "", "else", ":", "\n", "            ", "all_attn_dist", "=", "None", "\n", "all_scores", "=", "None", "\n", "", "all_reps", "=", "torch", ".", "zeros", "(", "(", "t", ",", "batch_size_", ",", "max_span_num", ",", "self", ".", "concat_size", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "for", "timestep", "in", "range", "(", "t", ")", ":", "\n", "            ", "dec_state", "=", "sent_decoder_states", "[", "timestep", "]", "# batch, dim", "\n", "logit", "=", "sent_decoder_outputs_logit", "[", "timestep", "]", "# batch", "\n", "\n", "# valid_mask = (logit > 0)", "\n", "positive_logit", "=", "self", ".", "relu", "(", "logit", ".", "float", "(", ")", ")", ".", "long", "(", ")", "# turn -1 to 0", "\n", "\n", "span_t", ",", "span_msk_t", ",", "sent_t", "=", "self", ".", "encode_sent_and_span_paral", "(", "text", "=", "text", ",", "\n", "text_msk", "=", "text_msk", ",", "\n", "span", "=", "span", ",", "\n", "sent_idx", "=", "positive_logit", ")", "\n", "# sent_t : batch, sent_dim", "\n", "# span_t: batch, span_num, span_dim", "\n", "# span_msk_t: batch, span_num [[1,1,1,0,0,0],", "\n", "\n", "concated_rep_high_level", "=", "torch", ".", "cat", "(", "[", "dec_state", ",", "document_rep", ",", "sent_t", "]", ",", "dim", "=", "1", ")", "\n", "# batch, DIM", "\n", "if", "self", ".", "aggressive_compression", ">", "0", ":", "\n", "                ", "attn_dist", ",", "score", "=", "self", ".", "attn", ".", "forward_one_step", "(", "enc_state", "=", "span_t", ",", "\n", "dec_state", "=", "concated_rep_high_level", ",", "\n", "enc_mask", "=", "span_msk_t", ".", "float", "(", ")", ")", "\n", "# attn_dist: batch, span num", "\n", "# score:    batch, span num", "\n", "\n", "# concated_rep: batch, dim ==> batch, 1, dim ==> batch, max_span_num, dim", "\n", "", "expanded_concated_rep", "=", "concated_rep_high_level", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "(", "batch", ",", "max_span_num", ",", "-", "1", ")", ")", "\n", "all_reps", "[", "timestep", ",", ":", ",", ":", ",", ":", "]", "=", "torch", ".", "cat", "(", "[", "expanded_concated_rep", ",", "span_t", "]", ",", "dim", "=", "2", ")", "\n", "if", "self", ".", "aggressive_compression", ">", "0", ":", "\n", "                ", "all_attn_dist", "[", "timestep", ",", ":", ",", ":", "]", "=", "attn_dist", "\n", "all_scores", "[", "timestep", ",", ":", ",", ":", "]", "=", "score", "\n", "\n", "", "", "return", "all_attn_dist", ",", "all_scores", ",", "all_reps", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.comp_loss_inf_deletion": [[457, 505], ["torch.nn.functional.relu().long.size", "torch.nn.functional.relu().long.size", "scores.size", "span_rouge.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "scores.view", "goal_rouge_label.view.view.view", "weights.view.view.view", "compression_decoder.CompressDecoder.XELoss", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "compression_decoder.two_dim_index_select", "torch.gt().long", "torch.gt().long", "torch.gt().long", "torch.gt().long", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.gt"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.two_dim_index_select"], ["", "def", "comp_loss_inf_deletion", "(", "self", ",", "\n", "decoder_outputs_logit", ",", "# gold label!!!!", "\n", "# span_seq_label,  # batch, max sent num", "\n", "span_rouge", ",", "# batch, max sent num, max compression num", "\n", "scores", ",", "\n", "comp_rouge_ratio", ",", "\n", "loss_thres", "=", "1", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        :param decoder_outputs_logit:\n        :param span_rouge: [batch, max_sent, max_compression]\n        :param scores: [timestep, batch, max_compression, 2]\n        :param comp_rouge_ratio: [batch_size, max_sent, max_compression]\n        :return:\n        \"\"\"", "\n", "tim", ",", "bat", "=", "decoder_outputs_logit", ".", "size", "(", ")", "\n", "time", ",", "batch", ",", "max_span", ",", "_", "=", "scores", ".", "size", "(", ")", "\n", "batch_", ",", "sent_len", ",", "max_sp", "=", "span_rouge", ".", "size", "(", ")", "\n", "assert", "batch_", "==", "batch", "==", "bat", "\n", "assert", "time", "==", "tim", "\n", "assert", "max_sp", "==", "max_span", "\n", "goal_rouge_label", "=", "torch", ".", "ones", "(", "(", "tim", ",", "batch", ",", "max_span", ")", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "*", "(", "-", "1", ")", "\n", "weights", "=", "torch", ".", "ones", "(", "(", "tim", ",", "batch", ",", "max_span", ")", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "decoder_outputs_logit_mask", "=", "(", "decoder_outputs_logit", ">=", "0", ")", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "(", "time", ",", "batch", ",", "max_span", ")", ")", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "decoder_outputs_logit", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "decoder_outputs_logit", ")", ".", "long", "(", ")", "\n", "z", "=", "torch", ".", "zeros", "(", "(", "1", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "for", "tt", "in", "range", "(", "tim", ")", ":", "\n", "            ", "decoder_outputs_logit_t", "=", "decoder_outputs_logit", "[", "tt", "]", "\n", "out", "=", "two_dim_index_select", "(", "inp", "=", "comp_rouge_ratio", ",", "index", "=", "decoder_outputs_logit_t", ")", "\n", "label", "=", "torch", ".", "gt", "(", "out", ",", "loss_thres", ")", ".", "long", "(", ")", "\n", "\n", "mini_mask", "=", "torch", ".", "gt", "(", "out", ",", "0.01", ")", ".", "float", "(", ")", "\n", "\n", "# baseline_mask = 1 - torch.lt(torch.abs(out - 0.99), 0.01).float()  # baseline will be 0", "\n", "\n", "# weight = torch.max(input=-out + 0.5, other=z) + 1", "\n", "# weights[tt] = mini_mask * baseline_mask", "\n", "weights", "[", "tt", "]", "=", "mini_mask", "\n", "goal_rouge_label", "[", "tt", "]", "=", "label", "\n", "", "probs", "=", "scores", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "goal_rouge_label", "=", "goal_rouge_label", ".", "view", "(", "-", "1", ")", "\n", "weights", "=", "weights", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "self", ".", "XELoss", "(", "input", "=", "probs", ",", "target", "=", "goal_rouge_label", ")", "\n", "loss", "=", "loss", "*", "decoder_outputs_logit_mask", "*", "weights", "\n", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.comp_loss": [[506, 550], ["decoder_outputs_logit.size", "scores.size", "span_seq_label.long.long.size", "span_rouge.size", "span_seq_label.long.long.long", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "torch.from_numpy().to().long", "[].unsqueeze", "score_t.expand.expand.expand", "compression_decoder.CompressDecoder.XEloss", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ref_rouge_score.size", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.arange", "numpy.arange"], "methods", ["None"], ["", "def", "comp_loss", "(", "self", ",", "decoder_outputs_logit", ",", "# gold label!!!!", "\n", "scores", ",", "\n", "span_seq_label", ",", "# batch, max sent num", "\n", "span_rouge", ",", "# batch, max sent num, max compression num", "\n", "comp_rouge_ratio", "\n", ")", ":", "\n", "        ", "t", ",", "batch", "=", "decoder_outputs_logit", ".", "size", "(", ")", "\n", "t_", ",", "batch_", ",", "comp_num", "=", "scores", ".", "size", "(", ")", "\n", "b", ",", "max_sent", "=", "span_seq_label", ".", "size", "(", ")", "\n", "# b_, max_sen, max_comp_, _ = span.size()", "\n", "_b", ",", "max_sent_", ",", "max_comp", "=", "span_rouge", ".", "size", "(", ")", "\n", "assert", "batch", "==", "batch_", "==", "b", "==", "_b", "\n", "assert", "max_sent_", "==", "max_sent", "\n", "assert", "comp_num", "==", "max_comp", "\n", "span_seq_label", "=", "span_seq_label", ".", "long", "(", ")", "\n", "total_loss", "=", "torch", ".", "zeros", "(", "(", "t", ",", "b", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# print(decoder_outputs_logit)", "\n", "# print(span_seq_label)", "\n", "for", "timestep", "in", "range", "(", "t", ")", ":", "\n", "\n", "# this is the sent idx", "\n", "            ", "for", "batch_idx", "in", "range", "(", "b", ")", ":", "\n", "                ", "logit", "=", "decoder_outputs_logit", "[", "timestep", "]", "[", "batch_idx", "]", "\n", "# print(logit)", "\n", "# decoder_outputs_logit should be the gold label for sentence emission.", "\n", "# if it's 0 or -1, then we skip supervision.", "\n", "if", "logit", "<", "0", ":", "\n", "                    ", "continue", "\n", "", "ref_rouge_score", "=", "comp_rouge_ratio", "[", "batch_idx", "]", "[", "logit", "]", "\n", "num_of_compression", "=", "ref_rouge_score", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "_supervision_label_msk", "=", "(", "ref_rouge_score", ">", "0.98", ")", ".", "float", "(", ")", "\n", "label", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "num_of_compression", ")", ")", ".", "to", "(", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "score_t", "=", "scores", "[", "timestep", "]", "[", "batch_idx", "]", ".", "unsqueeze", "(", "0", ")", "# comp num", "\n", "score_t", "=", "score_t", ".", "expand", "(", "num_of_compression", ",", "-", "1", ")", "\n", "# label = span_seq_label[batch_idx][logit].unsqueeze(0)", "\n", "\n", "loss", "=", "self", ".", "XEloss", "(", "score_t", ",", "label", ")", "\n", "# print(loss)", "\n", "loss", "=", "_supervision_label_msk", "*", "loss", "\n", "total_loss", "[", "timestep", "]", "[", "batch_idx", "]", "=", "torch", ".", "sum", "(", "loss", ")", "\n", "# sent_msk_t = two_dim_index_select(sent_mask, logit)", "\n", "\n", "", "", "return", "torch", ".", "mean", "(", "total_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder._dec_compression_one_step": [[551, 619], ["set", "enumerate", "collections.OrderedDict", "enumerate", "enumerate", "zip", "range", "set.copy", "sorted", "set", "collections.OrderedDict.items", "list", "pred.sort", "visual_outputs.append", "meta_keep_ratio_word.append", "neusum.service.basic_service.easy_post_processing", "words_for_evaluation.append", "d.append", "len", "range", "stat_compression.items", "set", "float", "len", "float", "float", "float", "len", "set", "range", "enumerate", "set", "set", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing"], ["", "def", "_dec_compression_one_step", "(", "self", ",", "predict_compression", ",", "\n", "sp_meta", ",", "\n", "word_sent", ":", "List", "[", "str", "]", ",", "keep_threshold", ":", "List", "[", "float", "]", ",", "\n", "context", ":", "List", "[", "List", "[", "str", "]", "]", "=", "None", ")", ":", "\n", "\n", "        ", "full_set_len", "=", "set", "(", "range", "(", "len", "(", "word_sent", ")", ")", ")", "\n", "# max_comp, _ = predict_compression.size", "\n", "\n", "preds", "=", "[", "full_set_len", ".", "copy", "(", ")", "for", "_", "in", "range", "(", "len", "(", "keep_threshold", ")", ")", "]", "\n", "\n", "# Show all of the compression spans", "\n", "stat_compression", "=", "{", "}", "\n", "for", "comp_idx", ",", "comp_meta", "in", "enumerate", "(", "sp_meta", ")", ":", "\n", "            ", "p", "=", "predict_compression", "[", "comp_idx", "]", "[", "1", "]", "\n", "node_type", ",", "sel_idx", ",", "rouge", ",", "ratio", "=", "comp_meta", "\n", "if", "node_type", "!=", "\"BASELINE\"", ":", "\n", "                ", "selected_words", "=", "[", "x", "for", "idx", ",", "x", "in", "enumerate", "(", "word_sent", ")", "if", "idx", "in", "sel_idx", "]", "\n", "selected_words_str", "=", "\"_\"", ".", "join", "(", "selected_words", ")", "\n", "stat_compression", "[", "\"{}\"", ".", "format", "(", "selected_words_str", ")", "]", "=", "{", "\n", "\"prob\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "p", ")", ")", ",", "# float(\"{0:.2f}\".format())", "\n", "\"type\"", ":", "node_type", ",", "\n", "\"rouge\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "rouge", ")", ")", ",", "\n", "\"ratio\"", ":", "float", "(", "\"{0:.2f}\"", ".", "format", "(", "ratio", ")", ")", ",", "\n", "\"sel_idx\"", ":", "sel_idx", ",", "\n", "\"len\"", ":", "len", "(", "sel_idx", ")", "\n", "}", "\n", "", "", "stat_compression_order", "=", "OrderedDict", "(", "\n", "sorted", "(", "stat_compression", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", "[", "\"prob\"", "]", ",", "reverse", "=", "True", ")", ")", "# Python 3", "\n", "for", "idx", ",", "_keep_thres", "in", "enumerate", "(", "keep_threshold", ")", ":", "\n", "            ", "history", ":", "List", "[", "str", "]", "=", "context", "[", "idx", "]", "\n", "his_set", "=", "set", "(", "(", "\" \"", ".", "join", "(", "history", ")", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "for", "key", ",", "value", "in", "stat_compression_order", ".", "items", "(", ")", ":", "\n", "                ", "p", "=", "value", "[", "'prob'", "]", "\n", "sel_idx", "=", "value", "[", "'sel_idx'", "]", "\n", "sel_txt", "=", "set", "(", "[", "word_sent", "[", "x", "]", "for", "x", "in", "sel_idx", "]", ")", "\n", "if", "sel_txt", "-", "his_set", "==", "set", "(", ")", ":", "\n", "# print(\"Save big!\")", "\n", "# print(\"Context: {}\\tCandidate: {}\".format(his_set, sel_txt))", "\n", "                    ", "preds", "[", "idx", "]", "=", "preds", "[", "idx", "]", "-", "set", "(", "value", "[", "'sel_idx'", "]", ")", "\n", "continue", "\n", "", "if", "p", ">", "_keep_thres", ":", "\n", "                    ", "preds", "[", "idx", "]", "=", "preds", "[", "idx", "]", "-", "set", "(", "value", "[", "'sel_idx'", "]", ")", "\n", "\n", "", "", "", "preds", "=", "[", "list", "(", "x", ")", "for", "x", "in", "preds", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "            ", "pred", ".", "sort", "(", ")", "\n", "# Visual output", "\n", "", "visual_outputs", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "words_for_evaluation", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "meta_keep_ratio_word", "=", "[", "]", "\n", "\n", "for", "idx", ",", "compression", "in", "enumerate", "(", "preds", ")", ":", "\n", "            ", "output", "=", "[", "word_sent", "[", "jdx", "]", "if", "(", "jdx", "in", "compression", ")", "else", "'_'", "+", "word_sent", "[", "jdx", "]", "+", "'_'", "for", "jdx", "in", "\n", "range", "(", "len", "(", "word_sent", ")", ")", "]", "\n", "visual_outputs", ".", "append", "(", "\" \"", ".", "join", "(", "output", ")", ")", "\n", "\n", "words", "=", "[", "word_sent", "[", "x", "]", "for", "x", "in", "compression", "]", "\n", "meta_keep_ratio_word", ".", "append", "(", "float", "(", "len", "(", "words", ")", "/", "len", "(", "word_sent", ")", ")", ")", "\n", "# meta_kepp_ratio_span.append(1 - float(len(survery['type'][idx]) / len(sp_meta)))", "\n", "words", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "words", "=", "easy_post_processing", "(", "words", ")", "\n", "# print(words)", "\n", "words_for_evaluation", ".", "append", "(", "words", ")", "\n", "", "d", ":", "List", "[", "List", "]", "=", "[", "]", "\n", "for", "kep_th", ",", "vis", ",", "words_eva", ",", "keep_word_ratio", "in", "zip", "(", "keep_threshold", ",", "visual_outputs", ",", "words_for_evaluation", ",", "\n", "meta_keep_ratio_word", ")", ":", "\n", "            ", "d", ".", "append", "(", "[", "kep_th", ",", "vis", ",", "words_eva", ",", "keep_word_ratio", "]", ")", "\n", "", "return", "stat_compression_order", ",", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompressDecoder.decode_inf_deletion": [[620, 657], ["span_rouge.size", "span_prob.size", "torch.nn.functional.softmax().cpu().numpy", "torch.nn.functional.softmax().cpu().numpy", "torch.nn.functional.softmax().cpu().numpy", "torch.nn.functional.softmax().cpu().numpy", "sent_decoder_outputs_logit.size", "enumerate", "sent_decoder_outputs_logit.cpu", "compression_decoder.CompExecutor", "compression_decoder.CompExecutor.run", "range", "torch.nn.functional.softmax().cpu", "torch.nn.functional.softmax().cpu", "torch.nn.functional.softmax().cpu", "torch.nn.functional.softmax().cpu", "len", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.run"], ["", "def", "decode_inf_deletion", "(", "self", ",", "\n", "sent_decoder_outputs_logit", ",", "# time, batch", "\n", "span_prob", ",", "# time, batch, max_comp, 2", "\n", "metadata", ":", "List", ",", "\n", "span_meta", ":", "List", ",", "\n", "span_rouge", ",", "# batch, sent, max_comp", "\n", "keep_threshold", ":", "List", "[", "float", "]", "\n", ")", ":", "\n", "        ", "batch_size", ",", "max_sent_num", ",", "max_comp_num", "=", "span_rouge", ".", "size", "(", ")", "\n", "t", ",", "batsz", ",", "max_comp", ",", "_", "=", "span_prob", ".", "size", "(", ")", "\n", "span_score", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "span_prob", ",", "dim", "=", "3", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "timestep", ",", "batch", "=", "sent_decoder_outputs_logit", ".", "size", "(", ")", "\n", "sent_decoder_outputs_logit", "=", "sent_decoder_outputs_logit", ".", "cpu", "(", ")", ".", "data", "\n", "\n", "for", "idx", ",", "m", "in", "enumerate", "(", "metadata", ")", ":", "\n", "            ", "abs_s", "=", "[", "\" \"", ".", "join", "(", "s", ")", "for", "s", "in", "m", "[", "\"abs_list\"", "]", "]", "\n", "comp_exe", "=", "CompExecutor", "(", "span_meta", "=", "span_meta", "[", "idx", "]", ",", "\n", "sent_idxs", "=", "sent_decoder_outputs_logit", "[", ":", ",", "idx", "]", ",", "\n", "prediction_score", "=", "span_score", "[", ":", ",", "idx", ",", ":", ",", ":", "]", ",", "\n", "abs_str", "=", "abs_s", ",", "\n", "name", "=", "m", "[", "'name'", "]", ",", "\n", "doc_list", "=", "m", "[", "\"doc_list\"", "]", ",", "\n", "keep_threshold", "=", "keep_threshold", ",", "\n", "part", "=", "m", "[", "'name'", "]", ",", "ser_dir", "=", "self", ".", "valid_tmp_path", ",", "\n", "ser_fname", "=", "self", ".", "serilization_name", "\n", ")", "\n", "# processed_words, del_record, \\", "\n", "# compressions, full_sents, \\", "\n", "bag_pred_eval", "=", "comp_exe", ".", "run", "(", ")", "\n", "full_sents", ":", "List", "[", "List", "[", "str", "]", "]", "=", "comp_exe", ".", "full_sents", "\n", "# assemble full sents", "\n", "full_sents", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "full_sents", "]", "\n", "\n", "# visual to console", "\n", "for", "idx", "in", "range", "(", "len", "(", "keep_threshold", ")", ")", ":", "\n", "                ", "self", ".", "rouge_metrics_compression_dict", "[", "\"{}\"", ".", "format", "(", "keep_threshold", "[", "idx", "]", ")", "]", "(", "pred", "=", "bag_pred_eval", "[", "idx", "]", ",", "\n", "ref", "=", "[", "abs_s", "]", ",", "origin", "=", "full_sents", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.s": [[215, 217], ["print", "x.size"], "function", ["None"], ["", "", "def", "s", "(", "x", ")", ":", "\n", "    ", "print", "(", "x", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.two_dim_index_select": [[224, 253], ["torch.zeros_like", "torch.zeros_like", "enumerate", "torch.index_select", "torch.index_select", "inp.size", "inp.size", "len", "inp.view", "inp.size", "len", "inp.view", "inp.size", "inp.size", "len", "inp.view", "inp.size", "inp.size", "inp.size"], "function", ["None"], ["def", "two_dim_index_select", "(", "inp", ",", "index", ")", ":", "\n", "    ", "\"\"\"\n    retrieve [0,a] [1,b] [2,c]\n    :param inp: [batch, max_sent_num, ....]\n    :param index: len=batch [a,b,c,..]\n    :return:\n    \"\"\"", "\n", "batch_size", "=", "inp", ".", "size", "(", ")", "[", "0", "]", "\n", "max_sent_num", "=", "inp", ".", "size", "(", ")", "[", "1", "]", "\n", "if", "len", "(", "inp", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "        ", "comb_first_two_dim_inp", "=", "inp", ".", "view", "(", "batch_size", "*", "max_sent_num", ")", "\n", "", "elif", "len", "(", "inp", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "        ", "left_dim", "=", "inp", ".", "size", "(", ")", "[", "2", "]", "\n", "comb_first_two_dim_inp", "=", "inp", ".", "view", "(", "batch_size", "*", "max_sent_num", ",", "left_dim", ")", "\n", "", "elif", "len", "(", "inp", ".", "size", "(", ")", ")", "==", "4", ":", "\n", "        ", "left_dim", "=", "inp", ".", "size", "(", ")", "[", "2", "]", "\n", "sec_left_dim", "=", "inp", ".", "size", "(", ")", "[", "3", "]", "\n", "comb_first_two_dim_inp", "=", "inp", ".", "view", "(", "batch_size", "*", "max_sent_num", ",", "left_dim", ",", "sec_left_dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# print(index)", "\n", "", "local_index", "=", "torch", ".", "zeros_like", "(", "index", ")", "# TODO device issue", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "index", ")", ":", "\n", "        ", "local_index", "[", "idx", "]", "=", "idx", "*", "max_sent_num", "+", "i", "\n", "# print(index.size())", "\n", "# print(comb_first_two_dim_inp.size())", "\n", "# print(index)", "\n", "", "selected", "=", "torch", ".", "index_select", "(", "comb_first_two_dim_inp", ",", "dim", "=", "0", ",", "index", "=", "local_index", ")", "\n", "return", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.__init__": [[17, 47], ["torch.Module.__init__", "seq2idx_decoder.InputFeedRNNDecoder.build_rnn", "neusum.nn_modules.attention.NewAttention", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.build_rnn"], ["    ", "def", "__init__", "(", "self", ",", "device", ":", "torch", ".", "device", ",", "\n", "rnn_type", ":", "str", "=", "'lstm'", ",", "\n", "dec_hidden_size", ":", "int", "=", "100", ",", "\n", "dec_input_size", ":", "int", "=", "50", ",", "\n", "attn_type", ":", "str", "=", "'dot'", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "flexible_dec_step", ":", "bool", "=", "False", ",", "\n", "max_dec_steps", ":", "int", "=", "3", ",", "\n", "min_dec_steps", ":", "int", "=", "3", ",", "\n", "schedule_ratio_from_ground_truth", ":", "float", "=", "0.5", ",", "\n", "mult_orac_sampling", ":", "bool", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "_rnn_type", "=", "rnn_type", "\n", "self", ".", "_dec_input_size", "=", "dec_input_size", "\n", "self", ".", "_dec_hidden_size", "=", "dec_hidden_size", "\n", "\n", "self", ".", "_max_dec_steps", "=", "max_dec_steps", "\n", "self", ".", "rnn", "=", "self", ".", "build_rnn", "(", "self", ".", "_rnn_type", ",", "self", ".", "_dec_input_size", ",", "\n", "self", ".", "_dec_hidden_size", ",", "\n", ")", "\n", "self", ".", "attn", "=", "NewAttention", "(", "enc_dim", "=", "dec_input_size", ",", "dec_dim", "=", "dec_hidden_size", ",", "\n", "attn_type", "=", "attn_type", ")", "\n", "\n", "self", ".", "sampling", "=", "schedule_ratio_from_ground_truth", "\n", "self", ".", "mult_orac_sampling", "=", "mult_orac_sampling", "\n", "self", ".", "CELoss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "\n", "reduction", "=", "'none'", ")", "\n", "self", ".", "_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.comp_loss_with_oracle": [[48, 113], ["tgt.size", "rouge.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous.size", "enumerate", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.view", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "seq2idx_decoder.InputFeedRNNDecoder.CELoss", "tgt_mask.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.unsqueeze", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.expand().contiguous", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.view", "tgt.view().long", "seq2idx_decoder.InputFeedRNNDecoder.CELoss", "tgt_mask.view", "rouge.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.masked_select().view.view", "torch.masked_select().view.view", "torch.masked_select().view.view", "torch.masked_select().view.view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.size", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.expand", "tgt.view", "rouge.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous.unsqueeze().expand_as", "rouge.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous.view", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "random.randint", "rouge.unsqueeze().expand_as().contiguous.unsqueeze().expand_as().contiguous.unsqueeze"], "methods", ["None"], ["", "def", "comp_loss_with_oracle", "(", "self", ",", "_single_oracle_flag", ":", "bool", ",", "\n", "batch_size", ":", "int", ",", "\n", "decoder_outputs_prob", ":", "torch", ".", "Tensor", ",", "\n", "max_dec_steps", ":", "int", ",", "\n", "tgt", ":", "torch", ".", "Tensor", ",", "\n", "rouge", ":", "torch", ".", "Tensor", ",", "\n", "mult_orac_sampling", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        :param _single_oracle_flag:\n        :param batch_size:\n        :param decoder_outputs_prob: dec_time_step, batchsize, src_len\n        :param max_dec_steps:\n        :param tgt: batchsize, n_of_oracles, dec_time_step\n        :param tgt_mask: batchsize, n_of_oracles, dec_time_step\n        :param rouge: batchsize, n_of_oracles\n        :param mult_orac_sampling: True=only sample one from the bag;\n                    False=use all the oracles and average\n        :return:\n        \"\"\"", "\n", "batch_size_", ",", "n_oracles", ",", "dec_step", "=", "tgt", ".", "size", "(", ")", "\n", "batch_sizee_", ",", "n_ora", "=", "rouge", ".", "size", "(", ")", "\n", "assert", "batch_sizee_", "==", "batch_size_", "==", "batch_size", "\n", "\n", "if", "mult_orac_sampling", ":", "\n", "# sample one from all possible data uniformly", "\n", "            ", "lists", "=", "[", "[", "0", "]", "*", "n_ora", "for", "_", "in", "range", "(", "batch_size_", ")", "]", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "lists", ")", ":", "\n", "                ", "lists", "[", "idx", "]", "[", "random", ".", "randint", "(", "0", ",", "n_oracles", "-", "1", ")", "]", "=", "1", "\n", "# for rouge", "\n", "", "torch_rand_idx", "=", "torch", ".", "ByteTensor", "(", "lists", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# selected_rouge = torch.masked_select(rouge, torch_rand_idx)  # size: batchsz", "\n", "# for tgt, do broadcast first", "\n", "torch_rand_idx_bc", "=", "torch_rand_idx", ".", "unsqueeze", "(", "2", ")", "\n", "selected_tgt", "=", "torch", ".", "masked_select", "(", "tgt", ",", "torch_rand_idx_bc", ")", ".", "view", "(", "batch_size_", ",", "dec_step", ")", "# batch, step", "\n", "# comp loss", "\n", "batch_first_decoder_outputs_prob", "=", "torch", ".", "transpose", "(", "decoder_outputs_prob", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "flatten_prob", "=", "batch_first_decoder_outputs_prob", ".", "view", "(", "batch_size", "*", "max_dec_steps", ",", "-", "1", ")", "\n", "flatten_tgt", "=", "selected_tgt", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "loss_bf_msk", "=", "self", ".", "CELoss", "(", "flatten_prob", ",", "flatten_tgt", ")", "\n", "tgt_mask", "=", "(", "selected_tgt", "[", ":", ",", ":", "]", ">=", "0", ")", ".", "float", "(", ")", "\n", "flatten_tgt_msk", "=", "tgt_mask", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "loss_bf_msk", "*", "flatten_tgt_msk", "\n", "total_loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "", "else", ":", "\n", "            ", "batch_first_decoder_outputs_prob", "=", "torch", ".", "transpose", "(", "decoder_outputs_prob", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "batch_first_decoder_outputs_prob", "=", "batch_first_decoder_outputs_prob", ".", "unsqueeze", "(", "1", ")", "\n", "assert", "batch_first_decoder_outputs_prob", ".", "size", "(", ")", "[", "1", "]", "==", "1", "\n", "batch_first_decoder_outputs_prob", "=", "batch_first_decoder_outputs_prob", ".", "expand", "(", "batch_size", ",", "n_ora", ",", "dec_step", ",", "\n", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "flatten_prob", "=", "batch_first_decoder_outputs_prob", ".", "view", "(", "batch_size", "*", "max_dec_steps", "*", "n_ora", ",", "-", "1", ")", "\n", "flatten_tgt", "=", "tgt", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# batch, nora, step", "\n", "loss_bf_msk", "=", "self", ".", "CELoss", "(", "flatten_prob", ",", "flatten_tgt", ")", "\n", "\n", "tgt_mask", "=", "(", "tgt", "[", ":", ",", ":", ",", ":", "]", ">=", "0", ")", ".", "float", "(", ")", "\n", "flatten_tgt_msk", "=", "tgt_mask", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "loss_bf_msk", "*", "flatten_tgt_msk", "\n", "\n", "rouge", "=", "rouge", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "tgt", ")", ".", "contiguous", "(", ")", "\n", "rouge", "=", "rouge", ".", "view", "(", "-", "1", ")", "-", "torch", ".", "min", "(", "rouge", ")", "+", "0.1", "# baseline= 0.1", "\n", "rouge_mean", "=", "torch", ".", "mean", "(", "rouge", ")", "\n", "weighted_loss", "=", "loss", "*", "rouge", "*", "(", "1", "/", "rouge_mean", ")", "\n", "total_loss", "=", "torch", ".", "mean", "(", "weighted_loss", ")", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.compute_loss": [[114, 124], ["decoder_outputs_prob.size", "seq2idx_decoder.InputFeedRNNDecoder.comp_loss_with_oracle"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.comp_loss_with_oracle"], ["", "def", "compute_loss", "(", "self", ",", "decoder_outputs_prob", ",", "tgt", ",", "rouge", ")", ":", "\n", "        ", "max_dec_steps", ",", "batch_size", ",", "src_len", "=", "decoder_outputs_prob", ".", "size", "(", ")", "\n", "loss", "=", "self", ".", "comp_loss_with_oracle", "(", "False", ",", "batch_size", ",", "\n", "decoder_outputs_prob", ",", "\n", "max_dec_steps", ",", "\n", "tgt", ",", "\n", "rouge", ",", "\n", "mult_orac_sampling", "=", "self", ".", "mult_orac_sampling", "\n", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.forward": [[125, 226], ["context.size", "tgt.size", "last_state.size", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "seq2idx_decoder.InputFeedRNNDecoder.run_forward_one", "score.data.topk", "topi.squeeze.squeeze.squeeze", "neusum.service.nn_services.ptr_network_index_select", "tgt.size", "tgt.squeeze().long", "tgt[].long", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "tgt.size", "tgt[].long.size", "random.random", "tgt.squeeze", "best_tgt_as_ground_truth_mask.long"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.run_forward_one", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.nn_services.ptr_network_index_select"], ["", "def", "forward", "(", "self", ",", "\n", "context", ":", "torch", ".", "FloatTensor", ",", "# batch size, enc sent num, dim;", "\n", "context_mask", ",", "# batch size, enc sent num; [1,0]", "\n", "last_state", ":", "torch", ".", "FloatTensor", ",", "# batch size, dim;", "\n", "tgt", ":", "torch", ".", "LongTensor", "=", "None", ",", "# batch size, time step, num of samples", "\n", "# rouge=None,  # batch size, num of samples", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        :param context:\n        :param context_mask:\n        :param last_state:\n        :param tgt: If tgt is available (training mode), then use tgt sometimes as the input for next step.\n                    self.sampling=schedule_ratio_from_ground_truth\n        :return:\n        \"\"\"", "\n", "batch_size", ",", "src_len", ",", "encoder_dim", "=", "context", ".", "size", "(", ")", "\n", "batch_size_", ",", "num_oracles", ",", "max_dec_t", "=", "tgt", ".", "size", "(", ")", "\n", "_batch_size", ",", "hidden_size", "=", "last_state", ".", "size", "(", ")", "\n", "assert", "batch_size_", "==", "batch_size", "==", "_batch_size", "\n", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "max_dec_steps", "=", "tgt", ".", "size", "(", ")", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "max_dec_steps", "=", "self", ".", "_max_dec_steps", "\n", "\n", "", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "if", "tgt", ".", "size", "(", ")", "[", "1", "]", "==", "1", ":", "\n", "# _single_oracle_flag = True", "\n", "                ", "best_tgt_as_ground_truth", "=", "tgt", ".", "squeeze", "(", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "# _single_oracle_flag = False", "\n", "                ", "best_tgt_as_ground_truth", "=", "tgt", "[", ":", ",", "0", ",", ":", "]", ".", "long", "(", ")", "# already sorted", "\n", "", "assert", "len", "(", "best_tgt_as_ground_truth", ".", "size", "(", ")", ")", "==", "2", "\n", "best_tgt_as_ground_truth_mask", "=", "(", "best_tgt_as_ground_truth", "[", ":", ",", ":", "]", ">=", "0", ")", "\n", "", "else", ":", "\n", "            ", "best_tgt_as_ground_truth", "=", "None", "\n", "best_tgt_as_ground_truth_mask", "=", "None", "\n", "\n", "# assert", "\n", "", "if", "best_tgt_as_ground_truth", "is", "not", "None", ":", "\n", "            ", "best_tgt_as_ground_truth", "=", "best_tgt_as_ground_truth", "+", "(", "best_tgt_as_ground_truth_mask", ".", "long", "(", ")", "-", "1", ")", "*", "(", "-", "1", ")", "\n", "# invalid positions in best_tgt_as_ground_truth was -1. add (0-1)*(-1)=1 to make it -1+1 = 0 = <SOS>", "\n", "\n", "", "decoder_outputs_logit", "=", "torch", ".", "LongTensor", "(", "max_dec_steps", ",", "batch_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "decoder_outputs_prob", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "src_len", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_states_h", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "hidden_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_states_c", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "hidden_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "# decoder input now is the state", "\n", "decoder_input", "=", "last_state", "\n", "\n", "prev_attn", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "src_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "prev_attn", "[", ":", ",", "0", "]", "=", "1.", "# never attend to <SOS>!", "\n", "\n", "# all_attentions = torch.empty((max_dec_steps, batch_size, src_len),", "\n", "#                              device=self.device)", "\n", "\n", "_init_zero", "=", "torch", ".", "zeros_like", "(", "last_state", ",", "device", "=", "self", ".", "device", ")", "\n", "state", "=", "(", "_init_zero", ",", "_init_zero", ")", "# TODO use zero as h_0?", "\n", "\n", "for", "t", "in", "range", "(", "max_dec_steps", ")", ":", "\n", "            ", "state", ",", "prev_attn", ",", "attn", ",", "score", ",", "weighted_context", "=", "self", ".", "run_forward_one", "(", "inp", "=", "decoder_input", ",", "\n", "context", "=", "context", ",", "\n", "context_mask", "=", "context_mask", ",", "\n", "prev_state", "=", "state", ",", "\n", "prev_attn", "=", "prev_attn", ",", "\n", "timestep", "=", "t", "\n", ")", "\n", "decoder_states_h", "[", "t", "]", "=", "state", "[", "0", "]", "\n", "decoder_states_c", "[", "t", "]", "=", "state", "[", "1", "]", "\n", "decoder_outputs_prob", "[", "t", "]", "=", "score", "\n", "topv", ",", "topi", "=", "score", ".", "data", ".", "topk", "(", "1", ")", "\n", "topi", "=", "topi", ".", "squeeze", "(", ")", "\n", "# Record", "\n", "decoder_outputs_logit", "[", "t", "]", "=", "topi", "\n", "# all_attentions[t] = attn", "\n", "\n", "if", "best_tgt_as_ground_truth", "is", "not", "None", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", ">=", "self", ".", "sampling", ":", "\n", "                    ", "decoder_input_idx", "=", "topi", "\n", "", "else", ":", "\n", "                    ", "decoder_input_idx", "=", "best_tgt_as_ground_truth", "[", ":", ",", "t", "]", "\n", "", "", "else", ":", "\n", "                ", "decoder_input_idx", "=", "topi", "\n", "\n", "", "decoder_input", "=", "ptr_network_index_select", "(", "self", ".", "device", ",", "\n", "context", ",", "decoder_input_idx", ")", "\n", "# decoder_input = torch.index_select(context, 1, decoder_input_idx)", "\n", "\n", "", "output_dict", "=", "{", "}", "\n", "output_dict", "[", "\"decoder_outputs_logit\"", "]", "=", "decoder_outputs_logit", "\n", "output_dict", "[", "\"decoder_outputs_prob\"", "]", "=", "decoder_outputs_prob", "\n", "output_dict", "[", "\"best_tgt_as_ground_truth\"", "]", "=", "best_tgt_as_ground_truth", "\n", "output_dict", "[", "\"decoder_states\"", "]", "=", "[", "decoder_states_h", ",", "decoder_states_c", "]", "\n", "# output_dict['all_attentions'] = all_attentions", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.build_rnn": [[227, 235], ["torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell"], "methods", ["None"], ["", "def", "build_rnn", "(", "self", ",", "rnn_type", ":", "str", ",", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ")", ":", "\n", "        ", "if", "rnn_type", "==", "\"lstm\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ")", "\n", "", "elif", "rnn_type", "==", "'gru'", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "GRUCell", "(", "input_size", ",", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.seq2idx_decoder.InputFeedRNNDecoder.run_forward_one": [[236, 292], ["context.size", "seq2idx_decoder.InputFeedRNNDecoder.rnn", "seq2idx_decoder.InputFeedRNNDecoder._dropout", "seq2idx_decoder.InputFeedRNNDecoder.attn.forward_one_step", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "attention_distribution.unsqueeze", "type"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.forward_one_step"], ["", "", "def", "run_forward_one", "(", "self", ",", "\n", "inp", ":", "torch", ".", "FloatTensor", ",", "\n", "context", ":", "torch", ".", "FloatTensor", ",", "\n", "context_mask", ":", "torch", ".", "FloatTensor", ",", "\n", "prev_state", ":", "Tuple", "[", "torch", ".", "FloatTensor", ",", "torch", ".", "FloatTensor", "]", ",", "\n", "prev_attn", ":", "torch", ".", "FloatTensor", ",", "\n", "timestep", ":", "int", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        :param inp: batch x hidden_size\n        :param context: batch x src_len x hidden_size\n        :param context_mask: batch x src_len\n        :param prev_state: (batch x hidden), (batch x hidden)\n        :param prev_attn: batch x src_len: prev_attn is the average of previous attns\n        :return: current_raw_state,\n                prev_attn,\n                attention_distribution,\n                penaltied_score,\n                weighted_context: batch, dim. use attn distribution to reweight context\n        \"\"\"", "\n", "\n", "batch_size", ",", "src_len", ",", "hidden_size", "=", "context", ".", "size", "(", ")", "\n", "\n", "current_raw_state", "=", "self", ".", "rnn", "(", "inp", ",", "\n", "prev_state", ")", "# rnn_output: batch x hiddensize. hidden batch x hiddensize", "\n", "\n", "if", "self", ".", "_rnn_type", "==", "'lstm'", ":", "\n", "            ", "assert", "type", "(", "current_raw_state", ")", "==", "tuple", "\n", "current_state_h", "=", "current_raw_state", "[", "0", "]", "\n", "current_state_c", "=", "current_raw_state", "[", "1", "]", "\n", "", "elif", "self", ".", "_rnn_type", "==", "'gru'", ":", "\n", "            ", "current_state_h", "=", "current_raw_state", "\n", "current_state_c", "=", "current_raw_state", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "current_state_h", "=", "self", ".", "_dropout", "(", "current_state_h", ")", "\n", "attention_distribution", ",", "penaltied_score", "=", "self", ".", "attn", ".", "forward_one_step", "(", "context", ",", "\n", "current_state_h", ",", "\n", "context_mask", ",", "\n", "prev_attn", ")", "\n", "# attention_distribution: batch, context len", "\n", "# penaltied_score: batch, context len", "\n", "prev_attn", "=", "(", "prev_attn", "*", "(", "timestep", "+", "1", ")", "+", "attention_distribution", ")", "/", "(", "timestep", "+", "2", ")", "\n", "weighted_context", "=", "attention_distribution", ".", "unsqueeze", "(", "2", ")", "*", "context", "\n", "weighted_context", "=", "torch", ".", "sum", "(", "weighted_context", ",", "dim", "=", "1", ")", "\n", "# attn_h_weighted: batch, dim", "\n", "# a:               batch, src", "\n", "\n", "####", "\n", "# prob = torch.log(prob + 0.0000001)", "\n", "####", "\n", "return", "current_raw_state", ",", "prev_attn", ",", "attention_distribution", ",", "penaltied_score", ",", "weighted_context", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.__init__": [[10, 30], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "enc_dim", ":", "int", ",", "dec_dim", ":", "int", ",", "attn_type", "=", "\"dot\"", ")", ":", "\n", "        ", "super", "(", "NewAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "enc_dim", "=", "enc_dim", "\n", "self", ".", "dec_dim", "=", "dec_dim", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "# for prev_attn", "\n", "# self.gate_prev_attn = nn.Linear(dec_dim, 1", "\n", "#                                 )", "\n", "self", ".", "_relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "if", "self", ".", "attn_type", "==", "'general'", ":", "\n", "# self.W_squeeze = nn.Linear(dim * 2, dim, bias=True)", "\n", "            ", "self", ".", "W_h", "=", "nn", ".", "Linear", "(", "enc_dim", ",", "dec_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "W_s", "=", "nn", ".", "Linear", "(", "dec_dim", ",", "dec_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dec_dim", ",", "1", ")", "\n", "raise", "NotImplementedError", "\n", "", "elif", "self", ".", "attn_type", "==", "'dot'", ":", "\n", "            ", "self", ".", "W_h", "=", "nn", ".", "Linear", "(", "enc_dim", ",", "dec_dim", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.forward_one_step": [[31, 78], ["enc_state.size", "dec_state.size", "attention.NewAttention.masked_softmax", "attention.NewAttention._relu", "attention.NewAttention.W_h", "dec_state.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "score.squeeze.squeeze.squeeze", "attention.NewAttention.gate_prev_attn", "attention.NewAttention.W_h", "attention.NewAttention.W_s().unsqueeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attention.NewAttention.v", "score.squeeze.squeeze.squeeze", "attention.NewAttention.W_s"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.masked_softmax"], ["", "", "def", "forward_one_step", "(", "self", ",", "enc_state", ",", "dec_state", ",", "enc_mask", ",", "\n", "prev_attn", "=", "None", ",", "penalty_val", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n\n        :param enc_state: batch_size_, src_len, enc_dim\n        :param dec_state: batch_size, dec_dim\n        :param enc_mask: batch_size_, src_len\n        :param prev_attn:\n        :param penalty_val:\n        :return:\n        \"\"\"", "\n", "batch_size_", ",", "src_len", ",", "enc_dim", "=", "enc_state", ".", "size", "(", ")", "\n", "batch_size", ",", "dec_dim", "=", "dec_state", ".", "size", "(", ")", "\n", "assert", "batch_size", "==", "batch_size_", "\n", "assert", "enc_dim", "==", "self", ".", "enc_dim", "\n", "assert", "dec_dim", "==", "self", ".", "dec_dim", "\n", "if", "prev_attn", "is", "not", "None", ":", "\n", "# prev_attn", "\n", "            ", "gating_prev_attn", "=", "self", ".", "_relu", "(", "self", ".", "gate_prev_attn", "(", "dec_state", ")", ")", "# batch, 1", "\n", "gated_prev_attn", "=", "gating_prev_attn", "*", "prev_attn", "# batch, src_len <= a distribution", "\n", "\n", "", "if", "self", ".", "attn_type", "==", "'dot'", ":", "\n", "            ", "_middle", "=", "self", ".", "W_h", "(", "enc_state", ")", "# batch_size, src_len, dec_dim", "\n", "unsqueezed_dec_state", "=", "dec_state", ".", "unsqueeze", "(", "2", ")", "\n", "score", "=", "torch", ".", "matmul", "(", "_middle", ",", "unsqueezed_dec_state", ")", "# batch, src_len, 1", "\n", "score", "=", "score", ".", "squeeze", "(", "2", ")", "# batch, src", "\n", "", "elif", "self", ".", "attn_type", "==", "'general'", ":", "\n", "            ", "w_enc", "=", "self", ".", "W_h", "(", "enc_state", ")", "# batch, src, decdim", "\n", "w_dec", "=", "self", ".", "W_s", "(", "dec_state", ")", ".", "unsqueeze", "(", "1", ")", "# batch, [1], decdim", "\n", "_middle", "=", "torch", ".", "tanh", "(", "w_enc", "+", "w_dec", ")", "# batch, src, decdim", "\n", "score", "=", "self", ".", "v", "(", "_middle", ")", "\n", "score", "=", "score", ".", "squeeze", "(", "2", ")", "# batch, src", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# checkNaN(score)", "\n", "", "if", "prev_attn", "is", "not", "None", ":", "\n", "# print(enc_mask.size())", "\n", "            ", "penaltied_score", "=", "score", "+", "(", "enc_mask", "-", "1", ")", "*", "penalty_val", "-", "gated_prev_attn", "\n", "", "else", ":", "\n", "            ", "penaltied_score", "=", "score", "+", "(", "enc_mask", "-", "1", ")", "*", "penalty_val", "\n", "", "attention_distribution", "=", "self", ".", "masked_softmax", "(", "penaltied_score", ",", "enc_mask", ")", "\n", "# x = self.named_parameters()", "\n", "# for k, v in x:", "\n", "#     print(\"k: {}\\nv: {}\".format(k,v))", "\n", "# checkNaN(attention_distribution)", "\n", "return", "attention_distribution", ",", "penaltied_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.masked_softmax": [[79, 93], ["torch.softmax", "torch.softmax", "torch.softmax", "score.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "masked_softmax", "(", "score", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n\n        :param score: [batch_size, src_len]\n        :param mask:\n        :return:\n        \"\"\"", "\n", "\"\"\"Take softmax of e then apply enc_padding_mask and re-normalize\"\"\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "score", "=", "score", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "# mask = mask + 0.00001", "\n", "", "attn_dist", "=", "F", ".", "softmax", "(", "score", ",", "dim", "=", "1", ")", "# take softmax. shape (batch_size, attn_length)", "\n", "return", "attn_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.__init__": [[17, 63], ["torch.Module.__init__", "neusum.service.shared_asset.get_device", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "sent_dec.SentRNNDecoder.build_rnn", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "neusum.nn_modules.attention.NewAttention", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.build_rnn"], ["    ", "def", "__init__", "(", "self", ",", "\n", "rnn_type", ":", "str", "=", "'lstm'", ",", "\n", "dec_hidden_size", ":", "int", "=", "100", ",", "\n", "dec_input_size", ":", "int", "=", "50", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "fixed_dec_step", ":", "int", "=", "-", "1", ",", "\n", "max_dec_steps", ":", "int", "=", "2", ",", "\n", "min_dec_steps", ":", "int", "=", "2", ",", "\n", "schedule_ratio_from_ground_truth", ":", "float", "=", "0.5", ",", "\n", "dec_avd_trigram_rep", ":", "bool", "=", "True", ",", "\n", "mult_orac_sample_one", ":", "bool", "=", "True", ",", "\n", "abs_board_file", "=", "\"/home/cc/exComp/board.txt\"", ",", "\n", "valid_tmp_path", "=", "'/scratch/cluster/jcxu/exComp'", ",", "\n", "serilization_name", ":", "str", "=", "\"\"", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "get_device", "(", ")", "\n", "self", ".", "_rnn_type", "=", "rnn_type", "\n", "self", ".", "_dec_input_size", "=", "dec_input_size", "\n", "self", ".", "_dec_hidden_size", "=", "dec_hidden_size", "\n", "\n", "self", ".", "fixed_dec_step", "=", "fixed_dec_step", "\n", "if", "fixed_dec_step", "==", "-", "1", ":", "\n", "            ", "self", ".", "min_dec_steps", "=", "min_dec_steps", "\n", "self", ".", "max_dec_steps", "=", "max_dec_steps", "\n", "", "else", ":", "\n", "            ", "self", ".", "min_dec_steps", ",", "self", ".", "max_dec_steps", "=", "fixed_dec_step", ",", "fixed_dec_step", "\n", "", "self", ".", "schedule_ratio_from_ground_truth", "=", "schedule_ratio_from_ground_truth", "\n", "self", ".", "mult_orac_sample_one_as_gt", "=", "mult_orac_sample_one", "\n", "self", ".", "_dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "rnn", "=", "self", ".", "build_rnn", "(", "self", ".", "_rnn_type", ",", "self", ".", "_dec_input_size", ",", "\n", "self", ".", "_dec_hidden_size", ",", "\n", ")", "\n", "self", ".", "rnn_init_state_h", "=", "torch", ".", "nn", ".", "Linear", "(", "dec_hidden_size", ",", "dec_hidden_size", ")", "\n", "self", ".", "rnn_init_state_c", "=", "torch", ".", "nn", ".", "Linear", "(", "dec_hidden_size", ",", "dec_hidden_size", ")", "\n", "\n", "self", ".", "attn", "=", "NewAttention", "(", "enc_dim", "=", "dec_input_size", ",", "dec_dim", "=", "dec_hidden_size", "\n", ")", "\n", "self", ".", "CELoss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "\n", "reduction", "=", "'none'", ")", "# TODO", "\n", "self", ".", "rouge_metrics_sent", "=", "RougeStrEvaluation", "(", "name", "=", "'sent'", ",", "\n", "path_to_valid", "=", "valid_tmp_path", ",", "\n", "writting_address", "=", "valid_tmp_path", ",", "\n", "serilization_name", "=", "serilization_name", ")", "\n", "self", ".", "dec_avd_trigram_rep", "=", "dec_avd_trigram_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.get_output_dim": [[64, 66], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dec_hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.forward": [[67, 167], ["context.size", "last_state.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "sent_dec.SentRNNDecoder.rnn_init_state_h", "sent_dec.SentRNNDecoder.rnn_init_state_c", "range", "tgt.size", "sent_dec.SentRNNDecoder._forward_step", "score.data.topk", "topi.squeeze.squeeze.squeeze", "tgt.size", "tgt.squeeze().long", "tgt[].long", "len", "random.random", "neusum.service.nn_services.ptr_network_index_select", "sent_dec.SentRNNDecoder._dropout", "tgt.size", "tgt[].long.size", "random.random", "print", "print", "print", "print", "print", "print", "exit", "tgt.squeeze", "best_tgt_as_ground_truth_mask.long", "context.size", "decoder_input_idx.size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder._forward_step", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.nn_services.ptr_network_index_select"], ["", "def", "forward", "(", "self", ",", "context", ":", "torch", ".", "FloatTensor", ",", "# batch size, enc sent num, dim;", "\n", "context_mask", ",", "# batch size, enc sent num; [1,0]", "\n", "last_state", ":", "torch", ".", "FloatTensor", ",", "# batch size, dim;", "\n", "tgt", ":", "torch", ".", "LongTensor", "=", "None", "# batch size,  num of samples,time step", "\n", ")", ":", "\n", "        ", "batch_size", ",", "src_len", ",", "encoder_dim", "=", "context", ".", "size", "(", ")", "\n", "_batch_size", ",", "hidden_size", "=", "last_state", ".", "size", "(", ")", "\n", "assert", "batch_size", "==", "_batch_size", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "batch_size_", ",", "num_oracles", ",", "max_dec_t", "=", "tgt", ".", "size", "(", ")", "\n", "assert", "batch_size_", "==", "_batch_size", "\n", "\n", "", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "max_dec_steps", "=", "tgt", ".", "size", "(", ")", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "max_dec_steps", "=", "self", ".", "max_dec_steps", "\n", "\n", "", "if", "tgt", "is", "not", "None", ":", "\n", "            ", "if", "tgt", ".", "size", "(", ")", "[", "1", "]", "==", "1", ":", "\n", "# _single_oracle_flag = True", "\n", "                ", "best_tgt_as_ground_truth", "=", "tgt", ".", "squeeze", "(", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "# _single_oracle_flag = False", "\n", "                ", "best_tgt_as_ground_truth", "=", "tgt", "[", ":", ",", "0", ",", ":", "]", ".", "long", "(", ")", "# already sorted", "\n", "", "assert", "len", "(", "best_tgt_as_ground_truth", ".", "size", "(", ")", ")", "==", "2", "\n", "best_tgt_as_ground_truth_mask", "=", "(", "best_tgt_as_ground_truth", "[", ":", ",", ":", "]", ">=", "0", ")", "\n", "", "else", ":", "\n", "            ", "best_tgt_as_ground_truth", "=", "None", "\n", "best_tgt_as_ground_truth_mask", "=", "None", "\n", "\n", "# assert", "\n", "", "if", "best_tgt_as_ground_truth", "is", "not", "None", ":", "\n", "            ", "best_tgt_as_ground_truth", "=", "best_tgt_as_ground_truth", "+", "(", "best_tgt_as_ground_truth_mask", ".", "long", "(", ")", "-", "1", ")", "*", "(", "-", "1", ")", "\n", "# invalid positions in best_tgt_as_ground_truth was -1. add (0-1)*(-1)=1 to make it -1+1 = 0 = <SOS>", "\n", "\n", "", "decoder_outputs_logit", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_outputs_score", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "src_len", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_states_h", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "hidden_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_states_c", "=", "torch", ".", "zeros", "(", "size", "=", "(", "max_dec_steps", ",", "batch_size", ",", "hidden_size", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "decoder_input", "=", "last_state", "\n", "\n", "# prev_attn = torch.zeros((batch_size, src_len)).to(self.device)", "\n", "# prev_attn[:, 0] = 1.  # never attend to <SOS>!", "\n", "prev_attn", "=", "None", "\n", "# _init_unif = torch.rand_like(last_state, device=self.device) - 0.5", "\n", "# _init_unif = torch.zeros_like(last_state, device=self.device)", "\n", "_ones", "=", "torch", ".", "ones", "(", "(", "_batch_size", ",", "hidden_size", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "init_h", "=", "self", ".", "rnn_init_state_h", "(", "_ones", ")", "\n", "init_c", "=", "self", ".", "rnn_init_state_c", "(", "_ones", ")", "\n", "state", "=", "(", "init_h", ",", "init_c", ")", "# TODO use unif(+-0.5) as h_0?", "\n", "# print(max_dec_steps)", "\n", "for", "t", "in", "range", "(", "max_dec_steps", ")", ":", "\n", "            ", "state", ",", "prev_attn", ",", "attn", ",", "score", ",", "weighted_context", "=", "self", ".", "_forward_step", "(", "inp", "=", "decoder_input", ",", "\n", "context", "=", "context", ",", "\n", "context_mask", "=", "context_mask", ",", "\n", "prev_state", "=", "state", ",", "\n", "prev_attn", "=", "prev_attn", ",", "\n", "timestep", "=", "t", "\n", ")", "\n", "# checkNaN(attn)", "\n", "decoder_states_h", "[", "t", "]", "=", "state", "[", "0", "]", "\n", "decoder_states_c", "[", "t", "]", "=", "state", "[", "1", "]", "\n", "decoder_outputs_score", "[", "t", "]", "=", "score", "\n", "topv", ",", "topi", "=", "score", ".", "data", ".", "topk", "(", "1", ")", "\n", "topi", "=", "topi", ".", "squeeze", "(", "1", ")", "\n", "# Record", "\n", "decoder_outputs_logit", "[", "t", "]", "=", "topi", "\n", "# all_attentions[t] = attn", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.0005", ":", "\n", "# print(\"\\nAttn: {}\".format(attn[1]))", "\n", "# print(\"Score: {}\".format(score[1]))", "\n", "                ", "pass", "\n", "", "if", "best_tgt_as_ground_truth", "is", "not", "None", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "schedule_ratio_from_ground_truth", ":", "\n", "                    ", "decoder_input_idx", "=", "topi", "\n", "", "else", ":", "\n", "                    ", "decoder_input_idx", "=", "best_tgt_as_ground_truth", "[", ":", ",", "t", "]", "\n", "", "", "else", ":", "\n", "                ", "decoder_input_idx", "=", "topi", "\n", "", "try", ":", "\n", "                ", "decoder_input", "=", "ptr_network_index_select", "(", "self", ".", "device", ",", "\n", "context", ",", "decoder_input_idx", ")", "\n", "decoder_input", "=", "self", ".", "_dropout", "(", "decoder_input", ")", "\n", "", "except", "IndexError", ":", "\n", "                ", "print", "(", "'-'", "*", "50", ")", "\n", "print", "(", "batch_size_", ")", "\n", "print", "(", "context", ")", "\n", "print", "(", "decoder_input_idx", ")", "\n", "print", "(", "context", ".", "size", "(", ")", ")", "\n", "print", "(", "decoder_input_idx", ".", "size", "(", ")", ")", "\n", "exit", "(", ")", "\n", "# print(self.rnn.weight_hh)", "\n", "# checkNaN(decoder_outputs_logit)", "\n", "# checkNaN(decoder_outputs_score)", "\n", "", "", "return", "decoder_outputs_logit", ",", "decoder_outputs_score", ",", "[", "decoder_states_h", ",", "decoder_states_c", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder._forward_step": [[168, 210], ["context.size", "sent_dec.SentRNNDecoder.rnn", "sent_dec.SentRNNDecoder._dropout", "sent_dec.SentRNNDecoder.attn.forward_one_step", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "attention_distribution.unsqueeze", "type"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.forward_one_step"], ["", "def", "_forward_step", "(", "self", ",", "inp", ":", "torch", ".", "FloatTensor", ",", "\n", "context", ":", "torch", ".", "FloatTensor", ",", "\n", "context_mask", ":", "torch", ".", "FloatTensor", ",", "\n", "prev_state", ":", "Tuple", "[", "torch", ".", "FloatTensor", ",", "torch", ".", "FloatTensor", "]", ",", "\n", "prev_attn", ":", "torch", ".", "FloatTensor", ",", "\n", "timestep", ":", "int", ")", ":", "\n", "\n", "        ", "batch_size", ",", "src_len", ",", "hidden_size", "=", "context", ".", "size", "(", ")", "\n", "\n", "current_raw_state", "=", "self", ".", "rnn", "(", "inp", ",", "\n", "prev_state", ")", "# rnn_output: batch x hiddensize. hidden batch x hiddensize", "\n", "\n", "if", "self", ".", "_rnn_type", "==", "'lstm'", ":", "\n", "            ", "assert", "type", "(", "current_raw_state", ")", "==", "tuple", "\n", "current_state_h", "=", "current_raw_state", "[", "0", "]", "\n", "current_state_c", "=", "current_raw_state", "[", "1", "]", "\n", "", "elif", "self", ".", "_rnn_type", "==", "'gru'", ":", "\n", "            ", "current_state_h", "=", "current_raw_state", "\n", "current_state_c", "=", "current_raw_state", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "current_state_h", "=", "self", ".", "_dropout", "(", "current_state_h", ")", "\n", "attention_distribution", ",", "penaltied_score", "=", "self", ".", "attn", ".", "forward_one_step", "(", "context", ",", "\n", "current_state_h", ",", "\n", "context_mask", ",", "\n", "prev_attn", ")", "\n", "# attention_distribution: batch, context len", "\n", "# penaltied_score: batch, context len", "\n", "# prev_attn = (prev_attn * (timestep + 1) + attention_distribution) / \\", "\n", "#             (timestep + 2)", "\n", "weighted_context", "=", "attention_distribution", ".", "unsqueeze", "(", "2", ")", "*", "context", "\n", "weighted_context", "=", "torch", ".", "sum", "(", "weighted_context", ",", "dim", "=", "1", ")", "\n", "# attn_h_weighted: batch, dim", "\n", "# a:               batch, src", "\n", "# print(attention_distribution)", "\n", "####", "\n", "# prob = torch.log(prob + 0.0000001)", "\n", "####", "\n", "\n", "return", "current_raw_state", ",", "prev_attn", ",", "attention_distribution", ",", "penaltied_score", ",", "weighted_context", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.build_rnn": [[211, 219], ["torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.LSTMCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell", "torch.nn.GRUCell"], "methods", ["None"], ["", "def", "build_rnn", "(", "self", ",", "rnn_type", ":", "str", ",", "input_size", ":", "int", ",", "\n", "hidden_size", ":", "int", ")", ":", "\n", "        ", "if", "rnn_type", "==", "\"lstm\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ")", "\n", "", "elif", "rnn_type", "==", "'gru'", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "GRUCell", "(", "input_size", ",", "hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.extract_trigram_feature": [[220, 224], ["len", "range"], "methods", ["None"], ["", "", "def", "extract_trigram_feature", "(", "self", ",", "inp", ":", "List", "[", "str", "]", ")", ":", "\n", "        ", "l", "=", "len", "(", "inp", ")", "\n", "features", "=", "[", "\"_\"", ".", "join", "(", "[", "inp", "[", "i", "]", ",", "inp", "[", "i", "+", "1", "]", ",", "inp", "[", "i", "+", "2", "]", "]", ")", "for", "i", "in", "range", "(", "l", "-", "2", ")", "]", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder._decode_one_sample": [[225, 308], ["len", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "sent_dec.SentRNNDecoder.rouge_metrics_sent", "random.random", "neusum.service.basic_service.log_predict_example", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "sent_ids.append", "sent_words.append", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "torch.argmax().tolist", "print", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.log_predict_example"], ["", "def", "_decode_one_sample", "(", "self", ",", "name", ":", "str", ",", "abs_list", ":", "List", ",", "\n", "doc_list", ":", "List", ",", "\n", "sent_label", ",", "dec_prob_t", ",", "max_dec_step", ":", "int", ",", "min_dec_step", ":", "int", ")", ":", "\n", "        ", "_abs", "=", "[", "\" \"", ".", "join", "(", "a_list", ")", "for", "a_list", "in", "abs_list", "]", "\n", "\n", "total_sent_num", "=", "len", "(", "doc_list", ")", "\n", "dec_prob_t", "[", ":", ",", "total_sent_num", ":", "]", "=", "-", "100", "\n", "max_idx", "=", "torch", ".", "argmax", "(", "dec_prob_t", ",", "dim", "=", "1", ")", ".", "tolist", "(", ")", "# first choice. [time, source sentence]", "\n", "# dec_prob_t[:, 0] = -100", "\n", "# backup_max_idx = torch.argmax(dec_prob_t, dim=1).tolist()", "\n", "sent_ids", "=", "[", "]", "\n", "sent_words", "=", "[", "]", "\n", "_max_count", "=", "8", "\n", "t", "=", "0", "\n", "\n", "while", "(", "t", "<", "max_dec_step", ")", ":", "\n", "# propose", "\n", "\n", "            ", "trail_num", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "trail_num", "+=", "1", "\n", "sent_id", "=", "max_idx", "[", "t", "]", "\n", "\n", "proposed_words", "=", "doc_list", "[", "sent_id", "]", "\n", "if", "sent_id", "in", "sent_ids", ":", "\n", "                        ", "raise", "IndexError", "\n", "", "", "except", "IndexError", ":", "\n", "                    ", "if", "trail_num", "==", "_max_count", ":", "\n", "# print(dec_prob_t)", "\n", "                        ", "print", "(", "\"Not enough sents selected!\"", ")", "\n", "break", "\n", "", "dec_prob_t", "[", "t", ",", "sent_id", "]", "-=", "10", "\n", "max_idx", "=", "torch", ".", "argmax", "(", "dec_prob_t", ",", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "continue", "\n", "", "sent_ids", ".", "append", "(", "sent_id", ")", "\n", "sent_words", ".", "append", "(", "proposed_words", ")", "\n", "break", "\n", "", "t", "+=", "1", "\n", "#     if sent_id == 0:", "\n", "#         if t < min_dec_step:", "\n", "#             sent_id = backup_max_idx[t]", "\n", "#             # assert sent_id != 0", "\n", "#             if sent_id == 0:", "\n", "#                 break", "\n", "#         else:", "\n", "#             stop_flag = True", "\n", "#             sent_ids.append(sent_id)", "\n", "#             break", "\n", "#     else:", "\n", "#         try:", "\n", "#             proposed_words = doc_list[sent_id]", "\n", "#         except IndexError:", "\n", "#             # print(\"Invalid choice. {}\".format(sent_id))", "\n", "#             pass", "\n", "#             break", "\n", "#", "\n", "#         # if self.dec_avd_trigram_rep:", "\n", "#         #     proposed_features = self.extract_trigram_feature(proposed_words)", "\n", "#         #     trigram_flag = any([True for f in proposed_features if f in trigram_features])", "\n", "#         # else:", "\n", "#         #     trigram_flag = False", "\n", "#         if trigram_flag or (sent_id in sent_ids):  # no rep", "\n", "#             dec_prob_t[t, sent_id] -= 1", "\n", "#             backup_max_idx = torch.argmax(dec_prob_t, dim=1).tolist()", "\n", "#             sent_id = backup_max_idx[t]", "\n", "#         else:", "\n", "#             sent_ids.append(sent_id)", "\n", "#             sent_words.append(proposed_words)", "\n", "#             # trigram_features += proposed_features", "\n", "#             break", "\n", "# t += 1", "\n", "# _pred = [\" \".join(doc_list[i]) for i in sent_ids]", "\n", "", "_pred", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "sent_words", "]", "\n", "# print to screen", "\n", "if", "random", ".", "random", "(", ")", "<", "0.01", ":", "\n", "# print(\"sent_ids: {}\".format(sent_ids))", "\n", "# print(\"sent_lab: {}\".format(sent_label))", "\n", "            ", "log_predict_example", "(", "name", ",", "sent_ids", ",", "sent_label", ",", "_pred", ",", "_abs", ")", "\n", "# sent_ids.append(0)", "\n", "# Add to globad evaluation bag", "\n", "", "self", ".", "rouge_metrics_sent", "(", "pred", "=", "_pred", ",", "ref", "=", "[", "_abs", "]", ")", "\n", "return", "_pred", ",", "_abs", ",", "sent_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.decode": [[309, 351], ["decoder_outputs_prob.size", "len", "enumerate", "decoder_outputs_prob.cpu", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "sent_dec.SentRNNDecoder._decode_one_sample", "range", "sent_label[].cpu", "sent_label[].tolist", "len", "int"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder._decode_one_sample"], ["", "def", "decode", "(", "self", ",", "decoder_outputs_prob", ",", "metadata", ",", "sent_label", "=", "None", ")", ":", "\n", "\n", "        ", "batch", ",", "timestep", ",", "sent_num", "=", "decoder_outputs_prob", ".", "size", "(", ")", "\n", "batch_", "=", "len", "(", "metadata", ")", "\n", "part", "=", "metadata", "[", "0", "]", "[", "'part'", "]", "\n", "assert", "batch", "==", "batch_", "\n", "if", "part", "==", "'cnn'", ":", "\n", "# max_dec_steps, min_dec_steps = self.max_dec_steps - 1, self.min_dec_steps - 1", "\n", "            ", "max_dec_steps", ",", "min_dec_steps", "=", "self", ".", "max_dec_steps", ",", "self", ".", "min_dec_steps", "\n", "", "elif", "part", "==", "'dm'", ":", "\n", "            ", "max_dec_steps", ",", "min_dec_steps", "=", "self", ".", "max_dec_steps", ",", "self", ".", "min_dec_steps", "\n", "", "elif", "part", "==", "'nyt'", ":", "\n", "            ", "max_dec_steps", ",", "min_dec_steps", "=", "self", ".", "max_dec_steps", ",", "self", ".", "min_dec_steps", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "dec_prob", "=", "decoder_outputs_prob", ".", "cpu", "(", ")", ".", "data", "\n", "batch_sent_decoding_result", "=", "torch", ".", "ones", "(", "(", "max_dec_steps", ",", "batch_", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "*", "-", "1", "\n", "if", "sent_label", "is", "not", "None", ":", "\n", "            ", "sent_label", "=", "sent_label", "[", ":", ",", "0", ",", ":", "]", ".", "cpu", "(", ")", ".", "data", "\n", "\n", "", "for", "idx", ",", "m", "in", "enumerate", "(", "metadata", ")", ":", "\n", "# _pred = []", "\n", "            ", "name", "=", "m", "[", "'name'", "]", "\n", "part", "=", "m", "[", "'part'", "]", "\n", "dec_prob_t", "=", "dec_prob", "[", "idx", "]", "# timestep, source len", "\n", "if", "sent_label", "is", "not", "None", ":", "\n", "                ", "label", "=", "sent_label", "[", "idx", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "[", "]", "\n", "\n", "", "_pred", ",", "_abs", ",", "sent_ids", "=", "self", ".", "_decode_one_sample", "(", "name", "=", "name", ",", "\n", "abs_list", "=", "m", "[", "\"abs_list\"", "]", ",", "doc_list", "=", "m", "[", "\"doc_list\"", "]", ",", "\n", "sent_label", "=", "label", ",", "\n", "dec_prob_t", "=", "dec_prob_t", ",", "max_dec_step", "=", "max_dec_steps", ",", "\n", "min_dec_step", "=", "min_dec_steps", ")", "\n", "\n", "# record", "\n", "for", "wt_step", "in", "range", "(", "len", "(", "sent_ids", ")", ")", ":", "\n", "                ", "batch_sent_decoding_result", "[", "wt_step", ",", "idx", "]", "=", "int", "(", "sent_ids", "[", "wt_step", "]", ")", "\n", "\n", "# print(batch_sent_decoding_result)", "\n", "", "", "return", "batch_sent_decoding_result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.sent_dec.SentRNNDecoder.comp_loss": [[352, 410], ["decoder_outputs_prob.contiguous.contiguous.size", "oracles.size", "rouge.view.view.size", "decoder_outputs_prob.contiguous.contiguous.contiguous", "enumerate", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.ByteTensor().to.unsqueeze", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "decoder_outputs_prob.contiguous.contiguous.view", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "torch.masked_select().view.view().long", "sent_dec.SentRNNDecoder.CELoss", "tgt_mask.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "decoder_outputs_prob.contiguous.contiguous.unsqueeze", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.expand().contiguous", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.view", "oracles.contiguous().view().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "torch.nn.functional.relu().long", "sent_dec.SentRNNDecoder.CELoss", "tgt_mask.view", "rouge.view.view.unsqueeze().expand_as().contiguous", "rouge.view.view.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "print", "print", "range", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.ByteTensor", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select().view.view", "torch.masked_select().view.view", "torch.masked_select().view.view", "torch.masked_select().view.view", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.size", "batch_first_decoder_outputs_prob.expand().contiguous.expand().contiguous.expand", "oracles.contiguous().view", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "rouge.view.view.unsqueeze().expand_as", "random.randint", "torch.nn.functional.relu().long.float", "torch.nn.functional.relu().long.float", "torch.nn.functional.relu().long.float", "torch.nn.functional.relu().long.float", "oracles.contiguous", "rouge.view.view.unsqueeze"], "methods", ["None"], ["", "def", "comp_loss", "(", "self", ",", "\n", "decoder_outputs_prob", ":", "torch", ".", "Tensor", ",", "# batch, timestep, prob_over_source", "\n", "oracles", ":", "torch", ".", "Tensor", ",", "# batchsize, n_of_oracles, dec_time_step", "\n", "rouge", ":", "torch", ".", "Tensor", ",", "# batchsize, n_of_oracles", "\n", ")", ":", "\n", "        ", "batch", ",", "time", ",", "_", "=", "decoder_outputs_prob", ".", "size", "(", ")", "\n", "batch_size_", ",", "n_oracles", ",", "dec_step", "=", "oracles", ".", "size", "(", ")", "# invalid position = -1", "\n", "batch_sizee_", ",", "n_ora", "=", "rouge", ".", "size", "(", ")", "# invalid position = 0", "\n", "assert", "batch_sizee_", "==", "batch_size_", "==", "batch", "\n", "assert", "time", "==", "dec_step", "\n", "try", ":", "\n", "            ", "assert", "n_ora", "==", "n_oracles", "\n", "", "except", "AssertionError", ":", "\n", "            ", "print", "(", "oracles", ")", "\n", "print", "(", "rouge", ")", "\n", "", "decoder_outputs_prob", "=", "decoder_outputs_prob", ".", "contiguous", "(", ")", "\n", "# batch_first_decoder_outputs_prob = torch.transpose(decoder_outputs_prob, 0, 1).contiguous()", "\n", "\n", "if", "self", ".", "mult_orac_sample_one_as_gt", ":", "\n", "            ", "lists", "=", "[", "[", "0", "]", "*", "n_ora", "for", "_", "in", "range", "(", "batch_size_", ")", "]", "\n", "for", "idx", ",", "_", "in", "enumerate", "(", "lists", ")", ":", "\n", "                ", "lists", "[", "idx", "]", "[", "random", ".", "randint", "(", "0", ",", "n_oracles", "-", "1", ")", "]", "=", "1", "\n", "", "torch_rand_idx", "=", "torch", ".", "ByteTensor", "(", "lists", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "torch_rand_idx_bc", "=", "torch_rand_idx", ".", "unsqueeze", "(", "2", ")", "\n", "selected_tgt", "=", "torch", ".", "masked_select", "(", "oracles", ",", "torch_rand_idx_bc", ")", ".", "view", "(", "batch_size_", ",", "dec_step", ")", "# batch, step", "\n", "flatten_prob", "=", "decoder_outputs_prob", ".", "view", "(", "batch_size_", "*", "dec_step", ",", "-", "1", ")", "\n", "flatten_tgt", "=", "selected_tgt", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "loss_bf_msk", "=", "self", ".", "CELoss", "(", "flatten_prob", ",", "flatten_tgt", ")", "\n", "tgt_mask", "=", "(", "selected_tgt", "[", ":", ",", ":", "]", ">=", "0", ")", ".", "float", "(", ")", "\n", "flatten_tgt_msk", "=", "tgt_mask", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "loss_bf_msk", "*", "flatten_tgt_msk", "\n", "total_loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "return", "total_loss", ",", "total_loss", "\n", "", "else", ":", "\n", "            ", "batch_first_decoder_outputs_prob", "=", "decoder_outputs_prob", ".", "unsqueeze", "(", "1", ")", "\n", "assert", "batch_first_decoder_outputs_prob", ".", "size", "(", ")", "[", "1", "]", "==", "1", "\n", "batch_first_decoder_outputs_prob", "=", "batch_first_decoder_outputs_prob", ".", "expand", "(", "batch_size_", ",", "n_ora", ",", "dec_step", ",", "\n", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "flatten_prob", "=", "batch_first_decoder_outputs_prob", ".", "view", "(", "batch_size_", "*", "dec_step", "*", "n_ora", ",", "-", "1", ")", "\n", "flatten_tgt", "=", "oracles", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# batch, nora, step", "\n", "# print(flatten_tgt)", "\n", "# TODO why do i need this....", "\n", "flatten_tgt", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "flatten_tgt", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "# print(flatten_prob)", "\n", "loss_bf_msk", "=", "self", ".", "CELoss", "(", "flatten_prob", ",", "flatten_tgt", ")", "\n", "# print(loss_bf_msk)", "\n", "tgt_mask", "=", "(", "oracles", "[", ":", ",", ":", ",", ":", "]", ">=", "0", ")", ".", "float", "(", ")", "\n", "flatten_tgt_msk", "=", "tgt_mask", ".", "view", "(", "-", "1", ")", "\n", "loss_ori", "=", "loss_bf_msk", "*", "flatten_tgt_msk", "\n", "rouge", "=", "rouge", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "oracles", ")", ".", "contiguous", "(", ")", "\n", "rouge", "=", "(", "rouge", ".", "view", "(", "-", "1", ")", ")", "# baseline= 0.1", "\n", "# rouge_mean = torch.mean(rouge)", "\n", "# weighted_loss = loss * rouge * (1 / rouge_mean)", "\n", "weighted_loss", "=", "loss_ori", "*", "rouge", "\n", "# print(\"=\"*100)", "\n", "loss_ori", "=", "torch", ".", "mean", "(", "loss_ori", ")", "\n", "total_loss", "=", "torch", ".", "mean", "(", "weighted_loss", ")", "\n", "return", "total_loss", ",", "loss_ori", "# use original loss!!!", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.SelfAttnSpanExtractor.SelfAttnExtractor.__init__": [[38, 47], ["torch.Module.__init__", "SelfAttnSpanExtractor.clones", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.clones"], ["    ", "def", "__init__", "(", "self", ",", "h", "=", "8", ",", "d_model", "=", "512", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "4", ")", "\n", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.SelfAttnSpanExtractor.SelfAttnExtractor.forward": [[48, 95], ["sequence_tensor.size", "span_indices.size", "SelfAttnSpanExtractor.convert_span_indices_to_mask", "query.size", "scores.masked_fill.masked_fill.unsqueeze", "scores.masked_fill.masked_fill.expand().contiguous", "scores.masked_fill.masked_fill.view", "print", "spans.view.view.view", "spans.view.view.expand", "spans.view.view.expand", "spans.view.view.view", "print", "print", "print", "scores.masked_fill.masked_fill.masked_fill", "print", "print", "l().view().transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill.size", "spans.view.view.size", "scores.masked_fill.masked_fill.size", "zip", "key.transpose", "scores.masked_fill.masked_fill.expand", "l().view", "l"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.SelfAttnSpanExtractor.convert_span_indices_to_mask"], ["", "def", "forward", "(", "self", ",", "sequence_tensor", ":", "torch", ".", "FloatTensor", ",", "\n", "span_indices", ":", "torch", ".", "LongTensor", ",", "\n", "# sequence_mask: torch.LongTensor = None,", "\n", "span_indices_mask", ":", "torch", ".", "LongTensor", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        convert span_indices to masks. eg. [1,4] (inclusive start, exclusive end) = mask [0 1 1 1 0 0 0 0]\n\n        multi-head self attention to aggragate rep {batch, span_num, t, dim} => {batch, span_num, dim}\n        for those invalid span_indices, span is set to be [0, t]\n\n        :param sequence_tensor: torch.FloatTensor {batch, t, d_model}\n        :param span_indices: torch.LongTensor {batch, span_num, 2}\n        # :param sequence_mask: torch.LongTensor {batch, t} [1,0]\n        :param span_indices_mask: torch.LongTensor {batch, span_num} [1,0]\n        :return:\n        \"\"\"", "\n", "\n", "nbatch", ",", "t", ",", "dim", "=", "sequence_tensor", ".", "size", "(", ")", "\n", "nb", ",", "span_num", ",", "_", "=", "span_indices", ".", "size", "(", ")", "\n", "spans", "=", "convert_span_indices_to_mask", "(", "span_indices", ",", "max_len", "=", "t", ")", "# batch, span_num, t [111110000, 00011000,]", "\n", "# 1) Do all the linear projections in batch from d_model => h x d_k", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatch", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "sequence_tensor", ",", "sequence_tensor", ",", "sequence_tensor", ")", ")", "]", "\n", "# nbatch, t, d_model = > nbatch, t, h, d_k => nbatch, h, t, d_k", "\n", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "# batch, h, t, t", "\n", "scores", "=", "scores", ".", "unsqueeze", "(", "1", ")", "\n", "scores", "=", "scores", ".", "expand", "(", "(", "nbatch", ",", "span_num", ",", "self", ".", "h", ",", "t", ",", "t", ")", ")", ".", "contiguous", "(", ")", "\n", "scores", "=", "scores", ".", "view", "(", "(", "nbatch", "*", "span_num", ",", "self", ".", "h", ",", "t", ",", "t", ")", ")", "\n", "print", "(", "scores", ".", "size", "(", ")", ")", "\n", "\n", "spans", "=", "spans", ".", "view", "(", "(", "nbatch", ",", "span_num", ",", "1", ",", "t", ",", "1", ")", ")", "\n", "spans", "=", "spans", ".", "expand", "(", "(", "nbatch", ",", "span_num", ",", "self", ".", "h", ",", "t", ",", "1", ")", ")", "\n", "spans", "=", "spans", ".", "expand", "(", "(", "nbatch", ",", "span_num", ",", "self", ".", "h", ",", "t", ",", "t", ")", ")", "\n", "spans", "=", "spans", ".", "view", "(", "(", "nbatch", "*", "span_num", ",", "self", ".", "h", ",", "t", ",", "t", ")", ")", "\n", "# print(scores[0])", "\n", "# print(spans_for_masking[0])", "\n", "# print(scores[2])", "\n", "# print(spans_for_masking[2])", "\n", "print", "(", "spans", ".", "size", "(", ")", ")", "\n", "print", "(", "spans", "[", "0", ",", "0", "]", ")", "\n", "print", "(", "scores", "[", "0", ",", "0", "]", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "spans", "==", "0", ",", "-", "1e9", ")", "\n", "print", "(", "scores", "[", "0", ",", "0", "]", ")", "\n", "print", "(", "scores", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.SelfAttnSpanExtractor.clones": [[9, 12], ["torch.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["def", "clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "\"Produce N identical layers.\"", "\n", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "_", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.SelfAttnSpanExtractor.convert_span_indices_to_mask": [[17, 35], ["numpy.zeros", "range", "torch.from_numpy", "torch.from_numpy", "span_indices.size", "range"], "function", ["None"], ["def", "convert_span_indices_to_mask", "(", "span_indices", ",", "span_indices_mask", ":", "torch", ".", "LongTensor", "=", "None", ",", "max_len", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n\n    :param span_indices: torch.LongTensor {batch, span_num, 2} [3,5] [-1,-1]\n    :param span_indices_mask:  torch.LongTensor {batch, span_num} [1,0]\n    :return: context_mask {batch, span_num, t} [ 0000111110000, 1111100000,....]\n    \"\"\"", "\n", "batch_size", ",", "span_num", "=", "span_indices", ".", "size", "(", ")", "[", "0", ":", "2", "]", "\n", "# if span_indices_mask is None:", "\n", "#     virtual_mask = torch.ge(span_indices[:, :, 0], 0).long()", "\n", "mask", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "span_num", ",", "max_len", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "# [  [for sp_idx in range(span_num)] for batch_sz in range(batch_size)]", "\n", "for", "batchsz", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "for", "sp_idx", "in", "range", "(", "span_num", ")", ":", "\n", "            ", "start", ",", "end", "=", "span_indices", "[", "batchsz", ",", "sp_idx", "]", "\n", "mask", "[", "batchsz", ",", "sp_idx", ",", "start", ":", "end", "]", "=", "1", "\n", "", "", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.GatherCNN.__init__": [[59, 64], ["super().__init__", "allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_filters", ",", "output_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "cnn_module", "=", "CnnEncoder", "(", "\n", "embedding_dim", "=", "input_dim", ",", "num_filters", "=", "num_filters", ",", "output_dim", "=", "output_dim", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.GatherCNN.forward": [[66, 76], ["gather.GatherCNN.cnn_module.forward"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "forward", "(", "self", ",", "tokens", ",", "\n", "msk", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param tokens: batch_size, num_tokens, embedding_dim\n        :param msk:\n        :return:\n        \"\"\"", "\n", "output", "=", "self", ".", "cnn_module", ".", "forward", "(", "tokens", "=", "tokens", ",", "mask", "=", "msk", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.GatherCNN.get_output_dim": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.select_gather": [[5, 14], ["ValueError"], "function", ["None"], ["def", "select_gather", "(", "name", ")", ":", "\n", "    ", "if", "name", "==", "'sum'", ":", "\n", "        ", "return", "masked_sum", "\n", "", "elif", "name", "==", "'mean'", ":", "\n", "        ", "return", "masked_mean", "\n", "", "elif", "name", "==", "'attn'", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"sum or mean or attn expected.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.masked_sum": [[16, 34], ["torch.sum", "msk.unsqueeze.unsqueeze", "msk.unsqueeze.size", "inp.size", "msk.unsqueeze.size", "inp.size"], "function", ["None"], ["", "", "def", "masked_sum", "(", "inp", ",", "dim", ",", "msk", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n\n    :param inp: Float [*0,*1, ..., *n, hid_dim]\n    :param dim: int: i\n    :param msk: {0,1} [*0,*1, ..., *n,#]\n    :return: [*0,*1, ..*i-1, *i+1, .., *n,, hid_dim]\n    \"\"\"", "\n", "if", "msk", "is", "not", "None", ":", "\n", "        ", "if", "(", "msk", ".", "size", "(", ")", "[", "-", "1", "]", "!=", "inp", ".", "size", "(", ")", "[", "-", "1", "]", ")", "or", "(", "msk", ".", "size", "(", ")", "!=", "inp", ".", "size", "(", ")", ")", ":", "\n", "            ", "msk", "=", "msk", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# print(\"dinner\")", "\n", "# print(inp.size())", "\n", "# print(msk.size())", "\n", "", "inp", "=", "inp", "*", "msk", "\n", "", "result", "=", "torch", ".", "sum", "(", "inp", ",", "dim", ")", "\n", "# print(result.size())", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.masked_mean": [[36, 51], ["torch.sum", "torch.mean", "torch.sum", "msk.unsqueeze.unsqueeze", "msk.unsqueeze.size", "inp.size", "msk.unsqueeze.size", "inp.size"], "function", ["None"], ["", "def", "masked_mean", "(", "inp", ",", "dim", ",", "msk", "=", "None", ")", ":", "\n", "# inp: [ *, dimension]", "\n", "# msk: [ *] in [0,1]", "\n", "    ", "if", "msk", "is", "not", "None", ":", "\n", "        ", "sum_of_mask", "=", "torch", ".", "sum", "(", "msk", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1", "\n", "if", "(", "msk", ".", "size", "(", ")", "[", "-", "1", "]", "!=", "inp", ".", "size", "(", ")", "[", "-", "1", "]", ")", "or", "(", "msk", ".", "size", "(", ")", "!=", "inp", ".", "size", "(", ")", ")", ":", "\n", "            ", "msk", "=", "msk", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "inp", "=", "inp", "*", "msk", "\n", "", "if", "msk", "is", "not", "None", ":", "\n", "        ", "result", "=", "torch", ".", "sum", "(", "inp", ",", "dim", ")", "\n", "result", "=", "result", "/", "sum_of_mask", "\n", "", "else", ":", "\n", "        ", "result", "=", "torch", ".", "mean", "(", "inp", ",", "dim", ")", "\n", "# print(result.size())", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.cnn": [[81, 88], ["allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder", "allennlp.modules.seq2vec_encoders.cnn_encoder.CnnEncoder.forward", "print", "print", "cnn_module.forward.size"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "", "def", "cnn", "(", "tokens", ",", "msk", ",", "embedding_dim", ",", "num_filters", ",", "output_dim", ")", ":", "\n", "    ", "cnn_module", "=", "CnnEncoder", "(", "\n", "embedding_dim", "=", "embedding_dim", ",", "num_filters", "=", "num_filters", ",", "output_dim", "=", "output_dim", "\n", ")", "\n", "output", "=", "cnn_module", ".", "forward", "(", "tokens", "=", "tokens", ",", "mask", "=", "msk", ")", "\n", "print", "(", "output", ".", "size", "(", ")", ")", "\n", "print", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_word2sent.EncWord2Sent.__init__": [[20, 33], ["super().__init__", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "neusum.nn_modules.enc.gather.GatherCNN", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "neusum.service.shared_asset.get_device", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "enc_word2sent.EncWord2Sent.enc_blstm.get_output_dim", "enc_word2sent.EncWord2Sent.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "inp_dim", ",", "hid_dim", ",", "dropout", ",", "nenc_lay", "=", "1", ",", "gather", "=", "'sum'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hid_dim", "\n", "self", ".", "enc_blstm", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "inp_dim", ",", "hid_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "\n", "num_layers", "=", "nenc_lay", ")", ")", "\n", "\n", "# self._span_encoder = select_gather(gather)", "\n", "self", ".", "_span_encoder", "=", "GatherCNN", "(", "input_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ",", "\n", "num_filters", "=", "5", ",", "output_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "device", "=", "get_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_word2sent.EncWord2Sent.get_output_dim": [[34, 37], ["enc_word2sent.EncWord2Sent.enc_blstm.get_output_dim", "enc_word2sent.EncWord2Sent.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "==", "self", ".", "hidden_dim", "*", "2", "\n", "return", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_word2sent.EncWord2Sent.forward": [[38, 56], ["enc_word2sent.EncWord2Sent._dropout", "enc_word2sent.EncWord2Sent._span_encoder.forward", "context.size", "context_msk.size", "enc_word2sent.EncWord2Sent.enc_blstm", "context.size", "context_msk.size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "forward", "(", "self", ",", "context", ",", "context_msk", ")", ":", "\n", "        ", "\"\"\"\n\n        :param context: [batch, t, inp_dim]\n        :param context_msk: [batch, t] [0,1]\n        :return: blstm_output [batch, t, hid_dim*2]\n                avg_blstm_out [batch, hid*2]\n        \"\"\"", "\n", "batch_size", "=", "context", ".", "size", "(", ")", "[", "0", "]", "\n", "b_size", "=", "context_msk", ".", "size", "(", ")", "[", "0", "]", "\n", "assert", "context", ".", "size", "(", ")", "[", "1", "]", "==", "context_msk", ".", "size", "(", ")", "[", "1", "]", "\n", "assert", "batch_size", "==", "b_size", "\n", "\n", "blstm_output", "=", "self", ".", "_dropout", "(", "self", ".", "enc_blstm", "(", "context", ",", "context_msk", ")", ")", "# blstm", "\n", "# blstm_output: batch, t, dim", "\n", "gathered_output", "=", "self", ".", "_span_encoder", ".", "forward", "(", "tokens", "=", "blstm_output", ",", "msk", "=", "context_msk", ")", "\n", "# gathered_output: batch, dim", "\n", "return", "blstm_output", ",", "gathered_output", "\n", "# context_msk[:, 0] = 1", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.__init__": [[26, 44], ["super().__init__", "neusum.service.shared_asset.get_device", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "torch.nn.Dropout", "neusum.nn_modules.enc.gather.select_gather", "neusum.nn_modules.enc.gather.GatherCNN", "neusum.nn_modules.enc.gather.GatherCNN", "torch.nn.LSTM", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.shared_asset.get_device", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.gather.select_gather", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "\n", "inp_dim", ",", "hid_dim", ",", "dropout", "=", "0.2", ",", "gather", "=", "'sum'", ",", "nenc_lay", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "device", "=", "get_device", "(", ")", "\n", "self", ".", "enc_blstm", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "inp_dim", ",", "hid_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "\n", "num_layers", "=", "nenc_lay", ")", ")", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "gather_func", "=", "select_gather", "(", "gather", ")", "\n", "\n", "# self.attn = NewAttention(enc_dim=self.enc_blstm.get_output_dim() * 3,", "\n", "#                          dec_dim=self.enc_blstm.get_output_dim())", "\n", "self", ".", "cnn_sent_enc", "=", "GatherCNN", "(", "input_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ",", "\n", "num_filters", "=", "3", ",", "output_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", "\n", "self", ".", "cnn_comp_enc", "=", "GatherCNN", "(", "input_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ",", "\n", "num_filters", "=", "3", ",", "output_dim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.get_output_dim": [[45, 47], ["enc_compression.EncCompression.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "*", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.get_output_dim_unit": [[48, 50], ["enc_compression.EncCompression.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["", "def", "get_output_dim_unit", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.enc_compression.EncCompression.forward": [[51, 103], ["enc_compression.EncCompression.unsqueeze.size", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression._dropout", "span.size", "enc_compression.EncCompression.unsqueeze", "enc_compression.EncCompression.unsqueeze.expand().contiguous", "blstm_output.unsqueeze.expand().contiguous.view().contiguous", "span.view", "enc_compression.EncCompression.cnn_comp_enc.forward", "enc_compression.EncCompression.view", "enc_compression.EncCompression.cnn_sent_enc.forward", "enc_compression.EncCompression.unsqueeze", "sqz_original_sent_rep.expand.expand.expand", "torch.cat", "torch.sum", "enc_compression.EncCompression.enc_blstm", "enc_compression.EncCompression.cnn_comp_enc.get_output_dim", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression.unsqueeze.expand", "blstm_output.unsqueeze.expand().contiguous.view", "enc_compression.EncCompression.enc_blstm.get_output_dim", "enc_compression.EncCompression.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["", "def", "forward", "(", "self", ",", "word_emb", ",", "word_emb_msk", ",", "span", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word_emb: [batch, t, dim]\n        :param word_emb_msk: [batch, t]\n        :param span: [batch, n_span, t] like 000111110000\n        :return: concat_rep: [batch, n_span, output dim]\n                mask_of_span: [batch, n_span]\n                original_sent_rep: [batch, out dim]\n        \"\"\"", "\n", "batch_z", ",", "t_", ",", "dim", "=", "word_emb", ".", "size", "(", ")", "\n", "hiddim", "=", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", "blstm_output", "=", "self", ".", "_dropout", "(", "self", ".", "enc_blstm", "(", "word_emb", ",", "word_emb_msk", ")", ")", "\n", "batch", ",", "num_of_compression", ",", "t", "=", "span", ".", "size", "(", ")", "\n", "word_emb", "=", "blstm_output", ".", "unsqueeze", "(", "1", ")", "\n", "expanded_word_emb", "=", "word_emb", ".", "expand", "(", "batch", ",", "num_of_compression", ",", "t", ",", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "# these are compressions", "\n", "# easy version", "\n", "# enc_compressions = self.gather_func(inp=expanded_word_emb, dim=2, msk=span)", "\n", "# cnn version", "\n", "sqzed_expanded_word_emb", "=", "expanded_word_emb", ".", "view", "(", "batch", "*", "num_of_compression", ",", "t", ",", "\n", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", ".", "contiguous", "(", ")", "\n", "sqzed_span", "=", "span", ".", "view", "(", "batch", "*", "num_of_compression", ",", "t", ")", "\n", "comp_out", "=", "self", ".", "cnn_comp_enc", ".", "forward", "(", "tokens", "=", "sqzed_expanded_word_emb", ",", "msk", "=", "sqzed_span", ")", "\n", "enc_compressions", "=", "comp_out", ".", "view", "(", "batch", ",", "num_of_compression", ",", "self", ".", "cnn_comp_enc", ".", "get_output_dim", "(", ")", ")", "\n", "# enc_compressions: batch, num_of_compression, dim", "\n", "\n", "original_sent_rep", "=", "self", ".", "cnn_sent_enc", ".", "forward", "(", "tokens", "=", "blstm_output", ",", "msk", "=", "word_emb_msk", ")", "\n", "# original_sent_rep = self.gather_func(inp=blstm_output, dim=1)", "\n", "# original_sent_rep: batch, dim", "\n", "sqz_original_sent_rep", "=", "original_sent_rep", ".", "unsqueeze", "(", "1", ")", "\n", "sqz_original_sent_rep", "=", "sqz_original_sent_rep", ".", "expand", "(", "batch", ",", "num_of_compression", ",", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", ")", "\n", "\n", "full_minus_compression", "=", "sqz_original_sent_rep", "-", "enc_compressions", "\n", "concat_rep", "=", "torch", ".", "cat", "(", "[", "enc_compressions", ",", "sqz_original_sent_rep", ",", "full_minus_compression", "]", "\n", ",", "dim", "=", "-", "1", ")", "\n", "\n", "sum_of_span", "=", "torch", ".", "sum", "(", "input", "=", "span", ",", "dim", "=", "2", ")", "\n", "mask_of_span", "=", "(", "sum_of_span", ">", "0", ")", ".", "float", "(", ")", "\n", "# s(concat_rep)", "\n", "# s(original_sent_rep)", "\n", "# s(mask_of_span)", "\n", "# torch.Size([7, 17, 222])", "\n", "# torch.Size([7, 74])", "\n", "# torch.Size([7, 17])", "\n", "# attention_distribution, penaltied_score = self.attn.forward_one_step(enc_state=concat_rep,", "\n", "#                                                                      dec_state=original_sent_rep,", "\n", "#                                                                      enc_mask=mask_of_span)", "\n", "# s(attention_distribution)", "\n", "# s(penaltied_score)", "\n", "return", "concat_rep", ",", "mask_of_span", ",", "original_sent_rep", "\n", "# , attention_distribution, penaltied_score", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncWord2Sent.__init__": [[17, 29], ["super().__init__", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "allennlp.modules.span_extractors.BidirectionalEndpointSpanExtractor", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "encoders.EncWord2Sent.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "inp_dim", ",", "hidden_dim", ",", "nenc_lay", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "enc_blstm", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "inp_dim", ",", "hidden_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "\n", "num_layers", "=", "nenc_lay", ")", ")", "\n", "self", ".", "_span_encoder", "=", "BidirectionalEndpointSpanExtractor", "(", "\n", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", ")", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncWord2Sent.get_output_dim": [[30, 32], ["encoders.EncWord2Sent.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncWord2Sent.forward": [[33, 71], ["encoders.EncWord2Sent._dropout", "context_mask_sum.unsqueeze().unsqueeze().long", "torch.cat().long.view", "torch.cat().long.view", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "encoders.EncWord2Sent._span_encoder.forward", "encoders.EncWord2Sent.squeeze", "encoders.EncWord2Sent._dropout", "context.size", "encoders.EncWord2Sent.enc_blstm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "context_mask_sum.unsqueeze().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "valid_bit.unsqueeze", "context_mask_sum.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "forward", "(", "self", ",", "context", ",", "context_msk", ")", ":", "\n", "        ", "\"\"\"\n\n        :param context: [batch, t, inp_dim]\n        :param context_msk: [batch, t] [0,1]\n        :return: blstm_output [batch, t, hid_dim*2]\n                avg_blstm_out [batch, hid*2]\n        \"\"\"", "\n", "batch_size", "=", "context", ".", "size", "(", ")", "[", "0", "]", "\n", "blstm_output", "=", "self", ".", "_dropout", "(", "self", ".", "enc_blstm", "(", "context", ",", "context_msk", ")", ")", "# blstm", "\n", "context_msk", "[", ":", ",", "0", "]", "=", "1", "\n", "# context_msk = [batch, t]", "\n", "context_mask_sum", "=", "torch", ".", "sum", "(", "context_msk", ",", "dim", "=", "1", ")", "-", "1", "\n", "# context_mask_sum = [batch]   [ 40, 4, 9, 0(sent len=1) , -1(sent len=0), -1]", "\n", "sum_of_mask", "=", "context_mask_sum", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "dim", "=", "2", ")", ".", "long", "(", ")", "\n", "\n", "span_idx", "=", "torch", ".", "ones", "(", "(", "batch_size", ")", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "*", "-", "1", "\n", "# [ [-1] [-1] [-1] [-1] ]", "\n", "# according to sum_of_mask", "\n", "valid_bit", "=", "(", "context_mask_sum", ">=", "0", ")", ".", "long", "(", ")", "\n", "span_idx", "=", "span_idx", "+", "valid_bit", "\n", "span_idx", "=", "span_idx", ".", "view", "(", "(", "batch_size", ",", "1", ",", "1", ")", ")", "\n", "span_idx", "=", "torch", ".", "cat", "(", "[", "span_idx", ",", "sum_of_mask", "]", ",", "dim", "=", "2", ")", ".", "long", "(", ")", "\n", "# Span module: (batch_size, sequence_length, embedding_size)", "\n", "#                (batch_size, num_spans, 2)", "\n", "attended_text_embeddings", "=", "self", ".", "_span_encoder", ".", "forward", "(", "sequence_tensor", "=", "blstm_output", ",", "\n", "span_indices", "=", "span_idx", ",", "\n", "sequence_mask", "=", "context_msk", ",", "\n", "span_indices_mask", "=", "valid_bit", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# attended_text_embeddings: batch, 1, dim", "\n", "\n", "\n", "attended_text_embeddings", "=", "attended_text_embeddings", ".", "squeeze", "(", "1", ")", "\n", "# valid_len = context_msk.sum(dim=1).unsqueeze(1)  # batchsz,1.", "\n", "# context_msk = context_msk.unsqueeze(2)", "\n", "# msked_blstm_out = context_msk * blstm_output", "\n", "attended_text_embeddings", "=", "self", ".", "_dropout", "(", "attended_text_embeddings", ")", "\n", "return", "blstm_output", ",", "attended_text_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncWord2PhrasesViaMapping.__init__": [[86, 96], ["super().__init__", "allennlp.modules.seq2seq_encoders.PytorchSeq2SeqWrapper", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "allennlp.modules.span_extractors.BidirectionalEndpointSpanExtractor", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "encoders.EncWord2PhrasesViaMapping.enc_blstm.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "inp_dim", ",", "hidden_dim", ",", "nenc_lay", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "enc_blstm", "=", "PytorchSeq2SeqWrapper", "(", "\n", "torch", ".", "nn", ".", "LSTM", "(", "inp_dim", ",", "hidden_dim", ",", "\n", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ",", "\n", "num_layers", "=", "nenc_lay", ")", ")", "\n", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "_span_encoder", "=", "BidirectionalEndpointSpanExtractor", "(", "\n", "self", ".", "enc_blstm", ".", "get_output_dim", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncWord2PhrasesViaMapping.forward": [[98, 132], ["encoders.EncWord2PhrasesViaMapping._dropout", "torch.relu().long", "torch.relu().long", "encoders.EncWord2PhrasesViaMapping._span_encoder", "context_msk.unsqueeze.unsqueeze.sum().unsqueeze", "context_msk.unsqueeze.unsqueeze.unsqueeze", "encoders.EncWord2PhrasesViaMapping.enc_blstm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.relu", "torch.relu", "context_msk.unsqueeze.unsqueeze.sum", "span.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context", ",", "context_msk", ",", "span", ")", ":", "\n", "        ", "\"\"\"\n\n        :param context:\n        :param context_msk:\n        :param span:\n        :return: spans_rep: [batch, n_span, dim], float\n                span_msk: [batch, n_span], binary [1,1,0,0]...\n        \"\"\"", "\n", "blstm_output", "=", "self", ".", "_dropout", "(", "self", ".", "enc_blstm", "(", "context", ",", "context_msk", ")", ")", "\n", "span_msk", "=", "(", "span", "[", ":", ",", ":", ",", "0", "]", ">=", "0", ")", ".", "long", "(", ")", "\n", "\n", "# tensor([[1., 1., 1., 0.],", "\n", "# [1., 1., 1., 1.],", "\n", "# [1., 1., 1., 0.]])", "\n", "spans_for_comp", "=", "F", ".", "relu", "(", "span", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "\n", "spans_rep", "=", "self", ".", "_span_encoder", "(", "\n", "sequence_tensor", "=", "blstm_output", ",", "\n", "span_indices", "=", "spans_for_comp", ",", "\n", "sequence_mask", "=", "context_msk", ",", "\n", "span_indices_mask", "=", "span_msk", ")", "\n", "\n", "valid_len", "=", "context_msk", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "# batchsz,1.", "\n", "context_msk", "=", "context_msk", ".", "unsqueeze", "(", "2", ")", "\n", "msked_blstm_out", "=", "context_msk", "*", "blstm_output", "\n", "avg_blstm_out", "=", "torch", ".", "sum", "(", "msked_blstm_out", ",", "dim", "=", "1", ")", "/", "valid_len", "\n", "\n", "# for name, param in self._span_encoder.named_parameters():", "\n", "#     if 'bias' in name:", "\n", "#         print(\"name: {}\".format(name))", "\n", "#         print(\"Param: {}\".format(param))", "\n", "\n", "return", "blstm_output", ",", "avg_blstm_out", ",", "spans_rep", ",", "span_msk", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncPhrases2CondensedPhraseViaAttn.__init__": [[139, 142], ["super().__init__", "neusum.nn_modules.attention.NewAttention"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "context_dim", ",", "sent_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attn", "=", "NewAttention", "(", "enc_dim", "=", "context_dim", ",", "dec_dim", "=", "sent_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncPhrases2CondensedPhraseViaAttn.forward": [[143, 160], ["encoders.EncPhrases2CondensedPhraseViaAttn.attn.forward_one_step", "attn_dist.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "phrases_msk.float"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.attention.NewAttention.forward_one_step"], ["", "def", "forward", "(", "self", ",", "phrases", ",", "phrases_msk", ",", "attn_sent", ")", ":", "\n", "        ", "\"\"\"\n\n        :param phrases:\n        :param phrases_msk:\n        :param attn_sent:\n        :return: reweighted_phrases: use attn to reweight phrasese: [batch, dim]\n                attn_dist: attn dist of phrases given doc: [batch, nspan=src_len]\n        \"\"\"", "\n", "attn_dist", ",", "score", "=", "self", ".", "attn", ".", "forward_one_step", "(", "enc_state", "=", "phrases", ",", "\n", "dec_state", "=", "attn_sent", ",", "\n", "enc_mask", "=", "phrases_msk", ".", "float", "(", ")", ")", "\n", "unsqueezed_attn_dist", "=", "attn_dist", ".", "unsqueeze", "(", "-", "1", ")", "\n", "reweighted_phrases", "=", "unsqueezed_attn_dist", "*", "phrases", "\n", "reweighted_phrases", "=", "torch", ".", "sum", "(", "reweighted_phrases", ",", "dim", "=", "1", ")", "\n", "# print(reweighted_phrases.size())", "\n", "return", "reweighted_phrases", ",", "attn_dist", ",", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncSent.__init__": [[164, 175], ["super().__init__", "encoders.EncWord2PhrasesViaMapping", "encoders.EncPhrases2CondensedPhraseViaAttn", "encoders.EncWord2Sent"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "inp_dim", ",", "hid_dim", ",", "compression", "=", "True", ",", "dropout", "=", "0.4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "compression", "=", "compression", "\n", "if", "compression", ":", "\n", "            ", "self", ".", "plain_enc", "=", "EncWord2PhrasesViaMapping", "(", "inp_dim", "=", "inp_dim", ",", "hidden_dim", "=", "hid_dim", ",", "\n", "nenc_lay", "=", "2", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "condensed_phrases", "=", "EncPhrases2CondensedPhraseViaAttn", "(", "context_dim", "=", "hid_dim", "*", "2", ",", "sent_dim", "=", "hid_dim", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "enc", "=", "EncWord2Sent", "(", "device", "=", "device", ",", "inp_dim", "=", "inp_dim", ",", "hidden_dim", "=", "hid_dim", ",", "\n", "nenc_lay", "=", "1", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncSent.get_output_dim": [[176, 181], ["None"], "methods", ["None"], ["", "", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "compression", ":", "\n", "            ", "return", "self", ".", "hid_dim", "*", "4", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "hid_dim", "*", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncSent.forward": [[182, 209], ["encoders.EncSent.plain_enc.forward", "encoders.EncSent.condensed_phrases.forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoders.EncSent.enc.forward"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "", "def", "forward", "(", "self", ",", "word_emb", ",", "word_emb_msk", ",", "span", ")", ":", "\n", "        ", "\"\"\"\n\n        :param word_emb: batch, t, dim\n        :param word_emb_msk: [batch, t]\n        :param span: batch, n_span, 2\n        :return:\n        \"\"\"", "\n", "# word_emb: batch, t, dim", "\n", "# word_emb_msk: [batch, t] [0,1]", "\n", "# span: batch, n_span, 2", "\n", "if", "self", ".", "compression", ":", "\n", "            ", "blstm_output", ",", "avg_blstm_out", ",", "spans_rep", ",", "span_msk", "=", "self", ".", "plain_enc", ".", "forward", "(", "context", "=", "word_emb", ",", "\n", "context_msk", "=", "word_emb_msk", ",", "\n", "span", "=", "span", ")", "\n", "\n", "reweighted_phrases", ",", "attn_dist", ",", "score", "=", "self", ".", "condensed_phrases", ".", "forward", "(", "phrases", "=", "spans_rep", ",", "\n", "phrases_msk", "=", "span_msk", ",", "\n", "attn_sent", "=", "avg_blstm_out", ")", "\n", "# print(reweighted_phrases.size())", "\n", "# print(avg_blstm_out.size())", "\n", "cat_rep", "=", "torch", ".", "cat", "(", "[", "reweighted_phrases", ",", "avg_blstm_out", "]", ",", "dim", "=", "1", ")", "\n", "# print(cat_rep.size())", "\n", "return", "cat_rep", ",", "attn_dist", ",", "spans_rep", ",", "span_msk", ",", "score", "\n", "", "else", ":", "\n", "            ", "blstm_output", ",", "avg_blstm_out", "=", "self", ".", "enc", ".", "forward", "(", "context", "=", "word_emb", ",", "context_msk", "=", "word_emb_msk", ")", "\n", "return", "avg_blstm_out", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncDoc.__init__": [[213, 238], ["super().__init__", "encoders.EncSent", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "encoders.EncWord2Sent", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "logging.getLogger", "logging.getLogger.info", "allennlp.modules.token_embedders.Embedding.from_params", "vocab.get_vocab_size", "encoders.EncDoc.sent_enc.get_output_dim", "allennlp.common.params.Params"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "inp_dim", ",", "hid_dim", ",", "compression", ",", "vocab", ",", "dropout", ":", "float", "=", "0.4", ",", "\n", "dropout_emb", ":", "float", "=", "0.2", ",", "pretrain_embedding_file", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "compression", "=", "compression", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "sent_enc", "=", "EncSent", "(", "device", "=", "device", ",", "inp_dim", "=", "inp_dim", ",", "hid_dim", "=", "hid_dim", ",", "compression", "=", "compression", ")", "\n", "token_embedding", "=", "Embedding", "(", "num_embeddings", "=", "vocab", ".", "get_vocab_size", "(", "'tokens'", ")", ",", "\n", "embedding_dim", "=", "inp_dim", ")", "\n", "\n", "if", "dropout_emb", ">", "0", ":", "\n", "            ", "self", ".", "_lexical_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout_emb", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_lexical_dropout", "=", "lambda", "x", ":", "x", "\n", "\n", "", "if", "pretrain_embedding_file", "is", "not", "None", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "\"Loading word embedding: {}\"", ".", "format", "(", "pretrain_embedding_file", ")", ")", "\n", "token_embedding", ".", "from_params", "(", "vocab", "=", "vocab", ",", "\n", "params", "=", "Params", "(", "{", "\"pretrained_file\"", ":", "pretrain_embedding_file", ",", "\n", "\"embedding_dim\"", ":", "inp_dim", "}", ")", "\n", ")", "\n", "", "self", ".", "_text_field_embedder", "=", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedding", "}", ")", "\n", "\n", "self", ".", "sent2doc", "=", "EncWord2Sent", "(", "device", "=", "device", ",", "inp_dim", "=", "self", ".", "sent_enc", ".", "get_output_dim", "(", ")", ",", "hidden_dim", "=", "hid_dim", ",", "\n", "nenc_lay", "=", "2", ",", "dropout", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.encoders.EncDoc.forward": [[239, 286], ["encoders.EncDoc._text_field_embedder", "encoders.EncDoc._lexical_dropout", "encoders.EncDoc.size", "encoders.EncDoc.view", "context_msk.view", "spans.view", "encoders.EncDoc.sent_enc.forward", "flattened_enc.view", "encoders.EncDoc.sent2doc.forward", "spans.size", "spans_rep.view", "span_msk.view", "attn_dist.view"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["", "def", "forward", "(", "self", ",", "context", ",", "context_msk", ",", "spans", ")", ":", "\n", "#", "\n", "# inp: batch, max_sent, max_t LongTensor", "\n", "# [sent_0, sent_1, ... sent_n]", "\n", "# for every sent, word_emb, word_embed_msk, span", "\n", "# sent and compression encoding is based on every sent", "\n", "# doc_rep is based on the whole batch", "\n", "# context: batch, max_sent, max_word, inp_dim", "\n", "# context_msk: batch, max_sent, max_word {1,0}", "\n", "# spans: batch, max_sent, nspan, 2", "\n", "\n", "\n", "        ", "context", "=", "self", ".", "_text_field_embedder", "(", "context", ")", "\n", "context", "=", "self", ".", "_lexical_dropout", "(", "context", ")", "\n", "num_doc", ",", "max_sent", ",", "max_word", ",", "inp_dim", "=", "context", ".", "size", "(", ")", "\n", "num_doc_", ",", "max_sent_", ",", "nspan", "=", "spans", ".", "size", "(", ")", "[", "0", ":", "-", "1", "]", "\n", "assert", "num_doc", "==", "num_doc_", "\n", "assert", "max_sent", "==", "max_sent_", "\n", "\n", "mix_batch_and_sent", "=", "num_doc", "*", "max_sent", "\n", "flattened_context", "=", "context", ".", "view", "(", "mix_batch_and_sent", ",", "max_word", ",", "inp_dim", ")", "\n", "flattened_context_msk", "=", "context_msk", ".", "view", "(", "mix_batch_and_sent", ",", "max_word", ")", "\n", "flattened_spans", "=", "spans", ".", "view", "(", "mix_batch_and_sent", ",", "nspan", ",", "2", ")", "\n", "flattened_enc", ",", "attn_dist", ",", "spans_rep", ",", "span_msk", ",", "score", "=", "self", ".", "sent_enc", ".", "forward", "(", "word_emb", "=", "flattened_context", ",", "\n", "word_emb_msk", "=", "flattened_context_msk", ",", "\n", "span", "=", "flattened_spans", ")", "\n", "if", "spans_rep", "is", "not", "None", ":", "\n", "            ", "reorg_spans_rep", "=", "spans_rep", ".", "view", "(", "num_doc", ",", "max_sent", ",", "nspan", ",", "self", ".", "hid_dim", "*", "2", ")", "\n", "reorg_span_msk", "=", "span_msk", ".", "view", "(", "num_doc", ",", "max_sent", ",", "nspan", ")", "\n", "", "else", ":", "\n", "            ", "reorg_spans_rep", ",", "reorg_span_msk", "=", "None", ",", "None", "\n", "", "if", "attn_dist", "is", "not", "None", ":", "\n", "# print(attn_dist.size())", "\n", "            ", "attn_dist_of_phrases", "=", "attn_dist", ".", "view", "(", "num_doc", ",", "max_sent", ",", "nspan", ")", "\n", "", "else", ":", "\n", "            ", "attn_dist_of_phrases", "=", "None", "\n", "", "enc", "=", "flattened_enc", ".", "view", "(", "num_doc", ",", "max_sent", ",", "-", "1", ")", "\n", "# print(enc.size())", "\n", "sent_mask", "=", "context_msk", "[", ":", ",", ":", ",", "0", "]", "\n", "# print(sent_mask.size())", "\n", "sent_blstm_output", ",", "document_rep", "=", "self", ".", "sent2doc", ".", "forward", "(", "context", "=", "enc", ",", "context_msk", "=", "sent_mask", ")", "\n", "# sent_blstm_output: batch, max_sent, hdim*2", "\n", "# document_rep:     batch, hdim*2", "\n", "# attn_dist_of_phrases: batch, max_sent, max_num_of_span", "\n", "# reorg_spans_rep:         batch, max_sent, max_num_of_span, hid*2", "\n", "# reorg_span_msk:       batch, max_sent, max_num_of_span", "\n", "return", "sent_blstm_output", ",", "document_rep", ",", "attn_dist_of_phrases", ",", "reorg_spans_rep", ",", "reorg_span_msk", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.test_encoderLayer.TestEncoderLayer.test_forward": [[6, 36], ["torch.ones", "torch.ones.uniform_", "torch.ones", "print", "torch.ones", "print", "print", "neusum.nn_modules.enc.transformer.attention", "neusum.nn_modules.enc.transformer.EncoderLayer", "torch.ones.size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.attention"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "# test attention module it self", "\n", "        ", "inp_dim", "=", "11", "\n", "hid_dim", "=", "13", "\n", "batch", "=", "3", "\n", "max_sent", "=", "7", "\n", "max_t", "=", "19", "\n", "\n", "context", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "max_t", ",", "inp_dim", ")", ")", "\n", "context", ".", "uniform_", "(", ")", "\n", "\n", "context_msk", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "max_t", ")", ")", "# dtype?", "\n", "context_msk", "[", "batch", "-", "2", ",", "1", ",", "5", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "1", ",", "0", ",", "2", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "3", ",", "1", ",", "4", ":", "]", "=", "0", "\n", "print", "(", "context_msk", ")", "\n", "span", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "4", ",", "2", ")", ")", "\n", "span", "[", ":", ",", "0", ",", "1", ",", "0", "]", "=", "5", "\n", "span", "[", ":", ",", "0", ",", "1", ",", "1", "]", "=", "17", "\n", "span", "[", ":", ",", "1", ",", "2", ",", "0", "]", "=", "2", "\n", "span", "[", ":", ",", "1", ",", "2", ",", "1", "]", "=", "11", "\n", "span", "[", "batch", "-", "1", ",", "1", ",", ":", "]", "=", "-", "1", "\n", "# span[1, 3, 0] = 5", "\n", "# span[1, 3, 1] = 9", "\n", "print", "(", "\"Span: {}\"", ".", "format", "(", "span", ")", ")", "\n", "print", "(", "span", ".", "size", "(", ")", ")", "\n", "\n", "sent_level_context_msk", "=", "context_msk", "[", ":", ",", ":", ",", "0", "]", "\n", "attention", "(", ")", "\n", "EncoderLayer", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.__init__.EncoderBase.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], []], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.__init__.EncoderBase.get_output_dim": [[9, 12], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.test_multiHeadedAttention.TestMultiHeadedAttention.test_forward": [[5, 7], ["neusum.nn_modules.enc.transformer.MultiHeadedAttention"], "methods", ["None"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "MultiHeadedAttention", "(", "h", "=", "4", ",", "d_model", "=", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.__init__": [[16, 26], ["torch.Module.__init__", "transformer.MultiHeadedAttention", "transformer.PositionwiseFeedForward", "transformer.Encoder", "Encoder.parameters", "transformer.EncoderLayer", "c", "c", "p.dim", "torch.init.xavier_uniform", "torch.init.xavier_uniform", "torch.init.xavier_uniform"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "N", "=", "6", ",", "d_model", "=", "512", ",", "d_ff", "=", "2048", ",", "h", "=", "8", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "c", "=", "copy", ".", "deepcopy", "\n", "attn", "=", "MultiHeadedAttention", "(", "h", ",", "d_model", ")", "\n", "ff", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "model", "=", "Encoder", "(", "EncoderLayer", "(", "d_model", ",", "c", "(", "attn", ")", ",", "c", "(", "ff", ")", ",", "dropout", ")", ",", "N", ")", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform", "(", "p", ")", "\n", "", "", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim": [[27, 29], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.forward": [[30, 32], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "input", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.Encoder.__init__": [[37, 41], ["torch.Module.__init__", "transformer.clones", "transformer.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.Encoder.forward": [[42, 47], ["transformer.Encoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Pass the input (and mask) through each layer in turn.\"", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.LayerNorm.__init__": [[52, 57], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.LayerNorm.forward": [[58, 62], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.SublayerConnection.__init__": [[70, 74], ["torch.Module.__init__", "transformer.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "SublayerConnection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.SublayerConnection.forward": [[75, 78], ["transformer.SublayerConnection.dropout", "sublayer", "transformer.SublayerConnection.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sublayer", ")", ":", "\n", "        ", "\"Apply residual connection to any sublayer with the same size.\"", "\n", "return", "x", "+", "self", ".", "dropout", "(", "sublayer", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.EncoderLayer.__init__": [[83, 89], ["torch.Module.__init__", "transformer.clones", "transformer.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.EncoderLayer.forward": [[90, 94], ["transformer.EncoderLayer.self_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (left) for connections.\"", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.MultiHeadedAttention.__init__": [[110, 120], ["torch.Module.__init__", "transformer.clones", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.clones"], ["    ", "def", "__init__", "(", "self", ",", "h", ",", "d_model", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "\"Take in model size and number of heads.\"", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "4", ")", "\n", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.MultiHeadedAttention.forward": [[121, 141], ["query.size", "transformer.attention", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "mask.unsqueeze.unsqueeze.unsqueeze", "l().view().transpose", "zip", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "l().view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "l"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"Implements Figure 2\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# Same mask applied to all h heads.", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "nbatches", "=", "query", ".", "size", "(", "0", ")", "\n", "\n", "# 1) Do all the linear projections in batch from d_model => h x d_k", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "\n", "# 2) Apply attention on all the projected vectors in batch.", "\n", "x", ",", "self", ".", "attn", "=", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "mask", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "# 3) \"Concat\" using a view and apply a final linear.", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", "*", "self", ".", "d_k", ")", "\n", "return", "self", ".", "linears", "[", "-", "1", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.PositionalEncoding.__init__": [[146, 159], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "transformer.PositionalEncoding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "dropout", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "# Compute the positional encodings once in log space.", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.PositionalEncoding.forward": [[160, 164], ["transformer.PositionalEncoding.dropout", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "Variable", "(", "self", ".", "pe", "[", ":", ",", ":", "x", ".", "size", "(", "1", ")", "]", ",", "\n", "requires_grad", "=", "False", ")", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.PositionwiseFeedForward.__init__": [[169, 174], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.PositionwiseFeedForward.forward": [[175, 177], ["transformer.PositionwiseFeedForward.w_2", "transformer.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "transformer.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "w_2", "(", "self", ".", "dropout", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.clones": [[10, 13], ["torch.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["def", "clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "\"Produce N identical layers.\"", "\n", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "_", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.attention": [[96, 107], ["query.size", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill", "dropout", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose"], "function", ["None"], ["", "", "def", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ",", "dropout", "=", "None", ")", ":", "\n", "    ", "\"Compute 'Scaled Dot Product Attention'\"", "\n", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "# last dim of query", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scores", "=", "scores", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "", "p_attn", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "if", "dropout", "is", "not", "None", ":", "# TODO ?????", "\n", "        ", "p_attn", "=", "dropout", "(", "p_attn", ")", "\n", "", "return", "torch", ".", "matmul", "(", "p_attn", ",", "value", ")", ",", "p_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encWord2Sent.TestEncWord2Sent.test_forward": [[7, 23], ["neusum.nn_modules.enc.enc_doc.EncWord2Sent", "torch.ones", "torch.ones.uniform_", "torch.ones", "print", "print", "neusum.nn_modules.enc.enc_doc.EncWord2Sent.forward", "torch.device", "neusum.nn_modules.enc.enc_doc.EncWord2Sent.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "dim", "=", "11", "\n", "hid_dim", "=", "13", "\n", "module", "=", "EncWord2Sent", "(", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ",", "inp_dim", "=", "dim", ",", "hidden_dim", "=", "hid_dim", ",", "nenc_lay", "=", "2", ",", "dropout", "=", "0.1", ")", "\n", "batch", "=", "4", "\n", "t", "=", "19", "\n", "\n", "context", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ",", "dim", ")", ")", "\n", "context", ".", "uniform_", "(", ")", "\n", "context_msk", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ")", ")", "# dtype?", "\n", "context_msk", "[", "batch", "-", "2", ",", "5", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "1", ",", "15", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "3", ",", ":", "]", "=", "0", "\n", "print", "(", "context_msk", ")", "\n", "print", "(", "\"output dim: \"", ".", "format", "(", "module", ".", "get_output_dim", "(", ")", ")", ")", "\n", "out", "=", "module", ".", "forward", "(", "context", ",", "context_msk", "=", "context_msk", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_multilabel_margin_loss.TestMultilabel_margin_loss.test_multilabel_margin_loss": [[7, 19], ["torch.zeros", "print", "torch.ones", "neusum.service.basic_service.multilabel_margin_loss", "print"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.multilabel_margin_loss"], ["    ", "def", "test_multilabel_margin_loss", "(", "self", ")", ":", "\n", "        ", "inp", "=", "torch", ".", "zeros", "(", "(", "2", ",", "3", ")", ")", "\n", "inp", "[", "0", ",", "0", "]", "=", "0.2", "\n", "inp", "[", "0", ",", "1", "]", "=", "0.5", "\n", "inp", "[", "0", ",", "2", "]", "=", "0.3", "\n", "inp", "[", "1", ",", "1", "]", "=", "1", "\n", "print", "(", "inp", ")", "\n", "tgt", "=", "torch", ".", "ones", "(", "(", "2", ",", "3", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "# tgt[0,1] =1", "\n", "\n", "loss", "=", "multilabel_margin_loss", "(", "inp", ",", "tgt", ")", "\n", "print", "(", "loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encWord2PhrasesViaMapping.TestEncWord2PhrasesViaMapping.test_forward": [[7, 30], ["neusum.nn_modules.enc.EncWord2PhrasesViaMapping", "torch.ones", "torch.ones.uniform_", "torch.ones", "print", "torch.ones", "print", "neusum.nn_modules.enc.EncWord2PhrasesViaMapping.forward"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "dim", "=", "11", "\n", "hid_dim", "=", "13", "\n", "module", "=", "EncWord2PhrasesViaMapping", "(", "inp_dim", "=", "dim", ",", "hidden_dim", "=", "hid_dim", ",", "nenc_lay", "=", "2", ",", "dropout", "=", "0.1", ")", "\n", "batch", "=", "3", "\n", "t", "=", "19", "\n", "\n", "context", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ",", "dim", ")", ")", "\n", "context", ".", "uniform_", "(", ")", "\n", "context_msk", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ")", ")", "# dtype?", "\n", "context_msk", "[", "batch", "-", "2", ",", "5", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "1", ",", "15", ":", "]", "=", "0", "\n", "print", "(", "context_msk", ")", "\n", "span", "=", "torch", ".", "ones", "(", "(", "batch", ",", "4", ",", "2", ")", ")", "\n", "span", "[", ":", ",", "1", ",", "0", "]", "=", "5", "\n", "span", "[", ":", ",", "1", ",", "1", "]", "=", "17", "\n", "span", "[", ":", ",", "2", ",", "0", "]", "=", "2", "\n", "span", "[", ":", ",", "2", ",", "1", "]", "=", "11", "\n", "span", "[", ":", ",", "3", ",", ":", "]", "=", "-", "1", "\n", "span", "[", "1", ",", "3", ",", "0", "]", "=", "5", "\n", "span", "[", "1", ",", "3", ",", "1", "]", "=", "9", "\n", "print", "(", "\"Span: {}\"", ".", "format", "(", "span", ")", ")", "\n", "spans_rep", ",", "span_msk", "=", "module", ".", "forward", "(", "context", "=", "context", ",", "context_msk", "=", "context_msk", ",", "span", "=", "span", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encDoc.TestEncDoc.test_forward": [[17, 79], ["neusum.nn_modules.enc.EncDoc", "torch.ones", "torch.ones.uniform_", "torch.ones", "print", "torch.ones", "print", "print", "neusum.nn_modules.enc.EncDoc.forward", "neusum.nn_modules.sent_dec.SentRNNDecoder", "numpy.asarray", "torch.from_numpy().view", "print", "neusum.nn_modules.sent_dec.SentRNNDecoder.forward", "test_encDoc.s", "test_encDoc.s", "print", "test_encDoc.s", "print", "print", "neusum.nn_modules.compression_decoder.CompressDecoder", "neusum.nn_modules.compression_decoder.CompressDecoder.forward", "torch.ones.size", "list", "torch.device", "range", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encDoc.s", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encDoc.s", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encDoc.s", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "inp_dim", "=", "11", "\n", "hid_dim", "=", "13", "\n", "batch", "=", "3", "\n", "max_sent", "=", "7", "\n", "max_t", "=", "19", "\n", "model", "=", "EncDoc", "(", "inp_dim", ",", "hid_dim", ",", "compression", "=", "True", ",", "vocab", "=", "None", ")", "\n", "\n", "context", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "max_t", ",", "inp_dim", ")", ")", "\n", "context", ".", "uniform_", "(", ")", "\n", "\n", "context_msk", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "max_t", ")", ")", "# dtype?", "\n", "context_msk", "[", "batch", "-", "2", ",", "1", ",", "5", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "1", ",", "0", ",", "2", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "3", ",", "1", ",", "4", ":", "]", "=", "0", "\n", "print", "(", "context_msk", ")", "\n", "span", "=", "torch", ".", "ones", "(", "(", "batch", ",", "max_sent", ",", "4", ",", "2", ")", ")", "\n", "span", "[", ":", ",", "0", ",", "1", ",", "0", "]", "=", "5", "\n", "span", "[", ":", ",", "0", ",", "1", ",", "1", "]", "=", "17", "\n", "span", "[", ":", ",", "1", ",", "2", ",", "0", "]", "=", "2", "\n", "span", "[", ":", ",", "1", ",", "2", ",", "1", "]", "=", "11", "\n", "span", "[", "batch", "-", "1", ",", "1", ",", ":", "]", "=", "-", "1", "\n", "# span[1, 3, 0] = 5", "\n", "# span[1, 3, 1] = 9", "\n", "print", "(", "\"Span: {}\"", ".", "format", "(", "span", ")", ")", "\n", "print", "(", "span", ".", "size", "(", ")", ")", "\n", "\n", "sent_level_context_msk", "=", "context_msk", "[", ":", ",", ":", ",", "0", "]", "\n", "sent_blstm_output", ",", "document_rep", ",", "attn_dist_of_phrases", ",", "reorg_spans_rep", ",", "reorg_span_msk", "=", "model", ".", "forward", "(", "context", "=", "context", ",", "\n", "context_msk", "=", "context_msk", ",", "spans", "=", "span", ")", "\n", "\n", "sent_dec_1", "=", "SentRNNDecoder", "(", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "dec_hidden_size", "=", "hid_dim", "*", "2", ",", "\n", "dec_input_size", "=", "hid_dim", "*", "2", ",", "fixed_dec_step", "=", "3", ")", "\n", "\n", "# sent_dec_2 = SentRNNDecoder(device=torch.device(\"cpu\"),dec_hidden_size=23,", "\n", "#                dec_input_size=hid_dim*2,fixed_dec_step=-1)", "\n", "\n", "noracles", "=", "2", "\n", "lis", "=", "list", "(", "range", "(", "1", ",", "4", ")", ")", "+", "[", "0", "]", "\n", "tgt_np", "=", "np", ".", "asarray", "(", "lis", "*", "batch", "*", "noracles", ")", "\n", "tgt", "=", "torch", ".", "from_numpy", "(", "tgt_np", ")", ".", "view", "(", "batch", ",", "noracles", ",", "4", ")", "\n", "print", "(", "tgt", ")", "\n", "\n", "decoder_outputs_logit", ",", "decoder_outputs_prob", ",", "[", "decoder_states_h", ",", "decoder_states_c", "]", "=", "sent_dec_1", ".", "forward", "(", "context", "=", "sent_blstm_output", ",", "\n", "context_mask", "=", "sent_level_context_msk", ",", "\n", "last_state", "=", "document_rep", ",", "tgt", "=", "tgt", ")", "\n", "s", "(", "tgt", ")", "\n", "s", "(", "decoder_outputs_logit", ")", "\n", "print", "(", "decoder_outputs_logit", ")", "\n", "s", "(", "decoder_outputs_prob", ")", "\n", "print", "(", "\"-\"", "*", "40", ")", "\n", "print", "(", "\"Compression\"", ")", "\n", "compression", "=", "CompressDecoder", "(", "context_dim", "=", "hid_dim", "*", "2", ",", "doc_dim", "=", "hid_dim", "*", "2", ",", "\n", "sent_dim", "=", "hid_dim", "*", "2", ",", "dec_state_dim", "=", "hid_dim", "*", "2", ")", "\n", "compression", ".", "forward", "(", "decoder_states", "=", "decoder_states_h", ",", "\n", "decoder_outputs_logit", "=", "decoder_outputs_logit", ",", "\n", "document_rep", "=", "document_rep", ",", "\n", "sent_rep", "=", "sent_blstm_output", ",", "\n", "spans_rep", "=", "reorg_spans_rep", ",", "\n", "span_msk", "=", "reorg_span_msk", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encDoc.s": [[9, 11], ["print", "x.size"], "function", ["None"], ["def", "s", "(", "x", ")", ":", "\n", "    ", "print", "(", "x", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_encPhrases2CondensedPhraseViaAttn.TestEncPhrases2CondensedPhraseViaAttn.test_forward": [[8, 36], ["neusum.nn_modules.enc.EncWord2PhrasesViaMapping", "torch.ones", "torch.ones.uniform_", "torch.ones", "print", "torch.ones", "print", "neusum.nn_modules.enc.EncWord2PhrasesViaMapping.forward", "torch.ones", "torch.ones.uniform_", "print", "neusum.nn_modules.enc.EncPhrases2CondensedPhraseViaAttn", "neusum.nn_modules.enc.EncPhrases2CondensedPhraseViaAttn.forward", "spans_rep.size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward"], ["    ", "def", "test_forward", "(", "self", ")", ":", "\n", "        ", "dim", "=", "11", "\n", "hid_dim", "=", "13", "\n", "module", "=", "EncWord2PhrasesViaMapping", "(", "inp_dim", "=", "dim", ",", "hidden_dim", "=", "hid_dim", ",", "nenc_lay", "=", "2", ",", "dropout", "=", "0.1", ")", "\n", "batch", "=", "3", "\n", "t", "=", "19", "\n", "\n", "context", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ",", "dim", ")", ")", "\n", "context", ".", "uniform_", "(", ")", "\n", "context_msk", "=", "torch", ".", "ones", "(", "(", "batch", ",", "t", ")", ")", "# dtype?", "\n", "context_msk", "[", "batch", "-", "2", ",", "5", ":", "]", "=", "0", "\n", "context_msk", "[", "batch", "-", "1", ",", "15", ":", "]", "=", "0", "\n", "print", "(", "context_msk", ")", "\n", "span", "=", "torch", ".", "ones", "(", "(", "batch", ",", "4", ",", "2", ")", ")", "\n", "span", "[", ":", ",", "1", ",", "0", "]", "=", "5", "\n", "span", "[", ":", ",", "1", ",", "1", "]", "=", "17", "\n", "span", "[", ":", ",", "2", ",", "0", "]", "=", "2", "\n", "span", "[", ":", ",", "2", ",", "1", "]", "=", "11", "\n", "span", "[", ":", ",", "3", ",", ":", "]", "=", "-", "1", "\n", "span", "[", "1", ",", "3", ",", "0", "]", "=", "5", "\n", "span", "[", "1", ",", "3", ",", "1", "]", "=", "9", "\n", "print", "(", "\"Span: {}\"", ".", "format", "(", "span", ")", ")", "\n", "spans_rep", ",", "span_msk", "=", "module", ".", "forward", "(", "context", "=", "context", ",", "context_msk", "=", "context_msk", ",", "span", "=", "span", ")", "\n", "doc_rep", "=", "torch", ".", "ones", "(", "(", "batch", ",", "hid_dim", ")", ")", "\n", "doc_rep", ".", "uniform_", "(", ")", "\n", "print", "(", "spans_rep", ".", "size", "(", ")", ")", "\n", "mod", "=", "EncPhrases2CondensedPhraseViaAttn", "(", "context_dim", "=", "hid_dim", "*", "2", ",", "sent_dim", "=", "hid_dim", ")", "\n", "mod", ".", "forward", "(", "spans_rep", ",", "span_msk", ",", "doc_rep", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_convert_document_to_read_ready_string.TestConvert_document_to_read_ready_string.test_convert_document_to_read_ready_string": [[5, 7], ["test_convert_document_to_read_ready_string.TestConvert_document_to_read_ready_string.fail"], "methods", ["None"], ["    ", "def", "test_convert_document_to_read_ready_string", "(", "self", ")", ":", "\n", "        ", "self", ".", "fail", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.tests.test_read_single_parse_tree.TestRead_single_parse_tree.test_read_single_parse_tree": [[6, 12], ["neusum.data.create_oracle.read_single_parse_tree", "print", "neusum.data.create_oracle.find_deletable_span_rule_based"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based"], ["    ", "def", "test_read_single_parse_tree", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"(ROOT\\n  (NP\\n    (NP (NN NEW))\\n    (: :)\\n    (NP (NN Diagnosis))\\n    (: :) (`` ``)\\n    (S\\n      (NP\\n        (NP (NN autism))\\n        (, ,)\\n        (NP\\n          (NP (JJ severe) (NN anxiety))\\n          (, ,)\\n          (NP (JJ post-traumatic) (NN stress) (NN disorder)\\n            (CC and)\\n            (NN depression) ('' '') (NNP Burkhart))))\\n      (VP (VBZ is)\\n        (ADVP (RB also))\\n        (VP (VBN suspected)\\n          (PP (IN in)\\n            (NP (DT a) (JJ German) (NN arson) (NN probe))))))\\n    (, ,)\\n    (S\\n      (NP (NNS officials))\\n      (VP (VBP say)))\\n    (. .)))\"", "\n", "out", "=", "read_single_parse_tree", "(", "s", ")", "\n", "rules", "=", "[", "\"PP\"", ",", "\"SBAR\"", ",", "\"ADVP\"", ",", "\"ADJP\"", ",", "\"S\"", "]", "\n", "print", "(", "out", ")", "\n", "find_deletable_span_rule_based", "(", "rules", ",", "out", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.baselines.edu_oracle_baseline.get_best_rouge": [[7, 9], ["None"], "function", ["None"], ["def", "get_best_rouge", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.baselines.edu_oracle_baseline.oracle_baseline": [[11, 42], ["print", "pythonrouge.pythonrouge.Pythonrouge", "pythonrouge.pythonrouge.Pythonrouge.calc_score", "print", "open", "fd.read().splitlines", "l.split", "doc.split.split", "list", "abst.replace().split", "pred_str_bag.append", "ref_str_bag.append", "int", "zip", "int", "_buff.append", "fd.read", "span_info.split", "gold.split", "abst.replace", "len"], "function", ["None"], ["", "def", "oracle_baseline", "(", "path_file", ")", ":", "\n", "    ", "with", "open", "(", "path_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "pred_str_bag", ",", "ref_str_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "name", ",", "doc", ",", "abst", ",", "span_info", ",", "gold", "=", "l", ".", "split", "(", "'\\t'", ")", "\n", "doc", "=", "doc", ".", "split", "(", ")", "\n", "span_info", "=", "[", "int", "(", "w", ")", "for", "w", "in", "span_info", ".", "split", "(", ")", "]", "\n", "idx_in_span", "=", "list", "(", "zip", "(", "span_info", "[", "0", ":", ":", "2", "]", ",", "span_info", "[", "1", ":", ":", "2", "]", ")", ")", "\n", "gold_label", "=", "[", "int", "(", "l", ")", "for", "l", "in", "gold", ".", "split", "(", ")", "]", "\n", "\n", "abs_str", "=", "abst", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\\n\"", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "abs_str", "=", "[", "x", "for", "x", "in", "abs_str", "if", "len", "(", "x", ")", ">", "1", "]", "\n", "_buff", "=", "[", "]", "\n", "for", "g", "in", "gold_label", ":", "\n", "            ", "content", "=", "doc", "[", "idx_in_span", "[", "g", "]", "[", "0", "]", ":", "idx_in_span", "[", "g", "]", "[", "1", "]", "+", "1", "]", "\n", "_buff", ".", "append", "(", "' '", ".", "join", "(", "content", ")", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\"", ")", ")", "\n", "\n", "", "pred_str_bag", ".", "append", "(", "_buff", ")", "\n", "ref_str_bag", ".", "append", "(", "[", "abs_str", "]", ")", "\n", "", "print", "(", "'Finish reading'", ")", "\n", "rouge", "=", "Pythonrouge", "(", "summary_file_exist", "=", "False", ",", "\n", "summary", "=", "pred_str_bag", ",", "reference", "=", "ref_str_bag", ",", "\n", "n_gram", "=", "2", ",", "ROUGE_SU4", "=", "True", ",", "ROUGE_L", "=", "True", ",", "ROUGE_W", "=", "True", ",", "\n", "ROUGE_W_Weight", "=", "1.2", ",", "\n", "recall_only", "=", "False", ",", "stemming", "=", "True", ",", "stopwords", "=", "False", ",", "\n", "word_level", "=", "True", ",", "length_limit", "=", "False", ",", "length", "=", "50", ",", "\n", "use_cf", "=", "False", ",", "cf", "=", "95", ",", "scoring_formula", "=", "'average'", ",", "\n", "resampling", "=", "True", ",", "samples", "=", "1000", ",", "favor", "=", "True", ",", "p", "=", "0.5", ",", "default_conf", "=", "True", ")", "\n", "score", "=", "rouge", ".", "calc_score", "(", ")", "\n", "print", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.baselines.lead3_baseline.lead3_baseline": [[7, 38], ["print", "pythonrouge.pythonrouge.Pythonrouge", "pythonrouge.pythonrouge.Pythonrouge.calc_score", "print", "open", "fd.read().splitlines", "l.split", "doc.split.split", "abst.replace().split", "pred_str_bag.append", "ref_str_bag.append", "len", "fd.read", "enumerate", "abst.replace", "len", "len"], "function", ["None"], ["def", "lead3_baseline", "(", "path_file", ")", ":", "\n", "    ", "with", "open", "(", "path_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "pred_str_bag", ",", "ref_str_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "name", ",", "doc", ",", "abst", ",", "span_info", ",", "gold", "=", "l", ".", "split", "(", "'\\t'", ")", "\n", "doc", "=", "doc", ".", "split", "(", ")", "\n", "indices", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "doc", ")", "if", "x", "==", "\"@@SS@@\"", "]", "\n", "abs_str", "=", "abst", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\\n\"", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "abs_str", "=", "[", "x", "for", "x", "in", "abs_str", "if", "len", "(", "x", ")", ">", "1", "]", "\n", "if", "len", "(", "indices", ")", ">", "2", ":", "\n", "            ", "sent1", "=", "' '", ".", "join", "(", "doc", "[", ":", "indices", "[", "0", "]", "]", ")", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\"", ")", "\n", "sent2", "=", "' '", ".", "join", "(", "doc", "[", "indices", "[", "0", "]", ":", "indices", "[", "1", "]", "]", ")", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\"", ")", "\n", "sent3", "=", "' '", ".", "join", "(", "doc", "[", "indices", "[", "1", "]", ":", "indices", "[", "2", "]", "]", ")", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\"", ")", "\n", "lead3", "=", "[", "sent1", ",", "sent2", ",", "sent3", "]", "\n", "", "else", ":", "\n", "            ", "lead3", "=", "' '", ".", "join", "(", "doc", ")", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\\n\"", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "lead3", "=", "[", "x", "for", "x", "in", "lead3", "if", "len", "(", "x", ")", ">", "1", "]", "\n", "", "pred_str_bag", ".", "append", "(", "lead3", ")", "\n", "ref_str_bag", ".", "append", "(", "[", "abs_str", "]", ")", "\n", "", "print", "(", "'Finish reading'", ")", "\n", "rouge", "=", "Pythonrouge", "(", "summary_file_exist", "=", "False", ",", "\n", "summary", "=", "pred_str_bag", ",", "reference", "=", "ref_str_bag", ",", "\n", "n_gram", "=", "2", ",", "ROUGE_SU4", "=", "True", ",", "ROUGE_L", "=", "True", ",", "ROUGE_W", "=", "True", ",", "\n", "ROUGE_W_Weight", "=", "1.2", ",", "\n", "recall_only", "=", "False", ",", "stemming", "=", "True", ",", "stopwords", "=", "False", ",", "\n", "word_level", "=", "True", ",", "length_limit", "=", "False", ",", "length", "=", "50", ",", "\n", "use_cf", "=", "False", ",", "cf", "=", "95", ",", "scoring_formula", "=", "'average'", ",", "\n", "resampling", "=", "True", ",", "samples", "=", "1000", ",", "favor", "=", "True", ",", "p", "=", "0.5", ",", "default_conf", "=", "True", ")", "\n", "score", "=", "rouge", ".", "calc_score", "(", ")", "\n", "print", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.TreeNode.__init__": [[17, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ":", "str", ",", "text", ",", "children", ":", "List", ",", "depth", ":", "int", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "children", "=", "children", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "start_idx", "=", "-", "1", "\n", "self", ".", "end_idx", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.TreeNode.__repr__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Text: {}\\tTag:{}\\tDepth:{}\"", ".", "format", "(", "\" \"", ".", "join", "(", "self", ".", "text", ")", ",", "self", ".", "tag", ",", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.split_branch_of_cc": [[29, 48], ["enumerate", "create_oracle.TreeNode", "create_oracle.TreeNode", "list", "list", "itertools.chain", "itertools.chain"], "function", ["None"], ["", "", "def", "split_branch_of_cc", "(", "tree", ":", "TreeNode", ")", "->", "List", ":", "\n", "# where is cc", "\n", "    ", "left", ",", "right", "=", "0", ",", "0", "\n", "seg_idx", "=", "0", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "        ", "if", "c", ".", "tag", "==", "'CC'", ":", "\n", "            ", "left", "=", "c", ".", "start_idx", "\n", "right", "=", "c", ".", "end_idx", "\n", "seg_idx", "=", "idx", "\n", "break", "\n", "", "", "left_tree", "=", "TreeNode", "(", "tag", "=", "\"CC_branch\"", ",", "text", "=", "list", "(", "itertools", ".", "chain", "(", "[", "child", "for", "child", "in", "tree", ".", "children", "[", ":", "seg_idx", "+", "1", "]", "]", ")", ")", ",", "\n", "children", "=", "tree", ".", "children", "[", ":", "seg_idx", "+", "1", "]", ",", "depth", "=", "tree", ".", "depth", ")", "\n", "left_tree", ".", "start_idx", "=", "tree", ".", "start_idx", "\n", "left_tree", ".", "end_idx", "=", "right", "\n", "right_tree", "=", "TreeNode", "(", "tag", "=", "\"CC_branch\"", ",", "text", "=", "list", "(", "itertools", ".", "chain", "(", "[", "child", "for", "child", "in", "tree", ".", "children", "[", "seg_idx", ":", "]", "]", ")", ")", ",", "\n", "children", "=", "tree", ".", "children", "[", "seg_idx", ":", "]", ",", "depth", "=", "tree", ".", "depth", ")", "\n", "right_tree", ".", "start_idx", "=", "left", "\n", "right_tree", ".", "end_idx", "=", "tree", ".", "end_idx", "\n", "return", "[", "left_tree", ",", "right_tree", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.comp_oracle_delete_one_unit": [[50, 55], ["del_spans.sort"], "function", ["None"], ["", "def", "comp_oracle_delete_one_unit", "(", "tree", ":", "TreeNode", ",", "del_spans", ":", "List", ",", "topk", ")", ":", "\n", "    ", "del_spans", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "del_spans", "=", "del_spans", "[", ":", "topk", "]", "\n", "most_deletable", "=", "del_spans", "[", "0", "]", "# {[sidx][eidx][node][rouge]}", "\n", "return", "del_spans", ",", "most_deletable", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.find_deletable_span_rule_based": [[57, 75], ["any", "create_oracle.split_branch_of_cc", "create_oracle.find_deletable_span_rule_based"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.split_branch_of_cc", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based"], ["", "def", "find_deletable_span_rule_based", "(", "rule", ",", "tree", ":", "TreeNode", ")", "->", "List", "[", "TreeNode", "]", ":", "\n", "# Rule is a list with TAG names", "\n", "# return a list of TreeNodes which are deletable", "\n", "    ", "tag", "=", "tree", ".", "tag", "\n", "deletable_bag", "=", "[", "]", "\n", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "# CC", "\n", "        ", "flag_cc", "=", "any", "(", "[", "c", ".", "tag", "==", "'CC'", "for", "c", "in", "tree", ".", "children", "]", ")", "\n", "if", "flag_cc", ":", "\n", "            ", "deletable_bag", "+=", "split_branch_of_cc", "(", "tree", ")", "\n", "", "for", "child", "in", "tree", ".", "children", ":", "\n", "            ", "deletable_bag", "+=", "find_deletable_span_rule_based", "(", "rule", ",", "child", ")", "\n", "", "", "if", "tag", "in", "rule", ":", "\n", "        ", "deletable_bag", "+=", "[", "tree", "]", "\n", "", "if", "' '", ".", "join", "(", "tree", ".", "text", ")", "==", "'-LRB- CNN -RRB-'", ":", "\n", "        ", "deletable_bag", "+=", "[", "tree", "]", "\n", "\n", "", "return", "deletable_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.extract_parse": [[77, 81], ["None"], "function", ["None"], ["", "def", "extract_parse", "(", "snlp_dict", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff_parse", "=", "[", "s", "[", "'parse'", "]", "for", "s", "in", "sentences", "]", "\n", "return", "buff_parse", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.extract_tokens": [[83, 99], ["buff.append", "buff_str.append"], "function", ["None"], ["", "def", "extract_tokens", "(", "snlp_dict", ")", ":", "\n", "    ", "\"\"\"\n\n    :param snlp_dict:\n    :return: buff: List[List[str]]\n            string: a C B\\nD e f\\n...\n    \"\"\"", "\n", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff", "=", "[", "]", "\n", "buff_str", "=", "[", "]", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "tokens", "=", "s", "[", "\"tokens\"", "]", "\n", "tokens_list", "=", "[", "x", "[", "\"word\"", "]", "for", "x", "in", "tokens", "]", "\n", "buff", ".", "append", "(", "tokens_list", ")", "\n", "buff_str", ".", "append", "(", "\" \"", ".", "join", "(", "tokens_list", ")", ")", "\n", "", "return", "buff", ",", "\"\\n\"", ".", "join", "(", "buff_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.convert_document_to_read_ready_string": [[101, 214], ["os.path.join", "os.path.join", "json.loads", "json.loads", "create_oracle.extract_tokens", "rt_sentences.append", "neusum.data.generate_compression_based_data.comp_document_oracle", "json.dumps", "open", "fd.read", "open", "fd.read", "create_oracle.extract_parse", "create_oracle.read_single_parse_tree", "len", "create_oracle.find_deletable_span_rule_based", "rt_del_spans.append", "create_oracle.comp_oracle_delete_one_unit", "rt_sentences.append", "open", "fd.write", "os.path.isfile", "os.path.isfile", "set", "list", "list.sort", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "os.path.join", "len", "range", "len", "rt_del_spans.append", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "list", "len", "set", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_oracle_delete_one_unit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram"], ["", "def", "convert_document_to_read_ready_string", "(", "path_read", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", ",", "\n", "grammar", ",", "rules", "=", "None", ",", "max_sent", "=", "40", ",", "data_name", "=", "'dm'", ",", "merge_sz", "=", "5", ",", "depth", "=", "3", ",", "\n", "topk", "=", "10", ",", "\n", "set_of_del", "=", "[", "1", ",", "2", "]", ")", ":", "\n", "    ", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "with", "open", "(", "doc_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "doc_str", "=", "fd", ".", "read", "(", ")", "\n", "", "with", "open", "(", "abs_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "abs_str", "=", "fd", ".", "read", "(", ")", "\n", "\n", "", "doc_dict", "=", "json", ".", "loads", "(", "doc_str", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "abs_str", ")", "\n", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "[", ":", "max_sent", "]", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "\n", "rt_sentences", "=", "[", "]", "\n", "\n", "# dft = CompressionSpan(sidx=0, eidx=1, node=\"BASELINE\", rouge=0, selected_idx=[])", "\n", "dft", "=", "{", "\"sidx\"", ":", "0", ",", "'eidx'", ":", "1", ",", "'node'", ":", "\"BASELINE\"", ",", "'rouge'", ":", "0", ",", "'selected_idx'", ":", "[", "]", "}", "\n", "# <SOS> Used for pred the end of decoding", "\n", "# sent_sos_dict = SentDataWithOracle(token=[\"<SOS>\"],del_span= [dft],single_del=[dft],single_del_best=dft)", "\n", "sent_sos_dict", "=", "{", "'token'", ":", "[", "\"<SOS>\"", "]", ",", "'del_span'", ":", "[", "dft", "]", ",", "'single_del'", ":", "[", "dft", "]", ",", "'single_del_best'", ":", "dft", "}", "\n", "\n", "rt_sentences", ".", "append", "(", "sent_sos_dict", ")", "\n", "\n", "for", "sent_parse", "in", "doc_parse", ":", "\n", "\n", "        ", "sent_tree", "=", "read_single_parse_tree", "(", "sent_parse", ")", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "rt_del_spans", "=", "[", "]", "\n", "del_spans", "=", "find_deletable_span_rule_based", "(", "rules", ",", "sent_tree", ")", "\n", "\n", "# List of tree nodes", "\n", "for", "del_sp", "in", "del_spans", ":", "\n", "            ", "if", "len", "(", "del_sp", ".", "text", ")", "<", "2", ":", "# ASSUM", "\n", "                ", "continue", "\n", "", "full_set", "=", "set", "(", "range", "(", "len", "(", "sent_tree", ".", "text", ")", ")", ")", "\n", "selected_set", "=", "list", "(", "full_set", "-", "set", "(", "range", "(", "del_sp", ".", "start_idx", ",", "del_sp", ".", "end_idx", ")", ")", ")", "\n", "selected_set", ".", "sort", "(", ")", "\n", "text_left", "=", "sent_tree", ".", "text", "[", "0", ":", "del_sp", ".", "start_idx", "]", "+", "sent_tree", ".", "text", "[", "del_sp", ".", "end_idx", ":", "]", "\n", "_txt", "=", "\" \"", ".", "join", "(", "text_left", ")", "\n", "_rouge1", "=", "get_rouge_est_str_4gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "_txt", ")", "\n", "# to prevent nothing to compress, always add the whole sentence itself to the del list?", "\n", "if", "len", "(", "selected_set", ")", ">=", "2", ":", "# TODO you have to keep something   ASSUM", "\n", "# rt_del_spans.append(CompressionSpan(sidx=del_sp.start_idx, eidx=del_sp.end_idx,", "\n", "#                                     node=del_sp.tag, rouge=_rouge1, selected_idx=selected_set))", "\n", "                ", "rt_del_spans", ".", "append", "(", "\n", "{", "'sidx'", ":", "del_sp", ".", "start_idx", ",", "'eidx'", ":", "del_sp", ".", "end_idx", ",", "'node'", ":", "del_sp", ".", "tag", ",", "'rouge'", ":", "_rouge1", ",", "\n", "'selected_idx'", ":", "selected_set", "}", ")", "\n", "", "", "rt_del_spans", ".", "append", "(", "{", "'sidx'", ":", "tree_len", "-", "1", ",", "'eidx'", ":", "tree_len", ",", "\n", "'node'", ":", "\"BASELINE\"", ",", "'rouge'", ":", "get_rouge_est_str_4gram", "(", "\n", "gold", "=", "abs_str", ",", "pred", "=", "\" \"", ".", "join", "(", "sent_tree", ".", "text", "[", ":", "-", "1", "]", ")", ")", ",", "'selected_idx'", ":", "list", "(", "range", "(", "tree_len", "-", "1", ")", ")", "}", ")", "\n", "\n", "# del_multi_units, most_trash_multi_unit = comp_oracle_delete_multiple_unit(abs_str, sent_tree, rt_del_spans,", "\n", "#                                                                           topk)  # delete multi and best delete multi", "\n", "\n", "# delete 1 and best delete 1", "\n", "del_single_units", ",", "most_trash_single_unit", "=", "comp_oracle_delete_one_unit", "(", "sent_tree", ",", "rt_del_spans", ",", "topk", ")", "\n", "# TODO", "\n", "# sent_pack = SentDataWithOracle(sent_tree.text, del_span=rt_del_spans, single_del=del_single_units,", "\n", "#                                single_del_best=most_trash_single_unit)", "\n", "sent_pack", "=", "{", "\"token\"", ":", "sent_tree", ".", "text", ",", "\"del_span\"", ":", "rt_del_spans", ",", "\n", "\"single_del\"", ":", "del_single_units", ",", "\"single_del_best\"", ":", "most_trash_single_unit", ",", "\n", "}", "\n", "rt_sentences", ".", "append", "(", "sent_pack", ")", "\n", "# print(\"Finding Oracle ...\")", "\n", "# Sentence Level Oracle", "\n", "", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "rt_sentences", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list", ",", "abs_str", ")", "\n", "#", "\n", "\n", "# Subsentence Level Oracle", "\n", "# doc_list_trimmed_for_oracle = []", "\n", "# for x in rt_sentences:", "\n", "#     doc_list_trimmed_for_oracle.append(\" \".join([x['token'][kdx] for kdx in x['single_del_best']['selected_idx']]))", "\n", "# trim_ora_json = comp_document_oracle(doc_list_trimmed_for_oracle, abs_str)", "\n", "# print(\"Oracle found\")", "\n", "# Return the datapack", "\n", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "rt", "[", "'part'", "]", "=", "data_name", "\n", "# span_pairs = gen_span_segmentation([x['token'] for x in rt_sentences])", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_list\"", "]", "=", "abs_token", "\n", "rt", "[", "\"doc\"", "]", "=", "\" \"", ".", "join", "(", "doc_list", ")", "\n", "rt", "[", "\"doc_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "rt_sentences", "]", "\n", "rt", "[", "\"sentences\"", "]", "=", "rt_sentences", "\n", "\n", "# rt[\"sent_oracle\"] = trim_ora_json", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "sent_ora_json", "\n", "# rt[\"sent_oracle_trim\"] = trim_ora_json", "\n", "\n", "# output format: document{ name:str,", "\n", "# '<SOS>' + @@SS@@'.join tokens_all, sentence segmentation span,", "\n", "# sentences:[", "\n", "# start idx,", "\n", "# end idx,", "\n", "# token list,", "\n", "# deletable spans:[relative startidx in the sentence, relative endidx, nodetype, rouge(slot kept)],", "\n", "# what if nothing deletable?  always add the the whole sentence", "\n", "# top k  trimed version (multiple oracle) [ combination of deletable spans]", "\n", "# oracle: sentence level oracle (n of n)", "\n", "#           trimed sentence level (n of n)", "\n", "# TODO compression version: [ tokens+license+rouge(slot), tokens+license+rouge,... ]", "\n", "# TODO or trash candidate : [tokens+rouge,...]", "\n", "#  ] }", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.return_childrens": [[216, 233], ["enumerate", "buff.append", "rt_list.append"], "function", ["None"], ["", "", "def", "return_childrens", "(", "inp", ":", "str", ")", "->", "List", ":", "\n", "    ", "dep", "=", "0", "\n", "rt_list", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "inp", ")", ":", "\n", "        ", "if", "c", "==", "'('", ":", "\n", "            ", "dep", "+=", "1", "\n", "", "elif", "c", "==", "')'", ":", "\n", "            ", "dep", "-=", "1", "\n", "", "if", "buff", "==", "[", "]", "and", "c", "==", "\" \"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "buff", ".", "append", "(", "c", ")", "\n", "", "if", "dep", "==", "0", "and", "buff", "!=", "[", "]", ":", "\n", "            ", "rt_list", ".", "append", "(", "\"\"", ".", "join", "(", "buff", ")", ")", "\n", "buff", "=", "[", "]", "\n", "", "", "return", "rt_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.parse_subtree": [[235, 254], ["inp_str.find", "inp_str.rfind", "inp_str.find", "create_oracle.TreeNode", "create_oracle.return_childrens", "create_oracle.parse_subtree", "child.strip"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.return_childrens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree"], ["", "def", "parse_subtree", "(", "inp_str", ":", "str", ",", "depth", ":", "int", ")", ":", "\n", "# print(inp_str)", "\n", "    ", "index_lb", "=", "inp_str", ".", "find", "(", "\"(\"", ")", "\n", "index_rb", "=", "inp_str", ".", "rfind", "(", "\")\"", ")", "\n", "idex_split_of_tag_children", "=", "inp_str", ".", "find", "(", "\" \"", ")", "\n", "tag", "=", "inp_str", "[", "index_lb", "+", "1", ":", "idex_split_of_tag_children", "]", "\n", "child", "=", "inp_str", "[", "idex_split_of_tag_children", "+", "1", ":", "index_rb", "]", "\n", "if", "\"(\"", "in", "child", ":", "\n", "        ", "children_list", "=", "return_childrens", "(", "child", ")", "# (NP   =>(x x) (x x) (x x)<=)", "\n", "children_node", "=", "[", "parse_subtree", "(", "x", ",", "depth", "+", "1", ")", "for", "x", "in", "children_list", "]", "\n", "txt_buff", "=", "[", "]", "\n", "for", "n", "in", "children_node", ":", "\n", "            ", "txt_buff", "+=", "n", ".", "text", "\n", "", "text", "=", "txt_buff", "\n", "", "else", ":", "\n", "# reach leaf node", "\n", "        ", "text", "=", "[", "child", ".", "strip", "(", ")", "]", "\n", "children_node", "=", "None", "\n", "", "return", "TreeNode", "(", "tag", "=", "tag", ",", "text", "=", "text", ",", "children", "=", "children_node", ",", "depth", "=", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.read_single_parse_tree": [[256, 269], ["re.sub.replace", "re.sub", "create_oracle.parse_subtree", "create_oracle.add_idx_of_tree", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "def", "read_single_parse_tree", "(", "inp_str", ")", "->", "TreeNode", ":", "\n", "    ", "\"\"\"\n    Given a string from stanfordnlp, convert to a tree.\n    :param inp_str: (ROOT\\n  (FRAG\\n    (NP (NN NEW))\\n ....\n    :return:\n    \"\"\"", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "# inp_str = re.split('\\(|\\)|\\s', inp_str)", "\n", "inp_str", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "inp_str", ")", "\n", "# inp = inp.split(\" \")", "\n", "out", "=", "parse_subtree", "(", "inp_str", ",", "depth", "=", "0", ")", "\n", "out", "=", "add_idx_of_tree", "(", "out", ",", "start_idx", "=", "0", ",", "end_idx", "=", "len", "(", "out", ".", "text", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.create_oracle.add_idx_of_tree": [[271, 284], ["len", "new_children.append", "create_oracle.add_idx_of_tree"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "def", "add_idx_of_tree", "(", "tree", ":", "TreeNode", ",", "start_idx", ":", "int", ",", "end_idx", ":", "int", ")", ":", "\n", "    ", "tree", ".", "start_idx", "=", "start_idx", "\n", "tree", ".", "end_idx", "=", "end_idx", "\n", "if", "not", "tree", ".", "children", ":", "\n", "        ", "return", "tree", "\n", "", "cur_start", "=", "start_idx", "\n", "new_children", "=", "[", "]", "\n", "for", "child", "in", "tree", ".", "children", ":", "\n", "        ", "span_len", "=", "len", "(", "child", ".", "text", ")", "\n", "new_children", ".", "append", "(", "add_idx_of_tree", "(", "child", ",", "start_idx", "=", "cur_start", ",", "end_idx", "=", "cur_start", "+", "span_len", ")", ")", "\n", "cur_start", "+=", "span_len", "\n", "", "tree", ".", "children", "=", "new_children", "\n", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx": [[26, 31], ["_tmp.append"], "function", ["None"], ["def", "assemble_doc_list_from_idx", "(", "doc", ",", "idxs", ")", ":", "\n", "    ", "_tmp", "=", "[", "]", "\n", "for", "i", "in", "idxs", ":", "\n", "        ", "_tmp", ".", "append", "(", "doc", "[", "i", "]", ")", "\n", "", "return", "_tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_oracle_combination": [[33, 40], ["None"], "function", ["None"], ["", "def", "comp_oracle_combination", "(", "_filtered_doc_list", ",", "\n", "_num_edu", ",", "\n", "_absas_read_str", ",", "\n", "abs_as_read_list", ",", "\n", "map_from_new_to_ori_idx", ",", "\n", "beam_sz", "=", "4", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam": [[42, 168], ["list", "beam.append", "range", "len", "range", "sorted", "n_comb.sort", "n_comb_original.sort", "generate_oracle_with_dplp.assemble_doc_list_from_idx", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "len", "len", "sorted", "int", "sorted", "generate_oracle_with_dplp.assemble_doc_list_from_idx", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "new_in.sort", "todo.copy", "todo.copy.remove", "global_board.append", "str", "beam_waitlist.append", "check_dict.append", "_comb_bag.keys", "sorted", "str"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.assemble_doc_list_from_idx", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram"], ["", "def", "comp_num_seg_out_of_p_sent_beam", "(", "_filtered_doc_list", ",", "\n", "_num_edu", ",", "\n", "_absas_read_str", ",", "\n", "abs_as_read_list", ",", "\n", "map_from_new_to_ori_idx", ",", "\n", "beam_sz", "=", "8", ")", ":", "\n", "    ", "beam", "=", "[", "]", "\n", "if", "len", "(", "_filtered_doc_list", ")", "<=", "_num_edu", ":", "\n", "        ", "return", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "{", "}", ",", "\n", "\"best\"", ":", "None", "\n", "}", "\n", "\n", "", "combs", "=", "list", "(", "range", "(", "1", ",", "len", "(", "_filtered_doc_list", ")", ")", ")", "## TODO should be 1 because SOS as the first sentence", "\n", "# _num_edu seq_len", "\n", "cur_beam", "=", "{", "\n", "\"in\"", ":", "[", "]", ",", "\n", "\"todo\"", ":", "combs", ",", "\n", "\"val\"", ":", "0", "\n", "}", "\n", "beam", ".", "append", "(", "cur_beam", ")", "\n", "for", "t", "in", "range", "(", "_num_edu", ")", ":", "\n", "        ", "dict_pattern", "=", "{", "}", "\n", "# compute top beam_sz for every beam", "\n", "global_board", "=", "[", "]", "\n", "for", "b", "in", "beam", ":", "\n", "            ", "already_in_beam", "=", "b", "[", "'in'", "]", "\n", "todo", "=", "b", "[", "'todo'", "]", "\n", "\n", "leaderboard", "=", "{", "}", "\n", "for", "to_add", "in", "todo", ":", "\n", "                ", "after_add", "=", "already_in_beam", "+", "[", "to_add", "]", "\n", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "after_add", ")", "\n", "_tmp", "=", "'\\n'", ".", "join", "(", "_tmp", ")", "\n", "average_f_score", "=", "get_rouge_est_str_4gram", "(", "_absas_read_str", ",", "_tmp", ")", "\n", "\n", "leaderboard", "[", "to_add", "]", "=", "average_f_score", "\n", "", "sorted_beam", "=", "[", "(", "k", ",", "leaderboard", "[", "k", "]", ")", "for", "k", "in", "sorted", "(", "leaderboard", ",", "key", "=", "leaderboard", ".", "get", ",", "reverse", "=", "True", ")", "]", "\n", "\n", "for", "it", "in", "sorted_beam", ":", "\n", "                ", "new_in", "=", "already_in_beam", "+", "[", "it", "[", "0", "]", "]", "\n", "new_in", ".", "sort", "(", ")", "\n", "str_new_in", "=", "[", "str", "(", "x", ")", "for", "x", "in", "new_in", "]", "\n", "if", "'_'", ".", "join", "(", "str_new_in", ")", "in", "dict_pattern", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "dict_pattern", "[", "'_'", ".", "join", "(", "str_new_in", ")", "]", "=", "True", "\n", "", "new_list", "=", "todo", ".", "copy", "(", ")", "\n", "new_list", ".", "remove", "(", "it", "[", "0", "]", ")", "\n", "# rank_actual_idx = sort_idx_map[it[0]]", "\n", "# new list", "\n", "# if rank_actual_idx + 1 == len(_filtered_doc_list):", "\n", "#     continue", "\n", "# it[0] is the index in combs = index in filter_doc_list", "\n", "# sort_idx_map ====> the rank in original document", "\n", "# new_list only contains stuff have larger rank than rank_actual_idx", "\n", "# for _i, _rank in enumerate(sort_idx_map):", "\n", "#     if _rank > rank_actual_idx:", "\n", "#         new_list.append(combs[_i])", "\n", "# assert len(new_list) != 0", "\n", "_beam", "=", "{", "\n", "\"in\"", ":", "new_in", ",", "\n", "\"todo\"", ":", "new_list", ",", "\n", "\"val\"", ":", "it", "[", "1", "]", "\n", "}", "\n", "global_board", ".", "append", "(", "_beam", ")", "\n", "# merge and get the top beam_sz among all", "\n", "\n", "", "", "sorted_global_board", "=", "sorted", "(", "global_board", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"val\"", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "_cnt", "=", "0", "\n", "check_dict", "=", "[", "]", "\n", "beam_waitlist", "=", "[", "]", "\n", "for", "it", "in", "sorted_global_board", ":", "\n", "            ", "str_in", "=", "sorted", "(", "it", "[", "'in'", "]", ")", "\n", "str_in", "=", "[", "str", "(", "x", ")", "for", "x", "in", "str_in", "]", "\n", "_tmp_key", "=", "'_'", ".", "join", "(", "str_in", ")", "\n", "if", "_tmp_key", "in", "check_dict", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "beam_waitlist", ".", "append", "(", "it", ")", "\n", "check_dict", ".", "append", "(", "_tmp_key", ")", "\n", "", "_cnt", "+=", "1", "\n", "if", "_cnt", ">=", "beam_sz", ":", "\n", "                ", "break", "\n", "", "", "beam", "=", "beam_waitlist", "\n", "# if len(beam) < 2:", "\n", "#     print(len(_filtered_doc_list))", "\n", "#     print(_num_edu)", "\n", "# Write oracle to a string like: 0.4 0.3 0.4", "\n", "", "_comb_bag", "=", "{", "}", "\n", "for", "it", "in", "beam", ":", "\n", "        ", "n_comb", "=", "it", "[", "'in'", "]", "\n", "n_comb", ".", "sort", "(", ")", "\n", "n_comb_original", "=", "[", "map_from_new_to_ori_idx", "[", "a", "]", "for", "a", "in", "n_comb", "]", "\n", "n_comb_original", ".", "sort", "(", ")", "# json label", "\n", "n_comb_original", "=", "[", "int", "(", "x", ")", "for", "x", "in", "n_comb_original", "]", "\n", "# print(n_comb_original)", "\n", "_tmp", "=", "assemble_doc_list_from_idx", "(", "_filtered_doc_list", ",", "n_comb", ")", "\n", "# score = rouge_protocol([[_tmp]], [[abs_as_read_list]])", "\n", "_tmp", "=", "'\\n'", ".", "join", "(", "_tmp", ")", "\n", "f1", "=", "get_rouge_est_str_4gram", "(", "_absas_read_str", ",", "_tmp", ")", "\n", "\n", "# f1 = score['ROUGE-1-F']", "\n", "# f2 = score['ROUGE-2-F']", "\n", "# fl = score['ROUGE-L-F']", "\n", "# f_avg = (f1 + f2 + fl) / 3", "\n", "_comb_bag", "[", "f1", "]", "=", "{", "\"label\"", ":", "n_comb_original", ",", "\n", "\"R1\"", ":", "f1", ",", "\n", "# \"R2\": f2,", "\n", "# \"RL\": fl,", "\n", "# \"R\": f_avg,", "\n", "\"nlabel\"", ":", "_num_edu", "}", "\n", "# print(len(_comb_bag))", "\n", "", "if", "len", "(", "_comb_bag", ")", "==", "0", ":", "\n", "        ", "return", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "{", "}", ",", "\n", "\"best\"", ":", "None", "\n", "}", "\n", "", "else", ":", "\n", "        ", "best_key", "=", "sorted", "(", "_comb_bag", ".", "keys", "(", ")", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "rt_dict", "=", "{", "\"nlabel\"", ":", "_num_edu", ",", "\n", "\"data\"", ":", "_comb_bag", ",", "\n", "\"best\"", ":", "_comb_bag", "[", "best_key", "]", "\n", "}", "\n", "return", "rt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.sent_oracle": [[170, 254], ["len", "doc_list.insert", "abs_str.replace", "range", "range", "json.dumps", "d.strip", "d.replace().strip", "d.replace", "len", "span.append", "span.append", "f_score_full.append", "f_score_list.append", "numpy.argsort", "len", "filtered_doc_list.append", "map_from_new_to_ori_idx.append", "len", "abs_str.split", "d.split", "str", "str", "neusum.evaluation.rough_rouge.get_rouge_est_str_2gram", "rouge_protocol", "generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam", "d.replace", "len", "int", "d.split", "rt_doc.split"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.rouge_protocol", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam"], ["", "", "def", "sent_oracle", "(", "doc_list", ":", "List", ",", "abs_str", ",", "name", ",", "path_write_data", ",", "\n", "use_beam", "=", "True", ",", "approx_rouge_filter", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n\n    :param doc_list: List of strings. all \\n are represented as @@SS@@\n    :param abs_str: a single string will \\n\n    :param name:\n    :return:\n    \"\"\"", "\n", "# print(name)", "\n", "# print(time.localtime())", "\n", "doc_list", "=", "[", "d", ".", "strip", "(", ")", "for", "d", "in", "doc_list", "]", "# trim", "\n", "for", "d", "in", "doc_list", ":", "\n", "        ", "assert", "len", "(", "d", ")", ">", "0", "\n", "", "len_of_doc", "=", "len", "(", "doc_list", ")", "\n", "doc_list", ".", "insert", "(", "0", ",", "\"<SOS>\"", ")", "\n", "doc_as_readable_list", "=", "[", "d", ".", "replace", "(", "\"@@SS@@\"", ",", "\"\"", ")", ".", "strip", "(", ")", "for", "d", "in", "doc_list", "]", "\n", "abs_as_readable_list", "=", "[", "x", "for", "x", "in", "abs_str", ".", "split", "(", "\"\\n\"", ")", "if", "(", "x", "!=", "\"\"", ")", "and", "(", "x", "!=", "\" \"", ")", "]", "# no SS and \\n", "\n", "\n", "doc_list", "=", "[", "d", ".", "replace", "(", "'\\n'", ",", "'@@SS@@'", ")", "for", "d", "in", "doc_list", "]", "\n", "doc_list", "=", "[", "\" \"", ".", "join", "(", "d", ".", "split", "(", ")", ")", "for", "d", "in", "doc_list", "]", "\n", "rt_doc", "=", "' '", ".", "join", "(", "doc_list", ")", "\n", "# abs_str = abs_str.replace('\\n', '@@SS@@')", "\n", "rt_abs", "=", "abs_str", ".", "replace", "(", "'\\n'", ",", "'@@SS@@'", ")", "\n", "# print(len(rt_doc.split(\" \")))", "\n", "\n", "span", "=", "[", "]", "\n", "jdx", "=", "0", "\n", "for", "d", "in", "doc_list", ":", "\n", "        ", "num", "=", "len", "(", "[", "x", "for", "x", "in", "d", ".", "split", "(", "' '", ")", "if", "x", "!=", "''", "]", ")", "\n", "span", ".", "append", "(", "str", "(", "jdx", ")", ")", "\n", "span", ".", "append", "(", "str", "(", "jdx", "+", "num", "-", "1", ")", ")", "\n", "jdx", "+=", "num", "\n", "", "assert", "(", "len", "(", "rt_doc", ".", "split", "(", "\" \"", ")", ")", "-", "int", "(", "span", "[", "-", "1", "]", ")", "-", "1", ")", "==", "0", "\n", "# return None", "\n", "span_str", "=", "' '", ".", "join", "(", "span", ")", "\n", "f_score_list", "=", "[", "]", "\n", "f_score_full", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len_of_doc", ")", ":", "\n", "        ", "if", "approx_rouge_filter", ":", "\n", "            ", "average_f_score", ",", "f1", ",", "f2", ",", "fl", "=", "get_rouge_est_str_2gram", "(", "gold", "=", "'\\n'", ".", "join", "(", "abs_as_readable_list", ")", ",", "\n", "pred", "=", "doc_as_readable_list", "[", "i", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "score", "=", "rouge_protocol", "(", "[", "[", "doc_as_readable_list", "[", "i", "]", "]", "]", ",", "[", "[", "abs_as_readable_list", "]", "]", ")", "\n", "f1", "=", "score", "[", "'ROUGE-1-F'", "]", "\n", "f2", "=", "score", "[", "'ROUGE-2-F'", "]", "\n", "fl", "=", "score", "[", "'ROUGE-L-F'", "]", "\n", "\n", "", "f_score_full", ".", "append", "(", "[", "f1", ",", "f2", ",", "fl", "]", ")", "\n", "f_score_list", ".", "append", "(", "f1", "+", "f2", "+", "fl", ")", "\n", "", "top_p_sent_idx", "=", "numpy", ".", "argsort", "(", "f_score_list", ")", "[", "-", "P_SENT", ":", "]", "\n", "\n", "map_from_new_to_ori_idx", "=", "[", "]", "\n", "# filter", "\n", "filtered_doc_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "top_p_sent_idx", ")", ")", ":", "\n", "        ", "filtered_doc_list", ".", "append", "(", "doc_as_readable_list", "[", "top_p_sent_idx", "[", "i", "]", "]", ")", "\n", "map_from_new_to_ori_idx", ".", "append", "(", "top_p_sent_idx", "[", "i", "]", ")", "\n", "\n", "# filter_doc_list stores filtered doc", "\n", "# map_from_new_to_ori_idx contains their original index", "\n", "", "combination_data_dict", "=", "{", "}", "\n", "for", "num_of_edu", "in", "NUM_EDU", ":", "\n", "        ", "if", "use_beam", ":", "\n", "            ", "combination_data", "=", "comp_num_seg_out_of_p_sent_beam", "(", "_filtered_doc_list", "=", "filtered_doc_list", ",", "\n", "_num_edu", "=", "num_of_edu", ",", "\n", "_absas_read_str", "=", "abs_str", ",", "\n", "abs_as_read_list", "=", "abs_as_readable_list", ",", "\n", "map_from_new_to_ori_idx", "=", "map_from_new_to_ori_idx", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# combination_data = comp_num_seg_out_of_p_sent(_filtered_doc_list=filtered_doc_list, _num_edu=num_of_edu,", "\n", "#                                               _absas_read_str=abs_str,", "\n", "#                                               abs_as_read_list=abs_as_readable_list,", "\n", "#                                               map_from_new_to_ori_idx=map_from_new_to_ori_idx)", "\n", "", "combination_data_dict", "[", "num_of_edu", "]", "=", "combination_data", "\n", "", "json_str", "=", "json", ".", "dumps", "(", "combination_data_dict", ")", "\n", "rt", "=", "'\\t'", ".", "join", "(", "[", "name", ",", "rt_doc", ",", "rt_abs", ",", "span_str", ",", "json_str", "]", ")", "\n", "\n", "# with open(os.path.join(path_write_data, name + '.txt'), 'w') as fd:", "\n", "#     fd.write(rt)", "\n", "\n", "return", "rt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.truncate_doc_list": [[259, 268], ["enumerate", "bag.append", "bag.append"], "function", ["None"], ["def", "truncate_doc_list", "(", "_max_edu_num", ",", "doc", ")", ":", "\n", "    ", "bag", "=", "[", "]", "\n", "for", "idx", ",", "content", "in", "enumerate", "(", "doc", ")", ":", "\n", "        ", "if", "idx", ">=", "_max_edu_num", ":", "\n", "            ", "if", "\"@@SS@@\"", "in", "content", ":", "\n", "                ", "bag", ".", "append", "(", "content", ")", "\n", "break", "\n", "", "", "bag", ".", "append", "(", "content", ")", "\n", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.convert_edu_doc_to_sent_doc": [[270, 285], ["enumerate", "bag.append", "buff.append", "bag.append", "buff.append"], "function", ["None"], ["", "def", "convert_edu_doc_to_sent_doc", "(", "doc", ")", ":", "\n", "    ", "buff", "=", "[", "]", "\n", "bag", "=", "[", "]", "\n", "for", "i", ",", "content", "in", "enumerate", "(", "doc", ")", ":", "\n", "        ", "if", "'@@SS@@'", "in", "content", ":", "\n", "            ", "buff", ".", "append", "(", "content", ")", "\n", "buff", "=", "' '", ".", "join", "(", "buff", ")", "\n", "bag", ".", "append", "(", "buff", ")", "\n", "buff", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "buff", ".", "append", "(", "content", ")", "\n", "", "", "if", "buff", "!=", "[", "]", ":", "\n", "        ", "buff", "=", "' '", ".", "join", "(", "buff", ")", "\n", "bag", ".", "append", "(", "buff", ")", "\n", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_sent_ora": [[287, 327], ["os.listdir", "os.listdir", "enumerate", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "len", "len", "neusum.service.basic_service.read_merge_span", "generate_oracle_with_dplp.convert_edu_doc_to_sent_doc", "generate_oracle_with_dplp.truncate_doc_list", "neusum.service.basic_service.read_merge_simple", "bag_doc.append", "bag_abs.append", "bag_name.append", "len", "len", "len", "len", "zip", "open", "fd.write", "f.endswith", "f.endswith", "fdoc.split", "os.path.join", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_span", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.convert_edu_doc_to_sent_doc", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.truncate_doc_list", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_simple"], ["", "def", "comp_sent_ora", "(", "single_file", ",", "max_edu_num", ",", "beam", ",", "path_doc", ",", "path_abs", ",", "path_write_data", ")", ":", "\n", "    ", "doc_files", "=", "os", ".", "listdir", "(", "path_doc", ")", "\n", "f_docs", "=", "[", "f", "for", "f", "in", "doc_files", "if", "f", ".", "endswith", "(", "'.doc.merge'", ")", "]", "\n", "\n", "abs_files", "=", "os", ".", "listdir", "(", "path_abs", ")", "\n", "f_abss", "=", "[", "f", "for", "f", "in", "abs_files", "if", "f", ".", "endswith", "(", "'.abs.merge'", ")", "]", "\n", "\n", "assert", "len", "(", "f_docs", ")", "==", "len", "(", "f_abss", ")", "\n", "\n", "bag_abs", "=", "[", "]", "\n", "bag_doc", "=", "[", "]", "\n", "bag_name", "=", "[", "]", "\n", "# f_docs = f_docs[:100]", "\n", "for", "j", ",", "fdoc", "in", "enumerate", "(", "f_docs", ")", ":", "\n", "# print(j)", "\n", "        ", "name", "=", "fdoc", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "doc_spans", ",", "doc_sent_idx", "=", "read_merge_span", "(", "os", ".", "path", ".", "join", "(", "path_doc", ",", "fdoc", ")", ")", "\n", "doc_spans", "=", "convert_edu_doc_to_sent_doc", "(", "doc_spans", ")", "\n", "doc_spans", "=", "truncate_doc_list", "(", "max_edu_num", ",", "doc_spans", ")", "\n", "doc_spans", "=", "[", "s", "for", "s", "in", "doc_spans", "if", "len", "(", "s", ")", ">", "0", "]", "\n", "inp_abs_str", "=", "read_merge_simple", "(", "os", ".", "path", ".", "join", "(", "path_abs", ",", "name", "+", "'.abs.merge'", ")", ")", "\n", "\n", "bag_doc", ".", "append", "(", "doc_spans", ")", "\n", "bag_abs", ".", "append", "(", "inp_abs_str", ")", "\n", "bag_name", ".", "append", "(", "name", ")", "\n", "\n", "# f = sent_oracle(doc_spans, inp_abs_str, name, path_write_data)", "\n", "\n", "", "bag_path_write_data", "=", "[", "path_write_data", "]", "*", "len", "(", "bag_name", ")", "\n", "bag_beam", "=", "[", "beam", "]", "*", "len", "(", "bag_name", ")", "\n", "assert", "len", "(", "bag_doc", ")", "==", "len", "(", "bag_abs", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pairs", "=", "pool", ".", "starmap", "(", "sent_oracle", ",", "zip", "(", "bag_doc", ",", "bag_abs", ",", "bag_name", ",", "bag_path_write_data", ",", "bag_beam", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "pairs", "=", "[", "p", "for", "p", "in", "pairs", "if", "p", "is", "not", "None", "]", "\n", "print", "(", "'Final Stage'", ")", "\n", "with", "open", "(", "single_file", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "'\\n'", ".", "join", "(", "pairs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_edu_ora": [[329, 370], ["os.listdir", "os.listdir", "time.time", "enumerate", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "len", "len", "neusum.service.basic_service.read_merge_span", "generate_oracle_with_dplp.truncate_doc_list", "neusum.service.basic_service.read_merge_simple", "bag_doc.append", "bag_abs.append", "bag_name.append", "len", "len", "len", "len", "zip", "open", "fd.write", "f.endswith", "f.endswith", "fdoc.split", "os.path.join", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_span", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.truncate_doc_list", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.read_merge_simple"], ["", "", "def", "comp_edu_ora", "(", "single_file", ",", "max_edu_num", ",", "beam", ",", "path_doc", ",", "path_abs", ",", "path_write_data", ")", ":", "\n", "    ", "doc_files", "=", "os", ".", "listdir", "(", "path_doc", ")", "\n", "f_docs", "=", "[", "f", "for", "f", "in", "doc_files", "if", "f", ".", "endswith", "(", "'.doc.merge'", ")", "]", "\n", "\n", "abs_files", "=", "os", ".", "listdir", "(", "path_abs", ")", "\n", "f_abss", "=", "[", "f", "for", "f", "in", "abs_files", "if", "f", ".", "endswith", "(", "'.abs.merge'", ")", "]", "\n", "\n", "assert", "len", "(", "f_docs", ")", "==", "len", "(", "f_abss", ")", "\n", "\n", "bag_abs", "=", "[", "]", "\n", "bag_doc", "=", "[", "]", "\n", "bag_name", "=", "[", "]", "\n", "f1_bag", ",", "f2_bag", ",", "fl_bag", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# f_docs = f_docs[:100]", "\n", "for", "j", ",", "fdoc", "in", "enumerate", "(", "f_docs", ")", ":", "\n", "# print(j)", "\n", "        ", "name", "=", "fdoc", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "doc_spans", ",", "doc_sent_idx", "=", "read_merge_span", "(", "os", ".", "path", ".", "join", "(", "path_doc", ",", "fdoc", ")", ")", "\n", "doc_spans", "=", "truncate_doc_list", "(", "max_edu_num", ",", "doc_spans", ")", "\n", "doc_spans", "=", "[", "s", "for", "s", "in", "doc_spans", "if", "len", "(", "s", ")", ">", "3", "]", "\n", "inp_abs_str", "=", "read_merge_simple", "(", "os", ".", "path", ".", "join", "(", "path_abs", ",", "name", "+", "'.abs.merge'", ")", ")", "\n", "\n", "bag_doc", ".", "append", "(", "doc_spans", ")", "\n", "bag_abs", ".", "append", "(", "inp_abs_str", ")", "\n", "bag_name", ".", "append", "(", "name", ")", "\n", "\n", "# f = sent_oracle(doc_spans, inp_abs_str, name, path_write_data)", "\n", "\n", "", "bag_path_write_data", "=", "[", "path_write_data", "]", "*", "len", "(", "bag_name", ")", "\n", "bag_beam", "=", "[", "beam", "]", "*", "len", "(", "bag_name", ")", "\n", "assert", "len", "(", "bag_doc", ")", "==", "len", "(", "bag_abs", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pairs", "=", "pool", ".", "starmap", "(", "sent_oracle", ",", "zip", "(", "bag_doc", ",", "bag_abs", ",", "bag_name", ",", "bag_path_write_data", ",", "bag_beam", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "pairs", "=", "[", "p", "for", "p", "in", "pairs", "if", "p", "is", "not", "None", "]", "\n", "print", "(", "'Final Stage'", ")", "\n", "with", "open", "(", "single_file", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "'\\n'", ".", "join", "(", "pairs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.observe_data.comp_ratio_distribution": [[15, 38], ["print", "open", "pickle.load", "os.listdir", "x.startswith", "os.path.join", "r.array.tolist", "len", "print", "exit", "str"], "function", ["None"], ["def", "comp_ratio_distribution", "(", "data_path", ",", "data_name", ")", ":", "\n", "    ", "print", "(", "data_path", ")", "\n", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "data_path", ")", "if", "x", ".", "startswith", "(", "\"test.pkl.{}\"", ".", "format", "(", "data_name", ")", ")", "]", "\n", "bag", "=", "[", "]", "\n", "for", "file", "in", "files", ":", "\n", "        ", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "file", ")", ",", "'rb'", ")", "\n", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "for", "instance_fields", "in", "data", ":", "\n", "            ", "meta", "=", "instance_fields", "[", "'metadata'", "]", "\n", "ratios", "=", "instance_fields", "[", "'comp_rouge_ratio'", "]", "\n", "\n", "for", "r", "in", "ratios", ".", "field_list", ":", "\n", "                ", "np_arr", "=", "r", ".", "array", ".", "tolist", "(", ")", "\n", "bag", "+=", "np_arr", "\n", "if", "len", "(", "bag", ")", ">", "2000", ":", "\n", "                    ", "bag", "=", "[", "str", "(", "x", ")", "for", "x", "in", "bag", "]", "[", ":", "2000", "]", "\n", "print", "(", "\"\\n\"", ".", "join", "(", "bag", ")", ")", "\n", "exit", "(", ")", "\n", "", "", "doc_list", "=", "meta", "[", "'doc_list'", "]", "[", "0", ":", "3", "]", "\n", "abs_list", "=", "meta", "[", "'abs_list'", "]", "\n", "# x = [print(len(a)) for a in meta['doc_list'] ]", "\n", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "doc_list", "]", "\n", "abs_list", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "abs_list", "]", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.set_data_name": [[17, 40], ["print", "print", "allennlp.data.vocabulary.Vocabulary.from_files"], "function", ["None"], ["def", "set_data_name", "(", "_n", ",", "servername", ")", ":", "\n", "    ", "global", "name", "\n", "name", "=", "_n", "\n", "global", "vocab", "\n", "print", "(", "name", ")", "\n", "if", "servername", "==", "'titan'", ":", "\n", "        ", "root", "=", "\"/scratch/cluster/jcxu/exComp/\"", "\n", "", "elif", "servername", "==", "'eve'", ":", "\n", "        ", "root", "=", "\"/backup3/jcxu/exComp/\"", "\n", "", "elif", "servername", "==", "'cc'", ":", "\n", "        ", "root", "=", "'/home/cc/exComp/'", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "", "if", "name", "==", "'nyt'", ":", "\n", "\n", "        ", "vocab_path", "=", "root", "+", "\"nyt_vocab\"", "\n", "", "else", ":", "\n", "# vocab_path = \"/home/cc/exComp/cnndm_vocab\"", "\n", "        ", "vocab_path", "=", "root", "+", "\"cnndm_vocab\"", "\n", "# vocab_path = \"/home/cc/nyt_vocab\"", "\n", "# vocab_path = \"/backup3/jcxu/data/cnndm_vocab\"", "\n", "", "print", "(", "\"reading vocab {}\"", ".", "format", "(", "vocab_path", ")", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_files", "(", "vocab_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.read_sent_object": [[42, 86], ["len", "random.shuffle", "len", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField.index", "range", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ListField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.LabelField", "allennlp.data.tokenizers.Token", "numpy.zeros", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ListField.append", "allennlp.data.fields.ArrayField.append", "allennlp.data.fields.ArrayField.append", "allennlp.data.fields.MetadataField.append", "numpy.asarray", "numpy.asarray", "numpy.argsort", "int"], "function", ["None"], ["", "def", "read_sent_object", "(", "sentence", ",", "word_token_indexers", ")", ":", "\n", "    ", "txt_list", "=", "sentence", "[", "'token'", "]", "\n", "sent_len", "=", "len", "(", "txt_list", ")", "\n", "del_span", "=", "sentence", "[", "'del_span'", "]", "\n", "# baseline = sentence['baseline']", "\n", "random", ".", "shuffle", "(", "del_span", ")", "\n", "# del_span = del_span[:25]  # TODO assum", "\n", "l", "=", "len", "(", "del_span", ")", "\n", "txt_token_obj", "=", "[", "Token", "(", "word", ")", "for", "word", "in", "txt_list", "]", "\n", "txt_field", "=", "TextField", "(", "txt_token_obj", ",", "word_token_indexers", ")", "\n", "txt_field", ".", "index", "(", "vocab", ")", "\n", "# l = len(del_span)", "\n", "# random.shuffle(del_span)", "\n", "bag_of_compression_bit", "=", "[", "]", "\n", "bag_of_rouge", "=", "[", "]", "\n", "bag_of_rouge_ratio", "=", "[", "]", "\n", "bag_of_span_meta", "=", "[", "]", "\n", "\n", "for", "index", "in", "range", "(", "l", ")", ":", "\n", "        ", "sp", "=", "del_span", "[", "index", "]", "\n", "# sp['ratio'] = sp['rouge'] / baseline", "\n", "del_indexs", "=", "sp", "[", "'selected_idx'", "]", "\n", "blank", "=", "np", ".", "zeros", "(", "sent_len", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "_idx", "in", "del_indexs", ":", "\n", "            ", "blank", "[", "_idx", "]", "=", "1", "\n", "", "del_mask", "=", "ArrayField", "(", "array", "=", "blank", ")", "\n", "bag_of_compression_bit", ".", "append", "(", "del_mask", ")", "\n", "bag_of_rouge", ".", "append", "(", "sp", "[", "'rouge'", "]", ")", "\n", "bag_of_rouge_ratio", ".", "append", "(", "sp", "[", "'ratio'", "]", ")", "\n", "# bag_of_span.append(span)", "\n", "bag_of_span_meta", ".", "append", "(", "\n", "[", "sp", "[", "'node'", "]", ",", "sp", "[", "'selected_idx'", "]", ",", "sp", "[", "'rouge'", "]", "\n", ",", "sp", "[", "'ratio'", "]", "\n", "]", ")", "\n", "", "bag_of_rouge", "=", "ArrayField", "(", "np", ".", "asarray", "(", "bag_of_rouge", ")", ")", "\n", "bag_of_rouge_ratio", "=", "ArrayField", "(", "np", ".", "asarray", "(", "bag_of_rouge_ratio", ")", ")", "\n", "bag_of_compression_bit", "=", "ListField", "(", "bag_of_compression_bit", ")", "\n", "bag_of_span_meta", "=", "MetadataField", "(", "bag_of_span_meta", ")", "\n", "# sort rouge and get label", "\n", "scores", "=", "[", "x", "[", "'rouge'", "]", "for", "x", "in", "del_span", "]", "\n", "r_idx", "=", "np", ".", "argsort", "(", "scores", ")", "[", ":", ":", "-", "1", "]", "\n", "seq_label", "=", "LabelField", "(", "label", "=", "int", "(", "r_idx", "[", "0", "]", ")", ",", "skip_indexing", "=", "True", ")", "\n", "\n", "return", "txt_token_obj", ",", "bag_of_rouge", ",", "bag_of_rouge_ratio", ",", "bag_of_compression_bit", ",", "bag_of_span_meta", ",", "seq_label", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.read_doc_object": [[88, 108], ["allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "len", "convert_json_to_pkl.read_sent_object", "txt_token_objs.append", "allennlp.data.fields.ListField.append", "allennlp.data.fields.ListField.append", "allennlp.data.fields.ListField.append", "allennlp.data.fields.ListField.append", "allennlp.data.fields.ListField.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.read_sent_object"], ["", "def", "read_doc_object", "(", "sentences", ":", "List", ",", "word_token_indexers", ")", ":", "\n", "    ", "txt_token_objs", ",", "list_rouge", ",", "list_rouge_ratio", ",", "list_span", ",", "list_span_meta", ",", "list_seq_label", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "assert", "len", "(", "sentences", ")", "!=", "0", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "txt_token_obj", ",", "bag_of_rouge", ",", "bag_of_rouge_ratio", ",", "bag_of_span", ",", "bag_of_span_meta", ",", "seq_label", "=", "read_sent_object", "(", "s", ",", "word_token_indexers", ")", "\n", "# TextField, ArrayField, ListField, MetadataField", "\n", "txt_token_objs", ".", "append", "(", "txt_token_obj", ")", "\n", "list_rouge", ".", "append", "(", "bag_of_rouge", ")", "\n", "list_rouge_ratio", ".", "append", "(", "bag_of_rouge_ratio", ")", "\n", "list_span", ".", "append", "(", "bag_of_span", ")", "\n", "list_span_meta", ".", "append", "(", "bag_of_span_meta", ")", "\n", "list_seq_label", ".", "append", "(", "seq_label", ")", "\n", "# txt_token_obj = ListField(txt_token_objs)", "\n", "", "list_rouge", "=", "ListField", "(", "list_rouge", ")", "\n", "list_span", "=", "ListField", "(", "list_span", ")", "\n", "list_span_meta", "=", "ListField", "(", "list_span_meta", ")", "\n", "list_seq_label", "=", "ListField", "(", "list_seq_label", ")", "\n", "list_rouge_ratio", "=", "ListField", "(", "list_rouge_ratio", ")", "\n", "return", "txt_token_objs", ",", "list_rouge", ",", "list_rouge_ratio", ",", "list_span", ",", "list_span_meta", ",", "list_seq_label", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_one_line": [[110, 167], ["json.loads", "convert_json_to_pkl.read_doc_object", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField.index", "allennlp.data.fields.MetadataField", "len", "allennlp.data.token_indexers.SingleIdTokenIndexer", "allennlp.data.fields.TextField"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.read_doc_object"], ["", "def", "convert_one_line", "(", "line", ")", ":", "\n", "    ", "data_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "sentences", "=", "data_dict", "[", "'sentences'", "]", "\n", "if", "len", "(", "sentences", ")", "<=", "1", ":", "\n", "        ", "return", "None", "\n", "\n", "", "name", "=", "data_dict", "[", "'name'", "]", "\n", "doc_str", "=", "data_dict", "[", "'doc'", "]", "\n", "abs_str", "=", "data_dict", "[", "'abs'", "]", "\n", "# span_pairs = data_dict['span']", "\n", "doc_list", "=", "data_dict", "[", "'doc_list'", "]", "\n", "abs_list", "=", "data_dict", "[", "'abs_list'", "]", "\n", "# print(name)", "\n", "if", "\"part\"", "in", "data_dict", ":", "\n", "        ", "part", "=", "data_dict", "[", "'part'", "]", "\n", "", "else", ":", "\n", "        ", "part", "=", "'cnn'", "\n", "", "sent_oracle", "=", "data_dict", "[", "'sent_oracle'", "]", "\n", "non_compression_sent_oracle", "=", "data_dict", "[", "'non_compression_sent_oracle'", "]", "\n", "word_token_indexers", "=", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "instance_fields", "=", "{", "}", "\n", "txt_token_obj", ",", "list_rouge", ",", "list_rouge_ratio", ",", "list_span", ",", "list_span_meta", ",", "list_seq_label", "=", "read_doc_object", "(", "sentences", ",", "\n", "word_token_indexers", ")", "\n", "\n", "txt_field", "=", "ListField", "(", "[", "TextField", "(", "obj", ",", "word_token_indexers", ")", "for", "obj", "in", "txt_token_obj", "]", ")", "\n", "txt_field", ".", "index", "(", "vocab", ")", "\n", "# print(txt_field.get_padding_lengths())", "\n", "# txt_field.get_padding_lengths()", "\n", "# instance_fields[\"token\"] = TextField(tokens,self.word_token_indexers)", "\n", "instance_fields", "[", "\"text\"", "]", "=", "txt_field", "\n", "instance_fields", "[", "\"comp_rouge\"", "]", "=", "list_rouge", "\n", "instance_fields", "[", "\"comp_msk\"", "]", "=", "list_span", "\n", "instance_fields", "[", "\"comp_meta\"", "]", "=", "list_span_meta", "\n", "instance_fields", "[", "\"comp_seq_label\"", "]", "=", "list_seq_label", "\n", "instance_fields", "[", "\"comp_rouge_ratio\"", "]", "=", "list_rouge_ratio", "\n", "\n", "# def edit_label_rouge(_label_list, _rouge_list):", "\n", "#     _label_list = [x for x in _label_list]", "\n", "#     _max_len = max([len(x) for x in _label_list])", "\n", "#     for idx, label in enumerate(_label_list):", "\n", "#         if len(label) < _max_len:", "\n", "#             _label_list[idx] = _label_list[idx] + [-1] * (_max_len - len(label))", "\n", "#     np_gold_label = np.asarray(_label_list, dtype=np.int)", "\n", "#     f = ArrayField(array=np_gold_label, padding_value=-1)", "\n", "#     r = ArrayField(np.asarray(_rouge_list, dtype=np.float32))", "\n", "#     return f, r", "\n", "\n", "instance_fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "\n", "{", "\n", "\"doc_list\"", ":", "doc_list", ",", "\n", "\"abs_list\"", ":", "abs_list", ",", "\n", "\"name\"", ":", "name", ",", "\n", "\"part\"", ":", "part", "\n", "}", ")", "\n", "instance_fields", "[", "'_sent_oracle'", "]", "=", "sent_oracle", "\n", "instance_fields", "[", "'_non_compression_sent_oracle'", "]", "=", "non_compression_sent_oracle", "\n", "return", "instance_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.convert_json_to_pkl.convert_json_file_to_pkl_dump": [[172, 212], ["len", "print", "open", "fd.read().splitlines", "int", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "len", "math.ceil", "range", "print", "len", "os.path.join", "print", "os.path.join", "len", "open", "pickle.dump", "open.close", "fd.read", "multiprocessing.cpu_count", "str", "str"], "function", ["None"], ["def", "convert_json_file_to_pkl_dump", "(", "path", ",", "txt_fname", ",", "part", ":", "str", ")", ":", "\n", "    ", "chunk_size", "=", "5000", "\n", "# vocab = Vocabulary.from_files(vocab_path)", "\n", "# pkl_fname = os.path.join(path, txt_fname + '.pkl')", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "txt_fname", "+", "'.txt'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "glob_cnt", "=", "0", "\n", "total_l", "=", "len", "(", "lines", ")", "\n", "assertion_cnt", "=", "0", "\n", "l", "=", "total_l", "\n", "while", "l", ">", "0", ":", "\n", "        ", "todo", "=", "lines", "[", ":", "chunk_size", "*", "5", "]", "\n", "lines", "=", "lines", "[", "chunk_size", "*", "5", ":", "]", "\n", "cnt", "=", "int", "(", "multiprocessing", ".", "cpu_count", "(", ")", "/", "4", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pairs", "=", "pool", ".", "map", "(", "convert_one_line", ",", "todo", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "pairs", "=", "[", "x", "for", "x", "in", "pairs", "if", "x", "is", "not", "None", "]", "\n", "print", "(", "pairs", "[", "4", "]", ")", "\n", "this_l", "=", "len", "(", "pairs", ")", "\n", "import", "math", "\n", "num_of_files", "=", "math", ".", "ceil", "(", "this_l", "/", "chunk_size", ")", "\n", "\n", "for", "idx", "in", "range", "(", "num_of_files", ")", ":", "\n", "            ", "print", "(", "\"Writing to disk\"", ")", "\n", "pkl_fname", "=", "os", ".", "path", ".", "join", "(", "path", ",", "txt_fname", "+", "'.pkl.{}.'", ".", "format", "(", "part", ")", "+", "str", "(", "glob_cnt", ")", "+", "str", "(", "idx", ")", ")", "\n", "if", "idx", "==", "num_of_files", "-", "1", ":", "\n", "                ", "wt_content", "=", "pairs", "[", "idx", "*", "chunk_size", ":", "]", "\n", "", "else", ":", "\n", "                ", "wt_content", "=", "pairs", "[", "idx", "*", "chunk_size", ":", "(", "idx", "+", "1", ")", "*", "chunk_size", "]", "\n", "", "assertion_cnt", "+=", "len", "(", "wt_content", ")", "\n", "f", "=", "open", "(", "pkl_fname", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "wt_content", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "glob_cnt", "+=", "1", "\n", "print", "(", "\"reaming {}\"", ".", "format", "(", "l", ")", ")", "\n", "l", "=", "len", "(", "lines", ")", "\n", "", "print", "(", "\"Writing done.\"", ")", "\n", "# assert assertion_cnt == total_l", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.berkeley_parse.run_on_one_gpu": [[19, 26], ["allennlp.models.archival.load_archive", "allennlp.predictors.predictor.Predictor.from_archive", "Predictor.from_archive.predict", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.predict"], ["def", "run_on_one_gpu", "(", "root", ",", "input", ":", "List", ",", "cuda_device_id", ")", ":", "\n", "    ", "arc", "=", "load_archive", "(", "\n", "archive_file", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"elmo-constituency-parser-2018.03.14.tar.gz\"", ")", ",", "\n", "cuda_device", "=", "cuda_device_id", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", "=", "arc", ")", "\n", "predictor", ".", "predict", "(", "\n", "sentence", "=", "sentence", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.berkeley_parse.clear_dir": [[30, 34], ["os.path.isdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.compare_omitted_files.run_snlp": [[7, 25], ["print", "cmd.split", "subprocess.call"], "function", ["None"], ["def", "run_snlp", "(", "inp", ")", ":", "\n", "    ", "filelist", ",", "output_dir", "=", "inp", "\n", "cmd", "=", "(", "\n", "\"java -mx4g -cp /home/cc/stanford-corenlp-full-2018-02-27/* edu.stanford.nlp.pipeline.StanfordCoreNLP \"", "\n", "\"-annotators tokenize,ssplit,pos,lemma,ner,parse \"", "\n", "\" -filelist {} -outputFormat json  \"", "\n", "\"-outputDirectory {}\"", ".", "format", "(", "\n", "filelist", ",", "output_dir", ")", ")", "\n", "# cmd = (", "\n", "#     \"java -mx4g -cp /home/jcxu/stanford-corenlp-full-2018-02-27/* edu.stanford.nlp.pipeline.StanfordCoreNLP \"", "\n", "#     \"-annotators tokenize,ssplit,pos,lemma,ner,parse \"", "\n", "#     \" -filelist {} -outputFormat json  \"", "\n", "#     \"-outputDirectory {}\".format(", "\n", "#         os.path.join(path_root, data_name + str(i) + flist), path_data_af))", "\n", "\n", "print", "(", "cmd", ")", "\n", "command", "=", "cmd", ".", "split", "(", "' '", ")", "\n", "subprocess", ".", "call", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.compare_omitted_files.stanford_pre": [[27, 51], ["os.listdir", "multiprocessing.cpu_count", "range", "zip", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.join", "len", "os.path.join", "open", "fd.write", "range", "len", "os.path.join", "str", "str"], "function", ["None"], ["", "def", "stanford_pre", "(", "path_bf", ",", "\n", "path_af", ",", "\n", "path_root", "=", "'/home/cc'", ",", "\n", "data_name", "=", "'nyt'", ",", "flist", "=", "'before-parse-problems-flist.txt'", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "path_bf", ")", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "path_bf", ",", "f", ")", "for", "f", "in", "files", "]", "\n", "\n", "num_flist", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "slice", "=", "len", "(", "files", ")", "//", "num_flist", "\n", "for", "i", "in", "range", "(", "num_flist", ")", ":", "\n", "        ", "if", "i", "==", "num_flist", "-", "1", ":", "\n", "            ", "tmp", "=", "files", "[", "i", "*", "slice", ":", "]", "\n", "", "else", ":", "\n", "            ", "tmp", "=", "files", "[", "i", "*", "slice", ":", "(", "i", "+", "1", ")", "*", "slice", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_root", ",", "data_name", "+", "str", "(", "i", ")", "+", "flist", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "'\\n'", ".", "join", "(", "tmp", ")", ")", "\n", "\n", "", "", "file_lists", "=", "[", "os", ".", "path", ".", "join", "(", "path_root", ",", "data_name", "+", "str", "(", "i", ")", "+", "flist", ")", "for", "i", "in", "range", "(", "num_flist", ")", "]", "\n", "inp", "=", "zip", "(", "file_lists", ",", "[", "path_af", "]", "*", "len", "(", "file_lists", ")", ")", "\n", "# cnt = multiprocessing.cpu_count()", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "num_flist", ")", "\n", "pool", ".", "map", "(", "run_snlp", ",", "inp", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.compare_omitted_files.clear_dir": [[53, 57], ["os.path.isdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["", "def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.gen_nyt_index.read_one_file": [[7, 15], ["json.dumps", "open", "fd.read().splitlines", "json.loads", "open", "wfd.write", "fd.read"], "function", ["None"], ["def", "read_one_file", "(", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "\"r\"", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "lines", "=", "[", "json", ".", "loads", "(", "l", ")", "for", "l", "in", "lines", "]", "\n", "lines", "=", "[", "l", "[", "'name'", "]", "for", "l", "in", "lines", "]", "\n", "x", "=", "json", ".", "dumps", "(", "lines", ")", "\n", "with", "open", "(", "\"nyt-train.txt\"", ",", "\"w\"", ")", "as", "wfd", ":", "\n", "        ", "wfd", ".", "write", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.clear_dir": [[7, 11], ["os.path.isdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.hashhex": [[23, 28], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.get_url_hashes": [[30, 37], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "# return [hashhex(url) for url in url_list]", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.fix_missing_period": [[40, 48], ["line.rstrip.rstrip"], "function", ["None"], ["", "def", "fix_missing_period", "(", "line", ")", ":", "\n", "    ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "\"\"\"Adds a period to a line that is missing a period\"\"\"", "\n", "if", "\"@highlight\"", "in", "line", ":", "return", "line", "\n", "if", "line", "==", "\"\"", ":", "return", "line", "\n", "if", "line", "[", "-", "1", "]", "in", "END_TOKENS", ":", "return", "line", "\n", "# print line[-1]", "\n", "return", "line", "+", "\" .\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.read_text_file": [[50, 56], ["open", "lines.append", "line.strip"], "function", ["None"], ["", "def", "read_text_file", "(", "text_file", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "open", "(", "text_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.get_art_abs": [[58, 86], ["seperate_file_from_raw.read_text_file", "enumerate", "seperate_file_from_raw.fix_missing_period", "line.startswith", "highlights.append", "article_lines.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.read_text_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.fix_missing_period"], ["", "def", "get_art_abs", "(", "story_file", ")", ":", "\n", "    ", "lines", "=", "read_text_file", "(", "story_file", ")", "\n", "\n", "# Put periods on the ends of lines that are missing them (this is a problem in the dataset because many image captions don't end in periods; consequently they end up in the body of the article as run-on sentences)", "\n", "lines", "=", "[", "fix_missing_period", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "\n", "# Separate out article and abstract sentences", "\n", "article_lines", "=", "[", "]", "\n", "highlights", "=", "[", "]", "\n", "next_is_highlight", "=", "False", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "line", "==", "\"\"", ":", "\n", "            ", "continue", "# empty line", "\n", "", "elif", "line", ".", "startswith", "(", "\"@highlight\"", ")", ":", "\n", "            ", "next_is_highlight", "=", "True", "\n", "", "elif", "next_is_highlight", ":", "\n", "            ", "highlights", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "article_lines", ".", "append", "(", "line", ")", "\n", "\n", "# Make article into a single string", "\n", "", "", "article_lines", "=", "article_lines", "[", ":", "35", "]", "\n", "article", "=", "'\\n'", ".", "join", "(", "article_lines", ")", "\n", "\n", "# Make abstract into a signle string, putting <s> and </s> tags around the sentences", "\n", "abstract", "=", "'\\n'", ".", "join", "(", "[", "sent", "for", "sent", "in", "highlights", "]", ")", "\n", "\n", "return", "article", ",", "abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.seperate_file": [[88, 98], ["seperate_file_from_raw.get_art_abs", "name.split", "os.path.join", "print", "open", "fd.write", "open", "fd.write", "len", "len", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_art_abs"], ["", "def", "seperate_file", "(", "dir_to_read", ",", "name", ",", "to_write_dir", ")", ":", "\n", "    ", "name_token", "=", "name", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "article", ",", "abstract", "=", "get_art_abs", "(", "os", ".", "path", ".", "join", "(", "dir_to_read", ",", "name", ")", ")", "\n", "if", "len", "(", "article", ")", "<", "5", "or", "len", "(", "abstract", ")", "<", "5", ":", "\n", "        ", "print", "(", "'Discard: {}'", ".", "format", "(", "name", ")", ")", "\n", "return", "None", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "to_write_dir", ",", "name_token", "+", "'.doc'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "article", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "to_write_dir", ",", "name_token", "+", "'.abs'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "abstract", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.seperate_file_from_raw.stage1": [[100, 109], ["os.listdir", "print", "len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "zip"], "function", ["None"], ["", "", "def", "stage1", "(", "source_path", ",", "_path_data_bf", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "source_path", ")", "\n", "print", "(", "'Start seperating files!'", ")", "\n", "l", "=", "len", "(", "files", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pool", ".", "starmap", "(", "seperate_file", ",", "zip", "(", "[", "source_path", "]", "*", "l", ",", "files", ",", "[", "_path_data_bf", "]", "*", "l", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.sent_len_and_num_deletion_portion": [[32, 39], ["len", "dic[].append", "len"], "function", ["None"], ["def", "sent_len_and_num_deletion_portion", "(", "zip_inp", ",", "dic", ":", "dict", ")", ":", "\n", "    ", "for", "sent", ",", "doc_list", "in", "zip_inp", ":", "\n", "        ", "sent_len", "=", "len", "(", "doc_list", ")", "\n", "if", "sent_len", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "sent_len", "]", "=", "[", "]", "\n", "", "dic", "[", "sent_len", "]", ".", "append", "(", "len", "(", "sent", "[", "'del_span'", "]", ")", ")", "\n", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.sum_len": [[41, 43], ["sum", "len"], "function", ["None"], ["", "def", "sum_len", "(", "inp", ")", ":", "\n", "    ", "return", "sum", "(", "[", "len", "(", "a", ")", "for", "a", "in", "inp", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.avg_len": [[45, 47], ["analysis_data.avg", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.avg"], ["", "def", "avg_len", "(", "inp", ")", ":", "\n", "    ", "return", "avg", "(", "[", "len", "(", "a", ")", "for", "a", "in", "inp", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.rank_of_baseline": [[49, 59], ["len", "enumerate", "tmp.append", "float"], "function", ["None"], ["", "def", "rank_of_baseline", "(", "inp_list", ")", ":", "\n", "    ", "tmp", "=", "[", "]", "\n", "for", "inp", "in", "inp_list", ":", "\n", "        ", "l", "=", "inp", "[", "'del_span'", "]", "\n", "total", "=", "len", "(", "l", ")", "\n", "for", "idx", ",", "it", "in", "enumerate", "(", "l", ")", ":", "\n", "            ", "if", "it", "[", "'node'", "]", "==", "'BASELINE'", ":", "\n", "                ", "tmp", ".", "append", "(", "float", "(", "idx", "/", "total", ")", ")", "\n", "break", "\n", "", "", "", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.num_del": [[61, 68], ["len", "tmp.append"], "function", ["None"], ["", "def", "num_del", "(", "inp_lists", ")", ":", "\n", "    ", "tmp", "=", "[", "]", "\n", "for", "inp", "in", "inp_lists", ":", "\n", "        ", "l", "=", "inp", "[", "'del_span'", "]", "\n", "total", "=", "len", "(", "l", ")", "\n", "tmp", ".", "append", "(", "total", "-", "1", ")", "\n", "", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.del_score_over_baseline": [[70, 85], ["len", "cur.append"], "function", ["None"], ["", "def", "del_score_over_baseline", "(", "inp_lists", ",", "dic", ":", "dict", ")", ":", "\n", "    ", "for", "inp", "in", "inp_lists", ":", "\n", "        ", "sp", "=", "inp", "[", "'del_span'", "]", "\n", "BASELINE_rouge", "=", "[", "s", "[", "\"rouge\"", "]", "for", "s", "in", "sp", "if", "s", "[", "\"node\"", "]", "==", "'BASELINE'", "]", "\n", "assert", "len", "(", "BASELINE_rouge", ")", "==", "1", "\n", "BASELINE_rouge", "=", "BASELINE_rouge", "[", "0", "]", "\n", "if", "BASELINE_rouge", "<", "0.01", ":", "\n", "            ", "continue", "\n", "", "for", "s", "in", "sp", ":", "\n", "            ", "if", "s", "[", "'node'", "]", "not", "in", "dic", ":", "\n", "                ", "dic", "[", "s", "[", "'node'", "]", "]", "=", "[", "]", "\n", "", "cur", "=", "dic", "[", "s", "[", "'node'", "]", "]", "\n", "cur", ".", "append", "(", "s", "[", "'rouge'", "]", "/", "BASELINE_rouge", ")", "\n", "dic", "[", "s", "[", "'node'", "]", "]", "=", "cur", "\n", "", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.avg": [[87, 89], ["round", "sum", "len"], "function", ["None"], ["", "def", "avg", "(", "x", ")", ":", "\n", "    ", "return", "round", "(", "sum", "(", "x", ")", "/", "len", "(", "x", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.count_occ": [[91, 97], ["enumerate"], "function", ["None"], ["", "def", "count_occ", "(", "inp_lists", ",", "cnter", ":", "Counter", ")", ":", "\n", "    ", "for", "inp", "in", "inp_lists", ":", "\n", "        ", "sp", "=", "inp", "[", "'del_span'", "]", "\n", "for", "idx", ",", "it", "in", "enumerate", "(", "sp", ")", ":", "\n", "            ", "cnter", "[", "it", "[", "'node'", "]", "]", "+=", "1", "\n", "", "", "return", "cnter", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.avg_dict": [[160, 164], ["iter", "analysis_data.avg"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.analysis_data.avg"], ["def", "avg_dict", "(", "inp", ")", ":", "\n", "    ", "for", "k", "in", "iter", "(", "inp", ")", ":", "\n", "        ", "inp", "[", "k", "]", "=", "avg", "(", "inp", "[", "k", "]", ")", "\n", "", "return", "inp", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.build_data.data_builder": [[8, 40], ["neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl", "neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.read", "neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.read", "neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.read", "neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.read", "neusum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.read", "os.path.join"], "function", ["None"], ["def", "data_builder", "(", "dbg", ":", "bool", "=", "False", ",", "\n", "lazy", "=", "True", ",", "\n", "dataset_dir", ":", "str", "=", "\"/backup2/jcxu/data/cnn-v1/read-ready-files\"", ",", "\n", "train_file", ":", "str", "=", "\"train.pkl\"", ",", "\n", "dev_file", ":", "str", "=", "\"dev.pkl\"", ",", "\n", "test_file", ":", "str", "=", "'test.pkl'", ",", "\n", "single_oracle", "=", "True", ",", "\n", "fix_edu_num", "=", "None", ",", "\n", "trim_sent_oracle", ":", "bool", "=", "True", ",", "\n", "save_to", ":", "str", "=", "None", ")", ":", "\n", "    ", "reader", "=", "SummarizationDatasetReaderPkl", "(", "lazy", "=", "lazy", ",", "dir", "=", "dataset_dir", ",", "\n", "single_oracle", "=", "single_oracle", ",", "fix_edu_num", "=", "fix_edu_num", ",", "\n", "trim_sent_oracle", "=", "trim_sent_oracle", ",", "\n", "vocab_path", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "dev_file", ")", ",", "\n", "save_to", "=", "save_to", ",", "dbg", "=", "dbg", "\n", ")", "\n", "\n", "if", "dbg", ":", "\n", "# dev_file = \"minidev.txt\"", "\n", "        ", "dev_data", "=", "reader", ".", "read", "(", "dev_file", ")", "\n", "\n", "test_data", "=", "reader", ".", "read", "(", "test_file", ")", "\n", "train_data", "=", "dev_data", "\n", "", "else", ":", "\n", "        ", "train_data", "=", "reader", ".", "read", "(", "train_file", ")", "\n", "test_data", "=", "reader", ".", "read", "(", "test_file", ")", "\n", "dev_data", "=", "reader", ".", "read", "(", "dev_file", ")", "\n", "\n", "# vocab = Vocabulary.from_instances(instances=train_data + dev_data + test_data,", "\n", "#                                   min_count={\"tokens\": 5})", "\n", "# logging.info(\"Vocab size: {}\".format(int(vocab.get_vocab_size())))", "\n", "", "return", "train_data", ",", "dev_data", ",", "test_data", ",", "reader", ".", "vocab", ",", "reader", ".", "word_token_indexers", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.TreeNode.__init__": [[21, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ",", "text", ",", "children", ",", "depth", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "children", "=", "children", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "start_idx", "=", "-", "1", "\n", "self", ".", "end_idx", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.TreeNode.__repr__": [[29, 31], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Text: {}\\tTag:{}\\tDepth:{}\"", ".", "format", "(", "\" \"", ".", "join", "(", "self", ".", "text", ")", ",", "self", ".", "tag", ",", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.clear_dir": [[14, 18], ["os.path.isdir", "os.path.isdir", "os.mkdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.return_childrens": [[33, 50], ["enumerate", "buff.append", "rt_list.append"], "function", ["None"], ["", "", "def", "return_childrens", "(", "inp", ":", "str", ")", "->", "List", ":", "\n", "    ", "dep", "=", "0", "\n", "rt_list", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "inp", ")", ":", "\n", "        ", "if", "c", "==", "'('", ":", "\n", "            ", "dep", "+=", "1", "\n", "", "elif", "c", "==", "')'", ":", "\n", "            ", "dep", "-=", "1", "\n", "", "if", "buff", "==", "[", "]", "and", "c", "==", "\" \"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "buff", ".", "append", "(", "c", ")", "\n", "", "if", "dep", "==", "0", "and", "buff", "!=", "[", "]", ":", "\n", "            ", "rt_list", ".", "append", "(", "\"\"", ".", "join", "(", "buff", ")", ")", "\n", "buff", "=", "[", "]", "\n", "", "", "return", "rt_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree": [[52, 71], ["inp_str.find", "inp_str.rfind", "inp_str.find", "generate_compression_based_data.TreeNode", "generate_compression_based_data.return_childrens", "generate_compression_based_data.parse_subtree", "child.strip"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.return_childrens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree"], ["", "def", "parse_subtree", "(", "inp_str", ":", "str", ",", "depth", ":", "int", ")", ":", "\n", "# print(inp_str)", "\n", "    ", "index_lb", "=", "inp_str", ".", "find", "(", "\"(\"", ")", "\n", "index_rb", "=", "inp_str", ".", "rfind", "(", "\")\"", ")", "\n", "idex_split_of_tag_children", "=", "inp_str", ".", "find", "(", "\" \"", ")", "\n", "tag", "=", "inp_str", "[", "index_lb", "+", "1", ":", "idex_split_of_tag_children", "]", "\n", "child", "=", "inp_str", "[", "idex_split_of_tag_children", "+", "1", ":", "index_rb", "]", "\n", "if", "\"(\"", "in", "child", ":", "\n", "        ", "children_list", "=", "return_childrens", "(", "child", ")", "# (NP   =>(x x) (x x) (x x)<=)", "\n", "children_node", "=", "[", "parse_subtree", "(", "x", ",", "depth", "+", "1", ")", "for", "x", "in", "children_list", "]", "\n", "txt_buff", "=", "[", "]", "\n", "for", "n", "in", "children_node", ":", "\n", "            ", "txt_buff", "+=", "n", ".", "text", "\n", "", "text", "=", "txt_buff", "\n", "", "else", ":", "\n", "# reach leaf node", "\n", "        ", "text", "=", "[", "child", ".", "strip", "(", ")", "]", "\n", "children_node", "=", "None", "\n", "", "return", "TreeNode", "(", "tag", "=", "tag", ",", "text", "=", "text", ",", "children", "=", "children_node", ",", "depth", "=", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree": [[73, 86], ["len", "new_children.append", "generate_compression_based_data.add_idx_of_tree"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "def", "add_idx_of_tree", "(", "tree", ":", "TreeNode", ",", "start_idx", ":", "int", ",", "end_idx", ":", "int", ")", ":", "\n", "    ", "tree", ".", "start_idx", "=", "start_idx", "\n", "tree", ".", "end_idx", "=", "end_idx", "\n", "if", "not", "tree", ".", "children", ":", "\n", "        ", "return", "tree", "\n", "", "cur_start", "=", "start_idx", "\n", "new_children", "=", "[", "]", "\n", "for", "child", "in", "tree", ".", "children", ":", "\n", "        ", "span_len", "=", "len", "(", "child", ".", "text", ")", "\n", "new_children", ".", "append", "(", "add_idx_of_tree", "(", "child", ",", "start_idx", "=", "cur_start", ",", "end_idx", "=", "cur_start", "+", "span_len", ")", ")", "\n", "cur_start", "+=", "span_len", "\n", "", "tree", ".", "children", "=", "new_children", "\n", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree": [[88, 96], ["re.sub.replace", "re.sub", "generate_compression_based_data.parse_subtree", "generate_compression_based_data.add_idx_of_tree", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.parse_subtree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.add_idx_of_tree"], ["", "def", "read_single_parse_tree", "(", "inp_str", ")", "->", "TreeNode", ":", "\n", "    ", "inp_str", "=", "inp_str", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "# inp_str = re.split('\\(|\\)|\\s', inp_str)", "\n", "inp_str", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "inp_str", ")", "\n", "# inp = inp.split(\" \")", "\n", "out", "=", "parse_subtree", "(", "inp_str", ",", "depth", "=", "0", ")", "\n", "out", "=", "add_idx_of_tree", "(", "out", ",", "start_idx", "=", "0", ",", "end_idx", "=", "len", "(", "out", ".", "text", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based": [[98, 111], ["generate_compression_based_data.find_deletable_span_rule_based"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based"], ["", "def", "find_deletable_span_rule_based", "(", "rule", ",", "tree", ":", "TreeNode", ")", "->", "List", "[", "TreeNode", "]", ":", "\n", "# Rule is a list with TAG names", "\n", "# return a list of TreeNodes which are deletable", "\n", "    ", "tag", "=", "tree", ".", "tag", "\n", "deletable_bag", "=", "[", "]", "\n", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "        ", "for", "child", "in", "tree", ".", "children", ":", "\n", "            ", "deletable_bag", "+=", "find_deletable_span_rule_based", "(", "rule", ",", "child", ")", "\n", "", "", "if", "tag", "in", "rule", ":", "\n", "        ", "deletable_bag", "+=", "[", "tree", "]", "\n", "", "if", "' '", ".", "join", "(", "tree", ".", "text", ")", "==", "'-LRB- CNN -RRB-'", ":", "\n", "        ", "deletable_bag", "+=", "[", "tree", "]", "\n", "", "return", "deletable_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.generate_span_segmentation": [[116, 125], ["len", "span.append", "span.append", "d.split"], "function", ["None"], ["def", "generate_span_segmentation", "(", "doc_list", ":", "List", "[", "str", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "    ", "span", "=", "[", "]", "\n", "jdx", "=", "0", "\n", "for", "d", "in", "doc_list", ":", "\n", "        ", "num", "=", "len", "(", "[", "x", "for", "x", "in", "d", ".", "split", "(", "' '", ")", "if", "x", "!=", "''", "]", ")", "\n", "span", ".", "append", "(", "jdx", ")", "\n", "span", ".", "append", "(", "jdx", "+", "num", "-", "1", ")", "\n", "jdx", "+=", "num", "\n", "", "return", "span", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse": [[127, 131], ["None"], "function", ["None"], ["", "def", "extract_parse", "(", "snlp_dict", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff_parse", "=", "[", "s", "[", "'parse'", "]", "for", "s", "in", "sentences", "]", "\n", "return", "buff_parse", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens": [[133, 149], ["buff.append", "buff_str.append"], "function", ["None"], ["", "def", "extract_tokens", "(", "snlp_dict", ")", ":", "\n", "    ", "\"\"\"\n\n    :param snlp_dict:\n    :return: buff: List[List[str]]\n            string: a C B\\nD e f\\n...\n    \"\"\"", "\n", "sentences", "=", "snlp_dict", "[", "'sentences'", "]", "\n", "buff", "=", "[", "]", "\n", "buff_str", "=", "[", "]", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "tokens", "=", "s", "[", "\"tokens\"", "]", "\n", "tokens_list", "=", "[", "x", "[", "\"word\"", "]", "for", "x", "in", "tokens", "]", "\n", "buff", ".", "append", "(", "tokens_list", ")", "\n", "buff_str", ".", "append", "(", "\" \"", ".", "join", "(", "tokens_list", ")", ")", "\n", "", "return", "buff", ",", "\"\\n\"", ".", "join", "(", "buff_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_oracle_delete_one_unit": [[151, 156], ["del_spans.sort"], "function", ["None"], ["", "def", "comp_oracle_delete_one_unit", "(", "tree", ":", "TreeNode", ",", "del_spans", ":", "List", ",", "topk", ")", ":", "\n", "    ", "del_spans", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "del_spans", "=", "del_spans", "[", ":", "topk", "]", "\n", "most_deletable", "=", "del_spans", "[", "0", "]", "# {[sidx][eidx][node][rouge]}", "\n", "return", "del_spans", ",", "most_deletable", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.BFS": [[158, 177], ["set", "len", "range", "max", "combinations.append", "all", "generate_compression_based_data.BFS"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.BFS"], ["", "def", "BFS", "(", "block_map", ",", "current_member", ":", "List", "[", "int", "]", ")", ":", "\n", "    ", "combinations", "=", "[", "]", "\n", "if", "current_member", "==", "[", "]", ":", "\n", "        ", "cur_max", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "cur_max", "=", "max", "(", "current_member", ")", "\n", "combinations", ".", "append", "(", "current_member", ")", "\n", "\n", "", "member_set", "=", "set", "(", "current_member", ")", "\n", "l", "=", "len", "(", "block_map", ")", "\n", "for", "i", "in", "range", "(", "cur_max", "+", "1", ",", "l", ")", ":", "\n", "        ", "if", "i", "in", "member_set", ":", "\n", "            ", "continue", "# already in", "\n", "", "b", "=", "block_map", "[", "i", "]", "\n", "friend", "=", "all", "(", "[", "b", "[", "m", "]", "for", "m", "in", "current_member", "]", ")", "\n", "if", "not", "friend", ":", "\n", "            ", "continue", "# not compatible with exsisting", "\n", "", "combinations", "+=", "BFS", "(", "block_map", ",", "current_member", "+", "[", "i", "]", ")", "\n", "", "return", "combinations", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_oracle_delete_multiple_unit": [[179, 216], ["del_spans.sort", "len", "enumerate", "generate_compression_based_data.BFS", "del_multi_units.sort", "range", "set", "list", "list.sort", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "del_multi_units.append", "range", "range", "set", "len", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.BFS", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram"], ["", "def", "comp_oracle_delete_multiple_unit", "(", "abs_str", ":", "str", ",", "tree", ":", "TreeNode", ",", "del_spans", ":", "List", ",", "topk", ")", ":", "\n", "    ", "full_text_list", "=", "tree", ".", "text", "\n", "del_spans", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "'rouge'", "]", ",", "reverse", "=", "True", ")", "\n", "del_spans", "=", "del_spans", "[", ":", "topk", "]", "\n", "l", "=", "len", "(", "del_spans", ")", "\n", "block_map", "=", "[", "[", "True", "]", "*", "l", "for", "_", "in", "range", "(", "l", ")", "]", "\n", "for", "idx", ",", "sp", "in", "enumerate", "(", "del_spans", ")", ":", "\n", "        ", "s", "=", "sp", "[", "'sidx'", "]", "\n", "e", "=", "sp", "[", "'eidx'", "]", "\n", "for", "jdx", "in", "range", "(", "idx", ",", "l", ")", ":", "\n", "            ", "_s", ",", "_e", "=", "del_spans", "[", "jdx", "]", "[", "'sidx'", "]", ",", "del_spans", "[", "jdx", "]", "[", "'eidx'", "]", "\n", "if", "_s", ">=", "e", "or", "s", ">=", "_e", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "block_map", "[", "idx", "]", "[", "jdx", "]", "=", "False", "\n", "block_map", "[", "jdx", "]", "[", "idx", "]", "=", "False", "\n", "", "", "", "possible_combinations", "=", "BFS", "(", "block_map", ",", "[", "]", ")", "\n", "del_multi_units", "=", "[", "]", "\n", "for", "p", "in", "possible_combinations", ":", "\n", "        ", "full_set", "=", "set", "(", "range", "(", "len", "(", "full_text_list", ")", ")", ")", "\n", "for", "x", "in", "p", ":", "\n", "            ", "this_start", "=", "del_spans", "[", "x", "]", "[", "\"sidx\"", "]", "\n", "this_end", "=", "del_spans", "[", "x", "]", "[", "\"eidx\"", "]", "\n", "this_set", "=", "set", "(", "range", "(", "this_start", ",", "this_end", ")", ")", "\n", "full_set", "=", "full_set", "-", "this_set", "\n", "\n", "", "full_list", "=", "list", "(", "full_set", ")", "\n", "full_list", ".", "sort", "(", ")", "\n", "text_chunks", "=", "[", "full_text_list", "[", "w", "]", "for", "w", "in", "full_list", "]", "\n", "_rouge", "=", "get_rouge_est_str_4gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "\" \"", ".", "join", "(", "text_chunks", ")", ")", "\n", "tmp", "=", "{", "\"del_spans\"", ":", "[", "del_spans", "[", "x", "]", "for", "x", "in", "p", "]", ",", "\"rouge\"", ":", "_rouge", ",", "\"selected_idx\"", ":", "full_list", "}", "\n", "del_multi_units", ".", "append", "(", "tmp", ")", "\n", "", "del_multi_units", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "\"rouge\"", "]", ",", "reverse", "=", "True", ")", "\n", "del_multi_units", "=", "del_multi_units", "[", ":", "topk", "]", "\n", "most_trash_multi_unit", "=", "del_multi_units", "[", "0", "]", "\n", "# return [{\"del_spans\", rouge}]", "\n", "return", "del_multi_units", ",", "most_trash_multi_unit", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.gen_span_segmentation": [[218, 227], ["len", "span_pairs.append"], "function", ["None"], ["", "def", "gen_span_segmentation", "(", "doc_list", ":", "List", "[", "List", "]", ")", ":", "\n", "# generate inclusive span representation", "\n", "    ", "point", "=", "0", "\n", "span_pairs", "=", "[", "]", "\n", "for", "d", "in", "doc_list", ":", "\n", "        ", "l", "=", "len", "(", "d", ")", "\n", "span_pairs", ".", "append", "(", "[", "point", ",", "point", "+", "l", "-", "1", "]", ")", "\n", "point", "+=", "l", "\n", "", "return", "span_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.convert_document_to_read_ready_string": [[229, 346], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "json.loads", "json.loads", "generate_compression_based_data.extract_parse", "generate_compression_based_data.extract_tokens", "rt_sentences.append", "generate_compression_based_data.comp_document_oracle", "generate_compression_based_data.comp_document_oracle", "generate_compression_based_data.gen_span_segmentation", "json.dumps", "open", "fd.read", "open", "fd.read", "generate_compression_based_data.read_single_parse_tree", "len", "generate_compression_based_data.find_deletable_span_rule_based", "rt_del_spans.append", "generate_compression_based_data.comp_oracle_delete_multiple_unit", "generate_compression_based_data.comp_oracle_delete_one_unit", "rt_sentences.append", "doc_list_trimmed_for_oracle.append", "open", "fd.write", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "set", "list", "list.sort", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "os.path.join", "os.path.join", "range", "len", "rt_del_spans.append", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "list", "len", "set", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.gen_span_segmentation", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_rule_based", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_oracle_delete_multiple_unit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_oracle_delete_one_unit", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram"], ["", "def", "convert_document_to_read_ready_string", "(", "path_read", ",", "path_write", ",", "\n", "fname_without_suffix", ":", "str", "\n", ")", ":", "\n", "    ", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "with", "open", "(", "doc_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "doc_str", "=", "fd", ".", "read", "(", ")", "\n", "", "with", "open", "(", "abs_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "abs_str", "=", "fd", ".", "read", "(", ")", "\n", "\n", "", "doc_dict", "=", "json", ".", "loads", "(", "doc_str", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "abs_str", ")", "\n", "doc_parse", "=", "extract_parse", "(", "doc_dict", ")", "\n", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "\n", "rt_sentences", "=", "[", "]", "\n", "\n", "dft", "=", "{", "\"sidx\"", ":", "0", ",", "\n", "\"eidx\"", ":", "1", ",", "\n", "\"node\"", ":", "\"BASELINE\"", ",", "\n", "\"rouge\"", ":", "0", ",", "\n", "\"selected_idx\"", ":", "[", "0", "]", "}", "\n", "# <SOS> Used for pred the end of decoding", "\n", "sent_sos_dict", "=", "{", "\"token\"", ":", "[", "\"<SOS>\"", "]", ",", "\n", "\"del_span\"", ":", "[", "dft", "]", ",", "\n", "\"1-del\"", ":", "[", "dft", "]", ",", "\"n-del\"", ":", "[", "dft", "]", ",", "\"n-del-best\"", ":", "dft", ",", "\"1-del-best\"", ":", "dft", "}", "\n", "\n", "rt_sentences", ".", "append", "(", "sent_sos_dict", ")", "\n", "\n", "for", "sent_parse", "in", "doc_parse", ":", "\n", "\n", "        ", "sent_tree", "=", "read_single_parse_tree", "(", "sent_parse", ")", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "rt_del_spans", "=", "[", "]", "\n", "del_spans", "=", "find_deletable_span_rule_based", "(", "rules", ",", "sent_tree", ")", "\n", "\n", "# List of tree nodes", "\n", "for", "del_sp", "in", "del_spans", ":", "\n", "            ", "full_set", "=", "set", "(", "range", "(", "len", "(", "sent_tree", ".", "text", ")", ")", ")", "\n", "selected_set", "=", "list", "(", "full_set", "-", "set", "(", "range", "(", "del_sp", ".", "start_idx", ",", "del_sp", ".", "end_idx", ")", ")", ")", "\n", "selected_set", ".", "sort", "(", ")", "\n", "text_left", "=", "sent_tree", ".", "text", "[", "0", ":", "del_sp", ".", "start_idx", "]", "+", "sent_tree", ".", "text", "[", "del_sp", ".", "end_idx", ":", "]", "\n", "_txt", "=", "\" \"", ".", "join", "(", "text_left", ")", "\n", "_rouge1", "=", "get_rouge_est_str_4gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "_txt", ")", "\n", "# to prevent nothing to compress, always add the whole sentence itself to the del list?", "\n", "if", "len", "(", "selected_set", ")", ">", "2", ":", "# TODO you have to keep something", "\n", "                ", "rt_del_spans", ".", "append", "(", "{", "\"sidx\"", ":", "del_sp", ".", "start_idx", ",", "\n", "\"eidx\"", ":", "del_sp", ".", "end_idx", ",", "\n", "\"node\"", ":", "del_sp", ".", "tag", ",", "\n", "\"rouge\"", ":", "_rouge1", ",", "\n", "\"selected_idx\"", ":", "selected_set", "}", ")", "\n", "", "", "rt_del_spans", ".", "append", "(", "{", "\"sidx\"", ":", "tree_len", "-", "1", ",", "\n", "\"eidx\"", ":", "tree_len", ",", "\n", "\"node\"", ":", "\"BASELINE\"", ",", "\n", "\"rouge\"", ":", "get_rouge_est_str_4gram", "(", "gold", "=", "abs_str", ",", "pred", "=", "\" \"", ".", "join", "(", "sent_tree", ".", "text", "[", ":", "-", "1", "]", ")", ")", ",", "\n", "\"selected_idx\"", ":", "list", "(", "range", "(", "tree_len", "-", "1", ")", ")", "}", ")", "\n", "# rt_del_spans.append({\"sidx\": sent_tree.start_idx,", "\n", "#                      \"eidx\": sent_tree.end_idx,", "\n", "#                      \"node\": \"ALL\",", "\n", "#                      \"rouge\": 0,", "\n", "#                      \"selected_idx\": []})", "\n", "\n", "del_multi_units", ",", "most_trash_multi_unit", "=", "comp_oracle_delete_multiple_unit", "(", "abs_str", ",", "sent_tree", ",", "rt_del_spans", ",", "\n", "topk", ")", "# delete multi and best delete multi", "\n", "\n", "# delete 1 and best delete 1", "\n", "del_single_units", ",", "most_trash_single_unit", "=", "comp_oracle_delete_one_unit", "(", "sent_tree", ",", "rt_del_spans", ",", "topk", ")", "\n", "\n", "sent_pack", "=", "{", "\"token\"", ":", "sent_tree", ".", "text", ",", "\"del_span\"", ":", "rt_del_spans", ",", "\n", "\"1-del\"", ":", "del_single_units", ",", "\"1-del-best\"", ":", "most_trash_single_unit", ",", "\n", "\"n-del\"", ":", "del_multi_units", ",", "\"n-del-best\"", ":", "most_trash_multi_unit", "\n", "}", "\n", "rt_sentences", ".", "append", "(", "sent_pack", ")", "\n", "# print(\"Finding Oracle ...\")", "\n", "# Sentence Level Oracle", "\n", "", "doc_list_for_oracle", "=", "[", "\" \"", ".", "join", "(", "x", "[", "'token'", "]", ")", "for", "x", "in", "rt_sentences", "]", "\n", "sent_ora_json", "=", "comp_document_oracle", "(", "doc_list_for_oracle", ",", "abs_str", ")", "\n", "#", "\n", "\n", "# Subsentence Level Oracle", "\n", "doc_list_trimmed_for_oracle", "=", "[", "]", "\n", "for", "x", "in", "rt_sentences", ":", "\n", "        ", "doc_list_trimmed_for_oracle", ".", "append", "(", "\" \"", ".", "join", "(", "[", "x", "[", "\"token\"", "]", "[", "kdx", "]", "for", "kdx", "in", "x", "[", "'1-del-best'", "]", "[", "'selected_idx'", "]", "]", ")", ")", "\n", "", "trim_ora_json", "=", "comp_document_oracle", "(", "doc_list_trimmed_for_oracle", ",", "abs_str", ")", "\n", "# print(\"Oracle found\")", "\n", "# Return the datapack", "\n", "rt", "=", "{", "}", "\n", "rt", "[", "\"name\"", "]", "=", "fname_without_suffix", "\n", "span_pairs", "=", "gen_span_segmentation", "(", "[", "x", "[", "'token'", "]", "for", "x", "in", "rt_sentences", "]", ")", "\n", "rt", "[", "\"abs\"", "]", "=", "abs_str", "\n", "rt", "[", "\"abs_token\"", "]", "=", "abs_token", "\n", "rt", "[", "\"token\"", "]", "=", "\" \"", ".", "join", "(", "doc_list_for_oracle", ")", "\n", "rt", "[", "\"token_list\"", "]", "=", "[", "x", "[", "'token'", "]", "for", "x", "in", "rt_sentences", "]", "\n", "rt", "[", "\"span\"", "]", "=", "span_pairs", "\n", "rt", "[", "\"sentences\"", "]", "=", "rt_sentences", "\n", "rt", "[", "\"sent_oracle\"", "]", "=", "sent_ora_json", "\n", "rt", "[", "\"sent_oracle_trim\"", "]", "=", "trim_ora_json", "\n", "\n", "# output format: document{ name:str,", "\n", "# '<SOS>' + @@SS@@'.join tokens_all, sentence segmentation span,", "\n", "# sentences:[", "\n", "# start idx,", "\n", "# end idx,", "\n", "# token list,", "\n", "# deletable spans:[relative startidx in the sentence, relative endidx, nodetype, rouge(slot kept)],", "\n", "# what if nothing deletable?  always add the the whole sentence", "\n", "# top k  trimed version (multiple oracle) [ combination of deletable spans]", "\n", "# oracle: sentence level oracle (n of n)", "\n", "#           trimed sentence level (n of n)", "\n", "# TODO compression version: [ tokens+license+rouge(slot), tokens+license+rouge,... ]", "\n", "# TODO or trash candidate : [tokens+rouge,...]", "\n", "#  ] }", "\n", "json_rt", "=", "json", ".", "dumps", "(", "rt", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_write", ",", "fname_without_suffix", "+", "'.data'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "json_rt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.comp_document_oracle": [[348, 391], ["len", "range", "range", "d.strip", "neusum.evaluation.rough_rouge.get_rouge_est_str_4gram", "f_score_list.append", "numpy.argsort", "len", "filtered_doc_list.append", "map_from_new_to_ori_idx.append", "neusum.data.generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam", "abs_str.split"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_oracle_with_dplp.comp_num_seg_out_of_p_sent_beam"], ["", "", "def", "comp_document_oracle", "(", "doc_list", ":", "List", ",", "abs_str", ",", "beam_sz", "=", "5", ")", ":", "\n", "    ", "\"\"\"\n    Given a document and the abstraction string, return the oracle set combination\n    :param doc_list: List of strings.\n    :param abs_str: a single string with \\n\n    :param name:\n    :return:\n    \"\"\"", "\n", "doc_list", "=", "[", "d", ".", "strip", "(", ")", "for", "d", "in", "doc_list", "]", "# trim", "\n", "# for d in doc_list:", "\n", "#     assert len(d) > 0", "\n", "len_of_doc", "=", "len", "(", "doc_list", ")", "\n", "doc_as_readable_list", "=", "doc_list", "\n", "abs_as_readable_list", "=", "[", "x", "for", "x", "in", "abs_str", ".", "split", "(", "\"\\n\"", ")", "if", "(", "x", "!=", "\"\"", ")", "and", "(", "x", "!=", "\" \"", ")", "]", "# no SS and \\n", "\n", "\n", "f_score_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len_of_doc", ")", ":", "\n", "        ", "f1", "=", "get_rouge_est_str_4gram", "(", "gold", "=", "'\\n'", ".", "join", "(", "abs_as_readable_list", ")", ",", "\n", "pred", "=", "doc_as_readable_list", "[", "i", "]", ")", "\n", "\n", "f_score_list", ".", "append", "(", "f1", ")", "\n", "", "top_p_sent_idx", "=", "numpy", ".", "argsort", "(", "f_score_list", ")", "[", "-", "P_SENT", ":", "]", "\n", "\n", "map_from_new_to_ori_idx", "=", "[", "]", "\n", "# filter", "\n", "filtered_doc_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "top_p_sent_idx", ")", ")", ":", "\n", "        ", "filtered_doc_list", ".", "append", "(", "doc_as_readable_list", "[", "top_p_sent_idx", "[", "i", "]", "]", ")", "\n", "map_from_new_to_ori_idx", ".", "append", "(", "top_p_sent_idx", "[", "i", "]", ")", "\n", "\n", "# filter_doc_list stores filtered doc", "\n", "# map_from_new_to_ori_idx contains their original index", "\n", "", "combination_data_dict", "=", "{", "}", "\n", "for", "num_of_edu", "in", "NUM_EDU", ":", "\n", "        ", "combination_data", "=", "comp_num_seg_out_of_p_sent_beam", "(", "_filtered_doc_list", "=", "filtered_doc_list", ",", "\n", "_num_edu", "=", "num_of_edu", ",", "\n", "_absas_read_str", "=", "abs_str", ",", "\n", "abs_as_read_list", "=", "abs_as_readable_list", ",", "\n", "map_from_new_to_ori_idx", "=", "map_from_new_to_ori_idx", ",", "\n", "beam_sz", "=", "beam_sz", ")", "\n", "combination_data_dict", "[", "num_of_edu", "]", "=", "combination_data", "\n", "# json_str = json.dumps(combination_data_dict)", "\n", "", "return", "combination_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_ungrammar": [[393, 441], ["buff_node.append", "generate_compression_based_data.TreeNode", "unified_bag.append", "generate_compression_based_data.TreeNode", "unified_bag.append", "generate_compression_based_data.find_deletable_span_ungrammar"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.find_deletable_span_ungrammar"], ["", "def", "find_deletable_span_ungrammar", "(", "merge_size", ",", "depth", ",", "tree", ":", "TreeNode", ")", ":", "\n", "    ", "un_unified_bag", "=", "[", "]", "\n", "if", "tree", ".", "depth", "<", "depth", ":", "\n", "        ", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "            ", "for", "child", "in", "tree", ".", "children", ":", "\n", "                ", "un_unified_bag", "+=", "find_deletable_span_ungrammar", "(", "merge_size", ",", "depth", ",", "child", ")", "\n", "\n", "", "", "else", ":", "\n", "# Reach leaf node", "\n", "            ", "return", "[", "tree", "]", "\n", "", "", "elif", "tree", ".", "depth", "==", "depth", ":", "\n", "        ", "return", "[", "tree", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "if", "tree", ".", "depth", "!=", "0", ":", "\n", "        ", "return", "un_unified_bag", "\n", "", "unified_bag", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "buff_node", "=", "[", "]", "\n", "buff_l", "=", "0", "\n", "buff_start", "=", "-", "1", "\n", "buff_end", "=", "-", "1", "\n", "for", "item", "in", "un_unified_bag", ":", "\n", "        ", "if", "buff_start", "==", "-", "1", ":", "\n", "            ", "buff_start", "=", "item", ".", "start_idx", "\n", "", "buff_end", "=", "item", ".", "end_idx", "\n", "l", "=", "item", ".", "end_idx", "-", "item", ".", "start_idx", "\n", "buff_l", "+=", "l", "\n", "buff", "+=", "item", ".", "text", "\n", "buff_node", ".", "append", "(", "item", ".", "tag", ")", "\n", "if", "buff_l", ">", "merge_size", ":", "\n", "            ", "newnode", "=", "TreeNode", "(", "tag", "=", "\"-\"", ".", "join", "(", "buff_node", ")", ",", "text", "=", "buff", ",", "\n", "children", "=", "None", ",", "depth", "=", "depth", ")", "\n", "newnode", ".", "start_idx", "=", "buff_start", "\n", "newnode", ".", "end_idx", "=", "buff_end", "\n", "unified_bag", ".", "append", "(", "newnode", ")", "\n", "buff", "=", "[", "]", "\n", "buff_node", "=", "[", "]", "\n", "buff_l", "=", "0", "\n", "buff_start", "=", "-", "1", "\n", "", "", "if", "buff", "!=", "[", "]", ":", "\n", "        ", "newnode", "=", "TreeNode", "(", "tag", "=", "\"-\"", ".", "join", "(", "buff_node", ")", ",", "text", "=", "buff", ",", "\n", "children", "=", "None", ",", "depth", "=", "depth", ")", "\n", "newnode", ".", "start_idx", "=", "buff_start", "\n", "newnode", ".", "end_idx", "=", "buff_end", "\n", "assert", "buff_end", ">", "buff_start", "\n", "unified_bag", ".", "append", "(", "newnode", ")", "\n", "", "return", "unified_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.hashhex": [[449, 454], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.get_url_hashes": [[456, 463], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_one_file": [[465, 473], ["os.path.isfile", "os.path.isfile", "open", "fd.read().splitlines", "len", "fd.read"], "function", ["None"], ["", "def", "read_one_file", "(", "fname", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "fname", "+", "'.data'", ")", ":", "\n", "        ", "with", "open", "(", "fname", "+", "'.data'", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "line", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "assert", "len", "(", "line", ")", "==", "1", "\n", "", "return", "line", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.move_file_to_dir_url": [[475, 493], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "open", "fd.read().splitlines", "generate_compression_based_data.get_url_hashes", "print", "os.path.join", "os.path.join", "open", "fd.write", "fd.read", "len"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes"], ["", "", "def", "move_file_to_dir_url", "(", "url_file", ",", "path_read", ",", "file_to_write", ")", ":", "\n", "    ", "with", "open", "(", "url_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "\n", "", "url_names", "=", "[", "os", ".", "path", ".", "join", "(", "path_read", ",", "url", ")", "for", "url", "in", "url_names", "]", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "rt_bag", "=", "pool", ".", "map", "(", "read_one_file", ",", "url_names", ")", "\n", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "rt_bag", "=", "[", "x", "for", "x", "in", "rt_bag", "if", "x", "is", "not", "None", "]", "\n", "wt_string", "=", "\"\\n\"", ".", "join", "(", "rt_bag", ")", "\n", "with", "open", "(", "file_to_write", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "wt_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.__init__": [[63, 83], ["allennlp.data.dataset_readers.DatasetReader.__init__", "cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.build_vocab", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.build_vocab"], ["    ", "def", "__init__", "(", "self", ",", "\n", "source_token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "# word token indexer", "\n", "dir", ":", "str", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "True", ",", "\n", "single_oracle", "=", "True", ",", "\n", "fix_edu_num", "=", "None", ",", "\n", "trim_sent_oracle", ":", "bool", "=", "True", ",", "\n", "vocab_path", ":", "str", "=", "\"\"", ",", "\n", "save_to", ":", "str", "=", "None", ",", "\n", "dbg", ":", "bool", "=", "False", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "word_token_indexers", "=", "source_token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "self", ".", "single_oracle", "=", "single_oracle", "\n", "self", ".", "fix_edu_num", "=", "fix_edu_num", "\n", "self", ".", "vocab", "=", "None", "\n", "self", ".", "trim_oracle", "=", "trim_sent_oracle", "\n", "self", ".", "build_vocab", "(", "vocab_path", ",", "save_to", "=", "save_to", ")", "\n", "self", ".", "dir", "=", "dir", "\n", "self", ".", "dbg", "=", "dbg", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.build_vocab": [[84, 106], ["os.path.isdir", "allennlp.data.vocabulary.Vocabulary.from_instances", "logging.info", "open", "cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.vocab.save_to_files", "allennlp.data.vocabulary.Vocabulary.from_files", "print", "logging.info", "json.loads", "allennlp.data.fields.TextField", "instances.append", "int", "print", "allennlp.data.instance.Instance", "cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.vocab.get_vocab_size", "int", "allennlp.data.tokenizers.Token", "cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.vocab.get_vocab_size", "doc_str.split"], "methods", ["None"], ["", "def", "build_vocab", "(", "self", ",", "file_path", ",", "save_to", ":", "str", "=", "None", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "save_to", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "vocab", "=", "Vocabulary", ".", "from_files", "(", "save_to", ")", "\n", "print", "(", "\"Load vocab success\"", ")", "\n", "logging", ".", "info", "(", "\"Vocab size: {}\"", ".", "format", "(", "int", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", ")", ")", ")", ")", "\n", "return", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Failed in loading pre-saved vocab.\"", ")", "\n", "", "", "raise", "NotImplementedError", "\n", "instances", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "for", "line", "in", "fd", ":", "\n", "                ", "data_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "doc_str", "=", "data_dict", "[", "'doc'", "]", "\n", "allen_token_word_in_doc", "=", "TextField", "(", "[", "Token", "(", "word", ")", "for", "word", "in", "doc_str", ".", "split", "(", ")", "]", ",", "self", ".", "word_token_indexers", ")", "\n", "instances", ".", "append", "(", "Instance", "(", "{", "\"text\"", ":", "allen_token_word_in_doc", "}", ")", ")", "\n", "", "", "self", ".", "vocab", "=", "Vocabulary", ".", "from_instances", "(", "instances", ",", "min_count", "=", "{", "'tokens'", ":", "10", "}", ")", "\n", "if", "save_to", "is", "not", "None", ":", "\n", "            ", "self", ".", "vocab", ".", "save_to_files", "(", "save_to", ")", "\n", "", "logging", ".", "info", "(", "\"Vocab size: {}\"", ".", "format", "(", "int", "(", "self", ".", "vocab", ".", "get_vocab_size", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl._read": [[107, 165], ["print", "file_path.startswith", "random.shuffle", "print", "logging.info", "open", "pickle.load", "file_path.startswith", "file_path.startswith", "os.path.join", "instance_fields.pop", "instance_fields.pop", "cnndm_dataset_read_pkl.filter_oracle_label", "os.listdir", "x.startswith", "max", "enumerate", "numpy.asarray", "numpy.asarray", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl._read.edit_label_rouge"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.filter_oracle_label"], ["", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterable", "[", "Instance", "]", ":", "\n", "        ", "assert", "self", ".", "vocab", "is", "not", "None", "\n", "# patten: file_path= train.pkl    .* pattern!!!!", "\n", "\n", "print", "(", "\"Into the read function. FP: {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "\n", "if", "file_path", ".", "startswith", "(", "\"train\"", ")", ":", "\n", "            ", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "self", ".", "dir", ")", "if", "x", ".", "startswith", "(", "file_path", ")", "]", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "if", "self", ".", "dbg", ":", "\n", "                ", "files", "=", "files", "[", ":", "1", "]", "\n", "", "else", ":", "\n", "                ", "files", "=", "files", "[", ":", "6", "]", "\n", "", "", "elif", "file_path", ".", "startswith", "(", "\"test\"", ")", "or", "file_path", ".", "startswith", "(", "\"dev\"", ")", ":", "\n", "            ", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "self", ".", "dir", ")", "if", "x", ".", "startswith", "(", "file_path", ")", "]", "\n", "# files = files[:1]", "\n", "\n", "", "for", "file", "in", "files", ":", "\n", "            ", "print", "(", "\"Reading {}\"", ".", "format", "(", "file", ")", ")", "\n", "logging", ".", "info", "(", "\"Reading {}\"", ".", "format", "(", "file", ")", ")", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "dir", ",", "file", ")", ",", "'rb'", ")", "\n", "\n", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "for", "instance_fields", "in", "data", ":", "\n", "\n", "                ", "if", "self", ".", "trim_oracle", ":", "\n", "                    ", "sent_oracle", "=", "instance_fields", "[", "'_sent_oracle'", "]", "\n", "", "else", ":", "\n", "                    ", "sent_oracle", "=", "instance_fields", "[", "'_non_compression_sent_oracle'", "]", "\n", "", "instance_fields", ".", "pop", "(", "'_sent_oracle'", ")", "\n", "instance_fields", ".", "pop", "(", "'_non_compression_sent_oracle'", ")", "\n", "# instance_fields['_sent_oracle'] = None", "\n", "# instance_fields['_non_compression_sent_oracle'] = None", "\n", "\n", "sent_label_list", ",", "sent_rouge_list", "=", "filter_oracle_label", "(", "self", ".", "single_oracle", ",", "\n", "self", ".", "fix_edu_num", ",", "sent_oracle", ")", "\n", "\n", "def", "edit_label_rouge", "(", "_label_list", ",", "_rouge_list", ")", ":", "\n", "                    ", "_label_list", "=", "[", "x", "for", "x", "in", "_label_list", "]", "\n", "_max_len", "=", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "_label_list", "]", ")", "\n", "for", "idx", ",", "label", "in", "enumerate", "(", "_label_list", ")", ":", "\n", "                        ", "if", "len", "(", "label", ")", "<", "_max_len", ":", "\n", "                            ", "_label_list", "[", "idx", "]", "=", "_label_list", "[", "idx", "]", "+", "[", "-", "1", "]", "*", "(", "_max_len", "-", "len", "(", "label", ")", ")", "\n", "", "", "np_gold_label", "=", "np", ".", "asarray", "(", "_label_list", ",", "dtype", "=", "np", ".", "int", ")", "\n", "f", "=", "ArrayField", "(", "array", "=", "np_gold_label", ",", "padding_value", "=", "-", "1", ")", "\n", "\n", "r", "=", "ArrayField", "(", "np", ".", "asarray", "(", "_rouge_list", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "return", "f", ",", "r", "\n", "\n", "", "if", "sent_label_list", "and", "sent_rouge_list", ":", "\n", "                    ", "label", ",", "rouge", "=", "edit_label_rouge", "(", "_label_list", "=", "sent_label_list", ",", "\n", "_rouge_list", "=", "sent_rouge_list", ")", "\n", "instance_fields", "[", "\"sent_label\"", "]", "=", "label", "\n", "instance_fields", "[", "\"sent_rouge\"", "]", "=", "rouge", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "yield", "self", ".", "text_to_instance", "(", "instance_fields", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.SummarizationDatasetReaderPkl.text_to_instance": [[167, 170], ["allennlp.data.instance.Instance"], "methods", ["None"], ["", "", "", "def", "text_to_instance", "(", "self", ",", "instance_fields", "\n", ")", "->", "Instance", ":", "\n", "        ", "return", "Instance", "(", "instance_fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.cnndm_dataset_read_pkl.filter_oracle_label": [[22, 57], ["str", "cur_data.items", "labels.items", "NotImplementedError", "rt_data.append", "rt_rouge.append", "data.items", "sorted", "range", "range", "rt_data.append", "rt_rouge.append", "enumerate", "len", "len", "str"], "function", ["None"], ["def", "filter_oracle_label", "(", "single_oracle", ",", "fix_edu_num", ",", "labels", ":", "Dict", ")", ":", "\n", "    ", "\"\"\"\n\n    :param single_oracle:\n    :param fix_edu_num:\n    :param labels:\n    :return: List[List], List[float]\n    \"\"\"", "\n", "if", "single_oracle", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "        ", "if", "fix_edu_num", ">", "0", ":", "\n", "            ", "rt_data", ",", "rt_rouge", "=", "[", "]", ",", "[", "]", "\n", "if", "str", "(", "fix_edu_num", ")", "in", "labels", ":", "\n", "                ", "cur_data", "=", "labels", "[", "str", "(", "fix_edu_num", ")", "]", "[", "'data'", "]", "\n", "for", "k", ",", "v", "in", "cur_data", ".", "items", "(", ")", ":", "\n", "                    ", "rt_data", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "rt_rouge", ".", "append", "(", "v", "[", "'R1'", "]", ")", "\n", "", "", "", "elif", "fix_edu_num", "==", "-", "1", ":", "\n", "            ", "fix_edu_num", "=", "2", "# just in case", "\n", "rt_data", ",", "rt_rouge", "=", "[", "]", ",", "[", "]", "\n", "for", "n", ",", "lab", "in", "labels", ".", "items", "(", ")", ":", "\n", "                ", "data", "=", "lab", "[", "'data'", "]", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "                    ", "rt_data", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "rt_rouge", ".", "append", "(", "v", "[", "'R1'", "]", ")", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Fix_edu_num == -1 or 2,3,4,5..\"", ")", "\n", "", "if", "not", "rt_rouge", ":", "\n", "            ", "return", "[", "[", "0", "]", "*", "fix_edu_num", "]", ",", "[", "0.1", "]", "\n", "", "else", ":", "\n", "            ", "sort_idx", "=", "[", "i", "[", "0", "]", "for", "i", "in", "sorted", "(", "enumerate", "(", "rt_rouge", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "sort_rt_data", "=", "[", "rt_data", "[", "sort_idx", "[", "idx", "]", "]", "for", "idx", "in", "range", "(", "len", "(", "rt_data", ")", ")", "]", "\n", "sort_rt_rouge", "=", "[", "rt_rouge", "[", "sort_idx", "[", "idx", "]", "]", "for", "idx", "in", "range", "(", "len", "(", "rt_rouge", ")", ")", "]", "\n", "return", "sort_rt_data", ",", "sort_rt_rouge", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.sent_tok": [[22, 35], ["nltk.tokenize.sent_tokenize", "nltk.tokenize.sent_tokenize", "open", "fd.read", "open", "fd.write", "open", "fd.read", "open", "fd.write", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "len"], "function", ["None"], ["def", "sent_tok", "(", "dir", ",", "name", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "name", "+", "'.doc'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "doc_list", "=", "fd", ".", "read", "(", ")", "\n", "", "doc_list", "=", "sent_tokenize", "(", "doc_list", ")", "\n", "doc_list", "=", "[", "x", "for", "x", "in", "doc_list", "if", "(", "len", "(", "x", ")", "<=", "500", "and", "len", "(", "x", ")", ">", "20", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "name", "+", "'.doc'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "doc_list", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "name", "+", "'.abs'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "abss", "=", "fd", ".", "read", "(", ")", "\n", "", "abs_list", "=", "sent_tokenize", "(", "abss", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "name", "+", "'.abs'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "abs_list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.prepare_toked_file": [[42, 51], ["len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "zip", "x.split", "os.listdir", "x.endswith"], "function", ["None"], ["def", "prepare_toked_file", "(", "read_path", ")", ":", "\n", "    ", "file_names", "=", "[", "x", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "x", "in", "os", ".", "listdir", "(", "read_path", ")", "if", "x", ".", "endswith", "(", "\".doc\"", ")", "]", "\n", "l", "=", "len", "(", "file_names", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pool", ".", "starmap", "(", "sent_tok", ",", "zip", "(", "[", "read_path", "]", "*", "l", ",", "file_names", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "print", "(", "\"finish sentence tokenization!\"", ")", "\n", "# sent_tok(read_path, file_names[0])", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.pred_batch": [[54, 62], ["predictor.predict", "rt_bag.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.predict"], ["", "def", "pred_batch", "(", "sentences", ")", ":", "\n", "    ", "rt_bag", "=", "[", "]", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "out", "=", "predictor", ".", "predict", "(", "\n", "sentence", "=", "s", "\n", ")", "\n", "rt_bag", ".", "append", "(", "out", "[", "'tree'", "]", ")", "\n", "", "return", "rt_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.divide_a_list_into_n_pieces": [[64, 66], ["len"], "function", ["None"], ["", "def", "divide_a_list_into_n_pieces", "(", "inp_list", ",", "n", ")", ":", "\n", "    ", "l", "=", "len", "(", "inp_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.wt_todo_to_disk": [[68, 88], ["len", "int", "range", "os.path.join", "os.path.join", "len", "len", "print", "bag.append", "open", "fd.write", "os.path.join", "os.path.join", "os.path.join", "zip"], "function", ["None"], ["", "def", "wt_todo_to_disk", "(", "path_todo", ",", "path_read", ",", "path_wt", ",", "files", ",", "batch_num", ":", "int", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "l", "=", "len", "(", "files", ")", "\n", "rd_files", "=", "[", "os", ".", "path", ".", "join", "(", "path_read", ",", "x", ")", "for", "x", "in", "files", "]", "\n", "wt_files", "=", "[", "os", ".", "path", ".", "join", "(", "path_wt", ",", "x", "+", "'.json'", ")", "for", "x", "in", "files", "]", "\n", "assert", "len", "(", "rd_files", ")", "==", "len", "(", "wt_files", ")", "\n", "unit_size", "=", "int", "(", "l", "/", "batch_num", ")", "\n", "bag", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "batch_num", ")", ":", "\n", "        ", "if", "idx", "==", "l", "-", "1", ":", "\n", "            ", "fr", "=", "rd_files", "[", "idx", "*", "unit_size", ":", "]", "\n", "fw", "=", "wt_files", "[", "idx", "*", "unit_size", ":", "]", "\n", "", "else", ":", "\n", "            ", "fr", "=", "rd_files", "[", "idx", "*", "unit_size", ":", "(", "idx", "+", "1", ")", "*", "unit_size", "]", "\n", "fw", "=", "wt_files", "[", "idx", "*", "unit_size", ":", "(", "idx", "+", "1", ")", "*", "unit_size", "]", "\n", "", "fline", "=", "\"\\n\"", ".", "join", "(", "[", "r", "+", "'\\t'", "+", "w", "for", "r", ",", "w", "in", "zip", "(", "fr", ",", "fw", ")", "]", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_todo", ",", "\"task-{}\"", ".", "format", "(", "idx", ")", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "fline", ")", "\n", "", "print", "(", "\"Finish writing {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "path_todo", ",", "\"task-{}\"", ".", "format", "(", "idx", ")", ")", ")", ")", "\n", "bag", ".", "append", "(", "os", ".", "path", ".", "join", "(", "path_todo", ",", "\"task-{}\"", ".", "format", "(", "idx", ")", ")", ")", "\n", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.run_on_server_w_gpus": [[90, 102], ["full_data_pipeline.compare_bf_and_af", "full_data_pipeline.wt_todo_to_disk", "print"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.compare_bf_and_af", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.wt_todo_to_disk"], ["", "def", "run_on_server_w_gpus", "(", "path_root", ",", "path_bf", ",", "path_af", ",", "path_model", ",", "path_exComp", ")", ":", "\n", "# compare bf after", "\n", "    ", "file_gap", "=", "compare_bf_and_af", "(", "path_bf", ",", "path_af", ")", "\n", "task_address", "=", "wt_todo_to_disk", "(", "path_todo", "=", "path_root", ",", "path_read", "=", "path_bf", ",", "path_wt", "=", "path_af", ",", "files", "=", "file_gap", ",", "\n", "batch_num", "=", "1", ")", "\n", "cnt", "=", "0", "\n", "for", "ta", "in", "task_address", ":", "\n", "        ", "cmd", "=", "(", "\n", "\"python {}/neusum/data/py_run_gpu.py {} {} {}\"", ".", "format", "(", "path_exComp", ",", "\n", "ta", ",", "cnt", "%", "8", ",", "path_model", ")", ")", "\n", "cnt", "+=", "1", "\n", "print", "(", "cmd", ")", "\n", "# command = cmd.split(' ')", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.run_on_one_gpu": [[106, 120], ["allennlp.models.archival.load_archive", "allennlp.predictors.predictor.Predictor.from_archive", "Predictor.from_archive.predict", "print", "bag.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.predict"], ["", "", "def", "run_on_one_gpu", "(", "path_model", ",", "input", ":", "List", "=", "None", ",", "cuda_device_id", ":", "int", "=", "0", ")", ":", "\n", "    ", "arc", "=", "load_archive", "(", "\n", "archive_file", "=", "path_model", ",", "\n", "cuda_device", "=", "cuda_device_id", ")", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", "=", "arc", ")", "\n", "bag", "=", "[", "]", "\n", "for", "s", "in", "input", ":", "\n", "        ", "out", "=", "predictor", ".", "predict", "(", "\n", "sentence", "=", "s", "\n", ")", "\n", "print", "(", "out", "[", "\"trees\"", "]", ")", "\n", "\n", "bag", ".", "append", "(", "out", "[", "'trees'", "]", ")", "\n", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.compare_bf_and_af": [[125, 132], ["os.listdir", "os.listdir", "list", "random.shuffle", "set", "set", "x.split"], "function", ["None"], ["def", "compare_bf_and_af", "(", "path_bf", ",", "path_af", ")", "->", "List", ":", "\n", "    ", "files_bf", "=", "os", ".", "listdir", "(", "path_bf", ")", "\n", "files_af", "=", "os", ".", "listdir", "(", "path_af", ")", "\n", "files_af_match", "=", "[", "\".\"", ".", "join", "(", "x", ".", "split", "(", "\".\"", ")", "[", ":", "2", "]", ")", "for", "x", "in", "files_af", "]", "\n", "file_gap", "=", "list", "(", "set", "(", "files_bf", ")", "-", "set", "(", "files_af_match", ")", ")", "\n", "random", ".", "shuffle", "(", "file_gap", ")", "\n", "return", "file_gap", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.full_data_pipeline.clear_dir": [[137, 141], ["os.path.isdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.merge_cnn_dm": [[19, 52], ["open", "pickle.load", "open.close", "open", "pickle.load", "open.close", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation", "zip", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "fine_cnn_pd.append", "fine_dm_pd.append", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.", "neusum.service.basic_service.easy_post_processing", "neusum.service.basic_service.easy_post_processing"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.service.basic_service.easy_post_processing"], ["def", "merge_cnn_dm", "(", ")", ":", "\n", "    ", "cnn", "=", "\"/scratch/cluster/jcxu/exComp/0.327,0.122,0.290-cnnTrue1.0-1True3-1093-cp_0.5\"", "\n", "dm", "=", "\"/scratch/cluster/jcxu/exComp/0.427,0.192,0.388-dmTrue1.0-1True3-10397-cp_0.7\"", "\n", "total_pred", "=", "[", "]", "\n", "total_ref", "=", "[", "]", "\n", "f", "=", "open", "(", "cnn", ",", "\"rb\"", ")", "\n", "cnn_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "fine_cnn_pd", "=", "[", "]", "\n", "for", "x", "in", "cnn_dict", "[", "\"pred\"", "]", ":", "\n", "        ", "fine_x", "=", "[", "easy_post_processing", "(", "s", ")", "for", "s", "in", "x", "]", "\n", "fine_cnn_pd", ".", "append", "(", "fine_x", ")", "\n", "", "total_pred", "+=", "fine_cnn_pd", "\n", "# total_pred += cnn_dict[\"pred\"]", "\n", "total_ref", "+=", "cnn_dict", "[", "\"ref\"", "]", "\n", "\n", "f", "=", "open", "(", "dm", ",", "\"rb\"", ")", "\n", "dm_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "fine_dm_pd", "=", "[", "]", "\n", "for", "x", "in", "dm_dict", "[", "\"pred\"", "]", ":", "\n", "        ", "fine_x", "=", "[", "easy_post_processing", "(", "s", ")", "for", "s", "in", "x", "]", "\n", "fine_dm_pd", ".", "append", "(", "fine_x", ")", "\n", "", "total_pred", "+=", "fine_dm_pd", "\n", "# cnnpd = [easy_post_processing(x) for x in dm_dict[\"pred\"]]", "\n", "# total_pred += cnnpd", "\n", "# total_pred += dm_dict[\"pred\"]", "\n", "# total_pred += dm_dict[\"pred\"]", "\n", "total_ref", "+=", "dm_dict", "[", "\"ref\"", "]", "\n", "rouge_metrics", "=", "RougeStrEvaluation", "(", "name", "=", "'mine'", ")", "\n", "for", "p", ",", "r", "in", "zip", "(", "total_pred", ",", "total_ref", ")", ":", "\n", "        ", "rouge_metrics", "(", "pred", "=", "p", ",", "ref", "=", "r", ")", "\n", "", "rouge_metrics", ".", "get_metric", "(", "True", ",", "note", "=", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.my_lead3": [[54, 78], ["print", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation", "print", "enumerate", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "print", "open", "print", "pickle.load", "os.listdir", "os.listdir", "x.startswith", "os.path.join", "os.path.join", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation."], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric"], ["", "def", "my_lead3", "(", ")", ":", "\n", "    ", "data_path", "=", "\"/scratch/cluster/jcxu/data/2merge-nyt\"", "\n", "print", "(", "data_path", ")", "\n", "lead", "=", "3", "\n", "if", "'nyt'", "in", "data_path", ":", "\n", "        ", "lead", "=", "5", "\n", "", "files", "=", "[", "x", "for", "x", "in", "os", ".", "listdir", "(", "data_path", ")", "if", "x", ".", "startswith", "(", "\"test.pkl\"", ")", "]", "\n", "rouge_metrics_sent", "=", "RougeStrEvaluation", "(", "name", "=", "'mine'", ")", "\n", "import", "pickle", "\n", "print", "(", "lead", ")", "\n", "for", "idx", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "print", "(", "idx", ")", "\n", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "file", ")", ",", "'rb'", ")", "\n", "print", "(", "\"reading {}\"", ".", "format", "(", "file", ")", ")", "\n", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "for", "instance_fields", "in", "data", ":", "\n", "            ", "meta", "=", "instance_fields", "[", "'metadata'", "]", "\n", "doc_list", "=", "meta", "[", "'doc_list'", "]", "[", ":", "lead", "]", "\n", "abs_list", "=", "meta", "[", "'abs_list'", "]", "\n", "\n", "doc_list", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "doc_list", "]", "\n", "abs_list", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "abs_list", "]", "\n", "rouge_metrics_sent", "(", "pred", "=", "doc_list", ",", "ref", "=", "[", "abs_list", "]", ")", "\n", "", "", "rouge_metrics_sent", ".", "get_metric", "(", "True", ",", "note", "=", "'test'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.hashhex": [[80, 85], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["", "def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.get_url_hashes": [[87, 94], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.get_refresh_metric": [[96, 141], ["print", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation", "print", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "open", "fd.read().splitlines", "get_lead_3.get_url_hashes", "print", "open", "fd.read().splitlines", "get_lead_3.get_url_hashes", "print", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.", "neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.", "fd.read", "len", "open", "fd.read().splitlines", "open", "fd.read().splitlines", "print", "fd.read", "len", "open", "fd.read().splitlines", "open", "fd.read().splitlines", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fd.read", "fd.read", "fd.read", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes"], ["", "def", "get_refresh_metric", "(", ")", ":", "\n", "    ", "gold_path", "=", "\"/backup3/jcxu/data/gold-cnn-dailymail-test-orgcase\"", "\n", "# 0034b7c223e24477e046cf3ee085dd006be38b27.gold", "\n", "model_path", "=", "\"/backup3/jcxu/data/cnn-dailymail-ensemble-model11-model7\"", "\n", "# 0034b7c223e24477e046cf3ee085dd006be38b27.model", "\n", "full_dataname", "=", "\"cnn\"", "\n", "\n", "test_urls", "=", "'/backup3/jcxu/data/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "\n", "with", "open", "(", "test_urls", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "", "print", "(", "url_names", "[", "0", "]", ")", "\n", "rouge_metrics_sent", "=", "RougeStrEvaluation", "(", "name", "=", "'refresh'", ")", "\n", "for", "url", "in", "url_names", ":", "\n", "# gold", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "gold_path", ",", "url", "+", "'.gold'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "                ", "abs", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "url", "+", "'.model'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "                ", "pred", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "rouge_metrics_sent", "(", "pred", "=", "pred", ",", "ref", "=", "[", "abs", "]", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "print", "(", "url", ")", "\n", "", "", "full_dataname", "=", "\"dailymail\"", "\n", "\n", "test_urls", "=", "'/backup3/jcxu/data/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "\n", "with", "open", "(", "test_urls", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "", "print", "(", "url_names", "[", "0", "]", ")", "\n", "for", "url", "in", "url_names", ":", "\n", "# gold", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "gold_path", ",", "url", "+", "'.gold'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "                ", "abs", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "url", "+", "'.model'", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "                ", "pred", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "rouge_metrics_sent", "(", "pred", "=", "pred", ",", "ref", "=", "[", "abs", "]", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "print", "(", "url", ")", "\n", "", "", "rouge_metrics_sent", ".", "get_metric", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.get_xxz_metric": [[146, 173], ["range", "open", "fd.read().splitlines", "int", "open", "fd.read().splitlines", "[].split", "art.split", "list", "enumerate", "tuple.strip", "tuple_list.split.split", "probs.append", "numpy.argsort", "fd.read", "len", "fd.read", "float", "bag.append", "dist.split"], "function", ["None"], ["def", "get_xxz_metric", "(", ")", ":", "\n", "    ", "article", "=", "\"/backup3/jcxu/data/xxz-latent/test.article\"", "\n", "pred_file", "=", "\"/backup3/jcxu/data/xxz-latent/1.test.out\"", "\n", "\n", "with", "open", "(", "pred_file", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "l", "=", "int", "(", "len", "(", "lines", ")", "/", "2", ")", "\n", "\n", "", "with", "open", "(", "article", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "article", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "for", "i", "in", "range", "(", "l", ")", ":", "\n", "        ", "dist", "=", "lines", "[", "2", "*", "i", "+", "1", "]", "\n", "probs", "=", "[", "]", "\n", "dists", "=", "dist", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", ".", "split", "(", "\"|\"", ")", "\n", "for", "tuple", "in", "dists", ":", "\n", "            ", "tuple_list", "=", "tuple", ".", "strip", "(", ")", "\n", "tuple_list", "=", "tuple_list", ".", "split", "(", "\" \"", ")", "\n", "tuple_list", "=", "[", "float", "(", "x", ")", "for", "x", "in", "tuple_list", "]", "\n", "probs", ".", "append", "(", "1", "-", "tuple_list", "[", "2", "]", ")", "\n", "", "art", "=", "article", "[", "i", "]", "\n", "art_sents", "=", "art", ".", "split", "(", "\"<S_SEP>\"", ")", "\n", "\n", "bag", "=", "[", "]", "\n", "idxs", "=", "list", "(", "np", ".", "argsort", "(", "probs", ")", ")", "\n", "for", "location_in_artile", ",", "rank", "in", "enumerate", "(", "idxs", ")", ":", "\n", "            ", "if", "rank", "<=", "2", ":", "\n", "                ", "bag", ".", "append", "(", "[", "art_sents", "[", "location_in_artile", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.get_lead_3.get_qyz": [[177, 197], ["neusum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation", "os.path.join", "os.path.join", "open", "fd.read().splitlines", "open", "fd.read().splitlines", "x.replace", "x.split", "fd.read", "fd.read"], "function", ["None"], ["", "", "", "", "def", "get_qyz", "(", ")", ":", "\n", "    ", "path", "=", "\"/scratch/cluster/jcxu/data/cnndm_compar/qyz-output\"", "\n", "data", "=", "\"cnn\"", "\n", "ref", "=", "\"qyz_{}_sum.txt\"", "\n", "pred", "=", "\"qyz_{}.txt\"", "\n", "rouge_metrics", "=", "RougeStrEvaluation", "(", "name", "=", "'neusum'", ")", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "pred_path", ")", "\n", "\n", "def", "read_prediction", "(", "pred_path", ")", ":", "\n", "        ", "with", "open", "(", "pred_path", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "lines", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", "for", "x", "in", "lines", "]", "\n", "return", "lines", "\n", "\n", "##SENT##", "\n", "", "def", "read_sum", "(", "sum_path", ")", ":", "\n", "        ", "with", "open", "(", "sum_path", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "lines", "=", "[", "x", ".", "replace", "(", "\"##SENT##\"", ",", "\" \"", ")", "for", "x", "in", "lines", "]", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.clear_dir": [[40, 44], ["os.path.isdir", "os.path.isdir", "os.mkdir", "os.mkdir", "shutil.rmtree"], "function", ["None"], ["def", "clear_dir", "(", "_path", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "_path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "_path", ")", "\n", "", "os", ".", "mkdir", "(", "_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.hashhex": [[56, 61], ["hashlib.sha1", "hashlib.sha1.update", "hashlib.sha1.hexdigest", "s.encode"], "function", ["None"], ["def", "hashhex", "(", "s", ")", ":", "\n", "    ", "\"\"\"Returns a heximal formated SHA1 hash of the input string.\"\"\"", "\n", "h", "=", "hashlib", ".", "sha1", "(", ")", "\n", "h", ".", "update", "(", "s", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "return", "h", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes": [[63, 70], ["multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join"], "function", ["None"], ["", "def", "get_url_hashes", "(", "url_list", ")", ":", "\n", "    ", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "out", "=", "pool", ".", "map", "(", "hashhex", ",", "url_list", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "return", "out", "\n", "# return [hashhex(url) for url in url_list]", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.fix_missing_period": [[73, 81], ["line.rstrip.rstrip"], "function", ["None"], ["", "def", "fix_missing_period", "(", "line", ")", ":", "\n", "    ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "\"\"\"Adds a period to a line that is missing a period\"\"\"", "\n", "if", "\"@highlight\"", "in", "line", ":", "return", "line", "\n", "if", "line", "==", "\"\"", ":", "return", "line", "\n", "if", "line", "[", "-", "1", "]", "in", "END_TOKENS", ":", "return", "line", "\n", "# print line[-1]", "\n", "return", "line", "+", "\" .\"", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.read_text_file": [[83, 89], ["open", "lines.append", "line.strip"], "function", ["None"], ["", "def", "read_text_file", "(", "text_file", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "open", "(", "text_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_art_abs": [[91, 119], ["extract_data_from_raw.read_text_file", "enumerate", "extract_data_from_raw.fix_missing_period", "line.startswith", "highlights.append", "article_lines.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.read_text_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.fix_missing_period"], ["", "def", "get_art_abs", "(", "story_file", ")", ":", "\n", "    ", "lines", "=", "read_text_file", "(", "story_file", ")", "\n", "\n", "# Put periods on the ends of lines that are missing them (this is a problem in the dataset because many image captions don't end in periods; consequently they end up in the body of the article as run-on sentences)", "\n", "lines", "=", "[", "fix_missing_period", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "\n", "# Separate out article and abstract sentences", "\n", "article_lines", "=", "[", "]", "\n", "highlights", "=", "[", "]", "\n", "next_is_highlight", "=", "False", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "line", "==", "\"\"", ":", "\n", "            ", "continue", "# empty line", "\n", "", "elif", "line", ".", "startswith", "(", "\"@highlight\"", ")", ":", "\n", "            ", "next_is_highlight", "=", "True", "\n", "", "elif", "next_is_highlight", ":", "\n", "            ", "highlights", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "article_lines", ".", "append", "(", "line", ")", "\n", "\n", "# Make article into a single string", "\n", "", "", "article_lines", "=", "article_lines", "[", ":", "30", "]", "\n", "article", "=", "'\\n'", ".", "join", "(", "article_lines", ")", "\n", "\n", "# Make abstract into a signle string, putting <s> and </s> tags around the sentences", "\n", "abstract", "=", "'\\n'", ".", "join", "(", "[", "sent", "for", "sent", "in", "highlights", "]", ")", "\n", "\n", "return", "article", ",", "abstract", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.seperate_file": [[127, 137], ["extract_data_from_raw.get_art_abs", "name.split", "os.path.join", "os.path.join", "print", "open", "fd.write", "open", "fd.write", "len", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_art_abs"], ["", "def", "seperate_file", "(", "dir_to_read", ",", "name", ",", "to_write_dir", ")", ":", "\n", "    ", "name_token", "=", "name", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "article", ",", "abstract", "=", "get_art_abs", "(", "os", ".", "path", ".", "join", "(", "dir_to_read", ",", "name", ")", ")", "\n", "if", "len", "(", "article", ")", "<", "30", "or", "len", "(", "abstract", ")", "<", "10", ":", "\n", "        ", "print", "(", "'Discard: {}'", ".", "format", "(", "name", ")", ")", "\n", "return", "None", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "to_write_dir", ",", "name_token", "+", "'.doc'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "article", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "to_write_dir", ",", "name_token", "+", "'.abs'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "abstract", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.stage1": [[139, 149], ["os.listdir", "os.listdir", "len", "print", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "print", "zip"], "function", ["None"], ["", "", "def", "stage1", "(", "source_path", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "source_path", ")", "\n", "l", "=", "len", "(", "files", ")", "\n", "print", "(", "'Start seperating files!'", ")", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pool", ".", "starmap", "(", "seperate_file", ",", "zip", "(", "[", "source_path", "]", "*", "l", ",", "files", ",", "[", "path_data_bf", "]", "*", "l", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "print", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.run_snlp": [[150, 160], ["print", "cmd.split", "subprocess.call", "os.path.join", "os.path.join", "str"], "function", ["None"], ["", "def", "run_snlp", "(", "i", ")", ":", "\n", "    ", "cmd", "=", "(", "\n", "\"java -mx4g -cp /home/cc/stanford-corenlp-full-2018-02-27/* edu.stanford.nlp.pipeline.StanfordCoreNLP \"", "\n", "\"-annotators tokenize,ssplit,pos,lemma,ner,parse \"", "\n", "\" -filelist {} -outputFormat json \"", "\n", "\"-outputDirectory {}\"", ".", "format", "(", "\n", "os", ".", "path", ".", "join", "(", "path_root", ",", "data_name", "+", "str", "(", "i", ")", "+", "flist", ")", ",", "path_data_af", ")", ")", "\n", "print", "(", "cmd", ")", "\n", "command", "=", "cmd", ".", "split", "(", "' '", ")", "\n", "subprocess", ".", "call", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.stanford_pre": [[162, 181], ["os.listdir", "os.listdir", "int", "range", "multiprocessing.Pool", "multiprocessing.Pool.map", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.join", "os.path.join", "multiprocessing.cpu_count", "len", "range", "open", "fd.write", "os.path.join", "os.path.join", "str"], "function", ["None"], ["", "def", "stanford_pre", "(", "path_bf", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "path_bf", ")", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "path_bf", ",", "f", ")", "for", "f", "in", "files", "]", "\n", "\n", "num_flist", "=", "int", "(", "multiprocessing", ".", "cpu_count", "(", ")", ")", "\n", "slice", "=", "len", "(", "files", ")", "//", "num_flist", "\n", "for", "i", "in", "range", "(", "num_flist", ")", ":", "\n", "        ", "if", "i", "==", "num_flist", "-", "1", ":", "\n", "            ", "tmp", "=", "files", "[", "i", "*", "slice", ":", "]", "\n", "", "else", ":", "\n", "            ", "tmp", "=", "files", "[", "i", "*", "slice", ":", "(", "i", "+", "1", ")", "*", "slice", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path_root", ",", "data_name", "+", "str", "(", "i", ")", "+", "flist", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "'\\n'", ".", "join", "(", "tmp", ")", ")", "\n", "\n", "# cnt = multiprocessing.cpu_count()", "\n", "", "", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "num_flist", ")", "\n", "pool", ".", "map", "(", "run_snlp", ",", "range", "(", "num_flist", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw._mv_from_to": [[206, 212], ["os.path.isfile", "os.path.isfile", "os.path.join", "os.path.join", "shutil.move", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.move"], ["def", "_mv_from_to", "(", "src_path", ",", "fname", ",", "tgt_path", ")", "->", "None", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "fname", ")", ")", ":", "\n", "        ", "shutil", ".", "move", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "fname", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "fname", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"warning: missing file {}\"", ".", "format", "(", "fname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.move": [[214, 244], ["os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "len", "len", "multiprocessing.cpu_count", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "fd.read().splitlines", "extract_data_from_raw.get_url_hashes", "print", "zip", "zip", "fd.read", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes"], ["", "", "def", "move", "(", "src_path", ":", "str", "\n", ",", "tgt_path", ",", "\n", "suffix", ":", "str", ",", "\n", "split_name", ":", "str", ",", "\n", "url", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "split_name", ")", ")", "# gen data-cnn/xml/train/", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "split_name", ",", "'doc'", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "split_name", ",", "'abs'", ")", ")", "\n", "\n", "with", "open", "(", "url", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "print", "(", "\"len of urls {}\"", ".", "format", "(", "len", "(", "url_names", ")", ")", ")", "\n", "", "f_abs", "=", "[", "u", "+", "'.abs.'", "+", "suffix", "for", "u", "in", "url_names", "]", "\n", "f_doc", "=", "[", "u", "+", "'.doc.'", "+", "suffix", "for", "u", "in", "url_names", "]", "\n", "\n", "l", "=", "len", "(", "f_abs", ")", "\n", "_l", "=", "len", "(", "f_doc", ")", "\n", "assert", "l", "==", "_l", "\n", "\n", "cnt", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pool", ".", "starmap", "(", "_mv_from_to", ",", "zip", "(", "[", "src_path", "]", "*", "l", ",", "f_abs", ",", "[", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "split_name", ",", "'abs'", ")", "]", "*", "l", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "processes", "=", "cnt", ")", "\n", "pool", ".", "starmap", "(", "_mv_from_to", ",", "zip", "(", "[", "src_path", "]", "*", "l", ",", "f_doc", ",", "[", "os", ".", "path", ".", "join", "(", "tgt_path", ",", "split_name", ",", "'doc'", ")", "]", "*", "l", ")", ")", "\n", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.extract_keyword_xxz": [[4, 6], ["None"], "function", ["None"], ["def", "extract_keyword_xxz", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.set_original_files": [[14, 38], ["open", "fd.read().splitlines", "neusum.data.extract_data_from_raw.get_url_hashes", "os.path.join", "neusum.data.extract_data_from_raw.get_art_abs", "re.findall", "set", "article.split", "fd.read", "x.lowercase"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_url_hashes", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.extract_data_from_raw.get_art_abs"], ["def", "set_original_files", "(", "full_dataname", ",", "lowercase", ":", "bool", "=", "False", ")", ":", "\n", "# work on the original files", "\n", "# For CNN DM, filter test set of CNN and DM.", "\n", "# return a dict with uid and feature words.", "\n", "    ", "test_urls", "=", "'/scratch/cluster/jcxu/cnn-dailymail/url_lists/{}_wayback_test_urls.txt'", ".", "format", "(", "full_dataname", ")", "\n", "original_file_dir", "=", "\"/scratch/cluster/jcxu/data/original-cnndm/{}/stories/\"", ".", "format", "(", "full_dataname", ")", "\n", "# article, abstract = get_art_abs(os.path.join(dir_to_read, name))", "\n", "\n", "d", "=", "{", "}", "\n", "with", "open", "(", "test_urls", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "url_names", "=", "get_url_hashes", "(", "lines", ")", "\n", "\n", "", "for", "url", "in", "url_names", ":", "\n", "        ", "story_file", "=", "os", ".", "path", ".", "join", "(", "original_file_dir", ",", "url", "+", "'.story'", ")", "\n", "article", ",", "abstract", "=", "get_art_abs", "(", "story_file", ")", "\n", "feat", "=", "article", ".", "split", "(", "\" \"", ")", "[", ":", "50", "]", "\n", "feat_sent", "=", "\" \"", ".", "join", "(", "feat", ")", "\n", "out", "=", "re", ".", "findall", "(", "r\"[\\w']+\"", ",", "feat_sent", ")", "\n", "if", "lowercase", ":", "\n", "            ", "feat", "=", "[", "x", ".", "lowercase", "(", ")", "for", "x", "in", "out", "]", "\n", "", "feat", "=", "set", "(", "feat", ")", "\n", "d", "[", "'{}-{}'", ".", "format", "(", "full_dataname", ",", "url", ")", "]", "=", "feat", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.match_qyz": [[39, 69], ["len", "enumerate", "print", "print", "print", "print", "open", "fd.read().splitlines", "l.replace.split", "meta_sents.append", "l.replace.replace", "set", "match_dict.items", "range", "range", "l.replace.split", "set.union", "fd.read", "len", "len"], "function", ["None"], ["", "def", "match_qyz", "(", "match_dict", ")", ":", "\n", "    ", "split_tok", "=", "\"##SENT##\"", "\n", "path", "=", "\"/backup3/jcxu/data/xxz-latent/test.article\"", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "line_num", "=", "len", "(", "lines", ")", "\n", "output_list", "=", "[", "\"\"", "for", "_", "in", "range", "(", "line_num", ")", "]", "\n", "\n", "feat_lines", "=", "[", "[", "]", "for", "_", "in", "range", "(", "line_num", ")", "]", "\n", "meta_sents", "=", "[", "]", "\n", "for", "idx", ",", "l", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "sents", "=", "l", ".", "split", "(", "split_tok", ")", "\n", "meta_sents", ".", "append", "(", "sents", ")", "\n", "l", "=", "l", ".", "replace", "(", "split_tok", ",", "\"\"", ")", "\n", "toks", "=", "l", ".", "split", "(", "\" \"", ")", "[", ":", "52", "]", "\n", "toks", "=", "set", "(", "[", "x", "for", "x", "in", "toks", "if", "x", "!=", "\"\"", "]", ")", "\n", "\n", "for", "key", ",", "val", "in", "match_dict", ".", "items", "(", ")", ":", "\n", "            ", "joint", "=", "toks", ".", "union", "(", "val", ")", "\n", "rat", "=", "len", "(", "joint", ")", "/", "len", "(", "toks", ")", "\n", "if", "rat", ">", "0.85", ":", "\n", "# print(\"Match. \")", "\n", "                ", "output_list", "[", "idx", "]", "=", "key", "\n", "del", "match_dict", "[", "key", "]", "\n", "break", "\n", "", "", "", "print", "(", "\"remain\"", ")", "\n", "print", "(", "match_dict", ")", "\n", "print", "(", "\"match\"", ")", "\n", "print", "(", "output_list", ")", "\n", "return", "output_list", ",", "meta_sents", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.match_see": [[70, 72], ["None"], "function", ["None"], ["", "def", "match_see", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.match_xxz": [[74, 103], ["len", "enumerate", "print", "print", "print", "print", "open", "fd.read().splitlines", "l.replace.split", "meta_sents.append", "l.replace.replace", "set", "match_dict.items", "range", "range", "l.replace.split", "set.union", "fd.read", "len", "len"], "function", ["None"], ["", "def", "match_xxz", "(", "match_dict", ")", ":", "\n", "    ", "path", "=", "\"/backup3/jcxu/data/xxz-latent/test.article\"", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "line_num", "=", "len", "(", "lines", ")", "\n", "output_list", "=", "[", "\"\"", "for", "_", "in", "range", "(", "line_num", ")", "]", "\n", "\n", "feat_lines", "=", "[", "[", "]", "for", "_", "in", "range", "(", "line_num", ")", "]", "\n", "meta_sents", "=", "[", "]", "\n", "for", "idx", ",", "l", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "sents", "=", "l", ".", "split", "(", "\"<S_SEP>\"", ")", "\n", "meta_sents", ".", "append", "(", "sents", ")", "\n", "l", "=", "l", ".", "replace", "(", "\"<S_SEP>\"", ",", "\"\"", ")", "\n", "toks", "=", "l", ".", "split", "(", "\" \"", ")", "[", ":", "52", "]", "\n", "toks", "=", "set", "(", "[", "x", "for", "x", "in", "toks", "if", "x", "!=", "\"\"", "]", ")", "\n", "\n", "for", "key", ",", "val", "in", "match_dict", ".", "items", "(", ")", ":", "\n", "            ", "joint", "=", "toks", ".", "union", "(", "val", ")", "\n", "rat", "=", "len", "(", "joint", ")", "/", "len", "(", "toks", ")", "\n", "if", "rat", ">", "0.85", ":", "\n", "# print(\"Match. \")", "\n", "                ", "output_list", "[", "idx", "]", "=", "key", "\n", "del", "match_dict", "[", "key", "]", "\n", "break", "\n", "", "", "", "print", "(", "\"remain\"", ")", "\n", "print", "(", "match_dict", ")", "\n", "print", "(", "\"match\"", ")", "\n", "print", "(", "output_list", ")", "\n", "return", "output_list", ",", "meta_sents", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.read_xxz_prediction": [[108, 139], ["int", "range", "open", "fd.read().splitlines", "right.split", "meta_results.append", "len", "content.split", "x.strip", "dec.split", "float", "preds.append", "len", "list", "meta_results.append", "numpy.argmax", "list.append", "fd.read", "range", "len"], "function", ["None"], ["def", "read_xxz_prediction", "(", ")", ":", "\n", "    ", "path", "=", "\"/backup3/jcxu/data/xxz-latent/1.test.out\"", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "l", "=", "int", "(", "len", "(", "lines", ")", "/", "2", ")", "\n", "meta_results", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "l", ")", ":", "\n", "        ", "preds", "=", "[", "]", "\n", "content", "=", "lines", "[", "idx", "*", "2", "+", "1", "]", "\n", "right", "=", "content", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", "\n", "decisions", "=", "right", ".", "split", "(", "\"|\"", ")", "\n", "decisions", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "decisions", "]", "\n", "for", "dec", "in", "decisions", ":", "\n", "            ", "_", ",", "_", ",", "pred", "=", "dec", ".", "split", "(", "\" \"", ")", "\n", "pred", "=", "float", "(", "pred", ")", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "\n", "", "result", "=", "[", "]", "\n", "if", "len", "(", "preds", ")", "<", "3", ":", "\n", "            ", "result", "=", "list", "(", "range", "(", "len", "(", "preds", ")", ")", ")", "\n", "meta_results", ".", "append", "(", "result", ")", "\n", "continue", "\n", "\n", "", "cnt", "=", "0", "\n", "while", "cnt", "<", "3", ":", "\n", "            ", "out", "=", "np", ".", "argmax", "(", "preds", ")", "\n", "result", ".", "append", "(", "out", ")", "\n", "preds", "[", "out", "]", "=", "-", "1", "\n", "cnt", "+=", "1", "\n", "", "meta_results", ".", "append", "(", "result", ")", "\n", "", "return", "meta_results", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.match_xxz.wt_xxz_output_to_disk": [[141, 147], ["zip", "open", "fd.write", "os.path.join"], "function", ["None"], ["", "def", "wt_xxz_output_to_disk", "(", "dir", ",", "fname_list", ",", "full_docs", ",", "decision", ")", ":", "\n", "    ", "for", "output", ",", "doc", ",", "dec", "in", "zip", "(", "fname_list", ",", "full_docs", ",", "decision", ")", ":", "\n", "        ", "sent_picked", "=", "[", "doc", "[", "idx", "]", "for", "idx", "in", "dec", "]", "\n", "wt_content", "=", "\"\\n\"", ".", "join", "(", "sent_picked", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "output", "+", "'.txt'", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "wt_content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.TreeNode.__init__": [[11, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tag", ":", "str", ",", "text", ",", "children", ":", "List", ",", "depth", ":", "int", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "tag", "=", "tag", "\n", "self", ".", "children", "=", "children", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "start_idx", "=", "-", "1", "\n", "self", ".", "end_idx", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.TreeNode.__repr__": [[19, 21], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Text: {}\\tTag:{}\\tDepth:{}\"", ".", "format", "(", "\" \"", ".", "join", "(", "self", ".", "text", ")", ",", "self", ".", "tag", ",", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_pp": [[60, 76], ["len", "set", "range"], "function", ["None"], ["def", "det_pp", "(", "node", ":", "TreeNode", ",", "parent", ":", "TreeNode", ")", ":", "\n", "    ", "if", "node", ".", "tag", "==", "'PP'", "and", "len", "(", "node", ".", "text", ")", ">", "1", ":", "\n", "        ", "first_child", "=", "node", ".", "children", "[", "0", "]", "\n", "if", "parent", "is", "not", "None", "and", "(", "\"to\"", "in", "first_child", ".", "text", ")", "and", "(", "parent", ".", "tag", "in", "[", "\"VP\"", ",", "\"ADJP\"", ",", "\"ADVP\"", "]", ")", ":", "\n", "# if (\"to\" in first_child.text) and (parent.tag in [\"VP\", \"ADJP\", \"ADVP\", \"PP\"]):       # conservative", "\n", "            ", "return", "[", "]", "\n", "", "if", "parent", "is", "not", "None", "and", "(", "\"as\"", "in", "first_child", ".", "text", ")", "and", "(", "parent", ".", "tag", "in", "[", "\"VP\"", ",", "\"ADVP\"", "]", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "parent", "is", "not", "None", "and", "(", "\"of\"", "in", "first_child", ".", "text", ")", "and", "(", "parent", ".", "tag", "in", "[", "\"ADJP\"", ",", "\"ADVP\"", "]", ")", ":", "\n", "# if (\"of\" in first_child.text) and (parent.tag in [\"NP\", \"ADJP\", \"ADVP\"]):", "\n", "            ", "return", "[", "]", "\n", "", "if", "parent", "is", "not", "None", "and", "parent", ".", "tag", "==", "'VP'", "and", "parent", ".", "children", "[", "0", "]", ".", "text", "in", "[", "\"is\"", ",", "\"was\"", ",", "\"are\"", ",", "\"were\"", ",", "\"be\"", "]", ":", "\n", "            ", "return", "[", "]", "\n", "", "return", "[", "{", "\"node\"", ":", "node", ".", "tag", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "node", ".", "start_idx", ",", "node", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "node", ".", "text", "}", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_sbar": [[78, 101], ["len", "set", "range", "set", "set", "range", "range"], "function", ["None"], ["", "def", "det_sbar", "(", "node", ":", "TreeNode", ",", "root_len", ",", "parent", ":", "TreeNode", "=", "None", ")", ":", "\n", "# \"SBAR\": \"between split tokens or first child=IN or WH* \",", "\n", "# \"SBAR-sel\": \"(SBAR (IN) (S ))  keep the S here\",", "\n", "    ", "bag", "=", "[", "]", "\n", "if", "node", ".", "tag", "==", "'SBAR'", "and", "node", ".", "children", ":", "\n", "        ", "if", "parent", "is", "not", "None", "and", "(", "parent", ".", "children", "[", "0", "]", ".", "tag", "!=", "'VBG'", ")", ":", "\n", "            ", "bag", "+=", "[", "{", "\"node\"", ":", "node", ".", "tag", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "node", ".", "start_idx", ",", "node", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "node", ".", "text", ")", "}", "]", "\n", "# if parent is not None and (parent.tag == \"VP\"):", "\n", "#     return []", "\n", "", "first_child", "=", "node", ".", "children", "[", "0", "]", "\n", "first_child_tag", "=", "first_child", ".", "tag", "\n", "# if first_child_tag.startswith(\"W\") or first_child_tag == 'IN':", "\n", "#     bag += [{\"node\": node.tag, \"selected_idx\": set(range(node.start_idx, node.end_idx)),", "\n", "#              \"text\": \" \".join(node.text)}]", "\n", "if", "first_child_tag", "==", "'IN'", "and", "len", "(", "node", ".", "children", ")", ">", "1", ":", "\n", "            ", "sec_child_tag", "=", "node", ".", "children", "[", "1", "]", ".", "tag", "\n", "if", "sec_child_tag", "==", "\"S\"", ":", "\n", "                ", "bag", "+=", "[", "{", "\"node\"", ":", "\"_S_\"", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "root_len", ")", ")", "-", "set", "(", "\n", "range", "(", "node", ".", "children", "[", "1", "]", ".", "start_idx", ",", "node", ".", "children", "[", "1", "]", ".", "end_idx", ")", ")", ",", "\n", "\"kep_text\"", ":", "\" \"", ".", "join", "(", "node", ".", "children", "[", "1", "]", ".", "text", ")", "}", "]", "\n", "", "", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_JJ": [[103, 112], ["enumerate", "set", "range"], "function", ["None"], ["", "def", "det_JJ", "(", "node", ":", "TreeNode", ")", ":", "\n", "    ", "bag", "=", "[", "]", "\n", "if", "node", ".", "tag", "==", "'NP'", ":", "\n", "        ", "if", "node", ".", "children", ":", "\n", "            ", "for", "idx", ",", "child", "in", "enumerate", "(", "node", ".", "children", ")", ":", "\n", "                ", "if", "child", ".", "tag", "==", "\"JJ\"", "or", "child", ".", "tag", "==", "\"ADJP\"", ":", "\n", "                    ", "bag", "+=", "[", "{", "\"node\"", ":", "child", ".", "tag", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "child", ".", "start_idx", ",", "child", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "child", ".", "text", ")", ",", "\"par_text\"", ":", "\" \"", ".", "join", "(", "node", ".", "text", ")", "}", "]", "\n", "", "", "", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_vp_vbg_vbn": [[114, 137], ["set", "set", "set", "range", "range", "range"], "function", ["None"], ["", "def", "det_vp_vbg_vbn", "(", "tree", ":", "TreeNode", ",", "parent", ":", "TreeNode", ",", "grand_parent", ":", "TreeNode", "=", "None", ")", ":", "\n", "    ", "if", "tree", ".", "tag", "==", "'VP'", ":", "\n", "        ", "if", "tree", ".", "children", "[", "0", "]", ".", "tag", "==", "'VBG'", ":", "\n", "            ", "if", "parent", "and", "parent", ".", "tag", "==", "'NP'", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "'VBG'", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "parent", ".", "text", ")", "\n", "}", "]", "\n", "", "if", "parent", "and", "parent", ".", "tag", "==", "'S'", "and", "grand_parent", "and", "grand_parent", ".", "tag", "!=", "\"PP\"", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "'VBG'", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "parent", ".", "text", ")", "\n", "}", "]", "\n", "", "", "if", "tree", ".", "children", "[", "0", "]", ".", "tag", "==", "'VBN'", ":", "\n", "            ", "if", "parent", "and", "parent", ".", "tag", "==", "'NP'", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "'VBN'", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "parent", ".", "text", ")", "\n", "}", "]", "\n", "", "", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_advp": [[139, 146], ["set", "range"], "function", ["None"], ["", "def", "det_advp", "(", "tree", ":", "TreeNode", ",", "parent", ":", "TreeNode", ")", ":", "\n", "    ", "if", "tree", ".", "tag", "==", "'ADVP'", ":", "\n", "        ", "return", "[", "{", "\"node\"", ":", "'ADVP'", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "\n", "}", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_np_np": [[148, 190], ["any", "enumerate", "range", "child_seq.append", "len", "child_seq.append", "child_seq.append", "x.isupper", "set", "range", "set().union", "set", "set", "range", "range"], "function", ["None"], ["", "def", "det_np_np", "(", "tree", ":", "TreeNode", ")", ":", "\n", "    ", "bag", "=", "[", "]", "\n", "if", "not", "tree", ".", "children", ":", "\n", "        ", "return", "[", "]", "\n", "", "flag", "=", "any", "(", "[", "x", ".", "tag", "in", "SPLIT", "for", "x", "in", "tree", ".", "children", "]", ")", "\n", "if", "not", "flag", ":", "\n", "        ", "return", "[", "]", "\n", "", "child_seq", "=", "[", "]", "\n", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "        ", "if", "child", ".", "tag", "in", "SPLIT", ":", "\n", "            ", "child_seq", ".", "append", "(", "\"|\"", ")", "\n", "", "elif", "child", ".", "tag", "==", "'NP'", ":", "\n", "            ", "child_seq", ".", "append", "(", "\"NP\"", ")", "\n", "", "else", ":", "\n", "            ", "child_seq", ".", "append", "(", "\"*\"", ")", "\n", "", "", "for", "idx", "in", "range", "(", "len", "(", "tree", ".", "children", ")", "-", "3", ")", ":", "\n", "        ", "if", "child_seq", "[", "idx", "]", "==", "'NP'", "and", "child_seq", "[", "idx", "+", "2", "]", "==", "'NP'", "and", "child_seq", "[", "idx", "+", "1", "]", "==", "\"|\"", "and", "child_seq", "[", "\n", "idx", "+", "3", "]", "==", "\"|\"", ":", "\n", "            ", "bag", "+=", "[", "{", "\"node\"", ":", "\"NP_np\"", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "children", "[", "idx", "+", "1", "]", ".", "start_idx", ",", "tree", ".", "children", "[", "idx", "+", "3", "]", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "\n", "tree", ".", "children", "[", "idx", "+", "1", "]", ".", "text", "+", "tree", ".", "children", "[", "idx", "+", "2", "]", ".", "text", "+", "tree", ".", "children", "[", "idx", "+", "3", "]", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "\n", "}", "\n", "]", "\n", "\n", "_txt", "=", "tree", ".", "children", "[", "idx", "+", "2", "]", ".", "text", "\n", "for", "x", "in", "_txt", ":", "\n", "                ", "if", "x", ".", "isupper", "(", ")", ":", "\n", "                    ", "bag", "+=", "[", "{", "\"node\"", ":", "\"np_NP\"", ",", "\n", "\"selected_idx\"", ":", "set", "(", "\n", "range", "(", "tree", ".", "children", "[", "idx", "+", "0", "]", ".", "start_idx", ",", "tree", ".", "children", "[", "idx", "+", "1", "]", ".", "end_idx", ")", ")", ".", "union", "(", "\n", "set", "(", "range", "(", "tree", ".", "children", "[", "idx", "+", "3", "]", ".", "start_idx", ",", "tree", ".", "children", "[", "idx", "+", "3", "]", ".", "end_idx", ")", ")", ")", "\n", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "\n", "tree", ".", "children", "[", "idx", "+", "0", "]", ".", "text", "+", "tree", ".", "children", "[", "idx", "+", "1", "]", ".", "text", "+", "[", "\" ___\"", "]", "+", "tree", ".", "children", "[", "\n", "idx", "+", "3", "]", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "\n", "}", "\n", "]", "\n", "break", "\n", "", "", "", "", "return", "bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_between_split": [[192, 276], ["any", "enumerate", "enumerate", "split_child_id.append", "len", "len", "len", "len", "check_snlp_tree.det_between_split._easy_match"], "function", ["None"], ["", "def", "det_between_split", "(", "tree", ":", "TreeNode", ",", "rootlen", ":", "int", ")", ":", "\n", "# \"(, ,)\": \"Between same depth split tokens, \"", "\n", "# \"SINGLE ADVP or SBAR or PP or [(VP)(NP) or (NP)(VP) ](len<8)", "\n", "# or S(len<5)   or NP {, NP ,}\",", "\n", "\n", "    ", "def", "_easy_match", "(", "tag", ")", ":", "\n", "        ", "if", "tag", "in", "[", "\"ADVP\"", ",", "\"SBAR\"", ",", "\"PP\"", "]", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "def", "_easy_match_len_limit", "(", "_node", ":", "TreeNode", ",", "tag", "=", "\"S\"", ",", "l", "=", "5", ")", ":", "\n", "        ", "if", "tag", "==", "_node", ".", "tag", "and", "(", "len", "(", "_node", ".", "text", ")", "<=", "l", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "def", "_easy_two_step_match", "(", "_node", ":", "TreeNode", ",", "match_tag", "=", "[", "\"VP\"", "]", ",", "match_subtag", "=", "[", "'VBG'", ",", "'VBN'", "]", ")", ":", "\n", "        ", "if", "_node", ".", "tag", "in", "match_tag", ":", "\n", "            ", "if", "_node", ".", "children", ":", "\n", "                ", "if", "_node", ".", "children", "[", "0", "]", ".", "tag", "in", "match_subtag", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n", "", "def", "_mix_np_vp", "(", "_node_a", ",", "_node_b", ")", ":", "\n", "        ", "if", "(", "_node_a", ".", "tag", "==", "\"NP\"", ")", "and", "(", "_node_b", ".", "tag", "==", "\"VP\"", ")", "and", "len", "(", "_node_a", ".", "text", "+", "_node_b", ".", "text", ")", "<=", "6", ":", "\n", "            ", "return", "True", "\n", "# return [{\"node\":\"NP_VP\",", "\n", "#          \"selected_idx\":", "\n", "#          }]", "\n", "", "if", "(", "_node_b", ".", "tag", "==", "\"NP\"", ")", "and", "(", "_node_a", ".", "tag", "==", "\"VP\"", ")", "and", "len", "(", "_node_a", ".", "text", "+", "_node_b", ".", "text", ")", "<=", "6", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "bag", "=", "[", "]", "\n", "if", "not", "tree", ".", "children", ":", "\n", "        ", "return", "[", "]", "\n", "", "flag", "=", "any", "(", "[", "x", ".", "tag", "in", "SPLIT", "for", "x", "in", "tree", ".", "children", "]", ")", "\n", "if", "not", "flag", ":", "\n", "        ", "return", "[", "]", "\n", "", "split_child_id", "=", "[", "]", "\n", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "        ", "if", "child", ".", "tag", "in", "SPLIT", ":", "\n", "            ", "split_child_id", ".", "append", "(", "idx", ")", "\n", "# split_child_id = [ 3, 6] __ __ __ , __ __ .", "\n", "\n", "", "", "last", "=", "-", "1", "\n", "# single rule check: VP (VBG)  VP(VBN) ADVP SBAR PP", "\n", "for", "idx_c", ",", "c", "in", "enumerate", "(", "split_child_id", ")", ":", "\n", "        ", "if", "last", "==", "-", "1", ":", "\n", "            ", "cand_child", "=", "tree", ".", "children", "[", ":", "c", "]", "\n", "", "else", ":", "\n", "            ", "cand_child", "=", "tree", ".", "children", "[", "last", "+", "1", ":", "c", "]", "\n", "", "last", "=", "c", "\n", "\n", "if", "len", "(", "cand_child", ")", "==", "1", ":", "\n", "            ", "candi", "=", "cand_child", "[", "0", "]", "\n", "if", "_easy_match", "(", "candi", ".", "tag", ")", "or", "_easy_two_step_match", "(", "candi", ")", "or", "_easy_match_len_limit", "(", "candi", ")", ":", "\n", "                ", "right", ",", "left", "=", "False", ",", "False", "\n", "if", "idx_c", "==", "0", ":", "\n", "                    ", "right", "=", "True", "\n", "", "elif", "c", "==", "rootlen", "-", "1", ":", "\n", "                    ", "left", "=", "True", "\n", "", "else", ":", "\n", "                    ", "right", ",", "left", "=", "True", ",", "True", "\n", "\n", "", "sel_idx", "=", "set", "(", ")", "\n", "if", "left", ":", "\n", "                    ", "sel_idx", "=", "sel_idx", ".", "union", "(", "set", "(", "range", "(", "tree", ".", "children", "[", "split_child_id", "[", "idx_c", "-", "1", "]", "]", ".", "start_idx", ",", "\n", "tree", ".", "children", "[", "split_child_id", "[", "idx_c", "-", "1", "]", "]", ".", "end_idx", ")", ")", ")", "\n", "", "if", "right", ":", "\n", "                    ", "sel_idx", "=", "sel_idx", ".", "union", "(", "set", "(", "range", "(", "tree", ".", "children", "[", "split_child_id", "[", "idx_c", "]", "]", ".", "start_idx", ",", "\n", "tree", ".", "children", "[", "split_child_id", "[", "idx_c", "]", "]", ".", "end_idx", ")", ")", ")", "\n", "", "sel_idx", "=", "sel_idx", ".", "union", "(", "set", "(", "range", "(", "candi", ".", "start_idx", ",", "candi", ".", "end_idx", ")", ")", ")", "\n", "bag", "+=", "[", "{", "\"node\"", ":", "\"Split_\"", "+", "candi", ".", "tag", ",", "\n", "\"selected_idx\"", ":", "sel_idx", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "candi", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "\n", "", "", "elif", "len", "(", "cand_child", ")", "==", "3", ":", "\n", "            ", "if", "cand_child", "[", "0", "]", ".", "tag", ".", "startswith", "(", "'\\''", ")", "and", "_mix_np_vp", "(", "cand_child", "[", "1", "]", ",", "cand_child", "[", "2", "]", ")", ":", "\n", "                ", "bag", "+=", "[", "{", "\"node\"", ":", "\"NPxVP\"", ",", "\n", "\"selected_idx\"", ":", "set", "(", "range", "(", "cand_child", "[", "1", "]", ".", "start_idx", ",", "cand_child", "[", "2", "]", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "cand_child", "[", "1", "]", ".", "text", "+", "cand_child", "[", "2", "]", ".", "text", ")", ",", "\n", "\"par_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "", "", "", "return", "bag", "\n", "# [(VP)(NP) or (NP)(VP)](len < 8) or S(len < 5) or NP", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_children_tag": [[280, 295], ["enumerate"], "function", ["None"], ["", "def", "match_children_tag", "(", "tree", ":", "TreeNode", ",", "tag_name", ",", "word_name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Match the tag of children. If found, return start_idx , end_idx and child_idx\n    :param tree:\n    :param tag_name:\n    :return:\n    \"\"\"", "\n", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "        ", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "            ", "if", "child", ".", "tag", "==", "tag_name", ":", "\n", "                ", "if", "word_name", "is", "None", ":", "\n", "                    ", "return", "child", ".", "start_idx", ",", "child", ".", "end_idx", ",", "idx", "\n", "", "elif", "word_name", "in", "child", ".", "text", ":", "\n", "                    ", "return", "child", ".", "start_idx", ",", "child", ".", "end_idx", ",", "idx", "\n", "", "", "", "", "return", "-", "1", ",", "-", "1", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_list_nodes": [[297, 299], ["None"], "function", ["None"], ["", "def", "match_list_nodes", "(", "list_of_nodes", ",", "tag_name", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_ccs": [[301, 319], ["check_snlp_tree.match_children_tag", "check_snlp_tree.match_children_tag", "len", "len", "set", "set", "set", "set", "range", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_children_tag", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_children_tag"], ["", "def", "det_ccs", "(", "tree", ":", "TreeNode", ",", "root_len", ")", ":", "\n", "# { S [,] (CC but/and) } (S ..)", "\n", "    ", "sid", ",", "eid", ",", "child_idx", "=", "match_children_tag", "(", "tree", ",", "'CC'", ",", "word_name", "=", "\"and\"", ")", "\n", "if", "(", "sid", ">=", "0", "and", "eid", ">=", "0", "and", "child_idx", ">=", "0", ")", ":", "\n", "        ", "if", "len", "(", "tree", ".", "children", ")", ">", "child_idx", "+", "1", ":", "\n", "            ", "if", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "tag", "==", "\"S\"", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "\"CCS\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "root_len", ")", ")", "-", "set", "(", "range", "(", "\n", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "start_idx", ",", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "end_idx", ")", ")", ",", "\n", "\"kep_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "text", ")", "}", "]", "\n", "\n", "", "", "", "sid", ",", "eid", ",", "child_idx", "=", "match_children_tag", "(", "tree", ",", "'CC'", ",", "word_name", "=", "\"but\"", ")", "\n", "if", "(", "sid", ">=", "0", "and", "eid", ">=", "0", "and", "child_idx", ">=", "0", ")", ":", "\n", "        ", "if", "len", "(", "tree", ".", "children", ")", ">", "child_idx", "+", "1", ":", "\n", "            ", "if", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "tag", "==", "\"S\"", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "\"CCS\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "root_len", ")", ")", "-", "set", "(", "range", "(", "\n", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "start_idx", ",", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "end_idx", ")", ")", ",", "\n", "\"kep_text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "children", "[", "child_idx", "+", "1", "]", ".", "text", ")", "}", "]", "\n", "", "", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_rb": [[321, 326], ["set", "range"], "function", ["None"], ["", "def", "det_rb", "(", "tree", ":", "TreeNode", ")", ":", "\n", "    ", "if", "tree", ".", "tag", "==", "'RB'", "and", "tree", ".", "text", "[", "0", "]", "in", "[", "'very'", ",", "'quite'", ",", "\"much\"", ",", "\"also\"", ",", "\"still\"", ",", "\"just\"", "]", ":", "\n", "        ", "return", "[", "{", "\"node\"", ":", "\"PRN\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_PRN": [[328, 333], ["set", "range"], "function", ["None"], ["", "def", "det_PRN", "(", "tree", ":", "TreeNode", ")", ":", "\n", "    ", "if", "tree", ".", "tag", "==", "'PRN'", ":", "\n", "        ", "return", "[", "{", "\"node\"", ":", "\"PRN\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "tree", ".", "start_idx", ",", "tree", ".", "end_idx", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_RB": [[335, 350], ["check_snlp_tree.match_children_tag", "check_snlp_tree.match_children_tag", "set", "set", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_children_tag", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.match_children_tag"], ["", "def", "det_RB", "(", "tree", ":", "TreeNode", ",", "parent", ":", "TreeNode", ")", ":", "\n", "    ", "ls", ",", "le", ",", "lid", "=", "match_children_tag", "(", "tree", ",", "'-LRB-'", ")", "\n", "if", "ls", ">=", "0", "and", "le", ">=", "0", ":", "\n", "        ", "rs", ",", "re", ",", "rid", "=", "match_children_tag", "(", "tree", ",", "'-RRB-'", ")", "\n", "if", "rs", ">=", "0", "and", "re", ">=", "0", ":", "\n", "\n", "            ", "if", "ls", "<=", "5", "and", "'CNN'", "in", "tree", ".", "text", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "\"RB\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "0", ",", "re", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "{", "\"node\"", ":", "\"RB\"", ",", "\"selected_idx\"", ":", "set", "(", "range", "(", "ls", ",", "re", ")", ")", ",", "\n", "\"text\"", ":", "\" \"", ".", "join", "(", "tree", ".", "text", ")", "}", "]", "\n", "", "", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_SS": [[352, 362], ["len", "print"], "function", ["None"], ["", "def", "det_SS", "(", "tree", ":", "TreeNode", ")", ":", "\n", "    ", "if", "tree", ".", "children", ":", "\n", "        ", "total_child_num", "=", "len", "(", "tree", ".", "children", ")", "\n", "first_child", "=", "tree", ".", "children", "[", "0", "]", "\n", "if", "total_child_num", ">=", "3", "and", "first_child", ".", "tag", "==", "\"S\"", ":", "\n", "            ", "sec_child", "=", "tree", ".", "children", "[", "1", "]", "\n", "if", "sec_child", ".", "tag", "in", "SPLIT", ":", "\n", "                ", "print", "(", "\" \"", ".", "join", "(", "tree", ".", "text", ")", ")", "\n", "\n", "", "", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated": [[364, 390], ["check_snlp_tree.det_JJ", "check_snlp_tree.det_PRN", "check_snlp_tree.det_ccs", "check_snlp_tree.det_pp", "check_snlp_tree.det_sbar", "check_snlp_tree.det_vp_vbg_vbn", "check_snlp_tree.det_np_np", "check_snlp_tree.det_RB", "check_snlp_tree.det_between_split", "check_snlp_tree.det_advp", "check_snlp_tree.det_rb", "enumerate", "check_snlp_tree.find_deletable_span_rule_based_updated"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_JJ", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_PRN", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_ccs", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_pp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_sbar", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_vp_vbg_vbn", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_np_np", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_RB", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_between_split", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_advp", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.det_rb", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated"], ["", "def", "find_deletable_span_rule_based_updated", "(", "tree", ":", "TreeNode", ",", "\n", "root_len", ":", "int", ",", "\n", "parent", "=", "None", ",", "\n", "grand_parent", "=", "None", ")", ":", "\n", "    ", "next_parent", "=", "tree", "\n", "next_grandparent", "=", "parent", "\n", "\n", "deletable_bag", "=", "[", "]", "\n", "deletable_bag", "+=", "det_JJ", "(", "tree", ")", "\n", "deletable_bag", "+=", "det_PRN", "(", "tree", ")", "\n", "deletable_bag", "+=", "det_ccs", "(", "tree", ",", "root_len", ")", "\n", "deletable_bag", "+=", "det_pp", "(", "node", "=", "tree", ",", "parent", "=", "parent", ")", "\n", "deletable_bag", "+=", "det_sbar", "(", "node", "=", "tree", ",", "root_len", "=", "root_len", ",", "parent", "=", "parent", ")", "\n", "deletable_bag", "+=", "det_vp_vbg_vbn", "(", "tree", "=", "tree", ",", "parent", "=", "parent", ",", "grand_parent", "=", "grand_parent", ")", "\n", "deletable_bag", "+=", "det_np_np", "(", "tree", ")", "\n", "deletable_bag", "+=", "det_RB", "(", "tree", ",", "parent", ")", "\n", "deletable_bag", "+=", "det_between_split", "(", "tree", ",", "root_len", ")", "\n", "deletable_bag", "+=", "det_advp", "(", "tree", ",", "parent", ")", "\n", "deletable_bag", "+=", "det_rb", "(", "tree", ")", "\n", "# if len(deletable_bag) > 0:", "\n", "#     print(deletable_bag)", "\n", "if", "tree", ".", "children", "is", "not", "None", ":", "\n", "        ", "for", "idx", ",", "child", "in", "enumerate", "(", "tree", ".", "children", ")", ":", "\n", "            ", "deletable_bag", "+=", "find_deletable_span_rule_based_updated", "(", "child", ",", "root_len", ",", "parent", "=", "next_parent", ",", "\n", "grand_parent", "=", "next_grandparent", ")", "\n", "", "", "return", "deletable_bag", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.read_one_file": [[392, 409], ["json.loads", "neusum.orac.util.extract_parse", "open", "fd.read", "neusum.orac.util.read_single_parse_tree", "print", "len", "check_snlp_tree.find_deletable_span_rule_based_updated", "print", "print", "print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_parse", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.read_single_parse_tree", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.find_deletable_span_rule_based_updated"], ["", "def", "read_one_file", "(", "dir", ",", "fp", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "fp", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", "\n", "", "line_dict", "=", "json", ".", "loads", "(", "lines", ")", "\n", "doc_parse", "=", "extract_parse", "(", "line_dict", ")", "\n", "for", "sent_parse", "in", "doc_parse", ":", "\n", "# sent_parse = \"(S (, ,) ('' '') (NP (NNP Armstrong))    (VP (VBD said))    (. .))\"", "\n", "        ", "sent_tree", "=", "read_single_parse_tree", "(", "sent_parse", ")", "\n", "print", "(", "sent_parse", ")", "\n", "tree_len", "=", "len", "(", "sent_tree", ".", "text", ")", "\n", "# print(sent_tree)", "\n", "# continue", "\n", "del_bag", "=", "find_deletable_span_rule_based_updated", "(", "sent_tree", ",", "root_len", "=", "tree_len", ",", "parent", "=", "None", ",", "grand_parent", "=", "None", ")", "\n", "# exit()", "\n", "print", "(", "\" \"", ".", "join", "(", "sent_tree", ".", "text", ")", ")", "\n", "print", "(", "del_bag", ")", "\n", "print", "(", "'-'", "*", "50", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.check_snlp_tree.remove_redundant_del": [[414, 425], ["new_list.append"], "function", ["None"], ["def", "remove_redundant_del", "(", "del_spans", ")", ":", "\n", "    ", "d", "=", "{", "}", "\n", "new_list", "=", "[", "]", "\n", "for", "del_sp", "in", "del_spans", ":", "\n", "        ", "txt", "=", "del_sp", "[", "'text'", "]", "\n", "if", "txt", "in", "d", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "new_list", ".", "append", "(", "del_sp", ")", "\n", "d", "[", "txt", "]", "=", "True", "\n", "", "", "return", "new_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.try_rules._get_2gram_sets": [[6, 15], ["list", "len", "set", "set", "filter", "map", "map", "list.split", "range", "range", "str", "str", "str"], "function", ["None"], ["def", "_get_2gram_sets", "(", "highlights", ")", ":", "\n", "    ", "\"\"\"The input highlights should be a sequence of texts.\"\"\"", "\n", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "\n", "fullen", "=", "len", "(", "highlights", ")", "\n", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "fullen", ")", ")", ")", "\n", "set_2gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", ",", "range", "(", "fullen", "-", "1", ")", ")", ")", "\n", "return", "set_1gram", ",", "set_2gram", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.try_rules.get_rouge_est_str_2gram": [[17, 43], ["try_rules._get_2gram_sets", "try_rules._get_2gram_sets", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "len", "len", "len", "len", "len", "len", "len", "len", "gold_1gram.intersection", "gold_2gram.intersection", "gold_1gram.intersection", "gold_1gram.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_2gram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_2gram_sets"], ["", "def", "get_rouge_est_str_2gram", "(", "gold", ",", "pred", ")", "->", "float", ":", "\n", "    ", "cand_1gram", ",", "cand_2gram", "=", "_get_2gram_sets", "(", "pred", ")", "\n", "gold_1gram", ",", "gold_2gram", "=", "_get_2gram_sets", "(", "gold", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1gram", ")", ")", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2gram", ".", "intersection", "(", "cand_2gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2gram", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "cand_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_1gram", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "cand_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_2gram", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "average_f_score", "=", "(", "f1", "+", "f2", ")", "/", "2", "\n", "\n", "# print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)", "\n", "return", "average_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.try_rules.length_compensation": [[57, 69], ["len", "len", "type", "doc.split.split"], "function", ["None"], ["def", "length_compensation", "(", "doc", ",", "abs", ":", "List", ")", "->", "str", ":", "\n", "    ", "if", "type", "(", "doc", ")", "is", "str", ":", "\n", "        ", "doc", "=", "doc", ".", "split", "(", "\" \"", ")", "\n", "", "l_abs", "=", "len", "(", "abs", ")", "\n", "l_doc", "=", "len", "(", "doc", ")", "\n", "if", "l_abs", ">", "l_doc", ":", "\n", "        ", "gap", "=", "l_abs", "-", "l_doc", "\n", "backup", "=", "CONTENT_LIB", "[", ":", "gap", "]", "\n", "", "else", ":", "\n", "        ", "backup", "=", "[", "]", "\n", "", "doc", "=", "doc", "+", "backup", "\n", "return", "\" \"", ".", "join", "(", "doc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.try_rules.plain": [[71, 73], ["None"], "function", ["None"], ["", "def", "plain", "(", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.try_rules.tok_preprocess": [[78, 89], ["re.sub", "re.split", "output.append", "output_stem.append", "stemmer.stem", "len"], "function", ["None"], ["def", "tok_preprocess", "(", "text", ":", "List", ")", ":", "\n", "    ", "output", "=", "[", "]", "\n", "output_stem", "=", "[", "]", "\n", "for", "e", "in", "text", ":", "\n", "        ", "o", "=", "re", ".", "sub", "(", "r\"[^a-zA-Z0-9]+\"", ",", "\" \"", ",", "e", ")", "\n", "tokens", "=", "re", ".", "split", "(", "r\"\\s+\"", ",", "o", ")", "\n", "tokens", "=", "[", "stemmer", ".", "stem", "(", "x", ")", "if", "len", "(", "x", ")", ">", "3", "else", "x", "for", "x", "in", "tokens", "]", "\n", "o_stem", "=", "\" \"", ".", "join", "(", "tokens", ")", "\n", "output", ".", "append", "(", "o", ")", "\n", "output_stem", ".", "append", "(", "o_stem", ")", "\n", "", "return", "output", ",", "output_stem", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.build_data_from_snlp_parse.recover_one_sample": [[8, 47], ["os.path.join", "os.path.join", "neusum.orac.util.extract_tokens", "neusum.orac.util.extract_tokens", "enumerate", "json.loads", "json.loads", "len", "doc_bag.append", "abs_bag.append", "os.path.isfile", "os.path.isfile", "neusum.orac.util.read_file", "neusum.orac.util.read_file", "print", "_formal_doc_token.append"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_compression_based_data.extract_tokens", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.orac.util.read_file"], ["def", "recover_one_sample", "(", "path_read", ",", "fname_without_suffix", ",", "data_name", ",", "max_sent", "=", "30", ")", ":", "\n", "    ", "doc_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".doc.json\"", ")", "\n", "abs_file", "=", "os", ".", "path", ".", "join", "(", "path_read", ",", "fname_without_suffix", "+", "\".abs.json\"", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "doc_file", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "abs_file", ")", ")", ":", "\n", "        ", "raise", "TypeError", "\n", "", "try", ":", "\n", "        ", "doc_dict", "=", "json", ".", "loads", "(", "read_file", "(", "doc_file", ")", ")", "\n", "abs_dict", "=", "json", ".", "loads", "(", "read_file", "(", "abs_file", ")", ")", "\n", "", "except", "json", ".", "decoder", ".", "JSONDecodeError", ":", "\n", "        ", "print", "(", "\"forget it?\"", ")", "\n", "return", "\"\"", "\n", "", "abs_token", ",", "abs_str", "=", "extract_tokens", "(", "abs_dict", ")", "\n", "doc_token", ",", "doc_str", "=", "extract_tokens", "(", "doc_dict", ")", "\n", "\n", "# filter doc", "\n", "cnt", "=", "0", "\n", "_formal_doc_token", "=", "[", "]", "\n", "for", "doc_idx", ",", "doc_t", "in", "enumerate", "(", "doc_token", ")", ":", "\n", "        ", "l", "=", "len", "(", "doc_t", ")", "\n", "if", "l", ">", "3", "and", "l", "<", "70", ":", "# stat shows l>70+ is  64 out of 26k", "\n", "            ", "_formal_doc_token", ".", "append", "(", "doc_t", ")", "\n", "cnt", "+=", "1", "\n", "", "if", "cnt", ">=", "max_sent", ":", "\n", "            ", "break", "\n", "", "", "doc_token", "=", "_formal_doc_token", "\n", "doc_bag", ",", "abs_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "d_token", "in", "doc_token", ":", "\n", "        ", "d_str", "=", "\" \"", ".", "join", "(", "d_token", ")", "\n", "doc_bag", ".", "append", "(", "d_str", ")", "\n", "", "for", "a_token", "in", "abs_token", ":", "\n", "        ", "a_str", "=", "\" \"", ".", "join", "(", "a_token", ")", "\n", "abs_bag", ".", "append", "(", "a_str", ")", "\n", "", "doc_bag", "=", "[", "x", "for", "x", "in", "doc_bag", "if", "x", "!=", "\"\"", "]", "\n", "rt_doc", "=", "\"{}\"", ".", "format", "(", "SPLIT_SIG", ")", ".", "join", "(", "doc_bag", ")", "\n", "abs_bag", "=", "[", "x", "for", "x", "in", "abs_bag", "if", "x", "!=", "\"\"", "]", "\n", "rt_abs", "=", "\"{}\"", ".", "format", "(", "SPLIT_SIG", ")", ".", "join", "(", "abs_bag", ")", "\n", "# cnn-8hu23fh923hf \\tdoc_sent_1<SPLIT>doc_sent_2<SPLIT>doc_sent_3<SPLIT>...\\tabs_sent_1<SPLIT>abs_sent_2..", "\n", "wt", "=", "\"{}\\t{}\\t{}\\t{}\"", ".", "format", "(", "data_name", ",", "fname_without_suffix", ",", "rt_doc", ",", "rt_abs", ")", "\n", "return", "wt", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.data.generate_vocab.read_one": [[35, 44], ["open", "json.loads", "allennlp.data.fields.TextField", "instances.append", "allennlp.data.instance.Instance", "allennlp.data.tokenizers.Token", "doc_str.split"], "function", ["None"], ["def", "read_one", "(", "file_path", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "for", "line", "in", "fd", ":", "\n", "            ", "data_dict", "=", "json", ".", "loads", "(", "line", ")", "\n", "doc_str", "=", "data_dict", "[", "'doc'", "]", "\n", "allen_token_word_in_doc", "=", "TextField", "(", "[", "Token", "(", "word", ")", "for", "word", "in", "doc_str", ".", "split", "(", ")", "]", ",", "word_token_indexers", ")", "\n", "instances", ".", "append", "(", "Instance", "(", "{", "\"text\"", ":", "allen_token_word_in_doc", "}", ")", ")", "\n", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.__init__": [[46, 56], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "path_to_valid", ":", "str", "=", "'/tmp/'", ",", "writting_address", ":", "str", "=", "\"\"", ",", "\n", "serilization_name", ":", "str", "=", "\"\"", ")", "->", "None", ":", "\n", "        ", "self", ".", "pred_str_bag", ":", "List", "[", "List", "[", "str", "]", "]", "=", "[", "]", "\n", "self", ".", "ref_str_bag", ":", "List", "[", "List", "[", "List", "[", "str", "]", "]", "]", "=", "[", "]", "\n", "self", ".", "origin_str_bag", "=", "[", "]", "\n", "self", ".", "name_bag", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "writting_address", "=", "writting_address", "\n", "self", ".", "path", "=", "path_to_valid", "\n", "self", ".", "serilization_name", "=", "serilization_name", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.__call__": [[57, 71], ["rouge_with_pythonrouge.RougeStrEvaluation.pred_str_bag.append", "rouge_with_pythonrouge.RougeStrEvaluation.ref_str_bag.append", "rouge_with_pythonrouge.RougeStrEvaluation.origin_str_bag.append"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "pred", ":", "List", "[", "str", "]", ",", "ref", ":", "List", "[", "List", "[", "str", "]", "]", ",", "origin", ":", "List", "[", "str", "]", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# # summary: double list", "\n", "# summary = [[summaryA_sent1, summaryA_sent2],", "\n", "#            [summaryB_sent1, summaryB_sent2]]", "\n", "# # reference: triple list", "\n", "# reference = [[[summaryA_ref1_sent1, summaryA_ref1_sent2],", "\n", "#               [summaryA_ref2_sent1, summaryA_ref2_sent2]],", "\n", "#              [[summaryB_ref1_sent1, summaryB_ref1_sent2],", "\n", "#               [summaryB_ref2_sent1, summaryB_ref2_sent2]]", "\n", "        ", "self", ".", "pred_str_bag", ".", "append", "(", "pred", ")", "\n", "self", ".", "ref_str_bag", ".", "append", "(", "ref", ")", "\n", "if", "origin", ":", "\n", "            ", "self", ".", "origin_str_bag", ".", "append", "(", "origin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics": [[105, 113], ["rouge_with_pythonrouge.RougeStrEvaluation.reset"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.reset"], ["def", "return_blank_metrics", "(", "self", ")", ":", "\n", "        ", "all_metrics", "=", "{", "}", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_1'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_2'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_L'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_A'", "]", "=", "0", "\n", "self", ".", "reset", "(", ")", "\n", "return", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric": [[114, 216], ["logging.getLogger", "logging.getLogger.info", "pythonrouge.pythonrouge.Pythonrouge", "pythonrouge.pythonrouge.Pythonrouge.calc_score", "logging.getLogger.info", "print", "len", "open", "open.close", "rouge_with_pythonrouge.RougeStrEvaluation.reset", "len", "rouge_with_pythonrouge.RougeStrEvaluation.reset", "len", "print", "len", "os.path.join", "abs", "print", "logging.getLogger.warning", "rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "abs", "print", "logging.getLogger.warning", "rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "len", "logging.getLogger.warning", "rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "abs", "rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "pickle.dump", "pickle.dump", "pickle.dump", "pickle.dump", "len", "len", "len", "len", "len", "len", "len", "len", "pickle.dump", "pickle.dump", "NotImplementedError", "pickle.dump", "pickle.dump"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.reset", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.reset", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.return_blank_metrics"], ["", "def", "get_metric", "(", "self", ",", "reset", ":", "bool", ",", "note", "=", "\"\"", ")", ":", "\n", "        ", "if", "(", "not", "reset", ")", "or", "(", "len", "(", "self", ".", "pred_str_bag", ")", "==", "0", ")", ":", "\n", "# print(\"reset: {}\\tVolum: {}\\tNote:{}\".format(reset,len(self.pred_str_bag),note))", "\n", "            ", "all_metrics", "=", "{", "}", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_1'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_2'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_L'", "]", "=", "0", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_A'", "]", "=", "0", "\n", "if", "note", "==", "\"\"", ":", "\n", "                ", "self", ".", "reset", "(", ")", "\n", "", "return", "all_metrics", "\n", "\n", "# print(len(self.pred_str_bag))", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "info", "(", "\"reset: {}\\tVolum: {}\\tNote:{}\"", ".", "format", "(", "reset", ",", "len", "(", "self", ".", "pred_str_bag", ")", ",", "note", ")", ")", "\n", "if", "'dm'", "in", "self", ".", "serilization_name", "and", "'cnn'", "not", "in", "self", ".", "serilization_name", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "abs", "(", "len", "(", "self", ".", "pred_str_bag", ")", "-", "10397", ")", "<=", "10", "\n", "", "except", "AssertionError", ":", "\n", "                ", "print", "(", "\"Len: {}  -- match 10397\"", ".", "format", "(", "len", "(", "self", ".", "pred_str_bag", ")", ")", ")", "\n", "logger", ".", "warning", "(", "\"Len: {}  -- match 10397\"", ".", "format", "(", "len", "(", "self", ".", "pred_str_bag", ")", ")", ")", "\n", "return", "self", ".", "return_blank_metrics", "(", ")", "\n", "", "", "if", "'dm'", "not", "in", "self", ".", "serilization_name", "and", "'cnn'", "in", "self", ".", "serilization_name", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "abs", "(", "len", "(", "self", ".", "pred_str_bag", ")", "-", "1093", ")", "<=", "5", "\n", "", "except", "AssertionError", ":", "\n", "                ", "print", "(", "\"Len: {}  -- match 1093\"", ".", "format", "(", "len", "(", "self", ".", "pred_str_bag", ")", ")", ")", "\n", "logger", ".", "warning", "(", "\"Len: {}  -- match 1093\"", ".", "format", "(", "len", "(", "self", ".", "pred_str_bag", ")", ")", ")", "\n", "return", "self", ".", "return_blank_metrics", "(", ")", "\n", "\n", "", "", "if", "'nyt'", "in", "self", ".", "serilization_name", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "len", "(", "self", ".", "pred_str_bag", ")", "==", "17218", "\n", "", "except", "AssertionError", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Len: {}  -- match 17218\"", ".", "format", "(", "len", "(", "self", ".", "pred_str_bag", ")", ")", ")", "\n", "return", "self", ".", "return_blank_metrics", "(", ")", "\n", "", "", "if", "'cnndm'", "in", "self", ".", "serilization_name", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "abs", "(", "len", "(", "self", ".", "pred_str_bag", ")", "-", "11490", ")", "<=", "10", "\n", "", "except", "AssertionError", ":", "\n", "                ", "return", "self", ".", "return_blank_metrics", "(", ")", "\n", "# assert note != \"\"", "\n", "\n", "", "", "rouge", "=", "Pythonrouge", "(", "summary_file_exist", "=", "False", ",", "\n", "summary", "=", "self", ".", "pred_str_bag", ",", "reference", "=", "self", ".", "ref_str_bag", ",", "\n", "n_gram", "=", "2", ",", "ROUGE_SU4", "=", "True", ",", "ROUGE_L", "=", "True", ",", "ROUGE_W", "=", "True", ",", "\n", "ROUGE_W_Weight", "=", "1.2", ",", "\n", "recall_only", "=", "False", ",", "stemming", "=", "True", ",", "stopwords", "=", "False", ",", "\n", "word_level", "=", "True", ",", "length_limit", "=", "False", ",", "length", "=", "50", ",", "\n", "use_cf", "=", "False", ",", "cf", "=", "95", ",", "scoring_formula", "=", "'average'", ",", "\n", "resampling", "=", "True", ",", "samples", "=", "1000", ",", "favor", "=", "True", ",", "p", "=", "0.5", ",", "default_conf", "=", "True", ",", "\n", "xml_dir", "=", "self", ".", "path", ",", "peer_path", "=", "self", ".", "path", ",", "model_path", "=", "self", ".", "path", ")", "\n", "score", "=", "rouge", ".", "calc_score", "(", ")", "\n", "try", ":", "\n", "            ", "print", "(", "\"Note: {}\\tName: {}\\tScore: {}\"", ".", "format", "(", "note", ",", "self", ".", "name", ",", "score", ")", ")", "\n", "", "except", "NameError", ":", "\n", "            ", "print", "(", "\"Score: {}\"", ".", "format", "(", "score", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Note: {}\\tName: {}\\tLen: {}\\tScore: {}\"", ".", "format", "(", "note", ",", "self", ".", "name", ",", "len", "(", "self", ".", "pred_str_bag", ")", ",", "score", ")", ")", "\n", "all_metrics", "=", "{", "}", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_1'", "]", "=", "score", "[", "'ROUGE-1-F'", "]", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_2'", "]", "=", "score", "[", "'ROUGE-2-F'", "]", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_L'", "]", "=", "score", "[", "'ROUGE-L-F'", "]", "\n", "all_metrics", "[", "self", ".", "name", "+", "'_A'", "]", "=", "(", "score", "[", "'ROUGE-1-F'", "]", "+", "score", "[", "'ROUGE-2-F'", "]", "+", "score", "[", "'ROUGE-L-F'", "]", ")", "/", "3.", "\n", "_ser_name", "=", "\"{0:.3f},{1:.3f},{2:.3f}-{3}-{4}-{5}\"", ".", "format", "(", "score", "[", "'ROUGE-1-F'", "]", ",", "score", "[", "'ROUGE-2-F'", "]", ",", "\n", "score", "[", "'ROUGE-L-F'", "]", ",", "\n", "self", ".", "serilization_name", ",", "len", "(", "self", ".", "pred_str_bag", ")", ",", "\n", "self", ".", "name", ")", "\n", "# f = open(os.path.join(self.writting_address, _ser_name), 'wb')", "\n", "# pickle.dump({}, f)", "\n", "# f.close()", "\n", "if", "note", "==", "\"test\"", ":", "\n", "            ", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "writting_address", ",", "_ser_name", ")", ",", "'wb'", ")", "\n", "# pickle.dump({}, f)", "\n", "# f.close()", "\n", "if", "'cnndm'", "in", "self", ".", "serilization_name", ":", "\n", "                ", "if", "score", "[", "'ROUGE-1-F'", "]", ">", "0.41", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "\"pred\"", ":", "self", ".", "pred_str_bag", ",", "\"ref\"", ":", "self", ".", "ref_str_bag", ",", "\"ori\"", ":", "self", ".", "origin_str_bag", "}", ",", "f", ")", "\n", "", "else", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "}", ",", "f", ")", "\n", "", "", "elif", "'dm'", "in", "self", ".", "serilization_name", ":", "\n", "                ", "if", "score", "[", "'ROUGE-1-F'", "]", ">", "0.418", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "\"pred\"", ":", "self", ".", "pred_str_bag", ",", "\"ref\"", ":", "self", ".", "ref_str_bag", ",", "\"ori\"", ":", "self", ".", "origin_str_bag", "}", ",", "f", ")", "\n", "", "else", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "}", ",", "f", ")", "\n", "", "", "elif", "'cnn'", "in", "self", ".", "serilization_name", ":", "\n", "                ", "if", "score", "[", "'ROUGE-1-F'", "]", ">", "0.32", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "\"pred\"", ":", "self", ".", "pred_str_bag", ",", "\"ref\"", ":", "self", ".", "ref_str_bag", ",", "\"ori\"", ":", "self", ".", "origin_str_bag", "}", ",", "f", ")", "\n", "", "else", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "}", ",", "f", ")", "\n", "", "", "elif", "'nyt'", "in", "self", ".", "serilization_name", ":", "\n", "                ", "if", "score", "[", "'ROUGE-1-F'", "]", ">", "0.452", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "\"pred\"", ":", "self", ".", "pred_str_bag", ",", "\"ref\"", ":", "self", ".", "ref_str_bag", ",", "\"ori\"", ":", "self", ".", "origin_str_bag", "}", ",", "f", ")", "\n", "", "else", ":", "\n", "                    ", "pickle", ".", "dump", "(", "{", "}", ",", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Dataset mismatch!\"", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.reset": [[217, 222], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "pred_str_bag", "=", "[", "]", "\n", "self", ".", "ref_str_bag", "=", "[", "]", "\n", "self", ".", "origin_str_bag", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.rouge_protocol": [[14, 41], ["pythonrouge.pythonrouge.Pythonrouge", "pythonrouge.pythonrouge.Pythonrouge.calc_score", "TypeError", "isinstance", "isinstance"], "function", ["None"], ["def", "rouge_protocol", "(", "list_of_pred", ",", "list_of_reference", ")", ":", "\n", "    ", "\"\"\"\n    # summary: double list\n        summary = [[summaryA_sent1, summaryA_sent2],\n                   [summaryB_sent1, summaryB_sent2]]\n    # reference: triple list\n    reference = [[[summaryA_ref1_sent1, summaryA_ref1_sent2],\n                     [summaryA_ref2_sent1, summaryA_ref2_sent2]],\n                     [[summaryB_ref1_sent1, summaryB_ref1_sent2],\n                     [summaryB_ref2_sent1, summaryB_ref2_sent2]]\n    :param list_of_pred: [[]]\n    :param list_of_reference:[[[]]]\n    :return:\n    \"\"\"", "\n", "# print(list_of_pred, list_of_reference)", "\n", "if", "(", "not", "isinstance", "(", "list_of_pred", ",", "List", ")", ")", "or", "(", "not", "isinstance", "(", "list_of_reference", ",", "List", ")", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"Input should be list.\"", ")", "\n", "", "rouge", "=", "Pythonrouge", "(", "summary_file_exist", "=", "False", ",", "\n", "summary", "=", "list_of_pred", ",", "reference", "=", "list_of_reference", ",", "\n", "n_gram", "=", "2", ",", "ROUGE_SU4", "=", "True", ",", "ROUGE_L", "=", "True", ",", "ROUGE_W", "=", "True", ",", "\n", "ROUGE_W_Weight", "=", "1.2", ",", "\n", "recall_only", "=", "False", ",", "stemming", "=", "True", ",", "stopwords", "=", "False", ",", "\n", "word_level", "=", "True", ",", "length_limit", "=", "False", ",", "length", "=", "50", ",", "\n", "use_cf", "=", "False", ",", "cf", "=", "95", ",", "scoring_formula", "=", "'average'", ",", "\n", "resampling", "=", "True", ",", "samples", "=", "1000", ",", "favor", "=", "True", ",", "p", "=", "0.5", ",", "default_conf", "=", "True", ")", "\n", "score", "=", "rouge", ".", "calc_score", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_1gram_sets": [[122, 129], ["list", "len", "set", "filter", "map", "list.split", "range", "str"], "function", ["None"], ["", "def", "_get_1gram_sets", "(", "highlights", ")", ":", "\n", "    ", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "\n", "fullen", "=", "len", "(", "highlights", ")", "\n", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "fullen", ")", ")", ")", "\n", "return", "set_1gram", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_1gram": [[28, 48], ["rough_rouge._get_1gram_sets", "rough_rouge._get_1gram_sets", "len", "len", "float", "float", "float", "float", "len", "len", "len", "len", "_get_1gram_sets.intersection", "_get_1gram_sets.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_1gram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_1gram_sets"], ["", "def", "get_rouge_est_str_1gram", "(", "gold", ":", "str", ",", "pred", ":", "str", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Given two string, return the rouge1 F1.\n    :param gold:\n    :param pred:\n    :return:\n    \"\"\"", "\n", "cand_1gram", "=", "_get_1gram_sets", "(", "pred", ")", "\n", "gold_1gram", "=", "_get_1gram_sets", "(", "gold", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1gram", ")", ")", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "cand_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_1gram", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "# print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_2gram": [[50, 75], ["rough_rouge._get_2gram_sets", "rough_rouge._get_2gram_sets", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "len", "len", "len", "len", "len", "len", "len", "len", "gold_1gram.intersection", "gold_2gram.intersection", "gold_1gram.intersection", "gold_1gram.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_2gram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_2gram_sets"], ["", "def", "get_rouge_est_str_2gram", "(", "gold", ",", "pred", ")", "->", "float", ":", "\n", "    ", "cand_1gram", ",", "cand_2gram", "=", "_get_2gram_sets", "(", "pred", ")", "\n", "gold_1gram", ",", "gold_2gram", "=", "_get_2gram_sets", "(", "gold", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1gram", ")", ")", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2gram", ".", "intersection", "(", "cand_2gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2gram", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "cand_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_1gram", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "cand_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_2gram", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "average_f_score", "=", "(", "f1", "+", "f2", ")", "/", "2", "\n", "# print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)", "\n", "return", "average_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str_4gram": [[77, 120], ["rough_rouge._get_ngram_sets", "rough_rouge._get_ngram_sets", "len", "len", "len", "len", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "gold_1gram.intersection", "gold_2gram.intersection", "gold_3gram.intersection", "gold_4gram.intersection", "gold_1gram.intersection", "gold_1gram.intersection", "gold_3gram.intersection", "gold_4gram.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_ngram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_ngram_sets"], ["", "def", "get_rouge_est_str_4gram", "(", "gold", ",", "pred", ")", ":", "\n", "    ", "cand_1gram", ",", "cand_2gram", ",", "cand_3gram", ",", "cand_4gram", "=", "_get_ngram_sets", "(", "pred", ")", "\n", "gold_1gram", ",", "gold_2gram", ",", "gold_3gram", ",", "gold_4gram", "=", "_get_ngram_sets", "(", "gold", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1gram", ")", ")", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2gram", ".", "intersection", "(", "cand_2gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2gram", ")", ")", "\n", "", "rouge_recall_3", "=", "0", "\n", "if", "len", "(", "gold_3gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_3", "=", "float", "(", "len", "(", "gold_3gram", ".", "intersection", "(", "cand_3gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_3gram", ")", ")", "\n", "", "rouge_recall_4", "=", "0", "\n", "if", "len", "(", "gold_4gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_4", "=", "float", "(", "len", "(", "gold_4gram", ".", "intersection", "(", "cand_4gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_4gram", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "cand_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_1gram", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "cand_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_2gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_2gram", ")", ")", "\n", "\n", "", "rouge_pre_3", "=", "0", "\n", "if", "len", "(", "cand_3gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_3", "=", "float", "(", "len", "(", "gold_3gram", ".", "intersection", "(", "cand_3gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_3gram", ")", ")", "\n", "\n", "", "rouge_pre_4", "=", "0", "\n", "if", "len", "(", "cand_4gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_4", "=", "float", "(", "len", "(", "gold_4gram", ".", "intersection", "(", "cand_4gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_4gram", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "f3", "=", "0", "if", "(", "rouge_recall_3", "+", "rouge_pre_3", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_3", "*", "rouge_pre_3", ")", "/", "(", "\n", "rouge_recall_3", "+", "rouge_pre_3", ")", "\n", "f4", "=", "0", "if", "(", "rouge_recall_4", "+", "rouge_pre_4", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_4", "*", "rouge_pre_4", ")", "/", "(", "\n", "rouge_recall_4", "+", "rouge_pre_4", ")", "\n", "average_f_score", "=", "(", "f1", "+", "f2", "+", "f3", "+", "f4", ")", "\n", "# print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)", "\n", "return", "average_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_2gram_sets": [[131, 140], ["list", "len", "set", "set", "filter", "map", "map", "list.split", "range", "range", "str", "str", "str"], "function", ["None"], ["", "def", "_get_2gram_sets", "(", "highlights", ")", ":", "\n", "    ", "\"\"\"The input highlights should be a sequence of texts.\"\"\"", "\n", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "\n", "fullen", "=", "len", "(", "highlights", ")", "\n", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "fullen", ")", ")", ")", "\n", "set_2gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", ",", "range", "(", "fullen", "-", "1", ")", ")", ")", "\n", "return", "set_1gram", ",", "set_2gram", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_ngram_sets": [[142, 158], ["list", "len", "set", "set", "set", "set", "filter", "map", "map", "map", "map", "list.split", "range", "range", "range", "range", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "_get_ngram_sets", "(", "highlights", ")", ":", "\n", "    ", "\"\"\"The input highlights should be a sequence of texts.\"\"\"", "\n", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "\n", "fullen", "=", "len", "(", "highlights", ")", "\n", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "fullen", ")", ")", ")", "\n", "set_2gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", ",", "range", "(", "fullen", "-", "1", ")", ")", ")", "\n", "set_3gram", "=", "set", "(", "\n", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "2", "]", ")", ",", "\n", "range", "(", "fullen", "-", "2", ")", ")", ")", "\n", "set_4gram", "=", "set", "(", "\n", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", "+", "\"-\"", "+", "str", "(", "\n", "highlights", "[", "widx", "+", "2", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "3", "]", ")", ",", "\n", "range", "(", "fullen", "-", "3", ")", ")", ")", "\n", "return", "set_1gram", ",", "set_2gram", ",", "set_3gram", ",", "set_4gram", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_lcs": [[160, 183], ["enumerate", "len", "enumerate", "len", "len", "range", "range", "max", "len", "len"], "function", ["None"], ["", "def", "_get_lcs", "(", "a", ",", "b", ")", ":", "\n", "    ", "lengths", "=", "[", "[", "0", "for", "j", "in", "range", "(", "len", "(", "b", ")", "+", "1", ")", "]", "for", "i", "in", "range", "(", "len", "(", "a", ")", "+", "1", ")", "]", "\n", "# row 0 and column 0 are initialized to 0 already", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "a", ")", ":", "\n", "        ", "for", "j", ",", "y", "in", "enumerate", "(", "b", ")", ":", "\n", "            ", "if", "x", "==", "y", ":", "\n", "                ", "lengths", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "lengths", "[", "i", "]", "[", "j", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "lengths", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "max", "(", "lengths", "[", "i", "+", "1", "]", "[", "j", "]", ",", "lengths", "[", "i", "]", "[", "j", "+", "1", "]", ")", "\n", "# read the substring out from the matrix", "\n", "", "", "", "result", "=", "[", "]", "\n", "x", ",", "y", "=", "len", "(", "a", ")", ",", "len", "(", "b", ")", "\n", "while", "x", "!=", "0", "and", "y", "!=", "0", ":", "\n", "        ", "if", "lengths", "[", "x", "]", "[", "y", "]", "==", "lengths", "[", "x", "-", "1", "]", "[", "y", "]", ":", "\n", "            ", "x", "-=", "1", "\n", "", "elif", "lengths", "[", "x", "]", "[", "y", "]", "==", "lengths", "[", "x", "]", "[", "y", "-", "1", "]", ":", "\n", "            ", "y", "-=", "1", "\n", "", "else", ":", "\n", "            ", "assert", "a", "[", "x", "-", "1", "]", "==", "b", "[", "y", "-", "1", "]", "\n", "result", "=", "[", "a", "[", "x", "-", "1", "]", "]", "+", "result", "\n", "x", "-=", "1", "\n", "y", "-=", "1", "\n", "", "", "return", "len", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge.get_rouge_est_str": [[185, 219], ["rough_rouge._get_ngram_sets", "rough_rouge._get_ngram_sets", "rough_rouge._get_lcs", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "float", "len", "float", "len", "len", "len", "len", "len", "len", "len", "len", "len", "gold_1gram.intersection", "gold_2gram.intersection", "gold_1gram.intersection", "gold_1gram.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_ngram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_ngram_sets", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rough_rouge._get_lcs"], ["", "def", "get_rouge_est_str", "(", "gold", ",", "pred", ")", ":", "\n", "    ", "cand_1gram", ",", "cand_2gram", ",", "cand_3gram", ",", "cand_4gram", "=", "_get_ngram_sets", "(", "pred", ")", "\n", "gold_1gram", ",", "gold_2gram", ",", "gold_3gram", ",", "gold_4gram", "=", "_get_ngram_sets", "(", "gold", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1gram", ")", ")", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2gram", ".", "intersection", "(", "cand_2gram", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2gram", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "cand_1gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_1gram", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "cand_2gram", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_1gram", ".", "intersection", "(", "cand_1gram", ")", ")", ")", "/", "float", "(", "len", "(", "cand_2gram", ")", ")", "\n", "\n", "# Get ROUGE-L", "\n", "", "len_lcs", "=", "_get_lcs", "(", "pred", ",", "gold", ")", "\n", "r", "=", "0", "if", "(", "len_lcs", "==", "0", ")", "else", "(", "float", "(", "len_lcs", ")", "/", "len", "(", "pred", ")", ")", "\n", "p", "=", "0", "if", "(", "len_lcs", "==", "0", ")", "else", "(", "float", "(", "len_lcs", ")", "/", "len", "(", "gold", ")", ")", "\n", "b", "=", "0", "if", "(", "r", "==", "0", ")", "else", "(", "p", "/", "r", ")", "\n", "rouge_recall_l", "=", "0", "if", "(", "len_lcs", "==", "0", ")", "else", "(", "(", "(", "1", "+", "(", "b", "*", "b", ")", ")", "*", "r", "*", "p", ")", "/", "(", "r", "+", "(", "b", "*", "b", "*", "p", ")", ")", ")", "\n", "rouge_pre_l", "=", "0", "if", "(", "len_lcs", "==", "0", ")", "else", "(", "(", "(", "1", "+", "(", "b", "*", "b", ")", ")", "*", "r", "*", "p", ")", "/", "(", "p", "+", "(", "b", "*", "b", "*", "r", ")", ")", ")", "\n", "\n", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "fl", "=", "0", "if", "rouge_pre_l", "+", "rouge_recall_l", "==", "0", "else", "2", "*", "(", "rouge_pre_l", "*", "rouge_recall_l", ")", "/", "(", "rouge_pre_l", "+", "rouge_recall_l", ")", "\n", "average_f_score", "=", "(", "f1", "+", "f2", "+", "fl", ")", "/", "3", "\n", "# print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)", "\n", "return", "average_f_score", ",", "f1", ",", "f2", ",", "fl", "\n", "", ""]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_keep_stop": [[27, 42], ["list", "len", "set", "set", "filter", "map", "map", "set", "set", "list.split", "range", "range", "map", "str", "range", "str", "str", "str", "str", "len", "stemmer.stem"], "function", ["None"], ["def", "_get_2gram_sets_keep_stop", "(", "highlights", ":", "str", ",", "stemming", "=", "True", ")", ":", "\n", "    ", "\"\"\"The input highlights should be a sequence of texts.\"\"\"", "\n", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "\n", "full_len", "=", "len", "(", "highlights", ")", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "full_len", ")", ")", ")", "\n", "\n", "set_2gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", ",", "range", "(", "full_len", "-", "1", ")", ")", ")", "\n", "\n", "if", "stemming", ":", "\n", "        ", "set_stem", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "stemmer", ".", "stem", "(", "highlights", "[", "widx", "]", ")", ")", "\n", "if", "len", "(", "highlights", "[", "widx", "]", ")", ">", "3", "else", "str", "(", "highlights", "[", "widx", "]", ")", ",", "range", "(", "full_len", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "set_stem", "=", "set", "(", ")", "\n", "", "return", "set_1gram", ",", "set_2gram", ",", "set_stem", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_rm_stop": [[44, 61], ["list", "list", "len", "len", "set", "set", "filter", "filter", "map", "map", "set", "set", "list.split", "range", "range", "map", "str", "range", "str", "str", "str", "str", "len", "stemmer.stem"], "function", ["None"], ["", "def", "_get_2gram_sets_rm_stop", "(", "highlights", ":", "str", ",", "stemming", "=", "True", ")", ":", "\n", "    ", "\"\"\"The input highlights should be a sequence of texts.\"\"\"", "\n", "highlights", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "!=", "\"\"", ",", "highlights", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "highlights_no_stop", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "not", "in", "STOP_WORDS", ",", "highlights", ")", ")", "\n", "\n", "full_len", "=", "len", "(", "highlights", ")", "\n", "partial_len", "=", "len", "(", "highlights_no_stop", ")", "\n", "set_1gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights_no_stop", "[", "widx", "]", ")", ",", "range", "(", "partial_len", ")", ")", ")", "\n", "\n", "set_2gram", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "highlights", "[", "widx", "]", ")", "+", "\"-\"", "+", "str", "(", "highlights", "[", "widx", "+", "1", "]", ")", ",", "range", "(", "full_len", "-", "1", ")", ")", ")", "\n", "\n", "if", "stemming", ":", "\n", "        ", "set_stem", "=", "set", "(", "map", "(", "lambda", "widx", ":", "str", "(", "stemmer", ".", "stem", "(", "highlights_no_stop", "[", "widx", "]", ")", ")", "\n", "if", "len", "(", "highlights_no_stop", "[", "widx", "]", ")", ">", "3", "else", "str", "(", "highlights_no_stop", "[", "widx", "]", ")", ",", "range", "(", "partial_len", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "set_stem", "=", "set", "(", ")", "\n", "", "return", "set_1gram", ",", "set_2gram", ",", "set_stem", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart_kick_stop_words": [[63, 103], ["smart_approx_rouge._get_2gram_sets_rm_stop", "smart_approx_rouge._get_2gram_sets_rm_stop", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "float", "float", "float", "float", "gold_1.intersection", "gold_1.intersection", "gold_2.intersection", "gold_2.intersection", "len", "len", "len", "len", "gold_st.intersection", "gold_st.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_rm_stop", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_rm_stop"], ["", "def", "get_rouge_est_str_2gram_smart_kick_stop_words", "(", "gold", ":", "str", ",", "pred", ":", "str", ",", "stemming", "=", "True", ")", ":", "\n", "    ", "gold_1", ",", "gold_2", ",", "gold_st", "=", "_get_2gram_sets_rm_stop", "(", "gold", ",", "stemming", ")", "\n", "pred_1", ",", "pred_2", ",", "pred_st", "=", "_get_2gram_sets_rm_stop", "(", "pred", ",", "stemming", ")", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1", ".", "intersection", "(", "pred_1", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "pred_1", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1", ".", "intersection", "(", "pred_1", ")", ")", ")", "/", "float", "(", "len", "(", "pred_1", ")", ")", "\n", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2", ".", "intersection", "(", "pred_2", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "pred_2", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_2", ".", "intersection", "(", "pred_2", ")", ")", ")", "/", "float", "(", "len", "(", "pred_2", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "if", "stemming", ":", "\n", "\n", "        ", "rouge_recall_st", "=", "0", "\n", "if", "len", "(", "gold_st", ")", "!=", "0", ":", "\n", "            ", "rouge_recall_st", "=", "float", "(", "len", "(", "gold_st", ".", "intersection", "(", "pred_st", ")", ")", ")", "/", "float", "(", "len", "(", "gold_st", ")", ")", "\n", "\n", "", "rouge_pre_st", "=", "0", "\n", "if", "len", "(", "pred_st", ")", "!=", "0", ":", "\n", "            ", "rouge_pre_st", "=", "float", "(", "len", "(", "gold_st", ".", "intersection", "(", "pred_st", ")", ")", ")", "/", "float", "(", "len", "(", "pred_st", ")", ")", "\n", "", "f_st", "=", "0", "if", "(", "rouge_recall_st", "+", "rouge_pre_st", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_st", "*", "rouge_pre_st", ")", "/", "(", "\n", "rouge_recall_st", "+", "rouge_pre_st", ")", "\n", "\n", "average_f_score", "=", "f1", "*", "0.25", "+", "f2", "*", "0.5", "+", "0.25", "*", "f_st", "\n", "", "else", ":", "\n", "        ", "average_f_score", "=", "(", "f1", "+", "f2", ")", "/", "2", "\n", "# average_f_score = (f1 )     # TODO", "\n", "", "return", "average_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge.get_rouge_est_str_2gram_smart": [[105, 154], ["smart_approx_rouge._get_2gram_sets_keep_stop", "smart_approx_rouge._get_2gram_sets_keep_stop", "len", "len", "len", "len", "float", "float", "float", "float", "float", "float", "float", "float", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "float", "float", "float", "float", "gold_1.intersection", "gold_1.intersection", "gold_2.intersection", "gold_2.intersection", "len", "len", "len", "len", "gold_st.intersection", "gold_st.intersection"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_keep_stop", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.smart_approx_rouge._get_2gram_sets_keep_stop"], ["", "def", "get_rouge_est_str_2gram_smart", "(", "gold", ":", "str", ",", "pred", ":", "str", ",", "stemming", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    If not stemming, return (f1 + f2) / 2\n    If stemming, return (f1 + f2 + stem_f1) / 3\n    All of the case remove the stop words.\n    :param gold:\n    :param pred:\n    :param stemming:\n    :return:\n    \"\"\"", "\n", "gold_1", ",", "gold_2", ",", "gold_st", "=", "_get_2gram_sets_keep_stop", "(", "gold", ",", "stemming", ")", "# TODO", "\n", "pred_1", ",", "pred_2", ",", "pred_st", "=", "_get_2gram_sets_keep_stop", "(", "pred", ",", "stemming", ")", "# TODO", "\n", "rouge_recall_1", "=", "0", "\n", "if", "len", "(", "gold_1", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_1", "=", "float", "(", "len", "(", "gold_1", ".", "intersection", "(", "pred_1", ")", ")", ")", "/", "float", "(", "len", "(", "gold_1", ")", ")", "\n", "\n", "", "rouge_pre_1", "=", "0", "\n", "if", "len", "(", "pred_1", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_1", "=", "float", "(", "len", "(", "gold_1", ".", "intersection", "(", "pred_1", ")", ")", ")", "/", "float", "(", "len", "(", "pred_1", ")", ")", "\n", "\n", "", "rouge_recall_2", "=", "0", "\n", "if", "len", "(", "gold_2", ")", "!=", "0", ":", "\n", "        ", "rouge_recall_2", "=", "float", "(", "len", "(", "gold_2", ".", "intersection", "(", "pred_2", ")", ")", ")", "/", "float", "(", "len", "(", "gold_2", ")", ")", "\n", "\n", "", "rouge_pre_2", "=", "0", "\n", "if", "len", "(", "pred_2", ")", "!=", "0", ":", "\n", "        ", "rouge_pre_2", "=", "float", "(", "len", "(", "gold_2", ".", "intersection", "(", "pred_2", ")", ")", ")", "/", "float", "(", "len", "(", "pred_2", ")", ")", "\n", "\n", "", "f1", "=", "0", "if", "(", "rouge_recall_1", "+", "rouge_pre_1", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_1", "*", "rouge_pre_1", ")", "/", "(", "\n", "rouge_recall_1", "+", "rouge_pre_1", ")", "\n", "f2", "=", "0", "if", "(", "rouge_recall_2", "+", "rouge_pre_2", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_2", "*", "rouge_pre_2", ")", "/", "(", "\n", "rouge_recall_2", "+", "rouge_pre_2", ")", "\n", "if", "stemming", ":", "\n", "\n", "        ", "rouge_recall_st", "=", "0", "\n", "if", "len", "(", "gold_st", ")", "!=", "0", ":", "\n", "            ", "rouge_recall_st", "=", "float", "(", "len", "(", "gold_st", ".", "intersection", "(", "pred_st", ")", ")", ")", "/", "float", "(", "len", "(", "gold_st", ")", ")", "\n", "\n", "", "rouge_pre_st", "=", "0", "\n", "if", "len", "(", "pred_st", ")", "!=", "0", ":", "\n", "            ", "rouge_pre_st", "=", "float", "(", "len", "(", "gold_st", ".", "intersection", "(", "pred_st", ")", ")", ")", "/", "float", "(", "len", "(", "pred_st", ")", ")", "\n", "", "f_st", "=", "0", "if", "(", "rouge_recall_st", "+", "rouge_pre_st", "==", "0", ")", "else", "2", "*", "(", "rouge_recall_st", "*", "rouge_pre_st", ")", "/", "(", "\n", "rouge_recall_st", "+", "rouge_pre_st", ")", "\n", "\n", "average_f_score", "=", "f1", "*", "0.25", "+", "f2", "*", "0.5", "+", "0.25", "*", "f_st", "\n", "", "else", ":", "\n", "        ", "average_f_score", "=", "(", "f1", "+", "f2", ")", "/", "2", "\n", "# average_f_score = (f1 )     # TODO", "\n", "", "return", "average_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader.__init__": [[147, 150], ["allennlp.data.dataset_readers.DatasetReader.__init__", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", "=", "False", ")", "\n", "self", ".", "token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader.text_to_instance": [[151, 160], ["allennlp.data.fields.TextField", "allennlp.data.Instance", "allennlp.data.fields.SequenceLabelField"], "methods", ["None"], ["", "def", "text_to_instance", "(", "self", ",", "tokens", ":", "List", "[", "Token", "]", ",", "tags", ":", "List", "[", "str", "]", "=", "None", ")", "->", "Instance", ":", "\n", "        ", "sentence_field", "=", "TextField", "(", "tokens", ",", "self", ".", "token_indexers", ")", "\n", "fields", "=", "{", "\"tokens\"", ":", "sentence_field", "}", "\n", "\n", "if", "tags", ":", "\n", "            ", "label_field", "=", "SequenceLabelField", "(", "labels", "=", "tags", ",", "sequence_field", "=", "sentence_field", ")", "\n", "fields", "[", "\"labels\"", "]", "=", "label_field", "\n", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader._read": [[161, 167], ["open", "allennlp.common.file_utils.cached_path", "line.strip().split", "zip", "BLSTMSimpleTagger.PosDatasetReader.text_to_instance", "line.strip", "pair.split", "allennlp.data.tokenizers.Token"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader.text_to_instance"], ["", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", "->", "Iterator", "[", "Instance", "]", ":", "\n", "        ", "with", "open", "(", "cached_path", "(", "file_path", ")", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "pairs", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "sentence", ",", "tags", "=", "zip", "(", "*", "(", "pair", ".", "split", "(", "\"#@#@#\"", ")", "for", "pair", "in", "pairs", ")", ")", "\n", "yield", "self", ".", "text_to_instance", "(", "[", "Token", "(", "word", ")", "for", "word", "in", "sentence", "]", ",", "tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.__init__": [[176, 197], ["allennlp.models.Model.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "print", "print", "print", "print", "print", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.F1Measure", "allennlp.training.metrics.F1Measure", "torch.nn.Dropout", "torch.nn.Dropout", "vocab.get_token_from_index", "vocab.get_token_from_index", "vocab.get_vocab_size", "vocab.get_token_from_index", "vocab.get_token_from_index", "sec_encoder.get_output_dim", "vocab.get_vocab_size"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.enc.transformer.TransformerEncoder.get_output_dim"], ["    ", "def", "__init__", "(", "self", ",", "\n", "word_embeddings", ":", "TextFieldEmbedder", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "sec_encoder", ":", "Seq2SeqEncoder", ",", "\n", "vocab", ":", "Vocabulary", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "word_embeddings", "=", "word_embeddings", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "sec_encoder", "=", "sec_encoder", "\n", "self", ".", "hidden2tag", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", "=", "sec_encoder", ".", "get_output_dim", "(", ")", ",", "\n", "out_features", "=", "vocab", ".", "get_vocab_size", "(", "'labels'", ")", ")", "\n", "print", "(", "vocab", ".", "get_token_from_index", "(", "2", ")", ")", "\n", "print", "(", "vocab", ".", "get_token_from_index", "(", "14", ")", ")", "\n", "print", "(", "vocab", ".", "get_vocab_size", "(", "'labels'", ")", ")", "\n", "print", "(", "vocab", ".", "get_token_from_index", "(", "0", ",", "'labels'", ")", ")", "\n", "print", "(", "vocab", ".", "get_token_from_index", "(", "1", ",", "'labels'", ")", ")", "\n", "\n", "self", ".", "accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "f1_ret", "=", "F1Measure", "(", "1", ")", "\n", "self", ".", "f1_del", "=", "F1Measure", "(", "0", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.forward": [[198, 221], ["allennlp.nn.util.get_text_field_mask", "BLSTMSimpleTagger.LstmTagger.word_embeddings", "BLSTMSimpleTagger.LstmTagger.encoder", "BLSTMSimpleTagger.LstmTagger.drop", "BLSTMSimpleTagger.LstmTagger.sec_encoder", "BLSTMSimpleTagger.LstmTagger.drop", "BLSTMSimpleTagger.LstmTagger.hidden2tag", "tokens[].tolist", "lexico_token.append", "BLSTMSimpleTagger.LstmTagger.accuracy", "BLSTMSimpleTagger.LstmTagger.f1_ret", "allennlp.nn.util.sequence_cross_entropy_with_logits", "BLSTMSimpleTagger.LstmTagger.vocab.get_token_from_index"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "labels", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "embeddings", "=", "self", ".", "word_embeddings", "(", "tokens", ")", "\n", "encoder_out", "=", "self", ".", "encoder", "(", "embeddings", ",", "mask", ")", "\n", "encoder_out", "=", "self", ".", "drop", "(", "encoder_out", ")", "\n", "encoder_out", "=", "self", ".", "sec_encoder", "(", "encoder_out", ",", "mask", ")", "\n", "encoder_out", "=", "self", ".", "drop", "(", "encoder_out", ")", "\n", "tag_logits", "=", "self", ".", "hidden2tag", "(", "encoder_out", ")", "\n", "\n", "token_list", "=", "tokens", "[", "'tokens'", "]", ".", "tolist", "(", ")", "\n", "lexico_token", "=", "[", "]", "\n", "for", "sent", "in", "token_list", ":", "\n", "            ", "lexico_token", ".", "append", "(", "[", "self", ".", "vocab", ".", "get_token_from_index", "(", "x", ")", "for", "x", "in", "sent", "if", "x", "!=", "0", "]", ")", "\n", "", "output", "=", "{", "\"tag_logits\"", ":", "tag_logits", ",", "\n", "\"tokens\"", ":", "lexico_token", "}", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "accuracy", "(", "tag_logits", ",", "labels", ",", "mask", ")", "\n", "self", ".", "f1_ret", "(", "tag_logits", ",", "labels", ",", "mask", ")", "\n", "output", "[", "\"loss\"", "]", "=", "sequence_cross_entropy_with_logits", "(", "tag_logits", ",", "labels", ",", "mask", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.LstmTagger.get_metrics": [[222, 228], ["BLSTMSimpleTagger.LstmTagger.f1_ret.get_metric", "BLSTMSimpleTagger.LstmTagger.accuracy.get_metric"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.evaluation.rouge_with_pythonrouge.RougeStrEvaluation.get_metric"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "precision", ",", "recall", ",", "fscore", "=", "self", ".", "f1_ret", ".", "get_metric", "(", "reset", ")", "\n", "return", "{", "\"accuracy\"", ":", "self", ".", "accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "\"f1\"", ":", "fscore", ",", "\n", "\"prec\"", ":", "precision", ",", "\n", "\"recall\"", ":", "recall", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.unfold_sentence": [[54, 59], ["pair_list.append"], "function", ["None"], ["def", "unfold_sentence", "(", "node", ")", ":", "\n", "    ", "pair_list", "=", "[", "]", "\n", "for", "n", "in", "node", ":", "\n", "        ", "pair_list", ".", "append", "(", "(", "n", "[", "'parent_id'", "]", ",", "n", "[", "'child_id'", "]", ")", ")", "\n", "", "return", "pair_list", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.load_data": [[64, 140], ["range", "print", "print", "open", "fd.read().splitlines", "json.loads", "BLSTMSimpleTagger.unfold_sentence", "BLSTMSimpleTagger.unfold_sentence", "list", "node_lists.sort", "zip", "dataset.append", "open", "fd.write", "open", "fd.write", "enumerate", "len", "len", "this_example.append", "fd.read", "enumerate", "set", "set", "itemgetter", "range", "range"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.unfold_sentence", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.unfold_sentence"], ["def", "load_data", "(", ")", ":", "\n", "# transfer the data to tsv format", "\n", "    ", "dir", "=", "'/backup3/jcxu/data/compression-data.json'", "\n", "train_file", "=", "'/backup3/jcxu/data/compression-train.tsv'", "\n", "test_file", "=", "'/backup3/jcxu/data/compression-test.tsv'", "\n", "with", "open", "(", "dir", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "line_num", "=", "[", "idx", "for", "idx", ",", "x", "in", "enumerate", "(", "lines", ")", "if", "x", "==", "\"\"", "]", "\n", "line_num", "=", "[", "0", "]", "+", "line_num", "+", "[", "-", "1", "]", "\n", "dataset", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "line_num", ")", "-", "1", ")", ":", "\n", "        ", "start_line", "=", "line_num", "[", "idx", "]", "\n", "if", "line_num", "[", "idx", "+", "1", "]", "==", "-", "1", ":", "\n", "            ", "end_line", "=", "-", "1", "\n", "tmp_lines", "=", "lines", "[", "start_line", ":", "]", "\n", "", "else", ":", "\n", "            ", "end_line", "=", "line_num", "[", "idx", "+", "1", "]", "\n", "tmp_lines", "=", "lines", "[", "start_line", ":", "end_line", "]", "\n", "", "str_lines", "=", "r' '", ".", "join", "(", "tmp_lines", ")", "\n", "data", "=", "json", ".", "loads", "(", "str_lines", ")", "\n", "\n", "compress_edges", "=", "unfold_sentence", "(", "data", "[", "'compression'", "]", "[", "'edge'", "]", ")", "\n", "original_edges", "=", "unfold_sentence", "(", "data", "[", "'graph'", "]", "[", "'edge'", "]", ")", "\n", "node_lists", "=", "[", "(", "n", "[", "'word'", "]", "[", "n", "[", "'head_word_index'", "]", "]", "[", "'id'", "]", ",", "\n", "n", "[", "'word'", "]", ")", "for", "idx", ",", "n", "in", "\n", "enumerate", "(", "data", "[", "'graph'", "]", "[", "'node'", "]", ")", "]", "\n", "\n", "delta_edges", "=", "list", "(", "set", "(", "original_edges", ")", "-", "set", "(", "compress_edges", ")", ")", "\n", "compressed_nodes", "=", "[", "c", "[", "1", "]", "for", "c", "in", "delta_edges", "]", "# all of the compressed child_ids", "\n", "# print(compressed)", "\n", "\n", "from", "operator", "import", "itemgetter", "\n", "node_lists", ".", "sort", "(", "key", "=", "itemgetter", "(", "0", ")", ")", "\n", "max_idx", "=", "node_lists", "[", "-", "1", "]", "[", "1", "]", "[", "-", "1", "]", "[", "'id'", "]", "+", "20", "\n", "# print(node_lists)", "\n", "\n", "tags", "=", "[", "\"\"", "for", "_", "in", "range", "(", "max_idx", ")", "]", "\n", "sents", "=", "[", "\"\"", "for", "_", "in", "range", "(", "max_idx", ")", "]", "\n", "for", "node", "in", "node_lists", ":", "\n", "            ", "idx", "=", "node", "[", "0", "]", "\n", "if", "idx", "==", "-", "1", ":", "\n", "                ", "continue", "\n", "", "words", "=", "node", "[", "1", "]", "\n", "for", "w_dict", "in", "words", ":", "\n", "                ", "sents", "[", "w_dict", "[", "'id'", "]", "]", "=", "w_dict", "[", "'form'", "]", "\n", "# words = [w['form'] for w in words]", "\n", "", "l", "=", "len", "(", "words", ")", "\n", "if", "idx", "in", "compressed_nodes", ":", "\n", "                ", "for", "w_dict", "in", "words", ":", "\n", "                    ", "tags", "[", "w_dict", "[", "'id'", "]", "]", "=", "'B'", "\n", "", "tags", "[", "words", "[", "0", "]", "[", "'id'", "]", "]", "=", "'B'", "\n", "", "else", ":", "\n", "                ", "for", "w_dict", "in", "words", ":", "\n", "                    ", "tags", "[", "w_dict", "[", "'id'", "]", "]", "=", "'O'", "\n", "\n", "", "", "", "this_example", "=", "[", "]", "\n", "for", "t", ",", "s", "in", "zip", "(", "tags", ",", "sents", ")", ":", "\n", "            ", "if", "t", "==", "\"\"", ":", "\n", "                ", "continue", "\n", "", "this_example", ".", "append", "(", "\"{}#@#@#{}\"", ".", "format", "(", "s", ",", "t", ")", ")", "\n", "\n", "#     print(t,s)", "\n", "", "ex", "=", "\"\\t\"", ".", "join", "(", "this_example", ")", "\n", "dataset", ".", "append", "(", "ex", ")", "\n", "\n", "# random.shuffle(dataset)", "\n", "", "test", "=", "dataset", "[", ":", "1000", "]", "\n", "train", "=", "dataset", "[", "1000", ":", "9000", "]", "\n", "# test = dataset[8000:]", "\n", "print", "(", "test", "[", "100", "]", ")", "\n", "print", "(", "test", "[", "101", "]", ")", "\n", "with", "open", "(", "train_file", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "train", ")", ")", "\n", "\n", "", "with", "open", "(", "test_file", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "test", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.pred": [[241, 271], ["allennlp.common.checks.check_for_gpu", "allennlp.models.archival.load_archive", "allennlp.predictors.predictor.Predictor.from_archive", "allennlp.commands.predict._PredictManager", "allennlp.commands.predict._PredictManager.run", "open", "json.dump", "fd.write", "json.dump", "fd.write", "json.dump"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.nn_modules.compression_decoder.CompExecutor.run"], ["def", "pred", "(", "cuda_device", "=", "0", ",", "\n", "archive_file", "=", "\"/backup3/jcxu/exComp/tmp_expsc74o5pf7/model.tar.gz\"", ",", "\n", "weights_file", "=", "\"/backup3/jcxu/exComp/tmp_expsc74o5pf7/best.th\"", ",", "\n", "predictor", "=", "'lstm-tagger'", ",", "\n", "input_file", "=", "\"/backup3/jcxu/exComp/example.txt\"", "\n", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "json", ".", "dump", "(", "\n", "{", "\"sentence\"", ":", "\"This is a useful sentence.\"", "}", ",", "fd", ")", "\n", "fd", ".", "write", "(", "\"\\n\"", ")", "\n", "json", ".", "dump", "(", "\n", "{", "\"sentence\"", ":", "\"This is a gree, blue and useful sentence.\"", "}", ",", "fd", ")", "\n", "fd", ".", "write", "(", "\"\\n\"", ")", "\n", "json", ".", "dump", "(", "\n", "{", "\"sentence\"", ":", "\"This is a useless sentence.\"", "}", ",", "fd", ")", "\n", "", "check_for_gpu", "(", "cuda_device", ")", "\n", "archive", "=", "load_archive", "(", "archive_file", ",", "\n", "weights_file", "=", "weights_file", ",", "\n", "cuda_device", "=", "cuda_device", ",", "\n", "overrides", "=", "\"\"", ")", "\n", "# predictor = SentenceTaggerPredictor(archive, dataset_reader=PosDatasetReader())", "\n", "predictor", "=", "Predictor", ".", "from_archive", "(", "archive", ",", "'sentence-tagger'", ")", "\n", "\n", "manager", "=", "_PredictManager", "(", "predictor", ",", "\n", "input_file", ",", "\n", "None", ",", "\n", "1", ",", "\n", "not", "False", ",", "\n", "False", ")", "\n", "manager", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.decode_human.read_a_problem": [[5, 16], ["decode_human.decode_ans", "collections.Counter"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.decode_human.decode_ans"], ["def", "read_a_problem", "(", "c", ",", "ans_index", ",", "field", ",", "p_name", "=", "'p1'", ")", ":", "\n", "    ", "ans", "=", "decode_ans", "(", "c", "[", "ans_index", "]", ",", "p_name", ")", "\n", "# l1, l2, l3 = c[f1_index[1]], c[f1_index[3]], c[f1_index[5]]", "\n", "labels", "=", "[", "c", "[", "field", "[", "1", "]", "]", ",", "c", "[", "field", "[", "3", "]", "]", ",", "c", "[", "field", "[", "5", "]", "]", "]", "\n", "d", "=", "Counter", "(", "[", "\"{}{}\"", ".", "format", "(", "0", ",", "labels", "[", "ans", "[", "0", "]", "]", ")", ",", "\n", "\"{}{}\"", ".", "format", "(", "1", ",", "labels", "[", "ans", "[", "1", "]", "]", ")", ",", "\n", "\"{}{}\"", ".", "format", "(", "2", ",", "labels", "[", "ans", "[", "2", "]", "]", ")", "]", ")", "\n", "# d.update(\"{}{}\".format(ans[0],labels[0]))", "\n", "# d.update(\"{}{}\".format(ans[1], labels[1]))", "\n", "# d.update(\"{}{}\".format(ans[2], labels[2]))", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.decode_human.decode_ans": [[21, 43], ["any", "any", "json.loads", "ans1.index", "ans2.index", "list", "list.remove", "list.remove", "range"], "function", ["None"], ["def", "decode_ans", "(", "ans_json", ",", "px", "=", "'p1'", ")", ":", "\n", "    ", "ans", "=", "json", ".", "loads", "(", "ans_json", ")", "[", "0", "]", "\n", "ans1", "=", "[", "ans", "[", "key", "]", "[", "'on'", "]", "for", "key", "in", "[", "px", "+", "'1a'", ",", "px", "+", "'1b'", ",", "px", "+", "'1c'", "]", "]", "\n", "if", "any", "(", "ans1", ")", ":", "\n", "        ", "x", "=", "ans1", ".", "index", "(", "True", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "-", "1", "\n", "\n", "", "ans2", "=", "[", "ans", "[", "key", "]", "[", "'on'", "]", "for", "key", "in", "[", "px", "+", "'2a'", ",", "px", "+", "'2b'", ",", "px", "+", "'2c'", "]", "]", "\n", "if", "any", "(", "ans2", ")", ":", "\n", "        ", "y", "=", "ans2", ".", "index", "(", "True", ")", "\n", "", "else", ":", "\n", "        ", "y", "=", "-", "1", "\n", "\n", "", "if", "x", "==", "-", "1", "or", "y", "==", "-", "1", "or", "x", "==", "y", ":", "\n", "        ", "return", "[", "0", ",", "0", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "l", "=", "list", "(", "range", "(", "3", ")", ")", "\n", "l", ".", "remove", "(", "x", ")", "\n", "l", ".", "remove", "(", "y", ")", "\n", "z", "=", "l", "[", "0", "]", "\n", "return", "[", "x", ",", "y", ",", "z", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.find_original_sents": [[58, 95], ["set", "enumerate", "x.lower", "set", "enumerate", "x.lower", "len", "outputs.append", "set", "len", "len", "len", "x.lower", "len", "outputs.append", "len", "set.intersection", "len", "len", "len", "set.intersection"], "function", ["None"], ["def", "find_original_sents", "(", "doc_list", ",", "pred_list", ")", ":", "\n", "    ", "rt_strings", "=", "[", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "pred", "in", "pred_list", ":", "\n", "\n", "        ", "pred", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "pred", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "# if pred[-1].endswith(\".\") and len(pred[-1])>1:", "\n", "\n", "pred_set", "=", "set", "(", "pred", ")", "\n", "success", "=", "False", "\n", "for", "idx", ",", "doc_sent", "in", "enumerate", "(", "doc_list", ")", ":", "\n", "            ", "doc_sent_set", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "doc_sent", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "doc_sent_set", "=", "set", "(", "doc_sent_set", ")", "\n", "if", "len", "(", "pred_set", ")", "==", "0", ":", "\n", "                ", "ratio", "=", "0", "\n", "", "else", ":", "\n", "                ", "ratio", "=", "len", "(", "pred_set", ".", "intersection", "(", "doc_sent_set", ")", ")", "/", "len", "(", "pred_set", ")", "\n", "", "if", "ratio", ">", "0.6", ":", "\n", "                ", "outputs", ".", "append", "(", "idx", ")", "\n", "success", "=", "True", "\n", "break", "\n", "", "", "ratio_thres", "=", "0.5", "\n", "while", "not", "success", ":", "\n", "            ", "for", "idx", ",", "doc_sent", "in", "enumerate", "(", "doc_list", ")", ":", "\n", "                ", "doc_sent_set", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "doc_sent", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "doc_sent_set", "=", "set", "(", "doc_sent_set", ")", "\n", "if", "len", "(", "pred_set", ")", "==", "0", ":", "\n", "                    ", "ratio", "=", "0", "\n", "", "else", ":", "\n", "                    ", "ratio", "=", "len", "(", "pred_set", ".", "intersection", "(", "doc_sent_set", ")", ")", "/", "len", "(", "pred_set", ")", "\n", "", "if", "ratio", ">", "ratio_thres", ":", "\n", "                    ", "outputs", ".", "append", "(", "idx", ")", "\n", "success", "=", "True", "\n", "break", "\n", "", "", "ratio_thres", "-=", ".1", "\n", "", "", "rt_strings", "=", "(", "[", "doc_list", "[", "idx", "]", "for", "idx", "in", "outputs", "]", ")", "\n", "return", "outputs", ",", "rt_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.write_list_of_strings_to_a_file": [[97, 107], ["isinstance", "print", "isinstance", "open", "fd.write"], "function", ["None"], ["", "def", "write_list_of_strings_to_a_file", "(", "list_of_strs", ",", "file_name", ")", ":", "\n", "    ", "if", "isinstance", "(", "list_of_strs", "[", "0", "]", ",", "str", ")", ":", "\n", "        ", "pass", "\n", "", "elif", "isinstance", "(", "list_of_strs", "[", "0", "]", ",", "list", ")", ":", "\n", "        ", "list_of_strs", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "list_of_strs", "]", "\n", "", "else", ":", "\n", "        ", "raise", "TypeError", "\n", "", "with", "open", "(", "file_name", ",", "'w'", ")", "as", "fd", ":", "\n", "        ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "list_of_strs", ")", ")", "\n", "", "print", "(", "'Finish writing to {}'", ".", "format", "(", "file_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.match_original_sents": [[109, 184], ["print", "print", "zip", "enumerate", "open", "fd.read().splitlines", "json.loads", "raw_dataset.append", "open", "pickle.load", "len", "len", "flatten", "our_data.append", "print", "flatten", "set", "print", "print", "compare_post_compression.find_original_sents", "compare_post_compression.write_list_of_strings_to_a_file", "compare_post_compression.write_list_of_strings_to_a_file", "compare_post_compression.write_list_of_strings_to_a_file", "compare_post_compression.write_list_of_strings_to_a_file", "pickle.load.split", "pickle.load.lower", "enumerate", "pickle.load.split", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fd.read", "set", "our_data.pop", "len", "len", "pickle.load.lower", "set.intersection", "set.union"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.find_original_sents", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.write_list_of_strings_to_a_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.write_list_of_strings_to_a_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.write_list_of_strings_to_a_file", "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.write_list_of_strings_to_a_file"], ["", "def", "match_original_sents", "(", "dataset", ",", "dataset_name", ",", "my_output", ",", "root", ",", "dir_sel_sents", ",", "dir_our_compression", ",", "dir_reference", ",", "\n", "dir_lead3", ")", ":", "\n", "    ", "with", "open", "(", "dataset", ",", "'r'", ")", "as", "fd", ":", "\n", "        ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "raw_dataset", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "        ", "d", "=", "json", ".", "loads", "(", "l", ")", "\n", "out", "=", "{", "\n", "'name'", ":", "d", "[", "'name'", "]", ",", "\n", "'doc_list'", ":", "d", "[", "'doc_list'", "]", ",", "\n", "'abs_list'", ":", "d", "[", "'abs_list'", "]", "\n", "}", "\n", "raw_dataset", ".", "append", "(", "out", ")", "\n", "\n", "", "with", "open", "(", "my_output", ",", "'rb'", ")", "as", "fd", ":", "\n", "        ", "x", "=", "pickle", ".", "load", "(", "fd", ")", "\n", "", "pred", ",", "ref", "=", "x", "[", "'pred'", "]", ",", "x", "[", "'ref'", "]", "\n", "\n", "print", "(", "len", "(", "ref", ")", ")", "\n", "print", "(", "len", "(", "raw_dataset", ")", ")", "\n", "\n", "# try to match", "\n", "our_data", "=", "[", "]", "\n", "for", "p", ",", "r", "in", "zip", "(", "pred", ",", "ref", ")", ":", "\n", "        ", "r_tokens", "=", "[", "x", ".", "split", "(", "\" \"", ")", "for", "x", "in", "r", "[", "0", "]", "]", "\n", "toks", "=", "flatten", "(", "r_tokens", ")", "\n", "our_data", ".", "append", "(", "[", "toks", ",", "p", "]", ")", "\n", "\n", "", "for", "idx", ",", "data", "in", "enumerate", "(", "raw_dataset", ")", ":", "\n", "        ", "print", "(", "data", "[", "'name'", "]", ")", "\n", "name", "=", "data", "[", "'name'", "]", "+", "'.txt'", "\n", "flatten_abs", "=", "flatten", "(", "data", "[", "'abs_list'", "]", ")", "\n", "flatten_abs", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "flatten_abs", "]", "\n", "flatten_abs", "=", "set", "(", "flatten_abs", ")", "\n", "predction", "=", "None", "\n", "\n", "for", "rate_thres", "in", "[", "0.7", ",", "0.5", ",", "0.3", "]", ":", "\n", "            ", "_pop_index", "=", "-", "1", "\n", "for", "jdx", ",", "candidate", "in", "enumerate", "(", "our_data", ")", ":", "\n", "                ", "candidate_abs", "=", "set", "(", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "candidate", "[", "0", "]", "]", ")", "\n", "ratio", "=", "len", "(", "flatten_abs", ".", "intersection", "(", "candidate_abs", ")", ")", "/", "len", "(", "flatten_abs", ".", "union", "(", "candidate_abs", ")", ")", "\n", "if", "ratio", ">", "rate_thres", ":", "\n", "                    ", "predction", "=", "candidate", "[", "1", "]", "\n", "_pop_index", "=", "jdx", "\n", "break", "\n", "# elif ratio > 0.5:", "\n", "#     print(candidate_abs)", "\n", "#     print(flatten_abs)", "\n", "", "", "if", "predction", "is", "not", "None", ":", "\n", "                ", "assert", "_pop_index", "!=", "-", "1", "\n", "our_data", ".", "pop", "(", "_pop_index", ")", "\n", "break", "\n", "", "", "data", "[", "'pred'", "]", "=", "predction", "\n", "raw_dataset", "[", "idx", "]", "=", "data", "\n", "# print(data['abs_list'])", "\n", "assert", "predction", "is", "not", "None", "\n", "#", "\n", "# exit()", "\n", "", "for", "data", "in", "raw_dataset", ":", "\n", "# print(r[0])", "\n", "        ", "print", "(", "data", "[", "'abs_list'", "]", ")", "\n", "\n", "print", "(", "data", "[", "'name'", "]", ")", "\n", "name", "=", "data", "[", "'name'", "]", "+", "'.txt'", "\n", "\n", "ref", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "data", "[", "'abs_list'", "]", "]", "\n", "p", "=", "data", "[", "'pred'", "]", "\n", "pred_tokens", "=", "[", "x", ".", "split", "(", "\" \"", ")", "for", "x", "in", "p", "]", "\n", "index", ",", "extraction_str", "=", "find_original_sents", "(", "data", "[", "'doc_list'", "]", ",", "pred_tokens", ")", "\n", "# lead3", "\n", "lead3_str", "=", "data", "[", "'doc_list'", "]", "[", ":", "3", "]", "\n", "write_list_of_strings_to_a_file", "(", "ref", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dir_reference", ",", "name", ")", ")", "\n", "write_list_of_strings_to_a_file", "(", "extraction_str", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dir_sel_sents", ",", "name", ")", ")", "\n", "write_list_of_strings_to_a_file", "(", "p", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dir_our_compression", ",", "name", ")", ")", "\n", "write_list_of_strings_to_a_file", "(", "lead3_str", ",", "os", ".", "path", ".", "join", "(", "root", ",", "dir_lead3", ",", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.load_offshelf_compression_model": [[190, 203], ["allennlp.models.archival.load_archive", "allennlp.common.util.prepare_environment", "model.eval", "neusum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor", "neusum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader"], "function", ["None"], ["def", "load_offshelf_compression_model", "(", "\n", "cuda_device", "=", "2", ",", "\n", "archive_file", "=", "\"/backup3/jcxu/exComp/tmp_expsc74o5pf7/model.tar.gz\"", ",", "\n", "weights_file", "=", "\"/backup3/jcxu/exComp/tmp_expsc74o5pf7/best.th\"", ",", "\n", "\n", ")", ":", "\n", "    ", "archive", "=", "load_archive", "(", "archive_file", ",", "cuda_device", ",", "\"\"", ",", "weights_file", ")", "\n", "config", "=", "archive", ".", "config", "\n", "prepare_environment", "(", "config", ")", "\n", "model", "=", "archive", ".", "model", "\n", "model", ".", "eval", "(", ")", "\n", "predictor", "=", "MySentenceTaggerPredictor", "(", "model", ",", "dataset_reader", "=", "PosDatasetReader", "(", ")", ")", "\n", "return", "model", ",", "predictor", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.predict_compression": [[205, 226], ["predictor.predict_batch_json", "enumerate", "len", "zip", "len", "comps.append", "rts.append", "rt.append"], "function", ["None"], ["", "def", "predict_compression", "(", "predictor", ",", "inp_batch_json", ",", "margin", "=", "0", ")", ":", "\n", "    ", "output", "=", "predictor", ".", "predict_batch_json", "(", "inp_batch_json", ")", "\n", "rts", "=", "[", "]", "\n", "comps", "=", "[", "]", "\n", "for", "idx", ",", "out", "in", "enumerate", "(", "output", ")", ":", "\n", "        ", "tag_logits", "=", "out", "[", "'tag_logits'", "]", "\n", "# tokens = out['tokens']", "\n", "tokens", "=", "inp_batch_json", "[", "idx", "]", "[", "'sentence'", "]", "\n", "original_len", "=", "len", "(", "tokens", ")", "\n", "rt", "=", "[", "]", "\n", "for", "logit", ",", "tok", "in", "zip", "(", "tag_logits", ",", "tokens", ")", ":", "\n", "            ", "del_score", "=", "logit", "[", "0", "]", "\n", "retain_score", "=", "logit", "[", "1", "]", "\n", "if", "del_score", "<=", "retain_score", "+", "margin", ":", "\n", "                ", "rt", ".", "append", "(", "tok", ".", "text", ")", "\n", "", "", "compressed_len", "=", "len", "(", "rt", ")", "\n", "rt", "=", "\" \"", ".", "join", "(", "rt", ")", "\n", "compression_rate", "=", "compressed_len", "/", "original_len", "\n", "comps", ".", "append", "(", "compression_rate", ")", "\n", "rts", ".", "append", "(", "rt", ")", "\n", "", "return", "rts", ",", "comps", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.compress": [[231, 249], ["print", "allennlp.data.tokenizers.word_splitter.SpacyWordSplitter", "os.path.join", "os.path.join", "os.listdir", "os.listdir", "print", "compare_post_compression.predict_compression", "open", "fd.read().splitlines", "open", "fd.write", "sum", "len", "os.path.join", "os.path.join", "allennlp.data.tokenizers.word_splitter.SpacyWordSplitter.split_words", "os.path.join", "os.path.join", "fd.read"], "function", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.predict_compression"], ["def", "compress", "(", "predictor", ",", "root", ",", "dir_sel_sents", ",", "tgt_dir", ",", "margin", ")", ":", "\n", "    ", "print", "(", "tgt_dir", ")", "\n", "tokenizer", "=", "SpacyWordSplitter", "(", "language", "=", "'en_core_web_sm'", ",", "pos_tags", "=", "True", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "dir_sel_sents", ")", "\n", "files", "=", "os", ".", "listdir", "(", "path", ")", "\n", "meta_comps", "=", "[", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "json_lines", "=", "[", "{", "\"sentence\"", ":", "tokenizer", ".", "split_words", "(", "sent", ")", "}", "for", "sent", "in", "lines", "]", "\n", "output", ",", "comps", "=", "predict_compression", "(", "predictor", ",", "json_lines", ",", "margin", ")", "\n", "# print(comps)", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "tgt_dir", ",", "f", ")", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "fd", ".", "write", "(", "\"\\n\"", ".", "join", "(", "output", ")", ")", "\n", "# print(\"Finish writing {}\".format(f))", "\n", "", "meta_comps", "+=", "comps", "\n", "", "print", "(", "sum", "(", "meta_comps", ")", "/", "len", "(", "meta_comps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.rouge": [[254, 276], ["os.listdir", "os.listdir", "os.listdir", "os.listdir", "zip", "print", "pythonrouge.pythonrouge.Pythonrouge", "pythonrouge.pythonrouge.Pythonrouge.calc_score", "print", "pred_str_bag.append", "ref_str_bag.append", "open", "fd.read().splitlines", "open", "fd.read().splitlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "fd.read", "fd.read"], "function", ["None"], ["def", "rouge", "(", "pred_dir", ",", "tgt_dir", ")", ":", "\n", "    ", "preds", "=", "os", ".", "listdir", "(", "pred_dir", ")", "\n", "tgts", "=", "os", ".", "listdir", "(", "tgt_dir", ")", "\n", "pred_str_bag", ",", "ref_str_bag", "=", "[", "]", ",", "[", "]", "\n", "for", "p", ",", "t", "in", "zip", "(", "preds", ",", "tgts", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "pred_dir", ",", "p", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "prediction", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tgt_dir", ",", "t", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "reference", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "pred_str_bag", ".", "append", "(", "prediction", ")", "\n", "ref_str_bag", ".", "append", "(", "[", "reference", "]", ")", "\n", "", "print", "(", "'Finish reading'", ")", "\n", "rouge", "=", "Pythonrouge", "(", "summary_file_exist", "=", "False", ",", "\n", "summary", "=", "pred_str_bag", ",", "reference", "=", "ref_str_bag", ",", "\n", "n_gram", "=", "2", ",", "ROUGE_SU4", "=", "True", ",", "ROUGE_L", "=", "True", ",", "ROUGE_W", "=", "True", ",", "\n", "ROUGE_W_Weight", "=", "1.2", ",", "\n", "recall_only", "=", "False", ",", "stemming", "=", "True", ",", "stopwords", "=", "False", ",", "\n", "word_level", "=", "True", ",", "length_limit", "=", "False", ",", "length", "=", "50", ",", "\n", "use_cf", "=", "False", ",", "cf", "=", "95", ",", "scoring_formula", "=", "'average'", ",", "\n", "resampling", "=", "True", ",", "samples", "=", "1000", ",", "favor", "=", "True", ",", "p", "=", "0.5", ",", "default_conf", "=", "True", ")", "\n", "score", "=", "rouge", ".", "calc_score", "(", ")", "\n", "print", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.compare_post_compression.grammarly": [[277, 286], ["os.listdir", "os.listdir", "random.shuffle", "exit", "open", "fd.read().splitlines", "print", "os.path.join", "os.path.join", "fd.read"], "function", ["None"], ["", "def", "grammarly", "(", "dir", "=", "'/backup3/jcxu/exComp/xu-durrett-output/lead3'", ")", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "dir", ")", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "files", "=", "files", "[", ":", "200", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "f", ")", ",", "'r'", ")", "as", "fd", ":", "\n", "            ", "lines", "=", "fd", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "print", "(", "\"\\n\"", ".", "join", "(", "lines", ")", ")", "\n", "", "", "exit", "(", ")", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.human_eval.sample_id": [[3, 8], ["os.listdir", "random.shuffle"], "function", ["None"], ["from", "neusum", ".", "service", ".", "basic_service", "import", "meta_str_surgery", ",", "easy_post_processing", "\n", "\n", "\n", "def", "iterator", "(", "bag", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.human_eval.check_avg_len": [[21, 34], ["os.listdir", "random.shuffle", "print", "flatten", "l_info.append", "sum", "len", "open", "fd.read().splitlines", "x.split", "len", "len", "os.path.join", "fd.read"], "function", ["None"], ["", "def", "replace_lrbrrb", "(", "inp_str", ":", "str", ")", ":", "\n", "    ", "inp_str", "=", "inp_str", ".", "replace", "(", "\"-LRB-\"", ",", "'('", ")", "\n", "inp_str", "=", "inp_str", ".", "replace", "(", "\"-RRB-\"", ",", "')'", ")", "\n", "return", "inp_str", "\n", "\n", "\n", "", "import", "csv", "\n", "\n", "\n", "def", "assign_task", "(", "ext_bag", ",", "ext_dp_bag", ",", "model_bag", ",", "see_bag", ")", ":", "\n", "    ", "cells", "=", "[", "]", "\n", "num_of_unit", "=", "4", "\n", "for", "ext", ",", "extdp", ",", "model", ",", "see", "in", "zip", "(", "ext_bag", ",", "ext_dp_bag", ",", "model_bag", ",", "see_bag", ")", ":", "\n", "        ", "_tmp", "=", "[", "None", "for", "_", "in", "range", "(", "2", "*", "num_of_unit", ")", "]", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.human_eval.random_drop_str": [[41, 51], ["inp_str.split", "trimmed_toks.append", "random.random", "trimmed_toks.append"], "function", ["None"], ["_tmp", "[", "int", "(", "2", "*", "m", "+", "1", ")", "]", "=", "nam", "[", "idx", "[", "m", "]", "]", "\n", "# _tmp[2] = lis[idx[1]]", "\n", "# _tmp[3] = nam[idx[1]]", "\n", "# _tmp[4] = lis[idx[2]]", "\n", "# _tmp[5] = nam[idx[2]]", "\n", "", "cells", ".", "append", "(", "_tmp", ")", "\n", "", "return", "cells", "\n", "\n", "\n", "", "from", "nltk", ".", "tokenize", ".", "treebank", "import", "TreebankWordTokenizer", ",", "TreebankWordDetokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__": [[19, 22], ["allennlp.predictors.predictor.Predictor.__init__", "allennlp.data.tokenizers.word_splitter.SpacyWordSplitter"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "self", ".", "_tokenizer", "=", "SpacyWordSplitter", "(", "language", "=", "'en_core_web_sm'", ",", "pos_tags", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor.predict": [[23, 25], ["my_sentence_tagger.MySentenceTaggerPredictor.predict_json"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "sentence", ":", "str", ")", "->", "JsonDict", ":", "\n", "        ", "return", "self", ".", "predict_json", "(", "{", "\"sentence\"", ":", "sentence", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.my_sentence_tagger.MySentenceTaggerPredictor._json_to_instance": [[26, 35], ["my_sentence_tagger.MySentenceTaggerPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.jiacheng-xu_neu-compression-sum.BaselineTagger.BLSTMSimpleTagger.PosDatasetReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Expects JSON that looks like ``{\"sentence\": [\"word\", \"word\", ]}``.\n        Runs the underlying model, and adds the ``\"words\"`` to the output.\n        \"\"\"", "\n", "sentence", "=", "json_dict", "[", "\"sentence\"", "]", "\n", "# tokens = self._tokenizer.split_words(sentence)", "\n", "return", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "sentence", ")", "\n", "", "", ""]]}