{"home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.frame_level_models.FrameLevelLogisticModel.create_model": [[52, 84], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_input.get_shape().as_list", "tensorflow.tile", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a logistic classifier over the average of the\n    frame-level features.\n\n    This class is intended to be an example for implementors of frame level\n    models. If you want to train a model over averaged features it is more\n    efficient to average them beforehand rather than on the fly.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "denominators", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "num_frames", ",", "[", "1", ",", "feature_size", "]", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "avg_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "\n", "axis", "=", "[", "1", "]", ")", "/", "denominators", "\n", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "avg_pooled", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.frame_level_models.DbofModel.create_model": [[108, 196], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "model_utils.FramePooling", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.FramePooling", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomSequence"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "      ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "activation", "=", "utils", ".", "FramePooling", "(", "activation", ",", "FLAGS", ".", "dbof_pooling_method", ")", "\n", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "cluster_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "hidden1_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.frame_level_models.LstmModel.create_model": [[199, 237], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", "[", "-", "1", "]", ".", "h", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.__init__": [[64, 82], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n\n    This class is used to calculate the average precision for a single label.\n\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or\n        None to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"", "\n", "if", "not", "(", "(", "isinstance", "(", "top_n", ",", "int", ")", "and", "top_n", ">=", "0", ")", "or", "top_n", "is", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"top_n must be a positive integer or None.\"", ")", "\n", "\n", "", "self", ".", "_top_n", "=", "top_n", "# average precision at n", "\n", "self", ".", "_total_positives", "=", "0", "# total number of positives have seen", "\n", "self", ".", "_heap", "=", "[", "]", "# max heap of (prediction, actual)", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.heap_size": [[83, 87], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "heap_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the heap size maintained in the class.\"\"\"", "\n", "return", "len", "(", "self", ".", "_heap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.num_accumulated_positives": [[88, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_accumulated_positives", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the number of positive samples that have been accumulated.\"\"\"", "\n", "return", "self", ".", "_total_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.accumulate": [[93, 133], ["range", "len", "len", "ValueError", "numpy.size", "numpy.size", "ValueError", "numpy.where", "heapq.heappush", "isinstance", "len", "heapq.heappop", "heapq.heappush"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives = If the 'predictions' and 'actuals' inputs aren't complete,\n      then it's possible some true positives were missed in them. In that case,\n      you can provide 'num_positives' in order to accurately track recall.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "num_positives", ",", "numbers", ".", "Number", ")", "or", "num_positives", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"'num_positives' was provided but it wan't a nonzero number.\"", ")", "\n", "\n", "", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "num_positives", "\n", "", "else", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "topk", "=", "self", ".", "_top_n", "\n", "heap", "=", "self", ".", "_heap", "\n", "\n", "for", "i", "in", "range", "(", "numpy", ".", "size", "(", "predictions", ")", ")", ":", "\n", "      ", "if", "topk", "is", "None", "or", "len", "(", "heap", ")", "<", "topk", ":", "\n", "        ", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "predictions", "[", "i", "]", ">", "heap", "[", "0", "]", "[", "0", "]", ":", "# heap[0] is the smallest", "\n", "          ", "heapq", ".", "heappop", "(", "heap", ")", "\n", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.clear": [[134, 138], ["None"], "methods", ["None"], ["", "", "", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the accumulated predictions.\"\"\"", "\n", "self", ".", "_heap", "=", "[", "]", "\n", "self", ".", "_total_positives", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n": [[139, 156], ["numpy.array", "average_precision_calculator.AveragePrecisionCalculator.ap_at_n", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "def", "peek_ap_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated average precision at n.\n\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"", "\n", "if", "self", ".", "heap_size", "<=", "0", ":", "\n", "      ", "return", "0", "\n", "", "predlists", "=", "numpy", ".", "array", "(", "list", "(", "zip", "(", "*", "self", ".", "_heap", ")", ")", ")", "\n", "\n", "ap", "=", "self", ".", "ap_at_n", "(", "predlists", "[", "0", "]", ",", "\n", "predlists", "[", "1", "]", ",", "\n", "n", "=", "self", ".", "_top_n", ",", "\n", "total_num_positives", "=", "self", ".", "_total_positives", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.ap": [[157, 178], ["average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "return", "AveragePrecisionCalculator", ".", "ap_at_n", "(", "predictions", ",", "\n", "actuals", ",", "\n", "n", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator.ap_at_n": [[179, 246], ["numpy.array", "numpy.array", "average_precision_calculator.AveragePrecisionCalculator._shuffle", "sorted", "len", "range", "len", "len", "ValueError", "range", "numpy.size", "min", "min", "ValueError", "len", "numpy.where", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator._shuffle"], ["", "@", "staticmethod", "\n", "def", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "20", ",", "total_num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive\n      in the list. If specified, it will be used in calculation.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "n", ",", "int", ")", "or", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"n must be 'None' or a positive integer.\"", "\n", "\" It was '%s'.\"", "%", "n", ")", "\n", "\n", "", "", "ap", "=", "0.0", "\n", "\n", "predictions", "=", "numpy", ".", "array", "(", "predictions", ")", "\n", "actuals", "=", "numpy", ".", "array", "(", "actuals", ")", "\n", "\n", "# add a shuffler to avoid overestimating the ap", "\n", "predictions", ",", "actuals", "=", "AveragePrecisionCalculator", ".", "_shuffle", "(", "predictions", ",", "\n", "actuals", ")", "\n", "sortidx", "=", "sorted", "(", "\n", "range", "(", "len", "(", "predictions", ")", ")", ",", "\n", "key", "=", "lambda", "k", ":", "predictions", "[", "k", "]", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "if", "total_num_positives", "is", "None", ":", "\n", "      ", "numpos", "=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "else", ":", "\n", "      ", "numpos", "=", "total_num_positives", "\n", "\n", "", "if", "numpos", "==", "0", ":", "\n", "      ", "return", "0", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "numpos", "=", "min", "(", "numpos", ",", "n", ")", "\n", "", "delta_recall", "=", "1.0", "/", "numpos", "\n", "poscount", "=", "0.0", "\n", "\n", "# calculate the ap", "\n", "r", "=", "len", "(", "sortidx", ")", "\n", "if", "n", "is", "not", "None", ":", "\n", "      ", "r", "=", "min", "(", "r", ",", "n", ")", "\n", "", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "      ", "if", "actuals", "[", "sortidx", "[", "i", "]", "]", ">", "0", ":", "\n", "        ", "poscount", "+=", "1", "\n", "ap", "+=", "poscount", "/", "(", "i", "+", "1", ")", "*", "delta_recall", "\n", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator._shuffle": [[247, 254], ["random.seed", "random.sample", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_shuffle", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "suffidx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "len", "(", "predictions", ")", ")", "\n", "predictions", "=", "predictions", "[", "suffidx", "]", "\n", "actuals", "=", "actuals", "[", "suffidx", "]", "\n", "return", "predictions", ",", "actuals", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.average_precision_calculator.AveragePrecisionCalculator._zero_one_normalize": [[255, 275], ["numpy.max", "numpy.min", "numpy.max", "numpy.min"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_one_normalize", "(", "predictions", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n\n    Returns:\n      The normalized prediction.\n    \"\"\"", "\n", "denominator", "=", "numpy", ".", "max", "(", "predictions", ")", "-", "numpy", ".", "min", "(", "predictions", ")", "\n", "ret", "=", "(", "predictions", "-", "numpy", ".", "min", "(", "predictions", ")", ")", "/", "numpy", ".", "max", "(", "denominator", ",", "\n", "epsilon", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.models.BaseModel.create_model": [[20, 22], ["NotImplementedError"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "unused_model_input", ",", "**", "unused_params", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.BaseReader.prepare_reader": [[61, 64], ["NotImplementedError"], "methods", ["None"], ["def", "prepare_reader", "(", "self", ",", "unused_filename_queue", ")", ":", "\n", "    ", "\"\"\"Create a thread for generating prediction and label tensors.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MAggregatedFeatureReader.__init__": [[74, 93], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"mean_inc3\"", "]", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MAggregatedFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MAggregatedFeatureReader.prepare_reader": [[94, 108], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read_up_to", "tensorflow.add_to_collection", "readers.YT8MAggregatedFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "filename_queue", ",", "batch_size", "=", "1024", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for pre-aggregated YouTube 8M Examples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n\n    Returns:\n      A tuple of video indexes, features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read_up_to", "(", "filename_queue", ",", "batch_size", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"serialized_examples\"", ",", "serialized_examples", ")", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MAggregatedFeatureReader.prepare_serialized_examples": [[109, 130], ["len", "range", "tensorflow.parse_example", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.concat", "len", "len", "len", "len", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.ones", "tensorflow.shape"], "methods", ["None"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_examples", ")", ":", "\n", "# set the mapping from the fields to data types in the proto", "\n", "    ", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"self.feature_names is empty!\"", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "feature_map", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_map", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "self", ".", "feature_sizes", "[", "feature_index", "]", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "", "features", "=", "tf", ".", "parse_example", "(", "serialized_examples", ",", "features", "=", "feature_map", ")", "\n", "labels", "=", "tf", ".", "sparse_to_indicator", "(", "features", "[", "\"labels\"", "]", ",", "self", ".", "num_classes", ")", "\n", "labels", ".", "set_shape", "(", "[", "None", ",", "self", ".", "num_classes", "]", ")", "\n", "concatenated_features", "=", "tf", ".", "concat", "(", "[", "\n", "features", "[", "feature_name", "]", "for", "feature_name", "in", "self", ".", "feature_names", "]", ",", "1", ")", "\n", "\n", "return", "features", "[", "\"video_id\"", "]", ",", "concatenated_features", ",", "labels", ",", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "serialized_examples", ")", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MFrameFeatureReader.__init__": [[140, 162], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"inc3\"", "]", ",", "\n", "max_frames", "=", "300", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MFrameFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n      max_frames: the maximum number of frames to process.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MFrameFeatureReader.get_video_matrix": [[163, 192], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.Dequantize", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.resize_axis"], ["", "def", "get_video_matrix", "(", "self", ",", "\n", "features", ",", "\n", "feature_size", ",", "\n", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", ":", "\n", "    ", "\"\"\"Decodes features from an input string and quantizes it.\n\n    Args:\n      features: raw feature values\n      feature_size: length of each frame feature vector\n      max_frames: number of frames (rows) in the output feature_matrix\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      feature_matrix: matrix of all frame-features\n      num_frames: number of frames in the sequence\n    \"\"\"", "\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "return", "feature_matrix", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MFrameFeatureReader.prepare_reader": [[193, 212], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.YT8MFrameFeatureReader.prepare_serialized_examples": [[213, 270], ["tensorflow.parse_single_sequence_example", "tensorflow.cast", "len", "range", "tensorflow.minimum", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "len", "len", "len", "len", "readers.YT8MFrameFeatureReader.get_video_matrix", "tensorflow.assert_equal", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenSequenceFeature"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.get_video_matrix"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "\n", "    ", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ",", "\n", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", ")", "\n", "\n", "# read ground truth labels", "\n", "labels", "=", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "\n", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "", "else", ":", "\n", "        ", "tf", ".", "assert_equal", "(", "num_frames", ",", "num_frames_in_this_feature", ")", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "# concatenate different features", "\n", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "\n", "# convert to batch format.", "\n", "# TODO: Do proper batch reads to remove the IO bottleneck.", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"video_id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "return", "batch_video_ids", ",", "batch_video_matrix", ",", "batch_labels", ",", "batch_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.readers.resize_axis": [[21, 57], ["tensorflow.convert_to_tensor", "tensorflow.unstack", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.concat", "tf.convert_to_tensor.get_shape().as_list", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.slice", "tensorflow.fill", "tf.convert_to_tensor.get_shape", "tensorflow.zeros_like", "tensorflow.stack", "tensorflow.cast"], "function", ["None"], ["def", "resize_axis", "(", "tensor", ",", "axis", ",", "new_size", ",", "fill_value", "=", "0", ")", ":", "\n", "  ", "\"\"\"Truncates or pads a tensor to new_size on on a given axis.\n\n  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n  size increases, the padding will be performed at the end, using fill_value.\n\n  Args:\n    tensor: The tensor to be resized.\n    axis: An integer representing the dimension to be sliced.\n    new_size: An integer or 0d tensor representing the new value for\n      tensor.shape[axis].\n    fill_value: Value to use to fill any new entries in the tensor. Will be\n      cast to the type of tensor.\n\n  Returns:\n    The resized tensor.\n  \"\"\"", "\n", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "\n", "pad_shape", "=", "shape", "[", ":", "]", "\n", "pad_shape", "[", "axis", "]", "=", "tf", ".", "maximum", "(", "0", ",", "new_size", "-", "shape", "[", "axis", "]", ")", "\n", "\n", "shape", "[", "axis", "]", "=", "tf", ".", "minimum", "(", "shape", "[", "axis", "]", ",", "new_size", ")", "\n", "shape", "=", "tf", ".", "stack", "(", "shape", ")", "\n", "\n", "resized", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "slice", "(", "tensor", ",", "tf", ".", "zeros_like", "(", "shape", ")", ",", "shape", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "stack", "(", "pad_shape", ")", ",", "tf", ".", "cast", "(", "fill_value", ",", "tensor", ".", "dtype", ")", ")", "\n", "]", ",", "axis", ")", "\n", "\n", "# Update shape.", "\n", "new_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# A copy is being made.", "\n", "new_shape", "[", "axis", "]", "=", "new_size", "\n", "resized", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.export_model.ModelExporter.__init__": [[29, 38], ["tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "export_model.ModelExporter.build_inputs_and_outputs", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.Graph", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_inputs_and_outputs"], ["  ", "def", "__init__", "(", "self", ",", "frame_features", ",", "model", ",", "reader", ")", ":", "\n", "    ", "self", ".", "frame_features", "=", "frame_features", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "self", ".", "inputs", ",", "self", ".", "outputs", "=", "self", ".", "build_inputs_and_outputs", "(", ")", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "sharded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.export_model.ModelExporter.export_model": [[39, 61], ["export_model.ModelExporter.graph.as_default", "tensorflow.Session", "tensorflow.Session", "session.run", "export_model.ModelExporter.saver.restore", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables", "tensorflow.python.saved_model.builder.SavedModelBuilder.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "export_model", "(", "self", ",", "model_dir", ",", "global_step_val", ",", "last_checkpoint", ")", ":", "\n", "    ", "\"\"\"Exports the model so that it can used for batch predictions.\"\"\"", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "      ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "session", ",", "last_checkpoint", ")", "\n", "\n", "signature", "=", "signature_def_utils", ".", "build_signature_def", "(", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "outputs", "=", "self", ".", "outputs", ",", "\n", "method_name", "=", "signature_constants", ".", "PREDICT_METHOD_NAME", ")", "\n", "\n", "signature_map", "=", "{", "signature_constants", ".", "DEFAULT_SERVING_SIGNATURE_DEF_KEY", ":", "\n", "signature", "}", "\n", "\n", "model_builder", "=", "saved_model_builder", ".", "SavedModelBuilder", "(", "model_dir", ")", "\n", "model_builder", ".", "add_meta_graph_and_variables", "(", "session", ",", "\n", "tags", "=", "[", "tag_constants", ".", "SERVING", "]", ",", "\n", "signature_def_map", "=", "signature_map", ",", "\n", "clear_devices", "=", "True", ")", "\n", "model_builder", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.export_model.ModelExporter.build_inputs_and_outputs": [[62, 86], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.placeholder", "tensorflow.placeholder", "export_model.ModelExporter.build_prediction_graph", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "export_model.ModelExporter.build_prediction_graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph"], ["", "", "", "def", "build_inputs_and_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame_features", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "fn", "=", "lambda", "x", ":", "self", ".", "build_prediction_graph", "(", "x", ")", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "tf", ".", "map_fn", "(", "fn", ",", "serialized_examples", ",", "\n", "dtype", "=", "(", "tf", ".", "string", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "self", ".", "build_prediction_graph", "(", "serialized_examples", ")", ")", "\n", "\n", "", "inputs", "=", "{", "\"example_bytes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "serialized_examples", ")", "}", "\n", "\n", "outputs", "=", "{", "\n", "\"video_id\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "video_id_output", ")", ",", "\n", "\"class_indexes\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_indices_output", ")", ",", "\n", "\"predictions\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_predictions_output", ")", "}", "\n", "\n", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.export_model.ModelExporter.build_prediction_graph": [[87, 110], ["export_model.ModelExporter.reader.prepare_serialized_examples", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "len", "tensorflow.variable_scope", "tensorflow.variable_scope", "export_model.ModelExporter.model.create_model", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "model_input_raw.get_shape", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["", "def", "build_prediction_graph", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "self", ".", "reader", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "      ", "result", "=", "self", ".", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "self", ".", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "\n", "top_predictions", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "predictions", ",", "\n", "_TOP_PREDICTIONS_IN_OUTPUT", ")", "\n", "", "return", "video_id", ",", "top_indices", ",", "top_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.mean_average_precision_calculator.MeanAveragePrecisionCalculator.__init__": [[48, 70], ["range", "ValueError", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators.append", "isinstance", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ")", ":", "\n", "    ", "\"\"\"Construct a calculator to calculate the (macro) average precision.\n\n    Args:\n      num_class: A positive Integer specifying the number of classes.\n      top_n_array: A list of positive integers specifying the top n for each\n      class. The top n in each class will be used to calculate its average\n      precision at n.\n      The size of the array must be num_class.\n\n    Raises:\n      ValueError: An error occurred when num_class is not a positive integer;\n      or the top_n_array is not a list of positive integers.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "num_class", ",", "int", ")", "or", "num_class", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"num_class must be a positive integer.\"", ")", "\n", "\n", "", "self", ".", "_ap_calculators", "=", "[", "]", "# member of AveragePrecisionCalculator", "\n", "self", ".", "_num_class", "=", "num_class", "# total number of classes", "\n", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "      ", "self", ".", "_ap_calculators", ".", "append", "(", "\n", "average_precision_calculator", ".", "AveragePrecisionCalculator", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.mean_average_precision_calculator.MeanAveragePrecisionCalculator.accumulate": [[71, 94], ["range", "len", "calculators[].accumulate"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate"], ["", "", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    Args:\n      predictions: A list of lists storing the prediction scores. The outer\n      dimension corresponds to classes.\n      actuals: A list of lists storing the ground truth labels. The dimensions\n      should correspond to the predictions input. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives: If provided, it is a list of numbers representing the\n      number of true positives for each class. If not provided, the number of\n      true positives will be inferred from the 'actuals' array.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n      does not match.\n    \"\"\"", "\n", "if", "not", "num_positives", ":", "\n", "      ", "num_positives", "=", "[", "None", "for", "i", "in", "predictions", ".", "shape", "[", "1", "]", "]", "\n", "\n", "", "calculators", "=", "self", ".", "_ap_calculators", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "      ", "calculators", "[", "i", "]", ".", "accumulate", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ",", "num_positives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.mean_average_precision_calculator.MeanAveragePrecisionCalculator.clear": [[95, 98], ["calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "for", "calculator", "in", "self", ".", "_ap_calculators", ":", "\n", "      ", "calculator", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.mean_average_precision_calculator.MeanAveragePrecisionCalculator.is_empty": [[99, 102], ["range"], "methods", ["None"], ["", "", "def", "is_empty", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "calculator", ".", "heap_size", "for", "calculator", "in", "self", ".", "_ap_calculators", "]", "==", "\n", "[", "0", "for", "_", "in", "range", "(", "self", ".", "_num_class", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n": [[103, 113], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators[].peek_ap_at_n", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "peek_map_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated mean average precision at n.\n\n    Returns:\n      An array of non-interpolated average precision at n (default 0) for each\n      class.\n    \"\"\"", "\n", "aps", "=", "[", "self", ".", "_ap_calculators", "[", "i", "]", ".", "peek_ap_at_n", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", "]", "\n", "return", "aps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.model_utils.SampleRandomSequence": [[23, 49], ["tensorflow.tile", "tensorflow.maximum", "tensorflow.cast", "tensorflow.minimum", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.cast", "tensorflow.range"], "function", ["None"], ["def", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random sequence of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index_offset", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_samples", ")", ",", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "max_start_frame_index", "=", "tf", ".", "maximum", "(", "num_frames", "-", "num_samples", ",", "0", ")", "\n", "start_frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "max_start_frame_index", "+", "1", ",", "tf", ".", "float32", ")", ")", ",", "tf", ".", "int32", ")", "\n", "frame_index", "=", "tf", ".", "minimum", "(", "start_frame_index", "+", "frame_index_offset", ",", "\n", "tf", ".", "cast", "(", "num_frames", "-", "1", ",", "tf", ".", "int32", ")", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.model_utils.SampleRandomFrames": [[51, 71], ["tensorflow.cast", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.range", "tensorflow.cast"], "function", ["None"], ["", "def", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random set of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "num_samples", "]", ")", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "cast", "(", "num_frames", ",", "tf", ".", "float32", ")", ",", "[", "1", ",", "num_samples", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.model_utils.FramePooling": [[72, 96], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reshape", "ValueError", "frames.shape_as_list"], "function", ["None"], ["", "def", "FramePooling", "(", "frames", ",", "method", ",", "**", "unused_params", ")", ":", "\n", "  ", "\"\"\"Pools over the frames of a video.\n\n  Args:\n    frames: A tensor with shape [batch_size, num_frames, feature_size].\n    method: \"average\", \"max\", \"attention\", or \"none\".\n  Returns:\n    A tensor with shape [batch_size, feature_size] for average, max, or\n    attention pooling. A tensor with shape [batch_size*num_frames, feature_size]\n    for none pooling.\n\n  Raises:\n    ValueError: if method is other than \"average\", \"max\", \"attention\", or\n    \"none\".\n  \"\"\"", "\n", "if", "method", "==", "\"average\"", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"max\"", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"none\"", ":", "\n", "    ", "feature_size", "=", "frames", ".", "shape_as_list", "(", ")", "[", "2", "]", "\n", "return", "tf", ".", "reshape", "(", "frames", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unrecognized pooling method: %s\"", "%", "method", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.find_class_by_name": [[72, 76], ["next", "getattr"], "function", ["None"], ["", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.get_input_evaluation_tensors": [[78, 115], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_evaluation_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the evaluation data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for evaluation.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"eval_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find the evaluation files.\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of evaluation files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "shuffle", "=", "False", ",", "num_epochs", "=", "1", ")", "\n", "eval_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "return", "tf", ".", "train", ".", "batch_join", "(", "\n", "eval_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "3", "*", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.build_graph": [[117, 176], ["tensorflow.Variable", "eval.get_input_evaluation_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.constant", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "len", "tensorflow.variable_scope", "model.create_model", "tensorflow.summary.histogram", "tensorflow.cast", "tensorflow.summary.merge_all", "model_input_raw.get_shape", "model.create_model.keys", "label_loss_fn.calculate_loss"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.get_input_evaluation_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "eval_data_pattern", ",", "\n", "label_loss_fn", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph for evaluation.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    eval_data_pattern: glob path to the evaluation data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    num_readers: How many threads to use for I/O operations.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "video_id_batch", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "get_input_evaluation_tensors", "(", "# pylint: disable=g-line-too-long", "\n", "reader", ",", "\n", "eval_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "# Normalize input features.", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "# CCMoe", "\n", "phase", "=", "tf", ".", "constant", "(", "False", ",", "name", "=", "\"phase\"", ")", "\n", "#", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "    ", "result", "=", "model", ".", "create_model", "(", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "phase", ")", "\n", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_activations\"", ",", "predictions", ")", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "      ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "      ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "labels_batch", ")", "\n", "\n", "", "", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "predictions", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"video_id_batch\"", ",", "video_id_batch", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"summary_op\"", ",", "tf", ".", "summary", ".", "merge_all", "(", ")", ")", "\n", "# CCMoe", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.evaluation_loop": [[179, 282], ["tensorflow.Session", "sess.run", "tensorflow.train.Coordinator", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.logging.info", "evl_metrics.clear", "[].split", "tensorflow.local_variables_initializer", "threads.extend", "tf.train.Coordinator.should_stop", "time.time", "sess.run", "evl_metrics.accumulate", "utils.AddGlobalStepSummary", "tensorflow.logging.info", "tensorflow.logging.info", "evl_metrics.get", "summary_writer.add_summary", "utils.AddEpochSummary", "tensorflow.logging.info", "evl_metrics.clear", "tensorflow.logging.info", "tf.train.Coordinator.request_stop", "qr.create_threads", "time.time", "str", "tf.train.latest_checkpoint.split"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddGlobalStepSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddEpochSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "def", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "\n", "summary_op", ",", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", ":", "\n", "  ", "\"\"\"Run the evaluation loop once.\n\n  Args:\n    video_id_batch: a tensor of video ids mini-batch.\n    prediction_batch: a tensor of predictions mini-batch.\n    label_batch: a tensor of label_batch mini-batch.\n    loss: a tensor of loss for the examples in the mini-batch.\n    summary_op: a tensor which runs the tensorboard summary operations.\n    saver: a tensorflow saver to restore the model.\n    summary_writer: a tensorflow summary_writer\n    evl_metrics: an EvaluationMetrics object.\n    last_global_step_val: the global step used in the previous evaluation.\n\n  Returns:\n    The global_step used in the latest model.\n  \"\"\"", "\n", "\n", "global_step_val", "=", "-", "1", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "if", "FLAGS", ".", "certain_step", "!=", "\"Latest\"", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"/\"", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "certain_step", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "if", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading checkpoint for eval: \"", "+", "latest_checkpoint", ")", "\n", "# Restores from checkpoint", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "# Assuming model_checkpoint_path looks something like:", "\n", "# /my-favorite-path/yt8m_train/model.ckpt-0, extract global_step from it.", "\n", "global_step_val", "=", "latest_checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"No checkpoint file found.\"", ")", "\n", "return", "global_step_val", "\n", "\n", "", "if", "global_step_val", "==", "last_global_step_val", ":", "\n", "      ", "logging", ".", "info", "(", "\"skip this checkpoint global_step_val=%s \"", "\n", "\"(same as the previous one).\"", ",", "global_step_val", ")", "\n", "return", "global_step_val", "\n", "\n", "", "sess", ".", "run", "(", "[", "tf", ".", "local_variables_initializer", "(", ")", "]", ")", "\n", "\n", "# Start the queue runners.", "\n", "fetches", "=", "[", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "summary_op", "]", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "try", ":", "\n", "      ", "threads", "=", "[", "]", "\n", "for", "qr", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "QUEUE_RUNNERS", ")", ":", "\n", "        ", "threads", ".", "extend", "(", "qr", ".", "create_threads", "(", "\n", "sess", ",", "coord", "=", "coord", ",", "daemon", "=", "True", ",", "\n", "start", "=", "True", ")", ")", "\n", "", "logging", ".", "info", "(", "\"enter eval_once loop global_step_val = %s. \"", ",", "\n", "global_step_val", ")", "\n", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "\n", "examples_processed", "=", "0", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "predictions_val", ",", "labels_val", ",", "loss_val", ",", "summary_val", "=", "sess", ".", "run", "(", "\n", "fetches", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "example_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "examples_processed", "+=", "labels_val", ".", "shape", "[", "0", "]", "\n", "\n", "iteration_info_dict", "=", "evl_metrics", ".", "accumulate", "(", "predictions_val", ",", "\n", "labels_val", ",", "loss_val", ")", "\n", "iteration_info_dict", "[", "\"examples_per_second\"", "]", "=", "example_per_second", "\n", "\n", "iterinfo", "=", "utils", ".", "AddGlobalStepSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "iteration_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "\"examples_processed: %d | %s\"", ",", "examples_processed", ",", "\n", "iterinfo", ")", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", "as", "e", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"Done with batched inference. Now calculating global performance \"", "\n", "\"metrics.\"", ")", "\n", "# calculate the metrics for the entire epoch", "\n", "epoch_info_dict", "=", "evl_metrics", ".", "get", "(", ")", "\n", "epoch_info_dict", "[", "\"epoch_id\"", "]", "=", "global_step_val", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_val", ",", "global_step_val", ")", "\n", "epochinfo", "=", "utils", ".", "AddEpochSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "epochinfo", ")", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "\n", "      ", "logging", ".", "info", "(", "\"Unexpected exception: \"", "+", "str", "(", "e", ")", ")", "\n", "coord", ".", "request_stop", "(", "e", ")", "\n", "\n", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ",", "stop_grace_period_secs", "=", "10", ")", "\n", "\n", "return", "global_step_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.evaluate": [[284, 334], ["tensorflow.set_random_seed", "tensorflow.Graph().as_default", "utils.GetListOfFeatureNamesAndSizes", "eval.build_graph", "tensorflow.logging.info", "tensorflow.train.Saver", "tensorflow.summary.FileWriter", "eval_util.EvaluationMetrics", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "eval.find_class_by_name", "eval.find_class_by_name", "IOError", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.global_variables", "eval.evaluation_loop", "tensorflow.Graph", "tensorflow.get_default_graph"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluation_loop"], ["", "", "def", "evaluate", "(", ")", ":", "\n", "  ", "tf", ".", "set_random_seed", "(", "0", ")", "# for reproducibility", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "    ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "\n", "if", "FLAGS", ".", "eval_data_pattern", "is", "\"\"", ":", "\n", "      ", "raise", "IOError", "(", "\"'eval_data_pattern' was not specified. \"", "+", "\n", "\"Nothing to evaluate.\"", ")", "\n", "\n", "", "build_graph", "(", "\n", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "eval_data_pattern", "=", "FLAGS", ".", "eval_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "logging", ".", "info", "(", "\"built evaluation graph\"", ")", "\n", "video_id_batch", "=", "tf", ".", "get_collection", "(", "\"video_id_batch\"", ")", "[", "0", "]", "\n", "prediction_batch", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "label_batch", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "summary_op", "=", "tf", ".", "get_collection", "(", "\"summary_op\"", ")", "[", "0", "]", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "FLAGS", ".", "train_dir", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "evl_metrics", "=", "eval_util", ".", "EvaluationMetrics", "(", "reader", ".", "num_classes", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "last_global_step_val", "=", "-", "1", "\n", "while", "True", ":", "\n", "      ", "last_global_step_val", "=", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "\n", "label_batch", ",", "loss", ",", "summary_op", ",", "\n", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", "\n", "if", "FLAGS", ".", "run_once", ":", "\n", "        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval.main": [[336, 340], ["tensorflow.logging.set_verbosity", "print", "eval.evaluate"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluate"], ["", "", "", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "print", "(", "\"tensorflow version: %s\"", "%", "tf", ".", "__version__", ")", "\n", "evaluate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.inference.format_lines": [[67, 76], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.inference.get_input_data_tensors": [[78, 112], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.inference.inference": [[113, 168], ["tensorflow.Session", "tensorflow.gfile.Open", "inference.get_input_data_tensors", "tensorflow.train.latest_checkpoint", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "inference.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.inference.main": [[170, 194], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "inference.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.LogisticModel.create_model": [[33, 48], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "l2_penalty", "=", "1e-8", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a logistic model.\n\n    Args:\n      model_input: 'batch' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\"\"\"", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.MoeModel.create_model": [[52, 104], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a Mixture of (Logistic) Experts model.\n\n     The model consists of a per-class softmax distribution over a\n     configurable number of logistic classifiers. One of the classifiers in the\n     mixture is not trained, and always predicts 0.\n\n    Args:\n      model_input: 'batch_size' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n      num_mixtures: The number of mixtures (excluding a dummy 'expert' that\n        always predicts the non-existence of an entity).\n      l2_penalty: How much to penalize the squared magnitudes of parameter\n        values.\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\n    \"\"\"", "\n", "num_mixtures", "=", "num_mixtures", "or", "FLAGS", ".", "moe_num_mixtures", "\n", "\n", "gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "(", "num_mixtures", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gates\"", ")", "\n", "expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "num_mixtures", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"experts\"", ")", "\n", "\n", "gating_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "gate_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "+", "1", "]", ")", ")", "# (Batch * #Labels) x (num_mixtures + 1)", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "expert_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "]", ")", ")", "# (Batch * #Labels) x num_mixtures", "\n", "\n", "final_probabilities_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gating_distribution", "[", ":", ",", ":", "num_mixtures", "]", "*", "expert_distribution", ",", "1", ")", "\n", "final_probabilities", "=", "tf", ".", "reshape", "(", "final_probabilities_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "vocab_size", "]", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.CCModel.create_model": [[106, 142], ["tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.contrib.rnn.LSTMCell.zero_state", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.LSTMCell.", "tensorflow.sigmoid", "tensorflow.sigmoid", "prob_chains.append", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "256", "\n", "state_size", "=", "96", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "time_steps", "=", "vocab_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "1", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_response", ")", "\n", "\n", "# paddings = tf.zeros([batch_size, vocab_size - time_steps], dtype=tf.float32)", "\n", "# prob_chains.append(paddings)", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.PartlyCCModel.create_model": [[144, 181], ["tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.contrib.rnn.LSTMCell.zero_state", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.LSTMCell.", "tensorflow.sigmoid", "tensorflow.sigmoid", "prob_chains.append", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "512", "\n", "state_size", "=", "512", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "36", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_part_response", ")", "\n", "\n", "# paddings = tf.zeros([batch_size, vocab_size - time_steps], dtype=tf.float32)", "\n", "# prob_chains.append(paddings)", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.PRCCModel.create_model": [[186, 225], ["tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.contrib.rnn.LSTMCell.zero_state", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.LSTMCell.", "tensorflow.sigmoid", "tensorflow.sigmoid", "prob_chains.append", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "512", "\n", "state_size", "=", "1024", "\n", "proj_size", "=", "512", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ",", "num_proj", "=", "proj_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "part_response", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "part_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# logistic_weights = tf.get_variable(\"logistic_weights\", [state_size, part_size], initializer=tf.random_normal_initializer())", "\n", "# Newly", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "proj_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "#", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "tf", ".", "concat", "(", "[", "reduced_feature", ",", "part_response", "]", ",", "1", ")", ",", "state", ")", "\n", "part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "part_response", ")", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.PRCCConcatModel.create_model": [[230, 285], ["tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.contrib.rnn.LSTMCell.zero_state", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.contrib.rnn.LSTMCell.", "tensorflow.sigmoid", "tensorflow.sigmoid", "prob_chains.append", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "range", "range", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "str", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "str", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduced_feature_size", "=", "1024", "\n", "reduced_distr_size", "=", "1024", "\n", "state_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "*", "4", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "reduced_feature_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduced_feature_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "reduced_feature", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_feature_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "[", "tf", ".", "get_variable", "(", "\"logistic_weights_\"", "+", "str", "(", "i", ")", ",", "[", "state_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "for", "i", "in", "range", "(", "time_steps", ")", "]", "\n", "logistic_biases", "=", "[", "tf", ".", "get_variable", "(", "\"logistic_biases_\"", "+", "str", "(", "i", ")", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "for", "i", "in", "range", "(", "time_steps", ")", "]", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "output", ",", "state", "=", "lstm", "(", "tf", ".", "concat", "(", "[", "reduced_feature", ",", "reduced_distr", "]", ",", "1", ")", ",", "state", ")", "\n", "part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", "[", "step", "]", ")", "+", "logistic_biases", "[", "step", "]", ")", "\n", "prob_chains", ".", "append", "(", "part_response", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "part_response", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.CCMoeModel.create_model": [[290, 373], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.dropout", "tensorflow.dropout", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "prob_chains.append", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.concat", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "str", "str"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduced_feature_size", "=", "512", "\n", "reduced_distr_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "reduced_feature_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduced_feature_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "reduced_feature", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_feature_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "group_input", "=", "slim", ".", "dropout", "(", "tf", ".", "concat", "(", "[", "reduced_distr", ",", "reduced_feature", "]", ",", "1", ")", ",", "\n", "keep_prob", "=", "0.5", ",", "\n", "is_training", "=", "is_training", ")", "\n", "group_expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "num_experts", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"pred_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "group_gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "(", "num_experts", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gate_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "group_expert_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "]", ")", ")", "\n", "gate_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "group_gate_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "+", "1", "]", ")", ")", "\n", "\n", "expert_distr_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gate_distribution", "[", ":", ",", ":", "num_experts", "]", "*", "expert_distribution", ",", "1", ")", "\n", "group_predictions", "=", "tf", ".", "reshape", "(", "expert_distr_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "part_size", "]", ")", "\n", "#", "\n", "\n", "prob_chains", ".", "append", "(", "group_predictions", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "group_predictions", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.CCOrigMoeModel.create_model": [[378, 462], ["tensorflow.zeros", "tensorflow.zeros", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "prob_chains.append", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "str", "str"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "# reduced_feature_size = 512 ", "\n", "# reduced_distr_size = 1024 ", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "# reduced_feature_activations = slim.fully_connected(", "\n", "#     model_input,", "\n", "#     reduced_feature_size,", "\n", "#     activation_fn=None,", "\n", "#     weights_regularizer=slim.l2_regularizer(l2_penalty),", "\n", "#     scope=\"reduce\")", "\n", "# reduced_feature = tf.nn.relu(slim.batch_norm(reduced_feature_activations, is_training=is_training))", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# distr_weights = tf.get_variable(\"distr_weights\", [vocab_size, reduced_distr_size], initializer=tf.random_normal_initializer())", "\n", "# distr_biases = tf.get_variable(\"distr_biases\", [reduced_distr_size], initializer=tf.constant_initializer(0.0))", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "# reduced_distr_activations = tf.matmul(distribution, distr_weights) + distr_biases ", "\n", "# reduced_distr = tf.nn.relu(slim.batch_norm(reduced_distr_activations, is_training=is_training))", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "", "group_input", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "model_input", "]", ",", "1", ")", "\n", "# group_input = slim.dropout(tf.concat([reduced_distr, reduced_feature], 1),", "\n", "#   keep_prob=0.5,", "\n", "#   is_training=is_training)", "\n", "group_expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "num_experts", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"pred_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "group_gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "(", "num_experts", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gate_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "group_expert_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "]", ")", ")", "\n", "gate_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "group_gate_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "+", "1", "]", ")", ")", "\n", "\n", "expert_distr_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gate_distribution", "[", ":", ",", ":", "num_experts", "]", "*", "expert_distribution", ",", "1", ")", "\n", "group_predictions", "=", "tf", ".", "reshape", "(", "expert_distr_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "part_size", "]", ")", "\n", "#", "\n", "\n", "prob_chains", ".", "append", "(", "group_predictions", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "group_predictions", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.video_level_models.CCDistrMoeModel.create_model": [[467, 552], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "xrange", "tensorflow.concat", "tensorflow.concat", "tensorflow.shape", "tensorflow.shape", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "prob_chains.append", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "str", "str"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "# reduced_feature_size = 512 ", "\n", "    ", "reduced_distr_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "# reduced_feature_activations = slim.fully_connected(", "\n", "#     model_input,", "\n", "#     reduced_feature_size,", "\n", "#     activation_fn=None,", "\n", "#     weights_regularizer=slim.l2_regularizer(l2_penalty),", "\n", "#     scope=\"reduce\")", "\n", "# reduced_feature = tf.nn.relu(slim.batch_norm(reduced_feature_activations, is_training=is_training))", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "# group_input = tf.concat([distribution, model_input], 1)", "\n", "group_input", "=", "tf", ".", "concat", "(", "[", "reduced_distr", ",", "model_input", "]", ",", "1", ")", "\n", "# group_input = slim.dropout(tf.concat([reduced_distr, reduced_feature], 1),", "\n", "#   keep_prob=0.5,", "\n", "#   is_training=is_training)", "\n", "group_expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "num_experts", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"pred_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "group_gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "(", "num_experts", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gate_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "group_expert_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "]", ")", ")", "\n", "gate_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "group_gate_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "+", "1", "]", ")", ")", "\n", "\n", "expert_distr_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gate_distribution", "[", ":", ",", ":", "num_experts", "]", "*", "expert_distribution", ",", "1", ")", "\n", "group_predictions", "=", "tf", ".", "reshape", "(", "expert_distr_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "part_size", "]", ")", "\n", "#", "\n", "\n", "prob_chains", ".", "append", "(", "group_predictions", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "group_predictions", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.__init__": [[349, 373], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.run": [[378, 474], ["train.Trainer.start_server_if_distributed", "train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "train.task_as_string", "tensorflow.train.Supervisor.managed_session", "train.task_as_string", "train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.Graph", "tensorflow.Graph", "train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "20", "*", "60", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "64", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.export_model": [[475, 491], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "train.Trainer.model_exporter.export_model", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.start_server_if_distributed": [[492, 508], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "train.task_as_string", "train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.remove_training_directory": [[509, 521], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.get_meta_filename": [[522, 541], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "train.task_as_string", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.recover_model": [[542, 546], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.Trainer.build_model": [[547, 568], ["train.find_class_by_name", "train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.ParameterServer.__init__": [[588, 599], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.ParameterServer.run": [[600, 607], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "start_server.join", "train.task_as_string", "train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.validate_class_name": [[104, 131], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.get_input_data_tensors": [[132, 175], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.find_class_by_name": [[177, 181], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.build_graph": [[182, 343], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "# PRCCConcat", "\n", "phase", "=", "tf", ".", "constant", "(", "True", ")", "\n", "#", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "# PRCCConcat", "\n", "is_training", "=", "phase", ")", "\n", "#)", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "# PRCCConcat", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.get_reader": [[570, 583], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.start_server": [[609, 631], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "train.task_as_string", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.task_as_string": [[632, 634], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.train.main": [[635, 673], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train.task_as_string", "train.get_reader", "export_model.ModelExporter", "train.Trainer.run", "train.find_class_by_name", "train.ParameterServer.run", "ValueError", "train.Trainer", "train.ParameterServer", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.EvaluationMetrics.__init__": [[140, 158], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "top_k", ")", ":", "\n", "    ", "\"\"\"Construct an EvaluationMetrics object to store the evaluation metrics.\n\n    Args:\n      num_class: A positive integer specifying the number of classes.\n      top_k: A positive integer specifying how many predictions are considered per video.\n\n    Raises:\n      ValueError: An error occurred when MeanAveragePrecisionCalculator cannot\n        not be constructed.\n    \"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", "=", "map_calculator", ".", "MeanAveragePrecisionCalculator", "(", "num_class", ")", "\n", "self", ".", "global_ap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "num_examples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.EvaluationMetrics.accumulate": [[159, 192], ["eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "numpy.mean", "eval_util.top_k_by_class", "eval_util.EvaluationMetrics.map_calculator.accumulate", "eval_util.EvaluationMetrics.global_ap_calculator.accumulate", "eval_util.flatten", "eval_util.flatten", "sum"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "labels", ",", "loss", ")", ":", "\n", "    ", "\"\"\"Accumulate the metrics calculated locally for this mini-batch.\n\n    Args:\n      predictions: A numpy matrix containing the outputs of the model.\n        Dimensions are 'batch' x 'num_classes'.\n      labels: A numpy matrix containing the ground truth labels.\n        Dimensions are 'batch' x 'num_classes'.\n      loss: A numpy array containing the loss for each sample.\n\n    Returns:\n      dictionary: A dictionary storing the metrics for the mini-batch.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n        does not match.\n    \"\"\"", "\n", "batch_size", "=", "labels", ".", "shape", "[", "0", "]", "\n", "mean_hit_at_one", "=", "calculate_hit_at_one", "(", "predictions", ",", "labels", ")", "\n", "mean_perr", "=", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "labels", ")", "\n", "mean_loss", "=", "numpy", ".", "mean", "(", "loss", ")", "\n", "\n", "# Take the top 20 predictions.", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "labels", ",", "self", ".", "top_k", ")", "\n", "self", ".", "map_calculator", ".", "accumulate", "(", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", ")", "\n", "self", ".", "global_ap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "\n", "self", ".", "num_examples", "+=", "batch_size", "\n", "self", ".", "sum_hit_at_one", "+=", "mean_hit_at_one", "*", "batch_size", "\n", "self", ".", "sum_perr", "+=", "mean_perr", "*", "batch_size", "\n", "self", ".", "sum_loss", "+=", "mean_loss", "*", "batch_size", "\n", "\n", "return", "{", "\"hit_at_one\"", ":", "mean_hit_at_one", ",", "\"perr\"", ":", "mean_perr", ",", "\"loss\"", ":", "mean_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.EvaluationMetrics.get": [[193, 216], ["eval_util.EvaluationMetrics.map_calculator.peek_map_at_n", "eval_util.EvaluationMetrics.global_ap_calculator.peek_ap_at_n", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "get", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calculate the evaluation metrics for the whole epoch.\n\n    Raises:\n      ValueError: If no examples were accumulated.\n\n    Returns:\n      dictionary: a dictionary storing the evaluation metrics for the epoch. The\n        dictionary has the fields: avg_hit_at_one, avg_perr, avg_loss, and\n        aps (default nan).\n    \"\"\"", "\n", "if", "self", ".", "num_examples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"total_sample must be positive.\"", ")", "\n", "", "avg_hit_at_one", "=", "self", ".", "sum_hit_at_one", "/", "self", ".", "num_examples", "\n", "avg_perr", "=", "self", ".", "sum_perr", "/", "self", ".", "num_examples", "\n", "avg_loss", "=", "self", ".", "sum_loss", "/", "self", ".", "num_examples", "\n", "\n", "aps", "=", "self", ".", "map_calculator", ".", "peek_map_at_n", "(", ")", "\n", "gap", "=", "self", ".", "global_ap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n", "epoch_info_dict", "=", "{", "}", "\n", "return", "{", "\"avg_hit_at_one\"", ":", "avg_hit_at_one", ",", "\"avg_perr\"", ":", "avg_perr", ",", "\n", "\"avg_loss\"", ":", "avg_loss", ",", "\"aps\"", ":", "aps", ",", "\"gap\"", ":", "gap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.EvaluationMetrics.clear": [[217, 225], ["eval_util.EvaluationMetrics.map_calculator.clear", "eval_util.EvaluationMetrics.global_ap_calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the evaluation metrics and reset the EvaluationMetrics object.\"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", ".", "clear", "(", ")", "\n", "self", ".", "global_ap_calculator", ".", "clear", "(", ")", "\n", "self", ".", "num_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.flatten": [[24, 27], ["None"], "function", ["None"], ["def", "flatten", "(", "l", ")", ":", "\n", "  ", "\"\"\" Merges a list of lists into a single list. \"\"\"", "\n", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.calculate_hit_at_one": [[28, 43], ["numpy.argmax", "numpy.average", "numpy.arange"], "function", ["None"], ["", "def", "calculate_hit_at_one", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the hit at one.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average hit at one across the entire batch.\n  \"\"\"", "\n", "top_prediction", "=", "numpy", ".", "argmax", "(", "predictions", ",", "1", ")", "\n", "hits", "=", "actuals", "[", "numpy", ".", "arange", "(", "actuals", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "numpy", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.calculate_precision_at_equal_recall_rate": [[45, 71], ["numpy.arange", "int", "numpy.sum", "numpy.argpartition"], "function", ["None"], ["", "def", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the PERR.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average precision at equal recall rate across the entire batch.\n  \"\"\"", "\n", "aggregated_precision", "=", "0.0", "\n", "num_videos", "=", "actuals", ".", "shape", "[", "0", "]", "\n", "for", "row", "in", "numpy", ".", "arange", "(", "num_videos", ")", ":", "\n", "    ", "num_labels", "=", "int", "(", "numpy", ".", "sum", "(", "actuals", "[", "row", "]", ")", ")", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "row", "]", ",", "\n", "-", "num_labels", ")", "[", "-", "num_labels", ":", "]", "\n", "item_precision", "=", "0.0", "\n", "for", "label_index", "in", "top_indices", ":", "\n", "      ", "if", "predictions", "[", "row", "]", "[", "label_index", "]", ">", "0", ":", "\n", "        ", "item_precision", "+=", "actuals", "[", "row", "]", "[", "label_index", "]", "\n", "", "", "item_precision", "/=", "top_indices", ".", "size", "\n", "aggregated_precision", "+=", "item_precision", "\n", "", "aggregated_precision", "/=", "num_videos", "\n", "return", "aggregated_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.calculate_gap": [[72, 91], ["average_precision_calculator.AveragePrecisionCalculator", "eval_util.top_k_by_class", "ap_calculator.AveragePrecisionCalculator.accumulate", "ap_calculator.AveragePrecisionCalculator.peek_ap_at_n", "eval_util.flatten", "eval_util.flatten", "sum"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "calculate_gap", "(", "predictions", ",", "actuals", ",", "top_k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the global average precision.\n\n  Only the top_k predictions are taken for each of the videos.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n    top_k: How many predictions to use per video.\n\n  Returns:\n    float: The global average precision.\n  \"\"\"", "\n", "gap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "actuals", ",", "top_k", ")", "\n", "gap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "return", "gap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.top_k_by_class": [[93, 128], ["min", "range", "ValueError", "prediction_triplets.extend", "out_predictions[].append", "out_labels[].append", "numpy.sum", "eval_util.top_k_triplets", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_triplets"], ["", "def", "top_k_by_class", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Extracts the top k predictions for each video, sorted by class.\n\n  Args:\n    predictions: A numpy matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    k: the top k non-zero entries to preserve in each prediction.\n\n  Returns:\n    A tuple (predictions,labels, true_positives). 'predictions' and 'labels'\n    are lists of lists of floats. 'true_positives' is a list of scalars. The\n    length of the lists are equal to the number of classes. The entries in the\n    predictions variable are probability predictions, and\n    the corresponding entries in the labels variable are the ground truth for\n    those predictions. The entries in 'true_positives' are the number of true\n    positives for each class in the ground truth.\n\n  Raises:\n    ValueError: An error occurred when the k is not a positive integer.\n  \"\"\"", "\n", "if", "k", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"k must be a positive integer.\"", ")", "\n", "", "k", "=", "min", "(", "k", ",", "predictions", ".", "shape", "[", "1", "]", ")", "\n", "num_classes", "=", "predictions", ".", "shape", "[", "1", "]", "\n", "prediction_triplets", "=", "[", "]", "\n", "for", "video_index", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "prediction_triplets", ".", "extend", "(", "top_k_triplets", "(", "predictions", "[", "video_index", "]", ",", "labels", "[", "video_index", "]", ",", "k", ")", ")", "\n", "", "out_predictions", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "triplet", "in", "prediction_triplets", ":", "\n", "    ", "out_predictions", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "1", "]", ")", "\n", "out_labels", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "2", "]", ")", "\n", "", "out_true_positives", "=", "[", "numpy", ".", "sum", "(", "labels", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "return", "out_predictions", ",", "out_labels", ",", "out_true_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.eval_util.top_k_triplets": [[129, 136], ["len", "min", "numpy.argpartition"], "function", ["None"], ["", "def", "top_k_triplets", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Get the top_k for a 1-d numpy array. Returns a sparse list of tuples in\n  (prediction, class) format\"\"\"", "\n", "m", "=", "len", "(", "predictions", ")", "\n", "k", "=", "min", "(", "k", ",", "m", ")", "\n", "indices", "=", "numpy", ".", "argpartition", "(", "predictions", ",", "-", "k", ")", "[", "-", "k", ":", "]", "\n", "return", "[", "(", "index", ",", "predictions", "[", "index", "]", ",", "labels", "[", "index", "]", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.convert_prediction_from_json_to_csv.get_csv_header": [[46, 48], ["None"], "function", ["None"], ["", "def", "get_csv_header", "(", ")", ":", "\n", "  ", "return", "\"VideoId,LabelConfidencePairs\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.convert_prediction_from_json_to_csv.to_csv_row": [[49, 69], ["isinstance", "len", "len", "ValueError", "video_id.decode", "len", "len", "builtins.range", "len"], "function", ["None"], ["", "def", "to_csv_row", "(", "json_data", ")", ":", "\n", "\n", "  ", "video_id", "=", "json_data", "[", "\"video_id\"", "]", "\n", "\n", "class_indexes", "=", "json_data", "[", "\"class_indexes\"", "]", "\n", "predictions", "=", "json_data", "[", "\"predictions\"", "]", "\n", "\n", "if", "isinstance", "(", "video_id", ",", "list", ")", ":", "\n", "    ", "video_id", "=", "video_id", "[", "0", "]", "\n", "class_indexes", "=", "class_indexes", "[", "0", "]", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "class_indexes", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The number of indexes (%s) and predictions (%s) must be equal.\"", "\n", "%", "(", "len", "(", "class_indexes", ")", ",", "len", "(", "predictions", ")", ")", ")", "\n", "\n", "", "return", "(", "video_id", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "\n", "(", "class_indexes", "[", "i", "]", ",", "predictions", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_indexes", ")", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.convert_prediction_from_json_to_csv.main": [[70, 101], ["tensorflow.logging.set_verbosity", "tensorflow.logging.info", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "ValueError", "ValueError", "tensorflow.gfile.Open", "output_file.write", "output_file.flush", "convert_prediction_from_json_to_csv.get_csv_header", "tensorflow.logging.info", "tensorflow.gfile.Open", "json.loads", "output_file.write", "convert_prediction_from_json_to_csv.to_csv_row"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.get_csv_header", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.to_csv_row"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "if", "not", "FLAGS", ".", "json_prediction_files_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The flag --json_prediction_files_pattern must be specified.\"", ")", "\n", "\n", "", "if", "not", "FLAGS", ".", "csv_output_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"The flag --csv_output_file must be specified.\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Looking for prediction files with pattern: %s\"", ",", "\n", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "\n", "file_paths", "=", "gfile", ".", "Glob", "(", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "logging", ".", "info", "(", "\"Found files: %s\"", ",", "file_paths", ")", "\n", "\n", "logging", ".", "info", "(", "\"Writing submission file to: %s\"", ",", "FLAGS", ".", "csv_output_file", ")", "\n", "with", "gfile", ".", "Open", "(", "FLAGS", ".", "csv_output_file", ",", "\"w+\"", ")", "as", "output_file", ":", "\n", "    ", "output_file", ".", "write", "(", "get_csv_header", "(", ")", ")", "\n", "\n", "for", "file_path", "in", "file_paths", ":", "\n", "      ", "logging", ".", "info", "(", "\"processing file: %s\"", ",", "file_path", ")", "\n", "\n", "with", "gfile", ".", "Open", "(", "file_path", ")", "as", "input_file", ":", "\n", "\n", "        ", "for", "line", "in", "input_file", ":", "\n", "          ", "json_data", "=", "json", ".", "loads", "(", "line", ")", "\n", "output_file", ".", "write", "(", "to_csv_row", "(", "json_data", ")", ")", "\n", "\n", "", "", "", "output_file", ".", "flush", "(", ")", "\n", "", "logging", ".", "info", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.Dequantize": [[23, 39], ["None"], "function", ["None"], ["def", "Dequantize", "(", "feat_vector", ",", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "  ", "\"\"\"Dequantize the feature from the byte format to the float format.\n\n  Args:\n    feat_vector: the input 1-d vector.\n    max_quantized_value: the maximum of the quantized value.\n    min_quantized_value: the minimum of the quantized value.\n\n  Returns:\n    A float vector which has the same shape as feat_vector.\n  \"\"\"", "\n", "assert", "max_quantized_value", ">", "min_quantized_value", "\n", "quantized_range", "=", "max_quantized_value", "-", "min_quantized_value", "\n", "scalar", "=", "quantized_range", "/", "255.0", "\n", "bias", "=", "(", "quantized_range", "/", "512.0", ")", "+", "min_quantized_value", "\n", "return", "feat_vector", "*", "scalar", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.MakeSummary": [[41, 48], ["tensorflow.Summary", "tf.Summary.value.add", "str", "float"], "function", ["None"], ["", "def", "MakeSummary", "(", "name", ",", "value", ")", ":", "\n", "  ", "\"\"\"Creates a tf.Summary proto with the given name and value.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "val", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "val", ".", "tag", "=", "str", "(", "name", ")", "\n", "val", ".", "simple_value", "=", "float", "(", "value", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.AddGlobalStepSummary": [[50, 92], ["global_step_info_dict.get", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "summary_writer.add_summary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddGlobalStepSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "global_step_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the global_step summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    global_step_info_dict: a dictionary of the evaluation metrics calculated for\n      a mini-batch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "this_hit_at_one", "=", "global_step_info_dict", "[", "\"hit_at_one\"", "]", "\n", "this_perr", "=", "global_step_info_dict", "[", "\"perr\"", "]", "\n", "this_loss", "=", "global_step_info_dict", "[", "\"loss\"", "]", "\n", "examples_per_second", "=", "global_step_info_dict", ".", "get", "(", "\"examples_per_second\"", ",", "-", "1", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Hit@1\"", ",", "this_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Perr\"", ",", "this_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Loss\"", ",", "this_loss", ")", ",", "\n", "global_step_val", ")", "\n", "\n", "if", "examples_per_second", "!=", "-", "1", ":", "\n", "    ", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Example_Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "info", "=", "(", "\"global_step {0} | Batch Hit@1: {1:.3f} | Batch PERR: {2:.3f} | Batch Loss: {3:.3f} \"", "\n", "\"| Examples_per_sec: {4:.3f}\"", ")", ".", "format", "(", "\n", "global_step_val", ",", "this_hit_at_one", ",", "this_perr", ",", "this_loss", ",", "\n", "examples_per_second", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.AddEpochSummary": [[94, 139], ["numpy.mean", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddEpochSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the epoch summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    epoch_info_dict: a dictionary of the evaluation metrics calculated for the\n      whole epoch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "epoch_id", "=", "epoch_info_dict", "[", "\"epoch_id\"", "]", "\n", "avg_hit_at_one", "=", "epoch_info_dict", "[", "\"avg_hit_at_one\"", "]", "\n", "avg_perr", "=", "epoch_info_dict", "[", "\"avg_perr\"", "]", "\n", "avg_loss", "=", "epoch_info_dict", "[", "\"avg_loss\"", "]", "\n", "aps", "=", "epoch_info_dict", "[", "\"aps\"", "]", "\n", "gap", "=", "epoch_info_dict", "[", "\"gap\"", "]", "\n", "mean_ap", "=", "numpy", ".", "mean", "(", "aps", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Hit@1\"", ",", "avg_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Perr\"", ",", "avg_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Loss\"", ",", "avg_loss", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_MAP\"", ",", "mean_ap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_GAP\"", ",", "gap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "info", "=", "(", "\"epoch/eval number {0} | Avg_Hit@1: {1:.3f} | Avg_PERR: {2:.3f} \"", "\n", "\"| MAP: {3:.3f} | GAP: {4:.3f} | Avg_Loss: {5:3f}\"", ")", ".", "format", "(", "\n", "epoch_id", ",", "avg_hit_at_one", ",", "avg_perr", ",", "mean_ap", ",", "gap", ",", "avg_loss", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.GetListOfFeatureNamesAndSizes": [[140, 162], ["feature_names.strip", "int", "len", "len", "tensorflow.logging.error", "feature_names.split", "feature_sizes.split", "str", "len", "str", "len"], "function", ["None"], ["", "def", "GetListOfFeatureNamesAndSizes", "(", "feature_names", ",", "feature_sizes", ")", ":", "\n", "  ", "\"\"\"Extract the list of feature names and the dimensionality of each feature\n     from string of comma separated values.\n\n  Args:\n    feature_names: string containing comma separated list of feature names\n    feature_sizes: string containing comma separated list of feature sizes\n\n  Returns:\n    List of the feature names and list of the dimensionality of each feature.\n    Elements in the first/second list are strings/integers.\n  \"\"\"", "\n", "list_of_feature_names", "=", "[", "\n", "feature_names", ".", "strip", "(", ")", "for", "feature_names", "in", "feature_names", ".", "split", "(", "','", ")", "]", "\n", "list_of_feature_sizes", "=", "[", "\n", "int", "(", "feature_sizes", ")", "for", "feature_sizes", "in", "feature_sizes", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "list_of_feature_names", ")", "!=", "len", "(", "list_of_feature_sizes", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"length of the feature names (=\"", "+", "\n", "str", "(", "len", "(", "list_of_feature_names", ")", ")", "+", "\") != length of feature \"", "\n", "\"sizes (=\"", "+", "str", "(", "len", "(", "list_of_feature_sizes", ")", ")", "+", "\")\"", ")", "\n", "\n", "", "return", "list_of_feature_names", ",", "list_of_feature_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.clip_gradient_norms": [[163, 183], ["clipped_grads_and_vars.append", "isinstance", "tensorflow.clip_by_norm", "tensorflow.IndexedSlices", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "clip_gradient_norms", "(", "gradients_to_variables", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clips the gradients by the given value.\n\n  Args:\n    gradients_to_variables: A list of gradient to variable pairs (tuples).\n    max_norm: the maximum norm value.\n\n  Returns:\n    A list of clipped gradient to variable pairs.\n  \"\"\"", "\n", "clipped_grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "gradients_to_variables", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "tmp", "=", "tf", ".", "clip_by_norm", "(", "grad", ".", "values", ",", "max_norm", ")", "\n", "grad", "=", "tf", ".", "IndexedSlices", "(", "tmp", ",", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "tf", ".", "clip_by_norm", "(", "grad", ",", "max_norm", ")", "\n", "", "", "clipped_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.utils.combine_gradients": [[184, 206], ["xrange", "len", "tensorflow.stack", "tensorflow.reduce_sum", "final_grads.append", "xrange", "len"], "function", ["None"], ["", "def", "combine_gradients", "(", "tower_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the combined gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been summed\n     across all towers.\n  \"\"\"", "\n", "filtered_grads", "=", "[", "[", "x", "for", "x", "in", "grad_list", "if", "x", "[", "0", "]", "is", "not", "None", "]", "for", "grad_list", "in", "tower_grads", "]", "\n", "final_grads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filtered_grads", "[", "0", "]", ")", ")", ":", "\n", "    ", "grads", "=", "[", "filtered_grads", "[", "t", "]", "[", "i", "]", "for", "t", "in", "xrange", "(", "len", "(", "filtered_grads", ")", ")", "]", "\n", "grad", "=", "tf", ".", "stack", "(", "[", "x", "[", "0", "]", "for", "x", "in", "grads", "]", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_sum", "(", "grad", ",", "0", ")", "\n", "final_grads", ".", "append", "(", "(", "grad", ",", "filtered_grads", "[", "0", "]", "[", "i", "]", "[", "1", "]", ",", ")", ")", "\n", "\n", "", "return", "final_grads", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.losses.BaseLoss.calculate_loss": [[23, 38], ["NotImplementedError"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "unused_predictions", ",", "unused_labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Calculates the average loss of the examples in a mini-batch.\n\n     Args:\n      unused_predictions: a 2-d tensor storing the prediction scores, in which\n        each row represents a sample in the mini-batch and each column\n        represents a class.\n      unused_labels: a 2-d tensor storing the labels, which has the same shape\n        as the unused_predictions. The labels must be in the range of 0 and 1.\n      unused_params: loss specific parameters.\n\n    Returns:\n      A scalar loss tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.losses.CrossEntropyLoss.calculate_loss": [[44, 52], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.losses.HingeLoss.calculate_loss": [[62, 71], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.CC.losses.SoftmaxLoss.calculate_loss": [[85, 98], ["tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.maximum", "tensorflow.div", "tensorflow.nn.softmax", "tensorflow.negative", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_softmax\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-8", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "# l1 normalization (labels are no less than 0)", "\n", "label_rowsum", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "reduce_sum", "(", "float_labels", ",", "1", ",", "keep_dims", "=", "True", ")", ",", "\n", "epsilon", ")", "\n", "norm_float_labels", "=", "tf", ".", "div", "(", "float_labels", ",", "label_rowsum", ")", "\n", "softmax_outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "predictions", ")", "\n", "softmax_loss", "=", "tf", ".", "negative", "(", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "norm_float_labels", ",", "tf", ".", "log", "(", "softmax_outputs", ")", ")", ",", "1", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "softmax_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.frame_level_models.FrameLevelLogisticModel.create_model": [[52, 84], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_input.get_shape().as_list", "tensorflow.tile", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape"], "methods", ["None"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a logistic classifier over the average of the\n    frame-level features.\n\n    This class is intended to be an example for implementors of frame level\n    models. If you want to train a model over averaged features it is more\n    efficient to average them beforehand rather than on the fly.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "denominators", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "num_frames", ",", "[", "1", ",", "feature_size", "]", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "avg_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "\n", "axis", "=", "[", "1", "]", ")", "/", "denominators", "\n", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "avg_pooled", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.frame_level_models.DbofModel.create_model": [[108, 196], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "model_utils.FramePooling", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.FramePooling", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomSequence"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_frames", ",", "\n", "iterations", "=", "None", ",", "\n", "add_batch_norm", "=", "None", ",", "\n", "sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "      ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "activation", "=", "utils", ".", "FramePooling", "(", "activation", ",", "FLAGS", ".", "dbof_pooling_method", ")", "\n", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "cluster_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "hidden1_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.frame_level_models.LstmModel.create_model": [[199, 237], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a model which uses a stack of LSTMs to represent the video.\n\n    Args:\n      model_input: A 'batch_size' x 'max_frames' x 'num_features' matrix of\n                   input features.\n      vocab_size: The number of classes in the dataset.\n      num_frames: A vector of length 'batch' which indicates the number of\n           frames for each video (before padding).\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      'batch_size' x 'num_classes'.\n    \"\"\"", "\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", "[", "-", "1", "]", ".", "h", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.__init__": [[64, 82], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n\n    This class is used to calculate the average precision for a single label.\n\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or\n        None to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"", "\n", "if", "not", "(", "(", "isinstance", "(", "top_n", ",", "int", ")", "and", "top_n", ">=", "0", ")", "or", "top_n", "is", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"top_n must be a positive integer or None.\"", ")", "\n", "\n", "", "self", ".", "_top_n", "=", "top_n", "# average precision at n", "\n", "self", ".", "_total_positives", "=", "0", "# total number of positives have seen", "\n", "self", ".", "_heap", "=", "[", "]", "# max heap of (prediction, actual)", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.heap_size": [[83, 87], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "heap_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the heap size maintained in the class.\"\"\"", "\n", "return", "len", "(", "self", ".", "_heap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.num_accumulated_positives": [[88, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_accumulated_positives", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the number of positive samples that have been accumulated.\"\"\"", "\n", "return", "self", ".", "_total_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.accumulate": [[93, 133], ["range", "len", "len", "ValueError", "numpy.size", "numpy.size", "ValueError", "numpy.where", "heapq.heappush", "isinstance", "len", "heapq.heappop", "heapq.heappush"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives = If the 'predictions' and 'actuals' inputs aren't complete,\n      then it's possible some true positives were missed in them. In that case,\n      you can provide 'num_positives' in order to accurately track recall.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "num_positives", ",", "numbers", ".", "Number", ")", "or", "num_positives", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"'num_positives' was provided but it wan't a nonzero number.\"", ")", "\n", "\n", "", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "num_positives", "\n", "", "else", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "topk", "=", "self", ".", "_top_n", "\n", "heap", "=", "self", ".", "_heap", "\n", "\n", "for", "i", "in", "range", "(", "numpy", ".", "size", "(", "predictions", ")", ")", ":", "\n", "      ", "if", "topk", "is", "None", "or", "len", "(", "heap", ")", "<", "topk", ":", "\n", "        ", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "predictions", "[", "i", "]", ">", "heap", "[", "0", "]", "[", "0", "]", ":", "# heap[0] is the smallest", "\n", "          ", "heapq", ".", "heappop", "(", "heap", ")", "\n", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.clear": [[134, 138], ["None"], "methods", ["None"], ["", "", "", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the accumulated predictions.\"\"\"", "\n", "self", ".", "_heap", "=", "[", "]", "\n", "self", ".", "_total_positives", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n": [[139, 156], ["numpy.array", "average_precision_calculator.AveragePrecisionCalculator.ap_at_n", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "def", "peek_ap_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated average precision at n.\n\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"", "\n", "if", "self", ".", "heap_size", "<=", "0", ":", "\n", "      ", "return", "0", "\n", "", "predlists", "=", "numpy", ".", "array", "(", "list", "(", "zip", "(", "*", "self", ".", "_heap", ")", ")", ")", "\n", "\n", "ap", "=", "self", ".", "ap_at_n", "(", "predlists", "[", "0", "]", ",", "\n", "predlists", "[", "1", "]", ",", "\n", "n", "=", "self", ".", "_top_n", ",", "\n", "total_num_positives", "=", "self", ".", "_total_positives", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.ap": [[157, 178], ["average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "return", "AveragePrecisionCalculator", ".", "ap_at_n", "(", "predictions", ",", "\n", "actuals", ",", "\n", "n", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator.ap_at_n": [[179, 246], ["numpy.array", "numpy.array", "average_precision_calculator.AveragePrecisionCalculator._shuffle", "sorted", "len", "range", "len", "len", "ValueError", "range", "numpy.size", "min", "min", "ValueError", "len", "numpy.where", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator._shuffle"], ["", "@", "staticmethod", "\n", "def", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "20", ",", "total_num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive\n      in the list. If specified, it will be used in calculation.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "n", ",", "int", ")", "or", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"n must be 'None' or a positive integer.\"", "\n", "\" It was '%s'.\"", "%", "n", ")", "\n", "\n", "", "", "ap", "=", "0.0", "\n", "\n", "predictions", "=", "numpy", ".", "array", "(", "predictions", ")", "\n", "actuals", "=", "numpy", ".", "array", "(", "actuals", ")", "\n", "\n", "# add a shuffler to avoid overestimating the ap", "\n", "predictions", ",", "actuals", "=", "AveragePrecisionCalculator", ".", "_shuffle", "(", "predictions", ",", "\n", "actuals", ")", "\n", "sortidx", "=", "sorted", "(", "\n", "range", "(", "len", "(", "predictions", ")", ")", ",", "\n", "key", "=", "lambda", "k", ":", "predictions", "[", "k", "]", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "if", "total_num_positives", "is", "None", ":", "\n", "      ", "numpos", "=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "else", ":", "\n", "      ", "numpos", "=", "total_num_positives", "\n", "\n", "", "if", "numpos", "==", "0", ":", "\n", "      ", "return", "0", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "numpos", "=", "min", "(", "numpos", ",", "n", ")", "\n", "", "delta_recall", "=", "1.0", "/", "numpos", "\n", "poscount", "=", "0.0", "\n", "\n", "# calculate the ap", "\n", "r", "=", "len", "(", "sortidx", ")", "\n", "if", "n", "is", "not", "None", ":", "\n", "      ", "r", "=", "min", "(", "r", ",", "n", ")", "\n", "", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "      ", "if", "actuals", "[", "sortidx", "[", "i", "]", "]", ">", "0", ":", "\n", "        ", "poscount", "+=", "1", "\n", "ap", "+=", "poscount", "/", "(", "i", "+", "1", ")", "*", "delta_recall", "\n", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator._shuffle": [[247, 254], ["random.seed", "random.sample", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_shuffle", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "suffidx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "len", "(", "predictions", ")", ")", "\n", "predictions", "=", "predictions", "[", "suffidx", "]", "\n", "actuals", "=", "actuals", "[", "suffidx", "]", "\n", "return", "predictions", ",", "actuals", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.average_precision_calculator.AveragePrecisionCalculator._zero_one_normalize": [[255, 275], ["numpy.max", "numpy.min", "numpy.max", "numpy.min"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_one_normalize", "(", "predictions", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n\n    Returns:\n      The normalized prediction.\n    \"\"\"", "\n", "denominator", "=", "numpy", ".", "max", "(", "predictions", ")", "-", "numpy", ".", "min", "(", "predictions", ")", "\n", "ret", "=", "(", "predictions", "-", "numpy", ".", "min", "(", "predictions", ")", ")", "/", "numpy", ".", "max", "(", "denominator", ",", "\n", "epsilon", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.models.BaseModel.create_model": [[20, 22], ["NotImplementedError"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "unused_model_input", ",", "**", "unused_params", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.BaseReader.prepare_reader": [[62, 65], ["NotImplementedError"], "methods", ["None"], ["    ", "\"\"\"Create a thread for generating prediction and label tensors.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MAggregatedFeatureReader.__init__": [[75, 98], ["numpy.load", "len", "len", "len", "len"], "methods", ["None"], ["num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"mean_inc3\"", "]", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MAggregatedFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "\n", "", "def", "prepare_reader", "(", "self", ",", "filename_queue", ",", "batch_size", "=", "1024", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MAggregatedFeatureReader.prepare_reader": [[100, 114], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read_up_to", "tensorflow.add_to_collection", "readers.YT8MAggregatedFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read_up_to", "(", "filename_queue", ",", "batch_size", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"serialized_examples\"", ",", "serialized_examples", ")", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", "\n", "\n", "", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_examples", ")", ":", "\n", "# set the mapping from the fields to data types in the proto", "\n", "    ", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"self.feature_names is empty!\"", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "("]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MAggregatedFeatureReader.prepare_serialized_examples": [[115, 144], ["len", "range", "tensorflow.parse_example", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.SparseTensor", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.concat", "len", "len", "len", "len", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.ones", "tensorflow.reshape", "tensorflow.gather", "tensorflow.constant", "tensorflow.shape"], "methods", ["None"], ["len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "feature_map", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_map", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "self", ".", "feature_sizes", "[", "feature_index", "]", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "", "features", "=", "tf", ".", "parse_example", "(", "serialized_examples", ",", "features", "=", "feature_map", ")", "\n", "labels", "=", "tf", ".", "sparse_to_indicator", "(", "features", "[", "\"labels\"", "]", ",", "self", ".", "num_classes", ")", "\n", "labels", ".", "set_shape", "(", "[", "None", ",", "self", ".", "num_classes", "]", ")", "\n", "concatenated_features", "=", "tf", ".", "concat", "(", "[", "\n", "features", "[", "feature_name", "]", "for", "feature_name", "in", "self", ".", "feature_names", "]", ",", "1", ")", "\n", "\n", "return", "features", "[", "\"video_id\"", "]", ",", "concatenated_features", ",", "labels", ",", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "serialized_examples", ")", "[", "0", "]", "]", ")", "\n", "\n", "", "", "class", "YT8MFrameFeatureReader", "(", "BaseReader", ")", ":", "\n", "  ", "\"\"\"Reads TFRecords of SequenceExamples.\n\n  The TFRecords must contain SequenceExamples with the sparse in64 'labels'\n  context feature and a fixed length byte-quantized feature vector, obtained\n  from the features in 'feature_names'. The quantized features will be mapped\n  back into a range between min_quantized_value and max_quantized_value.\n  \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"inc3\"", "]", ",", "\n", "max_frames", "=", "300", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MFrameFeatureReader.__init__": [[155, 177], ["len", "len", "len", "len"], "methods", ["None"], ["\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "\n", "", "def", "get_video_matrix", "(", "self", ",", "\n", "features", ",", "\n", "feature_size", ",", "\n", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MFrameFeatureReader.get_video_matrix": [[178, 207], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.Dequantize", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.resize_axis"], ["\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "return", "feature_matrix", ",", "num_frames", "\n", "\n", "", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MFrameFeatureReader.prepare_reader": [[208, 227], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "\n", "", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "\n", "    ", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ",", "\n", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", ")", "\n", "\n", "# read ground truth labels", "\n", "labels", "=", "(", "tf", ".", "cast", "(", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.YT8MFrameFeatureReader.prepare_serialized_examples": [[228, 285], ["tensorflow.parse_single_sequence_example", "tensorflow.cast", "len", "range", "tensorflow.minimum", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "len", "len", "len", "len", "readers.YT8MFrameFeatureReader.get_video_matrix", "tensorflow.assert_equal", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenSequenceFeature"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.get_video_matrix"], ["tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "\n", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "", "else", ":", "\n", "        ", "tf", ".", "assert_equal", "(", "num_frames", ",", "num_frames_in_this_feature", ")", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "# concatenate different features", "\n", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "\n", "# convert to batch format.", "\n", "# TODO: Do proper batch reads to remove the IO bottleneck.", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"video_id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "return", "batch_video_ids", ",", "batch_video_matrix", ",", "batch_labels", ",", "batch_frames", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.readers.resize_axis": [[22, 58], ["tensorflow.convert_to_tensor", "tensorflow.unstack", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.concat", "tf.convert_to_tensor.get_shape().as_list", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.slice", "tensorflow.fill", "tf.convert_to_tensor.get_shape", "tensorflow.zeros_like", "tensorflow.stack", "tensorflow.cast"], "function", ["None"], ["  ", "\"\"\"Truncates or pads a tensor to new_size on on a given axis.\n\n  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n  size increases, the padding will be performed at the end, using fill_value.\n\n  Args:\n    tensor: The tensor to be resized.\n    axis: An integer representing the dimension to be sliced.\n    new_size: An integer or 0d tensor representing the new value for\n      tensor.shape[axis].\n    fill_value: Value to use to fill any new entries in the tensor. Will be\n      cast to the type of tensor.\n\n  Returns:\n    The resized tensor.\n  \"\"\"", "\n", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "\n", "pad_shape", "=", "shape", "[", ":", "]", "\n", "pad_shape", "[", "axis", "]", "=", "tf", ".", "maximum", "(", "0", ",", "new_size", "-", "shape", "[", "axis", "]", ")", "\n", "\n", "shape", "[", "axis", "]", "=", "tf", ".", "minimum", "(", "shape", "[", "axis", "]", ",", "new_size", ")", "\n", "shape", "=", "tf", ".", "stack", "(", "shape", ")", "\n", "\n", "resized", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "slice", "(", "tensor", ",", "tf", ".", "zeros_like", "(", "shape", ")", ",", "shape", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "stack", "(", "pad_shape", ")", ",", "tf", ".", "cast", "(", "fill_value", ",", "tensor", ".", "dtype", ")", ")", "\n", "]", ",", "axis", ")", "\n", "\n", "# Update shape.", "\n", "new_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# A copy is being made.", "\n", "new_shape", "[", "axis", "]", "=", "new_size", "\n", "resized", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "resized", "\n", "\n", "", "class", "BaseReader", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.export_model.ModelExporter.__init__": [[29, 38], ["tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "export_model.ModelExporter.build_inputs_and_outputs", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.Graph", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_inputs_and_outputs"], ["  ", "def", "__init__", "(", "self", ",", "frame_features", ",", "model", ",", "reader", ")", ":", "\n", "    ", "self", ".", "frame_features", "=", "frame_features", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "self", ".", "inputs", ",", "self", ".", "outputs", "=", "self", ".", "build_inputs_and_outputs", "(", ")", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "sharded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.export_model.ModelExporter.export_model": [[39, 61], ["export_model.ModelExporter.graph.as_default", "tensorflow.Session", "tensorflow.Session", "session.run", "export_model.ModelExporter.saver.restore", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables", "tensorflow.python.saved_model.builder.SavedModelBuilder.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "export_model", "(", "self", ",", "model_dir", ",", "global_step_val", ",", "last_checkpoint", ")", ":", "\n", "    ", "\"\"\"Exports the model so that it can used for batch predictions.\"\"\"", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "      ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "session", ",", "last_checkpoint", ")", "\n", "\n", "signature", "=", "signature_def_utils", ".", "build_signature_def", "(", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "outputs", "=", "self", ".", "outputs", ",", "\n", "method_name", "=", "signature_constants", ".", "PREDICT_METHOD_NAME", ")", "\n", "\n", "signature_map", "=", "{", "signature_constants", ".", "DEFAULT_SERVING_SIGNATURE_DEF_KEY", ":", "\n", "signature", "}", "\n", "\n", "model_builder", "=", "saved_model_builder", ".", "SavedModelBuilder", "(", "model_dir", ")", "\n", "model_builder", ".", "add_meta_graph_and_variables", "(", "session", ",", "\n", "tags", "=", "[", "tag_constants", ".", "SERVING", "]", ",", "\n", "signature_def_map", "=", "signature_map", ",", "\n", "clear_devices", "=", "True", ")", "\n", "model_builder", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.export_model.ModelExporter.build_inputs_and_outputs": [[62, 86], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.placeholder", "tensorflow.placeholder", "export_model.ModelExporter.build_prediction_graph", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "export_model.ModelExporter.build_prediction_graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph"], ["", "", "", "def", "build_inputs_and_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame_features", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "fn", "=", "lambda", "x", ":", "self", ".", "build_prediction_graph", "(", "x", ")", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "tf", ".", "map_fn", "(", "fn", ",", "serialized_examples", ",", "\n", "dtype", "=", "(", "tf", ".", "string", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "self", ".", "build_prediction_graph", "(", "serialized_examples", ")", ")", "\n", "\n", "", "inputs", "=", "{", "\"example_bytes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "serialized_examples", ")", "}", "\n", "\n", "outputs", "=", "{", "\n", "\"video_id\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "video_id_output", ")", ",", "\n", "\"class_indexes\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_indices_output", ")", ",", "\n", "\"predictions\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_predictions_output", ")", "}", "\n", "\n", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.export_model.ModelExporter.build_prediction_graph": [[87, 116], ["export_model.ModelExporter.reader.prepare_serialized_examples", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "len", "tensorflow.variable_scope", "tensorflow.variable_scope", "export_model.ModelExporter.model.create_model", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "model_input_raw.get_shape", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["", "def", "build_prediction_graph", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "self", ".", "reader", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "      ", "result", "=", "self", ".", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "self", ".", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "\n", "top_predictions", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "predictions", ",", "\n", "_TOP_PREDICTIONS_IN_OUTPUT", ")", "\n", "", "return", "video_id", ",", "top_indices", ",", "top_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.mean_average_precision_calculator.MeanAveragePrecisionCalculator.__init__": [[48, 70], ["range", "ValueError", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators.append", "isinstance", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ")", ":", "\n", "    ", "\"\"\"Construct a calculator to calculate the (macro) average precision.\n\n    Args:\n      num_class: A positive Integer specifying the number of classes.\n      top_n_array: A list of positive integers specifying the top n for each\n      class. The top n in each class will be used to calculate its average\n      precision at n.\n      The size of the array must be num_class.\n\n    Raises:\n      ValueError: An error occurred when num_class is not a positive integer;\n      or the top_n_array is not a list of positive integers.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "num_class", ",", "int", ")", "or", "num_class", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"num_class must be a positive integer.\"", ")", "\n", "\n", "", "self", ".", "_ap_calculators", "=", "[", "]", "# member of AveragePrecisionCalculator", "\n", "self", ".", "_num_class", "=", "num_class", "# total number of classes", "\n", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "      ", "self", ".", "_ap_calculators", ".", "append", "(", "\n", "average_precision_calculator", ".", "AveragePrecisionCalculator", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.mean_average_precision_calculator.MeanAveragePrecisionCalculator.accumulate": [[71, 94], ["range", "len", "calculators[].accumulate"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate"], ["", "", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    Args:\n      predictions: A list of lists storing the prediction scores. The outer\n      dimension corresponds to classes.\n      actuals: A list of lists storing the ground truth labels. The dimensions\n      should correspond to the predictions input. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives: If provided, it is a list of numbers representing the\n      number of true positives for each class. If not provided, the number of\n      true positives will be inferred from the 'actuals' array.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n      does not match.\n    \"\"\"", "\n", "if", "not", "num_positives", ":", "\n", "      ", "num_positives", "=", "[", "None", "for", "i", "in", "predictions", ".", "shape", "[", "1", "]", "]", "\n", "\n", "", "calculators", "=", "self", ".", "_ap_calculators", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "      ", "calculators", "[", "i", "]", ".", "accumulate", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ",", "num_positives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.mean_average_precision_calculator.MeanAveragePrecisionCalculator.clear": [[95, 98], ["calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "for", "calculator", "in", "self", ".", "_ap_calculators", ":", "\n", "      ", "calculator", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.mean_average_precision_calculator.MeanAveragePrecisionCalculator.is_empty": [[99, 102], ["range"], "methods", ["None"], ["", "", "def", "is_empty", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "calculator", ".", "heap_size", "for", "calculator", "in", "self", ".", "_ap_calculators", "]", "==", "\n", "[", "0", "for", "_", "in", "range", "(", "self", ".", "_num_class", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n": [[103, 113], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators[].peek_ap_at_n", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "peek_map_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated mean average precision at n.\n\n    Returns:\n      An array of non-interpolated average precision at n (default 0) for each\n      class.\n    \"\"\"", "\n", "aps", "=", "[", "self", ".", "_ap_calculators", "[", "i", "]", ".", "peek_ap_at_n", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", "]", "\n", "return", "aps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.model_utils.SampleRandomSequence": [[23, 49], ["tensorflow.tile", "tensorflow.maximum", "tensorflow.cast", "tensorflow.minimum", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.cast", "tensorflow.range"], "function", ["None"], ["def", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random sequence of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index_offset", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_samples", ")", ",", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "max_start_frame_index", "=", "tf", ".", "maximum", "(", "num_frames", "-", "num_samples", ",", "0", ")", "\n", "start_frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "max_start_frame_index", "+", "1", ",", "tf", ".", "float32", ")", ")", ",", "tf", ".", "int32", ")", "\n", "frame_index", "=", "tf", ".", "minimum", "(", "start_frame_index", "+", "frame_index_offset", ",", "\n", "tf", ".", "cast", "(", "num_frames", "-", "1", ",", "tf", ".", "int32", ")", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.model_utils.SampleRandomFrames": [[51, 71], ["tensorflow.cast", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.range", "tensorflow.cast"], "function", ["None"], ["", "def", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random set of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "num_samples", "]", ")", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "cast", "(", "num_frames", ",", "tf", ".", "float32", ")", ",", "[", "1", ",", "num_samples", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.model_utils.FramePooling": [[72, 96], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reshape", "ValueError", "frames.shape_as_list"], "function", ["None"], ["", "def", "FramePooling", "(", "frames", ",", "method", ",", "**", "unused_params", ")", ":", "\n", "  ", "\"\"\"Pools over the frames of a video.\n\n  Args:\n    frames: A tensor with shape [batch_size, num_frames, feature_size].\n    method: \"average\", \"max\", \"attention\", or \"none\".\n  Returns:\n    A tensor with shape [batch_size, feature_size] for average, max, or\n    attention pooling. A tensor with shape [batch_size*num_frames, feature_size]\n    for none pooling.\n\n  Raises:\n    ValueError: if method is other than \"average\", \"max\", \"attention\", or\n    \"none\".\n  \"\"\"", "\n", "if", "method", "==", "\"average\"", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"max\"", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"none\"", ":", "\n", "    ", "feature_size", "=", "frames", ".", "shape_as_list", "(", ")", "[", "2", "]", "\n", "return", "tf", ".", "reshape", "(", "frames", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unrecognized pooling method: %s\"", "%", "method", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.find_class_by_name": [[71, 75], ["next", "getattr"], "function", ["None"], ["\n", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.get_input_evaluation_tensors": [[77, 114], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["\n", "", "def", "get_input_evaluation_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the evaluation data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for evaluation.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"eval_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find the evaluation files.\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of evaluation files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "shuffle", "=", "False", ",", "num_epochs", "=", "1", ")", "\n", "eval_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "return", "tf", ".", "train", ".", "batch_join", "(", "\n", "eval_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "3", "*", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.build_graph": [[116, 188], ["tensorflow.Variable", "eval.get_input_evaluation_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.constant", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "len", "tensorflow.variable_scope", "model.create_model", "tensorflow.summary.histogram", "tensorflow.cast", "tensorflow.summary.merge_all", "model_input_raw.get_shape", "model.create_model.keys", "label_loss_fn.calculate_loss"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.get_input_evaluation_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["\n", "", "", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "eval_data_pattern", ",", "\n", "label_loss_fn", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph for evaluation.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    eval_data_pattern: glob path to the evaluation data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    num_readers: How many threads to use for I/O operations.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "video_id_batch", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "get_input_evaluation_tensors", "(", "# pylint: disable=g-line-too-long", "\n", "reader", ",", "\n", "eval_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "# Normalize input features.", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "# CCMoe", "\n", "phase", "=", "tf", ".", "constant", "(", "False", ",", "name", "=", "\"phase\"", ")", "\n", "#", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "    ", "result", "=", "model", ".", "create_model", "(", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "phase", ")", "\n", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_activations\"", ",", "predictions", ")", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "      ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "      ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "labels_batch", ")", "\n", "\n", "", "", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "predictions", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"video_id_batch\"", ",", "video_id_batch", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"summary_op\"", ",", "tf", ".", "summary", ".", "merge_all", "(", ")", ")", "\n", "# CCMoe", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n", "\n", "\n", "", "def", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "\n", "summary_op", ",", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.evaluation_loop": [[190, 299], ["tensorflow.Session", "tensorflow.train.latest_checkpoint", "sess.run", "tensorflow.train.Coordinator", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "tensorflow.logging.info", "saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.logging.info", "evl_metrics.clear", "[].split", "tensorflow.local_variables_initializer", "threads.extend", "tf.train.Coordinator.should_stop", "time.time", "sess.run", "evl_metrics.accumulate", "utils.AddGlobalStepSummary", "tensorflow.logging.info", "tensorflow.logging.info", "evl_metrics.get", "summary_writer.add_summary", "utils.AddEpochSummary", "tensorflow.logging.info", "evl_metrics.clear", "tensorflow.logging.info", "tf.train.Coordinator.request_stop", "qr.create_threads", "time.time", "str", "tf.train.latest_checkpoint.split"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddGlobalStepSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddEpochSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["\n", "\n", "global_step_val", "=", "-", "1", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "if", "FLAGS", ".", "certain_step", "!=", "\"Latest\"", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"/\"", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "certain_step", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "if", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading checkpoint for eval: \"", "+", "latest_checkpoint", ")", "\n", "# Restores from checkpoint", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "# Assuming model_checkpoint_path looks something like:", "\n", "# /my-favorite-path/yt8m_train/model.ckpt-0, extract global_step from it.", "\n", "global_step_val", "=", "latest_checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"No checkpoint file found.\"", ")", "\n", "return", "global_step_val", "\n", "\n", "", "if", "global_step_val", "==", "last_global_step_val", ":", "\n", "      ", "logging", ".", "info", "(", "\"skip this checkpoint global_step_val=%s \"", "\n", "\"(same as the previous one).\"", ",", "global_step_val", ")", "\n", "return", "global_step_val", "\n", "\n", "", "sess", ".", "run", "(", "[", "tf", ".", "local_variables_initializer", "(", ")", "]", ")", "\n", "\n", "# Start the queue runners.", "\n", "fetches", "=", "[", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "summary_op", "]", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "try", ":", "\n", "      ", "threads", "=", "[", "]", "\n", "for", "qr", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "QUEUE_RUNNERS", ")", ":", "\n", "        ", "threads", ".", "extend", "(", "qr", ".", "create_threads", "(", "\n", "sess", ",", "coord", "=", "coord", ",", "daemon", "=", "True", ",", "\n", "start", "=", "True", ")", ")", "\n", "", "logging", ".", "info", "(", "\"enter eval_once loop global_step_val = %s. \"", ",", "\n", "global_step_val", ")", "\n", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "\n", "examples_processed", "=", "0", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "predictions_val", ",", "labels_val", ",", "loss_val", ",", "summary_val", "=", "sess", ".", "run", "(", "\n", "fetches", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "example_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "examples_processed", "+=", "labels_val", ".", "shape", "[", "0", "]", "\n", "\n", "iteration_info_dict", "=", "evl_metrics", ".", "accumulate", "(", "predictions_val", ",", "\n", "labels_val", ",", "loss_val", ")", "\n", "iteration_info_dict", "[", "\"examples_per_second\"", "]", "=", "example_per_second", "\n", "\n", "iterinfo", "=", "utils", ".", "AddGlobalStepSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "iteration_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "\"examples_processed: %d | %s\"", ",", "examples_processed", ",", "\n", "iterinfo", ")", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", "as", "e", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"Done with batched inference. Now calculating global performance \"", "\n", "\"metrics.\"", ")", "\n", "# calculate the metrics for the entire epoch", "\n", "epoch_info_dict", "=", "evl_metrics", ".", "get", "(", ")", "\n", "epoch_info_dict", "[", "\"epoch_id\"", "]", "=", "global_step_val", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_val", ",", "global_step_val", ")", "\n", "epochinfo", "=", "utils", ".", "AddEpochSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "epochinfo", ")", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "\n", "      ", "logging", ".", "info", "(", "\"Unexpected exception: \"", "+", "str", "(", "e", ")", ")", "\n", "coord", ".", "request_stop", "(", "e", ")", "\n", "\n", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ",", "stop_grace_period_secs", "=", "10", ")", "\n", "\n", "return", "global_step_val", "\n", "\n", "\n", "", "", "def", "evaluate", "(", ")", ":", "\n", "  ", "tf", ".", "set_random_seed", "(", "0", ")", "# for reproducibility", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "    ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.evaluate": [[301, 359], ["tensorflow.set_random_seed", "tensorflow.Graph().as_default", "utils.GetListOfFeatureNamesAndSizes", "eval.build_graph", "tensorflow.logging.info", "tensorflow.train.Saver", "tensorflow.summary.FileWriter", "eval_util.EvaluationMetrics", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "eval.find_class_by_name", "eval.find_class_by_name", "IOError", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.global_variables", "eval.evaluation_loop", "tensorflow.Graph", "tensorflow.get_default_graph"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluation_loop"], ["\n", "if", "FLAGS", ".", "eval_data_pattern", "is", "\"\"", ":", "\n", "      ", "raise", "IOError", "(", "\"'eval_data_pattern' was not specified. \"", "+", "\n", "\"Nothing to evaluate.\"", ")", "\n", "\n", "", "build_graph", "(", "\n", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "eval_data_pattern", "=", "FLAGS", ".", "eval_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "logging", ".", "info", "(", "\"built evaluation graph\"", ")", "\n", "video_id_batch", "=", "tf", ".", "get_collection", "(", "\"video_id_batch\"", ")", "[", "0", "]", "\n", "prediction_batch", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "label_batch", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "summary_op", "=", "tf", ".", "get_collection", "(", "\"summary_op\"", ")", "[", "0", "]", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "FLAGS", ".", "train_dir", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "evl_metrics", "=", "eval_util", ".", "EvaluationMetrics", "(", "reader", ".", "num_classes", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "last_global_step_val", "=", "-", "1", "\n", "while", "True", ":", "\n", "      ", "last_global_step_val", "=", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "\n", "label_batch", ",", "loss", ",", "summary_op", ",", "\n", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", "\n", "if", "FLAGS", ".", "run_once", ":", "\n", "        ", "break", "\n", "\n", "\n", "", "", "", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "print", "(", "\"tensorflow version: %s\"", "%", "tf", ".", "__version__", ")", "\n", "evaluate", "(", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "  ", "app", ".", "run", "(", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval.main": [[361, 365], ["tensorflow.logging.set_verbosity", "print", "eval.evaluate"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluate"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.inference.format_lines": [[69, 78], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.inference.get_input_data_tensors": [[80, 117], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n", "", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "latest_checkpoint", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.inference.inference": [[118, 181], ["tensorflow.Session", "tensorflow.gfile.Open", "inference.get_input_data_tensors", "tensorflow.train.latest_checkpoint", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "inference.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n", "\n", "", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.inference.main": [[183, 207], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "inference.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "  ", "app", ".", "run", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.LogisticModel.create_model": [[50, 65], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["  ", "\"\"\"A softmax over a mixture of logistic models (with L2 regularization).\"\"\"", "\n", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.MoeModel.create_model": [[69, 121], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["\n", "num_mixtures", "=", "num_mixtures", "or", "FLAGS", ".", "moe_num_mixtures", "\n", "\n", "gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "(", "num_mixtures", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gates\"", ")", "\n", "expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "num_mixtures", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"experts\"", ")", "\n", "\n", "gating_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "gate_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "+", "1", "]", ")", ")", "# (Batch * #Labels) x (num_mixtures + 1)", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "expert_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "]", ")", ")", "# (Batch * #Labels) x num_mixtures", "\n", "\n", "final_probabilities_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gating_distribution", "[", ":", ",", ":", "num_mixtures", "]", "*", "expert_distribution", ",", "1", ")", "\n", "final_probabilities", "=", "tf", ".", "reshape", "(", "final_probabilities_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "vocab_size", "]", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "CCModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "256", "\n", "state_size", "=", "96", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "time_steps", "=", "vocab_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.HMLPModel.create_model": [[123, 175], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "1", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_response", ")", "\n", "\n", "# paddings = tf.zeros([batch_size, vocab_size - time_steps], dtype=tf.float32)", "\n", "# prob_chains.append(paddings)", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "PartlyCCModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "512", "\n", "state_size", "=", "512", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "36", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_part_response", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.HMoeModel.create_model": [[179, 251], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "PRCCModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Partly Recurring Classifiers Chain\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "512", "\n", "state_size", "=", "1024", "\n", "proj_size", "=", "512", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ",", "num_proj", "=", "proj_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "part_response", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "part_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# logistic_weights = tf.get_variable(\"logistic_weights\", [state_size, part_size], initializer=tf.random_normal_initializer())", "\n", "# Newly", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "proj_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "#", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "tf", ".", "concat", "(", "[", "reduced_feature", ",", "part_response", "]", ",", "1", ")", ",", "state", ")", "\n", "part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "part_response", ")", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "PRCCConcatModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Partly Recurring Classifiers Chain\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduced_feature_size", "=", "1024", "\n", "reduced_distr_size", "=", "1024", "\n", "state_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "*", "4", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "reduced_feature_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduced_feature_size", ",", "\n", "activation_fn", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.ColRelModel.create_model": [[254, 397], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["reduced_feature", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_feature_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "[", "tf", ".", "get_variable", "(", "\"logistic_weights_\"", "+", "str", "(", "i", ")", ",", "[", "state_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "for", "i", "in", "range", "(", "time_steps", ")", "]", "\n", "logistic_biases", "=", "[", "tf", ".", "get_variable", "(", "\"logistic_biases_\"", "+", "str", "(", "i", ")", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "for", "i", "in", "range", "(", "time_steps", ")", "]", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "output", ",", "state", "=", "lstm", "(", "tf", ".", "concat", "(", "[", "reduced_feature", ",", "reduced_distr", "]", ",", "1", ")", ",", "state", ")", "\n", "part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", "[", "step", "]", ")", "+", "logistic_biases", "[", "step", "]", ")", "\n", "prob_chains", ".", "append", "(", "part_response", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "part_response", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "CCMoeModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Classifiers Chain Moe\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduced_feature_size", "=", "512", "\n", "reduced_distr_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "reduced_feature_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduced_feature_size", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "reduced_feature", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_feature_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "group_input", "=", "slim", ".", "dropout", "(", "tf", ".", "concat", "(", "[", "reduced_distr", ",", "reduced_feature", "]", ",", "1", ")", ",", "\n", "keep_prob", "=", "0.5", ",", "\n", "is_training", "=", "is_training", ")", "\n", "group_expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "num_experts", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"pred_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "group_gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "(", "num_experts", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gate_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "group_expert_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "]", ")", ")", "\n", "gate_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "group_gate_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "+", "1", "]", ")", ")", "\n", "\n", "expert_distr_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gate_distribution", "[", ":", ",", ":", "num_experts", "]", "*", "expert_distribution", ",", "1", ")", "\n", "group_predictions", "=", "tf", ".", "reshape", "(", "expert_distr_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "part_size", "]", ")", "\n", "#", "\n", "\n", "prob_chains", ".", "append", "(", "group_predictions", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "group_predictions", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "CCOrigMoeModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Classifiers Chain Moe\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "# reduced_feature_size = 512 ", "\n", "# reduced_distr_size = 1024 ", "\n", "    ", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "# reduced_feature_activations = slim.fully_connected(", "\n", "#     model_input,", "\n", "#     reduced_feature_size,", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.video_level_models.RefineModel.create_model": [[401, 508], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.dropout", "tensorflow.dropout", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.dropout", "tensorflow.dropout", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "numpy.load", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "matrix[].T.astype", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.constant", "tensorflow.constant", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.constant", "tensorflow.constant", "matrix[].reshape().astype", "matrix[].reshape().astype", "matrix[].reshape", "matrix[].reshape"], "methods", ["None"], ["# reduced_feature = tf.nn.relu(slim.batch_norm(reduced_feature_activations, is_training=is_training))", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# distr_weights = tf.get_variable(\"distr_weights\", [vocab_size, reduced_distr_size], initializer=tf.random_normal_initializer())", "\n", "# distr_biases = tf.get_variable(\"distr_biases\", [reduced_distr_size], initializer=tf.constant_initializer(0.0))", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "# reduced_distr_activations = tf.matmul(distribution, distr_weights) + distr_biases ", "\n", "# reduced_distr = tf.nn.relu(slim.batch_norm(reduced_distr_activations, is_training=is_training))", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "", "group_input", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "model_input", "]", ",", "1", ")", "\n", "# group_input = slim.dropout(tf.concat([reduced_distr, reduced_feature], 1),", "\n", "#   keep_prob=0.5,", "\n", "#   is_training=is_training)", "\n", "group_expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "num_experts", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"pred_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "group_gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "group_input", ",", "\n", "part_size", "*", "(", "num_experts", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gate_\"", "+", "str", "(", "step", ")", "\n", ")", "\n", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "group_expert_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "]", ")", ")", "\n", "gate_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "group_gate_activations", ",", "\n", "[", "-", "1", ",", "num_experts", "+", "1", "]", ")", ")", "\n", "\n", "expert_distr_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gate_distribution", "[", ":", ",", ":", "num_experts", "]", "*", "expert_distribution", ",", "1", ")", "\n", "group_predictions", "=", "tf", ".", "reshape", "(", "expert_distr_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "part_size", "]", ")", "\n", "#", "\n", "\n", "prob_chains", ".", "append", "(", "group_predictions", ")", "\n", "pre", "=", "distribution", "[", ":", ",", ":", "step", "*", "part_size", "]", "if", "step", ">", "0", "else", "None", "\n", "aft", "=", "distribution", "[", ":", ",", "(", "step", "+", "1", ")", "*", "part_size", ":", "]", "if", "step", "+", "1", "<", "time_steps", "else", "None", "\n", "distribution", "=", "group_predictions", "\n", "if", "pre", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "pre", ",", "distribution", "]", ",", "1", ")", "\n", "", "if", "aft", "is", "not", "None", ":", "\n", "        ", "distribution", "=", "tf", ".", "concat", "(", "[", "distribution", ",", "aft", "]", ",", "1", ")", "\n", "\n", "", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "CCDistrMoeModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Classifiers Chain Moe\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "# reduced_feature_size = 512 ", "\n", "    ", "reduced_distr_size", "=", "1024", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "part_size", "=", "393", "\n", "time_steps", "=", "vocab_size", "//", "part_size", "\n", "num_experts", "=", "8", "\n", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "# reduced input feature", "\n", "# reduced_feature_activations = slim.fully_connected(", "\n", "#     model_input,", "\n", "#     reduced_feature_size,", "\n", "#     activation_fn=None,", "\n", "#     weights_regularizer=slim.l2_regularizer(l2_penalty),", "\n", "#     scope=\"reduce\")", "\n", "# reduced_feature = tf.nn.relu(slim.batch_norm(reduced_feature_activations, is_training=is_training))", "\n", "# distribution feature", "\n", "distribution", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "vocab_size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "distr_weights", "=", "tf", ".", "get_variable", "(", "\"distr_weights\"", ",", "[", "vocab_size", ",", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "distr_biases", "=", "tf", ".", "get_variable", "(", "\"distr_biases\"", ",", "[", "reduced_distr_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# distribution reduced feature", "\n", "", "reduced_distr_activations", "=", "tf", ".", "matmul", "(", "distribution", ",", "distr_weights", ")", "+", "distr_biases", "\n", "reduced_distr", "=", "tf", ".", "nn", ".", "relu", "(", "slim", ".", "batch_norm", "(", "reduced_distr_activations", ",", "is_training", "=", "is_training", ")", ")", "\n", "#", "\n", "\n", "# group predictions", "\n", "# group_input = tf.concat([reduced_distr, reduced_feature], 1)", "\n", "# group_input = tf.concat([distribution, model_input], 1)", "\n", "group_input", "=", "tf", ".", "concat", "(", "[", "reduced_distr", ",", "model_input", "]", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.__init__": [[376, 400], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["#                           task_as_string(self.task))", "\n", "\n", "", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.run": [[405, 501], ["train.Trainer.start_server_if_distributed", "train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "train.task_as_string", "tensorflow.train.Supervisor.managed_session", "train.task_as_string", "train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.Graph", "tensorflow.Graph", "train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "20", "*", "60", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "64", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n", "", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n", "", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.export_model": [[502, 518], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "train.Trainer.model_exporter.export_model", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n", "", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.start_server_if_distributed": [[519, 535], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "train.task_as_string", "train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.remove_training_directory": [[536, 548], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n", "", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n", "", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.get_meta_filename": [[549, 568], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "train.task_as_string", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.recover_model": [[569, 573], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["\n", "", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.Trainer.build_model": [[574, 595], ["train.find_class_by_name", "train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n", "\n", "", "class", "ParameterServer", "(", "object", ")", ":", "\n", "  ", "\"\"\"A parameter server to serve variables in a distributed execution.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.ParameterServer.__init__": [[615, 626], ["None"], "methods", ["None"], ["\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.ParameterServer.run": [[627, 634], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "start_server.join", "train.task_as_string", "train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n", "", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.validate_class_name": [[104, 131], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.get_input_data_tensors": [[132, 175], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.find_class_by_name": [[177, 181], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.build_graph": [[182, 372], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "tensorflow.add_to_collection", "range", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.concat", "tensorflow.cast", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_coarse_predictions.append", "tower_predictions.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "tower_coarse_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "# PRCCConcat", "\n", "phase", "=", "tf", ".", "constant", "(", "True", ")", "\n", "#", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "# PRCCConcat", "\n", "is_training", "=", "phase", ")", "\n", "#)", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "# PRCCConcat", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n", "\n", "\n", "", "class", "Trainer", "(", "object", ")", ":", "\n", "  ", "\"\"\"A Trainer to train a Tensorflow graph.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.get_reader": [[597, 610], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n", "", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n", "\n", "", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.start_server": [[636, 658], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "train.task_as_string", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.task_as_string": [[659, 661], ["None"], "function", ["None"], ["model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.train.main": [[662, 700], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train.task_as_string", "train.get_reader", "export_model.ModelExporter", "train.Trainer.run", "train.find_class_by_name", "train.ParameterServer.run", "ValueError", "train.Trainer", "train.ParameterServer", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "  ", "app", ".", "run", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.EvaluationMetrics.__init__": [[140, 158], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "top_k", ")", ":", "\n", "    ", "\"\"\"Construct an EvaluationMetrics object to store the evaluation metrics.\n\n    Args:\n      num_class: A positive integer specifying the number of classes.\n      top_k: A positive integer specifying how many predictions are considered per video.\n\n    Raises:\n      ValueError: An error occurred when MeanAveragePrecisionCalculator cannot\n        not be constructed.\n    \"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", "=", "map_calculator", ".", "MeanAveragePrecisionCalculator", "(", "num_class", ")", "\n", "self", ".", "global_ap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "num_examples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.EvaluationMetrics.accumulate": [[159, 192], ["eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "numpy.mean", "eval_util.top_k_by_class", "eval_util.EvaluationMetrics.map_calculator.accumulate", "eval_util.EvaluationMetrics.global_ap_calculator.accumulate", "eval_util.flatten", "eval_util.flatten", "sum"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "labels", ",", "loss", ")", ":", "\n", "    ", "\"\"\"Accumulate the metrics calculated locally for this mini-batch.\n\n    Args:\n      predictions: A numpy matrix containing the outputs of the model.\n        Dimensions are 'batch' x 'num_classes'.\n      labels: A numpy matrix containing the ground truth labels.\n        Dimensions are 'batch' x 'num_classes'.\n      loss: A numpy array containing the loss for each sample.\n\n    Returns:\n      dictionary: A dictionary storing the metrics for the mini-batch.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n        does not match.\n    \"\"\"", "\n", "batch_size", "=", "labels", ".", "shape", "[", "0", "]", "\n", "mean_hit_at_one", "=", "calculate_hit_at_one", "(", "predictions", ",", "labels", ")", "\n", "mean_perr", "=", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "labels", ")", "\n", "mean_loss", "=", "numpy", ".", "mean", "(", "loss", ")", "\n", "\n", "# Take the top 20 predictions.", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "labels", ",", "self", ".", "top_k", ")", "\n", "self", ".", "map_calculator", ".", "accumulate", "(", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", ")", "\n", "self", ".", "global_ap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "\n", "self", ".", "num_examples", "+=", "batch_size", "\n", "self", ".", "sum_hit_at_one", "+=", "mean_hit_at_one", "*", "batch_size", "\n", "self", ".", "sum_perr", "+=", "mean_perr", "*", "batch_size", "\n", "self", ".", "sum_loss", "+=", "mean_loss", "*", "batch_size", "\n", "\n", "return", "{", "\"hit_at_one\"", ":", "mean_hit_at_one", ",", "\"perr\"", ":", "mean_perr", ",", "\"loss\"", ":", "mean_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.EvaluationMetrics.get": [[193, 216], ["eval_util.EvaluationMetrics.map_calculator.peek_map_at_n", "eval_util.EvaluationMetrics.global_ap_calculator.peek_ap_at_n", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "get", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calculate the evaluation metrics for the whole epoch.\n\n    Raises:\n      ValueError: If no examples were accumulated.\n\n    Returns:\n      dictionary: a dictionary storing the evaluation metrics for the epoch. The\n        dictionary has the fields: avg_hit_at_one, avg_perr, avg_loss, and\n        aps (default nan).\n    \"\"\"", "\n", "if", "self", ".", "num_examples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"total_sample must be positive.\"", ")", "\n", "", "avg_hit_at_one", "=", "self", ".", "sum_hit_at_one", "/", "self", ".", "num_examples", "\n", "avg_perr", "=", "self", ".", "sum_perr", "/", "self", ".", "num_examples", "\n", "avg_loss", "=", "self", ".", "sum_loss", "/", "self", ".", "num_examples", "\n", "\n", "aps", "=", "self", ".", "map_calculator", ".", "peek_map_at_n", "(", ")", "\n", "gap", "=", "self", ".", "global_ap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n", "epoch_info_dict", "=", "{", "}", "\n", "return", "{", "\"avg_hit_at_one\"", ":", "avg_hit_at_one", ",", "\"avg_perr\"", ":", "avg_perr", ",", "\n", "\"avg_loss\"", ":", "avg_loss", ",", "\"aps\"", ":", "aps", ",", "\"gap\"", ":", "gap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.EvaluationMetrics.clear": [[217, 225], ["eval_util.EvaluationMetrics.map_calculator.clear", "eval_util.EvaluationMetrics.global_ap_calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the evaluation metrics and reset the EvaluationMetrics object.\"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", ".", "clear", "(", ")", "\n", "self", ".", "global_ap_calculator", ".", "clear", "(", ")", "\n", "self", ".", "num_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.flatten": [[24, 27], ["None"], "function", ["None"], ["def", "flatten", "(", "l", ")", ":", "\n", "  ", "\"\"\" Merges a list of lists into a single list. \"\"\"", "\n", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.calculate_hit_at_one": [[28, 43], ["numpy.argmax", "numpy.average", "numpy.arange"], "function", ["None"], ["", "def", "calculate_hit_at_one", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the hit at one.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average hit at one across the entire batch.\n  \"\"\"", "\n", "top_prediction", "=", "numpy", ".", "argmax", "(", "predictions", ",", "1", ")", "\n", "hits", "=", "actuals", "[", "numpy", ".", "arange", "(", "actuals", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "numpy", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.calculate_precision_at_equal_recall_rate": [[45, 71], ["numpy.arange", "int", "numpy.sum", "numpy.argpartition"], "function", ["None"], ["", "def", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the PERR.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average precision at equal recall rate across the entire batch.\n  \"\"\"", "\n", "aggregated_precision", "=", "0.0", "\n", "num_videos", "=", "actuals", ".", "shape", "[", "0", "]", "\n", "for", "row", "in", "numpy", ".", "arange", "(", "num_videos", ")", ":", "\n", "    ", "num_labels", "=", "int", "(", "numpy", ".", "sum", "(", "actuals", "[", "row", "]", ")", ")", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "row", "]", ",", "\n", "-", "num_labels", ")", "[", "-", "num_labels", ":", "]", "\n", "item_precision", "=", "0.0", "\n", "for", "label_index", "in", "top_indices", ":", "\n", "      ", "if", "predictions", "[", "row", "]", "[", "label_index", "]", ">", "0", ":", "\n", "        ", "item_precision", "+=", "actuals", "[", "row", "]", "[", "label_index", "]", "\n", "", "", "item_precision", "/=", "top_indices", ".", "size", "\n", "aggregated_precision", "+=", "item_precision", "\n", "", "aggregated_precision", "/=", "num_videos", "\n", "return", "aggregated_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.calculate_gap": [[72, 91], ["average_precision_calculator.AveragePrecisionCalculator", "eval_util.top_k_by_class", "ap_calculator.AveragePrecisionCalculator.accumulate", "ap_calculator.AveragePrecisionCalculator.peek_ap_at_n", "eval_util.flatten", "eval_util.flatten", "sum"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "calculate_gap", "(", "predictions", ",", "actuals", ",", "top_k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the global average precision.\n\n  Only the top_k predictions are taken for each of the videos.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n    top_k: How many predictions to use per video.\n\n  Returns:\n    float: The global average precision.\n  \"\"\"", "\n", "gap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "actuals", ",", "top_k", ")", "\n", "gap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "return", "gap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.top_k_by_class": [[93, 128], ["min", "range", "ValueError", "prediction_triplets.extend", "out_predictions[].append", "out_labels[].append", "numpy.sum", "eval_util.top_k_triplets", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_triplets"], ["", "def", "top_k_by_class", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Extracts the top k predictions for each video, sorted by class.\n\n  Args:\n    predictions: A numpy matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    k: the top k non-zero entries to preserve in each prediction.\n\n  Returns:\n    A tuple (predictions,labels, true_positives). 'predictions' and 'labels'\n    are lists of lists of floats. 'true_positives' is a list of scalars. The\n    length of the lists are equal to the number of classes. The entries in the\n    predictions variable are probability predictions, and\n    the corresponding entries in the labels variable are the ground truth for\n    those predictions. The entries in 'true_positives' are the number of true\n    positives for each class in the ground truth.\n\n  Raises:\n    ValueError: An error occurred when the k is not a positive integer.\n  \"\"\"", "\n", "if", "k", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"k must be a positive integer.\"", ")", "\n", "", "k", "=", "min", "(", "k", ",", "predictions", ".", "shape", "[", "1", "]", ")", "\n", "num_classes", "=", "predictions", ".", "shape", "[", "1", "]", "\n", "prediction_triplets", "=", "[", "]", "\n", "for", "video_index", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "prediction_triplets", ".", "extend", "(", "top_k_triplets", "(", "predictions", "[", "video_index", "]", ",", "labels", "[", "video_index", "]", ",", "k", ")", ")", "\n", "", "out_predictions", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "triplet", "in", "prediction_triplets", ":", "\n", "    ", "out_predictions", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "1", "]", ")", "\n", "out_labels", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "2", "]", ")", "\n", "", "out_true_positives", "=", "[", "numpy", ".", "sum", "(", "labels", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "return", "out_predictions", ",", "out_labels", ",", "out_true_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.eval_util.top_k_triplets": [[129, 136], ["len", "min", "numpy.argpartition"], "function", ["None"], ["", "def", "top_k_triplets", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Get the top_k for a 1-d numpy array. Returns a sparse list of tuples in\n  (prediction, class) format\"\"\"", "\n", "m", "=", "len", "(", "predictions", ")", "\n", "k", "=", "min", "(", "k", ",", "m", ")", "\n", "indices", "=", "numpy", ".", "argpartition", "(", "predictions", ",", "-", "k", ")", "[", "-", "k", ":", "]", "\n", "return", "[", "(", "index", ",", "predictions", "[", "index", "]", ",", "labels", "[", "index", "]", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.convert_prediction_from_json_to_csv.get_csv_header": [[46, 48], ["None"], "function", ["None"], ["", "def", "get_csv_header", "(", ")", ":", "\n", "  ", "return", "\"VideoId,LabelConfidencePairs\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.convert_prediction_from_json_to_csv.to_csv_row": [[49, 69], ["isinstance", "len", "len", "ValueError", "video_id.decode", "len", "len", "builtins.range", "len"], "function", ["None"], ["", "def", "to_csv_row", "(", "json_data", ")", ":", "\n", "\n", "  ", "video_id", "=", "json_data", "[", "\"video_id\"", "]", "\n", "\n", "class_indexes", "=", "json_data", "[", "\"class_indexes\"", "]", "\n", "predictions", "=", "json_data", "[", "\"predictions\"", "]", "\n", "\n", "if", "isinstance", "(", "video_id", ",", "list", ")", ":", "\n", "    ", "video_id", "=", "video_id", "[", "0", "]", "\n", "class_indexes", "=", "class_indexes", "[", "0", "]", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "class_indexes", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The number of indexes (%s) and predictions (%s) must be equal.\"", "\n", "%", "(", "len", "(", "class_indexes", ")", ",", "len", "(", "predictions", ")", ")", ")", "\n", "\n", "", "return", "(", "video_id", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "\n", "(", "class_indexes", "[", "i", "]", ",", "predictions", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_indexes", ")", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.convert_prediction_from_json_to_csv.main": [[70, 101], ["tensorflow.logging.set_verbosity", "tensorflow.logging.info", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "ValueError", "ValueError", "tensorflow.gfile.Open", "output_file.write", "output_file.flush", "convert_prediction_from_json_to_csv.get_csv_header", "tensorflow.logging.info", "tensorflow.gfile.Open", "json.loads", "output_file.write", "convert_prediction_from_json_to_csv.to_csv_row"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.get_csv_header", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.to_csv_row"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "if", "not", "FLAGS", ".", "json_prediction_files_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The flag --json_prediction_files_pattern must be specified.\"", ")", "\n", "\n", "", "if", "not", "FLAGS", ".", "csv_output_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"The flag --csv_output_file must be specified.\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Looking for prediction files with pattern: %s\"", ",", "\n", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "\n", "file_paths", "=", "gfile", ".", "Glob", "(", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "logging", ".", "info", "(", "\"Found files: %s\"", ",", "file_paths", ")", "\n", "\n", "logging", ".", "info", "(", "\"Writing submission file to: %s\"", ",", "FLAGS", ".", "csv_output_file", ")", "\n", "with", "gfile", ".", "Open", "(", "FLAGS", ".", "csv_output_file", ",", "\"w+\"", ")", "as", "output_file", ":", "\n", "    ", "output_file", ".", "write", "(", "get_csv_header", "(", ")", ")", "\n", "\n", "for", "file_path", "in", "file_paths", ":", "\n", "      ", "logging", ".", "info", "(", "\"processing file: %s\"", ",", "file_path", ")", "\n", "\n", "with", "gfile", ".", "Open", "(", "file_path", ")", "as", "input_file", ":", "\n", "\n", "        ", "for", "line", "in", "input_file", ":", "\n", "          ", "json_data", "=", "json", ".", "loads", "(", "line", ")", "\n", "output_file", ".", "write", "(", "to_csv_row", "(", "json_data", ")", ")", "\n", "\n", "", "", "", "output_file", ".", "flush", "(", ")", "\n", "", "logging", ".", "info", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.Dequantize": [[23, 39], ["None"], "function", ["None"], ["def", "Dequantize", "(", "feat_vector", ",", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "  ", "\"\"\"Dequantize the feature from the byte format to the float format.\n\n  Args:\n    feat_vector: the input 1-d vector.\n    max_quantized_value: the maximum of the quantized value.\n    min_quantized_value: the minimum of the quantized value.\n\n  Returns:\n    A float vector which has the same shape as feat_vector.\n  \"\"\"", "\n", "assert", "max_quantized_value", ">", "min_quantized_value", "\n", "quantized_range", "=", "max_quantized_value", "-", "min_quantized_value", "\n", "scalar", "=", "quantized_range", "/", "255.0", "\n", "bias", "=", "(", "quantized_range", "/", "512.0", ")", "+", "min_quantized_value", "\n", "return", "feat_vector", "*", "scalar", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.MakeSummary": [[41, 48], ["tensorflow.Summary", "tf.Summary.value.add", "str", "float"], "function", ["None"], ["", "def", "MakeSummary", "(", "name", ",", "value", ")", ":", "\n", "  ", "\"\"\"Creates a tf.Summary proto with the given name and value.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "val", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "val", ".", "tag", "=", "str", "(", "name", ")", "\n", "val", ".", "simple_value", "=", "float", "(", "value", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.AddGlobalStepSummary": [[50, 92], ["global_step_info_dict.get", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "summary_writer.add_summary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddGlobalStepSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "global_step_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the global_step summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    global_step_info_dict: a dictionary of the evaluation metrics calculated for\n      a mini-batch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "this_hit_at_one", "=", "global_step_info_dict", "[", "\"hit_at_one\"", "]", "\n", "this_perr", "=", "global_step_info_dict", "[", "\"perr\"", "]", "\n", "this_loss", "=", "global_step_info_dict", "[", "\"loss\"", "]", "\n", "examples_per_second", "=", "global_step_info_dict", ".", "get", "(", "\"examples_per_second\"", ",", "-", "1", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Hit@1\"", ",", "this_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Perr\"", ",", "this_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Loss\"", ",", "this_loss", ")", ",", "\n", "global_step_val", ")", "\n", "\n", "if", "examples_per_second", "!=", "-", "1", ":", "\n", "    ", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Example_Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "info", "=", "(", "\"global_step {0} | Batch Hit@1: {1:.3f} | Batch PERR: {2:.3f} | Batch Loss: {3:.3f} \"", "\n", "\"| Examples_per_sec: {4:.3f}\"", ")", ".", "format", "(", "\n", "global_step_val", ",", "this_hit_at_one", ",", "this_perr", ",", "this_loss", ",", "\n", "examples_per_second", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.AddEpochSummary": [[94, 139], ["numpy.mean", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddEpochSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the epoch summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    epoch_info_dict: a dictionary of the evaluation metrics calculated for the\n      whole epoch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "epoch_id", "=", "epoch_info_dict", "[", "\"epoch_id\"", "]", "\n", "avg_hit_at_one", "=", "epoch_info_dict", "[", "\"avg_hit_at_one\"", "]", "\n", "avg_perr", "=", "epoch_info_dict", "[", "\"avg_perr\"", "]", "\n", "avg_loss", "=", "epoch_info_dict", "[", "\"avg_loss\"", "]", "\n", "aps", "=", "epoch_info_dict", "[", "\"aps\"", "]", "\n", "gap", "=", "epoch_info_dict", "[", "\"gap\"", "]", "\n", "mean_ap", "=", "numpy", ".", "mean", "(", "aps", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Hit@1\"", ",", "avg_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Perr\"", ",", "avg_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Loss\"", ",", "avg_loss", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_MAP\"", ",", "mean_ap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_GAP\"", ",", "gap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "info", "=", "(", "\"epoch/eval number {0} | Avg_Hit@1: {1:.3f} | Avg_PERR: {2:.3f} \"", "\n", "\"| MAP: {3:.3f} | GAP: {4:.3f} | Avg_Loss: {5:3f}\"", ")", ".", "format", "(", "\n", "epoch_id", ",", "avg_hit_at_one", ",", "avg_perr", ",", "mean_ap", ",", "gap", ",", "avg_loss", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.GetListOfFeatureNamesAndSizes": [[140, 162], ["feature_names.strip", "int", "len", "len", "tensorflow.logging.error", "feature_names.split", "feature_sizes.split", "str", "len", "str", "len"], "function", ["None"], ["", "def", "GetListOfFeatureNamesAndSizes", "(", "feature_names", ",", "feature_sizes", ")", ":", "\n", "  ", "\"\"\"Extract the list of feature names and the dimensionality of each feature\n     from string of comma separated values.\n\n  Args:\n    feature_names: string containing comma separated list of feature names\n    feature_sizes: string containing comma separated list of feature sizes\n\n  Returns:\n    List of the feature names and list of the dimensionality of each feature.\n    Elements in the first/second list are strings/integers.\n  \"\"\"", "\n", "list_of_feature_names", "=", "[", "\n", "feature_names", ".", "strip", "(", ")", "for", "feature_names", "in", "feature_names", ".", "split", "(", "','", ")", "]", "\n", "list_of_feature_sizes", "=", "[", "\n", "int", "(", "feature_sizes", ")", "for", "feature_sizes", "in", "feature_sizes", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "list_of_feature_names", ")", "!=", "len", "(", "list_of_feature_sizes", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"length of the feature names (=\"", "+", "\n", "str", "(", "len", "(", "list_of_feature_names", ")", ")", "+", "\") != length of feature \"", "\n", "\"sizes (=\"", "+", "str", "(", "len", "(", "list_of_feature_sizes", ")", ")", "+", "\")\"", ")", "\n", "\n", "", "return", "list_of_feature_names", ",", "list_of_feature_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.clip_gradient_norms": [[163, 183], ["clipped_grads_and_vars.append", "isinstance", "tensorflow.clip_by_norm", "tensorflow.IndexedSlices", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "clip_gradient_norms", "(", "gradients_to_variables", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clips the gradients by the given value.\n\n  Args:\n    gradients_to_variables: A list of gradient to variable pairs (tuples).\n    max_norm: the maximum norm value.\n\n  Returns:\n    A list of clipped gradient to variable pairs.\n  \"\"\"", "\n", "clipped_grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "gradients_to_variables", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "tmp", "=", "tf", ".", "clip_by_norm", "(", "grad", ".", "values", ",", "max_norm", ")", "\n", "grad", "=", "tf", ".", "IndexedSlices", "(", "tmp", ",", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "tf", ".", "clip_by_norm", "(", "grad", ",", "max_norm", ")", "\n", "", "", "clipped_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.utils.combine_gradients": [[184, 206], ["xrange", "len", "tensorflow.stack", "tensorflow.reduce_sum", "final_grads.append", "xrange", "len"], "function", ["None"], ["", "def", "combine_gradients", "(", "tower_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the combined gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been summed\n     across all towers.\n  \"\"\"", "\n", "filtered_grads", "=", "[", "[", "x", "for", "x", "in", "grad_list", "if", "x", "[", "0", "]", "is", "not", "None", "]", "for", "grad_list", "in", "tower_grads", "]", "\n", "final_grads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filtered_grads", "[", "0", "]", ")", ")", ":", "\n", "    ", "grads", "=", "[", "filtered_grads", "[", "t", "]", "[", "i", "]", "for", "t", "in", "xrange", "(", "len", "(", "filtered_grads", ")", ")", "]", "\n", "grad", "=", "tf", ".", "stack", "(", "[", "x", "[", "0", "]", "for", "x", "in", "grads", "]", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_sum", "(", "grad", ",", "0", ")", "\n", "final_grads", ".", "append", "(", "(", "grad", ",", "filtered_grads", "[", "0", "]", "[", "i", "]", "[", "1", "]", ",", ")", ")", "\n", "\n", "", "return", "final_grads", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.losses.BaseLoss.calculate_loss": [[23, 38], ["NotImplementedError"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "unused_predictions", ",", "unused_labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Calculates the average loss of the examples in a mini-batch.\n\n     Args:\n      unused_predictions: a 2-d tensor storing the prediction scores, in which\n        each row represents a sample in the mini-batch and each column\n        represents a class.\n      unused_labels: a 2-d tensor storing the labels, which has the same shape\n        as the unused_predictions. The labels must be in the range of 0 and 1.\n      unused_params: loss specific parameters.\n\n    Returns:\n      A scalar loss tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.losses.CrossEntropyLoss.calculate_loss": [[44, 52], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.losses.HingeLoss.calculate_loss": [[62, 71], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.HMoE.losses.SoftmaxLoss.calculate_loss": [[85, 98], ["tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.maximum", "tensorflow.div", "tensorflow.nn.softmax", "tensorflow.negative", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_softmax\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-8", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "# l1 normalization (labels are no less than 0)", "\n", "label_rowsum", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "reduce_sum", "(", "float_labels", ",", "1", ",", "keep_dims", "=", "True", ")", ",", "\n", "epsilon", ")", "\n", "norm_float_labels", "=", "tf", ".", "div", "(", "float_labels", ",", "label_rowsum", ")", "\n", "softmax_outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "predictions", ")", "\n", "softmax_loss", "=", "tf", ".", "negative", "(", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "norm_float_labels", ",", "tf", ".", "log", "(", "softmax_outputs", ")", ")", ",", "1", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "softmax_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.FrameLevelLogisticModel.create_model": [[58, 90], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_input.get_shape().as_list", "tensorflow.tile", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "model_input.get_shape"], "methods", ["None"], ["\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "\n", "denominators", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "num_frames", ",", "[", "1", ",", "feature_size", "]", ")", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "avg_pooled", "=", "tf", ".", "reduce_sum", "(", "model_input", ",", "\n", "axis", "=", "[", "1", "]", ")", "/", "denominators", "\n", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "avg_pooled", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "1e-8", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n", "", "", "class", "DbofModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.DbofModel.create_model": [[114, 202], ["tensorflow.cast", "tensorflow.cast", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.reshape", "tensorflow.reshape", "model_utils.FramePooling", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.relu6", "tensorflow.nn.relu6", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "getattr", "getattr.create_model", "tensorflow.expand_dims", "tensorflow.expand_dims", "model_utils.SampleRandomFrames", "model_utils.SampleRandomSequence", "model_utils.SampleRandomSequence.get_shape().as_list", "model_utils.SampleRandomSequence.get_shape().as_list", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "getattr.", "model_utils.SampleRandomSequence.get_shape", "model_utils.SampleRandomSequence.get_shape", "tensorflow.random_normal", "tensorflow.random_normal", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.FramePooling", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomFrames", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomSequence"], ["sample_random_frames", "=", "None", ",", "\n", "cluster_size", "=", "None", ",", "\n", "hidden_size", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "iterations", "=", "iterations", "or", "FLAGS", ".", "iterations", "\n", "add_batch_norm", "=", "add_batch_norm", "or", "FLAGS", ".", "dbof_add_batch_norm", "\n", "random_frames", "=", "sample_random_frames", "or", "FLAGS", ".", "sample_random_frames", "\n", "cluster_size", "=", "cluster_size", "or", "FLAGS", ".", "dbof_cluster_size", "\n", "hidden1_size", "=", "hidden_size", "or", "FLAGS", ".", "dbof_hidden_size", "\n", "\n", "num_frames", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "num_frames", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "if", "random_frames", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "else", ":", "\n", "      ", "model_input", "=", "utils", ".", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "\n", "iterations", ")", "\n", "", "max_frames", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "feature_size", "=", "model_input", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "\n", "reshaped_input", "=", "tf", ".", "reshape", "(", "model_input", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"input_hist\"", ",", "reshaped_input", ")", "\n", "\n", "if", "add_batch_norm", ":", "\n", "      ", "reshaped_input", "=", "slim", ".", "batch_norm", "(", "\n", "reshaped_input", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"input_bn\"", ")", "\n", "\n", "", "cluster_weights", "=", "tf", ".", "get_variable", "(", "\"cluster_weights\"", ",", "\n", "[", "feature_size", ",", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_weights\"", ",", "cluster_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "reshaped_input", ",", "cluster_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"cluster_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "cluster_biases", "=", "tf", ".", "get_variable", "(", "\"cluster_biases\"", ",", "\n", "[", "cluster_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "feature_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_biases\"", ",", "cluster_biases", ")", "\n", "activation", "+=", "cluster_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cluster_output\"", ",", "activation", ")", "\n", "\n", "activation", "=", "tf", ".", "reshape", "(", "activation", ",", "[", "-", "1", ",", "max_frames", ",", "cluster_size", "]", ")", "\n", "activation", "=", "utils", ".", "FramePooling", "(", "activation", ",", "FLAGS", ".", "dbof_pooling_method", ")", "\n", "\n", "hidden1_weights", "=", "tf", ".", "get_variable", "(", "\"hidden1_weights\"", ",", "\n", "[", "cluster_size", ",", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "1", "/", "math", ".", "sqrt", "(", "cluster_size", ")", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_weights\"", ",", "hidden1_weights", ")", "\n", "activation", "=", "tf", ".", "matmul", "(", "activation", ",", "hidden1_weights", ")", "\n", "if", "add_batch_norm", ":", "\n", "      ", "activation", "=", "slim", ".", "batch_norm", "(", "\n", "activation", ",", "\n", "center", "=", "True", ",", "\n", "scale", "=", "True", ",", "\n", "is_training", "=", "is_training", ",", "\n", "scope", "=", "\"hidden1_bn\"", ")", "\n", "", "else", ":", "\n", "      ", "hidden1_biases", "=", "tf", ".", "get_variable", "(", "\"hidden1_biases\"", ",", "\n", "[", "hidden1_size", "]", ",", "\n", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.01", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_biases\"", ",", "hidden1_biases", ")", "\n", "activation", "+=", "hidden1_biases", "\n", "", "activation", "=", "tf", ".", "nn", ".", "relu6", "(", "activation", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"hidden1_output\"", ",", "activation", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "activation", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "\n", "", "", "class", "LstmModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "\n", "  ", "def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "num_frames", ",", "**", "unused_params", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.LstmModel.create_model": [[205, 243], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.dynamic_rnn", "tensorflow.nn.dynamic_rnn", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["\n", "lstm_size", "=", "FLAGS", ".", "lstm_cells", "\n", "number_of_layers", "=", "FLAGS", ".", "lstm_layers", "\n", "\n", "stacked_lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "\n", "[", "\n", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "\n", "lstm_size", ",", "forget_bias", "=", "1.0", ")", "\n", "for", "_", "in", "range", "(", "number_of_layers", ")", "\n", "]", ")", "\n", "\n", "loss", "=", "0.0", "\n", "\n", "outputs", ",", "state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "stacked_lstm", ",", "model_input", ",", "\n", "sequence_length", "=", "num_frames", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "aggregated_model", "=", "getattr", "(", "video_level_models", ",", "\n", "FLAGS", ".", "video_level_classifier_model", ")", "\n", "\n", "return", "aggregated_model", "(", ")", ".", "create_model", "(", "\n", "model_input", "=", "state", "[", "-", "1", "]", ".", "h", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "**", "unused_params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.BiLstmModel.create_model": [[245, 271], ["tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.add", "tensorflow.add", "getattr", "getattr.create_model", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.ATT_BiLstm.create_model": [[274, 323], ["tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "getattr.", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.DropOut_ATT_BiLSTM.create_model": [[326, 380], ["tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.contrib.rnn.DropoutWrapper", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "getattr.", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.Split_ATT_BiLstm.create_model": [[383, 469], ["tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.concat", "tensorflow.concat", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "getattr.", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.Maxpool_ATT_BiLstm.create_model": [[472, 549], ["tensorflow.shape", "tensorflow.shape", "tensorflow.add", "tensorflow.add", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.ones_like", "tensorflow.ones_like", "getattr.", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.CNN.create_model": [[552, 580], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.relu", "tensorflow.nn.relu", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "getattr."], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.Split_BiLstm_CNN.create_model": [[583, 659], ["tensorflow.shape", "tensorflow.shape", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.add", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.conv2d", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.concat", "tensorflow.nn.relu", "tensorflow.nn.relu", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "getattr.", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.new_Maxpool_ATT_BiLstm.create_model": [[661, 739], ["tensorflow.shape", "tensorflow.shape", "tensorflow.add", "tensorflow.add", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.ones_like", "tensorflow.ones_like", "getattr.", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.Random.create_model": [[742, 811], ["tensorflow.range", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.add", "tensorflow.add", "tensorflow.tile", "tensorflow.tile", "tensorflow.stack", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.cast", "tensorflow.cast", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.range", "tensorflow.range", "tensorflow.cast", "tensorflow.cast", "getattr.", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.LSTMCell", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.zhao_Maxpool_ATT_BiLstm.create_model": [[814, 891], ["tensorflow.shape", "tensorflow.shape", "tensorflow.add", "tensorflow.add", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.ones_like", "tensorflow.ones_like", "getattr.", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.hlstm.create_model": [[893, 1004], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.tanh", "tensorflow.tanh", "getattr", "getattr.create_model", "tensorflow.shape", "tensorflow.shape", "tensorflow.ones", "tensorflow.ones", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.ones", "tensorflow.ones", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.ones", "tensorflow.ones", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "getattr.", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "range", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.frame_level_models.multi_att.create_model": [[1006, 1107], ["tensorflow.shape", "tensorflow.shape", "tensorflow.add", "tensorflow.add", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.add", "tensorflow.add", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.constant", "tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.dropout", "tensorflow.dropout", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.nn.bidirectional_dynamic_rnn", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.matmul", "numpy.load", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.range", "tensorflow.range", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.BasicLSTMCell", "range", "range", "range", "range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.__init__": [[64, 82], ["ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "top_n", "=", "None", ")", ":", "\n", "    ", "\"\"\"Construct an AveragePrecisionCalculator to calculate average precision.\n\n    This class is used to calculate the average precision for a single label.\n\n    Args:\n      top_n: A positive Integer specifying the average precision at n, or\n        None to use all provided data points.\n\n    Raises:\n      ValueError: An error occurred when the top_n is not a positive integer.\n    \"\"\"", "\n", "if", "not", "(", "(", "isinstance", "(", "top_n", ",", "int", ")", "and", "top_n", ">=", "0", ")", "or", "top_n", "is", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"top_n must be a positive integer or None.\"", ")", "\n", "\n", "", "self", ".", "_top_n", "=", "top_n", "# average precision at n", "\n", "self", ".", "_total_positives", "=", "0", "# total number of positives have seen", "\n", "self", ".", "_heap", "=", "[", "]", "# max heap of (prediction, actual)", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.heap_size": [[83, 87], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "heap_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the heap size maintained in the class.\"\"\"", "\n", "return", "len", "(", "self", ".", "_heap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.num_accumulated_positives": [[88, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_accumulated_positives", "(", "self", ")", ":", "\n", "    ", "\"\"\"Gets the number of positive samples that have been accumulated.\"\"\"", "\n", "return", "self", ".", "_total_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.accumulate": [[93, 133], ["range", "len", "len", "ValueError", "numpy.size", "numpy.size", "ValueError", "numpy.where", "heapq.heappush", "isinstance", "len", "heapq.heappop", "heapq.heappush"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    After the function call, we may call peek_ap_at_n to actually calculate\n    the average precision.\n    Note predictions and actuals must have the same shape.\n\n    Args:\n      predictions: a list storing the prediction scores.\n      actuals: a list storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives = If the 'predictions' and 'actuals' inputs aren't complete,\n      then it's possible some true positives were missed in them. In that case,\n      you can provide 'num_positives' in order to accurately track recall.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "num_positives", ",", "numbers", ".", "Number", ")", "or", "num_positives", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"'num_positives' was provided but it wan't a nonzero number.\"", ")", "\n", "\n", "", "", "if", "not", "num_positives", "is", "None", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "num_positives", "\n", "", "else", ":", "\n", "      ", "self", ".", "_total_positives", "+=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "topk", "=", "self", ".", "_top_n", "\n", "heap", "=", "self", ".", "_heap", "\n", "\n", "for", "i", "in", "range", "(", "numpy", ".", "size", "(", "predictions", ")", ")", ":", "\n", "      ", "if", "topk", "is", "None", "or", "len", "(", "heap", ")", "<", "topk", ":", "\n", "        ", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "predictions", "[", "i", "]", ">", "heap", "[", "0", "]", "[", "0", "]", ":", "# heap[0] is the smallest", "\n", "          ", "heapq", ".", "heappop", "(", "heap", ")", "\n", "heapq", ".", "heappush", "(", "heap", ",", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.clear": [[134, 138], ["None"], "methods", ["None"], ["", "", "", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the accumulated predictions.\"\"\"", "\n", "self", ".", "_heap", "=", "[", "]", "\n", "self", ".", "_total_positives", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n": [[139, 156], ["numpy.array", "average_precision_calculator.AveragePrecisionCalculator.ap_at_n", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "def", "peek_ap_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated average precision at n.\n\n    Returns:\n      The non-interpolated average precision at n (default 0).\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n    \"\"\"", "\n", "if", "self", ".", "heap_size", "<=", "0", ":", "\n", "      ", "return", "0", "\n", "", "predlists", "=", "numpy", ".", "array", "(", "list", "(", "zip", "(", "*", "self", ".", "_heap", ")", ")", ")", "\n", "\n", "ap", "=", "self", ".", "ap_at_n", "(", "predlists", "[", "0", "]", ",", "\n", "predlists", "[", "1", "]", ",", "\n", "n", "=", "self", ".", "_top_n", ",", "\n", "total_num_positives", "=", "self", ".", "_total_positives", ")", "\n", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap": [[157, 178], ["average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n"], ["", "@", "staticmethod", "\n", "def", "ap", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when the format of the input is not the\n      numpy 1-D array or the shape of predictions and actuals does not match.\n    \"\"\"", "\n", "return", "AveragePrecisionCalculator", ".", "ap_at_n", "(", "predictions", ",", "\n", "actuals", ",", "\n", "n", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.ap_at_n": [[179, 246], ["numpy.array", "numpy.array", "average_precision_calculator.AveragePrecisionCalculator._shuffle", "sorted", "len", "range", "len", "len", "ValueError", "range", "numpy.size", "min", "min", "ValueError", "len", "numpy.where", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator._shuffle"], ["", "@", "staticmethod", "\n", "def", "ap_at_n", "(", "predictions", ",", "actuals", ",", "n", "=", "20", ",", "total_num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate the non-interpolated average precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      actuals: a numpy 1-D array storing the ground truth labels. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      n: the top n items to be considered in ap@n.\n      total_num_positives : (optionally) you can specify the number of total\n        positive\n      in the list. If specified, it will be used in calculation.\n\n    Returns:\n      The non-interpolated average precision at n.\n      If n is larger than the length of the ranked list,\n      the average precision will be returned.\n\n    Raises:\n      ValueError: An error occurred when\n      1) the format of the input is not the numpy 1-D array;\n      2) the shape of predictions and actuals does not match;\n      3) the input n is not a positive integer.\n    \"\"\"", "\n", "if", "len", "(", "predictions", ")", "!=", "len", "(", "actuals", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"the shape of predictions and actuals does not match.\"", ")", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "if", "not", "isinstance", "(", "n", ",", "int", ")", "or", "n", "<=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"n must be 'None' or a positive integer.\"", "\n", "\" It was '%s'.\"", "%", "n", ")", "\n", "\n", "", "", "ap", "=", "0.0", "\n", "\n", "predictions", "=", "numpy", ".", "array", "(", "predictions", ")", "\n", "actuals", "=", "numpy", ".", "array", "(", "actuals", ")", "\n", "\n", "# add a shuffler to avoid overestimating the ap", "\n", "predictions", ",", "actuals", "=", "AveragePrecisionCalculator", ".", "_shuffle", "(", "predictions", ",", "\n", "actuals", ")", "\n", "sortidx", "=", "sorted", "(", "\n", "range", "(", "len", "(", "predictions", ")", ")", ",", "\n", "key", "=", "lambda", "k", ":", "predictions", "[", "k", "]", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "if", "total_num_positives", "is", "None", ":", "\n", "      ", "numpos", "=", "numpy", ".", "size", "(", "numpy", ".", "where", "(", "actuals", ">", "0", ")", ")", "\n", "", "else", ":", "\n", "      ", "numpos", "=", "total_num_positives", "\n", "\n", "", "if", "numpos", "==", "0", ":", "\n", "      ", "return", "0", "\n", "\n", "", "if", "n", "is", "not", "None", ":", "\n", "      ", "numpos", "=", "min", "(", "numpos", ",", "n", ")", "\n", "", "delta_recall", "=", "1.0", "/", "numpos", "\n", "poscount", "=", "0.0", "\n", "\n", "# calculate the ap", "\n", "r", "=", "len", "(", "sortidx", ")", "\n", "if", "n", "is", "not", "None", ":", "\n", "      ", "r", "=", "min", "(", "r", ",", "n", ")", "\n", "", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "      ", "if", "actuals", "[", "sortidx", "[", "i", "]", "]", ">", "0", ":", "\n", "        ", "poscount", "+=", "1", "\n", "ap", "+=", "poscount", "/", "(", "i", "+", "1", ")", "*", "delta_recall", "\n", "", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator._shuffle": [[247, 254], ["random.seed", "random.sample", "range", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_shuffle", "(", "predictions", ",", "actuals", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "suffidx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "predictions", ")", ")", ",", "len", "(", "predictions", ")", ")", "\n", "predictions", "=", "predictions", "[", "suffidx", "]", "\n", "actuals", "=", "actuals", "[", "suffidx", "]", "\n", "return", "predictions", ",", "actuals", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator._zero_one_normalize": [[255, 275], ["numpy.max", "numpy.min", "numpy.max", "numpy.min"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_one_normalize", "(", "predictions", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Normalize the predictions to the range between 0.0 and 1.0.\n\n    For some predictions like SVM predictions, we need to normalize them before\n    calculate the interpolated average precision. The normalization will not\n    change the rank in the original list and thus won't change the average\n    precision.\n\n    Args:\n      predictions: a numpy 1-D array storing the sparse prediction scores.\n      epsilon: a small constant to avoid denominator being zero.\n\n    Returns:\n      The normalized prediction.\n    \"\"\"", "\n", "denominator", "=", "numpy", ".", "max", "(", "predictions", ")", "-", "numpy", ".", "min", "(", "predictions", ")", "\n", "ret", "=", "(", "predictions", "-", "numpy", ".", "min", "(", "predictions", ")", ")", "/", "numpy", ".", "max", "(", "denominator", ",", "\n", "epsilon", ")", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.models.BaseModel.create_model": [[20, 22], ["NotImplementedError"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "unused_model_input", ",", "**", "unused_params", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.BaseReader.prepare_reader": [[61, 64], ["NotImplementedError"], "methods", ["None"], ["def", "prepare_reader", "(", "self", ",", "unused_filename_queue", ")", ":", "\n", "    ", "\"\"\"Create a thread for generating prediction and label tensors.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MAggregatedFeatureReader.__init__": [[74, 93], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"mean_inc3\"", "]", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MAggregatedFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MAggregatedFeatureReader.prepare_reader": [[94, 108], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read_up_to", "tensorflow.add_to_collection", "readers.YT8MAggregatedFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "filename_queue", ",", "batch_size", "=", "1024", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for pre-aggregated YouTube 8M Examples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n\n    Returns:\n      A tuple of video indexes, features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_examples", "=", "reader", ".", "read_up_to", "(", "filename_queue", ",", "batch_size", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"serialized_examples\"", ",", "serialized_examples", ")", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MAggregatedFeatureReader.prepare_serialized_examples": [[109, 130], ["len", "range", "tensorflow.parse_example", "tensorflow.sparse_to_indicator", "tensorflow.sparse_to_indicator.set_shape", "tensorflow.concat", "len", "len", "len", "len", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenFeature", "tensorflow.ones", "tensorflow.shape"], "methods", ["None"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_examples", ")", ":", "\n", "# set the mapping from the fields to data types in the proto", "\n", "    ", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"self.feature_names is empty!\"", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "feature_map", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_map", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", "=", "tf", ".", "FixedLenFeature", "(", "\n", "[", "self", ".", "feature_sizes", "[", "feature_index", "]", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "", "features", "=", "tf", ".", "parse_example", "(", "serialized_examples", ",", "features", "=", "feature_map", ")", "\n", "labels", "=", "tf", ".", "sparse_to_indicator", "(", "features", "[", "\"labels\"", "]", ",", "self", ".", "num_classes", ")", "\n", "labels", ".", "set_shape", "(", "[", "None", ",", "self", ".", "num_classes", "]", ")", "\n", "concatenated_features", "=", "tf", ".", "concat", "(", "[", "\n", "features", "[", "feature_name", "]", "for", "feature_name", "in", "self", ".", "feature_names", "]", ",", "1", ")", "\n", "\n", "return", "features", "[", "\"video_id\"", "]", ",", "concatenated_features", ",", "labels", ",", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "serialized_examples", ")", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.__init__": [[140, 162], ["len", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_classes", "=", "4716", ",", "\n", "feature_sizes", "=", "[", "1024", "]", ",", "\n", "feature_names", "=", "[", "\"inc3\"", "]", ",", "\n", "max_frames", "=", "300", ")", ":", "\n", "    ", "\"\"\"Construct a YT8MFrameFeatureReader.\n\n    Args:\n      num_classes: a positive integer for the number of classes.\n      feature_sizes: positive integer(s) for the feature dimensions as a list.\n      feature_names: the feature name(s) in the tensorflow record as a list.\n      max_frames: the maximum number of frames to process.\n    \"\"\"", "\n", "\n", "assert", "len", "(", "feature_names", ")", "==", "len", "(", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "feature_names", ")", ",", "len", "(", "feature_sizes", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "feature_sizes", "=", "feature_sizes", "\n", "self", ".", "feature_names", "=", "feature_names", "\n", "self", ".", "max_frames", "=", "max_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.get_video_matrix": [[163, 192], ["tensorflow.reshape", "tensorflow.minimum", "utils.Dequantize", "readers.resize_axis", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.Dequantize", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.resize_axis"], ["", "def", "get_video_matrix", "(", "self", ",", "\n", "features", ",", "\n", "feature_size", ",", "\n", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", ":", "\n", "    ", "\"\"\"Decodes features from an input string and quantizes it.\n\n    Args:\n      features: raw feature values\n      feature_size: length of each frame feature vector\n      max_frames: number of frames (rows) in the output feature_matrix\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      feature_matrix: matrix of all frame-features\n      num_frames: number of frames in the sequence\n    \"\"\"", "\n", "decoded_features", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "decode_raw", "(", "features", ",", "tf", ".", "uint8", ")", ",", "tf", ".", "float32", ")", ",", "\n", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "\n", "num_frames", "=", "tf", ".", "minimum", "(", "tf", ".", "shape", "(", "decoded_features", ")", "[", "0", "]", ",", "max_frames", ")", "\n", "feature_matrix", "=", "utils", ".", "Dequantize", "(", "decoded_features", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "feature_matrix", "=", "resize_axis", "(", "feature_matrix", ",", "0", ",", "max_frames", ")", "\n", "return", "feature_matrix", ",", "num_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader": [[193, 212], ["tensorflow.TFRecordReader", "tensorflow.TFRecordReader.read", "readers.YT8MFrameFeatureReader.prepare_serialized_examples"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples"], ["", "def", "prepare_reader", "(", "self", ",", "\n", "filename_queue", ",", "\n", "max_quantized_value", "=", "2", ",", "\n", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "    ", "\"\"\"Creates a single reader thread for YouTube8M SequenceExamples.\n\n    Args:\n      filename_queue: A tensorflow queue of filename locations.\n      max_quantized_value: the maximum of the quantized value.\n      min_quantized_value: the minimum of the quantized value.\n\n    Returns:\n      A tuple of video indexes, video features, labels, and padding data.\n    \"\"\"", "\n", "reader", "=", "tf", ".", "TFRecordReader", "(", ")", "\n", "_", ",", "serialized_example", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "return", "self", ".", "prepare_serialized_examples", "(", "serialized_example", ",", "\n", "max_quantized_value", ",", "min_quantized_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples": [[213, 270], ["tensorflow.parse_single_sequence_example", "tensorflow.cast", "len", "range", "tensorflow.minimum", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sparse_to_dense", "len", "len", "len", "len", "readers.YT8MFrameFeatureReader.get_video_matrix", "tensorflow.assert_equal", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.FixedLenSequenceFeature"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.get_video_matrix"], ["", "def", "prepare_serialized_examples", "(", "self", ",", "serialized_example", ",", "\n", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "\n", "    ", "contexts", ",", "features", "=", "tf", ".", "parse_single_sequence_example", "(", "\n", "serialized_example", ",", "\n", "context_features", "=", "{", "\"video_id\"", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "}", ",", "\n", "sequence_features", "=", "{", "\n", "feature_name", ":", "tf", ".", "FixedLenSequenceFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "for", "feature_name", "in", "self", ".", "feature_names", "\n", "}", ")", "\n", "\n", "# read ground truth labels", "\n", "labels", "=", "(", "tf", ".", "cast", "(", "\n", "tf", ".", "sparse_to_dense", "(", "contexts", "[", "\"labels\"", "]", ".", "values", ",", "(", "self", ".", "num_classes", ",", ")", ",", "1", ",", "\n", "validate_indices", "=", "False", ")", ",", "\n", "tf", ".", "bool", ")", ")", "\n", "\n", "# loads (potentially) different types of features and concatenates them", "\n", "num_features", "=", "len", "(", "self", ".", "feature_names", ")", "\n", "assert", "num_features", ">", "0", ",", "\"No feature selected: feature_names is empty!\"", "\n", "\n", "assert", "len", "(", "self", ".", "feature_names", ")", "==", "len", "(", "self", ".", "feature_sizes", ")", ",", "\"length of feature_names (={}) != length of feature_sizes (={})\"", ".", "format", "(", "len", "(", "self", ".", "feature_names", ")", ",", "len", "(", "self", ".", "feature_sizes", ")", ")", "\n", "\n", "num_frames", "=", "-", "1", "# the number of frames in the video", "\n", "feature_matrices", "=", "[", "None", "]", "*", "num_features", "# an array of different features", "\n", "for", "feature_index", "in", "range", "(", "num_features", ")", ":", "\n", "      ", "feature_matrix", ",", "num_frames_in_this_feature", "=", "self", ".", "get_video_matrix", "(", "\n", "features", "[", "self", ".", "feature_names", "[", "feature_index", "]", "]", ",", "\n", "self", ".", "feature_sizes", "[", "feature_index", "]", ",", "\n", "self", ".", "max_frames", ",", "\n", "max_quantized_value", ",", "\n", "min_quantized_value", ")", "\n", "if", "num_frames", "==", "-", "1", ":", "\n", "        ", "num_frames", "=", "num_frames_in_this_feature", "\n", "", "else", ":", "\n", "        ", "tf", ".", "assert_equal", "(", "num_frames", ",", "num_frames_in_this_feature", ")", "\n", "\n", "", "feature_matrices", "[", "feature_index", "]", "=", "feature_matrix", "\n", "\n", "# cap the number of frames at self.max_frames", "\n", "", "num_frames", "=", "tf", ".", "minimum", "(", "num_frames", ",", "self", ".", "max_frames", ")", "\n", "\n", "# concatenate different features", "\n", "video_matrix", "=", "tf", ".", "concat", "(", "feature_matrices", ",", "1", ")", "\n", "\n", "# convert to batch format.", "\n", "# TODO: Do proper batch reads to remove the IO bottleneck.", "\n", "batch_video_ids", "=", "tf", ".", "expand_dims", "(", "contexts", "[", "\"video_id\"", "]", ",", "0", ")", "\n", "batch_video_matrix", "=", "tf", ".", "expand_dims", "(", "video_matrix", ",", "0", ")", "\n", "batch_labels", "=", "tf", ".", "expand_dims", "(", "labels", ",", "0", ")", "\n", "batch_frames", "=", "tf", ".", "expand_dims", "(", "num_frames", ",", "0", ")", "\n", "\n", "return", "batch_video_ids", ",", "batch_video_matrix", ",", "batch_labels", ",", "batch_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.resize_axis": [[21, 57], ["tensorflow.convert_to_tensor", "tensorflow.unstack", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.stack", "tensorflow.concat", "tf.convert_to_tensor.get_shape().as_list", "tf.concat.set_shape", "tensorflow.shape", "tensorflow.slice", "tensorflow.fill", "tf.convert_to_tensor.get_shape", "tensorflow.zeros_like", "tensorflow.stack", "tensorflow.cast"], "function", ["None"], ["def", "resize_axis", "(", "tensor", ",", "axis", ",", "new_size", ",", "fill_value", "=", "0", ")", ":", "\n", "  ", "\"\"\"Truncates or pads a tensor to new_size on on a given axis.\n\n  Truncate or extend tensor such that tensor.shape[axis] == new_size. If the\n  size increases, the padding will be performed at the end, using fill_value.\n\n  Args:\n    tensor: The tensor to be resized.\n    axis: An integer representing the dimension to be sliced.\n    new_size: An integer or 0d tensor representing the new value for\n      tensor.shape[axis].\n    fill_value: Value to use to fill any new entries in the tensor. Will be\n      cast to the type of tensor.\n\n  Returns:\n    The resized tensor.\n  \"\"\"", "\n", "tensor", "=", "tf", ".", "convert_to_tensor", "(", "tensor", ")", "\n", "shape", "=", "tf", ".", "unstack", "(", "tf", ".", "shape", "(", "tensor", ")", ")", "\n", "\n", "pad_shape", "=", "shape", "[", ":", "]", "\n", "pad_shape", "[", "axis", "]", "=", "tf", ".", "maximum", "(", "0", ",", "new_size", "-", "shape", "[", "axis", "]", ")", "\n", "\n", "shape", "[", "axis", "]", "=", "tf", ".", "minimum", "(", "shape", "[", "axis", "]", ",", "new_size", ")", "\n", "shape", "=", "tf", ".", "stack", "(", "shape", ")", "\n", "\n", "resized", "=", "tf", ".", "concat", "(", "[", "\n", "tf", ".", "slice", "(", "tensor", ",", "tf", ".", "zeros_like", "(", "shape", ")", ",", "shape", ")", ",", "\n", "tf", ".", "fill", "(", "tf", ".", "stack", "(", "pad_shape", ")", ",", "tf", ".", "cast", "(", "fill_value", ",", "tensor", ".", "dtype", ")", ")", "\n", "]", ",", "axis", ")", "\n", "\n", "# Update shape.", "\n", "new_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "# A copy is being made.", "\n", "new_shape", "[", "axis", "]", "=", "new_size", "\n", "resized", ".", "set_shape", "(", "new_shape", ")", "\n", "return", "resized", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.infer2.format_lines": [[68, 78], ["len", "range", "int", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "#top_indices = numpy.argpartition(predictions[video_index], -top_k)[-top_k:]", "\n", "#line = [(class_index, predictions[video_index][class_index])", "\n", "#        for class_index in top_indices]", "\n", "#line = sorted(line, key=lambda p: -p[1])", "\n", "#yield video_ids[video_index].decode('utf-8') + \",\" + \" \".join(\"%i %f\" % pair", "\n", "#                                                  for pair in line) + \"\\n\"", "\n", "    ", "yield", "int", "(", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", ")", ",", "predictions", "[", "video_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.infer2.get_input_data_tensors": [[80, 114], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.infer2.inference": [[115, 205], ["tensorflow.Session", "tensorflow.gfile.Open", "infer2.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "infer2.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "# keep_prob = tf.get_collection(\"keep_prob\")[0]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "import", "numpy", "as", "np", "\n", "final", "=", "[", "]", "\n", "\n", "### DEBUG", "\n", "#cnt = 0", "\n", "try", ":", "\n", "#import numpy as np", "\n", "#final = []", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "##DEBUG", "\n", "#tang = sess.run(keep_prob)", "\n", "#print 'keep_prob is' + str(tang)", "\n", "###", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "#for line in format_lines(video_id_batch_val, predictions_val, top_k):", "\n", "#  out_file.write(line)", "\n", "for", "index", ",", "pred", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "#print pred, pred.shape, index", "\n", "            ", "pred", "=", "pred", ".", "tolist", "(", ")", "\n", "pred", ".", "append", "(", "index", ")", "\n", "### DEBUG", "\n", "#print pred", "\n", "final", ".", "append", "(", "pred", ")", "\n", "### DEBUG", "\n", "#cnt = cnt + 1", "\n", "#if cnt == 100:", "\n", "# break", "\n", "#break", "\n", "#print final", "\n", "#final = np.array(final)", "\n", "#np.save('/mnt/share2/tangtest/youtube-8m/niubige.npy',final)", "\n", "#exit(0)", "\n", "#out_file.flush()", "\n", "#final = np.array(final)", "\n", "#np.save('/mnt/share2/tangtest/youtube-8m/niubige.npy',final)", "\n", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "final", "=", "np", ".", "array", "(", "final", ")", "\n", "np", ".", "save", "(", "'/mnt/share2/tangluming/youtube-8m/niubi2ge.npy'", ",", "final", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.infer2.main": [[207, 231], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "infer2.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.__init__": [[29, 38], ["tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "export_model.ModelExporter.build_inputs_and_outputs", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.Graph", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_inputs_and_outputs"], ["  ", "def", "__init__", "(", "self", ",", "frame_features", ",", "model", ",", "reader", ")", ":", "\n", "    ", "self", ".", "frame_features", "=", "frame_features", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "      ", "self", ".", "inputs", ",", "self", ".", "outputs", "=", "self", ".", "build_inputs_and_outputs", "(", ")", "\n", "self", ".", "graph", "=", "graph", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ",", "sharded", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.export_model": [[39, 61], ["export_model.ModelExporter.graph.as_default", "tensorflow.Session", "tensorflow.Session", "session.run", "export_model.ModelExporter.saver.restore", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.signature_def_utils.build_signature_def", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder", "tensorflow.python.saved_model.builder.SavedModelBuilder.add_meta_graph_and_variables", "tensorflow.python.saved_model.builder.SavedModelBuilder.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "export_model", "(", "self", ",", "model_dir", ",", "global_step_val", ",", "last_checkpoint", ")", ":", "\n", "    ", "\"\"\"Exports the model so that it can used for batch predictions.\"\"\"", "\n", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "      ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "saver", ".", "restore", "(", "session", ",", "last_checkpoint", ")", "\n", "\n", "signature", "=", "signature_def_utils", ".", "build_signature_def", "(", "\n", "inputs", "=", "self", ".", "inputs", ",", "\n", "outputs", "=", "self", ".", "outputs", ",", "\n", "method_name", "=", "signature_constants", ".", "PREDICT_METHOD_NAME", ")", "\n", "\n", "signature_map", "=", "{", "signature_constants", ".", "DEFAULT_SERVING_SIGNATURE_DEF_KEY", ":", "\n", "signature", "}", "\n", "\n", "model_builder", "=", "saved_model_builder", ".", "SavedModelBuilder", "(", "model_dir", ")", "\n", "model_builder", ".", "add_meta_graph_and_variables", "(", "session", ",", "\n", "tags", "=", "[", "tag_constants", ".", "SERVING", "]", ",", "\n", "signature_def_map", "=", "signature_map", ",", "\n", "clear_devices", "=", "True", ")", "\n", "model_builder", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_inputs_and_outputs": [[62, 86], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.placeholder", "tensorflow.placeholder", "export_model.ModelExporter.build_prediction_graph", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "tensorflow.python.saved_model.utils.build_tensor_info", "export_model.ModelExporter.build_prediction_graph"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph"], ["", "", "", "def", "build_inputs_and_outputs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "frame_features", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "fn", "=", "lambda", "x", ":", "self", ".", "build_prediction_graph", "(", "x", ")", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "tf", ".", "map_fn", "(", "fn", ",", "serialized_examples", ",", "\n", "dtype", "=", "(", "tf", ".", "string", ",", "tf", ".", "int32", ",", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "      ", "serialized_examples", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "video_id_output", ",", "top_indices_output", ",", "top_predictions_output", "=", "(", "\n", "self", ".", "build_prediction_graph", "(", "serialized_examples", ")", ")", "\n", "\n", "", "inputs", "=", "{", "\"example_bytes\"", ":", "\n", "saved_model_utils", ".", "build_tensor_info", "(", "serialized_examples", ")", "}", "\n", "\n", "outputs", "=", "{", "\n", "\"video_id\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "video_id_output", ")", ",", "\n", "\"class_indexes\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_indices_output", ")", ",", "\n", "\"predictions\"", ":", "saved_model_utils", ".", "build_tensor_info", "(", "top_predictions_output", ")", "}", "\n", "\n", "return", "inputs", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.export_model.ModelExporter.build_prediction_graph": [[87, 111], ["export_model.ModelExporter.reader.prepare_serialized_examples", "tensorflow.nn.l2_normalize", "tensorflow.nn.l2_normalize", "len", "tensorflow.variable_scope", "tensorflow.variable_scope", "export_model.ModelExporter.model.create_model", "tensorflow.get_model_variables", "tensorflow.get_model_variables", "tensorflow.nn.top_k", "tensorflow.nn.top_k", "model_input_raw.get_shape", "tensorflow.summary.histogram", "tensorflow.summary.histogram"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_serialized_examples", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model"], ["", "def", "build_prediction_graph", "(", "self", ",", "serialized_examples", ")", ":", "\n", "    ", "video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "self", ".", "reader", ".", "prepare_serialized_examples", "(", "serialized_examples", ")", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "      ", "result", "=", "self", ".", "model", ".", "create_model", "(", "\n", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "self", ".", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "\n", "top_predictions", ",", "top_indices", "=", "tf", ".", "nn", ".", "top_k", "(", "predictions", ",", "\n", "_TOP_PREDICTIONS_IN_OUTPUT", ")", "\n", "", "return", "video_id", ",", "top_indices", ",", "top_predictions", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.__init__": [[48, 70], ["range", "ValueError", "mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators.append", "isinstance", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ")", ":", "\n", "    ", "\"\"\"Construct a calculator to calculate the (macro) average precision.\n\n    Args:\n      num_class: A positive Integer specifying the number of classes.\n      top_n_array: A list of positive integers specifying the top n for each\n      class. The top n in each class will be used to calculate its average\n      precision at n.\n      The size of the array must be num_class.\n\n    Raises:\n      ValueError: An error occurred when num_class is not a positive integer;\n      or the top_n_array is not a list of positive integers.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "num_class", ",", "int", ")", "or", "num_class", "<=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"num_class must be a positive integer.\"", ")", "\n", "\n", "", "self", ".", "_ap_calculators", "=", "[", "]", "# member of AveragePrecisionCalculator", "\n", "self", ".", "_num_class", "=", "num_class", "# total number of classes", "\n", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "      ", "self", ".", "_ap_calculators", ".", "append", "(", "\n", "average_precision_calculator", ".", "AveragePrecisionCalculator", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.accumulate": [[71, 94], ["range", "len", "calculators[].accumulate"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate"], ["", "", "def", "accumulate", "(", "self", ",", "predictions", ",", "actuals", ",", "num_positives", "=", "None", ")", ":", "\n", "    ", "\"\"\"Accumulate the predictions and their ground truth labels.\n\n    Args:\n      predictions: A list of lists storing the prediction scores. The outer\n      dimension corresponds to classes.\n      actuals: A list of lists storing the ground truth labels. The dimensions\n      should correspond to the predictions input. Any value\n      larger than 0 will be treated as positives, otherwise as negatives.\n      num_positives: If provided, it is a list of numbers representing the\n      number of true positives for each class. If not provided, the number of\n      true positives will be inferred from the 'actuals' array.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n      does not match.\n    \"\"\"", "\n", "if", "not", "num_positives", ":", "\n", "      ", "num_positives", "=", "[", "None", "for", "i", "in", "predictions", ".", "shape", "[", "1", "]", "]", "\n", "\n", "", "calculators", "=", "self", ".", "_ap_calculators", "\n", "for", "i", "in", "range", "(", "len", "(", "predictions", ")", ")", ":", "\n", "      ", "calculators", "[", "i", "]", ".", "accumulate", "(", "predictions", "[", "i", "]", ",", "actuals", "[", "i", "]", ",", "num_positives", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.clear": [[95, 98], ["calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "", "def", "clear", "(", "self", ")", ":", "\n", "    ", "for", "calculator", "in", "self", ".", "_ap_calculators", ":", "\n", "      ", "calculator", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.is_empty": [[99, 102], ["range"], "methods", ["None"], ["", "", "def", "is_empty", "(", "self", ")", ":", "\n", "    ", "return", "(", "[", "calculator", ".", "heap_size", "for", "calculator", "in", "self", ".", "_ap_calculators", "]", "==", "\n", "[", "0", "for", "_", "in", "range", "(", "self", ".", "_num_class", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n": [[103, 113], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator._ap_calculators[].peek_ap_at_n", "range"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "peek_map_at_n", "(", "self", ")", ":", "\n", "    ", "\"\"\"Peek the non-interpolated mean average precision at n.\n\n    Returns:\n      An array of non-interpolated average precision at n (default 0) for each\n      class.\n    \"\"\"", "\n", "aps", "=", "[", "self", ".", "_ap_calculators", "[", "i", "]", ".", "peek_ap_at_n", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_class", ")", "]", "\n", "return", "aps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.__init__": [[362, 386], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.run": [[391, 495], ["forzhao_train.Trainer.start_server_if_distributed", "forzhao_train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "forzhao_train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "forzhao_train.task_as_string", "tensorflow.train.Supervisor.managed_session", "forzhao_train.task_as_string", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.Trainer.restore", "tensorflow.Graph", "tensorflow.Graph", "forzhao_train.Trainer.recover_model", "forzhao_train.Trainer.build_model", "forzhao_train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "forzhao_train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "forzhao_train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "latest_checkpoint", ",", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "if", "not", "FLAGS", ".", "change_file", ":", "\n", "          ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "", "if", "FLAGS", ".", "change_file", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:restoring\"", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.export_model": [[496, 512], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.Trainer.model_exporter.export_model", "forzhao_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.start_server_if_distributed": [[513, 529], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "forzhao_train.task_as_string", "forzhao_train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.remove_training_directory": [[530, 542], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "forzhao_train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "forzhao_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.get_meta_filename": [[543, 562], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.task_as_string", "forzhao_train.task_as_string", "forzhao_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "latest_checkpoint", ",", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.recover_model": [[563, 567], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "forzhao_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.Trainer.build_model": [[568, 589], ["forzhao_train.find_class_by_name", "forzhao_train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "forzhao_train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.ParameterServer.__init__": [[609, 620], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.ParameterServer.run": [[621, 628], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_train.start_server", "start_server.join", "forzhao_train.task_as_string", "forzhao_train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.validate_class_name": [[114, 141], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.get_input_data_tensors": [[142, 185], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.find_class_by_name": [[187, 191], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.build_graph": [[192, 358], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "forzhao_train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "constant", "(", "FLAGS", ".", "keep_prob", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "keep_prob", "=", "keep_prob", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"features\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"keep_prob\"", ",", "keep_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.get_reader": [[591, 604], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.start_server": [[630, 652], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "forzhao_train.task_as_string", "forzhao_train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.task_as_string": [[653, 655], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_train.main": [[656, 694], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "forzhao_train.task_as_string", "forzhao_train.get_reader", "export_model.ModelExporter", "forzhao_train.Trainer.run", "forzhao_train.find_class_by_name", "forzhao_train.ParameterServer.run", "ValueError", "forzhao_train.Trainer", "forzhao_train.ParameterServer", "forzhao_train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature_forzhao.format_lines": [[72, 98], ["len", "range", "tensorflow.train.Example", "numpy.nonzero", "tf.train.Example.SerializeToString", "tensorflow.train.Features", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.BytesList", "tensorflow.train.Int64List", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "features", ",", "labels", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "#    top_indices = numpy.argpartition(predictions[video_index], -top_k)[-top_k:]", "\n", "#    line = [(class_index, predictions[video_index][class_index])", "\n", "#            for class_index in top_indices]", "\n", "#    line = sorted(line, key=lambda p: -p[1])", "\n", "#    yield video_ids[video_index].decode('utf-8') + \",\" + \" \".join(\"%i %f\" % pair", "\n", "#                                                  for pair in line) + \"\\n\"", "\n", "    ", "raw_label", "=", "numpy", ".", "nonzero", "(", "labels", "[", "video_index", "]", ")", "[", "0", "]", "\n", "raw_id", "=", "video_ids", "[", "video_index", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "#\"labels\":tf.train.Feature(int64_list=tf.train.Int64List(value=raw_label)),", "\n", "\"video_id\"", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "raw_id", "]", ")", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "raw_label", ")", ")", ",", "\n", "FLAGS", ".", "feature_name", ":", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "features", "[", "video_index", "]", ")", ")", "\n", "}", ")", ")", "\n", "\n", "#print \"video_id:\"", "\n", "#print video_ids[video_index]", "\n", "#print \"raw_label:\"", "\n", "#print raw_label", "\n", "#print \"saving feature...\"", "\n", "#numpy.save(\"/mnt/share4/tangluming/feature_new/feature_new_\"+str(video_index)+\".npy\",features[video_index])", "\n", "\n", "yield", "example", ".", "SerializeToString", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature_forzhao.get_input_data_tensors": [[100, 134], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "unused_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature_forzhao.inference": [[135, 224], ["tensorflow.Session", "tensorflow.python_io.TFRecordWriter", "write_feature_forzhao.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "write_feature_forzhao.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "#with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess, gfile.Open(out_file_location, \"w+\") as out_file:", "\n", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "out_file_location", ")", "as", "out_file", ":", "\n", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "#keep_prob = tf.get_collection(\"keep_prob\")[0]", "\n", "features", "=", "tf", ".", "get_collection", "(", "\"features\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "#out_file.write(\"VideoId,LabelConfidencePairs\\n\")", "\n", "\n", "#tang = 0", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", ",", "labels_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "]", ")", "\n", "predictions_val", ",", "features_val", "=", "sess", ".", "run", "(", "[", "predictions_tensor", ",", "features", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "#for line in format_lines(video_id_batch_val, predictions_val, top_k):", "\n", "#print \"tang info:\"", "\n", "\n", "#print \"id_batch\"", "\n", "#print video_id_batch_val", "\n", "#print type(video_id_batch_val)", "\n", "#print numpy.shape(video_id_batch_val)", "\n", "\n", "#print \"feature_batch\"", "\n", "#print features_val", "\n", "#print type(features_val)", "\n", "#print numpy.shape(features_val)", "\n", "\n", "#print \"label_batch\"", "\n", "#print labels_batch_val", "\n", "#print type(labels_batch_val)", "\n", "#print numpy.shape(labels_batch_val)", "\n", "#print numpy.nonzero(labels_batch_val)", "\n", "for", "sample", "in", "format_lines", "(", "video_id_batch_val", ",", "features_val", ",", "labels_batch_val", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "sample", ")", "\n", "#tang+=1", "\n", "#out_file.flush()", "\n", "\n", "#if tang>10000:", "\n", "#  break", "\n", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature_forzhao.main": [[226, 250], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "write_feature_forzhao.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.zhaozhao_infer.format_lines": [[73, 89], ["len", "range", "label_str.strip.strip", "sorted", "numpy.nonzero", "numpy.argpartition", "str", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ",", "labels", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "    ", "raw_label", "=", "numpy", ".", "nonzero", "(", "labels", "[", "video_index", "]", ")", "[", "0", "]", "\n", "label_str", "=", "\"\"", "\n", "for", "i", "in", "raw_label", ":", "\n", "      ", "label_str", "+=", "str", "(", "i", ")", "+", "\",\"", "\n", "", "label_str", "=", "label_str", ".", "strip", "(", "\",\"", ")", "\n", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "'\\t'", "+", "label_str", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.zhaozhao_infer.get_input_data_tensors": [[91, 125], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "unused_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.zhaozhao_infer.inference": [[126, 190], ["tensorflow.Session", "tensorflow.gfile.Open", "zhaozhao_infer.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "zhaozhao_infer.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "FLAGS", ".", "clear_device", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "get_collection", "(", "\"keep_prob\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", ",", "labels_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", ",", "keep_prob", ":", "FLAGS", ".", "keep_prob", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ",", "labels_batch_val", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "break", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.zhaozhao_infer.main": [[192, 216], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "zhaozhao_infer.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.__init__": [[365, 389], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.run": [[394, 503], ["copy_graph.Trainer.start_server_if_distributed", "copy_graph.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "copy_graph.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "copy_graph.task_as_string", "tensorflow.train.Supervisor.managed_session", "copy_graph.task_as_string", "tensorflow.device", "tensorflow.device", "copy_graph.Trainer.build_model", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "sys.exit", "tensorflow.Graph", "tensorflow.Graph", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "copy_graph.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "int", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "copy_graph.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "copy_graph.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "latest_checkpoint", ",", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "#if meta_filename:", "\n", "#  if not FLAGS.change_file:", "\n", "#    saver = self.recover_model(meta_filename)", "\n", "\n", "      ", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "#        if not meta_filename:", "\n", "#          saver = self.build_model(self.model, self.reader)", "\n", "#        if FLAGS.change_file:", "\n", "        ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:restoring\"", ")", "\n", "sv", ".", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:saving model\"", ")", "\n", "sv", ".", "saver", ".", "save", "(", "sess", ",", "sv", ".", "save_path", ",", "int", "(", "FLAGS", ".", "checkpoint_name", ")", "+", "1", ")", "\n", "logging", ".", "info", "(", "\"TANG:SAVING OVER\"", ")", "\n", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.export_model": [[504, 520], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "copy_graph.Trainer.model_exporter.export_model", "copy_graph.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.start_server_if_distributed": [[521, 537], ["tensorflow.logging.info", "tensorflow.logging.info", "copy_graph.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "copy_graph.task_as_string", "copy_graph.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.remove_training_directory": [[538, 550], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "copy_graph.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "copy_graph.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.get_meta_filename": [[551, 571], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "copy_graph.task_as_string", "copy_graph.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "#latest_checkpoint = tf.train.latest_checkpoint(train_dir)", "\n", "#if not latest_checkpoint:", "\n", "#  logging.info(\"%s: No checkpoint file found. Building a new model.\",", "\n", "#               task_as_string(self.task))", "\n", "#  return None", "\n", "\n", "", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "latest_checkpoint", ",", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.recover_model": [[572, 576], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "copy_graph.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.Trainer.build_model": [[577, 598], ["copy_graph.find_class_by_name", "copy_graph.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "copy_graph.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.ParameterServer.__init__": [[618, 629], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.ParameterServer.run": [[630, 637], ["tensorflow.logging.info", "tensorflow.logging.info", "copy_graph.start_server", "start_server.join", "copy_graph.task_as_string", "copy_graph.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.validate_class_name": [[116, 143], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.get_input_data_tensors": [[144, 187], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.find_class_by_name": [[189, 193], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.build_graph": [[194, 361], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "copy_graph.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "constant", "(", "FLAGS", ".", "keep_prob", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "keep_prob", "=", "keep_prob", "\n", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"features\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"keep_prob\"", ",", "keep_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.get_reader": [[600, 613], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.start_server": [[639, 661], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "copy_graph.task_as_string", "copy_graph.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.task_as_string": [[662, 664], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.copy_graph.main": [[665, 703], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "copy_graph.task_as_string", "copy_graph.get_reader", "export_model.ModelExporter", "copy_graph.Trainer.run", "copy_graph.find_class_by_name", "copy_graph.ParameterServer.run", "ValueError", "copy_graph.Trainer", "copy_graph.ParameterServer", "copy_graph.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomSequence": [[23, 49], ["tensorflow.tile", "tensorflow.maximum", "tensorflow.cast", "tensorflow.minimum", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.multiply", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.random_uniform", "tensorflow.cast", "tensorflow.range"], "function", ["None"], ["def", "SampleRandomSequence", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random sequence of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index_offset", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "num_samples", ")", ",", "0", ")", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "max_start_frame_index", "=", "tf", ".", "maximum", "(", "num_frames", "-", "num_samples", ",", "0", ")", "\n", "start_frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", "]", ")", ",", "\n", "tf", ".", "cast", "(", "max_start_frame_index", "+", "1", ",", "tf", ".", "float32", ")", ")", ",", "tf", ".", "int32", ")", "\n", "frame_index", "=", "tf", ".", "minimum", "(", "start_frame_index", "+", "frame_index_offset", ",", "\n", "tf", ".", "cast", "(", "num_frames", "-", "1", ",", "tf", ".", "int32", ")", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.SampleRandomFrames": [[51, 71], ["tensorflow.cast", "tensorflow.tile", "tensorflow.stack", "tensorflow.gather_nd", "tensorflow.shape", "tensorflow.multiply", "tensorflow.expand_dims", "tensorflow.random_uniform", "tensorflow.tile", "tensorflow.range", "tensorflow.cast"], "function", ["None"], ["", "def", "SampleRandomFrames", "(", "model_input", ",", "num_frames", ",", "num_samples", ")", ":", "\n", "  ", "\"\"\"Samples a random set of frames of size num_samples.\n\n  Args:\n    model_input: A tensor of size batch_size x max_frames x feature_size\n    num_frames: A tensor of size batch_size x 1\n    num_samples: A scalar\n\n  Returns:\n    `model_input`: A tensor of size batch_size x num_samples x feature_size\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "frame_index", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "multiply", "(", "\n", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "num_samples", "]", ")", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "cast", "(", "num_frames", ",", "tf", ".", "float32", ")", ",", "[", "1", ",", "num_samples", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "batch_index", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "batch_size", ")", ",", "1", ")", ",", "[", "1", ",", "num_samples", "]", ")", "\n", "index", "=", "tf", ".", "stack", "(", "[", "batch_index", ",", "frame_index", "]", ",", "2", ")", "\n", "return", "tf", ".", "gather_nd", "(", "model_input", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.model_utils.FramePooling": [[72, 96], ["tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reshape", "ValueError", "frames.shape_as_list"], "function", ["None"], ["", "def", "FramePooling", "(", "frames", ",", "method", ",", "**", "unused_params", ")", ":", "\n", "  ", "\"\"\"Pools over the frames of a video.\n\n  Args:\n    frames: A tensor with shape [batch_size, num_frames, feature_size].\n    method: \"average\", \"max\", \"attention\", or \"none\".\n  Returns:\n    A tensor with shape [batch_size, feature_size] for average, max, or\n    attention pooling. A tensor with shape [batch_size*num_frames, feature_size]\n    for none pooling.\n\n  Raises:\n    ValueError: if method is other than \"average\", \"max\", \"attention\", or\n    \"none\".\n  \"\"\"", "\n", "if", "method", "==", "\"average\"", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"max\"", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "frames", ",", "1", ")", "\n", "", "elif", "method", "==", "\"none\"", ":", "\n", "    ", "feature_size", "=", "frames", ".", "shape_as_list", "(", ")", "[", "2", "]", "\n", "return", "tf", ".", "reshape", "(", "frames", ",", "[", "-", "1", ",", "feature_size", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unrecognized pooling method: %s\"", "%", "method", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature.format_lines": [[71, 90], ["len", "range", "tensorflow.train.Example", "numpy.nonzero", "tf.train.Example.SerializeToString", "tensorflow.train.Features", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.Feature", "tensorflow.train.BytesList", "tensorflow.train.Int64List", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "features", ",", "labels", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "#    top_indices = numpy.argpartition(predictions[video_index], -top_k)[-top_k:]", "\n", "#    line = [(class_index, predictions[video_index][class_index])", "\n", "#            for class_index in top_indices]", "\n", "#    line = sorted(line, key=lambda p: -p[1])", "\n", "#    yield video_ids[video_index].decode('utf-8') + \",\" + \" \".join(\"%i %f\" % pair", "\n", "#                                                  for pair in line) + \"\\n\"", "\n", "    ", "raw_label", "=", "numpy", ".", "nonzero", "(", "labels", "[", "video_index", "]", ")", "[", "0", "]", "\n", "raw_id", "=", "video_ids", "[", "video_index", "]", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "#\"labels\":tf.train.Feature(int64_list=tf.train.Int64List(value=raw_label)),", "\n", "\"video_id\"", ":", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "raw_id", "]", ")", ")", ",", "\n", "\"labels\"", ":", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "raw_label", ")", ")", ",", "\n", "\"plstm\"", ":", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "features", "[", "video_index", "]", ")", ")", "\n", "}", ")", ")", "\n", "\n", "yield", "example", ".", "SerializeToString", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature.get_input_data_tensors": [[92, 126], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "unused_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature.inference": [[127, 216], ["tensorflow.Session", "tensorflow.python_io.TFRecordWriter", "write_feature.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "write_feature.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "#with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess, gfile.Open(out_file_location, \"w+\") as out_file:", "\n", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "out_file_location", ")", "as", "out_file", ":", "\n", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "FLAGS", ".", "clear_device", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "get_collection", "(", "\"keep_prob\"", ")", "[", "0", "]", "\n", "features", "=", "tf", ".", "get_collection", "(", "\"features\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "#out_file.write(\"VideoId,LabelConfidencePairs\\n\")", "\n", "\n", "#tang = 0", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", ",", "labels_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", ",", "labels_batch", "]", ")", "\n", "predictions_val", ",", "features_val", "=", "sess", ".", "run", "(", "[", "predictions_tensor", ",", "features", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", ",", "keep_prob", ":", "1.0", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "#for line in format_lines(video_id_batch_val, predictions_val, top_k):", "\n", "#print \"tang info:\"", "\n", "\n", "#print \"id_batch\"", "\n", "#print video_id_batch_val", "\n", "#print type(video_id_batch_val)", "\n", "#print numpy.shape(video_id_batch_val)", "\n", "\n", "#print \"feature_batch\"", "\n", "#print features_val", "\n", "#print type(features_val)", "\n", "#print numpy.shape(features_val)", "\n", "\n", "#print \"label_batch\"", "\n", "#print labels_batch_val", "\n", "#print type(labels_batch_val)", "\n", "#print numpy.shape(labels_batch_val)", "\n", "#print numpy.nonzero(labels_batch_val)", "\n", "for", "sample", "in", "format_lines", "(", "video_id_batch_val", ",", "features_val", ",", "labels_batch_val", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "sample", ")", "\n", "#tang+=1", "\n", "#out_file.flush()", "\n", "\n", "#if tang>10000:", "\n", "#  break", "\n", "\n", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.write_feature.main": [[218, 242], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "write_feature.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.find_class_by_name": [[73, 77], ["next", "getattr"], "function", ["None"], ["  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.get_input_evaluation_tensors": [[79, 116], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["data_pattern", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the evaluation data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for evaluation.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"eval_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find the evaluation files.\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of evaluation files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "shuffle", "=", "False", ",", "num_epochs", "=", "1", ")", "\n", "eval_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "return", "tf", ".", "train", ".", "batch_join", "(", "\n", "eval_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "3", "*", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.build_graph": [[118, 171], ["tensorflow.Variable", "eval.get_input_evaluation_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "len", "tensorflow.variable_scope", "model.create_model", "tensorflow.summary.histogram", "tensorflow.cast", "tensorflow.summary.merge_all", "model_input_raw.get_shape", "model.create_model.keys", "label_loss_fn.calculate_loss"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.get_input_evaluation_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["model", ",", "\n", "eval_data_pattern", ",", "\n", "label_loss_fn", ",", "\n", "batch_size", "=", "1024", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph for evaluation.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    eval_data_pattern: glob path to the evaluation data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    num_readers: How many threads to use for I/O operations.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "video_id_batch", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "get_input_evaluation_tensors", "(", "# pylint: disable=g-line-too-long", "\n", "reader", ",", "\n", "eval_data_pattern", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_readers", "=", "num_readers", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "# Normalize input features.", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "# CCMoe", "\n", "phase", "=", "tf", ".", "constant", "(", "False", ",", "name", "=", "\"phase\"", ")", "\n", "#", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"tower\"", ")", ":", "\n", "    ", "result", "=", "model", ".", "create_model", "(", "model_input", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "labels_batch", ",", "\n", "is_training", "=", "phase", ")", "\n", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model_activations\"", ",", "predictions", ")", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "      ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "      ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "labels_batch", ")", "\n", "\n", "", "", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "predictions", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"video_id_batch\"", ",", "video_id_batch", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluation_loop": [[173, 276], ["tensorflow.Session", "sess.run", "tensorflow.train.Coordinator", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.logging.info", "evl_metrics.clear", "[].split", "tensorflow.local_variables_initializer", "threads.extend", "tf.train.Coordinator.should_stop", "time.time", "sess.run", "evl_metrics.accumulate", "utils.AddGlobalStepSummary", "tensorflow.logging.info", "tensorflow.logging.info", "evl_metrics.get", "summary_writer.add_summary", "utils.AddEpochSummary", "tensorflow.logging.info", "evl_metrics.clear", "tensorflow.logging.info", "tf.train.Coordinator.request_stop", "qr.create_threads", "time.time", "str", "tf.train.latest_checkpoint.split"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddGlobalStepSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddEpochSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["tf", ".", "add_to_collection", "(", "\"summary_op\"", ",", "tf", ".", "summary", ".", "merge_all", "(", ")", ")", "\n", "# CCMoe", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n", "\n", "\n", "", "def", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "\n", "summary_op", ",", "saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", ":", "\n", "  ", "\"\"\"Run the evaluation loop once.\n\n  Args:\n    video_id_batch: a tensor of video ids mini-batch.\n    prediction_batch: a tensor of predictions mini-batch.\n    label_batch: a tensor of label_batch mini-batch.\n    loss: a tensor of loss for the examples in the mini-batch.\n    summary_op: a tensor which runs the tensorboard summary operations.\n    saver: a tensorflow saver to restore the model.\n    summary_writer: a tensorflow summary_writer\n    evl_metrics: an EvaluationMetrics object.\n    last_global_step_val: the global step used in the previous evaluation.\n\n  Returns:\n    The global_step used in the latest model.\n  \"\"\"", "\n", "\n", "global_step_val", "=", "-", "1", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "if", "FLAGS", ".", "certain_step", "!=", "\"Latest\"", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"/\"", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "certain_step", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "if", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading checkpoint for eval: \"", "+", "latest_checkpoint", ")", "\n", "# Restores from checkpoint", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "# Assuming model_checkpoint_path looks something like:", "\n", "# /my-favorite-path/yt8m_train/model.ckpt-0, extract global_step from it.", "\n", "global_step_val", "=", "latest_checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"No checkpoint file found.\"", ")", "\n", "return", "global_step_val", "\n", "\n", "", "if", "global_step_val", "==", "last_global_step_val", ":", "\n", "      ", "logging", ".", "info", "(", "\"skip this checkpoint global_step_val=%s \"", "\n", "\"(same as the previous one).\"", ",", "global_step_val", ")", "\n", "return", "global_step_val", "\n", "\n", "", "sess", ".", "run", "(", "[", "tf", ".", "local_variables_initializer", "(", ")", "]", ")", "\n", "\n", "# Start the queue runners.", "\n", "fetches", "=", "[", "video_id_batch", ",", "prediction_batch", ",", "label_batch", ",", "loss", ",", "summary_op", "]", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "try", ":", "\n", "      ", "threads", "=", "[", "]", "\n", "for", "qr", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "QUEUE_RUNNERS", ")", ":", "\n", "        ", "threads", ".", "extend", "(", "qr", ".", "create_threads", "(", "\n", "sess", ",", "coord", "=", "coord", ",", "daemon", "=", "True", ",", "\n", "start", "=", "True", ")", ")", "\n", "", "logging", ".", "info", "(", "\"enter eval_once loop global_step_val = %s. \"", ",", "\n", "global_step_val", ")", "\n", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "\n", "examples_processed", "=", "0", "\n", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "predictions_val", ",", "labels_val", ",", "loss_val", ",", "summary_val", "=", "sess", ".", "run", "(", "\n", "fetches", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "example_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "examples_processed", "+=", "labels_val", ".", "shape", "[", "0", "]", "\n", "\n", "iteration_info_dict", "=", "evl_metrics", ".", "accumulate", "(", "predictions_val", ",", "\n", "labels_val", ",", "loss_val", ")", "\n", "iteration_info_dict", "[", "\"examples_per_second\"", "]", "=", "example_per_second", "\n", "\n", "iterinfo", "=", "utils", ".", "AddGlobalStepSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "iteration_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "\"examples_processed: %d | %s\"", ",", "examples_processed", ",", "\n", "iterinfo", ")", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", "as", "e", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"Done with batched inference. Now calculating global performance \"", "\n", "\"metrics.\"", ")", "\n", "# calculate the metrics for the entire epoch", "\n", "epoch_info_dict", "=", "evl_metrics", ".", "get", "(", ")", "\n", "epoch_info_dict", "[", "\"epoch_id\"", "]", "=", "global_step_val", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary_val", ",", "global_step_val", ")", "\n", "epochinfo", "=", "utils", ".", "AddEpochSummary", "(", "\n", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", "\n", "logging", ".", "info", "(", "epochinfo", ")", "\n", "evl_metrics", ".", "clear", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "\n", "      ", "logging", ".", "info", "(", "\"Unexpected exception: \"", "+", "str", "(", "e", ")", ")", "\n", "coord", ".", "request_stop", "(", "e", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluate": [[278, 328], ["tensorflow.set_random_seed", "tensorflow.Graph().as_default", "utils.GetListOfFeatureNamesAndSizes", "eval.build_graph", "tensorflow.logging.info", "tensorflow.train.Saver", "tensorflow.summary.FileWriter", "eval_util.EvaluationMetrics", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "eval.find_class_by_name", "eval.find_class_by_name", "IOError", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.global_variables", "eval.evaluation_loop", "tensorflow.Graph", "tensorflow.get_default_graph"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluation_loop"], ["", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ",", "stop_grace_period_secs", "=", "10", ")", "\n", "\n", "return", "global_step_val", "\n", "\n", "\n", "", "", "def", "evaluate", "(", ")", ":", "\n", "  ", "tf", ".", "set_random_seed", "(", "0", ")", "# for reproducibility", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "    ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "      ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "\n", "if", "FLAGS", ".", "eval_data_pattern", "is", "\"\"", ":", "\n", "      ", "raise", "IOError", "(", "\"'eval_data_pattern' was not specified. \"", "+", "\n", "\"Nothing to evaluate.\"", ")", "\n", "\n", "", "build_graph", "(", "\n", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "eval_data_pattern", "=", "FLAGS", ".", "eval_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "logging", ".", "info", "(", "\"built evaluation graph\"", ")", "\n", "video_id_batch", "=", "tf", ".", "get_collection", "(", "\"video_id_batch\"", ")", "[", "0", "]", "\n", "prediction_batch", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "label_batch", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "summary_op", "=", "tf", ".", "get_collection", "(", "\"summary_op\"", ")", "[", "0", "]", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "\n", "FLAGS", ".", "train_dir", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "evl_metrics", "=", "eval_util", ".", "EvaluationMetrics", "(", "reader", ".", "num_classes", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "last_global_step_val", "=", "-", "1", "\n", "while", "True", ":", "\n", "      ", "last_global_step_val", "=", "evaluation_loop", "(", "video_id_batch", ",", "prediction_batch", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.main": [[330, 334], ["tensorflow.logging.set_verbosity", "print", "eval.evaluate"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval.evaluate"], ["saver", ",", "summary_writer", ",", "evl_metrics", ",", "\n", "last_global_step_val", ")", "\n", "if", "FLAGS", ".", "run_once", ":", "\n", "        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.inference.format_lines": [[71, 80], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n", "\n", "", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.inference.get_input_data_tensors": [[82, 116], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n", "", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.inference.inference": [[117, 177], ["tensorflow.Session", "tensorflow.gfile.Open", "inference.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "inference.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n", "\n", "", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.inference.main": [[179, 203], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "inference.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "  ", "app", ".", "run", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.LogisticModel.create_model": [[33, 48], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "model_input", ",", "vocab_size", ",", "l2_penalty", "=", "1e-8", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a logistic model.\n\n    Args:\n      model_input: 'batch' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\"\"\"", "\n", "output", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "vocab_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ")", "\n", "return", "{", "\"predictions\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.MoeModel.create_model": [[52, 105], ["tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Creates a Mixture of (Logistic) Experts model.\n\n     The model consists of a per-class softmax distribution over a\n     configurable number of logistic classifiers. One of the classifiers in the\n     mixture is not trained, and always predicts 0.\n\n    Args:\n      model_input: 'batch_size' x 'num_features' matrix of input features.\n      vocab_size: The number of classes in the dataset.\n      num_mixtures: The number of mixtures (excluding a dummy 'expert' that\n        always predicts the non-existence of an entity).\n      l2_penalty: How much to penalize the squared magnitudes of parameter\n        values.\n    Returns:\n      A dictionary with a tensor containing the probability predictions of the\n      model in the 'predictions' key. The dimensions of the tensor are\n      batch_size x num_classes.\n    \"\"\"", "\n", "num_mixtures", "=", "num_mixtures", "or", "FLAGS", ".", "moe_num_mixtures", "\n", "\n", "gate_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "(", "num_mixtures", "+", "1", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"gates\"", ")", "\n", "expert_activations", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "vocab_size", "*", "num_mixtures", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"experts\"", ")", "\n", "\n", "gating_distribution", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "reshape", "(", "\n", "gate_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "+", "1", "]", ")", ")", "# (Batch * #Labels) x (num_mixtures + 1)", "\n", "expert_distribution", "=", "tf", ".", "nn", ".", "sigmoid", "(", "tf", ".", "reshape", "(", "\n", "expert_activations", ",", "\n", "[", "-", "1", ",", "num_mixtures", "]", ")", ")", "# (Batch * #Labels) x num_mixtures", "\n", "\n", "final_probabilities_by_class_and_batch", "=", "tf", ".", "reduce_sum", "(", "\n", "gating_distribution", "[", ":", ",", ":", "num_mixtures", "]", "*", "expert_distribution", ",", "1", ")", "\n", "final_probabilities", "=", "tf", ".", "reshape", "(", "final_probabilities_by_class_and_batch", ",", "\n", "[", "-", "1", ",", "vocab_size", "]", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "CCModel", "(", "models", ".", "BaseModel", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.new_MoeModel.create_model": [[109, 149], ["tensorflow.dropout", "tensorflow.dropout", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "256", "\n", "state_size", "=", "96", "\n", "batch_size", "=", "tf", ".", "shape", "(", "model_input", ")", "[", "0", "]", "\n", "time_steps", "=", "vocab_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "1", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_response", ")", "\n", "\n", "# paddings = tf.zeros([batch_size, vocab_size - time_steps], dtype=tf.float32)", "\n", "# prob_chains.append(paddings)", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "PartlyCCModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model": [[154, 194], ["tensorflow.dropout", "tensorflow.dropout", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer", "tensorflow.l2_regularizer"], "methods", ["None"], ["time_steps", "=", "vocab_size", "//", "part_size", "\n", "\n", "lstm", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "state_size", ")", "\n", "prob_chains", "=", "[", "]", "\n", "\n", "reduced_feature", "=", "slim", ".", "fully_connected", "(", "\n", "model_input", ",", "\n", "reduce_size", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "l2_penalty", ")", ",", "\n", "scope", "=", "\"reduce\"", ")", "\n", "state", "=", "lstm", ".", "zero_state", "(", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "logistic_weights", "=", "tf", ".", "get_variable", "(", "\"logistic_weights\"", ",", "[", "state_size", ",", "part_size", "]", ",", "initializer", "=", "tf", ".", "random_normal_initializer", "(", ")", ")", "\n", "logistic_biases", "=", "tf", ".", "get_variable", "(", "\"logistic_biases\"", ",", "[", "part_size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "for", "step", "in", "xrange", "(", "time_steps", ")", ":", "\n", "      ", "if", "step", ">", "0", ":", "\n", "        ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "output", ",", "state", "=", "lstm", "(", "reduced_feature", ",", "state", ")", "\n", "binary_part_response", "=", "tf", ".", "sigmoid", "(", "tf", ".", "matmul", "(", "output", ",", "logistic_weights", ")", "+", "logistic_biases", ")", "\n", "prob_chains", ".", "append", "(", "binary_part_response", ")", "\n", "\n", "# paddings = tf.zeros([batch_size, vocab_size - time_steps], dtype=tf.float32)", "\n", "# prob_chains.append(paddings)", "\n", "\n", "", "final_probabilities", "=", "tf", ".", "concat", "(", "prob_chains", ",", "1", ")", "\n", "return", "{", "\"predictions\"", ":", "final_probabilities", "}", "\n", "\n", "", "", "class", "PRCCModel", "(", "models", ".", "BaseModel", ")", ":", "\n", "  ", "\"\"\" \n  Partly Recurring Classifiers Chain\n  \"\"\"", "\n", "def", "create_model", "(", "self", ",", "\n", "model_input", ",", "\n", "vocab_size", ",", "\n", "num_mixtures", "=", "None", ",", "\n", "l2_penalty", "=", "1e-8", ",", "\n", "**", "unused_params", ")", ":", "\n", "    ", "reduce_size", "=", "512", "\n", "state_size", "=", "1024", "\n", "proj_size", "=", "512", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.old_infer.format_lines": [[73, 82], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.old_infer.get_input_data_tensors": [[84, 118], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.old_infer.inference": [[119, 181], ["tensorflow.Session", "tensorflow.gfile.Open", "old_infer.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "old_infer.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "FLAGS", ".", "clear_device", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "#keep_prob = tf.get_collection(\"keep_prob\")[0]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.old_infer.main": [[183, 207], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "old_infer.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.__init__": [[349, 373], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.run": [[378, 474], ["train.Trainer.start_server_if_distributed", "train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "train.task_as_string", "tensorflow.train.Supervisor.managed_session", "train.task_as_string", "train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.Graph", "tensorflow.Graph", "train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "20", "*", "60", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "64", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.export_model": [[475, 491], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "train.Trainer.model_exporter.export_model", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.start_server_if_distributed": [[492, 508], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "train.task_as_string", "train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.remove_training_directory": [[509, 521], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.get_meta_filename": [[522, 541], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "train.task_as_string", "train.task_as_string", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.recover_model": [[542, 546], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.Trainer.build_model": [[547, 568], ["train.find_class_by_name", "train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.ParameterServer.__init__": [[588, 599], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.ParameterServer.run": [[600, 607], ["tensorflow.logging.info", "tensorflow.logging.info", "train.start_server", "start_server.join", "train.task_as_string", "train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.validate_class_name": [[113, 140], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n", "", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.get_input_data_tensors": [[141, 184], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n", "\n", "", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n", "", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.find_class_by_name": [[186, 190], ["next", "getattr"], "function", ["None"], ["batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.build_graph": [[191, 344], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "# PRCCConcat", "\n", "phase", "=", "tf", ".", "constant", "(", "True", ")", "\n", "#", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "# PRCCConcat", "\n", "is_training", "=", "phase", ")", "\n", "#)", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "# PRCCConcat", "\n", "tf", ".", "add_to_collection", "(", "\"phase\"", ",", "phase", ")", "\n", "#", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.get_reader": [[570, 583], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.start_server": [[609, 631], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "train.task_as_string", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.task_as_string": [[632, 634], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.train.main": [[635, 673], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "train.task_as_string", "train.get_reader", "export_model.ModelExporter", "train.Trainer.run", "train.find_class_by_name", "train.ParameterServer.run", "ValueError", "train.Trainer", "train.ParameterServer", "train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.__init__": [[140, 158], ["mean_average_precision_calculator.MeanAveragePrecisionCalculator", "average_precision_calculator.AveragePrecisionCalculator"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_class", ",", "top_k", ")", ":", "\n", "    ", "\"\"\"Construct an EvaluationMetrics object to store the evaluation metrics.\n\n    Args:\n      num_class: A positive integer specifying the number of classes.\n      top_k: A positive integer specifying how many predictions are considered per video.\n\n    Raises:\n      ValueError: An error occurred when MeanAveragePrecisionCalculator cannot\n        not be constructed.\n    \"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", "=", "map_calculator", ".", "MeanAveragePrecisionCalculator", "(", "num_class", ")", "\n", "self", ".", "global_ap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "num_examples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate": [[159, 192], ["eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "numpy.mean", "eval_util.top_k_by_class", "eval_util.EvaluationMetrics.map_calculator.accumulate", "eval_util.EvaluationMetrics.global_ap_calculator.accumulate", "eval_util.flatten", "eval_util.flatten", "sum"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "accumulate", "(", "self", ",", "predictions", ",", "labels", ",", "loss", ")", ":", "\n", "    ", "\"\"\"Accumulate the metrics calculated locally for this mini-batch.\n\n    Args:\n      predictions: A numpy matrix containing the outputs of the model.\n        Dimensions are 'batch' x 'num_classes'.\n      labels: A numpy matrix containing the ground truth labels.\n        Dimensions are 'batch' x 'num_classes'.\n      loss: A numpy array containing the loss for each sample.\n\n    Returns:\n      dictionary: A dictionary storing the metrics for the mini-batch.\n\n    Raises:\n      ValueError: An error occurred when the shape of predictions and actuals\n        does not match.\n    \"\"\"", "\n", "batch_size", "=", "labels", ".", "shape", "[", "0", "]", "\n", "mean_hit_at_one", "=", "calculate_hit_at_one", "(", "predictions", ",", "labels", ")", "\n", "mean_perr", "=", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "labels", ")", "\n", "mean_loss", "=", "numpy", ".", "mean", "(", "loss", ")", "\n", "\n", "# Take the top 20 predictions.", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "labels", ",", "self", ".", "top_k", ")", "\n", "self", ".", "map_calculator", ".", "accumulate", "(", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", ")", "\n", "self", ".", "global_ap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "\n", "self", ".", "num_examples", "+=", "batch_size", "\n", "self", ".", "sum_hit_at_one", "+=", "mean_hit_at_one", "*", "batch_size", "\n", "self", ".", "sum_perr", "+=", "mean_perr", "*", "batch_size", "\n", "self", ".", "sum_loss", "+=", "mean_loss", "*", "batch_size", "\n", "\n", "return", "{", "\"hit_at_one\"", ":", "mean_hit_at_one", ",", "\"perr\"", ":", "mean_perr", ",", "\"loss\"", ":", "mean_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get": [[193, 216], ["eval_util.EvaluationMetrics.map_calculator.peek_map_at_n", "eval_util.EvaluationMetrics.global_ap_calculator.peek_ap_at_n", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.mean_average_precision_calculator.MeanAveragePrecisionCalculator.peek_map_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n"], ["", "def", "get", "(", "self", ")", ":", "\n", "    ", "\"\"\"Calculate the evaluation metrics for the whole epoch.\n\n    Raises:\n      ValueError: If no examples were accumulated.\n\n    Returns:\n      dictionary: a dictionary storing the evaluation metrics for the epoch. The\n        dictionary has the fields: avg_hit_at_one, avg_perr, avg_loss, and\n        aps (default nan).\n    \"\"\"", "\n", "if", "self", ".", "num_examples", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"total_sample must be positive.\"", ")", "\n", "", "avg_hit_at_one", "=", "self", ".", "sum_hit_at_one", "/", "self", ".", "num_examples", "\n", "avg_perr", "=", "self", ".", "sum_perr", "/", "self", ".", "num_examples", "\n", "avg_loss", "=", "self", ".", "sum_loss", "/", "self", ".", "num_examples", "\n", "\n", "aps", "=", "self", ".", "map_calculator", ".", "peek_map_at_n", "(", ")", "\n", "gap", "=", "self", ".", "global_ap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n", "epoch_info_dict", "=", "{", "}", "\n", "return", "{", "\"avg_hit_at_one\"", ":", "avg_hit_at_one", ",", "\"avg_perr\"", ":", "avg_perr", ",", "\n", "\"avg_loss\"", ":", "avg_loss", ",", "\"aps\"", ":", "aps", ",", "\"gap\"", ":", "gap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear": [[217, 225], ["eval_util.EvaluationMetrics.map_calculator.clear", "eval_util.EvaluationMetrics.global_ap_calculator.clear"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "    ", "\"\"\"Clear the evaluation metrics and reset the EvaluationMetrics object.\"\"\"", "\n", "self", ".", "sum_hit_at_one", "=", "0.0", "\n", "self", ".", "sum_perr", "=", "0.0", "\n", "self", ".", "sum_loss", "=", "0.0", "\n", "self", ".", "map_calculator", ".", "clear", "(", ")", "\n", "self", ".", "global_ap_calculator", ".", "clear", "(", ")", "\n", "self", ".", "num_examples", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten": [[24, 27], ["None"], "function", ["None"], ["def", "flatten", "(", "l", ")", ":", "\n", "  ", "\"\"\" Merges a list of lists into a single list. \"\"\"", "\n", "return", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one": [[28, 43], ["numpy.argmax", "numpy.average", "numpy.arange"], "function", ["None"], ["", "def", "calculate_hit_at_one", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the hit at one.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average hit at one across the entire batch.\n  \"\"\"", "\n", "top_prediction", "=", "numpy", ".", "argmax", "(", "predictions", ",", "1", ")", "\n", "hits", "=", "actuals", "[", "numpy", ".", "arange", "(", "actuals", ".", "shape", "[", "0", "]", ")", ",", "top_prediction", "]", "\n", "return", "numpy", ".", "average", "(", "hits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate": [[45, 71], ["numpy.arange", "int", "numpy.sum", "numpy.argpartition"], "function", ["None"], ["", "def", "calculate_precision_at_equal_recall_rate", "(", "predictions", ",", "actuals", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the PERR.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n\n  Returns:\n    float: The average precision at equal recall rate across the entire batch.\n  \"\"\"", "\n", "aggregated_precision", "=", "0.0", "\n", "num_videos", "=", "actuals", ".", "shape", "[", "0", "]", "\n", "for", "row", "in", "numpy", ".", "arange", "(", "num_videos", ")", ":", "\n", "    ", "num_labels", "=", "int", "(", "numpy", ".", "sum", "(", "actuals", "[", "row", "]", ")", ")", "\n", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "row", "]", ",", "\n", "-", "num_labels", ")", "[", "-", "num_labels", ":", "]", "\n", "item_precision", "=", "0.0", "\n", "for", "label_index", "in", "top_indices", ":", "\n", "      ", "if", "predictions", "[", "row", "]", "[", "label_index", "]", ">", "0", ":", "\n", "        ", "item_precision", "+=", "actuals", "[", "row", "]", "[", "label_index", "]", "\n", "", "", "item_precision", "/=", "top_indices", ".", "size", "\n", "aggregated_precision", "+=", "item_precision", "\n", "", "aggregated_precision", "/=", "num_videos", "\n", "return", "aggregated_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap": [[72, 91], ["average_precision_calculator.AveragePrecisionCalculator", "eval_util.top_k_by_class", "ap_calculator.AveragePrecisionCalculator.accumulate", "ap_calculator.AveragePrecisionCalculator.peek_ap_at_n", "eval_util.flatten", "eval_util.flatten", "sum"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.accumulate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.average_precision_calculator.AveragePrecisionCalculator.peek_ap_at_n", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.flatten"], ["", "def", "calculate_gap", "(", "predictions", ",", "actuals", ",", "top_k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Performs a local (numpy) calculation of the global average precision.\n\n  Only the top_k predictions are taken for each of the videos.\n\n  Args:\n    predictions: Matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    actuals: Matrix containing the ground truth labels.\n      Dimensions are 'batch' x 'num_classes'.\n    top_k: How many predictions to use per video.\n\n  Returns:\n    float: The global average precision.\n  \"\"\"", "\n", "gap_calculator", "=", "ap_calculator", ".", "AveragePrecisionCalculator", "(", ")", "\n", "sparse_predictions", ",", "sparse_labels", ",", "num_positives", "=", "top_k_by_class", "(", "predictions", ",", "actuals", ",", "top_k", ")", "\n", "gap_calculator", ".", "accumulate", "(", "flatten", "(", "sparse_predictions", ")", ",", "flatten", "(", "sparse_labels", ")", ",", "sum", "(", "num_positives", ")", ")", "\n", "return", "gap_calculator", ".", "peek_ap_at_n", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_by_class": [[93, 128], ["min", "range", "ValueError", "prediction_triplets.extend", "out_predictions[].append", "out_labels[].append", "numpy.sum", "eval_util.top_k_triplets", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_triplets"], ["", "def", "top_k_by_class", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Extracts the top k predictions for each video, sorted by class.\n\n  Args:\n    predictions: A numpy matrix containing the outputs of the model.\n      Dimensions are 'batch' x 'num_classes'.\n    k: the top k non-zero entries to preserve in each prediction.\n\n  Returns:\n    A tuple (predictions,labels, true_positives). 'predictions' and 'labels'\n    are lists of lists of floats. 'true_positives' is a list of scalars. The\n    length of the lists are equal to the number of classes. The entries in the\n    predictions variable are probability predictions, and\n    the corresponding entries in the labels variable are the ground truth for\n    those predictions. The entries in 'true_positives' are the number of true\n    positives for each class in the ground truth.\n\n  Raises:\n    ValueError: An error occurred when the k is not a positive integer.\n  \"\"\"", "\n", "if", "k", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"k must be a positive integer.\"", ")", "\n", "", "k", "=", "min", "(", "k", ",", "predictions", ".", "shape", "[", "1", "]", ")", "\n", "num_classes", "=", "predictions", ".", "shape", "[", "1", "]", "\n", "prediction_triplets", "=", "[", "]", "\n", "for", "video_index", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "    ", "prediction_triplets", ".", "extend", "(", "top_k_triplets", "(", "predictions", "[", "video_index", "]", ",", "labels", "[", "video_index", "]", ",", "k", ")", ")", "\n", "", "out_predictions", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "out_labels", "=", "[", "[", "]", "for", "v", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "triplet", "in", "prediction_triplets", ":", "\n", "    ", "out_predictions", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "1", "]", ")", "\n", "out_labels", "[", "triplet", "[", "0", "]", "]", ".", "append", "(", "triplet", "[", "2", "]", ")", "\n", "", "out_true_positives", "=", "[", "numpy", ".", "sum", "(", "labels", "[", ":", ",", "i", "]", ")", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "\n", "return", "out_predictions", ",", "out_labels", ",", "out_true_positives", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.top_k_triplets": [[129, 136], ["len", "min", "numpy.argpartition"], "function", ["None"], ["", "def", "top_k_triplets", "(", "predictions", ",", "labels", ",", "k", "=", "20", ")", ":", "\n", "  ", "\"\"\"Get the top_k for a 1-d numpy array. Returns a sparse list of tuples in\n  (prediction, class) format\"\"\"", "\n", "m", "=", "len", "(", "predictions", ")", "\n", "k", "=", "min", "(", "k", ",", "m", ")", "\n", "indices", "=", "numpy", ".", "argpartition", "(", "predictions", ",", "-", "k", ")", "[", "-", "k", ":", "]", "\n", "return", "[", "(", "index", ",", "predictions", "[", "index", "]", ",", "labels", "[", "index", "]", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.format_lines": [[73, 82], ["len", "range", "sorted", "numpy.argpartition", "video_ids[].decode"], "function", ["None"], ["", "def", "format_lines", "(", "video_ids", ",", "predictions", ",", "top_k", ")", ":", "\n", "  ", "batch_size", "=", "len", "(", "video_ids", ")", "\n", "for", "video_index", "in", "range", "(", "batch_size", ")", ":", "\n", "    ", "top_indices", "=", "numpy", ".", "argpartition", "(", "predictions", "[", "video_index", "]", ",", "-", "top_k", ")", "[", "-", "top_k", ":", "]", "\n", "line", "=", "[", "(", "class_index", ",", "predictions", "[", "video_index", "]", "[", "class_index", "]", ")", "\n", "for", "class_index", "in", "top_indices", "]", "\n", "line", "=", "sorted", "(", "line", ",", "key", "=", "lambda", "p", ":", "-", "p", "[", "1", "]", ")", "\n", "yield", "video_ids", "[", "video_index", "]", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "pair", "\n", "for", "pair", "in", "line", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.get_input_data_tensors": [[84, 118], ["tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.batch_join", "IOError", "reader.prepare_reader", "str", "range", "len"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "", "def", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ",", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the input data.\n\n  Args:\n    reader: A class which parses the input data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find input files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'\"", ")", "\n", "", "logging", ".", "info", "(", "\"number of input files: \"", "+", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "examples_and_labels", "=", "[", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "\n", "for", "_", "in", "range", "(", "num_readers", ")", "]", "\n", "\n", "video_id_batch", ",", "video_batch", ",", "unused_labels", ",", "num_frames_batch", "=", "(", "\n", "tf", ".", "train", ".", "batch_join", "(", "examples_and_labels", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", ")", "\n", "return", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference": [[119, 181], ["tensorflow.Session", "tensorflow.gfile.Open", "new_infer.get_input_data_tensors", "tensorflow.train.import_meta_graph", "tensorflow.logging.info", "tf.train.import_meta_graph.restore", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "time.time", "out_file.write", "tf.train.Coordinator.join", "sess.close", "tensorflow.train.latest_checkpoint", "Exception", "tensorflow.logging.info", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "list", "init_op_list.append", "new_infer.inference.set_up_init_ops"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run"], ["", "", "def", "inference", "(", "reader", ",", "train_dir", ",", "data_pattern", ",", "out_file_location", ",", "batch_size", ",", "top_k", ")", ":", "\n", "  ", "with", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ",", "gfile", ".", "Open", "(", "out_file_location", ",", "\"w+\"", ")", "as", "out_file", ":", "\n", "\n", "    ", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "=", "get_input_data_tensors", "(", "reader", ",", "data_pattern", ",", "batch_size", ")", "\n", "\n", "if", "FLAGS", ".", "checkpoint_name", "==", "\"\"", ":", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "", "if", "latest_checkpoint", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"unable to find a checkpoint at location: %s\"", "%", "train_dir", ")", "\n", "", "else", ":", "\n", "      ", "meta_graph_location", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "logging", ".", "info", "(", "\"loading meta-graph: \"", "+", "meta_graph_location", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_graph_location", ",", "clear_devices", "=", "FLAGS", ".", "clear_device", ")", "\n", "logging", ".", "info", "(", "\"restoring variables from \"", "+", "latest_checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "input_tensor", "=", "tf", ".", "get_collection", "(", "\"input_batch_raw\"", ")", "[", "0", "]", "\n", "num_frames_tensor", "=", "tf", ".", "get_collection", "(", "\"num_frames\"", ")", "[", "0", "]", "\n", "predictions_tensor", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "get_collection", "(", "\"keep_prob\"", ")", "[", "0", "]", "\n", "\n", "# Workaround for num_epochs issue.", "\n", "def", "set_up_init_ops", "(", "variables", ")", ":", "\n", "      ", "init_op_list", "=", "[", "]", "\n", "for", "variable", "in", "list", "(", "variables", ")", ":", "\n", "        ", "if", "\"train_input\"", "in", "variable", ".", "name", ":", "\n", "          ", "init_op_list", ".", "append", "(", "tf", ".", "assign", "(", "variable", ",", "1", ")", ")", "\n", "variables", ".", "remove", "(", "variable", ")", "\n", "", "", "init_op_list", ".", "append", "(", "tf", ".", "variables_initializer", "(", "variables", ")", ")", "\n", "return", "init_op_list", "\n", "\n", "", "sess", ".", "run", "(", "set_up_init_ops", "(", "tf", ".", "get_collection_ref", "(", "\n", "tf", ".", "GraphKeys", ".", "LOCAL_VARIABLES", ")", ")", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "sess", "=", "sess", ",", "coord", "=", "coord", ")", "\n", "num_examples_processed", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out_file", ".", "write", "(", "\"VideoId,LabelConfidencePairs\\n\"", ")", "\n", "\n", "try", ":", "\n", "      ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "          ", "video_id_batch_val", ",", "video_batch_val", ",", "num_frames_batch_val", "=", "sess", ".", "run", "(", "[", "video_id_batch", ",", "video_batch", ",", "num_frames_batch", "]", ")", "\n", "predictions_val", ",", "=", "sess", ".", "run", "(", "[", "predictions_tensor", "]", ",", "feed_dict", "=", "{", "input_tensor", ":", "video_batch_val", ",", "num_frames_tensor", ":", "num_frames_batch_val", ",", "keep_prob", ":", "FLAGS", ".", "keep_prob", "}", ")", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "num_examples_processed", "+=", "len", "(", "video_batch_val", ")", "\n", "num_classes", "=", "predictions_val", ".", "shape", "[", "1", "]", "\n", "logging", ".", "info", "(", "\"num examples processed: \"", "+", "str", "(", "num_examples_processed", ")", "+", "\" elapsed seconds: \"", "+", "\"{0:.2f}\"", ".", "format", "(", "now", "-", "start_time", ")", ")", "\n", "for", "line", "in", "format_lines", "(", "video_id_batch_val", ",", "predictions_val", ",", "top_k", ")", ":", "\n", "            ", "out_file", ".", "write", "(", "line", ")", "\n", "", "out_file", ".", "flush", "(", ")", "\n", "\n", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "'Done with inference. The output file was written to '", "+", "out_file_location", ")", "\n", "", "finally", ":", "\n", "        ", "coord", ".", "request_stop", "(", ")", "\n", "\n", "", "coord", ".", "join", "(", "threads", ")", "\n", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.main": [[183, 207], ["tensorflow.logging.set_verbosity", "utils.GetListOfFeatureNamesAndSizes", "new_infer.inference", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_infer.inference"], ["", "", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "# convert feature_names and feature_sizes to lists of values", "\n", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "feature_names", "=", "feature_names", ",", "\n", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "if", "FLAGS", ".", "output_file", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'output_file' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "if", "FLAGS", ".", "input_data_pattern", "is", "\"\"", ":", "\n", "    ", "raise", "ValueError", "(", "\"'input_data_pattern' was not specified. \"", "\n", "\"Unable to continue with inference.\"", ")", "\n", "\n", "", "inference", "(", "reader", ",", "FLAGS", ".", "train_dir", ",", "FLAGS", ".", "input_data_pattern", ",", "\n", "FLAGS", ".", "output_file", ",", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "top_k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.__init__": [[364, 388], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.run": [[393, 502], ["forzhao_oldpool.Trainer.start_server_if_distributed", "forzhao_oldpool.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "forzhao_oldpool.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "forzhao_oldpool.task_as_string", "tensorflow.train.Supervisor.managed_session", "forzhao_oldpool.task_as_string", "tensorflow.device", "tensorflow.device", "forzhao_oldpool.Trainer.build_model", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "sys.exit", "tensorflow.Graph", "tensorflow.Graph", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "forzhao_oldpool.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_oldpool.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "forzhao_oldpool.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "latest_checkpoint", ",", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "#if meta_filename:", "\n", "#  if not FLAGS.change_file:", "\n", "#    saver = self.recover_model(meta_filename)", "\n", "\n", "      ", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "#        if not meta_filename:", "\n", "#          saver = self.build_model(self.model, self.reader)", "\n", "#        if FLAGS.change_file:", "\n", "        ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:restoring\"", ")", "\n", "sv", ".", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:saving model\"", ")", "\n", "sv", ".", "saver", ".", "save", "(", "sess", ",", "sv", ".", "save_path", ",", "666", ")", "\n", "logging", ".", "info", "(", "\"TANG:SAVING OVER\"", ")", "\n", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.export_model": [[503, 519], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_oldpool.Trainer.model_exporter.export_model", "forzhao_oldpool.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.start_server_if_distributed": [[520, 536], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_oldpool.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "forzhao_oldpool.task_as_string", "forzhao_oldpool.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.remove_training_directory": [[537, 549], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "forzhao_oldpool.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "forzhao_oldpool.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.get_meta_filename": [[550, 570], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_oldpool.task_as_string", "forzhao_oldpool.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "#latest_checkpoint = tf.train.latest_checkpoint(train_dir)", "\n", "#if not latest_checkpoint:", "\n", "#  logging.info(\"%s: No checkpoint file found. Building a new model.\",", "\n", "#               task_as_string(self.task))", "\n", "#  return None", "\n", "\n", "", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "latest_checkpoint", ",", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.recover_model": [[571, 575], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "forzhao_oldpool.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.Trainer.build_model": [[576, 597], ["forzhao_oldpool.find_class_by_name", "forzhao_oldpool.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "forzhao_oldpool.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.ParameterServer.__init__": [[617, 628], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.ParameterServer.run": [[629, 636], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_oldpool.start_server", "start_server.join", "forzhao_oldpool.task_as_string", "forzhao_oldpool.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.validate_class_name": [[116, 143], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.get_input_data_tensors": [[144, 187], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.find_class_by_name": [[189, 193], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.build_graph": [[194, 359], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "forzhao_oldpool.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "#  keep_prob = tf.constant(FLAGS.keep_prob)", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", "\n", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"features\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "#  tf.add_to_collection(\"keep_prob\",keep_prob)", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.get_reader": [[599, 612], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.start_server": [[638, 660], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "forzhao_oldpool.task_as_string", "forzhao_oldpool.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.task_as_string": [[661, 663], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_oldpool.main": [[664, 702], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "forzhao_oldpool.task_as_string", "forzhao_oldpool.get_reader", "export_model.ModelExporter", "forzhao_oldpool.Trainer.run", "forzhao_oldpool.find_class_by_name", "forzhao_oldpool.ParameterServer.run", "ValueError", "forzhao_oldpool.Trainer", "forzhao_oldpool.ParameterServer", "forzhao_oldpool.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.__init__": [[362, 386], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.run": [[391, 495], ["forzhao_infer.Trainer.start_server_if_distributed", "forzhao_infer.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "forzhao_infer.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "forzhao_infer.task_as_string", "tensorflow.train.Supervisor.managed_session", "forzhao_infer.task_as_string", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.Trainer.restore", "tensorflow.Graph", "tensorflow.Graph", "forzhao_infer.Trainer.recover_model", "forzhao_infer.Trainer.build_model", "forzhao_infer.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "forzhao_infer.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "forzhao_infer.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "latest_checkpoint", ",", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "if", "not", "FLAGS", ".", "change_file", ":", "\n", "          ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "", "if", "FLAGS", ".", "change_file", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:restoring\"", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.export_model": [[496, 512], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.Trainer.model_exporter.export_model", "forzhao_infer.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.start_server_if_distributed": [[513, 529], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "forzhao_infer.task_as_string", "forzhao_infer.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.remove_training_directory": [[530, 542], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "forzhao_infer.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "forzhao_infer.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.get_meta_filename": [[543, 562], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.task_as_string", "forzhao_infer.task_as_string", "forzhao_infer.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "latest_checkpoint", ",", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.recover_model": [[563, 567], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "forzhao_infer.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.Trainer.build_model": [[568, 589], ["forzhao_infer.find_class_by_name", "forzhao_infer.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "forzhao_infer.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.ParameterServer.__init__": [[609, 620], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.ParameterServer.run": [[621, 628], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_infer.start_server", "start_server.join", "forzhao_infer.task_as_string", "forzhao_infer.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.validate_class_name": [[114, 141], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.get_input_data_tensors": [[142, 185], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.find_class_by_name": [[187, 191], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.build_graph": [[192, 357], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "forzhao_infer.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "#  keep_prob = tf.constant(FLAGS.keep_prob)", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"features\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "#tf.add_to_collection(\"keep_prob\",keep_prob)", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.get_reader": [[591, 604], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.start_server": [[630, 652], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "forzhao_infer.task_as_string", "forzhao_infer.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.task_as_string": [[653, 655], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_infer.main": [[656, 694], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "forzhao_infer.task_as_string", "forzhao_infer.get_reader", "export_model.ModelExporter", "forzhao_infer.Trainer.run", "forzhao_infer.find_class_by_name", "forzhao_infer.ParameterServer.run", "ValueError", "forzhao_infer.Trainer", "forzhao_infer.ParameterServer", "forzhao_infer.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.get_csv_header": [[46, 48], ["None"], "function", ["None"], ["", "def", "get_csv_header", "(", ")", ":", "\n", "  ", "return", "\"VideoId,LabelConfidencePairs\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.to_csv_row": [[49, 69], ["isinstance", "len", "len", "ValueError", "video_id.decode", "len", "len", "builtins.range", "len"], "function", ["None"], ["", "def", "to_csv_row", "(", "json_data", ")", ":", "\n", "\n", "  ", "video_id", "=", "json_data", "[", "\"video_id\"", "]", "\n", "\n", "class_indexes", "=", "json_data", "[", "\"class_indexes\"", "]", "\n", "predictions", "=", "json_data", "[", "\"predictions\"", "]", "\n", "\n", "if", "isinstance", "(", "video_id", ",", "list", ")", ":", "\n", "    ", "video_id", "=", "video_id", "[", "0", "]", "\n", "class_indexes", "=", "class_indexes", "[", "0", "]", "\n", "predictions", "=", "predictions", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "class_indexes", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The number of indexes (%s) and predictions (%s) must be equal.\"", "\n", "%", "(", "len", "(", "class_indexes", ")", ",", "len", "(", "predictions", ")", ")", ")", "\n", "\n", "", "return", "(", "video_id", ".", "decode", "(", "'utf-8'", ")", "+", "\",\"", "+", "\" \"", ".", "join", "(", "\"%i %f\"", "%", "\n", "(", "class_indexes", "[", "i", "]", ",", "predictions", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_indexes", ")", ")", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.main": [[70, 101], ["tensorflow.logging.set_verbosity", "tensorflow.logging.info", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "ValueError", "ValueError", "tensorflow.gfile.Open", "output_file.write", "output_file.flush", "convert_prediction_from_json_to_csv.get_csv_header", "tensorflow.logging.info", "tensorflow.gfile.Open", "json.loads", "output_file.write", "convert_prediction_from_json_to_csv.to_csv_row"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.get_csv_header", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.convert_prediction_from_json_to_csv.to_csv_row"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "  ", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "if", "not", "FLAGS", ".", "json_prediction_files_pattern", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The flag --json_prediction_files_pattern must be specified.\"", ")", "\n", "\n", "", "if", "not", "FLAGS", ".", "csv_output_file", ":", "\n", "    ", "raise", "ValueError", "(", "\"The flag --csv_output_file must be specified.\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Looking for prediction files with pattern: %s\"", ",", "\n", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "\n", "file_paths", "=", "gfile", ".", "Glob", "(", "FLAGS", ".", "json_prediction_files_pattern", ")", "\n", "logging", ".", "info", "(", "\"Found files: %s\"", ",", "file_paths", ")", "\n", "\n", "logging", ".", "info", "(", "\"Writing submission file to: %s\"", ",", "FLAGS", ".", "csv_output_file", ")", "\n", "with", "gfile", ".", "Open", "(", "FLAGS", ".", "csv_output_file", ",", "\"w+\"", ")", "as", "output_file", ":", "\n", "    ", "output_file", ".", "write", "(", "get_csv_header", "(", ")", ")", "\n", "\n", "for", "file_path", "in", "file_paths", ":", "\n", "      ", "logging", ".", "info", "(", "\"processing file: %s\"", ",", "file_path", ")", "\n", "\n", "with", "gfile", ".", "Open", "(", "file_path", ")", "as", "input_file", ":", "\n", "\n", "        ", "for", "line", "in", "input_file", ":", "\n", "          ", "json_data", "=", "json", ".", "loads", "(", "line", ")", "\n", "output_file", ".", "write", "(", "to_csv_row", "(", "json_data", ")", ")", "\n", "\n", "", "", "", "output_file", ".", "flush", "(", ")", "\n", "", "logging", ".", "info", "(", "\"done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.__init__": [[365, 389], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.run": [[394, 503], ["forzhao_test.Trainer.start_server_if_distributed", "forzhao_test.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "forzhao_test.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "forzhao_test.task_as_string", "tensorflow.train.Supervisor.managed_session", "forzhao_test.task_as_string", "tensorflow.device", "tensorflow.device", "forzhao_test.Trainer.build_model", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.restore", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "sys.exit", "tensorflow.Graph", "tensorflow.Graph", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "forzhao_test.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_test.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "forzhao_test.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "latest_checkpoint", ",", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "#if meta_filename:", "\n", "#  if not FLAGS.change_file:", "\n", "#    saver = self.recover_model(meta_filename)", "\n", "\n", "      ", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "#        if not meta_filename:", "\n", "#          saver = self.build_model(self.model, self.reader)", "\n", "#        if FLAGS.change_file:", "\n", "        ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:restoring\"", ")", "\n", "sv", ".", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "logging", ".", "info", "(", "\"TANG:saving model\"", ")", "\n", "sv", ".", "saver", ".", "save", "(", "sess", ",", "sv", ".", "save_path", ",", "666", ")", "\n", "logging", ".", "info", "(", "\"TANG:SAVING OVER\"", ")", "\n", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.export_model": [[504, 520], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_test.Trainer.model_exporter.export_model", "forzhao_test.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.start_server_if_distributed": [[521, 537], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_test.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "forzhao_test.task_as_string", "forzhao_test.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.remove_training_directory": [[538, 550], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "forzhao_test.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "forzhao_test.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.get_meta_filename": [[551, 571], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "forzhao_test.task_as_string", "forzhao_test.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "#latest_checkpoint = tf.train.latest_checkpoint(train_dir)", "\n", "#if not latest_checkpoint:", "\n", "#  logging.info(\"%s: No checkpoint file found. Building a new model.\",", "\n", "#               task_as_string(self.task))", "\n", "#  return None", "\n", "\n", "", "latest_checkpoint", "=", "FLAGS", ".", "train_dir", "+", "\"model.ckpt-\"", "+", "FLAGS", ".", "checkpoint_name", "\n", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "latest_checkpoint", ",", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.recover_model": [[572, 576], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "forzhao_test.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.Trainer.build_model": [[577, 598], ["forzhao_test.find_class_by_name", "forzhao_test.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "forzhao_test.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.ParameterServer.__init__": [[618, 629], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.ParameterServer.run": [[630, 637], ["tensorflow.logging.info", "tensorflow.logging.info", "forzhao_test.start_server", "start_server.join", "forzhao_test.task_as_string", "forzhao_test.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.validate_class_name": [[116, 143], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.get_input_data_tensors": [[144, 187], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.find_class_by_name": [[189, 193], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.build_graph": [[194, 361], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "forzhao_test.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "constant", "(", "FLAGS", ".", "keep_prob", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "keep_prob", "=", "keep_prob", "\n", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"zhaofeatures\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"zhaofeatures\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"keep_prob\"", ",", "keep_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.get_reader": [[600, 613], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.start_server": [[639, 661], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "forzhao_test.task_as_string", "forzhao_test.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.task_as_string": [[662, 664], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.forzhao_test.main": [[665, 703], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "forzhao_test.task_as_string", "forzhao_test.get_reader", "export_model.ModelExporter", "forzhao_test.Trainer.run", "forzhao_test.find_class_by_name", "forzhao_test.ParameterServer.run", "ValueError", "forzhao_test.Trainer", "forzhao_test.ParameterServer", "forzhao_test.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.__init__": [[361, 385], ["tensorflow.ConfigProto", "tensorflow.ConfigProto"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ",", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "log_device_placement", "=", "True", ",", "max_steps", "=", "None", ",", "\n", "export_model_steps", "=", "1000", ")", ":", "\n", "    ", "\"\"\"\"Creates a Trainer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "is_master", "=", "(", "task", ".", "type", "==", "\"master\"", "and", "task", ".", "index", "==", "0", ")", "\n", "self", ".", "train_dir", "=", "train_dir", "\n", "self", ".", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "log_device_placement", "=", "log_device_placement", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "reader", "=", "reader", "\n", "self", ".", "model_exporter", "=", "model_exporter", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "max_steps_reached", "=", "False", "\n", "self", ".", "export_model_steps", "=", "export_model_steps", "\n", "self", ".", "last_model_export_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.run": [[390, 486], ["new_train.Trainer.start_server_if_distributed", "new_train.Trainer.get_meta_filename", "tensorflow.train.Supervisor", "tensorflow.train.Supervisor", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.Stop", "new_train.Trainer.remove_training_directory", "tensorflow.Graph().as_default", "tensorflow.Graph().as_default", "new_train.task_as_string", "tensorflow.train.Supervisor.managed_session", "new_train.task_as_string", "new_train.Trainer.recover_model", "tensorflow.device", "tensorflow.device", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.Graph", "tensorflow.Graph", "new_train.Trainer.build_model", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "new_train.task_as_string", "time.time", "sess.run", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.should_stop", "time.time", "time.time", "eval_util.calculate_hit_at_one", "eval_util.calculate_precision_at_equal_recall_rate", "eval_util.calculate_gap", "time.time", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.add_summary", "tensorflow.train.Supervisor.summary_writer.flush", "tensorflow.logging.info", "tensorflow.logging.info", "new_train.task_as_string", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "new_train.Trainer.export_model", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_hit_at_one", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_precision_at_equal_recall_rate", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.calculate_gap", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model"], ["", "def", "run", "(", "self", ",", "start_new_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs training on the currently defined Tensorflow graph.\n\n    Returns:\n      A tuple of the training Hit@1 and the training PERR.\n    \"\"\"", "\n", "if", "self", ".", "is_master", "and", "start_new_model", ":", "\n", "      ", "self", ".", "remove_training_directory", "(", "self", ".", "train_dir", ")", "\n", "\n", "", "target", ",", "device_fn", "=", "self", ".", "start_server_if_distributed", "(", ")", "\n", "\n", "meta_filename", "=", "self", ".", "get_meta_filename", "(", "start_new_model", ",", "self", ".", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "\n", "      ", "if", "meta_filename", ":", "\n", "        ", "saver", "=", "self", ".", "recover_model", "(", "meta_filename", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_fn", ")", ":", "\n", "        ", "if", "not", "meta_filename", ":", "\n", "          ", "saver", "=", "self", ".", "build_model", "(", "self", ".", "model", ",", "self", ".", "reader", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_collection", "(", "\"global_step\"", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "get_collection", "(", "\"loss\"", ")", "[", "0", "]", "\n", "predictions", "=", "tf", ".", "get_collection", "(", "\"predictions\"", ")", "[", "0", "]", "\n", "labels", "=", "tf", ".", "get_collection", "(", "\"labels\"", ")", "[", "0", "]", "\n", "train_op", "=", "tf", ".", "get_collection", "(", "\"train_op\"", ")", "[", "0", "]", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "\n", "", "", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "\n", "graph", ",", "\n", "logdir", "=", "self", ".", "train_dir", ",", "\n", "init_op", "=", "init_op", ",", "\n", "is_chief", "=", "self", ".", "is_master", ",", "\n", "global_step", "=", "global_step", ",", "\n", "save_model_secs", "=", "60", "*", "FLAGS", ".", "time_to_save_model", ",", "\n", "save_summaries_secs", "=", "120", ",", "\n", "saver", "=", "saver", ")", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting managed session.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "with", "sv", ".", "managed_session", "(", "target", ",", "config", "=", "self", ".", "config", ")", "as", "sess", ":", "\n", "      ", "try", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Entering training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "while", "(", "not", "sv", ".", "should_stop", "(", ")", ")", "and", "(", "not", "self", ".", "max_steps_reached", ")", ":", "\n", "          ", "batch_start_time", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "global_step_val", ",", "loss_val", ",", "predictions_val", ",", "labels_val", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "global_step", ",", "loss", ",", "predictions", ",", "labels", "]", ")", "\n", "seconds_per_batch", "=", "time", ".", "time", "(", ")", "-", "batch_start_time", "\n", "examples_per_second", "=", "labels_val", ".", "shape", "[", "0", "]", "/", "seconds_per_batch", "\n", "\n", "if", "self", ".", "max_steps", "and", "self", ".", "max_steps", "<=", "global_step_val", ":", "\n", "            ", "self", ".", "max_steps_reached", "=", "True", "\n", "\n", "", "if", "self", ".", "is_master", "and", "global_step_val", "%", "FLAGS", ".", "eval_loop", "==", "0", "and", "self", ".", "train_dir", ":", "\n", "            ", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "hit_at_one", "=", "eval_util", ".", "calculate_hit_at_one", "(", "predictions_val", ",", "labels_val", ")", "\n", "perr", "=", "eval_util", ".", "calculate_precision_at_equal_recall_rate", "(", "predictions_val", ",", "\n", "labels_val", ")", "\n", "gap", "=", "eval_util", ".", "calculate_gap", "(", "predictions_val", ",", "labels_val", ")", "\n", "eval_end_time", "=", "time", ".", "time", "(", ")", "\n", "eval_time", "=", "eval_end_time", "-", "eval_start_time", "\n", "\n", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\n", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", "+", "\" | Hit@1: \"", "+", "\n", "(", "\"%.2f\"", "%", "hit_at_one", ")", "+", "\" PERR: \"", "+", "(", "\"%.2f\"", "%", "perr", ")", "+", "\n", "\" GAP: \"", "+", "(", "\"%.2f\"", "%", "gap", ")", ")", "\n", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Hit@1\"", ",", "hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_Perr\"", ",", "perr", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"model/Training_GAP\"", ",", "gap", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "\n", "utils", ".", "MakeSummary", "(", "\"global_step/Examples/Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "sv", ".", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "# Exporting the model every x steps", "\n", "time_to_export", "=", "(", "(", "self", ".", "last_model_export_step", "==", "0", ")", "or", "\n", "(", "global_step_val", "-", "self", ".", "last_model_export_step", "\n", ">=", "self", ".", "export_model_steps", ")", ")", "\n", "\n", "if", "self", ".", "is_master", "and", "time_to_export", ":", "\n", "              ", "self", ".", "export_model", "(", "global_step_val", ",", "sv", ".", "saver", ",", "sv", ".", "save_path", ",", "sess", ")", "\n", "self", ".", "last_model_export_step", "=", "global_step_val", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"training step \"", "+", "str", "(", "global_step_val", ")", "+", "\" | Loss: \"", "+", "\n", "(", "\"%.2f\"", "%", "loss_val", ")", "+", "\" Examples/sec: \"", "+", "(", "\"%.2f\"", "%", "examples_per_second", ")", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "logging", ".", "info", "(", "\"%s: Done training -- epoch limit reached.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"%s: Exited training loop.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "sv", ".", "Stop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model": [[487, 503], ["saver.save", "tensorflow.logging.info", "tensorflow.logging.info", "new_train.Trainer.model_exporter.export_model", "new_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.export_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "export_model", "(", "self", ",", "global_step_val", ",", "saver", ",", "save_path", ",", "session", ")", ":", "\n", "\n", "# If the model has already been exported at this step, return.", "\n", "    ", "if", "global_step_val", "==", "self", ".", "last_model_export_step", ":", "\n", "      ", "return", "\n", "\n", "", "last_checkpoint", "=", "saver", ".", "save", "(", "session", ",", "save_path", ",", "global_step_val", ")", "\n", "\n", "model_dir", "=", "\"{0}/export/step_{1}\"", ".", "format", "(", "self", ".", "train_dir", ",", "global_step_val", ")", "\n", "logging", ".", "info", "(", "\"%s: Exporting the model at step %s to %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "global_step_val", ",", "model_dir", ")", "\n", "\n", "self", ".", "model_exporter", ".", "export_model", "(", "\n", "model_dir", "=", "model_dir", ",", "\n", "global_step_val", "=", "global_step_val", ",", "\n", "last_checkpoint", "=", "last_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.start_server_if_distributed": [[504, 520], ["tensorflow.logging.info", "tensorflow.logging.info", "new_train.start_server", "tensorflow.train.replica_device_setter", "tensorflow.train.replica_device_setter", "new_train.task_as_string", "new_train.Trainer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "start_server_if_distributed", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts a server if the execution is distributed.\"\"\"", "\n", "\n", "if", "self", ".", "cluster", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Starting trainer within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "target", "=", "server", ".", "target", "\n", "device_fn", "=", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "ps_device", "=", "\"/job:ps\"", ",", "\n", "worker_device", "=", "\"/job:%s/task:%d\"", "%", "(", "self", ".", "task", ".", "type", ",", "self", ".", "task", ".", "index", ")", ",", "\n", "cluster", "=", "self", ".", "cluster", ")", "\n", "", "else", ":", "\n", "      ", "target", "=", "\"\"", "\n", "device_fn", "=", "\"\"", "\n", "", "return", "(", "target", ",", "device_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.remove_training_directory": [[521, 533], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "tensorflow.gfile.DeleteRecursively", "new_train.task_as_string", "tensorflow.logging.error", "tensorflow.logging.error", "new_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "remove_training_directory", "(", "self", ",", "train_dir", ")", ":", "\n", "    ", "\"\"\"Removes the training directory.\"\"\"", "\n", "try", ":", "\n", "      ", "logging", ".", "info", "(", "\n", "\"%s: Removing existing train directory.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "except", ":", "\n", "      ", "logging", ".", "error", "(", "\n", "\"%s: Failed to delete directory \"", "+", "train_dir", "+", "\n", "\" when starting a new model. Please delete it manually and\"", "+", "\n", "\" try again.\"", ",", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.get_meta_filename": [[534, 553], ["tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.logging.info", "tensorflow.logging.info", "new_train.task_as_string", "new_train.task_as_string", "new_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "get_meta_filename", "(", "self", ",", "start_new_model", ",", "train_dir", ")", ":", "\n", "    ", "if", "start_new_model", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: Flag 'start_new_model' is set. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "train_dir", ")", "\n", "if", "not", "latest_checkpoint", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No checkpoint file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "\n", "", "meta_filename", "=", "latest_checkpoint", "+", "\".meta\"", "\n", "if", "not", "gfile", ".", "Exists", "(", "meta_filename", ")", ":", "\n", "      ", "logging", ".", "info", "(", "\"%s: No meta graph file found. Building a new model.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "meta_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.recover_model": [[554, 558], ["tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.train.import_meta_graph", "tensorflow.train.import_meta_graph", "new_train.task_as_string"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "recover_model", "(", "self", ",", "meta_filename", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"%s: Restoring from meta graph file %s\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "meta_filename", ")", "\n", "return", "tf", ".", "train", ".", "import_meta_graph", "(", "meta_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.Trainer.build_model": [[559, 580], ["new_train.find_class_by_name", "new_train.build_graph", "tensorflow.train.Saver", "tensorflow.train.Saver", "new_train.find_class_by_name"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name"], ["", "def", "build_model", "(", "self", ",", "model", ",", "reader", ")", ":", "\n", "    ", "\"\"\"Find the model and build the graph.\"\"\"", "\n", "\n", "label_loss_fn", "=", "find_class_by_name", "(", "FLAGS", ".", "label_loss", ",", "[", "losses", "]", ")", "(", ")", "\n", "optimizer_class", "=", "find_class_by_name", "(", "FLAGS", ".", "optimizer", ",", "[", "tf", ".", "train", "]", ")", "\n", "\n", "build_graph", "(", "reader", "=", "reader", ",", "\n", "model", "=", "model", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "clip_gradient_norm", "=", "FLAGS", ".", "clip_gradient_norm", ",", "\n", "train_data_pattern", "=", "FLAGS", ".", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "label_loss_fn", ",", "\n", "base_learning_rate", "=", "FLAGS", ".", "base_learning_rate", ",", "\n", "learning_rate_decay", "=", "FLAGS", ".", "learning_rate_decay", ",", "\n", "learning_rate_decay_examples", "=", "FLAGS", ".", "learning_rate_decay_examples", ",", "\n", "regularization_penalty", "=", "FLAGS", ".", "regularization_penalty", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_epochs", "=", "FLAGS", ".", "num_epochs", ")", "\n", "\n", "return", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "0", ",", "keep_checkpoint_every_n_hours", "=", "FLAGS", ".", "time_to_save_model", "/", "60.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.__init__": [[600, 611], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cluster", ",", "task", ")", ":", "\n", "    ", "\"\"\"Creates a ParameterServer.\n\n    Args:\n      cluster: A tf.train.ClusterSpec if the execution is distributed.\n        None otherwise.\n      task: A TaskSpec describing the job type and the task index.\n    \"\"\"", "\n", "\n", "self", ".", "cluster", "=", "cluster", "\n", "self", ".", "task", "=", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run": [[612, 619], ["tensorflow.logging.info", "tensorflow.logging.info", "new_train.start_server", "start_server.join", "new_train.task_as_string", "new_train.ParameterServer.cluster.as_dict"], "methods", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "run", "(", "self", ")", ":", "\n", "    ", "\"\"\"Starts the parameter server.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "\"%s: Starting parameter server within cluster %s.\"", ",", "\n", "task_as_string", "(", "self", ".", "task", ")", ",", "self", ".", "cluster", ".", "as_dict", "(", ")", ")", "\n", "server", "=", "start_server", "(", "self", ".", "cluster", ",", "self", ".", "task", ")", "\n", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.validate_class_name": [[113, 140], ["tensorflow.flags.FlagsError", "getattr", "issubclass", "tensorflow.flags.FlagsError"], "function", ["None"], ["", "def", "validate_class_name", "(", "flag_value", ",", "category", ",", "modules", ",", "expected_superclass", ")", ":", "\n", "  ", "\"\"\"Checks that the given string matches a class of the expected type.\n\n  Args:\n    flag_value: A string naming the class to instantiate.\n    category: A string used further describe the class in error messages\n              (e.g. 'model', 'reader', 'loss').\n    modules: A list of modules to search for the given class.\n    expected_superclass: A class that the given class should inherit from.\n\n  Raises:\n    FlagsError: If the given class could not be found or if the first class\n    found with that name doesn't inherit from the expected superclass.\n\n  Returns:\n    True if a class was found that matches the given constraints.\n  \"\"\"", "\n", "candidates", "=", "[", "getattr", "(", "module", ",", "flag_value", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "for", "candidate", "in", "candidates", ":", "\n", "    ", "if", "not", "candidate", ":", "\n", "      ", "continue", "\n", "", "if", "not", "issubclass", "(", "candidate", ",", "expected_superclass", ")", ":", "\n", "      ", "raise", "flags", ".", "FlagsError", "(", "\"%s '%s' doesn't inherit from %s.\"", "%", "\n", "(", "category", ",", "flag_value", ",", "\n", "expected_superclass", ".", "__name__", ")", ")", "\n", "", "return", "True", "\n", "", "raise", "flags", ".", "FlagsError", "(", "\"Unable to find %s '%s'.\"", "%", "(", "category", ",", "flag_value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors": [[141, 184], ["tensorflow.logging.info", "tensorflow.name_scope", "tensorflow.gfile.Glob", "tensorflow.logging.info", "tensorflow.train.string_input_producer", "tensorflow.train.shuffle_batch_join", "IOError", "str", "reader.prepare_reader", "str", "len", "range"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.readers.YT8MFrameFeatureReader.prepare_reader"], ["", "def", "get_input_data_tensors", "(", "reader", ",", "\n", "data_pattern", ",", "\n", "batch_size", "=", "1000", ",", "\n", "num_epochs", "=", "None", ",", "\n", "num_readers", "=", "1", ")", ":", "\n", "  ", "\"\"\"Creates the section of the graph which reads the training data.\n\n  Args:\n    reader: A class which parses the training data.\n    data_pattern: A 'glob' style path to the data files.\n    batch_size: How many examples to process at a time.\n    num_epochs: How many passes to make over the training data. Set to 'None'\n                to run indefinitely.\n    num_readers: How many I/O threads to use.\n\n  Returns:\n    A tuple containing the features tensor, labels tensor, and optionally a\n    tensor containing the number of frames per video. The exact dimensions\n    depend on the reader being used.\n\n  Raises:\n    IOError: If no files matching the given pattern were found.\n  \"\"\"", "\n", "logging", ".", "info", "(", "\"Using batch size of \"", "+", "str", "(", "batch_size", ")", "+", "\" for training.\"", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"train_input\"", ")", ":", "\n", "    ", "files", "=", "gfile", ".", "Glob", "(", "data_pattern", ")", "\n", "if", "not", "files", ":", "\n", "      ", "raise", "IOError", "(", "\"Unable to find training files. data_pattern='\"", "+", "\n", "data_pattern", "+", "\"'.\"", ")", "\n", "", "logging", ".", "info", "(", "\"Number of training files: %s.\"", ",", "str", "(", "len", "(", "files", ")", ")", ")", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "\n", "files", ",", "num_epochs", "=", "num_epochs", ",", "shuffle", "=", "True", ")", "\n", "training_data", "=", "[", "\n", "reader", ".", "prepare_reader", "(", "filename_queue", ")", "for", "_", "in", "range", "(", "num_readers", ")", "\n", "]", "\n", "\n", "return", "tf", ".", "train", ".", "shuffle_batch_join", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "capacity", "=", "batch_size", "*", "5", ",", "\n", "min_after_dequeue", "=", "batch_size", ",", "\n", "allow_smaller_final_batch", "=", "True", ",", "\n", "enqueue_many", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name": [[186, 190], ["next", "getattr"], "function", ["None"], ["", "", "def", "find_class_by_name", "(", "name", ",", "modules", ")", ":", "\n", "  ", "\"\"\"Searches the provided modules for the named class and returns it.\"\"\"", "\n", "modules", "=", "[", "getattr", "(", "module", ",", "name", ",", "None", ")", "for", "module", "in", "modules", "]", "\n", "return", "next", "(", "a", "for", "a", "in", "modules", "if", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.build_graph": [[191, 357], ["losses.CrossEntropyLoss", "tensorflow.Variable", "tensorflow.python.client.device_lib.list_local_devices", "len", "tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "optimizer_class", "new_train.get_input_data_tensors", "tensorflow.summary.histogram", "tensorflow.nn.l2_normalize", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.constant", "range", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "utils.combine_gradients", "optimizer_class.apply_gradients", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.logging.info", "tensorflow.logging.info", "len", "tensorflow.stack", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "model_input_raw.get_shape", "tensorflow.device", "tensorflow.stack", "tensorflow.name_scope", "utils.clip_gradient_norms", "str", "tensorflow.variable_scope", "tensorflow.arg_scope", "model.create_model", "tensorflow.get_model_variables", "tower_predictions.append", "tower_features.append", "tensorflow.losses.get_regularization_losses", "tower_reg_losses.append", "tensorflow.get_collection", "tower_label_losses.append", "optimizer_class.compute_gradients", "tower_gradients.append", "tensorflow.summary.histogram", "model.create_model.keys", "label_loss_fn.calculate_loss", "model.create_model.keys", "tensorflow.constant", "tensorflow.add_n", "model.create_model.keys", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.control_dependencies", "tensorflow.identity"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_input_data_tensors", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.video_level_models.zhao_MoeModel.create_model", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss"], ["", "def", "build_graph", "(", "reader", ",", "\n", "model", ",", "\n", "train_data_pattern", ",", "\n", "label_loss_fn", "=", "losses", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "batch_size", "=", "1000", ",", "\n", "base_learning_rate", "=", "0.01", ",", "\n", "learning_rate_decay_examples", "=", "1000000", ",", "\n", "learning_rate_decay", "=", "0.95", ",", "\n", "optimizer_class", "=", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "clip_gradient_norm", "=", "1.0", ",", "\n", "regularization_penalty", "=", "1", ",", "\n", "num_readers", "=", "1", ",", "\n", "num_epochs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Tensorflow graph.\n\n  This will only be called once in the life of\n  a training model, because after the graph is created the model will be\n  restored from a meta graph file rather than being recreated.\n\n  Args:\n    reader: The data file reader. It should inherit from BaseReader.\n    model: The core model (e.g. logistic or neural net). It should inherit\n           from BaseModel.\n    train_data_pattern: glob path to the training data files.\n    label_loss_fn: What kind of loss to apply to the model. It should inherit\n                from BaseLoss.\n    batch_size: How many examples to process at a time.\n    base_learning_rate: What learning rate to initialize the optimizer with.\n    optimizer_class: Which optimization algorithm to use.\n    clip_gradient_norm: Magnitude of the gradient to clip to.\n    regularization_penalty: How much weight to give the regularization loss\n                            compared to the label loss.\n    num_readers: How many threads to use for I/O operations.\n    num_epochs: How many passes to make over the data. 'None' means an\n                unlimited number of passes.\n  \"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "\n", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", ")", "\n", "gpus", "=", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "num_gpus", "=", "len", "(", "gpus", ")", "\n", "\n", "if", "num_gpus", ">", "0", ":", "\n", "    ", "logging", ".", "info", "(", "\"Using the following GPUs to train: \"", "+", "str", "(", "gpus", ")", ")", "\n", "num_towers", "=", "num_gpus", "\n", "device_string", "=", "'/gpu:%d'", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"No GPUs found. Training on CPU.\"", ")", "\n", "num_towers", "=", "1", "\n", "device_string", "=", "'/cpu:%d'", "\n", "\n", "", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "base_learning_rate", ",", "\n", "global_step", "*", "batch_size", "*", "num_towers", ",", "\n", "learning_rate_decay_examples", ",", "\n", "learning_rate_decay", ",", "\n", "staircase", "=", "True", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", "\n", "\n", "optimizer", "=", "optimizer_class", "(", "learning_rate", ")", "\n", "unused_video_id", ",", "model_input_raw", ",", "labels_batch", ",", "num_frames", "=", "(", "\n", "get_input_data_tensors", "(", "\n", "reader", ",", "\n", "train_data_pattern", ",", "\n", "batch_size", "=", "batch_size", "*", "num_towers", ",", "\n", "num_readers", "=", "num_readers", ",", "\n", "num_epochs", "=", "num_epochs", ")", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"model/input_raw\"", ",", "model_input_raw", ")", "\n", "\n", "feature_dim", "=", "len", "(", "model_input_raw", ".", "get_shape", "(", ")", ")", "-", "1", "\n", "\n", "model_input", "=", "tf", ".", "nn", ".", "l2_normalize", "(", "model_input_raw", ",", "feature_dim", ")", "\n", "\n", "tower_inputs", "=", "tf", ".", "split", "(", "model_input", ",", "num_towers", ")", "\n", "tower_labels", "=", "tf", ".", "split", "(", "labels_batch", ",", "num_towers", ")", "\n", "tower_num_frames", "=", "tf", ".", "split", "(", "num_frames", ",", "num_towers", ")", "\n", "tower_gradients", "=", "[", "]", "\n", "tower_predictions", "=", "[", "]", "\n", "tower_label_losses", "=", "[", "]", "\n", "tower_reg_losses", "=", "[", "]", "\n", "\n", "tower_features", "=", "[", "]", "\n", "\n", "keep_prob", "=", "tf", ".", "constant", "(", "FLAGS", ".", "keep_prob", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_towers", ")", ":", "\n", "# For some reason these 'with' statements can't be combined onto the same", "\n", "# line. They have to be nested.", "\n", "    ", "with", "tf", ".", "device", "(", "device_string", "%", "i", ")", ":", "\n", "      ", "with", "(", "tf", ".", "variable_scope", "(", "(", "\"tower\"", ")", ",", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ")", ":", "\n", "        ", "with", "(", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "device", "=", "\"/cpu:0\"", "if", "num_gpus", "!=", "1", "else", "\"/gpu:0\"", ")", ")", ":", "\n", "          ", "result", "=", "model", ".", "create_model", "(", "\n", "tower_inputs", "[", "i", "]", ",", "\n", "num_frames", "=", "tower_num_frames", "[", "i", "]", ",", "\n", "vocab_size", "=", "reader", ".", "num_classes", ",", "\n", "labels", "=", "tower_labels", "[", "i", "]", ",", "\n", "keep_prob", "=", "keep_prob", ")", "\n", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", "\n", "\n", "", "predictions", "=", "result", "[", "\"predictions\"", "]", "\n", "tower_predictions", ".", "append", "(", "predictions", ")", "\n", "\n", "features", "=", "result", "[", "\"features\"", "]", "\n", "tower_features", ".", "append", "(", "features", ")", "\n", "\n", "\n", "if", "\"loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "label_loss", "=", "result", "[", "\"loss\"", "]", "\n", "", "else", ":", "\n", "            ", "label_loss", "=", "label_loss_fn", ".", "calculate_loss", "(", "predictions", ",", "tower_labels", "[", "i", "]", ")", "\n", "\n", "", "if", "\"regularization_loss\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "reg_loss", "=", "result", "[", "\"regularization_loss\"", "]", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "tf", ".", "constant", "(", "0.0", ")", "\n", "\n", "", "reg_losses", "=", "tf", ".", "losses", ".", "get_regularization_losses", "(", ")", "\n", "if", "reg_losses", ":", "\n", "            ", "reg_loss", "+=", "tf", ".", "add_n", "(", "reg_losses", ")", "\n", "\n", "", "tower_reg_losses", ".", "append", "(", "reg_loss", ")", "\n", "\n", "# Adds update_ops (e.g., moving average updates in batch normalization) as", "\n", "# a dependency to the train_op.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "\"update_ops\"", "in", "result", ".", "keys", "(", ")", ":", "\n", "            ", "update_ops", "+=", "result", "[", "\"update_ops\"", "]", "\n", "", "if", "update_ops", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "              ", "barrier", "=", "tf", ".", "no_op", "(", "name", "=", "\"gradient_barrier\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "barrier", "]", ")", ":", "\n", "                ", "label_loss", "=", "tf", ".", "identity", "(", "label_loss", ")", "\n", "\n", "", "", "", "tower_label_losses", ".", "append", "(", "label_loss", ")", "\n", "\n", "# Incorporate the L2 weight penalties etc.", "\n", "final_loss", "=", "regularization_penalty", "*", "reg_loss", "+", "label_loss", "\n", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "final_loss", ",", "\n", "colocate_gradients_with_ops", "=", "False", ")", "\n", "tower_gradients", ".", "append", "(", "gradients", ")", "\n", "", "", "", "", "label_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_label_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"label_loss\"", ",", "label_loss", ")", "\n", "if", "regularization_penalty", "!=", "0", ":", "\n", "    ", "reg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "stack", "(", "tower_reg_losses", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"reg_loss\"", ",", "reg_loss", ")", "\n", "", "merged_gradients", "=", "utils", ".", "combine_gradients", "(", "tower_gradients", ")", "\n", "\n", "if", "clip_gradient_norm", ">", "0", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'clip_grads'", ")", ":", "\n", "      ", "merged_gradients", "=", "utils", ".", "clip_gradient_norms", "(", "merged_gradients", ",", "clip_gradient_norm", ")", "\n", "\n", "", "", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "merged_gradients", ",", "global_step", "=", "global_step", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"global_step\"", ",", "global_step", ")", "\n", "tf", ".", "add_to_collection", "(", "\"loss\"", ",", "label_loss", ")", "\n", "tf", ".", "add_to_collection", "(", "\"predictions\"", ",", "tf", ".", "concat", "(", "tower_predictions", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch_raw\"", ",", "model_input_raw", ")", "\n", "tf", ".", "add_to_collection", "(", "\"input_batch\"", ",", "model_input", ")", "\n", "tf", ".", "add_to_collection", "(", "\"num_frames\"", ",", "num_frames", ")", "\n", "tf", ".", "add_to_collection", "(", "\"labels\"", ",", "tf", ".", "cast", "(", "labels_batch", ",", "tf", ".", "float32", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"train_op\"", ",", "train_op", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "\"features\"", ",", "tf", ".", "concat", "(", "tower_features", ",", "0", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "\"keep_prob\"", ",", "keep_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader": [[582, 595], ["utils.GetListOfFeatureNamesAndSizes", "readers.YT8MFrameFeatureReader", "readers.YT8MAggregatedFeatureReader"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes"], ["", "", "def", "get_reader", "(", ")", ":", "\n", "# Convert feature_names and feature_sizes to lists of values.", "\n", "  ", "feature_names", ",", "feature_sizes", "=", "utils", ".", "GetListOfFeatureNamesAndSizes", "(", "\n", "FLAGS", ".", "feature_names", ",", "FLAGS", ".", "feature_sizes", ")", "\n", "\n", "if", "FLAGS", ".", "frame_features", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MFrameFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "", "else", ":", "\n", "    ", "reader", "=", "readers", ".", "YT8MAggregatedFeatureReader", "(", "\n", "feature_names", "=", "feature_names", ",", "feature_sizes", "=", "feature_sizes", ")", "\n", "\n", "", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.start_server": [[621, 643], ["tensorflow.train.Server", "ValueError", "ValueError", "tensorflow.train.ClusterSpec", "new_train.task_as_string", "new_train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "", "def", "start_server", "(", "cluster", ",", "task", ")", ":", "\n", "  ", "\"\"\"Creates a Server.\n\n  Args:\n    cluster: A tf.train.ClusterSpec if the execution is distributed.\n      None otherwise.\n    task: A TaskSpec describing the job type and the task index.\n  \"\"\"", "\n", "\n", "if", "not", "task", ".", "type", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task type must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "", "if", "task", ".", "index", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: The task index must be specified.\"", "%", "\n", "task_as_string", "(", "task", ")", ")", "\n", "\n", "# Create and start a server.", "\n", "", "return", "tf", ".", "train", ".", "Server", "(", "\n", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster", ")", ",", "\n", "protocol", "=", "\"grpc\"", ",", "\n", "job_name", "=", "task", ".", "type", ",", "\n", "task_index", "=", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string": [[644, 646], ["None"], "function", ["None"], ["", "def", "task_as_string", "(", "task", ")", ":", "\n", "  ", "return", "\"/job:%s/task:%s\"", "%", "(", "task", ".", "type", ",", "task", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.main": [[647, 685], ["json.loads", "json.loads.get", "type", "tensorflow.logging.set_verbosity", "tensorflow.logging.info", "os.environ.get", "tensorflow.train.ClusterSpec", "json.loads.get", "new_train.task_as_string", "new_train.get_reader", "export_model.ModelExporter", "new_train.Trainer.run", "new_train.find_class_by_name", "new_train.ParameterServer.run", "ValueError", "new_train.Trainer", "new_train.ParameterServer", "new_train.task_as_string"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.get_reader", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.find_class_by_name", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.ParameterServer.run", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.new_train.task_as_string"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Load the environment.", "\n", "  ", "env", "=", "json", ".", "loads", "(", "os", ".", "environ", ".", "get", "(", "\"TF_CONFIG\"", ",", "\"{}\"", ")", ")", "\n", "\n", "# Load the cluster data from the environment.", "\n", "cluster_data", "=", "env", ".", "get", "(", "\"cluster\"", ",", "None", ")", "\n", "cluster", "=", "tf", ".", "train", ".", "ClusterSpec", "(", "cluster_data", ")", "if", "cluster_data", "else", "None", "\n", "\n", "# Load the task data from the environment.", "\n", "task_data", "=", "env", ".", "get", "(", "\"task\"", ",", "None", ")", "or", "{", "\"type\"", ":", "\"master\"", ",", "\"index\"", ":", "0", "}", "\n", "task", "=", "type", "(", "\"TaskSpec\"", ",", "(", "object", ",", ")", ",", "task_data", ")", "\n", "\n", "# Logging the version.", "\n", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "logging", ".", "info", "(", "\"%s: Tensorflow version: %s.\"", ",", "\n", "task_as_string", "(", "task", ")", ",", "tf", ".", "__version__", ")", "\n", "\n", "# Dispatch to a master, a worker, or a parameter server.", "\n", "if", "not", "cluster", "or", "task", ".", "type", "==", "\"master\"", "or", "task", ".", "type", "==", "\"worker\"", ":", "\n", "    ", "model", "=", "find_class_by_name", "(", "FLAGS", ".", "model", ",", "\n", "[", "frame_level_models", ",", "video_level_models", "]", ")", "(", ")", "\n", "\n", "reader", "=", "get_reader", "(", ")", "\n", "\n", "model_exporter", "=", "export_model", ".", "ModelExporter", "(", "\n", "frame_features", "=", "FLAGS", ".", "frame_features", ",", "\n", "model", "=", "model", ",", "\n", "reader", "=", "reader", ")", "\n", "\n", "Trainer", "(", "cluster", ",", "task", ",", "FLAGS", ".", "train_dir", ",", "model", ",", "reader", ",", "model_exporter", ",", "\n", "FLAGS", ".", "log_device_placement", ",", "FLAGS", ".", "max_steps", ",", "\n", "FLAGS", ".", "export_model_steps", ")", ".", "run", "(", "start_new_model", "=", "FLAGS", ".", "start_new_model", ")", "\n", "\n", "", "elif", "task", ".", "type", "==", "\"ps\"", ":", "\n", "    ", "ParameterServer", "(", "cluster", ",", "task", ")", ".", "run", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"%s: Invalid task_type: %s.\"", "%", "\n", "(", "task_as_string", "(", "task", ")", ",", "task", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.Dequantize": [[23, 39], ["None"], "function", ["None"], ["def", "Dequantize", "(", "feat_vector", ",", "max_quantized_value", "=", "2", ",", "min_quantized_value", "=", "-", "2", ")", ":", "\n", "  ", "\"\"\"Dequantize the feature from the byte format to the float format.\n\n  Args:\n    feat_vector: the input 1-d vector.\n    max_quantized_value: the maximum of the quantized value.\n    min_quantized_value: the minimum of the quantized value.\n\n  Returns:\n    A float vector which has the same shape as feat_vector.\n  \"\"\"", "\n", "assert", "max_quantized_value", ">", "min_quantized_value", "\n", "quantized_range", "=", "max_quantized_value", "-", "min_quantized_value", "\n", "scalar", "=", "quantized_range", "/", "255.0", "\n", "bias", "=", "(", "quantized_range", "/", "512.0", ")", "+", "min_quantized_value", "\n", "return", "feat_vector", "*", "scalar", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary": [[41, 48], ["tensorflow.Summary", "tf.Summary.value.add", "str", "float"], "function", ["None"], ["", "def", "MakeSummary", "(", "name", ",", "value", ")", ":", "\n", "  ", "\"\"\"Creates a tf.Summary proto with the given name and value.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "val", "=", "summary", ".", "value", ".", "add", "(", ")", "\n", "val", ".", "tag", "=", "str", "(", "name", ")", "\n", "val", ".", "simple_value", "=", "float", "(", "value", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddGlobalStepSummary": [[50, 92], ["global_step_info_dict.get", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "summary_writer.add_summary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.eval_util.EvaluationMetrics.get", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddGlobalStepSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "global_step_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the global_step summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    global_step_info_dict: a dictionary of the evaluation metrics calculated for\n      a mini-batch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "this_hit_at_one", "=", "global_step_info_dict", "[", "\"hit_at_one\"", "]", "\n", "this_perr", "=", "global_step_info_dict", "[", "\"perr\"", "]", "\n", "this_loss", "=", "global_step_info_dict", "[", "\"loss\"", "]", "\n", "examples_per_second", "=", "global_step_info_dict", ".", "get", "(", "\"examples_per_second\"", ",", "-", "1", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Hit@1\"", ",", "this_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Perr\"", ",", "this_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Loss\"", ",", "this_loss", ")", ",", "\n", "global_step_val", ")", "\n", "\n", "if", "examples_per_second", "!=", "-", "1", ":", "\n", "    ", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"GlobalStep/\"", "+", "summary_scope", "+", "\"_Example_Second\"", ",", "\n", "examples_per_second", ")", ",", "global_step_val", ")", "\n", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "info", "=", "(", "\"global_step {0} | Batch Hit@1: {1:.3f} | Batch PERR: {2:.3f} | Batch Loss: {3:.3f} \"", "\n", "\"| Examples_per_sec: {4:.3f}\"", ")", ".", "format", "(", "\n", "global_step_val", ",", "this_hit_at_one", ",", "this_perr", ",", "this_loss", ",", "\n", "examples_per_second", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.AddEpochSummary": [[94, 139], ["numpy.mean", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.add_summary", "summary_writer.flush", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary", "utils.MakeSummary"], "function", ["home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary", "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.MakeSummary"], ["", "def", "AddEpochSummary", "(", "summary_writer", ",", "\n", "global_step_val", ",", "\n", "epoch_info_dict", ",", "\n", "summary_scope", "=", "\"Eval\"", ")", ":", "\n", "  ", "\"\"\"Add the epoch summary to the Tensorboard.\n\n  Args:\n    summary_writer: Tensorflow summary_writer.\n    global_step_val: a int value of the global step.\n    epoch_info_dict: a dictionary of the evaluation metrics calculated for the\n      whole epoch.\n    summary_scope: Train or Eval.\n\n  Returns:\n    A string of this global_step summary\n  \"\"\"", "\n", "epoch_id", "=", "epoch_info_dict", "[", "\"epoch_id\"", "]", "\n", "avg_hit_at_one", "=", "epoch_info_dict", "[", "\"avg_hit_at_one\"", "]", "\n", "avg_perr", "=", "epoch_info_dict", "[", "\"avg_perr\"", "]", "\n", "avg_loss", "=", "epoch_info_dict", "[", "\"avg_loss\"", "]", "\n", "aps", "=", "epoch_info_dict", "[", "\"aps\"", "]", "\n", "gap", "=", "epoch_info_dict", "[", "\"gap\"", "]", "\n", "mean_ap", "=", "numpy", ".", "mean", "(", "aps", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Hit@1\"", ",", "avg_hit_at_one", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Perr\"", ",", "avg_perr", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_Avg_Loss\"", ",", "avg_loss", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_MAP\"", ",", "mean_ap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "add_summary", "(", "\n", "MakeSummary", "(", "\"Epoch/\"", "+", "summary_scope", "+", "\"_GAP\"", ",", "gap", ")", ",", "\n", "global_step_val", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "info", "=", "(", "\"epoch/eval number {0} | Avg_Hit@1: {1:.3f} | Avg_PERR: {2:.3f} \"", "\n", "\"| MAP: {3:.3f} | GAP: {4:.3f} | Avg_Loss: {5:3f}\"", ")", ".", "format", "(", "\n", "epoch_id", ",", "avg_hit_at_one", ",", "avg_perr", ",", "mean_ap", ",", "gap", ",", "avg_loss", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.GetListOfFeatureNamesAndSizes": [[140, 162], ["feature_names.strip", "int", "len", "len", "tensorflow.logging.error", "feature_names.split", "feature_sizes.split", "str", "len", "str", "len"], "function", ["None"], ["", "def", "GetListOfFeatureNamesAndSizes", "(", "feature_names", ",", "feature_sizes", ")", ":", "\n", "  ", "\"\"\"Extract the list of feature names and the dimensionality of each feature\n     from string of comma separated values.\n\n  Args:\n    feature_names: string containing comma separated list of feature names\n    feature_sizes: string containing comma separated list of feature sizes\n\n  Returns:\n    List of the feature names and list of the dimensionality of each feature.\n    Elements in the first/second list are strings/integers.\n  \"\"\"", "\n", "list_of_feature_names", "=", "[", "\n", "feature_names", ".", "strip", "(", ")", "for", "feature_names", "in", "feature_names", ".", "split", "(", "','", ")", "]", "\n", "list_of_feature_sizes", "=", "[", "\n", "int", "(", "feature_sizes", ")", "for", "feature_sizes", "in", "feature_sizes", ".", "split", "(", "','", ")", "]", "\n", "if", "len", "(", "list_of_feature_names", ")", "!=", "len", "(", "list_of_feature_sizes", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"length of the feature names (=\"", "+", "\n", "str", "(", "len", "(", "list_of_feature_names", ")", ")", "+", "\") != length of feature \"", "\n", "\"sizes (=\"", "+", "str", "(", "len", "(", "list_of_feature_sizes", ")", ")", "+", "\")\"", ")", "\n", "\n", "", "return", "list_of_feature_names", ",", "list_of_feature_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.clip_gradient_norms": [[163, 183], ["clipped_grads_and_vars.append", "isinstance", "tensorflow.clip_by_norm", "tensorflow.IndexedSlices", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "clip_gradient_norms", "(", "gradients_to_variables", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clips the gradients by the given value.\n\n  Args:\n    gradients_to_variables: A list of gradient to variable pairs (tuples).\n    max_norm: the maximum norm value.\n\n  Returns:\n    A list of clipped gradient to variable pairs.\n  \"\"\"", "\n", "clipped_grads_and_vars", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "gradients_to_variables", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "tmp", "=", "tf", ".", "clip_by_norm", "(", "grad", ".", "values", ",", "max_norm", ")", "\n", "grad", "=", "tf", ".", "IndexedSlices", "(", "tmp", ",", "grad", ".", "indices", ",", "grad", ".", "dense_shape", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "tf", ".", "clip_by_norm", "(", "grad", ",", "max_norm", ")", "\n", "", "", "clipped_grads_and_vars", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "", "return", "clipped_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.utils.combine_gradients": [[184, 206], ["xrange", "len", "tensorflow.stack", "tensorflow.reduce_sum", "final_grads.append", "xrange", "len"], "function", ["None"], ["", "def", "combine_gradients", "(", "tower_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the combined gradient for each shared variable across all towers.\n\n  Note that this function provides a synchronization point across all towers.\n\n  Args:\n    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n      is over individual gradients. The inner list is over the gradient\n      calculation for each tower.\n  Returns:\n     List of pairs of (gradient, variable) where the gradient has been summed\n     across all towers.\n  \"\"\"", "\n", "filtered_grads", "=", "[", "[", "x", "for", "x", "in", "grad_list", "if", "x", "[", "0", "]", "is", "not", "None", "]", "for", "grad_list", "in", "tower_grads", "]", "\n", "final_grads", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "filtered_grads", "[", "0", "]", ")", ")", ":", "\n", "    ", "grads", "=", "[", "filtered_grads", "[", "t", "]", "[", "i", "]", "for", "t", "in", "xrange", "(", "len", "(", "filtered_grads", ")", ")", "]", "\n", "grad", "=", "tf", ".", "stack", "(", "[", "x", "[", "0", "]", "for", "x", "in", "grads", "]", ",", "0", ")", "\n", "grad", "=", "tf", ".", "reduce_sum", "(", "grad", ",", "0", ")", "\n", "final_grads", ".", "append", "(", "(", "grad", ",", "filtered_grads", "[", "0", "]", "[", "i", "]", "[", "1", "]", ",", ")", ")", "\n", "\n", "", "return", "final_grads", "\n", "", ""]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.BaseLoss.calculate_loss": [[23, 38], ["NotImplementedError"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "unused_predictions", ",", "unused_labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "\"\"\"Calculates the average loss of the examples in a mini-batch.\n\n     Args:\n      unused_predictions: a 2-d tensor storing the prediction scores, in which\n        each row represents a sample in the mini-batch and each column\n        represents a class.\n      unused_labels: a 2-d tensor storing the labels, which has the same shape\n        as the unused_predictions. The labels must be in the range of 0 and 1.\n      unused_params: loss specific parameters.\n\n    Returns:\n      A scalar loss tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.CrossEntropyLoss.calculate_loss": [[44, 52], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.negative", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.log", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_xent\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-6", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "cross_entropy_loss", "=", "float_labels", "*", "tf", ".", "log", "(", "predictions", "+", "epsilon", ")", "+", "(", "\n", "1", "-", "float_labels", ")", "*", "tf", ".", "log", "(", "1", "-", "predictions", "+", "epsilon", ")", "\n", "cross_entropy_loss", "=", "tf", ".", "negative", "(", "cross_entropy_loss", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "cross_entropy_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.HingeLoss.calculate_loss": [[62, 71], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.subtract", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.shape", "tensorflow.scalar_mul", "tensorflow.reduce_sum", "tensorflow.scalar_mul"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "b", "=", "1.0", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_hinge\"", ")", ":", "\n", "      ", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "all_zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "float_labels", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "sign_labels", "=", "tf", ".", "subtract", "(", "tf", ".", "scalar_mul", "(", "2", ",", "float_labels", ")", ",", "all_ones", ")", "\n", "hinge_loss", "=", "tf", ".", "maximum", "(", "\n", "all_zeros", ",", "tf", ".", "scalar_mul", "(", "b", ",", "all_ones", ")", "-", "sign_labels", "*", "predictions", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "hinge_loss", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tsingularity_youtube-8m.frame_level.losses.SoftmaxLoss.calculate_loss": [[85, 98], ["tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.maximum", "tensorflow.div", "tensorflow.nn.softmax", "tensorflow.negative", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.multiply", "tensorflow.log"], "methods", ["None"], ["def", "calculate_loss", "(", "self", ",", "predictions", ",", "labels", ",", "**", "unused_params", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"loss_softmax\"", ")", ":", "\n", "      ", "epsilon", "=", "10e-8", "\n", "float_labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", "\n", "# l1 normalization (labels are no less than 0)", "\n", "label_rowsum", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "reduce_sum", "(", "float_labels", ",", "1", ",", "keep_dims", "=", "True", ")", ",", "\n", "epsilon", ")", "\n", "norm_float_labels", "=", "tf", ".", "div", "(", "float_labels", ",", "label_rowsum", ")", "\n", "softmax_outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "predictions", ")", "\n", "softmax_loss", "=", "tf", ".", "negative", "(", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "multiply", "(", "norm_float_labels", ",", "tf", ".", "log", "(", "softmax_outputs", ")", ")", ",", "1", ")", ")", "\n", "", "return", "tf", ".", "reduce_mean", "(", "softmax_loss", ")", "\n", "", "", ""]]}