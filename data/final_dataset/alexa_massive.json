{"home.repos.pwc.inspect_result.alexa_massive.utils.training_args.MASSIVETrainingArguments.__init__": [[31, 48], ["kwargs.copy", "transformers.TrainingArguments.__init__", "kwargs.pop", "setattr"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "# add any MASSIVE-specific keyword arguments and S2S-specific kw arguments here:", "\n", "        ", "massive_kwargs", "=", "[", "\n", "'locale_eval_strategy'", ",", "\n", "'predict_with_generate'", ",", "\n", "'generation_max_length'", ",", "\n", "'generation_num_beams'", "\n", "]", "\n", "\n", "# pop MASSIVE-specific keyword args and set them", "\n", "for", "arg", "in", "kwargs", ".", "copy", "(", ")", ":", "\n", "            ", "if", "arg", "in", "massive_kwargs", ":", "\n", "                ", "val", "=", "kwargs", ".", "pop", "(", "arg", ")", "\n", "setattr", "(", "self", ",", "arg", ",", "val", ")", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVETrainer.__init__": [[34, 36], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVETrainer.evaluate": [[37, 150], ["trainer.MASSIVETrainer._memory_tracker.start", "trainer.MASSIVETrainer.callback_handler.on_evaluate", "trainer.MASSIVETrainer._memory_tracker.stop_and_update_metrics", "trainer.MASSIVETrainer.log", "sorted", "sorted.append", "trainer.MASSIVETrainer.get_eval_dataloader", "time.time", "eval_loop", "trainer.MASSIVETrainer.update", "trainer.MASSIVETrainer.update", "trainer.MASSIVETrainer._find_log_highest_lowest_locales", "transformers.trainer_utils.EvalLoopOutput", "set", "NotImplementedError", "datasets.logging.get_verbosity", "datasets.logging.set_verbosity", "eval_dataset.filter", "datasets.logging.set_verbosity", "transformers.trainer_utils.speed_metrics", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer._find_log_highest_lowest_locales"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", "=", "None", ",", "ignore_keys", "=", "None", ",", "metric_key_prefix", "=", "'eval'", ",", "\n", "return_all_outputs", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from:\n        https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py\n\n        Run evaluation and returns metrics.\n        The calling script will be responsible for providing a method to compute metrics, as they\n        are task-dependent (pass it to the init :obj:`compute_metrics` argument).\n        You can also subclass and override this method to inject custom behavior.\n\n        Args:\n            eval_dataset (:obj:`Dataset`, `optional`):\n                Pass a dataset if you wish to override :obj:`self.eval_dataset`. If it is an\n                :obj:`datasets.Dataset`, columns not accepted by the ``model.forward()`` method\n                are automatically removed. It must implement the\n                :obj:`__len__` method.\n            ignore_keys (:obj:`Lst[str]`, `optional`):\n                A list of keys in the output of your model (if it is a dictionary) that should be\n                ignored when gathering predictions.\n            metric_key_prefix (:obj:`str`, `optional`, defaults to :obj:`\"eval\"`):\n                An optional prefix to be used as the metrics key prefix. For example the metrics\n                \"bleu\" will be named \"eval_bleu\" if the prefix is \"eval\" (default)\n\n        Returns:\n            A dictionary containing the evaluation loss and the potential metrics computed from\n            the predictions. The dictionary also contains the epoch number which comes from the\n            training state.\n        \"\"\"", "\n", "\n", "# memory metrics - must set up as early as possible", "\n", "self", ".", "_memory_tracker", ".", "start", "(", ")", "\n", "\n", "# use two prefixes and add step/epoch info", "\n", "first_metric_key_prefix", "=", "metric_key_prefix", "\n", "metrics", "=", "{", "}", "\n", "metrics", "[", "'training_global_step'", "]", "=", "self", ".", "state", ".", "global_step", "\n", "metrics", "[", "'training_epoch'", "]", "=", "self", ".", "state", ".", "epoch", "\n", "\n", "eval_dataset", "=", "eval_dataset", "if", "eval_dataset", "else", "self", ".", "eval_dataset", "\n", "\n", "# Create a list of eval runs based on the strategy", "\n", "if", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all and each\"", ":", "\n", "            ", "locales", "=", "sorted", "(", "set", "(", "eval_dataset", "[", "'locale'", "]", ")", ")", "\n", "locales", ".", "append", "(", "'all'", ")", "\n", "", "elif", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all only\"", ":", "\n", "            ", "locales", "=", "[", "'all'", "]", "\n", "# add more strategies here", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'locale_eval_strategy not known'", ")", "\n", "\n", "# loop through all locales (including \"all\") and run evaluation", "\n", "", "for", "locale", "in", "locales", ":", "\n", "\n", "            ", "metric_key_prefix", "=", "first_metric_key_prefix", "+", "\"_\"", "+", "locale", "\n", "if", "locale", "==", "'all'", ":", "\n", "# use whole dataset", "\n", "                ", "dataset", "=", "eval_dataset", "\n", "", "else", ":", "\n", "# filter only to relevant locale", "\n", "# This will warn us every time it loads a cached dataset, which is annoying", "\n", "# I agree with stas00 here: https://github.com/huggingface/datasets/issues/1948", "\n", "# We'll suppress these warnings by temporarily changing the logging level", "\n", "                ", "lvl", "=", "datasets", ".", "logging", ".", "get_verbosity", "(", ")", "\n", "datasets", ".", "logging", ".", "set_verbosity", "(", "50", ")", "\n", "dataset", "=", "eval_dataset", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "==", "locale", ")", "\n", "datasets", ".", "logging", ".", "set_verbosity", "(", "lvl", ")", "\n", "\n", "", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "dataset", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "eval_loop", "=", "self", ".", "prediction_loop", "if", "self", ".", "args", ".", "use_legacy_prediction_loop", "else", "self", ".", "evaluation_loop", "\n", "output", "=", "eval_loop", "(", "\n", "eval_dataloader", ",", "\n", "description", "=", "\"Evaluation\"", ",", "\n", "# No point gathering the predictions if there are no metrics, otherwise we defer to", "\n", "# self.args.prediction_loss_only", "\n", "prediction_loss_only", "=", "True", "if", "self", ".", "compute_metrics", "is", "None", "else", "None", ",", "\n", "ignore_keys", "=", "ignore_keys", ",", "\n", "metric_key_prefix", "=", "metric_key_prefix", ",", "\n", ")", "\n", "metrics", ".", "update", "(", "output", ".", "metrics", ")", "\n", "\n", "total_batch_size", "=", "self", ".", "args", ".", "eval_batch_size", "*", "self", ".", "args", ".", "world_size", "\n", "metrics", ".", "update", "(", "\n", "speed_metrics", "(", "\n", "metric_key_prefix", ",", "\n", "start_time", ",", "\n", "num_samples", "=", "output", ".", "num_samples", ",", "\n", "num_steps", "=", "math", ".", "ceil", "(", "output", ".", "num_samples", "/", "total_batch_size", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_evaluate", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "\n", "metrics", ")", "\n", "\n", "self", ".", "_memory_tracker", ".", "stop_and_update_metrics", "(", "metrics", ")", "\n", "\n", "if", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all and each\"", ":", "\n", "            ", "metrics", "=", "self", ".", "_find_log_highest_lowest_locales", "(", "metrics", ")", "\n", "\n", "", "if", "return_all_outputs", ":", "\n", "            ", "return", "EvalLoopOutput", "(", "\n", "predictions", "=", "output", ".", "predictions", ",", "\n", "label_ids", "=", "output", ".", "label_ids", ",", "\n", "metrics", "=", "metrics", ",", "\n", "num_samples", "=", "output", ".", "num_samples", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "metrics", ")", "\n", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVETrainer.predict": [[151, 191], ["trainer.MASSIVETrainer.evaluate", "collections.namedtuple", "collections.namedtuple.", "trainer.MASSIVETrainer.tokenizer", "trainer.MASSIVETrainer.word_ids", "range", "tokenizer.convert_ids_to_tokens", "len"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.evaluate"], ["", "def", "predict", "(", "self", ",", "test_dataset", ",", "ignore_keys", "=", "None", ",", "metric_key_prefix", "=", "'test'", ",", "tokenizer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Overriding this method for custom test result logging using `evaluate`\n        \"\"\"", "\n", "\n", "output", "=", "self", ".", "evaluate", "(", "\n", "test_dataset", ",", "\n", "ignore_keys", ",", "\n", "metric_key_prefix", ",", "\n", "return_all_outputs", "=", "True", "\n", ")", "\n", "\n", "PredictionOutput", "=", "namedtuple", "(", "\n", "'PredictionOutput'", ",", "\n", "[", "'predictions'", ",", "'label_ids'", ",", "'metrics'", ",", "'ids'", ",", "'locales'", ",", "'utts'", ",", "'tok_utts'", ",", "\n", "'subword_aligns'", "]", "\n", ")", "\n", "\n", "subword_aligns", "=", "None", "\n", "if", "tokenizer", ":", "\n", "            ", "tokenized_inputs", "=", "self", ".", "tokenizer", "(", "\n", "[", "item", "[", "'utt'", "]", "for", "item", "in", "test_dataset", "]", ",", "\n", "truncation", "=", "True", ",", "\n", "is_split_into_words", "=", "True", "\n", ")", "\n", "subword_aligns", "=", "[", "tokenized_inputs", ".", "word_ids", "(", "batch_index", "=", "i", ")", "for", "i", "in", "range", "(", "len", "(", "test_dataset", ")", ")", "]", "\n", "\n", "", "preds", "=", "PredictionOutput", "(", "\n", "predictions", "=", "output", ".", "predictions", ",", "\n", "label_ids", "=", "output", ".", "label_ids", ",", "\n", "metrics", "=", "output", ".", "metrics", ",", "\n", "ids", "=", "[", "x", "[", "'id'", "]", "for", "x", "in", "test_dataset", "]", ",", "\n", "locales", "=", "[", "x", "[", "'locale'", "]", "for", "x", "in", "test_dataset", "]", ",", "\n", "utts", "=", "[", "x", "[", "'utt'", "]", "for", "x", "in", "test_dataset", "]", ",", "\n", "tok_utts", "=", "[", "tokenizer", ".", "convert_ids_to_tokens", "(", "x", ")", "for", "x", "in", "tokenized_inputs", ".", "input_ids", "]", ",", "\n", "subword_aligns", "=", "subword_aligns", "\n", ")", "\n", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVETrainer._find_log_highest_lowest_locales": [[192, 254], ["metrics.items", "highest_locale.keys", "k.split", "trainer.MASSIVETrainer.log", "metrics.update", "len", "highest_val.get", "lowest_val.get", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "_find_log_highest_lowest_locales", "(", "self", ",", "metrics", ")", ":", "\n", "        ", "\"\"\"\n        Method to determine the locales with the highest and lowest scores\n\n        :param metrics: A dictionary of the metrics found during evaluation across all locales\n        :type metrics: dict\n        :return metrics: The updated dictionary of metrics\n        :rtype metrics: dict\n        \"\"\"", "\n", "\n", "highest_val", ",", "highest_locale", ",", "lowest_val", ",", "lowest_locale", "=", "{", "}", ",", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "# Iterate through the metrics and get the highest and lowest values and locales", "\n", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "pieces", "=", "k", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "len", "(", "pieces", ")", "<", "3", ":", "\n", "                ", "continue", "\n", "\n", "", "pre", "=", "pieces", "[", "0", "]", "\n", "locale", "=", "pieces", "[", "1", "]", "\n", "metric", "=", "'_'", ".", "join", "(", "pieces", "[", "2", ":", "]", ")", "\n", "\n", "if", "metric", "in", "[", "'loss'", ",", "'samples_per_second'", ",", "'steps_per_second'", ",", "'runtime'", ",", "'step'", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "'stderr'", "in", "metric", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "v", ">", "highest_val", ".", "get", "(", "metric", ",", "float", "(", "'-inf'", ")", ")", ":", "\n", "                ", "highest_val", "[", "metric", "]", "=", "v", "\n", "highest_locale", "[", "metric", "]", "=", "locale", "\n", "\n", "", "if", "v", "<", "lowest_val", ".", "get", "(", "metric", ",", "float", "(", "'inf'", ")", ")", ":", "\n", "                ", "lowest_val", "[", "metric", "]", "=", "v", "\n", "lowest_locale", "[", "metric", "]", "=", "locale", "\n", "\n", "# Iterate through the newly found keys and log and save the values", "\n", "", "", "for", "metric", "in", "highest_locale", ".", "keys", "(", ")", ":", "\n", "            ", "highest_locale_key", "=", "pre", "+", "'_highest-locale_'", "+", "metric", "\n", "highest_locale_val_key", "=", "pre", "+", "'_highest-locale-val_'", "+", "metric", "\n", "lowest_locale_key", "=", "pre", "+", "'_lowest-locale_'", "+", "metric", "\n", "lowest_locale_val_key", "=", "pre", "+", "'_lowest-locale-val_'", "+", "metric", "\n", "all_locale_key", "=", "pre", "+", "'_all_'", "+", "metric", "\n", "self", ".", "log", "(", "{", "\n", "'training_global_step'", ":", "self", ".", "state", ".", "global_step", ",", "\n", "'training_epoch'", ":", "self", ".", "state", ".", "epoch", ",", "\n", "'metric'", ":", "metric", ",", "\n", "'highest_locale'", ":", "highest_locale", "[", "metric", "]", ",", "\n", "'highest_val'", ":", "highest_val", "[", "metric", "]", ",", "\n", "'lowest_locale'", ":", "lowest_locale", "[", "metric", "]", ",", "\n", "'lowest_val'", ":", "lowest_val", "[", "metric", "]", ",", "\n", "all_locale_key", ":", "metrics", "[", "all_locale_key", "]", "\n", "}", ")", "\n", "metrics", ".", "update", "(", "{", "\n", "highest_locale_key", ":", "highest_locale", "[", "metric", "]", ",", "\n", "highest_locale_val_key", ":", "highest_val", "[", "metric", "]", ",", "\n", "lowest_locale_key", ":", "lowest_locale", "[", "metric", "]", ",", "\n", "lowest_locale_val_key", ":", "lowest_val", "[", "metric", "]", ",", "\n", "}", ")", "\n", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.__init__": [[261, 263], ["transformers.Seq2SeqTrainer.__init__"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.evaluate": [[264, 383], ["trainer.MASSIVESeq2SeqTrainer._memory_tracker.start", "trainer.MASSIVESeq2SeqTrainer.callback_handler.on_evaluate", "trainer.MASSIVESeq2SeqTrainer._memory_tracker.stop_and_update_metrics", "trainer.MASSIVESeq2SeqTrainer.log", "sorted", "sorted.append", "trainer.MASSIVESeq2SeqTrainer.get_eval_dataloader", "time.time", "eval_loop", "trainer.MASSIVESeq2SeqTrainer.update", "trainer.MASSIVESeq2SeqTrainer.update", "trainer.MASSIVESeq2SeqTrainer._find_log_highest_lowest_locales", "transformers.trainer_utils.EvalLoopOutput", "set", "NotImplementedError", "datasets.logging.get_verbosity", "datasets.logging.set_verbosity", "eval_dataset.filter", "datasets.logging.set_verbosity", "transformers.trainer_utils.speed_metrics", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer._find_log_highest_lowest_locales"], ["", "def", "evaluate", "(", "self", ",", "eval_dataset", "=", "None", ",", "ignore_keys", "=", "None", ",", "metric_key_prefix", "=", "'eval'", ",", "\n", "max_length", "=", "None", ",", "num_beams", "=", "None", ",", "return_all_outputs", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from:\n        https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py\n\n        Run evaluation and returns metrics.\n        The calling script will be responsible for providing a method to compute metrics, as they\n        are task-dependent (pass it to the init :obj:`compute_metrics` argument).\n        You can also subclass and override this method to inject custom behavior.\n\n        Args:\n            eval_dataset (:obj:`Dataset`, `optional`):\n                Pass a dataset if you wish to override :obj:`self.eval_dataset`. If it is an\n                :obj:`datasets.Dataset`, columns not accepted by the ``model.forward()`` method\n                are automatically removed. It must implement the\n                :obj:`__len__` method.\n            ignore_keys (:obj:`Lst[str]`, `optional`):\n                A list of keys in the output of your model (if it is a dictionary) that should be\n                ignored when gathering predictions.\n            metric_key_prefix (:obj:`str`, `optional`, defaults to :obj:`\"eval\"`):\n                An optional prefix to be used as the metrics key prefix. For example the metrics\n                \"bleu\" will be named \"eval_bleu\" if the prefix is \"eval\" (default)\n            max_length (int): The max length for generation. Defaults to args.generation_max_length\n            num_beams (int): The number of generation beams. Defaults to args.generation_num_beams\n\n        Returns:\n            A dictionary containing the evaluation loss and the potential metrics computed from\n            the predictions. The dictionary also contains the epoch number which comes from the\n            training state.\n        \"\"\"", "\n", "\n", "# for generation", "\n", "self", ".", "_max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "args", ".", "generation_max_length", "\n", "self", ".", "_num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "args", ".", "generation_num_beams", "\n", "\n", "# memory metrics - must set up as early as possible", "\n", "self", ".", "_memory_tracker", ".", "start", "(", ")", "\n", "\n", "# use two prefixes and add step/epoch info", "\n", "first_metric_key_prefix", "=", "metric_key_prefix", "\n", "metrics", "=", "{", "}", "\n", "metrics", "[", "'training_global_step'", "]", "=", "self", ".", "state", ".", "global_step", "\n", "metrics", "[", "'training_epoch'", "]", "=", "self", ".", "state", ".", "epoch", "\n", "\n", "eval_dataset", "=", "eval_dataset", "if", "eval_dataset", "else", "self", ".", "eval_dataset", "\n", "\n", "# Create a list of eval runs based on the strategy", "\n", "if", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all and each\"", ":", "\n", "            ", "locales", "=", "sorted", "(", "set", "(", "eval_dataset", "[", "'locale'", "]", ")", ")", "\n", "locales", ".", "append", "(", "'all'", ")", "\n", "", "elif", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all only\"", ":", "\n", "            ", "locales", "=", "[", "'all'", "]", "\n", "# add more strategies here", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'locale_eval_strategy not known'", ")", "\n", "\n", "# loop through all locales (including \"all\") and run evaluation", "\n", "", "for", "locale", "in", "locales", ":", "\n", "\n", "            ", "metric_key_prefix", "=", "first_metric_key_prefix", "+", "\"_\"", "+", "locale", "\n", "if", "locale", "==", "'all'", ":", "\n", "# use whole dataset", "\n", "                ", "dataset", "=", "eval_dataset", "\n", "", "else", ":", "\n", "# filter only to relevant locale", "\n", "# This will warn us every time it loads a cached dataset, which is annoying", "\n", "# I agree with stas00 here: https://github.com/huggingface/datasets/issues/1948", "\n", "# We'll suppress these warnings by temporarily changing the logging level", "\n", "                ", "lvl", "=", "datasets", ".", "logging", ".", "get_verbosity", "(", ")", "\n", "datasets", ".", "logging", ".", "set_verbosity", "(", "50", ")", "\n", "dataset", "=", "eval_dataset", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "==", "locale", ")", "\n", "datasets", ".", "logging", ".", "set_verbosity", "(", "lvl", ")", "\n", "\n", "", "eval_dataloader", "=", "self", ".", "get_eval_dataloader", "(", "dataset", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "eval_loop", "=", "self", ".", "prediction_loop", "if", "self", ".", "args", ".", "use_legacy_prediction_loop", "else", "self", ".", "evaluation_loop", "\n", "output", "=", "eval_loop", "(", "\n", "eval_dataloader", ",", "\n", "description", "=", "\"Evaluation\"", ",", "\n", "# No point gathering the predictions if there are no metrics, otherwise we defer to", "\n", "# self.args.prediction_loss_only", "\n", "prediction_loss_only", "=", "True", "if", "self", ".", "compute_metrics", "is", "None", "else", "None", ",", "\n", "ignore_keys", "=", "ignore_keys", ",", "\n", "metric_key_prefix", "=", "metric_key_prefix", ",", "\n", ")", "\n", "metrics", ".", "update", "(", "output", ".", "metrics", ")", "\n", "\n", "total_batch_size", "=", "self", ".", "args", ".", "eval_batch_size", "*", "self", ".", "args", ".", "world_size", "\n", "metrics", ".", "update", "(", "\n", "speed_metrics", "(", "\n", "metric_key_prefix", ",", "\n", "start_time", ",", "\n", "num_samples", "=", "output", ".", "num_samples", ",", "\n", "num_steps", "=", "math", ".", "ceil", "(", "output", ".", "num_samples", "/", "total_batch_size", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_evaluate", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ",", "\n", "metrics", ")", "\n", "\n", "self", ".", "_memory_tracker", ".", "stop_and_update_metrics", "(", "metrics", ")", "\n", "\n", "if", "self", ".", "args", ".", "locale_eval_strategy", "==", "\"all and each\"", ":", "\n", "            ", "metrics", "=", "self", ".", "_find_log_highest_lowest_locales", "(", "metrics", ")", "\n", "\n", "", "if", "return_all_outputs", ":", "\n", "            ", "return", "EvalLoopOutput", "(", "\n", "predictions", "=", "output", ".", "predictions", ",", "\n", "label_ids", "=", "output", ".", "label_ids", ",", "\n", "metrics", "=", "metrics", ",", "\n", "num_samples", "=", "output", ".", "num_samples", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "metrics", ")", "\n", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.predict": [[384, 414], ["trainer.MASSIVESeq2SeqTrainer.evaluate", "collections.namedtuple", "collections.namedtuple."], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.evaluate"], ["", "def", "predict", "(", "self", ",", "test_dataset", ",", "ignore_keys", "=", "None", ",", "max_length", "=", "None", ",", "num_beams", "=", "None", ",", "\n", "metric_key_prefix", "=", "'test'", ",", "tokenizer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Overriding this method for custom test result logging using `evaluate`\n        \"\"\"", "\n", "\n", "output", "=", "self", ".", "evaluate", "(", "\n", "test_dataset", ",", "\n", "ignore_keys", "=", "ignore_keys", ",", "\n", "max_length", "=", "max_length", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "metric_key_prefix", "=", "metric_key_prefix", ",", "\n", "return_all_outputs", "=", "True", "\n", ")", "\n", "\n", "PredictionOutput", "=", "namedtuple", "(", "\n", "'PredictionOutput'", ",", "\n", "[", "'predictions'", ",", "'label_ids'", ",", "'metrics'", ",", "'ids'", ",", "'locales'", ",", "'utts'", "]", "\n", ")", "\n", "\n", "preds", "=", "PredictionOutput", "(", "\n", "predictions", "=", "output", ".", "predictions", ",", "\n", "label_ids", "=", "output", ".", "label_ids", ",", "\n", "metrics", "=", "output", ".", "metrics", ",", "\n", "ids", "=", "[", "x", "[", "'id'", "]", "for", "x", "in", "test_dataset", "]", ",", "\n", "locales", "=", "[", "x", "[", "'locale'", "]", "for", "x", "in", "test_dataset", "]", ",", "\n", "utts", "=", "[", "x", "[", "'utt'", "]", "for", "x", "in", "test_dataset", "]", "\n", ")", "\n", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer._find_log_highest_lowest_locales": [[416, 478], ["metrics.items", "highest_locale.keys", "k.split", "trainer.MASSIVESeq2SeqTrainer.log", "metrics.update", "len", "highest_val.get", "lowest_val.get", "float", "float"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "_find_log_highest_lowest_locales", "(", "self", ",", "metrics", ")", ":", "\n", "        ", "\"\"\"\n        Method to determine the locales with the highest and lowest scores\n\n        :param metrics: A dictionary of the metrics found during evaluation across all locales\n        :type metrics: dict\n        :return metrics: The updated dictionary of metrics\n        :rtype metrics: dict\n        \"\"\"", "\n", "\n", "highest_val", ",", "highest_locale", ",", "lowest_val", ",", "lowest_locale", "=", "{", "}", ",", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "\n", "# Iterate through the metrics and get the highest and lowest values and locales", "\n", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "pieces", "=", "k", ".", "split", "(", "'_'", ")", "\n", "\n", "if", "len", "(", "pieces", ")", "<", "3", ":", "\n", "                ", "continue", "\n", "\n", "", "pre", "=", "pieces", "[", "0", "]", "\n", "locale", "=", "pieces", "[", "1", "]", "\n", "metric", "=", "'_'", ".", "join", "(", "pieces", "[", "2", ":", "]", ")", "\n", "\n", "if", "metric", "in", "[", "'loss'", ",", "'samples_per_second'", ",", "'steps_per_second'", ",", "'runtime'", ",", "'step'", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "'stderr'", "in", "metric", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "v", ">", "highest_val", ".", "get", "(", "metric", ",", "float", "(", "'-inf'", ")", ")", ":", "\n", "                ", "highest_val", "[", "metric", "]", "=", "v", "\n", "highest_locale", "[", "metric", "]", "=", "locale", "\n", "\n", "", "if", "v", "<", "lowest_val", ".", "get", "(", "metric", ",", "float", "(", "'inf'", ")", ")", ":", "\n", "                ", "lowest_val", "[", "metric", "]", "=", "v", "\n", "lowest_locale", "[", "metric", "]", "=", "locale", "\n", "\n", "# Iterate through the newly found keys and log and save the values", "\n", "", "", "for", "metric", "in", "highest_locale", ".", "keys", "(", ")", ":", "\n", "            ", "highest_locale_key", "=", "pre", "+", "'_highest-locale_'", "+", "metric", "\n", "highest_locale_val_key", "=", "pre", "+", "'_highest-locale-val_'", "+", "metric", "\n", "lowest_locale_key", "=", "pre", "+", "'_lowest-locale_'", "+", "metric", "\n", "lowest_locale_val_key", "=", "pre", "+", "'_lowest-locale-val_'", "+", "metric", "\n", "all_locale_key", "=", "pre", "+", "'_all_'", "+", "metric", "\n", "self", ".", "log", "(", "{", "\n", "'training_global_step'", ":", "self", ".", "state", ".", "global_step", ",", "\n", "'training_epoch'", ":", "self", ".", "state", ".", "epoch", ",", "\n", "'metric'", ":", "metric", ",", "\n", "'highest_locale'", ":", "highest_locale", "[", "metric", "]", ",", "\n", "'highest_val'", ":", "highest_val", "[", "metric", "]", ",", "\n", "'lowest_locale'", ":", "lowest_locale", "[", "metric", "]", ",", "\n", "'lowest_val'", ":", "lowest_val", "[", "metric", "]", ",", "\n", "all_locale_key", ":", "metrics", "[", "all_locale_key", "]", "\n", "}", ")", "\n", "metrics", ".", "update", "(", "{", "\n", "highest_locale_key", ":", "highest_locale", "[", "metric", "]", ",", "\n", "highest_locale_val_key", ":", "highest_val", "[", "metric", "]", ",", "\n", "lowest_locale_key", ":", "lowest_locale", "[", "metric", "]", ",", "\n", "lowest_locale_val_key", ":", "lowest_val", "[", "metric", "]", ",", "\n", "}", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.utils.hpo_utils.prepare_hp_search_args": [[27, 55], ["conf.get", "hpo_utils._parse_mutations", "output[].pop", "output[].get", "ray.tune.suggest.create_searcher", "hpo_utils._parse_mutations", "getattr"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.hpo_utils._parse_mutations", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.hpo_utils._parse_mutations"], ["", "def", "prepare_hp_search_args", "(", "conf", ")", ":", "\n", "    ", "output", "=", "conf", ".", "get", "(", "'hpo_args'", ")", "\n", "# hp_space can either be a Trial object or a function returning a dict. This is latter.", "\n", "if", "'hp_space'", "in", "output", ":", "\n", "        ", "hp_space_fn_out", "=", "_parse_mutations", "(", "output", "[", "'hp_space'", "]", ")", "\n", "output", "[", "'hp_space'", "]", "=", "lambda", "x", ":", "hp_space_fn_out", "\n", "\n", "# The scheduler can have hyperparam_mutations of the same format as the hp_space dict", "\n", "", "if", "'scheduler'", "in", "output", ":", "\n", "        ", "if", "'hyperparam_mutations'", "in", "output", "[", "'scheduler'", "]", ":", "\n", "            ", "output", "[", "'scheduler'", "]", "[", "'hyperparam_mutations'", "]", "=", "_parse_mutations", "(", "\n", "output", "[", "'scheduler'", "]", "[", "'hyperparam_mutations'", "]", ")", "\n", "", "sched_cls", "=", "output", "[", "'scheduler'", "]", ".", "pop", "(", "'type'", ")", "\n", "output", "[", "'scheduler'", "]", "=", "getattr", "(", "tune", ".", "schedulers", ",", "sched_cls", ")", "(", "**", "output", "[", "'scheduler'", "]", ")", "\n", "\n", "# Pull the search algorithm", "\n", "", "if", "'search_alg'", "in", "output", ":", "\n", "        ", "salg_name", "=", "output", "[", "'search_alg'", "]", "[", "'type'", "]", "\n", "salg_args", "=", "output", "[", "'search_alg'", "]", ".", "get", "(", "'args'", ")", "\n", "output", "[", "'search_alg'", "]", "=", "tune", ".", "suggest", ".", "create_searcher", "(", "salg_name", ",", "**", "(", "salg_args", "or", "{", "}", ")", ")", "\n", "\n", "# Trainer needs this `compute_objective` in order to pull out the right eval metric", "\n", "", "if", "'metric'", "in", "output", ":", "\n", "        ", "def", "get_eval_metric", "(", "metrics", ")", ":", "\n", "            ", "return", "metrics", "[", "output", "[", "'metric'", "]", "]", "\n", "", "output", "[", "'compute_objective'", "]", "=", "get_eval_metric", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.hpo_utils._parse_mutations": [[56, 78], ["type", "getattr", "tuple", "getattr", "NotImplementedError", "NotImplementedError"], "function", ["None"], ["", "def", "_parse_mutations", "(", "spec", ")", ":", "\n", "    ", "spec", "=", "[", "spec", "]", "if", "type", "(", "spec", ")", "==", "dict", "else", "spec", "\n", "output", "=", "{", "}", "\n", "mut_types_tup", "=", "[", "'uniform'", ",", "'quniform'", ",", "'loguniform'", ",", "'qloguniform'", ",", "'randint'", ",", "\n", "'lograndint'", ",", "'qrandint'", ",", "'qlograndint'", ",", "'randn'", ",", "'qrandn'", "]", "\n", "\n", "# Converts the config entries into sampling objects from ray.tune", "\n", "for", "item", "in", "spec", ":", "\n", "        ", "hp", ",", "mut_type", ",", "args", "=", "item", "[", "'hp'", "]", ",", "item", "[", "'type'", "]", ",", "item", "[", "'args'", "]", "\n", "if", "mut_type", "in", "mut_types_tup", ":", "\n", "            ", "output", "[", "hp", "]", "=", "getattr", "(", "tune", ",", "mut_type", ")", "(", "*", "tuple", "(", "args", ")", ")", "\n", "", "elif", "mut_type", "==", "'choice'", ":", "\n", "            ", "output", "[", "hp", "]", "=", "getattr", "(", "tune", ",", "mut_type", ")", "(", "args", ")", "\n", "", "elif", "mut_type", "==", "'list'", ":", "\n", "            ", "output", "[", "hp", "]", "=", "args", "\n", "", "elif", "mut_type", "==", "'sample_from'", ":", "\n", "# This allows for a callable custom function", "\n", "            ", "raise", "NotImplementedError", "(", "'mutation type sample_from is not implemented'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'mutation type is not implemented'", ")", "\n", "\n", "", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_model": [[42, 129], ["training_utils.init_model.hpo_model_init"], "function", ["None"], ["", "def", "init_model", "(", "conf", ",", "intents", ",", "slots", ",", "return_hpo_fn", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Initialize a model based on the type given in the config\n\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param intent: A dictionary mapping each intent's numerical index to the intent\n    :type intent: dict\n    :param slots: A dictionary mapping each slot's numerical index to the slot\n    :type slots: dict\n    :return: The loaded model\n    :rtype: nn.Module\n    \"\"\"", "\n", "\n", "def", "hpo_model_init", "(", "hpo_params", "=", "None", ")", ":", "\n", "\n", "        ", "if", "hpo_params", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Chosen hyperparameter values: {hpo_params}\"", ")", "\n", "for", "param", "in", "hpo_params", ":", "\n", "                ", "if", "conf", ".", "get", "(", "param", ")", ":", "\n", "                    ", "logger", ".", "warning", "(", "f\"Overriding {param} with {hpo_params[param]}\"", ")", "\n", "conf", ".", "override", "(", "param", ",", "hpo_params", "[", "param", "]", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "warning", "(", "f\"{param} not found in config. Assuming it's a trainer arg\"", ")", "\n", "\n", "# Get the model class and config", "\n", "", "", "", "config_args", "=", "conf", ".", "get", "(", "'model.model_config_args'", ")", "\n", "if", "conf", ".", "get", "(", "'model.type'", ")", "==", "'xlmr intent classification slot filling'", ":", "\n", "            ", "model_config", "=", "XLMRobertaConfig", "(", "**", "config_args", ")", "if", "config_args", "else", "None", "\n", "model_cls", "=", "XLMRIntentClassSlotFill", "\n", "model_kwargs", "=", "{", "'intent_label_dict'", ":", "intents", ",", "'slot_label_dict'", ":", "slots", "}", "\n", "", "elif", "conf", ".", "get", "(", "'model.type'", ")", "==", "'mt5 for conditional generation'", ":", "\n", "            ", "model_config", "=", "MT5Config", "(", "**", "config_args", ")", "if", "config_args", "else", "None", "\n", "model_cls", "=", "MT5ForConditionalGeneration", "\n", "model_kwargs", "=", "{", "}", "\n", "", "elif", "conf", ".", "get", "(", "'model.type'", ")", "==", "'mt5 intent classification slot filling encoder only'", ":", "\n", "            ", "model_config", "=", "MT5Config", "(", "**", "config_args", ")", "if", "config_args", "else", "None", "\n", "model_cls", "=", "MT5IntentClassSlotFillEncoderOnly", "\n", "model_kwargs", "=", "{", "'intent_label_dict'", ":", "intents", ",", "'slot_label_dict'", ":", "slots", "}", "\n", "# add more models here as additional elif statements", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Model type {conf.get('model.type')} not found!\"", ")", "\n", "\n", "# Instantiate the model", "\n", "", "if", "conf", ".", "get", "(", "'model.checkpoint'", ")", ":", "\n", "            ", "return", "model_cls", ".", "from_pretrained", "(", "conf", ".", "get", "(", "'model.checkpoint'", ")", ",", "**", "model_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "model_cls", "(", "model_config", ",", "**", "model_kwargs", ")", "\n", "\n", "# Load pretrained weights", "\n", "", "if", "conf", ".", "get", "(", "'model.pretrained_weights'", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Loading pretrained weights from {conf.get('model.pretrained_weights')}\"", ")", "\n", "mod_weights", "=", "torch", ".", "load", "(", "conf", ".", "get", "(", "'model.pretrained_weights'", ")", ",", "map_location", "=", "'cpu'", ")", "\n", "if", "conf", ".", "get", "(", "'model.pretrained_weight_prepend'", ")", ":", "\n", "                ", "prepend", "=", "conf", ".", "get", "(", "'model.pretrained_weight_prepend'", ")", "\n", "# sometimes this parses as a list, sometimes as list of lists. Remove outer list.", "\n", "mod_weights", "=", "{", "(", "prepend", "+", "k", ")", ":", "v", "for", "k", ",", "v", "in", "mod_weights", ".", "items", "(", ")", "}", "\n", "", "if", "conf", ".", "get", "(", "'model.pretrained_weight_substring_transform'", ")", ":", "\n", "                ", "rpl", "=", "conf", ".", "get", "(", "'model.pretrained_weight_substring_transform'", ")", "\n", "# sometimes this parses as a list, sometimes as list of lists. Remove outer list.", "\n", "rpl", "=", "rpl", "[", "0", "]", "if", "type", "(", "rpl", "[", "0", "]", ")", "==", "list", "else", "rpl", "\n", "mod_weights", "=", "{", "k", ".", "replace", "(", "rpl", "[", "0", "]", ",", "rpl", "[", "1", "]", ")", ":", "v", "for", "k", ",", "v", "in", "mod_weights", ".", "items", "(", ")", "}", "\n", "", "load_strict", "=", "conf", ".", "get", "(", "'model.strict_load_pretrained_weights'", ")", "\n", "load_info", "=", "model", ".", "load_state_dict", "(", "mod_weights", ",", "strict", "=", "load_strict", ")", "\n", "logger", ".", "info", "(", "f\"Finished loading pretrained model. Results: {load_info}\"", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"No pretrained weights provided. All weights will be trained from scratch.\"", ")", "\n", "\n", "# Freeze layers if needed", "\n", "", "if", "conf", ".", "get", "(", "'model.model_config_args.freeze_layers'", ")", ":", "\n", "            ", "layers_to_freeze", "=", "conf", ".", "get", "(", "'model.model_config_args.freeze_layers'", ")", ".", "split", "(", "','", ")", "\n", "all_names", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "all_names", ".", "append", "(", "name", ")", "\n", "if", "name", "in", "layers_to_freeze", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Freezing layer {name}\"", ")", "\n", "param", ".", "requires_grad", "=", "False", "\n", "layers_to_freeze", ".", "remove", "(", "name", ")", "\n", "", "", "if", "not", "(", "layers_to_freeze", "==", "[", "''", "]", "or", "layers_to_freeze", "==", "[", "]", ")", ":", "\n", "                ", "logger", ".", "info", "(", "f\"all layer names: {all_names}\"", ")", "\n", "raise", "KeyError", "(", "f\"Could not find the following layers to freeze: {layers_to_freeze}\"", ")", "\n", "\n", "", "", "return", "model", "\n", "\n", "", "if", "return_hpo_fn", ":", "\n", "        ", "return", "hpo_model_init", "\n", "", "return", "hpo_model_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_tokenizer": [[130, 145], ["conf.get", "transformers.XLMRobertaTokenizerFast", "conf.get", "transformers.MT5TokenizerFast", "NotImplementedError", "conf.get", "conf.get"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "init_tokenizer", "(", "conf", ")", ":", "\n", "    ", "\"\"\"\n    Initialize a tokenizer based on the type given in the config\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :return: The loaded tokenizer\n    :rtype: PreTrainedTokenizerFast\n    \"\"\"", "\n", "if", "conf", ".", "get", "(", "'tokenizer.type'", ")", "==", "'xlmr base'", ":", "\n", "        ", "return", "XLMRobertaTokenizerFast", "(", "**", "conf", ".", "get", "(", "'tokenizer.tok_args'", ")", ")", "\n", "", "elif", "conf", ".", "get", "(", "'tokenizer.type'", ")", "==", "'mt5'", ":", "\n", "        ", "return", "MT5TokenizerFast", "(", "**", "conf", ".", "get", "(", "'tokenizer.tok_args'", ")", ")", "\n", "# Add more tokenizers here", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Tokenizer type not found!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_train_dev_datasets": [[146, 208], ["datasets.load_from_disk", "train.filter.shuffle", "conf.get", "logger.info", "logger.info", "datasets.load_from_disk", "conf.get", "conf.get", "dev.select.shuffle", "conf.get", "logger.info", "logger.info", "logger.info", "conf.get", "logger.info", "train.filter.filter", "conf.get", "logger.info", "dev.select.filter", "logger.info", "dev.select.filter", "dev.select.select", "open", "json.load", "open", "json.load", "type", "type", "type", "range", "conf.get", "conf.get", "len", "conf.get", "len", "len"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "", "def", "prepare_train_dev_datasets", "(", "conf", ",", "tokenizer", ",", "seed", "=", "42", ")", ":", "\n", "    ", "\"\"\"\n    Prepare the training and dev datasets based on the config.\n\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param tokenizer: The loaded tokenizer\n    :type tokenizer: PreTrainedTokenizerFast\n    :return: train set, dev set, an intent dictionary, a slot dictionary\n    :rtype: tuple(Dataset, Dataset, dict, dict)\n    \"\"\"", "\n", "\n", "train", "=", "datasets", ".", "load_from_disk", "(", "conf", ".", "get", "(", "'train_val.train_dataset'", ")", ")", "\n", "train", "=", "train", ".", "shuffle", "(", "seed", "=", "seed", ")", "\n", "\n", "# Filter to specific train locales", "\n", "train_locales", "=", "conf", ".", "get", "(", "'train_val.train_locales'", ",", "default", "=", "'all'", ")", "\n", "if", "train_locales", "!=", "'all'", "and", "train_locales", "!=", "[", "'all'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Filtering train dataset to locale(s): {train_locales}\"", ")", "\n", "if", "type", "(", "train_locales", ")", "==", "str", ":", "\n", "            ", "train_locales", "=", "[", "train_locales", "]", "\n", "", "train", "=", "train", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "in", "train_locales", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"The features of the train dataset: {train.features}\"", ")", "\n", "logger", ".", "info", "(", "f\"Length of the train dataset: {len(train)}\"", ")", "\n", "\n", "dev", "=", "datasets", ".", "load_from_disk", "(", "conf", ".", "get", "(", "'train_val.dev_dataset'", ")", ")", "\n", "\n", "# Filter to specific dev locales", "\n", "dev_locales", "=", "conf", ".", "get", "(", "'train_val.dev_locales'", ",", "default", "=", "'all'", ")", "\n", "if", "dev_locales", "!=", "'all'", "and", "dev_locales", "!=", "[", "'all'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Filtering dev dataset to locale(s): {dev_locales}\"", ")", "\n", "if", "type", "(", "dev_locales", ")", "==", "str", ":", "\n", "            ", "dev_locales", "=", "[", "dev_locales", "]", "\n", "", "dev", "=", "dev", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "in", "dev_locales", ")", "\n", "\n", "# Remove specified locales in the dev set", "\n", "", "dev_locales_remove", "=", "conf", ".", "get", "(", "'train_val.dev_locales_remove'", ",", "default", "=", "'none'", ")", "\n", "if", "dev_locales_remove", "!=", "'none'", "and", "dev_locales_remove", "!=", "[", "'none'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Removing locale(s) from dev dataset: {dev_locales_remove}\"", ")", "\n", "if", "type", "(", "dev_locales_remove", ")", "==", "str", ":", "\n", "            ", "dev_locales_remove", "=", "[", "dev_locales_remove", "]", "\n", "", "dev", "=", "dev", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "not", "in", "dev_locales_remove", ")", "\n", "\n", "# Shuffle the dev set", "\n", "", "dev", "=", "dev", ".", "shuffle", "(", "seed", "=", "seed", ")", "\n", "\n", "# Shorten the dev set to the first N examples if desired", "\n", "if", "conf", ".", "get", "(", "'train_val.dev_shorten_to'", ",", "None", ")", ":", "\n", "        ", "dev", "=", "dev", ".", "select", "(", "range", "(", "conf", ".", "get", "(", "'train_val.dev_shorten_to'", ")", ")", ")", "\n", "\n", "# Load the intent and slot labels", "\n", "", "with", "open", "(", "conf", ".", "get", "(", "'train_val.intent_labels'", ")", ",", "'r'", ")", "as", "i", ":", "\n", "        ", "intent_labels", "=", "json", ".", "load", "(", "i", ")", "\n", "", "with", "open", "(", "conf", ".", "get", "(", "'train_val.slot_labels'", ")", ",", "'r'", ")", "as", "s", ":", "\n", "        ", "slot_labels", "=", "json", ".", "load", "(", "s", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"The features of the train dataset: {train.features}\"", ")", "\n", "logger", ".", "info", "(", "f\"Length of the train dataset: {len(train)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Length of the loaded dev dataset: {len(dev)}\"", ")", "\n", "\n", "return", "train", ",", "dev", ",", "intent_labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_test_dataset": [[209, 250], ["datasets.load_from_disk", "test.select.shuffle", "conf.get", "conf.get", "conf.get", "logger.info", "logger.info", "conf.get", "logger.info", "test.select.filter", "logger.info", "test.select.filter", "test.select.select", "open", "json.load", "open", "json.load", "type", "type", "range", "conf.get", "conf.get", "conf.get", "len"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "prepare_test_dataset", "(", "conf", ",", "tokenizer", ",", "seed", "=", "42", ")", ":", "\n", "    ", "\"\"\"\n    Prepare the test dataset based on the config.\n\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param tokenizer: The loaded tokenizer\n    :type tokenizer: PreTrainedTokenizerFast\n    :return: test dataset, an intent dictionary, a slot dictionary\n    :rtype: tuple(Dataset, dict, dict)\n    \"\"\"", "\n", "\n", "test", "=", "datasets", ".", "load_from_disk", "(", "conf", ".", "get", "(", "'test.test_dataset'", ")", ")", "\n", "test", "=", "test", ".", "shuffle", "(", "seed", "=", "seed", ")", "\n", "\n", "# Filter to specific test locales", "\n", "test_locales", "=", "conf", ".", "get", "(", "'test.test_locales'", ",", "default", "=", "'all'", ")", "\n", "if", "test_locales", "!=", "'all'", "and", "test_locales", "!=", "[", "'all'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Filtering test dataset to locale(s): {test_locales}\"", ")", "\n", "if", "type", "(", "test_locales", ")", "==", "str", ":", "\n", "            ", "test_locales", "=", "[", "test_locales", "]", "\n", "", "test", "=", "test", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "in", "test_locales", ")", "\n", "\n", "# Remove specified locales in the test set", "\n", "", "test_locales_remove", "=", "conf", ".", "get", "(", "'test.test_locales_remove'", ",", "default", "=", "'none'", ")", "\n", "if", "test_locales_remove", "!=", "'none'", "and", "test_locales_remove", "!=", "[", "'none'", "]", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Removing locale(s) from test dataset: {test_locales_remove}\"", ")", "\n", "if", "type", "(", "test_locales_remove", ")", "==", "str", ":", "\n", "            ", "test_locales_remove", "=", "[", "test_locales_remove", "]", "\n", "", "test", "=", "test", ".", "filter", "(", "lambda", "x", ":", "x", "[", "'locale'", "]", "not", "in", "test_locales_remove", ")", "\n", "\n", "", "if", "conf", ".", "get", "(", "'test.test_shorten_to'", ",", "None", ")", ":", "\n", "        ", "test", "=", "test", ".", "select", "(", "range", "(", "conf", ".", "get", "(", "'test.test_shorten_to'", ")", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"The features of the test dataset: {test.features}\"", ")", "\n", "logger", ".", "info", "(", "f\"Length of the test dataset: {len(test)}\"", ")", "\n", "with", "open", "(", "conf", ".", "get", "(", "'test.intent_labels'", ")", ",", "'r'", ")", "as", "i", ":", "\n", "        ", "intent_labels", "=", "json", ".", "load", "(", "i", ")", "\n", "", "with", "open", "(", "conf", ".", "get", "(", "'test.slot_labels'", ")", ",", "'r'", ")", "as", "s", ":", "\n", "        ", "slot_labels", "=", "json", ".", "load", "(", "s", ")", "\n", "", "return", "test", ",", "intent_labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_collator": [[251, 274], ["conf.get", "massive.loaders.collator_ic_sf.CollatorMASSIVEIntentClassSlotFill", "conf.get", "massive.loaders.collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill", "NotImplementedError", "conf.get", "conf.get"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "prepare_collator", "(", "conf", ",", "tokenizer", ",", "model", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Prepare the collator based on the config.\n\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param tokenizer: The loaded tokenizer\n    :type tokenizer: PreTrainedTokenizerFast\n    :return: the collator object\n    \"\"\"", "\n", "if", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive intent class slot fill'", ":", "\n", "        ", "return", "CollatorMASSIVEIntentClassSlotFill", "(", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "**", "conf", ".", "get", "(", "'collator.args'", ")", "\n", ")", "\n", "", "if", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive text to text intent class slot fill'", ":", "\n", "        ", "return", "CollatorMASSIVET2TIntentClassSlotFill", "(", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "model", "=", "model", ",", "\n", "**", "conf", ".", "get", "(", "'collator.args'", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Collator type not found!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.create_compute_metrics": [[275, 377], ["int", "type", "conf.get", "slot_labels.items", "training_utils.eval_preds", "conf.get", "NotImplementedError", "numpy.argmax", "numpy.argmax", "tokenizer.batch_decode", "tokenizer.batch_decode", "conf.get", "training_utils.convert_t2t_batch_to_intents_slots", "training_utils.convert_t2t_batch_to_intents_slots", "training_utils.eval_preds", "clean_labels.append", "clean_preds.append"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.eval_preds", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_t2t_batch_to_intents_slots", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_t2t_batch_to_intents_slots", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.eval_preds"], ["", "", "def", "create_compute_metrics", "(", "intent_labels", ",", "slot_labels", ",", "conf", ",", "tokenizer", "=", "None", ",", "ignore_labels", "=", "None", ",", "\n", "metrics", "=", "'all'", ")", ":", "\n", "    ", "\"\"\"\n    Create a `compute_metrics` function for this task\n\n    :param intent_labels: A dictionary mapping each intent's numerical index to the intent\n    :type slot_labels: dict\n    :param slot_labels: A dictionary mapping each slot's numerical index to the slot\n    :type slot_labels: dict\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param ignore_labels: The labels to ignore\n    :type ignore_labels: list or str\n    :param metrics: The metrics to calculate\n    :type metrics: list or str\n    :return: the `compute_metrics` function\n    :rtype: Callable\n    \"\"\"", "\n", "\n", "# Determine any labels that should be ignored when calculating F1 score (EX: Other)", "\n", "ignore_labels", "=", "[", "]", "if", "ignore_labels", "is", "None", "else", "ignore_labels", "\n", "ignore_num_lab", "=", "[", "int", "(", "k", ")", "for", "k", ",", "v", "in", "slot_labels", ".", "items", "(", ")", "if", "v", "in", "ignore_labels", "]", "\n", "\n", "if", "type", "(", "metrics", ")", "!=", "list", ":", "\n", "        ", "metrics", "=", "[", "metrics", "]", "\n", "\n", "# COLLATOR: MASSIVE INTENT CLASS SLOT FILL", "\n", "", "if", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive intent class slot fill'", ":", "\n", "        ", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# p is named tuple with `predictions` and `label_ids`.", "\n", "# p.predictions is a tuple of two elements, the first being the intent classification", "\n", "# predictions of size num_examples and the second being the slot classification preds", "\n", "# of size num_examples. Each intent classification pred is of size num_intent_classes,", "\n", "# and each slot classification prediction is of shape (seq_len, num_slot_classes)", "\n", "# label_ids is tuple of two elements, first array of all IC labels (size num_examples)", "\n", "# The second element is size num_examples with each entry sized seq_len x num_slot_class", "\n", "\n", "            ", "intent_preds", "=", "p", ".", "predictions", "[", "0", "]", "\n", "slot_preds", "=", "p", ".", "predictions", "[", "1", "]", "\n", "\n", "intent_label_tuple", "=", "p", ".", "label_ids", "[", "0", "]", "\n", "slot_label_tuple", "=", "p", ".", "label_ids", "[", "1", "]", "\n", "\n", "intent_preds_am", "=", "[", "np", ".", "argmax", "(", "x", ")", "for", "x", "in", "intent_preds", "]", "\n", "slot_preds_am", "=", "[", "np", ".", "argmax", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "slot_preds", "]", "\n", "\n", "# merge -100, which we used for the subsequent subwords in a full word after tokenizing", "\n", "labels_merge", "=", "[", "-", "100", "]", "\n", "\n", "return", "eval_preds", "(", "\n", "pred_intents", "=", "intent_preds_am", ",", "\n", "lab_intents", "=", "intent_label_tuple", ",", "\n", "pred_slots", "=", "slot_preds_am", ",", "\n", "lab_slots", "=", "slot_label_tuple", ",", "\n", "eval_metrics", "=", "metrics", ",", "\n", "labels_merge", "=", "labels_merge", ",", "\n", "labels_ignore", "=", "ignore_num_lab", ",", "\n", "pad", "=", "'Other'", "\n", ")", "\n", "\n", "# COLLATOR: MASSIVE TEXT TO TEXT INTENT CLASS SLOT FILL", "\n", "", "", "elif", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive text to text intent class slot fill'", ":", "\n", "        ", "def", "compute_metrics", "(", "p", ")", ":", "\n", "# p is named tuple with `predictions` and `label_ids`", "\n", "\n", "            ", "clean_labels", "=", "[", "]", "\n", "for", "lab", "in", "p", ".", "label_ids", ":", "\n", "                ", "lab", "=", "lab", "[", "lab", "!=", "-", "100", "]", "\n", "lab", "=", "lab", "[", "lab", "!=", "tokenizer", ".", "pad_token_id", "]", "\n", "lab", "=", "lab", "[", "lab", "!=", "tokenizer", ".", "eos_token_id", "]", "\n", "clean_labels", ".", "append", "(", "lab", ")", "\n", "\n", "", "clean_preds", "=", "[", "]", "\n", "for", "pred", "in", "p", ".", "predictions", ":", "\n", "                ", "pred", "=", "pred", "[", "pred", "!=", "-", "100", "]", "\n", "pred", "=", "pred", "[", "pred", "!=", "tokenizer", ".", "pad_token_id", "]", "\n", "pred", "=", "pred", "[", "pred", "!=", "tokenizer", ".", "eos_token_id", "]", "\n", "clean_preds", ".", "append", "(", "pred", ")", "\n", "\n", "", "clean_lab_dec", "=", "tokenizer", ".", "batch_decode", "(", "clean_labels", ",", "skip_special_tokens", "=", "True", ")", "\n", "clean_pred_dec", "=", "tokenizer", ".", "batch_decode", "(", "clean_preds", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "t2t_args", "=", "conf", ".", "get", "(", "'collator.args.t2t_args'", ")", "\n", "intents_pred", ",", "slots_pred_all", "=", "convert_t2t_batch_to_intents_slots", "(", "\n", "clean_pred_dec", ",", "**", "t2t_args", ")", "\n", "intents_lab", ",", "slots_lab_all", "=", "convert_t2t_batch_to_intents_slots", "(", "\n", "clean_lab_dec", ",", "**", "t2t_args", ")", "\n", "\n", "return", "eval_preds", "(", "\n", "pred_intents", "=", "intents_pred", ",", "\n", "lab_intents", "=", "intents_lab", ",", "\n", "pred_slots", "=", "slots_pred_all", ",", "\n", "lab_slots", "=", "slots_lab_all", ",", "\n", "eval_metrics", "=", "metrics", ",", "\n", "labels_ignore", "=", "ignore_labels", ",", "\n", "pad", "=", "'Other'", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Could not find a compute_metrics function for your collator'", ")", "\n", "\n", "", "return", "compute_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_to_bio": [[378, 426], ["str", "str", "type", "str", "bio_tagged.append", "type", "bio_tagged.append", "bio_tagged.append", "bio_tagged.append", "bio_tagged.append"], "function", ["None"], ["", "def", "convert_to_bio", "(", "seq_tags", ",", "outside", "=", "'Other'", ",", "labels_merge", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Converts a sequence of tags into BIO format. EX:\n\n        ['city', 'city', 'Other', 'country', -100, 'Other']\n        to\n        ['B-city', 'I-city', 'O', 'B-country', 'I-country', 'O']\n        where outside = 'Other' and labels_merge = [-100]\n\n    :param seq_tags: the sequence of tags that should be converted\n    :type seq_tags: list\n    :param outside: The label(s) to put outside (ignore). Default: 'Other'\n    :type outside: str or list\n    :param labels_merge: The labels to merge leftward (i.e. for tokenized inputs)\n    :type labels_merge: str or list\n    :return: a BIO-tagged sequence\n    :rtype: list\n    \"\"\"", "\n", "\n", "seq_tags", "=", "[", "str", "(", "x", ")", "for", "x", "in", "seq_tags", "]", "\n", "\n", "outside", "=", "[", "outside", "]", "if", "type", "(", "outside", ")", "!=", "list", "else", "outside", "\n", "outside", "=", "[", "str", "(", "x", ")", "for", "x", "in", "outside", "]", "\n", "\n", "if", "labels_merge", ":", "\n", "        ", "labels_merge", "=", "[", "labels_merge", "]", "if", "type", "(", "labels_merge", ")", "!=", "list", "else", "labels_merge", "\n", "labels_merge", "=", "[", "str", "(", "x", ")", "for", "x", "in", "labels_merge", "]", "\n", "", "else", ":", "\n", "        ", "labels_merge", "=", "[", "]", "\n", "\n", "", "bio_tagged", "=", "[", "]", "\n", "prev_tag", "=", "None", "\n", "for", "tag", "in", "seq_tags", ":", "\n", "        ", "if", "prev_tag", "==", "None", "and", "tag", "in", "labels_merge", ":", "\n", "            ", "bio_tagged", ".", "append", "(", "'O'", ")", "\n", "", "elif", "tag", "in", "outside", ":", "\n", "            ", "bio_tagged", ".", "append", "(", "'O'", ")", "\n", "prev_tag", "=", "tag", "\n", "", "elif", "tag", "!=", "prev_tag", "and", "tag", "not", "in", "labels_merge", ":", "\n", "            ", "bio_tagged", ".", "append", "(", "'B-'", "+", "tag", ")", "\n", "prev_tag", "=", "tag", "\n", "", "elif", "tag", "==", "prev_tag", "or", "tag", "in", "labels_merge", ":", "\n", "            ", "if", "prev_tag", "in", "outside", ":", "\n", "                ", "bio_tagged", ".", "append", "(", "'O'", ")", "\n", "", "else", ":", "\n", "                ", "bio_tagged", ".", "append", "(", "'I-'", "+", "prev_tag", ")", "\n", "\n", "", "", "", "return", "bio_tagged", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.eval_preds": [[427, 514], ["sklearn.accuracy_score", "math.sqrt", "zip", "seqeval.metrics.f1_score", "sum", "math.sqrt", "zip", "math.sqrt", "len", "len", "len", "len", "enumerate", "bio_slot_labels.append", "bio_slot_preds.append", "len", "type", "training_utils.convert_to_bio", "training_utils.convert_to_bio", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_to_bio", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_to_bio"], ["", "def", "eval_preds", "(", "pred_intents", "=", "None", ",", "lab_intents", "=", "None", ",", "pred_slots", "=", "None", ",", "lab_slots", "=", "None", ",", "\n", "eval_metrics", "=", "'all'", ",", "labels_ignore", "=", "'Other'", ",", "labels_merge", "=", "None", ",", "pad", "=", "'Other'", ")", ":", "\n", "    ", "\"\"\"\n    Function to evaluate the predictions from a model\n\n    :param pred_intents: a list of predicted intents\n    :type pred_intents: list\n    :param lab_intents: a list of intents labels (ground truth)\n    :type lab_intents: list\n    :param pred_slots: a list of predicted slots, where each entry is a list of token-based slots\n    :type pred_slots: list\n    :param lab_slots: a list of slots labels (ground truth)\n    :type lab_slots: list\n    :param eval_metrics: The metrics to include. Options are 'all', 'intent_acc', 'ex_match_acc',\n                         'slot_micro_f1'\n    :type eval_metrics: str\n    :param labels_ignore: The labels to ignore (prune away). Default: ['Other']\n    :type labels_ignore: str or list\n    :param labels_merge: The labels to merge leftward (i.e. for tokenized inputs)\n    :type labels_merge: str or list\n    :param pad: The value to use when padding slot predictions to match the length of ground truth\n    :type pad: str\n    \"\"\"", "\n", "\n", "results", "=", "{", "}", "\n", "\n", "# Check lengths", "\n", "if", "pred_intents", "is", "not", "None", "and", "lab_intents", "is", "not", "None", ":", "\n", "        ", "assert", "len", "(", "pred_intents", ")", "==", "len", "(", "lab_intents", ")", ",", "\"pred_intents and lab_intents must be same len\"", "\n", "", "if", "pred_slots", "is", "not", "None", "and", "lab_slots", "is", "not", "None", ":", "\n", "        ", "assert", "len", "(", "pred_slots", ")", "==", "len", "(", "lab_slots", ")", ",", "\"pred_slots and lab_slots must be same length\"", "\n", "\n", "", "if", "(", "'intent_acc'", "in", "eval_metrics", ")", "or", "(", "'all'", "in", "eval_metrics", ")", ":", "\n", "        ", "intent_acc", "=", "sklm", ".", "accuracy_score", "(", "lab_intents", ",", "pred_intents", ")", "\n", "results", "[", "'intent_acc'", "]", "=", "intent_acc", "\n", "# Assuming normal distribution. Multiply by z (from \"z table\") to get confidence int", "\n", "results", "[", "'intent_acc_stderr'", "]", "=", "sqrt", "(", "intent_acc", "*", "(", "1", "-", "intent_acc", ")", "/", "len", "(", "pred_intents", ")", ")", "\n", "\n", "", "if", "lab_slots", "is", "not", "None", "and", "pred_slots", "is", "not", "None", ":", "\n", "        ", "bio_slot_labels", ",", "bio_slot_preds", "=", "[", "]", ",", "[", "]", "\n", "for", "lab", ",", "pred", "in", "zip", "(", "lab_slots", ",", "pred_slots", ")", ":", "\n", "\n", "# Pad or truncate prediction as needed using `pad` arg", "\n", "            ", "if", "type", "(", "pred", ")", "==", "list", ":", "\n", "                ", "pred", "=", "pred", "[", ":", "len", "(", "lab", ")", "]", "+", "[", "pad", "]", "*", "(", "len", "(", "lab", ")", "-", "len", "(", "pred", ")", ")", "\n", "\n", "# Fix for Issue 21 -- subwords after the first one from a word should be ignored", "\n", "", "for", "i", ",", "x", "in", "enumerate", "(", "lab", ")", ":", "\n", "                ", "if", "x", "==", "-", "100", ":", "\n", "                    ", "pred", "[", "i", "]", "=", "-", "100", "\n", "\n", "# convert to BIO", "\n", "", "", "bio_slot_labels", ".", "append", "(", "\n", "convert_to_bio", "(", "lab", ",", "outside", "=", "labels_ignore", ",", "labels_merge", "=", "labels_merge", ")", "\n", ")", "\n", "bio_slot_preds", ".", "append", "(", "\n", "convert_to_bio", "(", "pred", ",", "outside", "=", "labels_ignore", ",", "labels_merge", "=", "labels_merge", ")", "\n", ")", "\n", "\n", "", "", "if", "(", "'slot_micro_f1'", "in", "eval_metrics", ")", "or", "(", "'all'", "in", "eval_metrics", ")", ":", "\n", "\n", "# from seqeval", "\n", "        ", "smf1", "=", "f1_score", "(", "bio_slot_labels", ",", "bio_slot_preds", ")", "\n", "results", "[", "'slot_micro_f1'", "]", "=", "smf1", "\n", "# Assuming normal distribution. Multiply by z (from \"z table\") to get confidence int", "\n", "total_slots", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "bio_slot_preds", "]", ")", "\n", "results", "[", "'slot_micro_f1_stderr'", "]", "=", "sqrt", "(", "smf1", "*", "(", "1", "-", "smf1", ")", "/", "total_slots", ")", "\n", "\n", "", "if", "(", "'ex_match_acc'", "in", "eval_metrics", ")", "or", "(", "'all'", "in", "eval_metrics", ")", ":", "\n", "# calculate exact match accuracy (~0.01 seconds)", "\n", "        ", "matches", "=", "0", "\n", "denom", "=", "0", "\n", "for", "p_int", ",", "p_slot", ",", "l_int", ",", "l_slot", "in", "zip", "(", "pred_intents", ",", "\n", "bio_slot_preds", ",", "\n", "lab_intents", ",", "\n", "bio_slot_labels", ")", ":", "\n", "\n", "            ", "if", "(", "p_int", "==", "l_int", ")", "and", "(", "p_slot", "==", "l_slot", ")", ":", "\n", "                ", "matches", "+=", "1", "\n", "", "denom", "+=", "1", "\n", "", "emacc", "=", "matches", "/", "denom", "\n", "\n", "results", "[", "'ex_match_acc'", "]", "=", "emacc", "\n", "# Assuming normal distribution. Multiply by z (from \"z table\") to get confidence int", "\n", "results", "[", "'ex_match_acc_stderr'", "]", "=", "sqrt", "(", "emacc", "*", "(", "1", "-", "emacc", ")", "/", "len", "(", "pred_intents", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.output_predictions": [[515, 693], ["conf.get", "conf.get", "logger.info", "logger.info", "conf.get", "NotImplementedError", "conf.get", "zip", "conf.get", "numpy.argmax", "numpy.argmax", "slot_preds_str.append", "enumerate", "tok.strip.replace", "tok.strip.strip", "slots.append", "final_outputs.append", "conf.get", "tokenizer.batch_decode", "conf.get", "training_utils.convert_t2t_batch_to_intents_slots", "zip", "NotImplementedError", "parse.strip", "open", "clean_preds.append", "zip", "slots_pred_tup.append", "slots.append", "conf.get", "conf.get", "f.write", "str", "new.append", "zip", "slots.append", "tok_utt[].replace", "tok.strip.replace", "tok.strip.strip", "slots.append", "conf.get", "json.dumps", "str", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_t2t_batch_to_intents_slots", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "output_predictions", "(", "outputs", ",", "intent_labels", ",", "slot_labels", ",", "conf", ",", "tokenizer", "=", "None", ",", "\n", "combine_slots", "=", "True", ",", "remove_slots", "=", "None", ",", "add_pred_parse", "=", "True", ",", "\n", "save_to_file", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param outputs: The outputs from the model\n    :type outputs: named_tuple\n    :param intent_labels: A dictionary mapping each intent's numerical index to the intent\n    :type slot_labels: dict\n    :param slot_labels: A dictionary mapping each slot's numerical index to the slot\n    :type slot_labels: dict\n    :param conf: The MASSIVE configuration object\n    :type conf: massive.Configuration\n    :param tokenizer: The tokenizer\n    :type tokenizer: PreTrainedTokenizerFast\n    :param combine_slots: Whether or not to combine adjacent same-slotted tokens to one slot\n    :type combine_slots: bool\n    :param remove_slots: Slots to remove. Default ['Other']\n    :type remove_slots: list\n    :param add_pred_parse: Whether to add the SLURP-style parsed output\n    :type add_pred_parse: bool\n    :param save_to_file: Whether to save predictions to the file given in the config\n    :type save_to_file: bool\n    \"\"\"", "\n", "\n", "remove_slots", "=", "[", "'Other'", "]", "if", "not", "remove_slots", "else", "remove_slots", "\n", "\n", "pred_file", "=", "conf", ".", "get", "(", "'train_val.predictions_file'", ")", "\n", "\n", "if", "pred_file", "and", "(", "conf", ".", "get", "(", "'train_val.trainer_args.locale_eval_strategy'", ")", "!=", "'all only'", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must use 'all only' as the locale_eval_strategy if you\"", "\n", "\" specify a predictions file\"", ")", "\n", "\n", "", "final_outputs", "=", "[", "]", "\n", "\n", "# if there is a space within sequence of subwords that should be joined back together,", "\n", "# it's probably because the tokenizer converted a Zero Width Space to a normal space.", "\n", "# Make this False to not replace the space with a ZWSP when re-joining subwords", "\n", "replace_zwsp", "=", "conf", ".", "get", "(", "'test.replace_inner_space_zwsp'", ",", "default", "=", "True", ")", "\n", "\n", "if", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive intent class slot fill'", ":", "\n", "# Create strings of the slot predictions", "\n", "        ", "intent_preds", ",", "slot_preds", "=", "outputs", ".", "predictions", "[", "0", "]", ",", "outputs", ".", "predictions", "[", "1", "]", "\n", "intent_preds_am", "=", "[", "np", ".", "argmax", "(", "x", ")", "for", "x", "in", "intent_preds", "]", "\n", "intent_preds_str", "=", "[", "intent_labels", "[", "str", "(", "x", ")", "]", "for", "x", "in", "intent_preds_am", "]", "\n", "\n", "slot_preds_am", "=", "[", "np", ".", "argmax", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "slot_preds", "]", "\n", "slot_preds_str", "=", "[", "]", "\n", "for", "example", "in", "slot_preds_am", ":", "\n", "            ", "slot_preds_str", ".", "append", "(", "[", "slot_labels", "[", "str", "(", "x", ")", "]", "for", "x", "in", "example", "]", ")", "\n", "\n", "# Iterate through the examples", "\n", "", "for", "eyed", ",", "loc", ",", "utt", ",", "tok_utt", ",", "intent_pred", ",", "slot_pred", ",", "subword_align", "in", "zip", "(", "\n", "outputs", ".", "ids", ",", "\n", "outputs", ".", "locales", ",", "\n", "outputs", ".", "utts", ",", "\n", "outputs", ".", "tok_utts", ",", "\n", "intent_preds_str", ",", "\n", "slot_preds_str", ",", "\n", "outputs", ".", "subword_aligns", ")", ":", "\n", "\n", "            ", "line", "=", "{", "}", "\n", "line", "[", "'id'", "]", ",", "line", "[", "'locale'", "]", ",", "line", "[", "'utt'", "]", ",", "line", "[", "'pred_intent'", "]", "=", "eyed", ",", "loc", ",", "utt", ",", "intent_pred", "\n", "\n", "# Determine slot predictions", "\n", "running_detok_idx", ",", "tok", ",", "slot", ",", "slots", "=", "-", "1", ",", "''", ",", "''", ",", "[", "]", "\n", "for", "tok_idx", ",", "detok_idx", "in", "enumerate", "(", "subword_align", ")", ":", "\n", "                ", "if", "detok_idx", "is", "None", ":", "\n", "                    ", "continue", "\n", "# Combine the subwords that had been broken up", "\n", "", "if", "detok_idx", "==", "running_detok_idx", ":", "\n", "# If there is a \\u2581 within what was a single \"word\" from the input data,", "\n", "# then it's probably from a zero-width space, \\u200b, which the tokenizer", "\n", "# converted to a space. We don't want these extra spaces, so they are removed", "\n", "                    ", "if", "replace_zwsp", ":", "\n", "                        ", "tok_repl", "=", "tok_utt", "[", "tok_idx", "]", ".", "replace", "(", "u'\\u2581'", ",", "u'\\u200b'", ")", "\n", "", "else", ":", "\n", "                        ", "tok_repl", "=", "tok_utt", "[", "tok_idx", "]", "\n", "", "tok", "+=", "tok_repl", "\n", "\n", "# Record the token and slot and start a new one", "\n", "", "else", ":", "\n", "                    ", "if", "running_detok_idx", "!=", "-", "1", ":", "\n", "                        ", "tok", "=", "tok", ".", "replace", "(", "'\u2581'", ",", "' '", ")", "\n", "tok", "=", "tok", ".", "strip", "(", ")", "\n", "slots", ".", "append", "(", "(", "tok", ",", "slot", ")", ")", "\n", "", "slot", "=", "slot_pred", "[", "tok_idx", "]", "\n", "tok", "=", "tok_utt", "[", "tok_idx", "]", "\n", "", "running_detok_idx", "=", "detok_idx", "\n", "# Add the last token and slot", "\n", "", "tok", "=", "tok", ".", "replace", "(", "'\u2581'", ",", "' '", ")", "\n", "tok", "=", "tok", ".", "strip", "(", ")", "\n", "slots", ".", "append", "(", "(", "tok", ",", "slot", ")", ")", "\n", "\n", "line", "[", "'pred_slots'", "]", "=", "slots", "\n", "final_outputs", ".", "append", "(", "line", ")", "\n", "\n", "", "", "elif", "conf", ".", "get", "(", "'collator.type'", ")", "==", "'massive text to text intent class slot fill'", ":", "\n", "        ", "clean_preds", "=", "[", "]", "\n", "\n", "# Remove padding and other special tokens", "\n", "for", "pred", "in", "outputs", ".", "predictions", ":", "\n", "            ", "pred", "=", "pred", "[", "pred", "!=", "-", "100", "]", "\n", "pred", "=", "pred", "[", "pred", "!=", "tokenizer", ".", "pad_token_id", "]", "\n", "pred", "=", "pred", "[", "pred", "!=", "tokenizer", ".", "eos_token_id", "]", "\n", "clean_preds", ".", "append", "(", "pred", ")", "\n", "\n", "", "clean_pred_dec", "=", "tokenizer", ".", "batch_decode", "(", "clean_preds", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "t2t_args", "=", "conf", ".", "get", "(", "'collator.args.t2t_args'", ")", "\n", "intents_pred", ",", "slots_pred", "=", "convert_t2t_batch_to_intents_slots", "(", "clean_pred_dec", ",", "**", "t2t_args", ")", "\n", "\n", "# Convert slots to (token, slot) format", "\n", "slots_pred_tup", "=", "[", "]", "\n", "for", "utt", ",", "slots", "in", "zip", "(", "outputs", ".", "utts", ",", "slots_pred", ")", ":", "\n", "            ", "new", "=", "[", "]", "\n", "# Pad with Other to length of utt", "\n", "slots", "=", "slots", "[", ":", "len", "(", "utt", ")", "]", "+", "[", "'Other'", "]", "*", "(", "len", "(", "utt", ")", "-", "len", "(", "slots", ")", ")", "\n", "# make tuple with token", "\n", "for", "tok", ",", "slot", "in", "zip", "(", "utt", ",", "slots", ")", ":", "\n", "                ", "new", ".", "append", "(", "(", "tok", ",", "slot", ")", ")", "\n", "", "slots_pred_tup", ".", "append", "(", "new", ")", "\n", "\n", "\n", "# Create the list of dicts", "\n", "", "final_outputs", "=", "[", "\n", "{", "'id'", ":", "eyed", ",", "'locale'", ":", "loc", ",", "'utt'", ":", "utt", ",", "'pred_intent'", ":", "intent", ",", "'pred_slots'", ":", "slot", "}", "for", "eyed", ",", "loc", ",", "utt", ",", "intent", ",", "slot", "in", "zip", "(", "outputs", ".", "ids", ",", "outputs", ".", "locales", ",", "outputs", ".", "utts", ",", "intents_pred", ",", "slots_pred_tup", ")", "\n", "]", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Collator {conf.get('collator.type')} not known\"", ")", "\n", "\n", "\n", "", "for", "line", "in", "final_outputs", ":", "\n", "        ", "slots", "=", "[", "]", "\n", "for", "tup", "in", "line", "[", "'pred_slots'", "]", ":", "\n", "            ", "if", "not", "slots", ":", "\n", "                ", "slots", ".", "append", "(", "tup", ")", "\n", "slots_idx", "=", "0", "\n", "# if slot the same as previous token, combine", "\n", "", "elif", "tup", "[", "1", "]", "==", "slots", "[", "slots_idx", "]", "[", "1", "]", ":", "\n", "                ", "slots", "[", "slots_idx", "]", "=", "(", "slots", "[", "slots_idx", "]", "[", "0", "]", "+", "' '", "+", "tup", "[", "0", "]", ",", "slots", "[", "slots_idx", "]", "[", "1", "]", ")", "\n", "# otherwise add to end", "\n", "", "else", ":", "\n", "                ", "slots", ".", "append", "(", "tup", ")", "\n", "slots_idx", "+=", "1", "\n", "\n", "# Create a SLURP-like version of each utterance", "\n", "", "", "if", "add_pred_parse", ":", "\n", "            ", "parse", "=", "''", "\n", "for", "slot", "in", "slots", ":", "\n", "                ", "if", "slot", "[", "1", "]", "in", "remove_slots", ":", "\n", "                    ", "parse", "+=", "' '", "+", "slot", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "parse", "+=", "' ['", "+", "slot", "[", "1", "]", "+", "' : '", "+", "slot", "[", "0", "]", "+", "']'", "\n", "", "", "line", "[", "'pred_annot_utt'", "]", "=", "parse", ".", "strip", "(", ")", "\n", "\n", "# If adjacent tokens have the same slot, combine them", "\n", "", "if", "combine_slots", ":", "\n", "            ", "line", "[", "'pred_slots'", "]", "=", "slots", "\n", "\n", "# Remove slots in the remove_slots list", "\n", "", "if", "remove_slots", ":", "\n", "            ", "line", "[", "'pred_slots'", "]", "=", "[", "x", "for", "x", "in", "line", "[", "'pred_slots'", "]", "if", "x", "[", "1", "]", "not", "in", "remove_slots", "]", "\n", "\n", "", "", "logger", ".", "info", "(", "f\"Example of final output:\\n{final_outputs[:2]}\"", ")", "\n", "logger", ".", "info", "(", "f\"Writing to {conf.get('test.predictions_file')}\"", ")", "\n", "\n", "# True to output escaped unicode codes or False to output unicode", "\n", "ensure_ascii", "=", "conf", ".", "get", "(", "'test.predictions_ensure_ascii'", ",", "default", "=", "False", ")", "\n", "\n", "if", "save_to_file", ":", "\n", "        ", "with", "open", "(", "conf", ".", "get", "(", "'test.predictions_file'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "final_outputs", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "line", ",", "ensure_ascii", "=", "ensure_ascii", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "", "return", "final_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_input_to_t2t": [[694, 721], ["utt.insert", "new_utt.append", "new_utt.append", "input_prompt.strip", "str"], "function", ["None"], ["", "def", "convert_input_to_t2t", "(", "utt", ",", "input_prompt", "=", "\"Annotate: \"", ",", "sentinels", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to convert an input to text-to-text format\n\n    :param utt: A list of words pre-tokenization. The input to the model pre-formatting.\n    :type utt: list\n    :param input_prompt: The prompt to add before the input. Default: \"Annotate: \"\n    :type intent: str\n    :param sentinels: Whether to add T5 sentinels before each token. Default: False\n                      See: https://arxiv.org/pdf/2203.08378.pdf\n    :type sentinels: bool\n    :return: the reformatted input to the model\n    :rtype: list\n    \"\"\"", "\n", "\n", "if", "sentinels", ":", "\n", "        ", "new_utt", ",", "sent_id", "=", "[", "]", ",", "0", "\n", "for", "tok", "in", "utt", ":", "\n", "            ", "new_utt", ".", "append", "(", "'<extra_id_'", "+", "str", "(", "sent_id", ")", "+", "'>'", ")", "\n", "new_utt", ".", "append", "(", "tok", ")", "\n", "sent_id", "+=", "1", "\n", "", "utt", "=", "new_utt", "\n", "\n", "", "if", "input_prompt", ":", "\n", "        ", "utt", ".", "insert", "(", "0", ",", "input_prompt", ".", "strip", "(", ")", ")", "\n", "\n", "", "return", "utt", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_intent_slots_to_t2t": [[722, 838], ["enumerate", "new_slots.append", "new_utt.append", "ValueError", "zip", "new_slots.append", "new_slots.append", "str"], "function", ["None"], ["", "def", "convert_intent_slots_to_t2t", "(", "utt", ",", "intent", ",", "slots", ",", "use_output_descrip", "=", "False", ",", "intent_first", "=", "False", ",", "\n", "slots_mixed", "=", "False", ",", "toks_in_output", "=", "False", ",", "sentinels", "=", "False", ",", "\n", "inside_format", "=", "'slot_name'", ",", "outside_label", "=", "'Other'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to convert an intent and 0 or more slots to a text-to-text format\n\n    :param utt: A list of words pre-tokenization\n    :type utt: list\n    :param intent: The intent\n    :type intent: str\n    :param slots: a list of the slots\n    :type slots: list\n    :param use_output_descrip: Whether or not to include descriptive prompts in the output, being\n                               'tokens: ' and 'annotations' for non mixed slotting or 'annotation: '\n                               for mixed slotting. Default: False\n    :type use_output_descrip: bool\n    :param intent_first: Whether to put the intent before the slots and utterance (True) or after\n                         Default: True\n    :type intent_first: bool\n    :param slots_mixed: Whether to put each slot after its respective token (True) or to put all\n                        slots after all tokens (False). Default: False\n    :type slots_mixed: bool\n    :param input_prompt: The text prompt for the input. Leave blank for no prompt.\n                         Default: 'Annotate: '\n    :type input_prompt: str\n    :param toks_in_output: Whether to put tokens in the output or not. Default: False. If this is\n                           True, then slots_mixed must be False\n    :type toks_in_output: bool\n    :param sentinels: Whether to add T5 sentinels before each token. Overrides toks_in_output and\n                      slots_mixed. Default: False\n                      See: https://arxiv.org/pdf/2203.08378.pdf\n    :type sentinels: bool\n    :param inside_format: The slot to use for the inside of a multi-word slot. Options are\n                          \"slot_name\", in which the slot name is repeated, \"inside_slot_name\",\n                          in which \"I-\" is added to the slot name, or \"inside\", in which \"I\" is\n                          used on its own.\n    :type inside_format: str\n    :param outside_label: The word used for non-slotted tokens. Default: Other\n    :type outside_label: str\n\n    :return: the output text\n    :rtype: str\n    \"\"\"", "\n", "\n", "# Suppose we have:", "\n", "# intent: calendar_set", "\n", "# annot_utt: [event_name: meetings] this [date: monday]", "\n", "\n", "if", "sentinels", ":", "\n", "# using sentinels is the same as doing slots_mixed and toks_in_output and converting the", "\n", "# utterance to a sequence of sentinels", "\n", "        ", "toks_in_output", "=", "True", "\n", "slots_mixed", "=", "True", "\n", "new_utt", ",", "sent_id", "=", "[", "]", ",", "0", "\n", "for", "tok", "in", "utt", ":", "\n", "            ", "new_utt", ".", "append", "(", "'<extra_id_'", "+", "str", "(", "sent_id", ")", "+", "'>'", ")", "\n", "sent_id", "+=", "1", "\n", "", "utt", "=", "new_utt", "\n", "\n", "# Modify for inside format if needed", "\n", "", "new_slots", "=", "[", "]", "\n", "for", "idx", ",", "slot", "in", "enumerate", "(", "slots", ")", ":", "\n", "        ", "if", "idx", ">", "0", "and", "slot", "!=", "outside_label", ":", "\n", "            ", "if", "slot", "==", "slots", "[", "idx", "-", "1", "]", ":", "\n", "                ", "if", "inside_format", "==", "'inside_slot_name'", ":", "\n", "                    ", "new_slots", ".", "append", "(", "\"I-\"", "+", "slot", ")", "\n", "continue", "\n", "", "if", "inside_format", "==", "'inside'", ":", "\n", "                    ", "new_slots", ".", "append", "(", "\"I\"", ")", "\n", "continue", "\n", "", "", "", "new_slots", ".", "append", "(", "slot", ")", "\n", "", "slots", "=", "new_slots", "\n", "\n", "slot_list", "=", "slots", "\n", "toks", ",", "slots", "=", "' '", ".", "join", "(", "utt", ")", ",", "' '", ".", "join", "(", "slots", ")", "\n", "\n", "if", "use_output_descrip", ":", "\n", "        ", "intent_pre", "=", "'intent: '", "\n", "mixed_pre", "=", "'annotation: '", "\n", "non_mixed_tok_pre", "=", "'tokens: '", "\n", "non_mixed_slot_pre", "=", "'annotations: '", "\n", "\n", "", "if", "slots_mixed", ":", "\n", "        ", "if", "toks_in_output", "is", "False", ":", "\n", "            ", "raise", "ValueError", "(", "'slots_mixed cannot be True if toks_in_output is False'", ")", "\n", "\n", "# annot_utt = \"meeting event_name this Other monday date\"", "\n", "", "annot_utt", "=", "[", "tok", "+", "' '", "+", "slot", "for", "tok", ",", "slot", "in", "zip", "(", "utt", ",", "slot_list", ")", "]", "\n", "annot_utt", "=", "' '", ".", "join", "(", "annot_utt", ")", "\n", "if", "use_output_descrip", ":", "\n", "# annot_utt = \"annotation: meeting event_name this Other monday date\"", "\n", "            ", "annot_utt", "=", "mixed_pre", "+", "annot_utt", "\n", "", "", "else", ":", "\n", "# remove tokens entirely if needed", "\n", "        ", "if", "toks_in_output", ":", "\n", "            ", "toks", "+=", "' '", "\n", "", "else", ":", "\n", "            ", "toks", "=", "''", "\n", "non_mixed_tok_pre", "=", "''", "\n", "\n", "", "if", "use_output_descrip", ":", "\n", "# \"tokens: meeting this monday annotations: event_name Other date\"", "\n", "            ", "annot_utt", "=", "non_mixed_tok_pre", "+", "toks", "+", "non_mixed_slot_pre", "+", "slots", "\n", "", "else", ":", "\n", "# annot_utt = \"meeting this monday event_name Other date\"", "\n", "            ", "annot_utt", "=", "toks", "+", "slots", "\n", "\n", "# place intent either at beginning or end", "\n", "", "", "if", "intent_first", ":", "\n", "        ", "if", "use_output_descrip", ":", "\n", "            ", "return", "intent_pre", "+", "intent", "+", "' '", "+", "annot_utt", "\n", "", "return", "intent", "+", "' '", "+", "annot_utt", "\n", "", "else", ":", "\n", "        ", "if", "use_output_descrip", ":", "\n", "            ", "return", "annot_utt", "+", "' '", "+", "intent_pre", "+", "intent", "\n", "", "return", "annot_utt", "+", "' '", "+", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_t2t_batch_to_intents_slots": [[840, 944], ["enumerate", "enumerate", "new_slots.append", "new_utt.append", "x.split", "x.split", "slots_pred.append", "len", "x.split", "x.split", "x.split", "len", "slot.startswith", "x.split", "new_slots.append", "str", "new_slots.append"], "function", ["None"], ["", "", "def", "convert_t2t_batch_to_intents_slots", "(", "mod_out", ",", "use_output_descrip", "=", "False", ",", "intent_first", "=", "False", ",", "\n", "slots_mixed", "=", "False", ",", "toks_in_output", "=", "False", ",", "sentinels", "=", "False", ",", "\n", "inside_format", "=", "'slot_name'", ",", "outside_label", "=", "'Other'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to convert an intent and 0 or more slots to a text-to-text format\n\n    :param model_out: A list of outputs from the model, each a detokenized string\n    :type model_out: list\n    :param use_output_descrip: Whether or not to include descriptive prompts in the output, being\n                               'tokens: ' and 'annotations' for non mixed slotting or 'annotation: '\n                               for mixed slotting. Default: False\n    :type use_output_descrip: bool\n    :param intent_first: Whether to put the intent before the slots and utterance (True) or after\n                         Default: True\n    :type intent_first: bool\n    :param slots_mixed: Whether to put each slot after its respective token (True) or to put all\n                        slots after all tokens (False). Default: False\n    :type slots_mixed: bool\n    :param input_prompt: The text prompt for the input. Leave blank for no prompt.\n                         Default: 'Annotate: '\n    :type input_prompt: str\n    :param toks_in_output: Whether to put tokens in the output or not. Default: False. If this is\n                           True, then slots_mixed must be False\n    :type toks_in_output: bool\n    :param sentinels: Whether to add T5 sentinels before each token. Overrides toks_in_output and\n                      slots_mixed. Default: False\n                      See: https://arxiv.org/pdf/2203.08378.pdf\n    :type sentinels: bool\n    :param inside_format: The slot to use for the inside of a multi-word slot. Options are\n                          \"slot_name\", in which the slot name is repeated, \"inside_slot_name\",\n                          in which \"I-\" is added to the slot name, or \"inside\", in which \"I\" is\n                          used on its own.\n    :type inside_format: str\n    :param outside_label: The word used for non-slotted tokens. Default: Other\n    :type outside_label: str\n\n    :return: a list of intents, a list of slot lists\n    :rtype: list\n    \"\"\"", "\n", "\n", "if", "sentinels", ":", "\n", "# using sentinels is the same as doing slots_mixed and toks_in_output and converting the", "\n", "# utterance to a sequence of sentinels", "\n", "        ", "toks_in_output", "=", "True", "\n", "slots_mixed", "=", "True", "\n", "for", "example", "in", "mod_out", ":", "\n", "            ", "new_utt", ",", "sent_id", "=", "[", "]", ",", "0", "\n", "for", "tok", "in", "example", ":", "\n", "                ", "new_utt", ".", "append", "(", "'<extra_id_'", "+", "str", "(", "sent_id", ")", "+", "'>'", ")", "\n", "sent_id", "+=", "1", "\n", "", "example", "=", "new_utt", "\n", "\n", "# Get intents", "\n", "", "", "if", "intent_first", "and", "use_output_descrip", ":", "\n", "# Note: this assumes that the description is one word", "\n", "        ", "intents_pred", "=", "[", "x", ".", "split", "(", ")", "[", "1", "]", "if", "len", "(", "x", ".", "split", "(", ")", ")", ">", "1", "else", "''", "for", "x", "in", "mod_out", "]", "\n", "", "elif", "intent_first", ":", "\n", "        ", "intents_pred", "=", "[", "x", ".", "split", "(", ")", "[", "0", "]", "for", "x", "in", "mod_out", "]", "\n", "", "else", ":", "\n", "        ", "intents_pred", "=", "[", "x", ".", "split", "(", ")", "[", "-", "1", "]", "for", "x", "in", "mod_out", "]", "\n", "\n", "# Determine Slots. Note: this assumes that the description is one word", "\n", "", "descrip_shift", "=", "0", "\n", "if", "use_output_descrip", ":", "\n", "        ", "descrip_shift", "=", "1", "\n", "\n", "", "if", "intent_first", ":", "\n", "# Everthing after the intent", "\n", "        ", "slot_chunk_pred", "=", "[", "x", ".", "split", "(", ")", "[", "(", "1", "+", "2", "*", "descrip_shift", ")", ":", "]", "for", "x", "in", "mod_out", "]", "\n", "", "else", ":", "\n", "# Everything until the intent", "\n", "        ", "slot_chunk_pred", "=", "[", "x", ".", "split", "(", ")", "[", "(", "descrip_shift", ")", ":", "(", "-", "1", "*", "(", "descrip_shift", "+", "1", ")", ")", "]", "for", "x", "in", "mod_out", "]", "\n", "", "if", "toks_in_output", "and", "slots_mixed", ":", "\n", "# Grab every other item", "\n", "        ", "slots_pred", "=", "[", "x", "[", "1", ":", ":", "2", "]", "for", "x", "in", "slot_chunk_pred", "]", "\n", "", "elif", "toks_in_output", ":", "\n", "        ", "slots_pred", "=", "[", "]", "\n", "# Assume equal number of tokens and slots and take second half", "\n", "for", "pred", "in", "slot_chunk_pred", ":", "\n", "            ", "pred", "=", "pred", "[", "descrip_shift", ":", "]", "\n", "mid", "=", "len", "(", "pred", ")", "//", "2", "\n", "slots_pred", ".", "append", "(", "pred", "[", "mid", ":", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "slots_pred", "=", "slot_chunk_pred", "\n", "\n", "# Modify for inside format if needed", "\n", "", "for", "s_idx", ",", "slots", "in", "enumerate", "(", "slots_pred", ")", ":", "\n", "        ", "new_slots", "=", "[", "]", "\n", "for", "idx", ",", "slot", "in", "enumerate", "(", "slots", ")", ":", "\n", "            ", "if", "idx", ">", "0", "and", "slot", "!=", "outside_label", ":", "\n", "                ", "if", "inside_format", "==", "'inside_slot_name'", ":", "\n", "                    ", "if", "slot", ".", "startswith", "(", "'I-'", ")", ":", "\n", "                        ", "new_slots", ".", "append", "(", "slots", "[", "idx", "-", "1", "]", ")", "\n", "continue", "\n", "", "", "elif", "inside_format", "==", "'inside'", ":", "\n", "                    ", "if", "slot", "==", "'I'", ":", "\n", "                        ", "new_slots", ".", "append", "(", "slots", "[", "idx", "-", "1", "]", ")", "\n", "continue", "\n", "", "", "", "new_slots", ".", "append", "(", "slot", ")", "\n", "", "slots_pred", "[", "s_idx", "]", "=", "new_slots", "\n", "\n", "", "return", "intents_pred", ",", "slots_pred", "\n", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.__init__": [[23, 25], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "conf_dict", ")", ":", "\n", "        ", "self", ".", "kv", "=", "conf_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get": [[26, 47], ["key.split", "key_comps[].isdigit", "int", "len", "configuration.Configuration.get", "KeyError"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "get", "(", "self", ",", "key", ",", "required", "=", "False", ",", "default", "=", "None", ",", "d", "=", "None", ",", "_original_key", "=", "None", ")", ":", "\n", "        ", "if", "d", "is", "None", ":", "\n", "            ", "d", "=", "self", ".", "kv", "\n", "_original_key", "=", "key", "\n", "", "key_comps", "=", "key", ".", "split", "(", "'.'", ")", "\n", "try", ":", "\n", "# Extending the capability to get list indices in the configuration", "\n", "# Example: config.get(\"model_factory.model.embedding_block.embedding_layers.1.export!\")", "\n", "            ", "if", "key_comps", "[", "0", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "key_comps", "[", "0", "]", "=", "int", "(", "key_comps", "[", "0", "]", ")", "\n", "", "v", "=", "d", "[", "key_comps", "[", "0", "]", "]", "\n", "if", "len", "(", "key_comps", ")", ">", "1", ":", "\n", "                ", "return", "self", ".", "get", "(", "\n", "key", "=", "\".\"", ".", "join", "(", "key_comps", "[", "1", ":", "]", ")", ",", "d", "=", "v", ",", "required", "=", "required", ",", "default", "=", "default", ",", "\n", "_original_key", "=", "_original_key", ")", "\n", "", "return", "v", "\n", "", "except", "KeyError", ":", "\n", "# Find the nearest key in the list of keys.", "\n", "            ", "if", "required", ":", "\n", "                ", "raise", "KeyError", "(", ")", "\n", "", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.override": [[48, 81], ["key.split", "isinstance", "int", "len", "type", "isinstance", "configuration.Configuration.override", "configuration.Configuration.override._convert_type"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.override"], ["", "", "def", "override", "(", "self", ",", "key", ",", "value", ",", "d", "=", "None", ",", "_original_key", "=", "None", ",", "force", "=", "False", ")", ":", "\n", "        ", "def", "_convert_type", "(", "x", ",", "y", ")", ":", "\n", "            ", "return", "type", "(", "x", ")", "(", "y", ")", "\n", "\n", "", "if", "d", "is", "None", ":", "\n", "            ", "d", "=", "self", ".", "kv", "\n", "_original_key", "=", "key", "\n", "\n", "", "key_comps", "=", "key", ".", "split", "(", "'.'", ")", "\n", "if", "isinstance", "(", "d", ",", "list", ")", ":", "\n", "            ", "k", "=", "int", "(", "key_comps", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "k", "=", "key_comps", "[", "0", "]", "\n", "\n", "", "if", "len", "(", "key_comps", ")", ">", "1", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "isinstance", "(", "d", ",", "list", ")", ":", "\n", "                    ", "v", "=", "d", "[", "k", "]", "\n", "", "else", ":", "\n", "                    ", "v", "=", "d", ".", "setdefault", "(", "k", ",", "{", "}", ")", "\n", "", "return", "self", ".", "override", "(", "\n", "key", "=", "\".\"", ".", "join", "(", "key_comps", "[", "1", ":", "]", ")", ",", "d", "=", "v", ",", "value", "=", "value", ",", "_original_key", "=", "_original_key", ",", "\n", "force", "=", "force", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "raise", "KeyError", "(", "\"key '{}' does not exist in configuration\"", ".", "format", "(", "_original_key", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "force", ":", "\n", "                ", "assert", "type", "(", "d", ")", "is", "dict", "and", "k", "in", "d", ",", "\"Trying to override key '{}' that does not exist in configuration\"", ".", "format", "(", "\n", "_original_key", ")", "\n", "d", "[", "key_comps", "[", "0", "]", "]", "=", "_convert_type", "(", "d", "[", "k", "]", ",", "value", ")", "\n", "", "else", ":", "\n", "                ", "d", "[", "key_comps", "[", "0", "]", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get_as_dict": [[82, 84], ["None"], "methods", ["None"], ["", "", "", "def", "get_as_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "kv", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.read_conf": [[86, 110], ["configuration._parse_overrides_to_dict", "configuration.Configuration", "open", "ruamel.yaml.YAML", "ruamel.yaml.YAML.load", "f.read"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration._parse_overrides_to_dict"], ["", "", "def", "read_conf", "(", "file_name", ",", "overrides", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Parse a configuration file.\n\n    :param file_name: path to configuration file\n    :param overrides: list or dict of override parameters in \"path.to.key:value\" value format, e.g.\n        \"training.optimizer.parameters.learning_rate:0.001\"\n\n    :return: Configuration object\n    \"\"\"", "\n", "\n", "if", "overrides", "is", "None", ":", "\n", "        ", "overrides", "=", "[", "]", "\n", "\n", "", "override_dict", "=", "_parse_overrides_to_dict", "(", "overrides", ")", "\n", "\n", "# load configuration from file. The pyyaml's loader works fine with", "\n", "# both YAML and JSON files, as the former is a superset of the latter.", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "yaml", "=", "YAML", "(", "typ", "=", "\"safe\"", ")", "\n", "configuration_dict", "=", "yaml", ".", "load", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "# take care of overrides later", "\n", "", "return", "Configuration", "(", "configuration_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.utils.configuration._parse_overrides_to_dict": [[111, 138], ["isinstance", "isinstance", "RuntimeError", "isinstance", "ks.split.split", "override.split", "d.setdefault.setdefault", "overrides.get", "len", "ruamel.yaml.YAML.load"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["", "def", "_parse_overrides_to_dict", "(", "overrides", ")", ":", "\n", "    ", "\"\"\"\n    Parse the list of override in the key.to.override:value format\n    to a nested dictionary that can be merged with the parsed output.\n\n    :param overrides: list of strings containing overrides provided via command line.\n    :return: a dictionary containing any (nested) key to override.\n    :raise RuntimeError when overrides is neither list nor dict\n    \"\"\"", "\n", "if", "isinstance", "(", "overrides", ",", "list", ")", "or", "isinstance", "(", "overrides", ",", "dict", ")", ":", "\n", "        ", "override_dict", "=", "{", "}", "\n", "for", "override", "in", "overrides", ":", "\n", "            ", "if", "isinstance", "(", "overrides", ",", "list", ")", ":", "\n", "                ", "ks", ",", "v", "=", "override", ".", "split", "(", "':'", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "ks", ",", "v", "=", "override", ",", "overrides", ".", "get", "(", "override", ")", "\n", "", "ks", "=", "ks", ".", "split", "(", "'.'", ")", "\n", "d", "=", "override_dict", "\n", "while", "True", ":", "\n", "                ", "if", "len", "(", "ks", ")", "==", "1", ":", "\n", "                    ", "d", "[", "ks", "[", "0", "]", "]", "=", "YAML", ".", "load", "(", "v", ")", "\n", "break", "\n", "", "d", "=", "d", ".", "setdefault", "(", "ks", "[", "0", "]", ",", "{", "}", ")", "\n", "ks", "=", "ks", "[", "1", ":", "]", "\n", "", "", "return", "override_dict", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"override is not a list or dictionary! \\n {}\"", ".", "format", "(", "overrides", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.loaders.collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.__init__": [[44, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "max_length", ",", "padding", "=", "'longest'", ",", "pad_to_multiple_of", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "pad_to_multiple_of", "=", "pad_to_multiple_of", "\n", "\n", "self", ".", "col_chk", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.loaders.collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.__call__": [[52, 122], ["collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.tokenizer", "enumerate", "collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.tokenizer.pad", "collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.word_ids", "torch.tensor", "logger.info", "tokenized_inputs[].append", "torch.tensor", "collator_ic_sf.CollatorMASSIVEIntentClassSlotFill.items", "label_ids.append", "list", "list", "label_ids.append", "label_ids.append", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "# On-the-fly tokenization and alignment -- do NOT use a pre-tokenized dataset", "\n", "\n", "        ", "tokenized_inputs", "=", "self", ".", "tokenizer", "(", "\n", "[", "item", "[", "'utt'", "]", "for", "item", "in", "batch", "]", ",", "\n", "truncation", "=", "True", ",", "\n", "is_split_into_words", "=", "True", "\n", ")", "\n", "\n", "# Align the labels with the tokenized utterance", "\n", "# adapted from here: https://huggingface.co/docs/transformers/custom_datasets#tok_ner", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "label", "=", "entry", "[", "'slots_num'", "]", "\n", "word_ids", "=", "tokenized_inputs", ".", "word_ids", "(", "batch_index", "=", "i", ")", "# Map tokens to respective word", "\n", "previous_word_idx", "=", "None", "\n", "label_ids", "=", "[", "]", "\n", "# Set the special tokens to -100.", "\n", "for", "word_idx", "in", "word_ids", ":", "\n", "                ", "if", "word_idx", "is", "None", ":", "\n", "                    ", "label_ids", ".", "append", "(", "-", "100", ")", "\n", "# Only label the first token of a given word.", "\n", "", "elif", "word_idx", "!=", "previous_word_idx", ":", "\n", "                    ", "label_ids", ".", "append", "(", "label", "[", "word_idx", "]", ")", "\n", "previous_word_idx", "=", "word_idx", "\n", "", "else", ":", "\n", "                    ", "label_ids", ".", "append", "(", "-", "100", ")", "\n", "\n", "# Log example outputs from the collator for debugging", "\n", "", "", "if", "self", ".", "col_chk", "is", "not", "False", ":", "\n", "                ", "logger", ".", "info", "(", "f\"Collator Check! utt: {entry['utt']}; intent label: \"", "\n", "f\"{entry['intent_num']}; slot labels: {entry['slots_num']}, \"", "\n", "f\"tokenized utt: {tokenized_inputs[i]}; word_ids: {word_ids}; \"", "\n", "f\"label_ids: {label_ids}\"", ")", "\n", "if", "self", ".", "col_chk", "==", "4", ":", "\n", "                    ", "self", ".", "col_chk", "=", "False", "\n", "", "else", ":", "\n", "                    ", "self", ".", "col_chk", "+=", "1", "\n", "\n", "", "", "if", "'slots_num'", "in", "tokenized_inputs", ":", "\n", "                ", "tokenized_inputs", "[", "'slots_num'", "]", ".", "append", "(", "label_ids", ")", "\n", "", "else", ":", "\n", "                ", "tokenized_inputs", "[", "'slots_num'", "]", "=", "[", "label_ids", "]", "\n", "\n", "# Pad the inputs", "\n", "", "", "pad_tok_inputs", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "tokenized_inputs", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", "\n", ")", "\n", "\n", "# Pad the slot labels", "\n", "sequence_length", "=", "torch", ".", "tensor", "(", "pad_tok_inputs", "[", "\"input_ids\"", "]", ")", ".", "shape", "[", "1", "]", "\n", "padding_side", "=", "self", ".", "tokenizer", ".", "padding_side", "\n", "if", "padding_side", "==", "\"right\"", ":", "\n", "            ", "pad_tok_inputs", "[", "'slots_num'", "]", "=", "[", "\n", "list", "(", "label", ")", "+", "[", "-", "100", "]", "*", "(", "sequence_length", "-", "len", "(", "label", ")", ")", "for", "label", "in", "pad_tok_inputs", "[", "'slots_num'", "]", "\n", "]", "\n", "", "else", ":", "\n", "            ", "pad_tok_inputs", "[", "'slots_num'", "]", "=", "[", "\n", "[", "-", "100", "]", "*", "(", "sequence_length", "-", "len", "(", "label", ")", ")", "+", "list", "(", "label", ")", "for", "label", "in", "pad_tok_inputs", "[", "'slots_num'", "]", "\n", "]", "\n", "\n", "# Add in the intent labels", "\n", "", "pad_tok_inputs", "[", "\"intent_num\"", "]", "=", "[", "item", "[", "'intent_num'", "]", "for", "item", "in", "batch", "]", "\n", "\n", "# Convert to PyTorch tensors", "\n", "return", "{", "k", ":", "torch", ".", "tensor", "(", "v", ",", "dtype", "=", "torch", ".", "int64", ")", "for", "k", ",", "v", "in", "pad_tok_inputs", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.loaders.collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.__init__": [[52, 66], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ",", "model", ",", "t2t_args", ",", "padding", "=", "True", ",", "max_length", "=", "None", ",", "\n", "pad_to_multiple_of", "=", "None", ",", "label_pad_token_id", "=", "-", "100", ",", "return_tensors", "=", "'pt'", ")", ":", "\n", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "pad_to_multiple_of", "=", "pad_to_multiple_of", "\n", "self", ".", "label_pad_token_id", "=", "label_pad_token_id", "\n", "self", ".", "return_tensors", "=", "return_tensors", "\n", "\n", "self", ".", "t2t_args", "=", "t2t_args", "\n", "\n", "self", ".", "col_chk", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.loaders.collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.__call__": [[67, 182], ["enumerate", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.tokenizer", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.tokenizer", "range", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.tokenizer.pad", "convert_intent_slots_to_t2t", "labels.append", "logger.info", "logger.info", "logger.info", "convert_input_to_t2t", "len", "new_feat.append", "logger.info", "logger.info", "max", "hasattr", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.model.prepare_decoder_input_ids_from_labels", "isinstance", "len", "len", "numpy.concatenate().astype", "numpy.concatenate().astype", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.tokenizer.convert_ids_to_tokens", "collator_t2t_ic_sf.CollatorMASSIVET2TIntentClassSlotFill.tokenizer.convert_ids_to_tokens", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_intent_slots_to_t2t", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_input_to_t2t"], ["", "def", "__call__", "(", "self", ",", "batch", ",", "return_tensors", "=", "None", ")", ":", "\n", "# Get the t2t conversion utility", "\n", "        ", "from", "massive", ".", "utils", ".", "training_utils", "import", "convert_input_to_t2t", ",", "convert_intent_slots_to_t2t", "\n", "\n", "if", "return_tensors", "is", "None", ":", "\n", "            ", "return_tensors", "=", "self", ".", "return_tensors", "\n", "\n", "", "labels", "=", "[", "]", "\n", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "batch", ")", ":", "\n", "\n", "            ", "t2t_out", "=", "convert_intent_slots_to_t2t", "(", "\n", "entry", "[", "'utt'", "]", ",", "\n", "entry", "[", "'intent_str'", "]", ",", "\n", "entry", "[", "'slots_str'", "]", ",", "\n", "**", "self", ".", "t2t_args", "\n", ")", "\n", "\n", "labels", ".", "append", "(", "t2t_out", ")", "\n", "\n", "", "if", "self", ".", "col_chk", ":", "\n", "            ", "logger", ".", "info", "(", "f\"From Collator, labels before tokenization: {labels}\"", ")", "\n", "\n", "# Tokenize the labels", "\n", "", "tok_labels", "=", "self", ".", "tokenizer", "(", "labels", ",", "max_length", "=", "self", ".", "max_length", ",", "truncation", "=", "True", ")", "\n", "\n", "if", "self", ".", "col_chk", ":", "\n", "            ", "logger", ".", "info", "(", "f\"From Collator, example of tokenized label IDs: {tok_labels.input_ids}\"", ")", "\n", "logger", ".", "info", "(", "\"From Collator, example of tokenized labels: \"", "\n", "f\"{[self.tokenizer.convert_ids_to_tokens(item) for item in tok_labels.input_ids]}\"", ")", "\n", "", "labels", "=", "tok_labels", ".", "input_ids", "\n", "\n", "# Add input prompt if needed", "\n", "for", "item", "in", "batch", ":", "\n", "            ", "item", "[", "'utt'", "]", "=", "convert_input_to_t2t", "(", "item", "[", "'utt'", "]", ",", "**", "self", ".", "t2t_args", ")", "\n", "\n", "# tokenize the \"features\"", "\n", "", "features", "=", "self", ".", "tokenizer", "(", "\n", "[", "item", "[", "'utt'", "]", "for", "item", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "truncation", "=", "True", ",", "\n", "is_split_into_words", "=", "True", "\n", ")", "\n", "\n", "# convert to list of dictionaries", "\n", "new_feat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "features", "[", "'input_ids'", "]", ")", ")", ":", "\n", "            ", "new_feat", ".", "append", "(", "{", "\n", "'input_ids'", ":", "features", "[", "'input_ids'", "]", "[", "i", "]", ",", "\n", "'attention_mask'", ":", "features", "[", "'attention_mask'", "]", "[", "i", "]", ",", "\n", "'labels'", ":", "labels", "[", "i", "]", "\n", "}", ")", "\n", "", "features", "=", "new_feat", "\n", "\n", "if", "self", ".", "col_chk", ":", "\n", "            ", "logger", ".", "info", "(", "f\"From Collator, features after initial tokenization: {features}\"", ")", "\n", "logger", ".", "info", "(", "\"From Collator, features tokenized as tokens: \"", "\n", "f\"{[self.tokenizer.convert_ids_to_tokens(item['input_ids']) for item in features]}\"", ")", "\n", "\n", "# We have to pad the labels before calling `tokenizer.pad` as this method won't pad them", "\n", "# and needs them of the same length to return tensors.", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "            ", "max_label_length", "=", "max", "(", "len", "(", "l", ")", "for", "l", "in", "labels", ")", "\n", "if", "self", ".", "pad_to_multiple_of", "is", "not", "None", ":", "\n", "                ", "max_label_length", "=", "(", "\n", "(", "max_label_length", "+", "self", ".", "pad_to_multiple_of", "-", "1", ")", "\n", "//", "self", ".", "pad_to_multiple_of", "\n", "*", "self", ".", "pad_to_multiple_of", "\n", ")", "\n", "\n", "", "padding_side", "=", "self", ".", "tokenizer", ".", "padding_side", "\n", "for", "feature", "in", "features", ":", "\n", "                ", "remainder", "=", "[", "self", ".", "label_pad_token_id", "]", "*", "(", "max_label_length", "-", "len", "(", "feature", "[", "\"labels\"", "]", ")", ")", "\n", "if", "isinstance", "(", "feature", "[", "\"labels\"", "]", ",", "list", ")", ":", "\n", "                    ", "feature", "[", "\"labels\"", "]", "=", "(", "\n", "feature", "[", "\"labels\"", "]", "+", "remainder", "if", "padding_side", "==", "\"right\"", "else", "remainder", "+", "feature", "[", "\"labels\"", "]", "\n", ")", "\n", "", "elif", "padding_side", "==", "\"right\"", ":", "\n", "                    ", "feature", "[", "\"labels\"", "]", "=", "np", ".", "concatenate", "(", "\n", "[", "feature", "[", "\"labels\"", "]", ",", "remainder", "]", "\n", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "else", ":", "\n", "                    ", "feature", "[", "\"labels\"", "]", "=", "np", ".", "concatenate", "(", "\n", "[", "remainder", ",", "feature", "[", "\"labels\"", "]", "]", "\n", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "\n", "# add padding to everything besides the labels", "\n", "", "", "", "features", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "features", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", ")", "\n", "\n", "# prepare decoder_input_ids", "\n", "if", "(", "\n", "labels", "is", "not", "None", "\n", "and", "self", ".", "model", "is", "not", "None", "\n", "and", "hasattr", "(", "self", ".", "model", ",", "\"prepare_decoder_input_ids_from_labels\"", ")", "\n", ")", ":", "\n", "            ", "decoder_input_ids", "=", "self", ".", "model", ".", "prepare_decoder_input_ids_from_labels", "(", "\n", "labels", "=", "features", "[", "\"labels\"", "]", "\n", ")", "\n", "features", "[", "\"decoder_input_ids\"", "]", "=", "decoder_input_ids", "\n", "\n", "# Uncomment to log final features tensors", "\n", "#        if self.col_chk:", "\n", "#            logger.info(f\"From Collator, final features: {features}\")", "\n", "\n", "", "self", ".", "col_chk", "=", "False", "\n", "\n", "return", "features", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.XLMRIntentClassSlotFill.__init__": [[38, 83], ["transformers.RobertaPreTrainedModel.__init__", "len", "len", "transformers.XLMRobertaModel", "xlmr_ic_sf.IntentClassifier", "xlmr_ic_sf.SlotClassifier", "hasattr", "range", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "intent_label_dict", ",", "slot_label_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_intent_labels", "=", "len", "(", "intent_label_dict", ")", "\n", "self", ".", "num_slot_labels", "=", "len", "(", "slot_label_dict", ")", "\n", "\n", "# configure model to output all hidden states if not using last hidden layer", "\n", "# valid values for hidden_state_layer_for_class are 'last' or a layer number", "\n", "# note that layer count starts from 0, not 1", "\n", "self", ".", "hidden_layer_for_class", "=", "config", ".", "hidden_layer_for_class", "if", "hasattr", "(", "config", ",", "'hidden_layer_for_class'", ")", "else", "'last'", "\n", "if", "self", ".", "hidden_layer_for_class", "in", "range", "(", "config", ".", "num_hidden_layers", "-", "1", ")", ":", "\n", "            ", "config", ".", "output_hidden_states", "=", "True", "\n", "\n", "", "self", ".", "xlmr", "=", "XLMRobertaModel", "(", "config", "=", "config", ")", "# Load pretrained XLM-R", "\n", "\n", "# set defaults if not defined by user", "\n", "layer_dim", "=", "config", ".", "head_layer_dim", "if", "hasattr", "(", "config", ",", "'head_layer_dim'", ")", "else", "None", "\n", "num_layers", "=", "config", ".", "head_num_layers", "if", "hasattr", "(", "config", ",", "'head_num_layers'", ")", "else", "1", "\n", "activation", "=", "config", ".", "head_activation", "if", "hasattr", "(", "config", ",", "'head_activation'", ")", "else", "'gelu'", "\n", "dropout", "=", "config", ".", "head_dropout_rate", "if", "hasattr", "(", "config", ",", "'head_dropout_rate'", ")", "else", "config", ".", "hidden_dropout_prob", "\n", "pooling", "=", "config", ".", "head_intent_pooling", "if", "hasattr", "(", "config", ",", "'head_intent_pooling'", ")", "else", "'first'", "\n", "\n", "# Instantiate the heads", "\n", "self", ".", "intent_classifier", "=", "IntentClassifier", "(", "\n", "input_dim", "=", "config", ".", "hidden_size", ",", "\n", "num_intent_labels", "=", "self", ".", "num_intent_labels", ",", "\n", "layer_dim", "=", "layer_dim", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout_rate", "=", "dropout", ",", "\n", "activation", "=", "activation", ",", "\n", "pooling", "=", "pooling", "\n", ")", "\n", "self", ".", "slot_classifier", "=", "SlotClassifier", "(", "\n", "input_dim", "=", "config", ".", "hidden_size", ",", "\n", "num_slot_labels", "=", "self", ".", "num_slot_labels", ",", "\n", "layer_dim", "=", "layer_dim", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "activation", "=", "activation", ",", "\n", "dropout_rate", "=", "dropout", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.XLMRIntentClassSlotFill.forward": [[85, 135], ["xlmr_ic_sf.XLMRIntentClassSlotFill.xlmr", "xlmr_ic_sf.XLMRIntentClassSlotFill.intent_classifier", "xlmr_ic_sf.XLMRIntentClassSlotFill.slot_classifier", "range", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "xlmr_ic_sf.XLMRIntentClassSlotFill.view", "intent_num.view", "xlmr_ic_sf.XLMRIntentClassSlotFill.view", "intent_num.view", "attention_mask.view", "xlmr_ic_sf.XLMRIntentClassSlotFill.view", "slots_num.view", "xlmr_ic_sf.XLMRIntentClassSlotFill.view", "slots_num.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "intent_num", ",", "slots_num", ",", "token_type_ids", "=", "None", ")", ":", "\n", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "        ", "outputs", "=", "self", ".", "xlmr", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ")", "\n", "\n", "# Choose the right layer for the hidden states", "\n", "if", "self", ".", "hidden_layer_for_class", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", "-", "1", ")", ":", "\n", "            ", "hidden_states", "=", "outputs", "[", "2", "]", "\n", "attention_hidden_states", "=", "hidden_states", "[", "1", ":", "]", "# skip embedding outputs", "\n", "sequence_output", "=", "attention_hidden_states", "[", "self", ".", "hidden_layer_for_class", "]", "\n", "", "else", ":", "\n", "            ", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "", "intent_logits", "=", "self", ".", "intent_classifier", "(", "sequence_output", ",", "attention_mask", ")", "\n", "slot_logits", "=", "self", ".", "slot_classifier", "(", "sequence_output", ")", "\n", "\n", "total_loss", "=", "0", "\n", "\n", "# Intent Softmax", "\n", "if", "intent_num", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_intent_labels", "==", "1", ":", "\n", "                ", "intent_loss_fct", "=", "nn", ".", "MSELoss", "(", ")", "\n", "intent_loss", "=", "intent_loss_fct", "(", "intent_logits", ".", "view", "(", "-", "1", ")", ",", "intent_num", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "intent_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "intent_loss", "=", "intent_loss_fct", "(", "\n", "intent_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_intent_labels", ")", ",", "intent_num", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "", "total_loss", "+=", "intent_loss", "\n", "\n", "# Slot Softmax", "\n", "", "if", "slots_num", "is", "not", "None", ":", "\n", "            ", "slot_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "slot_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_slot_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "slots_num", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "slot_loss", "=", "slot_loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "slot_loss", "=", "slot_loss_fct", "(", "\n", "slot_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_slot_labels", ")", ",", "slots_num", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "", "total_loss", "+=", "self", ".", "config", ".", "slot_loss_coef", "*", "slot_loss", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", "(", "intent_logits", ",", "slot_logits", ")", ")", "\n", "\n", "# (loss), logits, (hidden_states), (attentions)", "\n", "# Logits is a tuple of intent and slot logits", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.IntentClassifier.__init__": [[138, 167], ["torch.nn.Module.__init__", "ic_head.append", "ic_head.append", "torch.nn.Sequential", "range", "torch.nn.Dropout", "torch.nn.Linear", "ic_head.append", "ic_head.append", "torch.nn.Dropout", "torch.nn.Linear", "ic_head.append", "torch.nn.GELU", "ic_head.append", "torch.nn.ELU", "ic_head.append", "NotImplementedError", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_intent_labels", ",", "layer_dim", "=", "None", ",", "num_layers", "=", "1", ",", "\n", "activation", "=", "'gelu'", ",", "dropout_rate", "=", "0.", ",", "pooling", "=", "'first'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer_dim", "=", "layer_dim", "if", "layer_dim", "else", "input_dim", "\n", "self", ".", "pooling", "=", "pooling", "\n", "ic_head", "=", "[", "]", "\n", "\n", "# Create the intermediate layers", "\n", "if", "num_layers", ">", "0", ":", "\n", "            ", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "ic_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "ic_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "layer_dim", ")", ")", "\n", "input_dim", "=", "layer_dim", "\n", "\n", "if", "activation", "==", "'gelu'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "GELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "ELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "f\"Activation {activation} is not implemented\"", ")", "\n", "\n", "# Final layer, condensed to number of intent labels", "\n", "", "", "", "ic_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "ic_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "num_intent_labels", ")", ")", "\n", "\n", "self", ".", "ic_head", "=", "nn", ".", "Sequential", "(", "*", "ic_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.IntentClassifier.forward": [[168, 185], ["xlmr_ic_sf.IntentClassifier.ic_head", "attention_mask.unsqueeze().expand().float", "torch.max", "attention_mask.unsqueeze().expand().float", "NotImplementedError", "attention_mask.unsqueeze().expand", "torch.sum", "torch.clamp", "inp.size", "attention_mask.unsqueeze().expand", "attention_mask.unsqueeze().expand().float.sum", "attention_mask.unsqueeze", "inp.size", "attention_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ",", "attention_mask", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooling", "==", "'first'", ":", "\n", "# Get hidden states from first token in seq", "\n", "            ", "inp", "=", "inp", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "pooling", "==", "'max'", ":", "\n", "            ", "mask_expand", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "inp", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "inp", "[", "mask_expand", "==", "0", "]", "=", "-", "1e9", "# set padding to large negative", "\n", "inp", "=", "torch", ".", "max", "(", "inp", ",", "1", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "pooling", "==", "'mean'", ":", "\n", "# see: https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens", "\n", "            ", "mask_expand", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "inp", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "inp", "=", "torch", ".", "sum", "(", "inp", "*", "mask_expand", ",", "1", ")", "/", "torch", ".", "clamp", "(", "mask_expand", ".", "sum", "(", "1", ")", ",", "min", "=", "1e-9", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Pooling type {self.pooling} not implemented\"", ")", "\n", "\n", "", "return", "self", ".", "ic_head", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.SlotClassifier.__init__": [[188, 216], ["torch.nn.Module.__init__", "sf_head.append", "sf_head.append", "torch.nn.Sequential", "range", "torch.nn.Dropout", "torch.nn.Linear", "sf_head.append", "sf_head.append", "torch.nn.Dropout", "torch.nn.Linear", "sf_head.append", "torch.nn.GELU", "sf_head.append", "torch.nn.ELU", "sf_head.append", "NotImplementedError", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_slot_labels", ",", "layer_dim", "=", "None", ",", "num_layers", "=", "1", ",", "\n", "activation", "=", "'gelu'", ",", "dropout_rate", "=", "0.", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer_dim", "=", "layer_dim", "if", "layer_dim", "else", "input_dim", "\n", "sf_head", "=", "[", "]", "\n", "\n", "# Create the intermediate layers", "\n", "if", "num_layers", ">", "0", ":", "\n", "            ", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "sf_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "sf_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "layer_dim", ")", ")", "\n", "input_dim", "=", "layer_dim", "\n", "\n", "if", "activation", "==", "'gelu'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "GELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "ELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "f\"Activation {activation} is not implemented\"", ")", "\n", "\n", "# Final layer, condensed to number of intent labels", "\n", "", "", "", "sf_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "sf_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "num_slot_labels", ")", ")", "\n", "\n", "self", ".", "sf_head", "=", "nn", ".", "Sequential", "(", "*", "sf_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.xlmr_ic_sf.SlotClassifier.forward": [[217, 219], ["xlmr_ic_sf.SlotClassifier.sf_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "sf_head", "(", "inp", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.__init__": [[38, 84], ["transformers.T5PreTrainedModel.__init__", "len", "len", "transformers.MT5EncoderModel", "mt5_ic_sf_encoder_only.IntentClassifier", "mt5_ic_sf_encoder_only.SlotClassifier", "hasattr", "range", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "intent_label_dict", ",", "slot_label_dict", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "model_parallel", "=", "False", "\n", "self", ".", "num_intent_labels", "=", "len", "(", "intent_label_dict", ")", "\n", "self", ".", "num_slot_labels", "=", "len", "(", "slot_label_dict", ")", "\n", "\n", "# configure model to output all hidden states if not using last hidden layer", "\n", "# valid values for hidden_state_layer_for_class are 'last' or a layer number", "\n", "# note that layer count starts from 0, not 1", "\n", "self", ".", "hidden_layer_for_class", "=", "config", ".", "hidden_layer_for_class", "if", "hasattr", "(", "config", ",", "'hidden_layer_for_class'", ")", "else", "'last'", "\n", "if", "self", ".", "hidden_layer_for_class", "in", "range", "(", "config", ".", "num_hidden_layers", "-", "1", ")", ":", "\n", "            ", "config", ".", "output_hidden_states", "=", "True", "\n", "\n", "", "self", ".", "mt5", "=", "MT5EncoderModel", "(", "config", "=", "config", ")", "# Load pretrained mt5 encoder", "\n", "\n", "# set defaults if not defined by user", "\n", "layer_dim", "=", "config", ".", "head_layer_dim", "if", "hasattr", "(", "config", ",", "'head_layer_dim'", ")", "else", "None", "\n", "num_layers", "=", "config", ".", "head_num_layers", "if", "hasattr", "(", "config", ",", "'head_num_layers'", ")", "else", "1", "\n", "activation", "=", "config", ".", "head_activation", "if", "hasattr", "(", "config", ",", "'head_activation'", ")", "else", "'gelu'", "\n", "dropout", "=", "config", ".", "head_dropout_rate", "if", "hasattr", "(", "config", ",", "'head_dropout_rate'", ")", "else", "config", ".", "hidden_dropout_prob", "\n", "pooling", "=", "config", ".", "head_intent_pooling", "if", "hasattr", "(", "config", ",", "'head_intent_pooling'", ")", "else", "'first'", "\n", "\n", "# Instantiate the heads", "\n", "self", ".", "intent_classifier", "=", "IntentClassifier", "(", "\n", "input_dim", "=", "config", ".", "d_model", ",", "\n", "num_intent_labels", "=", "self", ".", "num_intent_labels", ",", "\n", "layer_dim", "=", "layer_dim", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout_rate", "=", "dropout", ",", "\n", "activation", "=", "activation", ",", "\n", "pooling", "=", "config", ".", "head_intent_pooling", "\n", ")", "\n", "self", ".", "slot_classifier", "=", "SlotClassifier", "(", "\n", "input_dim", "=", "config", ".", "d_model", ",", "\n", "num_slot_labels", "=", "self", ".", "num_slot_labels", ",", "\n", "layer_dim", "=", "layer_dim", ",", "\n", "num_layers", "=", "config", ".", "head_num_layers", ",", "\n", "activation", "=", "activation", ",", "\n", "dropout_rate", "=", "dropout", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.forward": [[86, 135], ["mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.mt5", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.intent_classifier", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.slot_classifier", "range", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.view", "intent_num.view", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.view", "intent_num.view", "attention_mask.view", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.view", "slots_num.view", "mt5_ic_sf_encoder_only.MT5IntentClassSlotFillEncoderOnly.view", "slots_num.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "intent_num", ",", "slots_num", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "mt5", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "# Choose the right layer for the hidden states", "\n", "if", "self", ".", "hidden_layer_for_class", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", "-", "1", ")", ":", "\n", "            ", "hidden_states", "=", "outputs", "[", "1", "]", "\n", "attention_hidden_states", "=", "hidden_states", "[", "1", ":", "]", "# skip embedding outputs", "\n", "sequence_output", "=", "attention_hidden_states", "[", "self", ".", "hidden_layer_for_class", "]", "\n", "", "else", ":", "\n", "            ", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "", "intent_logits", "=", "self", ".", "intent_classifier", "(", "sequence_output", ",", "attention_mask", ")", "\n", "slot_logits", "=", "self", ".", "slot_classifier", "(", "sequence_output", ")", "\n", "\n", "total_loss", "=", "0", "\n", "\n", "# Intent Softmax", "\n", "if", "intent_num", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_intent_labels", "==", "1", ":", "\n", "                ", "intent_loss_fct", "=", "nn", ".", "MSELoss", "(", ")", "\n", "intent_loss", "=", "intent_loss_fct", "(", "intent_logits", ".", "view", "(", "-", "1", ")", ",", "intent_num", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "intent_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "intent_loss", "=", "intent_loss_fct", "(", "\n", "intent_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_intent_labels", ")", ",", "intent_num", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "", "total_loss", "+=", "intent_loss", "\n", "\n", "# Slot Softmax", "\n", "", "if", "slots_num", "is", "not", "None", ":", "\n", "            ", "slot_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "slot_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_slot_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "slots_num", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "slot_loss", "=", "slot_loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "slot_loss", "=", "slot_loss_fct", "(", "\n", "slot_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_slot_labels", ")", ",", "slots_num", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "", "total_loss", "+=", "self", ".", "config", ".", "slot_loss_coef", "*", "slot_loss", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", "(", "intent_logits", ",", "slot_logits", ")", ")", "\n", "\n", "# (loss), logits, (hidden_states), (attentions)", "\n", "# Logits is a tuple of intent and slot logits", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.IntentClassifier.__init__": [[138, 167], ["torch.nn.Module.__init__", "ic_head.append", "ic_head.append", "torch.nn.Sequential", "range", "torch.nn.Dropout", "torch.nn.Linear", "ic_head.append", "ic_head.append", "torch.nn.Dropout", "torch.nn.Linear", "ic_head.append", "torch.nn.GELU", "ic_head.append", "torch.nn.ELU", "ic_head.append", "NotImplementedError", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_intent_labels", ",", "layer_dim", "=", "None", ",", "num_layers", "=", "1", ",", "\n", "activation", "=", "'gelu'", ",", "dropout_rate", "=", "0.", ",", "pooling", "=", "'first'", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer_dim", "=", "layer_dim", "if", "layer_dim", "else", "input_dim", "\n", "self", ".", "pooling", "=", "pooling", "\n", "ic_head", "=", "[", "]", "\n", "\n", "# Create the intermediate layers", "\n", "if", "num_layers", ">", "0", ":", "\n", "            ", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "ic_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "ic_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "layer_dim", ")", ")", "\n", "input_dim", "=", "layer_dim", "\n", "\n", "if", "activation", "==", "'gelu'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "GELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "ELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "                    ", "ic_head", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "f\"Activation {activation} is not implemented\"", ")", "\n", "\n", "# Final layer, condensed to number of intent labels", "\n", "", "", "", "ic_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "ic_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "num_intent_labels", ")", ")", "\n", "\n", "self", ".", "ic_head", "=", "nn", ".", "Sequential", "(", "*", "ic_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.IntentClassifier.forward": [[168, 185], ["mt5_ic_sf_encoder_only.IntentClassifier.ic_head", "attention_mask.unsqueeze().expand().float", "torch.max", "attention_mask.unsqueeze().expand().float", "NotImplementedError", "attention_mask.unsqueeze().expand", "torch.sum", "torch.clamp", "inp.size", "attention_mask.unsqueeze().expand", "attention_mask.unsqueeze().expand().float.sum", "attention_mask.unsqueeze", "inp.size", "attention_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ",", "attention_mask", ")", ":", "\n", "\n", "        ", "if", "self", ".", "pooling", "==", "'first'", ":", "\n", "# Get hidden states from first token in seq", "\n", "            ", "inp", "=", "inp", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "pooling", "==", "'max'", ":", "\n", "            ", "mask_expand", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "inp", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "inp", "[", "mask_expand", "==", "0", "]", "=", "-", "1e9", "# set padding to large negative", "\n", "inp", "=", "torch", ".", "max", "(", "inp", ",", "1", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "pooling", "==", "'mean'", ":", "\n", "# see: https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens", "\n", "            ", "mask_expand", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "inp", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "inp", "=", "torch", ".", "sum", "(", "inp", "*", "mask_expand", ",", "1", ")", "/", "torch", ".", "clamp", "(", "mask_expand", ".", "sum", "(", "1", ")", ",", "min", "=", "1e-9", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Pooling type {self.pooling} not implemented\"", ")", "\n", "\n", "", "return", "self", ".", "ic_head", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.SlotClassifier.__init__": [[188, 216], ["torch.nn.Module.__init__", "sf_head.append", "sf_head.append", "torch.nn.Sequential", "range", "torch.nn.Dropout", "torch.nn.Linear", "sf_head.append", "sf_head.append", "torch.nn.Dropout", "torch.nn.Linear", "sf_head.append", "torch.nn.GELU", "sf_head.append", "torch.nn.ELU", "sf_head.append", "NotImplementedError", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_slot_labels", ",", "layer_dim", "=", "None", ",", "num_layers", "=", "1", ",", "\n", "activation", "=", "'gelu'", ",", "dropout_rate", "=", "0.", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "layer_dim", "=", "layer_dim", "if", "layer_dim", "else", "input_dim", "\n", "sf_head", "=", "[", "]", "\n", "\n", "# Create the intermediate layers", "\n", "if", "num_layers", ">", "0", ":", "\n", "            ", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "                ", "sf_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "sf_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "layer_dim", ")", ")", "\n", "input_dim", "=", "layer_dim", "\n", "\n", "if", "activation", "==", "'gelu'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "GELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "ELU", "(", ")", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "                    ", "sf_head", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "f\"Activation {activation} is not implemented\"", ")", "\n", "\n", "# Final layer, condensed to number of intent labels", "\n", "", "", "", "sf_head", ".", "append", "(", "nn", ".", "Dropout", "(", "dropout_rate", ")", ")", "\n", "sf_head", ".", "append", "(", "nn", ".", "Linear", "(", "input_dim", ",", "num_slot_labels", ")", ")", "\n", "\n", "self", ".", "sf_head", "=", "nn", ".", "Sequential", "(", "*", "sf_head", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.models.mt5_ic_sf_encoder_only.SlotClassifier.forward": [[217, 219], ["mt5_ic_sf_encoder_only.SlotClassifier.sf_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "return", "self", ".", "sf_head", "(", "inp", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.test.test_t2t.test_convert_intent_slots_to_t2t": [[149, 180], ["pytest.mark.parametrize", "massive.utils.training_utils.convert_intent_slots_to_t2t"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_intent_slots_to_t2t"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"utt, intent, slots, use_output_descrip, intent_first, slots_mixed, toks_in_output, sentinels,\"", "\n", "\" inside_format, output\"", ",", "\n", "output_tests", "\n", ")", "\n", "def", "test_convert_intent_slots_to_t2t", "(", "\n", "utt", ",", "\n", "intent", ",", "\n", "slots", ",", "\n", "use_output_descrip", ",", "\n", "intent_first", ",", "\n", "slots_mixed", ",", "\n", "toks_in_output", ",", "\n", "sentinels", ",", "\n", "inside_format", ",", "\n", "output", "\n", ")", ":", "\n", "\n", "    ", "out", "=", "convert_intent_slots_to_t2t", "(", "\n", "utt", ",", "\n", "intent", ",", "\n", "slots", ",", "\n", "use_output_descrip", ",", "\n", "intent_first", ",", "\n", "slots_mixed", ",", "\n", "toks_in_output", ",", "\n", "sentinels", ",", "\n", "inside_format", ",", "\n", ")", "\n", "\n", "assert", "out", "==", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.test.test_t2t.test_convert_t2t_batch_to_intents_slots": [[182, 213], ["pytest.mark.parametrize", "massive.utils.training_utils.convert_t2t_batch_to_intents_slots"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_t2t_batch_to_intents_slots"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"utt, intent, slots, use_output_descrip, intent_first, slots_mixed, toks_in_output, sentinels,\"", "\n", "\" inside_format, inp\"", ",", "\n", "output_tests", "\n", ")", "\n", "def", "test_convert_t2t_batch_to_intents_slots", "(", "\n", "utt", ",", "\n", "intent", ",", "\n", "slots", ",", "\n", "use_output_descrip", ",", "\n", "intent_first", ",", "\n", "slots_mixed", ",", "\n", "toks_in_output", ",", "\n", "sentinels", ",", "\n", "inside_format", ",", "\n", "inp", "\n", ")", ":", "\n", "\n", "    ", "inp", "=", "[", "inp", "]", "\n", "conv_intents", ",", "conv_slots", "=", "convert_t2t_batch_to_intents_slots", "(", "\n", "inp", ",", "\n", "use_output_descrip", ",", "\n", "intent_first", ",", "\n", "slots_mixed", ",", "\n", "toks_in_output", ",", "\n", "sentinels", ",", "\n", "inside_format", "\n", ")", "\n", "\n", "assert", "conv_intents", "==", "[", "intent", "]", "\n", "assert", "conv_slots", "==", "[", "slots", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.test.test_t2t.test_convert_input_to_t2t": [[228, 235], ["pytest.mark.parametrize", "massive.utils.training_utils.convert_input_to_t2t"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_input_to_t2t"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"utt, input_prompt, sentinels, conv_utt\"", ",", "\n", "input_tests", "\n", ")", "\n", "def", "test_convert_input_to_t2t", "(", "utt", ",", "input_prompt", ",", "sentinels", ",", "conv_utt", ")", ":", "\n", "    ", "out", "=", "convert_input_to_t2t", "(", "utt", ",", "input_prompt", ",", "sentinels", ")", "\n", "assert", "out", "==", "conv_utt", "\n", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.test.test_eval_metrics.test_eval_preds": [[158, 180], ["pytest.mark.parametrize", "massive.utils.training_utils.eval_preds", "round", "round"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.eval_preds"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "'pred_intents, lab_intents, pred_slots, lab_slots, labels_ignore, labels_merge, eval_metrics, '", "\n", "'out'", ",", "\n", "cases", "\n", ")", "\n", "def", "test_eval_preds", "(", "\n", "pred_intents", ",", "lab_intents", ",", "pred_slots", ",", "lab_slots", ",", "labels_ignore", ",", "labels_merge", ",", "eval_metrics", ",", "out", "\n", ")", ":", "\n", "\n", "    ", "results", "=", "eval_preds", "(", "\n", "pred_intents", "=", "pred_intents", ",", "\n", "lab_intents", "=", "lab_intents", ",", "\n", "pred_slots", "=", "pred_slots", ",", "\n", "lab_slots", "=", "lab_slots", ",", "\n", "labels_ignore", "=", "labels_ignore", ",", "\n", "labels_merge", "=", "labels_merge", ",", "\n", "eval_metrics", "=", "eval_metrics", "\n", ")", "\n", "\n", "for", "key", "in", "out", ":", "\n", "        ", "assert", "key", "in", "results", "\n", "assert", "round", "(", "out", "[", "key", "]", ",", "2", ")", "==", "round", "(", "results", "[", "key", "]", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.test.test_eval_metrics.test_convert_to_bio": [[203, 206], ["pytest.mark.parametrize", "massive.utils.training_utils.convert_to_bio"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.convert_to_bio"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "'seq_tags, outside, labels_merge, out'", ",", "bio_cases", ")", "\n", "def", "test_convert_to_bio", "(", "seq_tags", ",", "outside", ",", "labels_merge", ",", "out", ")", ":", "\n", "    ", "assert", "convert_to_bio", "(", "seq_tags", ",", "outside", ",", "labels_merge", ")", "==", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.alexa_massive.scripts.train.main": [[40, 100], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "massive.read_conf", "massive.MASSIVETrainingArguments", "logging.basicConfig", "massive.MASSIVETrainingArguments.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "logger.info", "ruamel.yaml.YAML", "logger.info", "massive.init_tokenizer", "massive.prepare_train_dev_datasets", "massive.init_model", "massive.prepare_collator", "massive.read_conf.get", "massive.read_conf.get", "massive.create_compute_metrics", "trainer_cls", "trainer_cls.train", "int", "os.getenv", "massive.read_conf.get", "int", "massive.read_conf.get", "logging.StreamHandler", "datetime.datetime.now", "ruamel.yaml.YAML.load", "open"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.read_conf", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_tokenizer", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_train_dev_datasets", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_model", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_collator", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.create_compute_metrics", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\" Run Training \"\"\"", "\n", "# parse the args", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Training on the MASSIVE dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--config'", ",", "help", "=", "'path to run configuration yaml'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "help", "=", "'local rank of this process. Optional'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# create the massive.Configuration master config object", "\n", "conf", "=", "read_conf", "(", "args", ".", "config", ")", "\n", "trainer_args", "=", "MASSIVETrainingArguments", "(", "**", "conf", ".", "get", "(", "'train_val.trainer_args'", ")", ")", "\n", "if", "args", ".", "local_rank", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "args", ".", "local_rank", ")", "\n", "", "elif", "os", ".", "getenv", "(", "'LOCAL_RANK'", ")", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "#format=\"[%(levelname)s|%(name)s] %(asctime)s >> %(message)s\",", "\n", "format", "=", "\"[%(levelname)s] %(asctime)s >> %(message)s\"", ",", "\n", "#datefmt=\"%Y%m%d %H:%M\",", "\n", "datefmt", "=", "\"%H:%M\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "log_level", "=", "trainer_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "logger", ".", "info", "(", "f\"Starting the run at {datetime.datetime.now()}\"", ")", "\n", "yaml", "=", "YAML", "(", "typ", "=", "'safe'", ")", "\n", "logger", ".", "info", "(", "f\"Using the following config: {yaml.load(open(args.config, 'r'))}\"", ")", "\n", "\n", "# Get all inputs to the trainer", "\n", "tokenizer", "=", "init_tokenizer", "(", "conf", ")", "\n", "train_ds", ",", "dev_ds", ",", "intents", ",", "slots", "=", "prepare_train_dev_datasets", "(", "conf", ",", "tokenizer", ")", "\n", "model", "=", "init_model", "(", "conf", ",", "intents", ",", "slots", ")", "\n", "collator", "=", "prepare_collator", "(", "conf", ",", "tokenizer", ",", "model", ")", "\n", "slots_ignore", "=", "conf", ".", "get", "(", "'train_val.slot_labels_ignore'", ",", "default", "=", "[", "]", ")", "\n", "metrics", "=", "conf", ".", "get", "(", "'train_val.eval_metrics'", ",", "default", "=", "'all'", ")", "\n", "compute_metrics", "=", "create_compute_metrics", "(", "intents", ",", "slots", ",", "conf", ",", "tokenizer", ",", "slots_ignore", ",", "\n", "metrics", ")", "\n", "\n", "\n", "# Get the right trainer", "\n", "trainer_cls", "=", "MASSIVESeq2SeqTrainer", "if", "conf", ".", "get", "(", "'train_val.trainer'", ")", "==", "'massive s2s'", "else", "MASSIVETrainer", "\n", "\n", "trainer", "=", "trainer_cls", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "trainer_args", ",", "\n", "train_dataset", "=", "train_ds", ",", "\n", "eval_dataset", "=", "dev_ds", ",", "\n", "data_collator", "=", "collator", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", "\n", ")", "\n", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.test.main": [[44, 129], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "massive.read_conf", "massive.MASSIVETrainingArguments", "logging.basicConfig", "massive.MASSIVETrainingArguments.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "logger.info", "ruamel.yaml.YAML", "logger.info", "massive.init_tokenizer", "massive.prepare_test_dataset", "massive.init_model", "massive.prepare_collator", "massive.read_conf.get", "massive.read_conf.get", "massive.create_compute_metrics", "trainer_cls", "trainer_cls.remove_callback", "trainer_cls.predict", "int", "os.getenv", "massive.read_conf.get", "logger.warning", "massive.read_conf.get", "NotImplementedError", "torch.is_initialized", "torch.get_rank", "time.sleep", "logger.info", "logger.info", "logger.info", "pprint.PrettyPrinter", "pprint.PrettyPrinter.pprint", "massive.output_predictions", "massive.read_conf.get", "int", "massive.read_conf.get", "massive.read_conf.get", "massive.read_conf.get", "logging.StreamHandler", "datetime.datetime.now", "ruamel.yaml.YAML.load", "open"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.read_conf", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_tokenizer", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_test_dataset", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_model", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_collator", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.create_compute_metrics", "home.repos.pwc.inspect_result.alexa_massive.utils.trainer.MASSIVESeq2SeqTrainer.predict", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.output_predictions", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\" Run Testing/Inference \"\"\"", "\n", "# parse the args", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Testing on the MASSIVE dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--config'", ",", "help", "=", "'path to run configuration yaml'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "help", "=", "'local rank of this process. Optional'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# create the massive.Configuration master config object", "\n", "conf", "=", "read_conf", "(", "args", ".", "config", ")", "\n", "trainer_args", "=", "MASSIVETrainingArguments", "(", "**", "conf", ".", "get", "(", "'test.trainer_args'", ")", ")", "\n", "if", "args", ".", "local_rank", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "args", ".", "local_rank", ")", "\n", "", "elif", "os", ".", "getenv", "(", "'LOCAL_RANK'", ")", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "#format=\"[%(levelname)s|%(name)s] %(asctime)s >> %(message)s\",", "\n", "format", "=", "\"[%(levelname)s] %(asctime)s >> %(message)s\"", ",", "\n", "#datefmt=\"%Y%m%d %H:%M\",", "\n", "datefmt", "=", "\"%H:%M\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "log_level", "=", "trainer_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "logger", ".", "info", "(", "f\"Starting the run at {datetime.datetime.now()}\"", ")", "\n", "yaml", "=", "YAML", "(", "typ", "=", "'safe'", ")", "\n", "logger", ".", "info", "(", "f\"Using the following config: {yaml.load(open(args.config, 'r'))}\"", ")", "\n", "\n", "# Check for right setup", "\n", "if", "not", "conf", ".", "get", "(", "'test.predictions_file'", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\"Outputs will not be saved because no test.predictions_file was given\"", ")", "\n", "", "if", "conf", ".", "get", "(", "'test.predictions_file'", ")", "and", "(", "conf", ".", "get", "(", "'test.trainer_args.locale_eval_strategy'", ")", "!=", "'all only'", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must use 'all only' as the locale_eval_strategy if you\"", "\n", "\" include a predictions file\"", ")", "\n", "\n", "\n", "# Get all inputs to the trainer", "\n", "", "tokenizer", "=", "init_tokenizer", "(", "conf", ")", "\n", "test_ds", ",", "intents", ",", "slots", "=", "prepare_test_dataset", "(", "conf", ",", "tokenizer", ")", "\n", "model", "=", "init_model", "(", "conf", ",", "intents", ",", "slots", ")", "\n", "collator", "=", "prepare_collator", "(", "conf", ",", "tokenizer", ",", "model", ")", "\n", "slots_ignore", "=", "conf", ".", "get", "(", "'test.slot_labels_ignore'", ",", "default", "=", "[", "]", ")", "\n", "metrics", "=", "conf", ".", "get", "(", "'test.eval_metrics'", ",", "default", "=", "'all'", ")", "\n", "compute_metrics", "=", "create_compute_metrics", "(", "intents", ",", "slots", ",", "conf", ",", "tokenizer", ",", "slots_ignore", ",", "\n", "metrics", ")", "\n", "\n", "# Get the right trainer", "\n", "trainer_cls", "=", "MASSIVESeq2SeqTrainer", "if", "conf", ".", "get", "(", "'test.trainer'", ")", "==", "'massive s2s'", "else", "MASSIVETrainer", "\n", "\n", "trainer", "=", "trainer_cls", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "trainer_args", ",", "\n", "data_collator", "=", "collator", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", "\n", ")", "\n", "\n", "trainer", ".", "remove_callback", "(", "transformers", ".", "integrations", ".", "TensorBoardCallback", ")", "\n", "\n", "outputs", "=", "trainer", ".", "predict", "(", "test_ds", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "rank", "=", "dist", ".", "get_rank", "(", ")", "if", "dist", ".", "is_initialized", "(", ")", "else", "0", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "time", ".", "sleep", "(", "3", ")", "\n", "logger", ".", "info", "(", "'CAUTION: Test with validation engine metrics are for reference only. For '", "\n", "'\"official\" metrics include a test.predictions_file in the config and use the '", "\n", "'eval.ai leaderboard'", ")", "\n", "logger", ".", "info", "(", "f'Validation engine metrics computer readable: {outputs.metrics}'", ")", "\n", "logger", ".", "info", "(", "'Validation engine metrics pretty printed: '", ")", "\n", "pp", "=", "pprint", ".", "PrettyPrinter", "(", "indent", "=", "2", ")", "\n", "pp", ".", "pprint", "(", "outputs", ".", "metrics", ")", "\n", "\n", "save_to_file", "=", "True", "if", "conf", ".", "get", "(", "'test.predictions_file'", ")", "else", "False", "\n", "\n", "output_predictions", "(", "outputs", ",", "intents", ",", "slots", ",", "conf", ",", "tokenizer", ",", "\n", "remove_slots", "=", "slots_ignore", ",", "save_to_file", "=", "save_to_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.hpo.main": [[41, 104], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "massive.read_conf", "massive.MASSIVETrainingArguments", "logging.basicConfig", "massive.MASSIVETrainingArguments.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "logger.info", "ruamel.yaml.YAML", "logger.info", "massive.init_tokenizer", "massive.prepare_train_dev_datasets", "massive.prepare_collator", "massive.init_model", "massive.read_conf.get", "massive.read_conf.get", "massive.create_compute_metrics", "trainer_cls", "massive.prepare_hp_search_args", "trainer_cls.hyperparameter_search", "logger.info", "logger.info", "int", "os.getenv", "massive.read_conf.get", "int", "massive.read_conf.get", "logging.StreamHandler", "datetime.datetime.now", "ruamel.yaml.YAML.load", "open"], "function", ["home.repos.pwc.inspect_result.alexa_massive.utils.configuration.read_conf", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_tokenizer", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_train_dev_datasets", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.prepare_collator", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.init_model", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.training_utils.create_compute_metrics", "home.repos.pwc.inspect_result.alexa_massive.utils.hpo_utils.prepare_hp_search_args", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get", "home.repos.pwc.inspect_result.alexa_massive.utils.configuration.Configuration.get"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\" Run hyperparameter tuning \"\"\"", "\n", "# parse the args", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Training on the MASSIVE dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'-c'", ",", "'--config'", ",", "help", "=", "'path to run configuration yaml'", ")", "\n", "parser", ".", "add_argument", "(", "'--local_rank'", ",", "help", "=", "'local rank of this process. Optional'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# create the massive.Configuration master config object", "\n", "conf", "=", "read_conf", "(", "args", ".", "config", ")", "\n", "trainer_args", "=", "MASSIVETrainingArguments", "(", "**", "conf", ".", "get", "(", "'train_val.trainer_args'", ")", ")", "\n", "if", "args", ".", "local_rank", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "args", ".", "local_rank", ")", "\n", "", "elif", "os", ".", "getenv", "(", "'LOCAL_RANK'", ")", ":", "\n", "        ", "trainer_args", ".", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "#format=\"[%(levelname)s|%(name)s] %(asctime)s >> %(message)s\",", "\n", "format", "=", "\"[%(levelname)s] %(asctime)s >> %(message)s\"", ",", "\n", "#datefmt=\"%Y%m%d %H:%M\",", "\n", "datefmt", "=", "\"%H:%M\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "log_level", "=", "trainer_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "logger", ".", "info", "(", "f\"Starting the run at {datetime.datetime.now()}\"", ")", "\n", "yaml", "=", "YAML", "(", "typ", "=", "'safe'", ")", "\n", "logger", ".", "info", "(", "f\"Using the following config: {yaml.load(open(args.config, 'r'))}\"", ")", "\n", "\n", "# Get all inputs to the trainer", "\n", "tokenizer", "=", "init_tokenizer", "(", "conf", ")", "\n", "train_ds", ",", "dev_ds", ",", "intents", ",", "slots", "=", "prepare_train_dev_datasets", "(", "conf", ",", "tokenizer", ")", "\n", "collator", "=", "prepare_collator", "(", "conf", ",", "tokenizer", ")", "\n", "model_init_fn", "=", "init_model", "(", "conf", ",", "intents", ",", "slots", ",", "return_hpo_fn", "=", "True", ")", "\n", "slots_ignore", "=", "conf", ".", "get", "(", "'train_val.slot_labels_ignore'", ",", "default", "=", "[", "]", ")", "\n", "metrics", "=", "conf", ".", "get", "(", "'train_val.eval_metrics'", ",", "default", "=", "'all'", ")", "\n", "compute_metrics", "=", "create_compute_metrics", "(", "intents", ",", "slots", ",", "conf", ",", "tokenizer", ",", "slots_ignore", ",", "metrics", ")", "\n", "\n", "# Get the right trainer", "\n", "trainer_cls", "=", "MASSIVESeq2SeqTrainer", "if", "conf", ".", "get", "(", "'train_val.trainer'", ")", "==", "'massive s2s'", "else", "MASSIVETrainer", "\n", "\n", "# Instantiate trainer", "\n", "trainer", "=", "trainer_cls", "(", "\n", "args", "=", "trainer_args", ",", "\n", "train_dataset", "=", "train_ds", ",", "\n", "eval_dataset", "=", "dev_ds", ",", "\n", "data_collator", "=", "collator", ",", "\n", "model_init", "=", "model_init_fn", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", "\n", ")", "\n", "\n", "# Prepare and then run hyperparameter tuning", "\n", "hp_args", "=", "prepare_hp_search_args", "(", "conf", ")", "\n", "best_trial", "=", "trainer", ".", "hyperparameter_search", "(", "**", "hp_args", ")", "\n", "logger", ".", "info", "(", "\"The best Trial:\"", ")", "\n", "logger", ".", "info", "(", "best_trial", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.__init__": [[49, 56], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "train", "=", "None", "\n", "self", ".", "dev", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "self", ".", "hidden_eval", "=", "None", "\n", "self", ".", "slot_dict", "=", "None", "\n", "self", ".", "intent_dict", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.create_datasets": [[57, 112], ["print", "create_hf_dataset.DatasetCreator._build_in_mem_dicts", "type", "os.path.join", "open", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict", "os.listdir", "os.path.isfile", "massive_raw.append", "datasets.concatenate_datasets", "datasets.concatenate_datasets", "datasets.concatenate_datasets", "datasets.concatenate_datasets", "os.path.join", "json.loads", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict", "datasets.Dataset.from_dict"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator._build_in_mem_dicts"], ["", "def", "create_datasets", "(", "self", ",", "data_paths", ",", "char_split_locales", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Loads the datasets, parses, and appends to the HF Dataset\n\n        :param data_path: The path(s) to the MASSIVE dataset\n        :type data_path: str or list\n        :param char_split_locales: Locales that should be split by character\n        :type char_split_locales: list[str]\n        \"\"\"", "\n", "\n", "char_split_locales", "=", "[", "'ja-JP'", ",", "'zh-CN'", ",", "'zh-TW'", "]", "if", "not", "char_split_locales", "else", "char_split_locales", "\n", "\n", "# Find locales based on the names of the files", "\n", "files", "=", "[", "]", "\n", "data_paths", "=", "[", "data_paths", "]", "if", "type", "(", "data_paths", ")", "==", "str", "else", "data_paths", "\n", "for", "path", "in", "data_paths", ":", "\n", "            ", "flist", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "path", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "path", ",", "f", ")", ")", "]", "\n", "files", "=", "files", "+", "flist", "\n", "\n", "", "for", "file", "in", "files", ":", "\n", "            ", "print", "(", "f'Reading in data from {file}'", ")", "\n", "massive_raw", "=", "[", "]", "\n", "# Read in the json per line", "\n", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "massive_raw", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "\n", "# Parse each line", "\n", "", "", "train", ",", "dev", ",", "test", ",", "hid", "=", "self", ".", "_build_in_mem_dicts", "(", "\n", "massive_raw", ",", "\n", "char_split_locales", "\n", ")", "\n", "\n", "# Either create the split or concatentate to an existing one", "\n", "if", "self", ".", "train", "is", "None", "and", "train", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "train", "=", "Dataset", ".", "from_dict", "(", "train", ")", "\n", "", "elif", "train", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "train", "=", "datasets", ".", "concatenate_datasets", "(", "[", "self", ".", "train", ",", "\n", "Dataset", ".", "from_dict", "(", "train", ")", "]", ")", "\n", "", "if", "self", ".", "dev", "is", "None", "and", "dev", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "dev", "=", "Dataset", ".", "from_dict", "(", "dev", ")", "\n", "", "elif", "dev", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "dev", "=", "datasets", ".", "concatenate_datasets", "(", "[", "self", ".", "dev", ",", "Dataset", ".", "from_dict", "(", "dev", ")", "]", ")", "\n", "", "if", "self", ".", "test", "is", "None", "and", "test", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "test", "=", "Dataset", ".", "from_dict", "(", "test", ")", "\n", "", "elif", "test", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "test", "=", "datasets", ".", "concatenate_datasets", "(", "[", "self", ".", "test", ",", "Dataset", ".", "from_dict", "(", "test", ")", "]", ")", "\n", "", "if", "self", ".", "hidden_eval", "is", "None", "and", "hid", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "hidden_eval", "=", "Dataset", ".", "from_dict", "(", "hid", ")", "\n", "", "elif", "hid", "[", "'id'", "]", ":", "\n", "                ", "self", ".", "hidden_eval", "=", "datasets", ".", "concatenate_datasets", "(", "[", "self", ".", "hidden_eval", ",", "\n", "Dataset", ".", "from_dict", "(", "hid", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator._build_in_mem_dicts": [[113, 199], ["dict_view[].append", "dict_view[].append", "dict_view[].append", "dict_view[].append", "dict_view[].append", "dict_view[].append", "dict_view[].append", "annot_utt.split", "utt.split", "annot_utt.split", "len", "len", "ValueError", "chunk.startswith", "create_hf_dataset.isascii", "len", "split_annot_utt[].startswith", "chunk.lstrip", "utt.split.append", "labels.append", "list", "split_annot_utt[].lstrip", "split_annot_utt[].endswith", "chunk.strip().rstrip", "chunk.strip", "labels.append", "labels.append", "ValueError", "utt.split.append", "labels.append", "chunk.strip"], "methods", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.isascii"], ["", "", "", "@", "staticmethod", "\n", "def", "_build_in_mem_dicts", "(", "massive_data", ",", "char_split", "=", "None", ")", ":", "\n", "        ", "\"\"\" Parse the JSON into a flat key/value format \"\"\"", "\n", "\n", "char_split", "=", "[", "'ja-JP'", ",", "'zh-CN'", ",", "'zh-TW'", "]", "if", "not", "char_split", "else", "char_split", "\n", "\n", "cols", "=", "[", "'id'", ",", "'locale'", ",", "'domain'", ",", "'intent_str'", ",", "'annot_utt'", ",", "'utt'", ",", "\n", "'slots_str'", "]", "\n", "train", ",", "dev", "=", "{", "k", ":", "[", "]", "for", "k", "in", "cols", "}", ",", "{", "k", ":", "[", "]", "for", "k", "in", "cols", "}", "\n", "test", ",", "hid_eval", "=", "{", "k", ":", "[", "]", "for", "k", "in", "cols", "}", ",", "{", "k", ":", "[", "]", "for", "k", "in", "cols", "}", "\n", "\n", "for", "row", "in", "massive_data", ":", "\n", "            ", "domain", ",", "intent", ",", "utt", ",", "locale", "=", "row", "[", "'scenario'", "]", ",", "row", "[", "'intent'", "]", ",", "row", "[", "'utt'", "]", ",", "row", "[", "'locale'", "]", "\n", "annot_utt", ",", "eyed", ",", "split", "=", "row", "[", "'annot_utt'", "]", ",", "row", "[", "'id'", "]", ",", "row", "[", "'partition'", "]", "\n", "\n", "# Split these languages by character", "\n", "if", "locale", "in", "char_split", ":", "\n", "                ", "tokens", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "label", "=", "'Other'", "\n", "skip_colon", "=", "False", "\n", "for", "chunk", "in", "annot_utt", ".", "split", "(", ")", ":", "\n", "                    ", "if", "chunk", ".", "startswith", "(", "'['", ")", ":", "\n", "                        ", "label", "=", "chunk", ".", "lstrip", "(", "'['", ")", "\n", "skip_colon", "=", "True", "\n", "continue", "\n", "", "if", "chunk", "==", "':'", "and", "skip_colon", "is", "True", ":", "\n", "                        ", "skip_colon", "=", "False", "\n", "continue", "\n", "# keep latin chars together in cases of code switching", "\n", "", "if", "isascii", "(", "chunk", ")", ":", "\n", "                        ", "tokens", ".", "append", "(", "chunk", ".", "strip", "(", ")", ".", "rstrip", "(", "']'", ")", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "else", ":", "\n", "                        ", "chars", "=", "list", "(", "chunk", ".", "strip", "(", ")", ")", "\n", "for", "char", "in", "chars", ":", "\n", "                            ", "if", "char", "==", "']'", ":", "\n", "                                ", "label", "=", "'Other'", "\n", "", "else", ":", "\n", "                                ", "tokens", ".", "append", "(", "char", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "", "", "", "else", ":", "\n", "# Create the tokens and labels by working left to right of annotated utt", "\n", "                ", "tokens", "=", "utt", ".", "split", "(", ")", "\n", "labels", "=", "[", "]", "\n", "label", "=", "'Other'", "\n", "split_annot_utt", "=", "annot_utt", ".", "split", "(", ")", "\n", "idx", "=", "0", "\n", "while", "idx", "<", "len", "(", "split_annot_utt", ")", ":", "\n", "                    ", "if", "split_annot_utt", "[", "idx", "]", ".", "startswith", "(", "'['", ")", ":", "\n", "                        ", "label", "=", "split_annot_utt", "[", "idx", "]", ".", "lstrip", "(", "'['", ")", "\n", "idx", "+=", "2", "\n", "", "elif", "split_annot_utt", "[", "idx", "]", ".", "endswith", "(", "']'", ")", ":", "\n", "                        ", "labels", ".", "append", "(", "label", ")", "\n", "label", "=", "'Other'", "\n", "idx", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "labels", ".", "append", "(", "label", ")", "\n", "idx", "+=", "1", "\n", "\n", "", "", "", "if", "len", "(", "tokens", ")", "!=", "len", "(", "labels", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Len of tokens, {tokens}, doesnt match len of labels, {labels}, \"", "\n", "f\"for id {eyed} and annot utt: {annot_utt}\"", ")", "\n", "\n", "# Pick the dictionary corresponding to this split", "\n", "", "if", "split", "==", "'train'", ":", "\n", "                ", "dict_view", "=", "train", "\n", "", "elif", "split", "==", "'dev'", ":", "\n", "                ", "dict_view", "=", "dev", "\n", "", "elif", "split", "==", "'test'", ":", "\n", "                ", "dict_view", "=", "test", "\n", "", "elif", "split", "==", "'heldout'", ":", "\n", "                ", "dict_view", "=", "hid_eval", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"split {split} is not valid\"", ")", "\n", "\n", "# add the values for the keys", "\n", "", "dict_view", "[", "'id'", "]", ".", "append", "(", "eyed", ")", "\n", "dict_view", "[", "'locale'", "]", ".", "append", "(", "locale", ")", "\n", "dict_view", "[", "'domain'", "]", ".", "append", "(", "domain", ")", "\n", "dict_view", "[", "'intent_str'", "]", ".", "append", "(", "intent", ")", "\n", "dict_view", "[", "'annot_utt'", "]", ".", "append", "(", "annot_utt", ")", "\n", "dict_view", "[", "'utt'", "]", ".", "append", "(", "tokens", ")", "\n", "dict_view", "[", "'slots_str'", "]", ".", "append", "(", "labels", ")", "\n", "\n", "", "return", "train", ",", "dev", ",", "test", ",", "hid_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.investigate_datasets": [[200, 206], ["print", "print"], "methods", ["None"], ["", "def", "investigate_datasets", "(", "self", ")", ":", "\n", "        ", "\"\"\" Prints out the seventh example from each split \"\"\"", "\n", "for", "dataset", "in", "[", "self", ".", "train", ",", "self", ".", "dev", ",", "self", ".", "test", ",", "self", ".", "hidden_eval", "]", ":", "\n", "            ", "if", "dataset", ":", "\n", "                ", "print", "(", "f\"dataset: {dataset}\"", ")", "\n", "print", "(", "f\"row 7: {dataset[7]}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.add_numeric_labels": [[207, 248], ["print", "set", "print", "set", "print", "create_hf_dataset.DatasetCreator.train.map", "create_hf_dataset.DatasetCreator.dev.map", "create_hf_dataset.DatasetCreator.test.map", "create_hf_dataset.DatasetCreator.hidden_eval.map", "set.update", "enumerate", "create_hf_dataset.DatasetCreator.intent_dict.items", "enumerate", "create_hf_dataset.DatasetCreator.slot_dict.items", "set.update"], "methods", ["None"], ["", "", "", "def", "add_numeric_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\" Creates integer version of the intent and slot labels, which is useful for modeling \"\"\"", "\n", "\n", "if", "not", "self", ".", "intent_dict", ":", "\n", "# Get the unique intents and create a mapping dict", "\n", "            ", "unique_intents", "=", "set", "(", "[", "]", ")", "\n", "for", "split", "in", "[", "self", ".", "train", ",", "self", ".", "dev", ",", "self", ".", "test", ",", "self", ".", "hidden_eval", "]", ":", "\n", "                ", "if", "split", ":", "\n", "                    ", "unique_intents", ".", "update", "(", "[", "i", "for", "i", "in", "split", "[", "'intent_str'", "]", "]", ")", "\n", "", "", "self", ".", "intent_dict", "=", "{", "k", ":", "v", "for", "v", ",", "k", "in", "enumerate", "(", "unique_intents", ")", "}", "\n", "print", "(", "'The following intent labels were detected across all partitions: '", ",", "\n", "self", ".", "intent_dict", ")", "\n", "", "else", ":", "\n", "# swap key and val", "\n", "            ", "self", ".", "intent_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "intent_dict", ".", "items", "(", ")", "}", "\n", "\n", "", "if", "not", "self", ".", "slot_dict", ":", "\n", "# Get the unique slots and create a mapping dict", "\n", "            ", "unique_slots", "=", "set", "(", ")", "\n", "for", "split", "in", "[", "self", ".", "train", ",", "self", ".", "dev", ",", "self", ".", "test", ",", "self", ".", "hidden_eval", "]", ":", "\n", "                ", "if", "split", ":", "\n", "                    ", "for", "ex_slots", "in", "split", ":", "\n", "                        ", "unique_slots", ".", "update", "(", "ex_slots", "[", "'slots_str'", "]", ")", "\n", "", "", "", "self", ".", "slot_dict", "=", "{", "k", ":", "v", "for", "v", ",", "k", "in", "enumerate", "(", "unique_slots", ")", "}", "\n", "print", "(", "'The following slot labels were detected across all partitions: '", ",", "self", ".", "slot_dict", ")", "\n", "", "else", ":", "\n", "# swap key and val", "\n", "            ", "self", ".", "slot_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "slot_dict", ".", "items", "(", ")", "}", "\n", "\n", "# Define a function for creating numeric labels from existing text labels", "\n", "", "def", "create_numeric_labels", "(", "example", ")", ":", "\n", "            ", "example", "[", "'slots_num'", "]", "=", "[", "self", ".", "slot_dict", "[", "x", "]", "for", "x", "in", "example", "[", "'slots_str'", "]", "]", "\n", "example", "[", "'intent_num'", "]", "=", "self", ".", "intent_dict", "[", "example", "[", "'intent_str'", "]", "]", "\n", "return", "example", "\n", "\n", "# Create the new numeric fields in the dataset with the map method", "\n", "", "print", "(", "'Adding numeric intent and slot labels to the datasets'", ")", "\n", "self", ".", "train", "=", "self", ".", "train", ".", "map", "(", "create_numeric_labels", ")", "if", "self", ".", "train", "else", "None", "\n", "self", ".", "dev", "=", "self", ".", "dev", ".", "map", "(", "create_numeric_labels", ")", "if", "self", ".", "dev", "else", "None", "\n", "self", ".", "test", "=", "self", ".", "test", ".", "map", "(", "create_numeric_labels", ")", "if", "self", ".", "test", "else", "None", "\n", "self", ".", "hidden_eval", "=", "self", ".", "hidden_eval", ".", "map", "(", "create_numeric_labels", ")", "if", "self", ".", "hidden_eval", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.save_label_dicts": [[249, 261], ["open", "open", "json.dump", "json.dump", "create_hf_dataset.DatasetCreator.intent_dict.items", "create_hf_dataset.DatasetCreator.slot_dict.items"], "methods", ["None"], ["", "def", "save_label_dicts", "(", "self", ",", "output_prefix", ")", ":", "\n", "        ", "\"\"\"\n        Save the dictionaries mapping numeric labels to text-based labels\n\n        :param output_prefix: The location and file prefix for saving the dictionaries\n        :type output_prefix: str\n        \"\"\"", "\n", "\n", "with", "open", "(", "output_prefix", "+", "'.intents'", ",", "\"w\"", ")", "as", "i", ",", "open", "(", "output_prefix", "+", "'.slots'", ",", "\"w\"", ")", "as", "s", ":", "\n", "# swap the keys and vals to use the index as key and slot as val", "\n", "            ", "json", ".", "dump", "(", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "intent_dict", ".", "items", "(", ")", "}", ",", "i", ")", "\n", "json", ".", "dump", "(", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "slot_dict", ".", "items", "(", ")", "}", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.save_datasets": [[262, 277], ["ds.save_to_disk"], "methods", ["None"], ["", "", "def", "save_datasets", "(", "self", ",", "output_prefix", ")", ":", "\n", "        ", "\"\"\"\n        Save the dataset splits\n\n        :param output_prefix: The location and file prefix for saving the dataset splits\n        :type output_prefix: str\n        \"\"\"", "\n", "for", "(", "ds", ",", "suf", ")", "in", "[", "\n", "(", "self", ".", "train", ",", "'.train'", ")", ",", "\n", "(", "self", ".", "dev", ",", "'.dev'", ")", ",", "\n", "(", "self", ".", "test", ",", "'.test'", ")", ",", "\n", "(", "self", ".", "hidden_eval", ",", "'.hidden_eval'", ")", "\n", "]", ":", "\n", "            ", "if", "ds", ":", "\n", "                ", "ds", ".", "save_to_disk", "(", "output_prefix", "+", "suf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.isascii": [[279, 284], ["s.isascii", "all", "ord"], "function", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.isascii"], ["", "", "", "", "def", "isascii", "(", "s", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "s", ".", "isascii", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "        ", "return", "all", "(", "[", "ord", "(", "c", ")", "<", "128", "for", "c", "in", "s", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.main": [[286, 316], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_hf_dataset.DatasetCreator", "create_hf_dataset.DatasetCreator.create_datasets", "create_hf_dataset.DatasetCreator.add_numeric_labels", "create_hf_dataset.DatasetCreator.investigate_datasets", "create_hf_dataset.DatasetCreator.save_datasets", "create_hf_dataset.DatasetCreator.save_label_dicts", "open", "json.load", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.create_datasets", "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.add_numeric_labels", "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.investigate_datasets", "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.save_datasets", "home.repos.pwc.inspect_result.alexa_massive.scripts.create_hf_dataset.DatasetCreator.save_label_dicts"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Create huggingface datasets from MASSIVE\"", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "'--massive-data-paths'", ",", "nargs", "=", "'+'", ",", "help", "=", "'path(s) to MASSIVE dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'-o'", ",", "'--out-prefix'", ",", "help", "=", "'output path and prefix for datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--intent-map'", ",", "nargs", "=", "'?'", ",", "default", "=", "{", "}", ",", "\n", "help", "=", "'optional existing intent numeric map'", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--slot-map'", ",", "nargs", "=", "'?'", ",", "default", "=", "{", "}", ",", "\n", "help", "=", "'optional existing slot numeric map'", ",", "required", "=", "False", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "intent_map", ":", "\n", "        ", "with", "open", "(", "args", ".", "intent_map", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "intent_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "intent_dict", "=", "None", "\n", "\n", "", "if", "args", ".", "slot_map", ":", "\n", "        ", "with", "open", "(", "args", ".", "slot_map", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "slot_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "slot_dict", "=", "None", "\n", "\n", "", "ds_creator", "=", "DatasetCreator", "(", ")", "\n", "ds_creator", ".", "create_datasets", "(", "args", ".", "massive_data_paths", ")", "\n", "ds_creator", ".", "intent_dict", "=", "intent_dict", "\n", "ds_creator", ".", "slot_dict", "=", "slot_dict", "\n", "ds_creator", ".", "add_numeric_labels", "(", ")", "\n", "ds_creator", ".", "investigate_datasets", "(", ")", "\n", "ds_creator", ".", "save_datasets", "(", "args", ".", "out_prefix", ")", "\n", "ds_creator", ".", "save_label_dicts", "(", "args", ".", "out_prefix", ")", "\n", "\n"]]}