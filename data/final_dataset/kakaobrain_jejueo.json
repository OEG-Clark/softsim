{"home.repos.pwc.inspect_result.kakaobrain_jejueo.translation.prepro.prepro": [[4, 21], ["os.system", "str"], "function", ["None"], ["def", "prepro", "(", "src", ",", "tgt", ",", "vocab_size", ")", ":", "\n", "    ", "dir", "=", "\"data/{}k\"", ".", "format", "(", "str", "(", "vocab_size", ")", "[", ":", "-", "3", "]", ")", "\n", "trainpref", "=", "f\"{dir}/bpe/train\"", "\n", "destdir", "=", "f\"{dir}/{src}-{tgt}-bin\"", "\n", "\n", "prepro", "=", "f\"fairseq-preprocess \\\n                  --source-lang {src} \\\n                  --target-lang {tgt} \\\n                  --trainpref {trainpref} \\\n                  --validpref {dir}/bpe/dev \\\n                  --testpref {dir}/bpe/test \\\n                  --srcdict {dir}/bpe/bpe.dict \\\n                  --tgtdict {dir}/bpe/bpe.dict \\\n                  --workers 8 \\\n                  --destdir {destdir}\"", "\n", "\n", "os", ".", "system", "(", "prepro", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.translation.bpe_segment.train_bpe": [[15, 30], ["os.path.dirname", "sentencepiece.SentencePieceTrainer.Train", "os.system", "line.replace", "codecs.open", "fout.write", "codecs.open().read().splitlines", "codecs.open().read", "codecs.open"], "function", ["None"], ["def", "train_bpe", "(", "fpath", ",", "vocab_size", ")", ":", "\n", "    ", "dir", "=", "os", ".", "path", ".", "dirname", "(", "fpath", ")", "\n", "train", "=", "f'--input={fpath} \\\n              --normalization_rule_name=identity \\\n              --model_prefix={dir}/bpe \\\n              --character_coverage=0.995 \\\n              --vocab_size={vocab_size} \\\n              --model_type=bpe'", "\n", "spm", ".", "SentencePieceTrainer", ".", "Train", "(", "train", ")", "\n", "\n", "# modify Dictionary", "\n", "lines", "=", "[", "line", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "for", "line", "in", "codecs", ".", "open", "(", "f'{dir}/bpe.vocab'", ",", "'r'", ",", "'utf8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "[", "3", ":", "]", "]", "\n", "with", "codecs", ".", "open", "(", "f'{dir}/bpe.dict'", ",", "'w'", ",", "'utf8'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "\"\\n\"", ".", "join", "(", "lines", ")", ")", "\n", "", "os", ".", "system", "(", "f'rm {dir}/bpe.vocab'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.translation.bpe_segment.apply_bpe": [[31, 34], ["codecs.open", "fout.write", "sp.EncodeAsPieces"], "function", ["None"], ["", "def", "apply_bpe", "(", "sp", ",", "sents", ",", "out_file", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "out_file", ",", "'w'", ",", "'utf8'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "\"\\n\"", ".", "join", "(", "\" \"", ".", "join", "(", "sp", ".", "EncodeAsPieces", "(", "sent", ")", ")", "for", "sent", "in", "sents", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.TextEnc": [[7, 65], ["modules.embed", "modules.conv1d", "modules.conv1d", "range", "range", "range", "tensorflow.split", "range", "modules.hc", "modules.hc", "len", "modules.hc"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.embed", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc"], ["def", "TextEnc", "(", "L", ",", "training", "=", "True", ")", ":", "\n", "    ", "'''\n    Args:\n      L: Text inputs. (B, N)\n\n    Return:\n        K: Keys. (B, N, d)\n        V: Values. (B, N, d)\n    '''", "\n", "i", "=", "1", "\n", "tensor", "=", "embed", "(", "L", ",", "\n", "vocab_size", "=", "len", "(", "hp", ".", "vocab", ")", ",", "\n", "num_units", "=", "hp", ".", "e", ",", "\n", "scope", "=", "\"embed_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "filters", "=", "2", "*", "hp", ".", "d", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "            ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", "**", "j", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "None", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "", "", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "None", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "None", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "", "K", ",", "V", "=", "tf", ".", "split", "(", "tensor", ",", "2", ",", "-", "1", ")", "\n", "return", "K", ",", "V", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.AudioEnc": [[66, 118], ["modules.conv1d", "modules.conv1d", "modules.conv1d", "range", "range", "range", "modules.hc", "modules.hc"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc"], ["", "def", "AudioEnc", "(", "S", ",", "training", "=", "True", ")", ":", "\n", "    ", "'''\n    Args:\n      S: melspectrogram. (B, T/r, n_mels)\n\n    Returns\n      Q: Queries. (B, T/r, d)\n    '''", "\n", "i", "=", "1", "\n", "tensor", "=", "conv1d", "(", "S", ",", "\n", "filters", "=", "hp", ".", "d", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "            ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", "**", "j", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "", "", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.Attention": [[119, 149], ["tensorflow.nn.softmax", "tensorflow.argmax", "tensorflow.matmul", "tensorflow.concat", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.rsqrt", "tensorflow.sequence_mask", "tensorflow.logical_or", "tensorflow.tile", "tensorflow.where", "tensorflow.to_float", "tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.equal"], "function", ["None"], ["", "def", "Attention", "(", "Q", ",", "K", ",", "V", ",", "mononotic_attention", "=", "False", ",", "prev_max_attentions", "=", "None", ")", ":", "\n", "    ", "'''\n    Args:\n      Q: Queries. (B, T/r, d)\n      K: Keys. (B, N, d)\n      V: Values. (B, N, d)\n      mononotic_attention: A boolean. At training, it is False.\n      prev_max_attentions: (B,). At training, it is set to None.\n\n    Returns:\n      R: [Context Vectors; Q]. (B, T/r, 2d)\n      alignments: (B, N, T/r)\n      max_attentions: (B, T/r)\n    '''", "\n", "A", "=", "tf", ".", "matmul", "(", "Q", ",", "K", ",", "transpose_b", "=", "True", ")", "*", "tf", ".", "rsqrt", "(", "tf", ".", "to_float", "(", "hp", ".", "d", ")", ")", "\n", "if", "mononotic_attention", ":", "# for inference", "\n", "        ", "key_masks", "=", "tf", ".", "sequence_mask", "(", "prev_max_attentions", "-", "1", ",", "hp", ".", "max_N", ")", "\n", "reverse_masks", "=", "tf", ".", "sequence_mask", "(", "hp", ".", "max_N", "-", "hp", ".", "attention_win_size", "-", "prev_max_attentions", ",", "hp", ".", "max_N", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "masks", "=", "tf", ".", "logical_or", "(", "key_masks", ",", "reverse_masks", ")", "\n", "masks", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "masks", ",", "1", ")", ",", "[", "1", ",", "hp", ".", "max_T", ",", "1", "]", ")", "\n", "paddings", "=", "tf", ".", "ones_like", "(", "A", ")", "*", "(", "-", "2", "**", "32", "+", "1", ")", "# (B, T/r, N)", "\n", "A", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "masks", ",", "False", ")", ",", "A", ",", "paddings", ")", "\n", "", "A", "=", "tf", ".", "nn", ".", "softmax", "(", "A", ")", "# (B, T/r, N)", "\n", "max_attentions", "=", "tf", ".", "argmax", "(", "A", ",", "-", "1", ")", "# (B, T/r)", "\n", "R", "=", "tf", ".", "matmul", "(", "A", ",", "V", ")", "\n", "R", "=", "tf", ".", "concat", "(", "(", "R", ",", "Q", ")", ",", "-", "1", ")", "\n", "\n", "alignments", "=", "tf", ".", "transpose", "(", "A", ",", "[", "0", ",", "2", ",", "1", "]", ")", "# (B, N, T/r)", "\n", "\n", "return", "R", ",", "alignments", ",", "max_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.AudioDec": [[150, 206], ["modules.conv1d", "range", "range", "range", "modules.conv1d", "tensorflow.nn.sigmoid", "modules.hc", "modules.hc", "modules.conv1d"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d"], ["", "def", "AudioDec", "(", "R", ",", "training", "=", "True", ")", ":", "\n", "    ", "'''\n    Args:\n      R: [Context Vectors; Q]. (B, T/r, 2d)\n\n    Returns:\n      Y: Melspectrogram predictions. (B, T/r, n_mels)\n    '''", "\n", "\n", "i", "=", "1", "\n", "tensor", "=", "conv1d", "(", "R", ",", "\n", "filters", "=", "hp", ".", "d", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", "**", "j", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "        ", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "# mel_hats", "\n", "", "logits", "=", "conv1d", "(", "tensor", ",", "\n", "filters", "=", "hp", ".", "n_mels", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"CAUSAL\"", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "Y", "=", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", "# mel_hats", "\n", "\n", "return", "logits", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.SSRN": [[207, 286], ["modules.conv1d", "range", "range", "modules.conv1d", "range", "modules.conv1d", "range", "modules.conv1d", "tensorflow.nn.sigmoid", "modules.hc", "modules.conv1d_transpose", "range", "modules.hc", "modules.conv1d", "modules.hc"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d_transpose", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc"], ["", "def", "SSRN", "(", "Y", ",", "training", "=", "True", ")", ":", "\n", "    ", "'''\n    Args:\n      Y: Melspectrogram Predictions. (B, T/r, n_mels)\n\n    Returns:\n      Z: Spectrogram Predictions. (B, T, 1+n_fft/2)\n    '''", "\n", "\n", "i", "=", "1", "# number of layers", "\n", "\n", "# -> (B, T/r, c)", "\n", "tensor", "=", "conv1d", "(", "Y", ",", "\n", "filters", "=", "hp", ".", "c", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", "**", "j", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "# -> (B, T/2, c) -> (B, T, c)", "\n", "        ", "tensor", "=", "conv1d_transpose", "(", "tensor", ",", "\n", "scope", "=", "\"D_{}\"", ".", "format", "(", "i", ")", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", ")", ";", "i", "+=", "1", "\n", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "            ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "3", "**", "j", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "# -> (B, T, 2*c)", "\n", "", "", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "filters", "=", "2", "*", "hp", ".", "c", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "hc", "(", "tensor", ",", "\n", "size", "=", "3", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"HC_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "# -> (B, T, 1+n_fft/2)", "\n", "", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "filters", "=", "1", "+", "hp", ".", "n_fft", "//", "2", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "        ", "tensor", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", ";", "i", "+=", "1", "\n", "", "logits", "=", "conv1d", "(", "tensor", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "dropout_rate", "=", "hp", ".", "dropout_rate", ",", "\n", "training", "=", "training", ",", "\n", "scope", "=", "\"C_{}\"", ".", "format", "(", "i", ")", ")", "\n", "Z", "=", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", "\n", "return", "logits", ",", "Z", "\n", "", ""]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.synthesize.synthesize": [[15, 59], ["data_load.load_data", "train.Graph", "print", "tensorflow.Session", "sess.run", "tensorflow.get_collection", "tensorflow.train.Saver", "tf.train.Saver.restore", "print", "tensorflow.train.Saver", "tf.train.Saver.restore", "print", "numpy.zeros", "numpy.zeros", "tqdm.tqdm", "sess.run", "enumerate", "tensorflow.global_variables_initializer", "tensorflow.train.latest_checkpoint", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.train.latest_checkpoint", "range", "sess.run", "os.path.exists", "os.makedirs", "print", "utils.spectrogram2wav", "scipy.io.wavfile.write", "len", "len"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_data", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.spectrogram2wav"], ["def", "synthesize", "(", ")", ":", "\n", "# Load data", "\n", "    ", "_", ",", "_", ",", "L", "=", "load_data", "(", "\"synthesize\"", ")", "\n", "\n", "# Load graph", "\n", "g", "=", "Graph", "(", "mode", "=", "\"synthesize\"", ")", ";", "print", "(", "\"Graph loaded\"", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# Restore parameters", "\n", "var_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "'Text2Mel'", ")", "\n", "saver1", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_list", ")", "\n", "saver1", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "hp", ".", "logdir", "+", "\"-1\"", ")", ")", "\n", "print", "(", "\"Text2Mel Restored!\"", ")", "\n", "\n", "var_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "'SSRN'", ")", "+", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "'gs'", ")", "\n", "saver2", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_list", ")", "\n", "saver2", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "hp", ".", "logdir", "+", "\"-2\"", ")", ")", "\n", "print", "(", "\"SSRN Restored!\"", ")", "\n", "\n", "# Feed Forward", "\n", "## mel", "\n", "Y", "=", "np", ".", "zeros", "(", "(", "len", "(", "L", ")", ",", "hp", ".", "max_T", ",", "hp", ".", "n_mels", ")", ",", "np", ".", "float32", ")", "\n", "prev_max_attentions", "=", "np", ".", "zeros", "(", "(", "len", "(", "L", ")", ",", ")", ",", "np", ".", "int32", ")", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "hp", ".", "max_T", ")", ")", ":", "\n", "            ", "_gs", ",", "_Y", ",", "_max_attentions", ",", "_alignments", "=", "sess", ".", "run", "(", "[", "g", ".", "global_step", ",", "g", ".", "Y", ",", "g", ".", "max_attentions", ",", "g", ".", "alignments", "]", ",", "\n", "{", "g", ".", "L", ":", "L", ",", "\n", "g", ".", "mels", ":", "Y", ",", "\n", "g", ".", "prev_max_attentions", ":", "prev_max_attentions", "}", ")", "\n", "Y", "[", ":", ",", "j", ",", ":", "]", "=", "_Y", "[", ":", ",", "j", ",", ":", "]", "\n", "prev_max_attentions", "=", "_max_attentions", "[", ":", ",", "j", "]", "\n", "\n", "# Get magnitude", "\n", "", "Z", "=", "sess", ".", "run", "(", "g", ".", "Z", ",", "{", "g", ".", "Y", ":", "Y", "}", ")", "\n", "\n", "# Generate wav files", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "hp", ".", "sampledir", ")", ":", "os", ".", "makedirs", "(", "hp", ".", "sampledir", ")", "\n", "for", "i", ",", "mag", "in", "enumerate", "(", "Z", ")", ":", "\n", "            ", "print", "(", "\"Working on file\"", ",", "i", "+", "1", ")", "\n", "wav", "=", "spectrogram2wav", "(", "mag", ")", "\n", "write", "(", "hp", ".", "sampledir", "+", "\"/{}.wav\"", ".", "format", "(", "i", "+", "1", ")", ",", "hp", ".", "sr", ",", "wav", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.embed": [[9, 39], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.concat", "tensorflow.truncated_normal_initializer", "tensorflow.zeros"], "function", ["None"], ["def", "embed", "(", "inputs", ",", "vocab_size", ",", "num_units", ",", "zero_pad", "=", "True", ",", "scope", "=", "\"embedding\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Embeds a given tensor. \n    \n    Args:\n      inputs: A `Tensor` with type `int32` or `int64` containing the ids\n         to be looked up in `lookup table`.\n      vocab_size: An int. Vocabulary size.\n      num_units: An int. Number of embedding hidden units.\n      zero_pad: A boolean. If True, all the values of the fist row (id 0)\n        should be constant zeros.\n      scope: Optional scope for `variable_scope`.  \n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n        \n    Returns:\n      A `Tensor` with one more rank than inputs's. The last dimensionality\n        should be `num_units`.\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "lookup_table", "=", "tf", ".", "get_variable", "(", "'lookup_table'", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "vocab_size", ",", "num_units", "]", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "mean", "=", "0.0", ",", "stddev", "=", "0.1", ")", ")", "\n", "if", "zero_pad", ":", "\n", "            ", "lookup_table", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros", "(", "shape", "=", "[", "1", ",", "num_units", "]", ")", ",", "\n", "lookup_table", "[", "1", ":", ",", ":", "]", ")", ",", "0", ")", "\n", "\n", "", "outputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "lookup_table", ",", "inputs", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.normalize": [[41, 61], ["tensorflow.contrib.layers.layer_norm"], "function", ["None"], ["", "def", "normalize", "(", "inputs", ",", "\n", "scope", "=", "\"normalize\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Applies layer normalization that normalizes along the last axis.\n\n    Args:\n      inputs: A tensor with 2 or more dimensions, where the first dimension has\n        `batch_size`. The normalization is over the last dimension.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A tensor with the same shape and data dtype as `inputs`.\n    '''", "\n", "outputs", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "inputs", ",", "\n", "begin_norm_axis", "=", "-", "1", ",", "\n", "scope", "=", "scope", ",", "\n", "reuse", "=", "reuse", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.highwaynet": [[63, 86], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "inputs.get_shape", "tensorflow.constant_initializer"], "function", ["None"], ["", "def", "highwaynet", "(", "inputs", ",", "num_units", "=", "None", ",", "scope", "=", "\"highwaynet\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "'''Highway networks, see https://arxiv.org/abs/1505.00387\n\n    Args:\n      inputs: A 3D tensor of shape [N, T, W].\n      num_units: An int or `None`. Specifies the number of units in the highway layer\n             or uses the input size if `None`.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A 3D tensor of shape [N, T, W].\n    '''", "\n", "if", "not", "num_units", ":", "\n", "        ", "num_units", "=", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "H", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "units", "=", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"dense1\"", ")", "\n", "T", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "units", "=", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "sigmoid", ",", "\n", "bias_initializer", "=", "tf", ".", "constant_initializer", "(", "-", "1.0", ")", ",", "name", "=", "\"dense2\"", ")", "\n", "outputs", "=", "H", "*", "T", "+", "inputs", "*", "(", "1.", "-", "T", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d": [[87, 138], ["tensorflow.variable_scope", "tensorflow.layers.conv1d", "modules.normalize", "tensorflow.layers.dropout", "padding.lower", "tensorflow.pad", "tensorflow.contrib.layers.variance_scaling_initializer", "activation_fn", "tf.pad.get_shape().as_list", "tf.pad.get_shape"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.normalize"], ["", "def", "conv1d", "(", "inputs", ",", "\n", "filters", "=", "None", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "use_bias", "=", "True", ",", "\n", "activation_fn", "=", "None", ",", "\n", "training", "=", "True", ",", "\n", "scope", "=", "\"conv1d\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''\n    Args:\n      inputs: A 3-D tensor with shape of [batch, time, depth].\n      filters: An int. Number of outputs (=activation maps)\n      size: An int. Filter size.\n      rate: An int. Dilation rate.\n      padding: Either `same` or `valid` or `causal` (case-insensitive).\n      dropout_rate: A float of [0, 1].\n      use_bias: A boolean.\n      activation_fn: A string.\n      training: A boolean. If True, dropout is applied.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A masked tensor of the same shape and dtypes as `inputs`.\n    '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "if", "padding", ".", "lower", "(", ")", "==", "\"causal\"", ":", "\n", "# pre-padding for causality", "\n", "            ", "pad_len", "=", "(", "size", "-", "1", ")", "*", "rate", "# padding size", "\n", "inputs", "=", "tf", ".", "pad", "(", "inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad_len", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "padding", "=", "\"valid\"", "\n", "\n", "", "if", "filters", "is", "None", ":", "\n", "            ", "filters", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "", "params", "=", "{", "\"inputs\"", ":", "inputs", ",", "\"filters\"", ":", "filters", ",", "\"kernel_size\"", ":", "size", ",", "\n", "\"dilation_rate\"", ":", "rate", ",", "\"padding\"", ":", "padding", ",", "\"use_bias\"", ":", "use_bias", ",", "\n", "\"kernel_initializer\"", ":", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "\"reuse\"", ":", "reuse", "}", "\n", "\n", "tensor", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "tensor", "=", "normalize", "(", "tensor", ")", "\n", "if", "activation_fn", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "activation_fn", "(", "tensor", ")", "\n", "\n", "", "tensor", "=", "tf", ".", "layers", ".", "dropout", "(", "tensor", ",", "rate", "=", "dropout_rate", ",", "training", "=", "training", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.hc": [[139, 194], ["tensorflow.variable_scope", "tensorflow.layers.conv1d", "tensorflow.split", "modules.normalize", "modules.normalize", "tensorflow.nn.sigmoid", "tensorflow.layers.dropout", "padding.lower", "tensorflow.pad", "tensorflow.contrib.layers.variance_scaling_initializer", "activation_fn", "tf.pad.get_shape().as_list", "tf.pad.get_shape"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.normalize", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.normalize"], ["", "def", "hc", "(", "inputs", ",", "\n", "filters", "=", "None", ",", "\n", "size", "=", "1", ",", "\n", "rate", "=", "1", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "use_bias", "=", "True", ",", "\n", "activation_fn", "=", "None", ",", "\n", "training", "=", "True", ",", "\n", "scope", "=", "\"hc\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''\n    Args:\n      inputs: A 3-D tensor with shape of [batch, time, depth].\n      filters: An int. Number of outputs (=activation maps)\n      size: An int. Filter size.\n      rate: An int. Dilation rate.\n      padding: Either `same` or `valid` or `causal` (case-insensitive).\n      use_bias: A boolean.\n      activation_fn: A string.\n      training: A boolean. If True, dropout is applied.\n      scope: Optional scope for `variable_scope`.\n      reuse: Boolean, whether to reuse the weights of a previous layer\n        by the same name.\n\n    Returns:\n      A masked tensor of the same shape and dtypes as `inputs`.\n    '''", "\n", "_inputs", "=", "inputs", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "if", "padding", ".", "lower", "(", ")", "==", "\"causal\"", ":", "\n", "# pre-padding for causality", "\n", "            ", "pad_len", "=", "(", "size", "-", "1", ")", "*", "rate", "# padding size", "\n", "inputs", "=", "tf", ".", "pad", "(", "inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad_len", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "padding", "=", "\"valid\"", "\n", "\n", "", "if", "filters", "is", "None", ":", "\n", "            ", "filters", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "\n", "", "params", "=", "{", "\"inputs\"", ":", "inputs", ",", "\"filters\"", ":", "2", "*", "filters", ",", "\"kernel_size\"", ":", "size", ",", "\n", "\"dilation_rate\"", ":", "rate", ",", "\"padding\"", ":", "padding", ",", "\"use_bias\"", ":", "use_bias", ",", "\n", "\"kernel_initializer\"", ":", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "\"reuse\"", ":", "reuse", "}", "\n", "\n", "tensor", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "H1", ",", "H2", "=", "tf", ".", "split", "(", "tensor", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "H1", "=", "normalize", "(", "H1", ",", "scope", "=", "\"H1\"", ")", "\n", "H2", "=", "normalize", "(", "H2", ",", "scope", "=", "\"H2\"", ")", "\n", "H1", "=", "tf", ".", "nn", ".", "sigmoid", "(", "H1", ",", "\"gate\"", ")", "\n", "H2", "=", "activation_fn", "(", "H2", ",", "\"info\"", ")", "if", "activation_fn", "is", "not", "None", "else", "H2", "\n", "tensor", "=", "H1", "*", "H2", "+", "(", "1.", "-", "H1", ")", "*", "_inputs", "\n", "\n", "tensor", "=", "tf", ".", "layers", ".", "dropout", "(", "tensor", ",", "rate", "=", "dropout_rate", ",", "training", "=", "training", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.conv1d_transpose": [[195, 244], ["tensorflow.variable_scope", "tensorflow.expand_dims", "tensorflow.layers.conv2d_transpose", "tensorflow.squeeze", "modules.normalize", "tensorflow.layers.dropout", "activation", "tf.expand_dims.get_shape().as_list", "tensorflow.contrib.layers.variance_scaling_initializer", "tf.expand_dims.get_shape"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.modules.normalize"], ["", "def", "conv1d_transpose", "(", "inputs", ",", "\n", "filters", "=", "None", ",", "\n", "size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "'same'", ",", "\n", "dropout_rate", "=", "0", ",", "\n", "use_bias", "=", "True", ",", "\n", "activation", "=", "None", ",", "\n", "training", "=", "True", ",", "\n", "scope", "=", "\"conv1d_transpose\"", ",", "\n", "reuse", "=", "None", ")", ":", "\n", "    ", "'''\n        Args:\n          inputs: A 3-D tensor with shape of [batch, time, depth].\n          filters: An int. Number of outputs (=activation maps)\n          size: An int. Filter size.\n          rate: An int. Dilation rate.\n          padding: Either `same` or `valid` or `causal` (case-insensitive).\n          dropout_rate: A float of [0, 1].\n          use_bias: A boolean.\n          activation_fn: A string.\n          training: A boolean. If True, dropout is applied.\n          scope: Optional scope for `variable_scope`.\n          reuse: Boolean, whether to reuse the weights of a previous layer\n            by the same name.\n\n        Returns:\n          A tensor of the shape with [batch, time*2, depth].\n        '''", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "if", "filters", "is", "None", ":", "\n", "            ", "filters", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "", "inputs", "=", "tf", ".", "expand_dims", "(", "inputs", ",", "1", ")", "\n", "tensor", "=", "tf", ".", "layers", ".", "conv2d_transpose", "(", "inputs", ",", "\n", "filters", "=", "filters", ",", "\n", "kernel_size", "=", "(", "1", ",", "size", ")", ",", "\n", "strides", "=", "(", "1", ",", "stride", ")", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "use_bias", "=", "use_bias", ")", "\n", "tensor", "=", "tf", ".", "squeeze", "(", "tensor", ",", "1", ")", "\n", "tensor", "=", "normalize", "(", "tensor", ")", "\n", "if", "activation", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "activation", "(", "tensor", ")", "\n", "\n", "", "tensor", "=", "tf", ".", "layers", ".", "dropout", "(", "tensor", ",", "rate", "=", "dropout_rate", ",", "training", "=", "training", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.train.Graph.__init__": [[18, 132], ["data_load.load_vocab", "data_load.get_batch", "tensorflow.ones", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.variable_scope", "tensorflow.Variable", "utils.learning_rate_decay", "tensorflow.train.AdamOptimizer", "tensorflow.summary.scalar", "train.Graph.optimizer.compute_gradients", "tensorflow.summary.merge_all", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "networks.SSRN", "tensorflow.variable_scope", "networks.SSRN", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.image", "tensorflow.summary.image", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.image", "tensorflow.summary.image", "tensorflow.clip_by_value", "train.Graph.clipped.append", "train.Graph.optimizer.apply_gradients", "tensorflow.variable_scope", "networks.TextEnc", "tensorflow.variable_scope", "networks.AudioEnc", "tensorflow.variable_scope", "networks.Attention", "tensorflow.variable_scope", "networks.AudioDec", "tensorflow.abs", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.pad", "tensorflow.not_equal", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.abs", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros_like", "tensorflow.abs", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_vocab", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.get_batch", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.learning_rate_decay", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.SSRN", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.SSRN", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.TextEnc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.AudioEnc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.Attention", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.networks.AudioDec"], ["    ", "def", "__init__", "(", "self", ",", "num", "=", "1", ",", "mode", "=", "\"train\"", ")", ":", "\n", "        ", "'''\n        Args:\n          num: Either 1 or 2. 1 for Text2Mel 2 for SSRN.\n          mode: Either \"train\" or \"synthesize\".\n        '''", "\n", "# Load vocabulary", "\n", "self", ".", "char2idx", ",", "self", ".", "idx2char", "=", "load_vocab", "(", ")", "\n", "\n", "# Set flag", "\n", "training", "=", "True", "if", "mode", "==", "\"train\"", "else", "False", "\n", "\n", "# Graph", "\n", "# Data Feeding", "\n", "## L: Text. (B, N), int32", "\n", "## mels: Reduced melspectrogram. (B, T/r, n_mels) float32", "\n", "## mags: Magnitude. (B, T, n_fft//2+1) float32", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "self", ".", "L", ",", "self", ".", "mels", ",", "self", ".", "mags", ",", "self", ".", "gts", ",", "self", ".", "fnames", ",", "self", ".", "num_batch", "=", "get_batch", "(", ")", "\n", "self", ".", "prev_max_attentions", "=", "tf", ".", "ones", "(", "shape", "=", "(", "hp", ".", "B", ",", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "# self.gts = tf.convert_to_tensor(guided_attention())", "\n", "", "else", ":", "# Synthesize", "\n", "            ", "self", ".", "L", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", "None", ")", ")", "\n", "self", ".", "mels", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "None", ",", "hp", ".", "n_mels", ")", ")", "\n", "self", ".", "prev_max_attentions", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "\n", "", "if", "num", "==", "1", "or", "(", "not", "training", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"Text2Mel\"", ")", ":", "\n", "# Get S or decoder inputs. (B, T//r, n_mels)", "\n", "                ", "self", ".", "S", "=", "tf", ".", "concat", "(", "(", "tf", ".", "zeros_like", "(", "self", ".", "mels", "[", ":", ",", ":", "1", ",", ":", "]", ")", ",", "self", ".", "mels", "[", ":", ",", ":", "-", "1", ",", ":", "]", ")", ",", "1", ")", "\n", "\n", "# Networks", "\n", "with", "tf", ".", "variable_scope", "(", "\"TextEnc\"", ")", ":", "\n", "                    ", "self", ".", "K", ",", "self", ".", "V", "=", "TextEnc", "(", "self", ".", "L", ",", "training", "=", "training", ")", "# (N, Tx, e)", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"AudioEnc\"", ")", ":", "\n", "                    ", "self", ".", "Q", "=", "AudioEnc", "(", "self", ".", "S", ",", "training", "=", "training", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Attention\"", ")", ":", "\n", "# R: (B, T/r, 2d)", "\n", "# alignments: (B, N, T/r)", "\n", "# max_attentions: (B,)", "\n", "                    ", "self", ".", "R", ",", "self", ".", "alignments", ",", "self", ".", "max_attentions", "=", "Attention", "(", "self", ".", "Q", ",", "self", ".", "K", ",", "self", ".", "V", ",", "\n", "mononotic_attention", "=", "(", "not", "training", ")", ",", "\n", "prev_max_attentions", "=", "self", ".", "prev_max_attentions", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"AudioDec\"", ")", ":", "\n", "                    ", "self", ".", "Y_logits", ",", "self", ".", "Y", "=", "AudioDec", "(", "self", ".", "R", ",", "training", "=", "training", ")", "# (B, T/r, n_mels)", "\n", "", "", "", "else", ":", "# num==2 & training. Note that during training,", "\n", "# the ground truth melspectrogram values are fed.", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"SSRN\"", ")", ":", "\n", "                ", "self", ".", "Z_logits", ",", "self", ".", "Z", "=", "SSRN", "(", "self", ".", "mels", ",", "training", "=", "training", ")", "\n", "\n", "", "", "if", "not", "training", ":", "\n", "# During inference, the predicted melspectrogram values are fed.", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"SSRN\"", ")", ":", "\n", "                ", "self", ".", "Z_logits", ",", "self", ".", "Z", "=", "SSRN", "(", "self", ".", "Y", ",", "training", "=", "training", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"gs\"", ")", ":", "\n", "            ", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'global_step'", ",", "trainable", "=", "False", ")", "\n", "\n", "", "if", "training", ":", "\n", "            ", "if", "num", "==", "1", ":", "# Text2Mel", "\n", "# mel L1 loss", "\n", "                ", "self", ".", "loss_mels", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "self", ".", "Y", "-", "self", ".", "mels", ")", ")", "\n", "\n", "# mel binary divergence loss", "\n", "self", ".", "loss_bd1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "Y_logits", ",", "labels", "=", "self", ".", "mels", ")", ")", "\n", "\n", "# guided_attention loss", "\n", "self", ".", "A", "=", "tf", ".", "pad", "(", "self", ".", "alignments", ",", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "hp", ".", "max_N", ")", ",", "(", "0", ",", "hp", ".", "max_T", ")", "]", ",", "mode", "=", "\"CONSTANT\"", ",", "constant_values", "=", "-", "1.", ")", "[", ":", ",", ":", "hp", ".", "max_N", ",", ":", "hp", ".", "max_T", "]", "\n", "# self.attention_masks = tf.to_float(tf.not_equal(self.gts, -1))", "\n", "self", ".", "attention_masks", "=", "tf", ".", "to_float", "(", "tf", ".", "not_equal", "(", "self", ".", "A", ",", "-", "1", ")", ")", "\n", "self", ".", "loss_att", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "self", ".", "A", "*", "self", ".", "gts", ")", "*", "self", ".", "attention_masks", ")", "\n", "self", ".", "mask_sum", "=", "tf", ".", "reduce_sum", "(", "self", ".", "attention_masks", ")", "\n", "self", ".", "loss_att", "/=", "self", ".", "mask_sum", "\n", "\n", "# total loss", "\n", "self", ".", "loss", "=", "self", ".", "loss_mels", "+", "self", ".", "loss_bd1", "+", "self", ".", "loss_att", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'train/loss_mels'", ",", "self", ".", "loss_mels", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'train/loss_bd1'", ",", "self", ".", "loss_bd1", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'train/loss_att'", ",", "self", ".", "loss_att", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'train/mel_gt'", ",", "tf", ".", "expand_dims", "(", "tf", ".", "transpose", "(", "self", ".", "mels", "[", ":", "1", "]", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "-", "1", ")", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'train/mel_hat'", ",", "tf", ".", "expand_dims", "(", "tf", ".", "transpose", "(", "self", ".", "Y", "[", ":", "1", "]", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "-", "1", ")", ")", "\n", "", "else", ":", "# SSRN", "\n", "# mag L1 loss", "\n", "                ", "self", ".", "loss_mags", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "self", ".", "Z", "-", "self", ".", "mags", ")", ")", "\n", "\n", "# mag binary divergence loss", "\n", "self", ".", "loss_bd2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "Z_logits", ",", "labels", "=", "self", ".", "mags", ")", ")", "\n", "\n", "# total loss", "\n", "self", ".", "loss", "=", "self", ".", "loss_mags", "+", "self", ".", "loss_bd2", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'train/loss_mags'", ",", "self", ".", "loss_mags", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'train/loss_bd2'", ",", "self", ".", "loss_bd2", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'train/mag_gt'", ",", "tf", ".", "expand_dims", "(", "tf", ".", "transpose", "(", "self", ".", "mags", "[", ":", "1", "]", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "-", "1", ")", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'train/mag_hat'", ",", "tf", ".", "expand_dims", "(", "tf", ".", "transpose", "(", "self", ".", "Z", "[", ":", "1", "]", ",", "[", "0", ",", "2", ",", "1", "]", ")", ",", "-", "1", ")", ")", "\n", "\n", "# Training Scheme", "\n", "", "self", ".", "lr", "=", "learning_rate_decay", "(", "hp", ".", "lr", ",", "self", ".", "global_step", ")", "\n", "self", ".", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"lr\"", ",", "self", ".", "lr", ")", "\n", "\n", "## gradient clipping", "\n", "self", ".", "gvs", "=", "self", ".", "optimizer", ".", "compute_gradients", "(", "self", ".", "loss", ")", "\n", "self", ".", "clipped", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "self", ".", "gvs", ":", "\n", "                ", "grad", "=", "tf", ".", "clip_by_value", "(", "grad", ",", "-", "1.", ",", "1.", ")", "\n", "self", ".", "clipped", ".", "append", "(", "(", "grad", ",", "var", ")", ")", "\n", "self", ".", "train_op", "=", "self", ".", "optimizer", ".", "apply_gradients", "(", "self", ".", "clipped", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "# Summary", "\n", "", "self", ".", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_vocab": [[14, 18], ["enumerate", "enumerate"], "function", ["None"], ["def", "load_vocab", "(", ")", ":", "\n", "    ", "char2idx", "=", "{", "char", ":", "idx", "for", "idx", ",", "char", "in", "enumerate", "(", "hp", ".", "vocab", ")", "}", "\n", "idx2char", "=", "{", "idx", ":", "char", "for", "idx", ",", "char", "in", "enumerate", "(", "hp", ".", "vocab", ")", "}", "\n", "return", "char2idx", ",", "idx2char", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_data": [[19, 68], ["data_load.load_vocab", "os.path.join", "codecs.open().readlines", "utils.load_j2hcj", "utils.load_j2sj", "utils.load_j2shcj", "line.strip().split", "os.path.join", "fpaths.append", "itertools.chain.from_iterable", "text_lengths.append", "codecs.open", "list", "itertools.chain.from_iterable", "len", "texts.append", "texts.append", "line.strip", "jamo.h2j", "numpy.array().tostring", "jamo.h2j", "j2sj.get", "numpy.array", "j2hcj.get", "len", "j2shcj.get"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_vocab", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2hcj", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2sj", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2shcj"], ["", "def", "load_data", "(", "mode", "=", "\"train\"", ")", ":", "\n", "    ", "'''Loads data\n      Args:\n          mode: \"train\" or \"synthesize\".\n    '''", "\n", "# Load vocabulary", "\n", "char2idx", ",", "idx2char", "=", "load_vocab", "(", ")", "\n", "\n", "# load conversion dictionaries", "\n", "j2hcj", ",", "j2sj", ",", "j2shcj", "=", "load_j2hcj", "(", ")", ",", "load_j2sj", "(", ")", ",", "load_j2shcj", "(", ")", "\n", "\n", "# Parse", "\n", "fpaths", ",", "text_lengths", ",", "texts", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "transcript", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "data", ",", "'jss.v1.0.txt'", ")", "\n", "lines", "=", "codecs", ".", "open", "(", "transcript", ",", "'r'", ",", "'utf-8'", ")", ".", "readlines", "(", ")", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "        ", "lines", "=", "lines", "[", ":", "-", "100", "]", "\n", "", "else", ":", "\n", "        ", "lines", "=", "lines", "[", "-", "100", ":", "]", "\n", "\n", "", "for", "line", "in", "lines", ":", "\n", "        ", "fname", ",", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "hp", ".", "data", ",", "fname", ")", "\n", "fpaths", ".", "append", "(", "fpath", ")", "\n", "\n", "text", "+=", "\"\u2403\"", "# \u2403: EOS", "\n", "if", "hp", ".", "token_type", "==", "\"char\"", ":", "# syllable", "\n", "            ", "text", "=", "list", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "[", "h2j", "(", "char", ")", "for", "char", "in", "text", "]", "\n", "text", "=", "chain", ".", "from_iterable", "(", "text", ")", "\n", "if", "hp", ".", "token_type", "==", "\"j\"", ":", "# jamo", "\n", "                ", "text", "=", "[", "h2j", "(", "char", ")", "for", "char", "in", "text", "]", "\n", "", "elif", "hp", ".", "token_type", "==", "\"sj\"", ":", "# single jamo", "\n", "                ", "text", "=", "[", "j2sj", ".", "get", "(", "j", ",", "j", ")", "for", "j", "in", "text", "]", "\n", "", "elif", "hp", ".", "token_type", "==", "\"hcj\"", ":", "# hangul compatibility jamo", "\n", "                ", "text", "=", "[", "j2hcj", ".", "get", "(", "j", ",", "j", ")", "for", "j", "in", "text", "]", "\n", "", "elif", "hp", ".", "token_type", "==", "\"shcj\"", ":", "# single hangul compatibility jamo", "\n", "                ", "text", "=", "[", "j2shcj", ".", "get", "(", "j", ",", "j", ")", "for", "j", "in", "text", "]", "\n", "", "", "text", "=", "chain", ".", "from_iterable", "(", "text", ")", "\n", "\n", "text", "=", "[", "char2idx", "[", "char", "]", "for", "char", "in", "text", "if", "char", "in", "char2idx", "]", "\n", "text_lengths", ".", "append", "(", "len", "(", "text", ")", ")", "\n", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "texts", ".", "append", "(", "np", ".", "array", "(", "text", ",", "np", ".", "int32", ")", ".", "tostring", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "texts", ".", "append", "(", "text", "+", "[", "0", "]", "*", "(", "hp", ".", "max_N", "-", "len", "(", "text", ")", ")", ")", "\n", "\n", "", "", "return", "fpaths", ",", "text_lengths", ",", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.get_batch": [[69, 107], ["tensorflow.device", "data_load.load_data", "print", "tensorflow.train.slice_input_producer", "tensorflow.decode_raw", "tensorflow.py_func", "tensorflow.py_func", "fname.set_shape", "tf.decode_raw.set_shape", "mel.set_shape", "mag.set_shape", "gt.set_shape", "tensorflow.contrib.training.bucket_by_sequence_length", "max", "min", "len", "range"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.data_load.load_data"], ["", "def", "get_batch", "(", ")", ":", "\n", "    ", "\"\"\"Loads training data and put them in queues\"\"\"", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "# Load data", "\n", "        ", "fpaths", ",", "text_lengths", ",", "texts", "=", "load_data", "(", ")", "# list", "\n", "maxlen", ",", "minlen", "=", "max", "(", "text_lengths", ")", ",", "min", "(", "text_lengths", ")", "\n", "print", "(", "\"maxlen=\"", ",", "maxlen", ",", "\"minlen=\"", ",", "minlen", ")", "\n", "\n", "# Calc total batch count", "\n", "num_batch", "=", "len", "(", "fpaths", ")", "//", "hp", ".", "B", "\n", "\n", "# Create Queues", "\n", "fpath", ",", "text_length", ",", "text", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "fpaths", ",", "text_lengths", ",", "texts", "]", ",", "shuffle", "=", "True", ")", "\n", "\n", "# Parse", "\n", "text", "=", "tf", ".", "decode_raw", "(", "text", ",", "tf", ".", "int32", ")", "# (None,)", "\n", "\n", "fname", ",", "mel", ",", "mag", ",", "t", "=", "tf", ".", "py_func", "(", "load_spectrograms", ",", "[", "fpath", "]", ",", "[", "tf", ".", "string", ",", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "tf", ".", "int64", "]", ")", "\n", "gt", ",", "=", "tf", ".", "py_func", "(", "guided_attention", ",", "[", "text_length", ",", "t", "]", ",", "[", "tf", ".", "float32", "]", ")", "\n", "\n", "# Add shape information", "\n", "fname", ".", "set_shape", "(", "(", ")", ")", "\n", "text", ".", "set_shape", "(", "(", "None", ",", ")", ")", "\n", "mel", ".", "set_shape", "(", "(", "None", ",", "hp", ".", "n_mels", ")", ")", "\n", "mag", ".", "set_shape", "(", "(", "None", ",", "hp", ".", "n_fft", "//", "2", "+", "1", ")", ")", "\n", "gt", ".", "set_shape", "(", "(", "hp", ".", "max_N", ",", "hp", ".", "max_T", ")", ")", "\n", "\n", "# Batching", "\n", "_", ",", "(", "texts", ",", "mels", ",", "mags", ",", "gts", ",", "fnames", ")", "=", "tf", ".", "contrib", ".", "training", ".", "bucket_by_sequence_length", "(", "\n", "input_length", "=", "text_length", ",", "\n", "tensors", "=", "[", "text", ",", "mel", ",", "mag", ",", "gt", ",", "fname", "]", ",", "\n", "batch_size", "=", "hp", ".", "B", ",", "\n", "bucket_boundaries", "=", "[", "i", "for", "i", "in", "range", "(", "minlen", "+", "1", ",", "maxlen", "-", "1", ",", "40", ")", "]", ",", "\n", "num_threads", "=", "8", ",", "\n", "capacity", "=", "hp", ".", "B", "*", "10", ",", "\n", "dynamic_pad", "=", "True", ")", "\n", "\n", "", "return", "texts", ",", "mels", ",", "mags", ",", "gts", ",", "fnames", ",", "num_batch", "\n", "", ""]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.mcd.get_mc": [[13, 23], ["soundfile.read", "y.astype.astype", "pyworld.dio", "pyworld.stonemask", "pyworld.cheaptrick", "pysptk.sp2mc", "mc.astype.astype"], "function", ["None"], ["def", "get_mc", "(", "wav", ")", ":", "\n", "    ", "y", ",", "sr", "=", "sf", ".", "read", "(", "wav", ")", "\n", "y", "=", "y", ".", "astype", "(", "np", ".", "float64", ")", "\n", "f0", ",", "timeaxis", "=", "pyworld", ".", "dio", "(", "y", ",", "sr", ",", "frame_period", "=", "5", ")", "\n", "f0", "=", "pyworld", ".", "stonemask", "(", "y", ",", "f0", ",", "timeaxis", ",", "sr", ")", "\n", "spectrogram", "=", "pyworld", ".", "cheaptrick", "(", "y", ",", "f0", ",", "timeaxis", ",", "sr", ")", "\n", "mc", "=", "pysptk", ".", "sp2mc", "(", "spectrogram", ",", "order", "=", "24", ",", "alpha", "=", "0.41", ")", "\n", "mc", "=", "mc", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "return", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.mcd.get_mcd": [[25, 43], ["mcd.get_mc", "mcd.get_mc", "numpy.expand_dims", "numpy.expand_dims", "aligner.transform", "numpy.squeeze", "numpy.squeeze", "nnmnkwii.metrics.melcd"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.mcd.get_mc", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.mcd.get_mc"], ["", "def", "get_mcd", "(", "inp", ",", "ref", ")", ":", "\n", "# extract mc", "\n", "    ", "inp_mc", "=", "get_mc", "(", "inp", ")", "\n", "ref_mc", "=", "get_mc", "(", "ref", ")", "\n", "\n", "# alignment", "\n", "inp", "=", "np", ".", "expand_dims", "(", "inp_mc", ",", "0", ")", "# rank=3", "\n", "ref", "=", "np", ".", "expand_dims", "(", "ref_mc", ",", "0", ")", "# rank=3", "\n", "\n", "inp_aligned", ",", "ref_aligned", "=", "aligner", ".", "transform", "(", "(", "inp", ",", "ref", ")", ")", "\n", "\n", "inp_aligned", "=", "np", ".", "squeeze", "(", "inp_aligned", ")", "\n", "ref_aligned", "=", "np", ".", "squeeze", "(", "ref_aligned", ")", "\n", "\n", "# calc mcd", "\n", "mcd", "=", "nnmnkwii", ".", "metrics", ".", "melcd", "(", "inp_aligned", ",", "ref_aligned", ")", "\n", "\n", "return", "mcd", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.get_spectrograms": [[16, 62], ["librosa.load", "numpy.append", "librosa.stft", "numpy.abs", "librosa.filters.mel", "numpy.dot", "numpy.clip", "numpy.clip", "mel.T.astype.T.astype", "mag.T.astype.T.astype", "numpy.log10", "numpy.log10", "numpy.maximum", "numpy.maximum"], "function", ["None"], ["def", "get_spectrograms", "(", "fpath", ")", ":", "\n", "    ", "'''Parse the wave file in `fpath` and\n    Returns normalized melspectrogram and linear spectrogram.\n\n    Args:\n      fpath: A string. The full path of a sound file.\n\n    Returns:\n      mel: A 2d array of shape (T, n_mels) and dtype of float32.\n      mag: A 2d array of shape (T, 1+n_fft/2) and dtype of float32.\n    '''", "\n", "# Loading sound file", "\n", "y", ",", "sr", "=", "librosa", ".", "load", "(", "fpath", ",", "sr", "=", "hp", ".", "sr", ")", "\n", "\n", "# # Trimming", "\n", "# y, _ = librosa.effects.trim(y, top_db=40)", "\n", "\n", "# Preemphasis", "\n", "y", "=", "np", ".", "append", "(", "y", "[", "0", "]", ",", "y", "[", "1", ":", "]", "-", "hp", ".", "preemphasis", "*", "y", "[", ":", "-", "1", "]", ")", "\n", "\n", "# stft", "\n", "linear", "=", "librosa", ".", "stft", "(", "y", "=", "y", ",", "\n", "n_fft", "=", "hp", ".", "n_fft", ",", "\n", "hop_length", "=", "hp", ".", "hop_length", ",", "\n", "win_length", "=", "hp", ".", "win_length", ")", "\n", "\n", "# magnitude spectrogram", "\n", "mag", "=", "np", ".", "abs", "(", "linear", ")", "# (1+n_fft//2, T)", "\n", "\n", "# mel spectrogram", "\n", "mel_basis", "=", "librosa", ".", "filters", ".", "mel", "(", "hp", ".", "sr", ",", "hp", ".", "n_fft", ",", "hp", ".", "n_mels", ")", "# (n_mels, 1+n_fft//2)", "\n", "mel", "=", "np", ".", "dot", "(", "mel_basis", ",", "mag", ")", "# (n_mels, t)", "\n", "\n", "# to decibel", "\n", "mel", "=", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "mel", ")", ")", "\n", "mag", "=", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "1e-5", ",", "mag", ")", ")", "\n", "\n", "# normalize", "\n", "mel", "=", "np", ".", "clip", "(", "(", "mel", "-", "hp", ".", "ref_db", "+", "hp", ".", "max_db", ")", "/", "hp", ".", "max_db", ",", "1e-8", ",", "1", ")", "\n", "mag", "=", "np", ".", "clip", "(", "(", "mag", "-", "hp", ".", "ref_db", "+", "hp", ".", "max_db", ")", "/", "hp", ".", "max_db", ",", "1e-8", ",", "1", ")", "\n", "\n", "# Transpose", "\n", "mel", "=", "mel", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", "# (T, n_mels)", "\n", "mag", "=", "mag", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", "# (T, 1+n_fft//2)", "\n", "\n", "return", "mel", ",", "mag", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.spectrogram2wav": [[63, 92], ["numpy.power", "utils.griffin_lim", "scipy.signal.lfilter", "librosa.effects.trim", "signal.lfilter.astype", "numpy.clip"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.griffin_lim", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.trim"], ["", "def", "spectrogram2wav", "(", "mag", ")", ":", "\n", "    ", "'''# Generate wave file from linear magnitude spectrogram\n\n    Args:\n      mag: A numpy array of (T, 1+n_fft//2)\n\n    Returns:\n      wav: A 1-D numpy array.\n    '''", "\n", "# transpose", "\n", "mag", "=", "mag", ".", "T", "\n", "\n", "# de-noramlize", "\n", "mag", "=", "(", "np", ".", "clip", "(", "mag", ",", "0", ",", "1", ")", "*", "hp", ".", "max_db", ")", "-", "hp", ".", "max_db", "+", "hp", ".", "ref_db", "\n", "\n", "# to amplitude", "\n", "mag", "=", "np", ".", "power", "(", "10.0", ",", "mag", "*", "0.05", ")", "\n", "\n", "# wav reconstruction", "\n", "wav", "=", "griffin_lim", "(", "mag", "**", "hp", ".", "power", ")", "\n", "\n", "# de-preemphasis", "\n", "wav", "=", "signal", ".", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "hp", ".", "preemphasis", "]", ",", "wav", ")", "\n", "\n", "# trim", "\n", "wav", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "wav", ",", "top_db", "=", "40", ")", "\n", "# wav = trim(wav)", "\n", "\n", "return", "wav", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.griffin_lim": [[93, 105], ["copy.deepcopy", "range", "utils.invert_spectrogram", "numpy.real", "utils.invert_spectrogram", "librosa.stft", "numpy.maximum", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.invert_spectrogram", "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.invert_spectrogram"], ["", "def", "griffin_lim", "(", "spectrogram", ")", ":", "\n", "    ", "'''Applies Griffin-Lim's raw.'''", "\n", "X_best", "=", "copy", ".", "deepcopy", "(", "spectrogram", ")", "\n", "for", "i", "in", "range", "(", "hp", ".", "n_iter", ")", ":", "\n", "        ", "X_t", "=", "invert_spectrogram", "(", "X_best", ")", "\n", "est", "=", "librosa", ".", "stft", "(", "X_t", ",", "hp", ".", "n_fft", ",", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ")", "\n", "phase", "=", "est", "/", "np", ".", "maximum", "(", "1e-8", ",", "np", ".", "abs", "(", "est", ")", ")", "\n", "X_best", "=", "spectrogram", "*", "phase", "\n", "", "X_t", "=", "invert_spectrogram", "(", "X_best", ")", "\n", "y", "=", "np", ".", "real", "(", "X_t", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.invert_spectrogram": [[106, 112], ["librosa.istft"], "function", ["None"], ["", "def", "invert_spectrogram", "(", "spectrogram", ")", ":", "\n", "    ", "'''Applies inverse fft.\n    Args:\n      spectrogram: [1+n_fft//2, t]\n    '''", "\n", "return", "librosa", ".", "istft", "(", "spectrogram", ",", "hp", ".", "hop_length", ",", "win_length", "=", "hp", ".", "win_length", ",", "window", "=", "\"hann\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.plot_alignment": [[113, 129], ["matplotlib.subplots", "ax.imshow", "fig.colorbar", "matplotlib.title", "matplotlib.savefig", "os.path.exists", "os.mkdir"], "function", ["None"], ["", "def", "plot_alignment", "(", "alignment", ",", "gs", ",", "dir", "=", "hp", ".", "logdir", ")", ":", "\n", "    ", "\"\"\"Plots the alignment.\n\n    Args:\n      alignment: A numpy array with shape of (encoder_steps, decoder_steps)\n      gs: (int) global step.\n      dir: Output path.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "os", ".", "mkdir", "(", "dir", ")", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "alignment", ")", "\n", "\n", "fig", ".", "colorbar", "(", "im", ")", "\n", "plt", ".", "title", "(", "'{} Steps'", ".", "format", "(", "gs", ")", ")", "\n", "plt", ".", "savefig", "(", "'{}/alignment_{}.png'", ".", "format", "(", "dir", ",", "gs", ")", ",", "format", "=", "'png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.guided_attention": [[130, 138], ["numpy.ones", "range", "range", "numpy.exp", "float", "float"], "function", ["None"], ["", "def", "guided_attention", "(", "n", ",", "t", ",", "g", "=", "0.2", ")", ":", "\n", "    ", "'''Guided attention. Refer to page 3 on the paper.'''", "\n", "gt", "=", "np", ".", "ones", "(", "(", "hp", ".", "max_N", ",", "hp", ".", "max_T", ")", ",", "np", ".", "float32", ")", "\n", "for", "n_pos", "in", "range", "(", "n", ")", ":", "\n", "        ", "for", "t_pos", "in", "range", "(", "t", ")", ":", "\n", "            ", "gt", "[", "n_pos", ",", "t_pos", "]", "=", "1", "-", "np", ".", "exp", "(", "-", "(", "t_pos", "/", "float", "(", "t", ")", "-", "n_pos", "/", "float", "(", "n", ")", ")", "**", "2", "/", "(", "2", "*", "g", "*", "g", ")", ")", "\n", "\n", "", "", "return", "gt", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.learning_rate_decay": [[139, 143], ["tensorflow.to_float", "tensorflow.minimum"], "function", ["None"], ["", "def", "learning_rate_decay", "(", "init_lr", ",", "global_step", ",", "warmup_steps", "=", "4000.0", ")", ":", "\n", "    ", "'''Noam scheme from tensor2tensor'''", "\n", "step", "=", "tf", ".", "to_float", "(", "global_step", "+", "1", ")", "\n", "return", "init_lr", "*", "warmup_steps", "**", "0.5", "*", "tf", ".", "minimum", "(", "step", "*", "warmup_steps", "**", "-", "1.5", ",", "step", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_spectrograms": [[144, 162], ["os.path.basename", "utils.get_spectrograms", "numpy.pad", "numpy.pad"], "function", ["home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.get_spectrograms"], ["", "def", "load_spectrograms", "(", "fpath", ")", ":", "\n", "    ", "'''Read the wave file in `fpath`\n    and extracts spectrograms'''", "\n", "\n", "fname", "=", "os", ".", "path", ".", "basename", "(", "fpath", ")", "\n", "mel", ",", "mag", "=", "get_spectrograms", "(", "fpath", ")", "\n", "t", "=", "mel", ".", "shape", "[", "0", "]", "\n", "\n", "# Marginal padding for reduction shape sync.", "\n", "num_paddings", "=", "hp", ".", "r", "-", "(", "t", "%", "hp", ".", "r", ")", "if", "t", "%", "hp", ".", "r", "!=", "0", "else", "0", "\n", "mel", "=", "np", ".", "pad", "(", "mel", ",", "[", "[", "0", ",", "num_paddings", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"constant\"", ")", "\n", "mag", "=", "np", ".", "pad", "(", "mag", ",", "[", "[", "0", ",", "num_paddings", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"constant\"", ")", "\n", "\n", "# Reduction", "\n", "mel", "=", "mel", "[", ":", ":", "hp", ".", "r", ",", ":", "]", "\n", "t", "=", "mel", ".", "shape", "[", "0", "]", "\n", "\n", "return", "fname", ",", "mel", ",", "mag", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.trim": [[165, 172], ["int", "int", "librosa.effects.split"], "function", ["None"], ["", "def", "trim", "(", "wav", ",", "top_db", "=", "40", ",", "min_silence_sec", "=", "0.8", ")", ":", "\n", "    ", "frame_length", "=", "int", "(", "hp", ".", "sr", "*", "min_silence_sec", ")", "\n", "hop_length", "=", "int", "(", "frame_length", "/", "4", ")", "\n", "endpoint", "=", "librosa", ".", "effects", ".", "split", "(", "wav", ",", "frame_length", "=", "frame_length", ",", "\n", "hop_length", "=", "hop_length", ",", "\n", "top_db", "=", "top_db", ")", "[", "0", ",", "1", "]", "\n", "return", "wav", "[", ":", "endpoint", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2hcj": [[173, 187], ["len", "len", "zip"], "function", ["None"], ["", "def", "load_j2hcj", "(", ")", ":", "\n", "    ", "'''\n    Arg:\n      jamo: A Hangul Jamo character(0x01100-0x011FF)\n    Returns:\n      A dictionary that converts jamo into Hangul Compatibility Jamo(0x03130 - 0x0318F) Character\n    '''", "\n", "j", "=", "'\u1100\u1101\u1102\u1103\u1104\u1105\u1106\u1107\u1108\u1109\u110a\u110b\u110c\u110d\u110e\u110f\u1110\u1111\u1112\u114c\u1161\u1162\u1163\u1164\u1165\u1166\u1167\u1168\u1169\u116a\u116b\u116c\u116d\u116e\u116f\u1170\u1171\u1172'", "'\u1173\u1174\u1175\u11a8\u11a9\u11ab\u11ac\u11ad\u11ae\u11af\u11b0\u11b1\u11b2\u11b4\u11b6\u11b7\u11b8\u11b9\u11ba\u11bb\u11bc\u11bd\u11be\u11bf\u11c0\u11c1\u11c2\u119e'", "\n", "hcj", "=", "'\u3131\u3132\u3134\u3137\u3138\u3139\u3141\u3142\u3143\u3145\u3146\u3147\u3148\u3149\u314a\u314b\u314c\u314d\u314e\u3147\u314f\u3150\u3151\u3152\u3153\u3154\u3155\u3156\u3157\u3158\u3159\u315a\u315b\u315c\u315d\u315e\u315f\u3160'", "'\u3161\u3162\u3163\u3131\u3132\u3134\u3135\u3136\u3137\u3139\u313a\u313b\u313c\u313e\u3140\u3141\u3142\u3144\u3145\u3146\u3147\u3148\u314a\u314b\u314c\u314d\u314e\u318d'", "\n", "assert", "len", "(", "j", ")", "==", "len", "(", "hcj", ")", "\n", "j2hcj", "=", "{", "j_", ":", "hcj_", "for", "j_", ",", "hcj_", "in", "zip", "(", "j", ",", "hcj", ")", "}", "\n", "return", "j2hcj", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2sj": [[188, 200], ["len", "len", "sj.split", "zip", "sj.split"], "function", ["None"], ["", "def", "load_j2sj", "(", ")", ":", "\n", "    ", "'''\n    Arg:\n      jamo: A Hangul Jamo character(0x01100-0x011FF)\n    Returns:\n      A dictionary that decomposes double consonants into two single consonants.\n    '''", "\n", "j", "=", "'\u1101\u1104\u1108\u110a\u110d\u11a9\u11ac\u11ad\u11b0\u11b1\u11b2\u11b4\u11b6\u11b9\u11bb'", "\n", "sj", "=", "'\u1100\u1100|\u1103\u1103|\u1107\u1107|\u1109\u1109|\u110c\u110c|\u11a8\u11a8|\u11ab\u11bd|\u11ab\u11c2|\u11af\u11a8|\u11af\u11b7|\u11af\u11b8|\u11af\u11c0|\u11af\u11c2|\u11b8\u11ba|\u11ba\u11ba'", "\n", "assert", "len", "(", "j", ")", "==", "len", "(", "sj", ".", "split", "(", "\"|\"", ")", ")", "\n", "j2sj", "=", "{", "j_", ":", "sj_", "for", "j_", ",", "sj_", "in", "zip", "(", "j", ",", "sj", ".", "split", "(", "\"|\"", ")", ")", "}", "\n", "return", "j2sj", "\n", "\n"]], "home.repos.pwc.inspect_result.kakaobrain_jejueo.speech.utils.load_j2shcj": [[201, 217], ["len", "len", "shcj.split", "zip", "shcj.split"], "function", ["None"], ["", "def", "load_j2shcj", "(", ")", ":", "\n", "    ", "'''\n    Arg:\n      jamo: A Hangul Jamo character(0x01100-0x011FF)\n    Returns:\n      A dictionary that converts jamo into Hangul Compatibility Jamo(0x03130 - 0x0318F) Character.\n      Double consonants are further decomposed into single consonants.\n    '''", "\n", "j", "=", "'\u1100\u1101\u1102\u1103\u1104\u1105\u1106\u1107\u1108\u1109\u110a\u110b\u110c\u110d\u110e\u110f\u1110\u1111\u1112\u114c\u1161\u1162\u1163\u1164\u1165\u1166\u1167\u1168\u1169\u116a\u116b\u116c\u116d\u116e\u116f\u1170\u1171\u1172'", "'\u1173\u1174\u1175\u11a8\u11a9\u11ab\u11ac\u11ad\u11ae\u11af\u11b0\u11b1\u11b2\u11b4\u11b6\u11b7\u11b8\u11b9\u11ba\u11bb\u11bc\u11bd\u11be\u11bf\u11c0\u11c1\u11c2\u119e'", "\n", "shcj", "=", "'\u3131|\u3131\u3131|\u3134|\u3137|\u3137\u3137|\u3139|\u3141|\u3142|\u3142\u3142|\u3145|\u3145\u3145|\u3147|\u3148|\u3148\u3148|\u314a|\u314b|\u314c|\u314d|\u314e|\u3147|\u314f|\u3150|\u3151|\u3152|\u3153|\u3154|\u3155|\u3156|\u3157|\u3158|\u3159|\u315a|\u315b|\u315c|\u315d|\u315e|\u315f|\u3160|'", "'\u3161|\u3162|\u3163|\u3131|\u3131\u3131|\u3134|\u3134\u3148|\u3134\u314e|\u3137|\u3139|\u3139\u3131|\u3139\u3141|\u3139\u3142|\u3139\u314c|\u3139\u314e|\u3141|\u3142|\u3142\u3145|\u3145|\u3145\u3145|\u3147|\u3148|\u314a|\u314b|\u314c|\u314d|\u314e|\u318d'", "\n", "\n", "assert", "len", "(", "j", ")", "==", "len", "(", "shcj", ".", "split", "(", "\"|\"", ")", ")", "\n", "j2shcj", "=", "{", "j_", ":", "shcj_", "for", "j_", ",", "shcj_", "in", "zip", "(", "j", ",", "shcj", ".", "split", "(", "\"|\"", ")", ")", "}", "\n", "return", "j2shcj", "", "", ""]]}