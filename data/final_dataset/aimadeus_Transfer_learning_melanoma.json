{"home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.MelanomaDataset.__init__": [[109, 131], ["albumentations.Compose", "albumentations.Compose", "albumentations.RandomResizedCrop", "albumentations.ShiftScaleRotate", "albumentations.HorizontalFlip", "albumentations.VerticalFlip", "albumentations.HueSaturationValue", "albumentations.RandomBrightnessContrast", "albumentations.pytorch.ToTensor", "albumentations.Resize", "albumentations.pytorch.ToTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataframe", ",", "vertical_flip", ",", "horizontal_flip", ",", "\n", "is_train", "=", "True", ")", ":", "\n", "        ", "self", ".", "dataframe", ",", "self", ".", "is_train", "=", "dataframe", ",", "is_train", "\n", "self", ".", "vertical_flip", ",", "self", ".", "horizontal_flip", "=", "vertical_flip", ",", "horizontal_flip", "\n", "\n", "# Data Augmentation (custom for each dataset type)", "\n", "if", "is_train", ":", "\n", "            ", "self", ".", "transform", "=", "Compose", "(", "[", "RandomResizedCrop", "(", "height", "=", "224", ",", "width", "=", "224", ",", "scale", "=", "(", "0.7", ",", "1.0", ")", ")", ",", "\n", "ShiftScaleRotate", "(", "rotate_limit", "=", "90", ",", "scale_limit", "=", "[", "0.7", ",", "1", "]", ")", ",", "\n", "HorizontalFlip", "(", "p", "=", "self", ".", "horizontal_flip", ")", ",", "\n", "VerticalFlip", "(", "p", "=", "self", ".", "vertical_flip", ")", ",", "\n", "HueSaturationValue", "(", "sat_shift_limit", "=", "[", "0.7", ",", "1.3", "]", ",", "\n", "hue_shift_limit", "=", "[", "-", "0.1", ",", "0.1", "]", ")", ",", "\n", "RandomBrightnessContrast", "(", "brightness_limit", "=", "[", "0.01", ",", "0.1", "]", ",", "\n", "contrast_limit", "=", "[", "0.01", ",", "0.1", "]", ")", ",", "\n", "#Normalize(),", "\n", "ToTensor", "(", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform", "=", "Compose", "(", "[", "# Normalize(),", "\n", "Resize", "(", "height", "=", "224", ",", "width", "=", "224", ")", ",", "\n", "ToTensor", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.MelanomaDataset.__len__": [[133, 135], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataframe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.MelanomaDataset.__getitem__": [[137, 154], ["cv2.imread", "numpy.array", "train.MelanomaDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# Select path and read image", "\n", "        ", "image_path", "=", "self", ".", "dataframe", "[", "'path_jpg'", "]", "[", "index", "]", "\n", "image", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "\n", "# For this image also import .csv information (sex, age, anatomy)", "\n", "csv_data", "=", "np", ".", "array", "(", "self", ".", "dataframe", ".", "iloc", "[", "index", "]", "[", "[", "'sex'", ",", "'age'", ",", "'anatomy'", "]", "]", ".", "values", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# Apply transforms", "\n", "image", "=", "self", ".", "transform", "(", "image", "=", "image", ")", "\n", "\n", "# Extract image from dictionary", "\n", "image", "=", "image", "[", "'image'", "]", "\n", "\n", "# If train/valid: image + class | If test: only image", "\n", "return", "(", "image", ",", "csv_data", ")", ",", "self", ".", "dataframe", "[", "'target'", "]", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.ResNet50Network.__init__": [[157, 176], ["torch.Module.__init__", "torchvision.models.resnet50", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "no_columns", ",", "self", ".", "output_size", "=", "no_columns", ",", "output_size", "\n", "\n", "# Define Feature part (IMAGE)", "\n", "self", ".", "features", "=", "resnet50", "(", "pretrained", "=", "True", ")", "# 1000 neurons out", "\n", "# (CSV data)", "\n", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", "\n", "\n", "# Define Classification part", "\n", "self", ".", "classification", "=", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.ResNet50Network.forward": [[177, 198], ["train.ResNet50Network.features", "train.ResNet50Network.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.ResNet50Network.classification", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Image CNN", "\n", "image", "=", "self", ".", "features", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate layers from image with layers from csv_data", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'Out shape:'", ",", "out", ".", "shape", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.EfficientNetwork.__init__": [[201, 231], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "efficientnet_pytorch.EfficientNet.from_pretrained", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "efficientnet_pytorch.EfficientNet.from_pretrained", "efficientnet_pytorch.EfficientNet.from_pretrained", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ",", "b4", "=", "False", ",", "b2", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "b4", ",", "self", ".", "b2", ",", "self", ".", "no_columns", "=", "b4", ",", "b2", ",", "no_columns", "\n", "\n", "# Define Feature part (IMAGE)", "\n", "if", "b4", ":", "\n", "            ", "self", ".", "features", "=", "EfficientNet", ".", "from_pretrained", "(", "'efficientnet-b4'", ")", "\n", "", "elif", "b2", ":", "\n", "            ", "self", ".", "features", "=", "EfficientNet", ".", "from_pretrained", "(", "'efficientnet-b2'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "features", "=", "EfficientNet", ".", "from_pretrained", "(", "'efficientnet-b7'", ")", "\n", "\n", "# (CSV)", "\n", "", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", "\n", "\n", "# Define Classification part", "\n", "if", "b4", ":", "\n", "            ", "self", ".", "classification", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1792", "+", "250", ",", "output_size", ")", ")", "\n", "", "elif", "b2", ":", "\n", "            ", "self", ".", "classification", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1408", "+", "250", ",", "output_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classification", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2560", "+", "250", ",", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.EfficientNetwork.forward": [[232, 261], ["train.EfficientNetwork.features.extract_features", "train.EfficientNetwork.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.EfficientNetwork.classification", "print", "print", "F.avg_pool2d().reshape", "print", "print", "print", "F.avg_pool2d().reshape", "F.avg_pool2d().reshape", "F.avg_pool2d", "F.avg_pool2d", "F.avg_pool2d", "F.avg_pool2d().reshape.size", "F.avg_pool2d().reshape.size", "F.avg_pool2d().reshape.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# IMAGE CNN", "\n", "image", "=", "self", ".", "features", ".", "extract_features", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "if", "self", ".", "b4", ":", "\n", "            ", "image", "=", "F", ".", "avg_pool2d", "(", "image", ",", "image", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "reshape", "(", "-", "1", ",", "1792", ")", "\n", "", "elif", "self", ".", "b2", ":", "\n", "            ", "image", "=", "F", ".", "avg_pool2d", "(", "image", ",", "image", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "reshape", "(", "-", "1", ",", "1408", ")", "\n", "", "else", ":", "\n", "            ", "image", "=", "F", ".", "avg_pool2d", "(", "image", ",", "image", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "reshape", "(", "-", "1", ",", "2560", ")", "\n", "", "if", "prints", ":", "print", "(", "'Image Reshaped shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'Out shape:'", ",", "out", ".", "shape", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.DenseNetNetwork.__init__": [[264, 281], ["torch.Module.__init__", "torchvision.models.densenet161", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "no_columns", ",", "self", ".", "output_size", "=", "no_columns", ",", "output_size", "\n", "# Define Feature part (IMAGE)", "\n", "self", ".", "features", "=", "densenet161", "(", "pretrained", "=", "True", ")", "\n", "# (CSV data)", "\n", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", "\n", "# Define Classification part", "\n", "self", ".", "classification", "=", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.DenseNetNetwork.forward": [[282, 303], ["train.DenseNetNetwork.features", "train.DenseNetNetwork.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.DenseNetNetwork.classification", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Image CNN", "\n", "image", "=", "self", ".", "features", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate layers from image with layers from csv_data", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'Out shape:'", ",", "out", ".", "shape", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.SqueezeNet.__init__": [[306, 323], ["torch.Module.__init__", "torchvision.models.squeezenet1_0", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "no_columns", ",", "self", ".", "output_size", "=", "no_columns", ",", "output_size", "\n", "# Define Feature part (IMAGE)", "\n", "self", ".", "features", "=", "squeezenet1_0", "(", "pretrained", "=", "True", ")", "\n", "# (CSV data)", "\n", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", "\n", "# Define Classification part", "\n", "self", ".", "classification", "=", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.SqueezeNet.forward": [[324, 345], ["train.SqueezeNet.features", "train.SqueezeNet.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.SqueezeNet.classification", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Image CNN", "\n", "image", "=", "self", ".", "features", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate layers from image with layers from csv_data", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'Out shape:'", ",", "out", ".", "shape", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.custom_vgg16.__init__": [[349, 386], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg16", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg16_bn", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg19", "torchvision.models.vgg19_bn", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ",", "v16", "=", "True", ",", "v16_bn", "=", "False", ",", "v19", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "no_columns", ",", "self", ".", "output_size", "=", "no_columns", ",", "output_size", "\n", "self", ".", "v16", ",", "self", ".", "v16_bn", ",", "self", ".", "v19", "=", "v16", ",", "v16_bn", ",", "v19", "\n", "\n", "# Define Feature part (IMAGE)", "\n", "if", "v16", ":", "\n", "            ", "self", ".", "features", "=", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "", "elif", "v16_bn", ":", "\n", "            ", "self", ".", "features", "=", "vgg16_bn", "(", "pretrained", "=", "True", ")", "\n", "", "elif", "v19", ":", "\n", "            ", "self", ".", "features", "=", "vgg19", "(", "pretrained", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "features", "=", "vgg19_bn", "(", "pretrained", "=", "True", ")", "\n", "\n", "# (CSV)", "\n", "# keep this the same for all models you try", "\n", "", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", "\n", "\n", "# Define Classification part", "\n", "# you'll need to change 1792 to whatever size the model outputs in self.features.", "\n", "if", "v16", ":", "\n", "            ", "self", ".", "classification", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", ")", "\n", "", "elif", "v16_bn", ":", "\n", "            ", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", ")", "\n", "", "elif", "v19", ":", "\n", "            ", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "1000", "+", "250", ",", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.custom_vgg16.forward": [[387, 407], ["train.custom_vgg16.features", "train.custom_vgg16.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.custom_vgg16.classification", "print", "print", "print"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# IMAGE CNN", "\n", "image", "=", "self", ".", "features", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__": [[410, 459], ["torch.Module.__init__", "range", "torch.MaxPool2d().to", "torch.MaxPool2d().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Linear().to", "torch.Linear().to", "train.CustomNetwork.cnn_layers.append", "torch.Sequential().to", "torch.Sequential().to", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_size", ",", "no_columns", ",", "device", ",", "set_params", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "no_columns", "=", "no_columns", "\n", "self", ".", "n_layers", "=", "set_params", "[", "'n_layers'", "]", "\n", "self", ".", "conv_filters", "=", "set_params", "[", "'conv_filters'", "]", "\n", "self", ".", "kernel_size", "=", "set_params", "[", "'kernel_size'", "]", "\n", "self", ".", "pool_size", "=", "set_params", "[", "'pool_size'", "]", "\n", "self", ".", "dropout_rate", "=", "set_params", "[", "'dropout_rate'", "]", "\n", "\n", "self", ".", "cnn_layers", "=", "[", "]", "\n", "\n", "# CONV LAYERS", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "cnn_layers", ".", "append", "(", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", "if", "i", "==", "0", "else", "self", ".", "conv_filters", ",", "\n", "out_channels", "=", "self", ".", "conv_filters", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ")", ",", "\n", "# nn.BatchNorm2d(self.conv_filters),", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "dropout_rate", ")", "\n", ")", ".", "to", "(", "device", ")", ")", "\n", "\n", "", "self", ".", "max_pool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "self", ".", "pool_size", ")", ".", "to", "(", "device", ")", "\n", "\n", "# CSV data", "\n", "self", ".", "csv", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "no_columns", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ",", "\n", "\n", "nn", ".", "Linear", "(", "250", ",", "250", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "250", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.2", ")", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Classification part", "\n", "\n", "# calculating the right size for the linear layer", "\n", "# i = input_size", "\n", "# o = output", "\n", "# p = padding", "\n", "# k = kernel_size", "\n", "# s = stride", "\n", "# d = dilation", "\n", "# o = [i + 2*p - k - (k-1)*(d-1)]/s + 1", "\n", "# in our case, s=1, p=0, d=1, so for each layer o=i-(k-1)", "\n", "self", ".", "output_dimensions", "=", "(", "(", "224", "-", "self", ".", "n_layers", "*", "(", "\n", "self", ".", "kernel_size", "-", "1", ")", ")", "//", "self", ".", "pool_size", ")", "**", "2", "*", "self", ".", "conv_filters", "\n", "self", ".", "classification", "=", "nn", ".", "Linear", "(", "self", ".", "output_dimensions", "+", "250", ",", "output_size", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.CustomNetwork.forward": [[460, 491], ["range", "train.CustomNetwork.max_pool", "image.reshape.reshape.reshape", "train.CustomNetwork.csv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.CustomNetwork.classification", "print", "print", "print", "print", "print"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "csv_data", ",", "prints", "=", "False", ")", ":", "\n", "\n", "        ", "if", "prints", ":", "print", "(", "'Input Image shape:'", ",", "image", ".", "shape", ",", "'\\n'", "+", "\n", "'Input csv_data shape:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# IMAGE CNN", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "image", "=", "self", ".", "cnn_layers", "[", "i", "]", "(", "image", ")", "\n", "# print(image.shape)", "\n", "\n", "# one maxpool", "\n", "", "image", "=", "self", ".", "max_pool", "(", "image", ")", "\n", "if", "prints", ":", "print", "(", "'Features Image shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# not sure I like this average pool thing. Let's just Flatten() instead", "\n", "# image = F.avg_pool2d(image, image.size()[2:]).reshape(self.batch_size, -1)", "\n", "image", "=", "image", ".", "reshape", "(", "-", "1", ",", "self", ".", "output_dimensions", ")", "\n", "if", "prints", ":", "print", "(", "'Image Reshaped shape:'", ",", "image", ".", "shape", ")", "\n", "\n", "# CSV FNN", "\n", "csv_data", "=", "self", ".", "csv", "(", "csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'CSV Data:'", ",", "csv_data", ".", "shape", ")", "\n", "\n", "# Concatenate", "\n", "image_csv_data", "=", "torch", ".", "cat", "(", "(", "image", ",", "csv_data", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# CLASSIF", "\n", "out", "=", "self", ".", "classification", "(", "image_csv_data", ")", "\n", "if", "prints", ":", "print", "(", "'Out shape:'", ",", "out", ".", "shape", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.get_data": [[36, 106], ["pandas.read_csv", "pandas.read_csv", "roman_train[].fillna", "roman_train[].astype", "roman_train[].astype", "sklearn.preprocessing.LabelEncoder", "my_train[].unique", "pandas.concat", "train_df[].fillna", "sklearn.preprocessing.normalize", "sklearn.model_selection.train_test_split", "print", "sklearn.preprocessing.LabelEncoder.fit_transform", "encoded_all.append", "pd.read_csv.drop", "len", "roman_train[].isin", "len"], "function", ["None"], ["def", "get_data", "(", ")", ":", "\n", "# My Train: with imputed missing values + OHE", "\n", "    ", "my_train", "=", "pd", ".", "read_csv", "(", "'../input/siim-melanoma-prep-data/train_clean.csv'", ")", "\n", "\n", "# Drop path columns and Diagnosis (it won't be available during TEST)", "\n", "# We'll rewrite them once the data is concatenated", "\n", "to_drop", "=", "[", "'path_dicom'", ",", "'path_jpeg'", ",", "'diagnosis'", "]", "\n", "for", "drop", "in", "to_drop", ":", "\n", "        ", "if", "drop", "in", "my_train", ".", "columns", ":", "\n", "            ", "my_train", ".", "drop", "(", "[", "drop", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "\n", "# Roman's Train: with added data for Malignant category", "\n", "", "", "roman_train", "=", "pd", ".", "read_csv", "(", "'../input/../input/melanoma-external-malignant-256/train_concat.csv'", ")", "\n", "\n", "# --- Before concatenatenating both together, let's preprocess roman_train ---", "\n", "# Replace NAN with 0 for patient_id", "\n", "roman_train", "[", "'patient_id'", "]", "=", "roman_train", "[", "'patient_id'", "]", ".", "fillna", "(", "0", ")", "\n", "\n", "# OHE", "\n", "to_encode", "=", "[", "'sex'", ",", "'anatom_site_general_challenge'", "]", "\n", "encoded_all", "=", "[", "]", "\n", "\n", "roman_train", "[", "to_encode", "[", "0", "]", "]", "=", "roman_train", "[", "to_encode", "[", "0", "]", "]", ".", "astype", "(", "str", ")", "\n", "roman_train", "[", "to_encode", "[", "1", "]", "]", "=", "roman_train", "[", "to_encode", "[", "1", "]", "]", ".", "astype", "(", "str", ")", "\n", "\n", "label_encoder", "=", "LabelEncoder", "(", ")", "\n", "\n", "for", "column", "in", "to_encode", ":", "\n", "        ", "encoded", "=", "label_encoder", ".", "fit_transform", "(", "roman_train", "[", "column", "]", ")", "\n", "encoded_all", ".", "append", "(", "encoded", ")", "\n", "\n", "", "roman_train", "[", "to_encode", "[", "0", "]", "]", "=", "encoded_all", "[", "0", "]", "\n", "roman_train", "[", "to_encode", "[", "1", "]", "]", "=", "encoded_all", "[", "1", "]", "\n", "\n", "# Give all columns the same name", "\n", "roman_train", ".", "columns", "=", "my_train", ".", "columns", "\n", "\n", "# --- Concatenate info which is not available in my_train ---", "\n", "common_images", "=", "my_train", "[", "'dcm_name'", "]", ".", "unique", "(", ")", "\n", "new_data", "=", "roman_train", "[", "~", "roman_train", "[", "'dcm_name'", "]", ".", "isin", "(", "common_images", ")", "]", "\n", "\n", "# Merge all together", "\n", "train_df", "=", "pd", ".", "concat", "(", "[", "my_train", ",", "new_data", "]", ",", "axis", "=", "0", ")", "\n", "\n", "\n", "# Create path column to image folder for both Train and Test", "\n", "path_train", "=", "'../input/melanoma-external-malignant-256/train/train/'", "\n", "train_df", "[", "'path_jpg'", "]", "=", "path_train", "+", "train_df", "[", "'dcm_name'", "]", "+", "'.jpg'", "\n", "\n", "\n", "# --- Last final thing: NORMALIZE! ---", "\n", "train_df", "[", "'age'", "]", "=", "train_df", "[", "'age'", "]", ".", "fillna", "(", "-", "1", ")", "\n", "\n", "normalized_train", "=", "preprocessing", ".", "normalize", "(", "train_df", "[", "[", "'sex'", ",", "'age'", ",", "'anatomy'", "]", "]", ")", "\n", "\n", "train_df", "[", "'sex'", "]", "=", "normalized_train", "[", ":", ",", "0", "]", "\n", "train_df", "[", "'age'", "]", "=", "normalized_train", "[", ":", ",", "1", "]", "\n", "train_df", "[", "'anatomy'", "]", "=", "normalized_train", "[", ":", ",", "2", "]", "\n", "\n", "train_df", ",", "test_df", "=", "model_selection", ".", "train_test_split", "(", "\n", "train_df", ",", "\n", "train_size", "=", "0.8", ",", "\n", "test_size", "=", "0.2", ",", "\n", "random_state", "=", "8", "# make sure train and test are always the same", "\n", ")", "\n", "\n", "print", "(", "'Train: {:,}'", ".", "format", "(", "len", "(", "train_df", ")", ")", ",", "'\\n'", "+", "\n", "'Test: {:,}'", ".", "format", "(", "len", "(", "test_df", ")", ")", ")", "\n", "\n", "return", "train_df", ",", "test_df", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.compute_metrics": [[493, 499], ["sklearn.metrics.accuracy_score", "sklearn.metrics.roc_auc_score", "sklearn.metrics.average_precision_score", "sklearn.metrics.f1_score"], "function", ["None"], ["", "", "def", "compute_metrics", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "acc", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "roc", "=", "roc_auc_score", "(", "y_true", ",", "y_pred", ")", "\n", "prc", "=", "average_precision_score", "(", "y_true", ",", "y_pred", ")", "\n", "f1", "=", "f1_score", "(", "y_true", ",", "y_pred", ")", "\n", "return", "acc", ",", "roc", ",", "prc", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.train_folds": [[501, 693], ["len", "sklearn.model_selection.GroupKFold", "sklearn.model_selection.GroupKFold.split", "enumerate", "print", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.BCEWithLogitsLoss", "train_df.iloc[].reset_index", "train_df.iloc[].reset_index", "train.MelanomaDataset", "train.MelanomaDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "range", "print", "training_model.eval", "test_df.reset_index.reset_index", "train.MelanomaDataset", "torch.utils.data.DataLoader", "torch.zeros", "torch.zeros", "gc.collect", "numpy.zeros", "train_df[].tolist", "open", "print", "training_model.parameters", "time.time", "training_model.train", "training_model.eval", "torch.zeros", "torch.zeros", "torch.no_grad", "torch.no_grad", "enumerate", "train.compute_metrics", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.optim.Adam.zero_grad", "training_model", "nn.BCEWithLogitsLoss.", "criterion.backward", "torch.optim.Adam.step", "criterion.item", "torch.round", "torch.round", "len", "torch.no_grad", "torch.no_grad", "enumerate", "train.compute_metrics", "print", "torch.optim.lr_scheduler.ReduceLROnPlateau.step", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "training_model", "torch.sigmoid", "torch.sigmoid", "torch.round", "torch.round", "open", "csv.writer", "csv.writer.writerow", "open", "numpy.expand_dims().astype", "torch.zeros.data.cpu().numpy", "numpy.savetxt", "np.expand_dims().astype.unsqueeze", "torch.sigmoid", "torch.sigmoid", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "training_model", "torch.sigmoid", "torch.sigmoid", "torch.round", "torch.round", "str", "open", "print", "torch.save", "torch.save", "glob.glob", "torch.save", "torch.save", "len", "torch.zeros.cpu", "numpy.concatenate", "len", "torch.zeros.cpu", "datetime.timedelta", "training_model.state_dict", "os.remove", "training_model.state_dict", "print", "numpy.expand_dims", "torch.zeros.data.cpu", "open", "print", "torch.round.cpu", "np.expand_dims().astype.cpu().unsqueeze", "time.time", "np.expand_dims().astype.cpu"], "function", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.compute_metrics", "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.compute_metrics"], ["", "def", "train_folds", "(", "model", ",", "train_df", ",", "test_df", ",", "version", "=", "'v1'", ",", "set_params", "=", "None", ",", "debug", "=", "False", ")", ":", "\n", "\n", "    ", "if", "debug", ":", "\n", "        ", "train_df", "=", "train_df", "[", ":", "100", "]", "\n", "test_df", "=", "test_df", "[", ":", "100", "]", "\n", "", "train_len", "=", "len", "(", "train_df", ")", "\n", "\n", "# Create Object", "\n", "group_fold", "=", "GroupKFold", "(", "n_splits", "=", "set_params", "[", "'K'", "]", ")", "\n", "\n", "# Generate indices to split data into training and test set.", "\n", "folds", "=", "group_fold", ".", "split", "(", "X", "=", "np", ".", "zeros", "(", "train_len", ")", ",", "\n", "y", "=", "train_df", "[", "'target'", "]", ",", "\n", "groups", "=", "train_df", "[", "'ID'", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "for", "fold", ",", "(", "train_index", ",", "valid_index", ")", "in", "enumerate", "(", "folds", ")", ":", "\n", "# Append to .txt", "\n", "        ", "with", "open", "(", "f\"logs_{version}_fold{fold}.txt\"", ",", "'a+'", ")", "as", "f", ":", "\n", "            ", "print", "(", "'-'", "*", "10", ",", "'Fold:'", ",", "fold", "+", "1", ",", "'-'", "*", "10", ",", "file", "=", "f", ")", "\n", "", "print", "(", "'-'", "*", "10", ",", "'Fold:'", ",", "fold", "+", "1", ",", "'-'", "*", "10", ")", "\n", "\n", "# --- Create Instances ---", "\n", "# Best ROC score in this fold", "\n", "best_roc", "=", "None", "\n", "# Reset patience before every fold", "\n", "patience_f", "=", "set_params", "[", "'patience'", "]", "\n", "\n", "# Initiate the model", "\n", "training_model", "=", "model", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "training_model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "set_params", "[", "'learning_rate'", "]", ",", "# learning_rate,", "\n", "weight_decay", "=", "set_params", "[", "'weight_decay'", "]", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "mode", "=", "'max'", ",", "\n", "patience", "=", "set_params", "[", "'lr_patience'", "]", ",", "verbose", "=", "True", ",", "factor", "=", "set_params", "[", "'lr_factor'", "]", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "# --- Read in Data ---", "\n", "train_data", "=", "train_df", ".", "iloc", "[", "train_index", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "valid_data", "=", "train_df", ".", "iloc", "[", "valid_index", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# Create Data instances", "\n", "train", "=", "MelanomaDataset", "(", "train_data", ",", "vertical_flip", "=", "set_params", "[", "'vertical_flip'", "]", ",", "horizontal_flip", "=", "set_params", "[", "'horizontal_flip'", "]", ",", "\n", "is_train", "=", "True", ")", "\n", "valid", "=", "MelanomaDataset", "(", "valid_data", ",", "vertical_flip", "=", "set_params", "[", "'vertical_flip'", "]", ",", "horizontal_flip", "=", "set_params", "[", "'horizontal_flip'", "]", ",", "\n", "is_train", "=", "False", ")", "\n", "\n", "\n", "# Dataloaders", "\n", "train_loader", "=", "DataLoader", "(", "train", ",", "batch_size", "=", "set_params", "[", "'train_batch_size'", "]", ",", "shuffle", "=", "True", ",", "num_workers", "=", "set_params", "[", "'num_workers'", "]", ")", "\n", "# shuffle=False! Otherwise function won't work!!!", "\n", "# how do I know? ^^", "\n", "valid_loader", "=", "DataLoader", "(", "valid", ",", "batch_size", "=", "set_params", "[", "'val_test_batch_size'", "]", ",", "shuffle", "=", "False", ",", "num_workers", "=", "set_params", "[", "'num_workers'", "]", ")", "\n", "\n", "# === EPOCHS ===", "\n", "print", "(", "'training...'", ")", "\n", "for", "epoch", "in", "range", "(", "set_params", "[", "'epochs'", "]", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "correct", "=", "0", "\n", "train_losses", "=", "0", "\n", "\n", "# === TRAIN ===", "\n", "# Sets the module in training mode.", "\n", "training_model", ".", "train", "(", ")", "\n", "\n", "for", "(", "images", ",", "csv_data", ")", ",", "labels", "in", "train_loader", ":", "\n", "# Save them to device", "\n", "                ", "images", "=", "torch", ".", "tensor", "(", "images", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "csv_data", "=", "torch", ".", "tensor", "(", "csv_data", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Clear gradients first; very important, usually done BEFORE prediction", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Log Probabilities & Backpropagation", "\n", "out", "=", "training_model", "(", "images", ",", "csv_data", ")", "\n", "\n", "loss", "=", "criterion", "(", "out", ",", "labels", ".", "unsqueeze", "(", "1", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "# --- Save information after this batch ---", "\n", "# Save loss", "\n", "train_losses", "+=", "loss", ".", "item", "(", ")", "\n", "# From log probabilities to actual probabilities", "\n", "train_preds", "=", "torch", ".", "round", "(", "torch", ".", "sigmoid", "(", "out", ")", ")", "# 0 and 1", "\n", "# Number of correct predictions", "\n", "correct", "+=", "(", "train_preds", ".", "cpu", "(", ")", "==", "labels", ".", "cpu", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Compute Train Accuracy", "\n", "", "train_acc", "=", "correct", "/", "len", "(", "train_index", ")", "\n", "\n", "\n", "# === EVAL ===", "\n", "# Sets the model in evaluation mode", "\n", "training_model", ".", "eval", "(", ")", "\n", "\n", "# Create matrix to store evaluation predictions (for accuracy)", "\n", "valid_preds", "=", "torch", ".", "zeros", "(", "size", "=", "(", "len", "(", "valid_index", ")", ",", "1", ")", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Disables gradients (we need to be sure no optimization happens)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "k", ",", "(", "(", "images", ",", "csv_data", ")", ",", "labels", ")", "in", "enumerate", "(", "valid_loader", ")", ":", "\n", "                    ", "images", "=", "torch", ".", "tensor", "(", "images", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "csv_data", "=", "torch", ".", "tensor", "(", "csv_data", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "out", "=", "training_model", "(", "images", ",", "csv_data", ")", "\n", "pred", "=", "torch", ".", "sigmoid", "(", "out", ")", "\n", "valid_preds", "[", "k", "*", "images", ".", "shape", "[", "0", "]", ":", "k", "*", "images", ".", "shape", "[", "0", "]", "+", "images", ".", "shape", "[", "0", "]", "]", "=", "pred", "\n", "\n", "", "labels", "=", "valid_data", "[", "'target'", "]", ".", "values", "\n", "\n", "valid_acc", ",", "valid_roc", ",", "valid_prc", ",", "valid_f1", "=", "compute_metrics", "(", "labels", ",", "torch", ".", "round", "(", "valid_preds", ".", "cpu", "(", ")", ")", ")", "\n", "\n", "# Compute time on Train + Eval", "\n", "duration", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "[", ":", "7", "]", "\n", "\n", "# PRINT INFO", "\n", "# Append to .txt file", "\n", "with", "open", "(", "f\"logs_{version}_fold{fold}.txt\"", ",", "'a+'", ")", "as", "f", ":", "\n", "                    ", "print", "(", "'{} | Epoch: {}/{} | Loss: {:.4} | Train Acc: {:.3} | Valid Acc: {:.3} | ROC: {:.3}'", ".", "format", "(", "duration", ",", "epoch", "+", "1", ",", "set_params", "[", "'epochs'", "]", ",", "train_losses", ",", "train_acc", ",", "valid_acc", ",", "valid_roc", ")", ",", "file", "=", "f", ")", "\n", "# Print to console", "\n", "", "print", "(", "'{} | Epoch: {}/{} | Loss: {:.4} | Train Acc: {:.3} | Valid Acc: {:.3} | ROC: {:.3}'", ".", "format", "(", "duration", ",", "epoch", "+", "1", ",", "set_params", "[", "'epochs'", "]", ",", "train_losses", ",", "train_acc", ",", "valid_acc", ",", "valid_roc", ")", ")", "\n", "\n", "\n", "# === SAVE MODEL ===", "\n", "# Update scheduler (for learning_rate)", "\n", "scheduler", ".", "step", "(", "valid_roc", ")", "\n", "\n", "# Update best_roc", "\n", "if", "not", "best_roc", ":", "# If best_roc = None", "\n", "                    ", "best_roc", "=", "valid_roc", "\n", "torch", ".", "save", "(", "training_model", ".", "state_dict", "(", ")", ",", "\n", "f\"{version}_Fold{fold+1}_Epoch{epoch+1}_ValidAcc_{valid_acc:.3f}_ROC_{valid_roc:.3f}.pth\"", ")", "\n", "continue", "\n", "\n", "", "if", "valid_roc", ">", "best_roc", ":", "\n", "                    ", "best_roc", "=", "valid_roc", "\n", "# Reset patience (because we have improvement)", "\n", "patience_f", "=", "set_params", "[", "'patience'", "]", "\n", "for", "filename", "in", "glob", ".", "glob", "(", "f\"{version}_Fold*\"", ")", ":", "# remove all prev checkpoints for this model", "\n", "                        ", "os", ".", "remove", "(", "filename", ")", "\n", "", "torch", ".", "save", "(", "training_model", ".", "state_dict", "(", ")", ",", "\n", "f\"{version}_Fold{fold+1}_Epoch{epoch+1}_ValidAcc_{valid_acc:.3f}_ROC_{valid_roc:.3f}.pth\"", ")", "\n", "\n", "", "else", ":", "\n", "# Decrease patience (no improvement in ROC)", "\n", "                    ", "patience_f", "=", "patience_f", "-", "1", "\n", "if", "patience_f", "==", "0", ":", "\n", "                        ", "with", "open", "(", "f\"logs_{version}_fold{fold}.txt\"", ",", "'a+'", ")", "as", "f", ":", "\n", "                            ", "print", "(", "'Early stopping (no improvement since 3 models) | Best ROC: {}'", ".", "format", "(", "best_roc", ")", ",", "file", "=", "f", ")", "\n", "", "print", "(", "'Early stopping (no improvement since 3 models) | Best ROC: {}'", ".", "format", "(", "best_roc", ")", ")", "\n", "break", "\n", "\n", "\n", "# === INFERENCE ===", "\n", "", "", "", "", "print", "(", "'testing...'", ")", "\n", "training_model", ".", "eval", "(", ")", "\n", "test_df", "=", "test_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "test", "=", "MelanomaDataset", "(", "test_df", ",", "vertical_flip", "=", "set_params", "[", "'vertical_flip'", "]", ",", "horizontal_flip", "=", "set_params", "[", "'horizontal_flip'", "]", ",", "\n", "is_train", "=", "False", ")", "\n", "test_loader", "=", "DataLoader", "(", "test", ",", "batch_size", "=", "set_params", "[", "'val_test_batch_size'", "]", ",", "shuffle", "=", "False", ",", "num_workers", "=", "set_params", "[", "'num_workers'", "]", ")", "\n", "test_preds", "=", "torch", ".", "zeros", "(", "size", "=", "(", "len", "(", "test_df", ")", ",", "1", ")", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "k", ",", "(", "(", "images", ",", "csv_data", ")", ",", "labels", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "images", "=", "torch", ".", "tensor", "(", "images", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "csv_data", "=", "torch", ".", "tensor", "(", "csv_data", ",", "device", "=", "set_params", "[", "'device'", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "out", "=", "training_model", "(", "images", ",", "csv_data", ")", "\n", "pred", "=", "torch", ".", "sigmoid", "(", "out", ")", "\n", "test_preds", "[", "k", "*", "images", ".", "shape", "[", "0", "]", ":", "k", "*", "images", ".", "shape", "[", "0", "]", "+", "images", ".", "shape", "[", "0", "]", "]", "=", "pred", "\n", "\n", "# Compute accuracy", "\n", "", "labels", "=", "test_df", "[", "'target'", "]", ".", "values", "\n", "test_acc", ",", "test_roc", ",", "test_prc", ",", "test_f1", "=", "compute_metrics", "(", "labels", ",", "torch", ".", "round", "(", "test_preds", ".", "cpu", "(", ")", ")", ")", "\n", "with", "open", "(", "f\"results_{version}.csv\"", ",", "'a+'", ")", "as", "h", ":", "# append", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "h", ")", "\n", "writer", ".", "writerow", "(", "[", "test_acc", ",", "test_roc", ",", "test_prc", ",", "test_f1", "]", ")", "\n", "", "with", "open", "(", "f\"preds_{version}_fold{fold}.txt\"", ",", "'w+'", ")", "as", "g", ":", "\n", "                ", "labels", "=", "np", ".", "expand_dims", "(", "labels", ",", "1", ")", ".", "astype", "(", "float", ")", "\n", "arr", "=", "test_preds", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "savetxt", "(", "g", ",", "np", ".", "concatenate", "(", "[", "labels", ",", "arr", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# === CLEANING ===", "\n", "# Clear memory", "\n", "", "", "del", "train", ",", "valid", ",", "train_loader", ",", "valid_loader", ",", "images", ",", "labels", "\n", "# Garbage collector", "\n", "gc", ".", "collect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.main": [[695, 737], ["torch.device", "torch.device", "print", "train.get_data", "train.train_folds", "ResNet50Network().to", "torch.cuda.is_available", "torch.cuda.is_available", "custom_vgg16().to", "train.ResNet50Network", "EfficientNetwork().to", "train.custom_vgg16", "DenseNetNetwork().to", "train.EfficientNetwork", "CustomNetwork().to", "train.DenseNetNetwork", "train.CustomNetwork"], "function", ["home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.get_data", "home.repos.pwc.inspect_result.aimadeus_Transfer_learning_melanoma.None.train.train_folds"], ["", "", "def", "main", "(", "model_type", "=", "None", ")", ":", "\n", "\n", "    ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "print", "(", "'Device available now:'", ",", "device", ")", "\n", "\n", "set_params", "=", "{", "\n", "'device'", ":", "device", ",", "\n", "'epochs'", ":", "15", ",", "\n", "'K'", ":", "10", ",", "\n", "'patience'", ":", "3", ",", "\n", "'TTA'", ":", "3", ",", "\n", "'num_workers'", ":", "8", ",", "\n", "'learning_rate'", ":", "0.0005", ",", "\n", "'weight_decay'", ":", "0.0", ",", "\n", "'lr_patience'", ":", "1", ",", "\n", "'lr_factor'", ":", "0.4", ",", "\n", "'train_batch_size'", ":", "64", ",", "\n", "'val_test_batch_size'", ":", "64", ",", "\n", "'vertical_flip'", ":", "0.5", ",", "\n", "'horizontal_flip'", ":", "0.5", ",", "\n", "'csv_columns'", ":", "[", "'sex'", ",", "'age'", ",", "'anatomy'", "]", "\n", "}", "\n", "\n", "if", "model_type", "==", "'resnet'", ":", "\n", "        ", "model", "=", "ResNet50Network", "(", "output_size", "=", "1", ",", "no_columns", "=", "3", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "model_type", "==", "'vgg'", ":", "\n", "        ", "model", "=", "custom_vgg16", "(", "output_size", "=", "1", ",", "no_columns", "=", "3", ",", "v16", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "model_type", "==", "'efficient'", ":", "\n", "        ", "model", "=", "EfficientNetwork", "(", "output_size", "=", "1", ",", "no_columns", "=", "3", ",", "b4", "=", "False", ",", "b2", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "model_type", "==", "'dense'", ":", "\n", "        ", "model", "=", "DenseNetNetwork", "(", "output_size", "=", "1", ",", "no_columns", "=", "3", ")", ".", "to", "(", "device", ")", "\n", "", "elif", "model_type", "==", "'custom'", ":", "\n", "        ", "set_params", "[", "'learning_rate'", "]", "=", "0.00977", "\n", "set_params", "[", "'n_layers'", "]", "=", "5", "\n", "set_params", "[", "'batch_size'", "]", "=", "8", "\n", "set_params", "[", "'conv_filters'", "]", "=", "11", "\n", "set_params", "[", "'kernel_size'", "]", "=", "4", "\n", "set_params", "[", "'pool_size'", "]", "=", "3", "\n", "set_params", "[", "'dropout_rate'", "]", "=", "0.4", "\n", "model", "=", "CustomNetwork", "(", "output_size", "=", "1", ",", "no_columns", "=", "3", ",", "device", "=", "device", ",", "set_params", "=", "set_params", ")", ".", "to", "(", "device", ")", "\n", "", "train_df", ",", "test_df", "=", "get_data", "(", ")", "\n", "train_folds", "(", "model", ",", "train_df", ",", "test_df", ",", "version", "=", "model_type", ",", "set_params", "=", "set_params", ",", "debug", "=", "True", ")", "\n", "\n"]]}