{"home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.SingleLabelSampler.__init__": [[15, 19], ["rand.shuffle", "enumerate"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ":", "Dataset", ",", "label_to_keep", ":", "int", ",", "shuffle", ":", "bool", "=", "False", ",", "rand", ":", "random", ".", "Random", "=", "None", ")", ":", "\n", "        ", "self", ".", "matching_indices", "=", "[", "i", "for", "(", "i", ",", "(", "_", ",", "_", ",", "_", ",", "label", ",", "_", ")", ")", "in", "enumerate", "(", "dataset", ")", "if", "label", "==", "label_to_keep", "]", "\n", "if", "shuffle", ":", "\n", "            ", "rand", ".", "shuffle", "(", "self", ".", "matching_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.SingleLabelSampler.__iter__": [[20, 23], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# Convert the list of indices to a generator.", "\n", "        ", "return", "(", "i", "for", "i", "in", "self", ".", "matching_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.SingleLabelSampler.__len__": [[24, 26], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "matching_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.__init__": [[64, 101], ["random.Random", "balanced_batch_sampler.SingleLabelSampler", "balanced_batch_sampler.SingleLabelSampler", "len", "isinstance", "ValueError", "isinstance", "ValueError", "len", "len", "ValueError", "isinstance", "round"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ":", "Dataset", ",", "batch_size", ":", "int", ",", "drop_last", ":", "bool", ",", "shuffle", ":", "bool", "=", "True", ",", "seed", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "if", "not", "isinstance", "(", "batch_size", ",", "int", ")", "or", "isinstance", "(", "batch_size", ",", "bool", ")", "or", "batch_size", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size should be a positive integer value, \"", "\n", "\"but got batch_size={}\"", ".", "format", "(", "batch_size", ")", ")", "\n", "", "if", "not", "isinstance", "(", "drop_last", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"drop_last should be a boolean value, but got \"", "\n", "\"drop_last={}\"", ".", "format", "(", "drop_last", ")", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "rand", "=", "random", ".", "Random", "(", "seed", ")", "\n", "self", ".", "pos_sampler", "=", "SingleLabelSampler", "(", "dataset", ",", "label_to_keep", "=", "1", ",", "shuffle", "=", "shuffle", ",", "rand", "=", "self", ".", "rand", ")", "\n", "self", ".", "neg_sampler", "=", "SingleLabelSampler", "(", "dataset", ",", "label_to_keep", "=", "0", ",", "shuffle", "=", "shuffle", ",", "rand", "=", "self", ".", "rand", ")", "\n", "neg_pos_ratio", "=", "len", "(", "self", ".", "neg_sampler", ")", "/", "len", "(", "self", ".", "pos_sampler", ")", "\n", "pos_is_minority", "=", "True", "\n", "if", "neg_pos_ratio", ">", "1.0", ":", "\n", "            ", "pos_is_minority", "=", "True", "\n", "# imbalance_ratio is the ratio of majority class to minority class", "\n", "self", ".", "imbalance_ratio", "=", "neg_pos_ratio", "\n", "", "else", ":", "\n", "            ", "pos_is_minority", "=", "False", "\n", "self", ".", "imbalance_ratio", "=", "1.0", "/", "neg_pos_ratio", "\n", "", "if", "self", ".", "imbalance_ratio", ">", "batch_size", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Cannot guarantee one minority sample in each batch if the batch size ({batch_size}) is smaller than the majority-minority class imbalance ratio ({round(self.imbalance_ratio, 4)}) minus 1\"", ")", "\n", "", "self", ".", "subsequent_minority_probability", "=", "(", "self", ".", "batch_size", "/", "(", "self", ".", "imbalance_ratio", "+", "1.0", ")", "-", "1", ")", "/", "(", "self", ".", "batch_size", "-", "2", ")", "\n", "\n", "if", "pos_is_minority", ":", "\n", "            ", "self", ".", "minority_sampler", "=", "self", ".", "pos_sampler", "\n", "self", ".", "majority_sampler", "=", "self", ".", "neg_sampler", "\n", "", "else", ":", "\n", "            ", "self", ".", "minority_sampler", "=", "self", ".", "neg_sampler", "\n", "self", ".", "majority_sampler", "=", "self", ".", "pos_sampler", "\n", "\n", "", "self", ".", "minority_points_sampled", "=", "0", "\n", "self", ".", "majority_points_sampled", "=", "0", "\n", "self", ".", "batches_remaining", "=", "len", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.__iter__": [[102, 151], ["balanced_batch_sampler.BalancedBatchSampler.minority_sampler.__iter__", "balanced_batch_sampler.BalancedBatchSampler.majority_sampler.__iter__", "next", "next", "breakpoint", "balanced_batch.append", "balanced_batch.append", "balanced_batch_sampler.BalancedBatchSampler.rand.random", "balanced_batch.append", "balanced_batch_sampler.BalancedBatchSampler.num_points_remaining", "len", "balanced_batch_sampler.BalancedBatchSampler.num_points_remaining", "balanced_batch_sampler.BalancedBatchSampler.num_minority_points_remaining", "next", "next", "balanced_batch_sampler.BalancedBatchSampler.maybe_shuffle_batch", "len", "balanced_batch_sampler.BalancedBatchSampler.maybe_shuffle_batch", "balanced_batch_sampler.BalancedBatchSampler.num_majority_points_remaining", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.TestDataset.__iter__", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.TestDataset.__iter__", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_points_remaining", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_points_remaining", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_minority_points_remaining", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.maybe_shuffle_batch", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.maybe_shuffle_batch", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_majority_points_remaining"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterator", "[", "List", "[", "int", "]", "]", ":", "\n", "        ", "minority_generator", "=", "self", ".", "minority_sampler", ".", "__iter__", "(", ")", "\n", "majority_generator", "=", "self", ".", "majority_sampler", ".", "__iter__", "(", ")", "\n", "balanced_batch", "=", "[", "]", "\n", "while", "True", ":", "\n", "# Place one minority class sample in the batch, and one majority class sample, to guarantee", "\n", "# that points of both labels will be seen in the batch.", "\n", "            ", "minority_idx", "=", "next", "(", "minority_generator", ",", "None", ")", "\n", "majority_idx", "=", "next", "(", "majority_generator", ",", "None", ")", "\n", "# Neither iterator should be empty at this point, by construction.", "\n", "assert", "minority_idx", "is", "not", "None", "and", "majority_idx", "is", "not", "None", ",", "breakpoint", "(", ")", "\n", "balanced_batch", ".", "append", "(", "minority_idx", ")", "\n", "self", ".", "minority_points_sampled", "+=", "1", "\n", "balanced_batch", ".", "append", "(", "majority_idx", ")", "\n", "self", ".", "majority_points_sampled", "+=", "1", "\n", "self", ".", "batches_remaining", "-=", "1", "\n", "\n", "while", "len", "(", "balanced_batch", ")", "<", "self", ".", "batch_size", "and", "self", ".", "num_points_remaining", "(", ")", ">", "0", ":", "\n", "                ", "p", "=", "self", ".", "rand", ".", "random", "(", ")", "\n", "if", "self", ".", "num_minority_points_remaining", "(", ")", "==", "self", ".", "batches_remaining", ":", "\n", "# If we have nearly exhausted all the minority points to distribute, set p = 1.0", "\n", "# to force the rest of the points in this batch to belong to the majority class.", "\n", "                    ", "p", "=", "1.0", "\n", "", "elif", "self", ".", "num_majority_points_remaining", "(", ")", "==", "self", ".", "batches_remaining", ":", "\n", "# Do the equivalent thing for the majority class, to ensure equal representation.", "\n", "                    ", "p", "=", "0.0", "\n", "\n", "", "if", "p", "<", "self", ".", "subsequent_minority_probability", ":", "\n", "# Place minority sample into batch.", "\n", "                    ", "sample_idx", "=", "next", "(", "minority_generator", ")", "\n", "self", ".", "minority_points_sampled", "+=", "1", "\n", "", "else", ":", "\n", "# Place majority sample into batch.", "\n", "                    ", "sample_idx", "=", "next", "(", "majority_generator", ")", "\n", "self", ".", "majority_points_sampled", "+=", "1", "\n", "", "balanced_batch", ".", "append", "(", "sample_idx", ")", "\n", "\n", "", "if", "self", ".", "num_points_remaining", "(", ")", "<=", "1", ":", "\n", "# If there are no points remaining, then we are done creating batches.", "\n", "# If there is one point remaining, there is no way to construct a final batch including both", "\n", "# class labels, so skip it. Either way, this is the final batch.", "\n", "                ", "if", "len", "(", "balanced_batch", ")", ">", "0", "and", "not", "self", ".", "drop_last", ":", "\n", "                    ", "self", ".", "maybe_shuffle_batch", "(", "balanced_batch", ")", "\n", "yield", "balanced_batch", "\n", "", "break", "\n", "", "elif", "len", "(", "balanced_batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "self", ".", "maybe_shuffle_batch", "(", "balanced_batch", ")", "\n", "yield", "balanced_batch", "\n", "balanced_batch", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.__len__": [[152, 161], ["int", "int", "numpy.floor", "numpy.ceil", "float", "float", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "# Can only be called if self.sampler has __len__ implemented", "\n", "# We cannot enforce this condition, so we turn off typechecking for the", "\n", "# implementation below.", "\n", "# Somewhat related: see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]", "\n", "        ", "if", "self", ".", "drop_last", ":", "\n", "            ", "return", "int", "(", "np", ".", "floor", "(", "(", "len", "(", "self", ".", "minority_sampler", ")", "+", "len", "(", "self", ".", "majority_sampler", ")", ")", "/", "float", "(", "self", ".", "batch_size", ")", ")", ")", "# type: ignore[arg-type]", "\n", "", "else", ":", "\n", "            ", "return", "int", "(", "np", ".", "ceil", "(", "(", "len", "(", "self", ".", "minority_sampler", ")", "+", "len", "(", "self", ".", "majority_sampler", ")", ")", "/", "float", "(", "self", ".", "batch_size", ")", ")", ")", "# type: ignore[arg-type]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.maybe_shuffle_batch": [[162, 165], ["balanced_batch_sampler.BalancedBatchSampler.rand.shuffle"], "methods", ["None"], ["", "", "def", "maybe_shuffle_batch", "(", "self", ",", "batch", ":", "List", ")", "->", "List", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "self", ".", "rand", ".", "shuffle", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_minority_points_remaining": [[166, 168], ["len"], "methods", ["None"], ["", "", "def", "num_minority_points_remaining", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "minority_sampler", ")", "-", "self", ".", "minority_points_sampled", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_majority_points_remaining": [[169, 171], ["len"], "methods", ["None"], ["", "def", "num_majority_points_remaining", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "majority_sampler", ")", "-", "self", ".", "majority_points_sampled", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_points_remaining": [[172, 174], ["balanced_batch_sampler.BalancedBatchSampler.num_minority_points_remaining", "balanced_batch_sampler.BalancedBatchSampler.num_majority_points_remaining"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_minority_points_remaining", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_majority_points_remaining"], ["", "def", "num_points_remaining", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_minority_points_remaining", "(", ")", "+", "self", ".", "num_majority_points_remaining", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.balanced_batch_sampler.BalancedBatchSampler.num_batches_remaining": [[175, 177], ["None"], "methods", ["None"], ["", "def", "num_batches_remaining", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batches_remaining", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DatasetRow.__init__": [[71, 75], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "segment_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DrugSynergyDataModule.__init__": [[139, 189], ["pytorch_lightning.LightningDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "train_data", ":", "List", "[", "Dict", "]", ",", "\n", "test_data", ":", "List", "[", "Dict", "]", ",", "\n", "tokenizer", ":", "AutoTokenizer", ",", "\n", "label_to_idx", ":", "Dict", ",", "\n", "row_idx_mapping", ":", "Dict", ",", "\n", "train_batch_size", ":", "int", "=", "32", ",", "\n", "dev_batch_size", ":", "int", "=", "32", ",", "\n", "test_batch_size", ":", "int", "=", "32", ",", "\n", "dev_train_ratio", ":", "float", "=", "0.1", ",", "\n", "max_seq_length", ":", "int", "=", "512", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "balance_training_batch_labels", ":", "bool", "=", "True", ")", ":", "\n", "        ", "'''Construct a DataModule for convenient PyTorch Lightning training.\n\n        Args:\n            train_data: List of (text, label) pairs for training and validation\n            test_data: List of (text, label) pairs for testing\n            tokenizer: Tokenizer/subword segmenter to process raw text\n            label_to_idx: Fixed mapping of label strings to numerical values\n            row_idx_mapping: Maps each unique row identifier to an integer.\n            train_batch_size: Batch size for training\n            dev_batch_size: Batch size for validation\n            test_batch_size: Batch size for testing\n            dev_train_ratio: Hold out this fraction of the training set as a dev set\n            max_seq_length: Fixed document length to use for the dataset\n            num_workers: Number of CPU workers to use for loading data\n\n        Returns:\n            self: PyTorch Lightning DataModule to load all data during training, validation, and testing.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "label_to_idx", "=", "label_to_idx", "\n", "self", ".", "row_idx_mapping", "=", "row_idx_mapping", "\n", "self", ".", "train_batch_size", "=", "train_batch_size", "\n", "self", ".", "dev_batch_size", "=", "dev_batch_size", "\n", "self", ".", "test_batch_size", "=", "test_batch_size", "\n", "self", ".", "dev_train_ratio", "=", "dev_train_ratio", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "balance_training_batch_labels", "=", "balance_training_batch_labels", "\n", "\n", "# self.dims is returned when you call dm.size()", "\n", "# Setting default dims here because we know them.", "\n", "# Could optionally be assigned dynamically in dm.setup()", "\n", "# TODO(Vijay): set dimensions here", "\n", "self", ".", "dims", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DrugSynergyDataModule.setup": [[190, 201], ["data_loader.construct_dataset", "data_loader.construct_dataset", "int", "torch.utils.data.random_split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.construct_dataset", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.construct_dataset"], ["", "def", "setup", "(", "self", ")", ":", "\n", "# Assign train/val datasets for use in dataloaders", "\n", "        ", "if", "self", ".", "train_data", "is", "not", "None", ":", "\n", "            ", "full_dataset", "=", "construct_dataset", "(", "self", ".", "train_data", ",", "self", ".", "tokenizer", ",", "self", ".", "row_idx_mapping", ",", "max_seq_length", "=", "self", ".", "max_seq_length", ")", "\n", "dev_size", "=", "int", "(", "self", ".", "dev_train_ratio", "*", "len", "(", "full_dataset", ")", ")", "\n", "train_size", "=", "len", "(", "full_dataset", ")", "-", "dev_size", "\n", "self", ".", "train", ",", "self", ".", "val", "=", "random_split", "(", "full_dataset", ",", "[", "train_size", ",", "dev_size", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train", ",", "self", ".", "val", "=", "None", ",", "None", "\n", "\n", "", "self", ".", "test", "=", "construct_dataset", "(", "self", ".", "test_data", ",", "self", ".", "tokenizer", ",", "self", ".", "row_idx_mapping", ",", "max_seq_length", "=", "self", ".", "max_seq_length", ")", "\n", "# Optionally...", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DrugSynergyDataModule.train_dataloader": [[204, 212], ["preprocessing.balanced_batch_sampler.BalancedBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "balance_training_batch_labels", ":", "\n", "            ", "train_batch_sampler", "=", "BalancedBatchSampler", "(", "dataset", "=", "self", ".", "train", ",", "batch_size", "=", "self", ".", "train_batch_size", ",", "drop_last", "=", "False", ")", "\n", "return", "DataLoader", "(", "self", ".", "train", ",", "num_workers", "=", "self", ".", "num_workers", ",", "batch_sampler", "=", "train_batch_sampler", ")", "\n", "", "else", ":", "\n", "            ", "return", "DataLoader", "(", "self", ".", "train", ",", "num_workers", "=", "self", ".", "num_workers", ",", "batch_size", "=", "self", ".", "train_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DrugSynergyDataModule.val_dataloader": [[213, 217], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "val", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "DataLoader", "(", "self", ".", "val", ",", "batch_size", "=", "self", ".", "dev_batch_size", ",", "num_workers", "=", "self", ".", "num_workers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.DrugSynergyDataModule.test_dataloader": [[218, 220], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "DataLoader", "(", "self", ".", "test", ",", "batch_size", "=", "self", ".", "test_batch_size", ",", "num_workers", "=", "self", ".", "num_workers", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.make_fixed_length": [[12, 31], ["len", "len"], "function", ["None"], ["def", "make_fixed_length", "(", "array", ":", "List", ",", "max_length", ":", "int", ",", "padding_value", ":", "int", "=", "0", ")", "->", "List", ":", "\n", "    ", "\"\"\"Helper function to make a variable-length array into a fixed-length one.\n    If the array is shorter than the fixed length, pad with the given value. If\n    longer than the fixed length, truncate it.\n\n    Args:\n        array: Array whose length we want to fix\n        max_length: Desired length to fix\n        padding_value: Value to pad array with, if shorter than desired length\n\n    Returns:\n        fixed_array: Fixed-length, padded version of the input array.\n    \"\"\"", "\n", "if", "len", "(", "array", ")", ">=", "max_length", ":", "\n", "        ", "fixed_array", "=", "array", "[", ":", "max_length", "]", "\n", "", "else", ":", "\n", "        ", "pad_length", "=", "max_length", "-", "len", "(", "array", ")", "\n", "fixed_array", "=", "array", "+", "[", "padding_value", "]", "*", "pad_length", "\n", "", "return", "fixed_array", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.tokenize_sentence": [[32, 69], ["text.split", "doc_subwords.append", "len", "entity_start_token_idxs.append", "doc_subwords.append", "doc_subwords.append", "tokenizer.tokenize", "doc_subwords.append"], "function", ["None"], ["", "def", "tokenize_sentence", "(", "text", ":", "str", ",", "tokenizer", ":", "AutoTokenizer", ",", "tokenizer_cache", ":", "Dict", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "int", "]", "]", ":", "\n", "    ", "'''Given a text sentence, run the Huggingface subword tokenizer on this sentence,\n    and return a list of subword tokens and the positions of all special entity marker\n    tokens in the text.\n\n    Args:\n        text: String to tokenize\n        tokenizer: HuggingFace tokenizer\n\n    Returns:\n        doc_subwords: List of subword strings\n        entity_start_token_idxs: Positions of all entity-start tokens in the list of subwords\n    '''", "\n", "doc_subwords", "=", "[", "CLS", "]", "\n", "whitespace_tokens", "=", "text", ".", "split", "(", ")", "\n", "entity_start_token_idxs", "=", "[", "]", "\n", "\n", "# Manually split up each token into subwords, to directly identify special entity tokens", "\n", "# and store their locations.", "\n", "for", "token", "in", "whitespace_tokens", ":", "\n", "        ", "if", "token", "==", "ENTITY_START_MARKER", ":", "\n", "            ", "entity_start_idx", "=", "len", "(", "doc_subwords", ")", "\n", "entity_start_token_idxs", ".", "append", "(", "entity_start_idx", ")", "\n", "doc_subwords", ".", "append", "(", "ENTITY_START_MARKER", ")", "\n", "", "elif", "token", "==", "ENTITY_END_MARKER", ":", "\n", "            ", "doc_subwords", ".", "append", "(", "ENTITY_END_MARKER", ")", "\n", "", "else", ":", "\n", "# If not a special token, then split the token into subwords.", "\n", "            ", "if", "token", "in", "tokenizer_cache", ":", "\n", "                ", "sub_tokens", "=", "tokenizer_cache", "[", "token", "]", "\n", "", "else", ":", "\n", "                ", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "tokenizer_cache", "[", "token", "]", "=", "sub_tokens", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                ", "doc_subwords", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "doc_subwords", ".", "append", "(", "SEP", ")", "\n", "return", "doc_subwords", ",", "entity_start_token_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.vectorize_subwords": [[76, 83], ["tokenizer.convert_tokens_to_ids", "data_loader.make_fixed_length", "data_loader.make_fixed_length", "data_loader.make_fixed_length", "data_loader.DatasetRow", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.make_fixed_length", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.make_fixed_length", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.make_fixed_length"], ["", "", "def", "vectorize_subwords", "(", "tokenizer", ",", "doc_subwords", ":", "List", "[", "str", "]", ",", "max_seq_length", ":", "int", "=", "512", ")", ":", "\n", "    ", "doc_input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "doc_subwords", ")", "\n", "input_ids", "=", "make_fixed_length", "(", "doc_input_ids", ",", "max_seq_length", ")", "\n", "attention_mask", "=", "make_fixed_length", "(", "[", "1", "]", "*", "len", "(", "doc_input_ids", ")", ",", "max_seq_length", ")", "\n", "# Treat entire paragraph as a single segment, without SEP tokens", "\n", "segment_ids", "=", "make_fixed_length", "(", "[", "0", "]", "*", "len", "(", "doc_input_ids", ")", ",", "max_seq_length", ")", "\n", "return", "DatasetRow", "(", "input_ids", ",", "attention_mask", ",", "segment_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.construct_dataset": [[84, 137], ["tqdm.tqdm", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.tensor.append", "data_loader.tokenize_sentence", "all_doc_subwords.append", "all_doc_entity_start_positions.append", "max", "torch.tensor.append", "numpy.zeros", "torch.tensor.append", "data_loader.vectorize_subwords", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "len", "np.zeros.tolist", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.tokenize_sentence", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.vectorize_subwords"], ["", "def", "construct_dataset", "(", "data", ":", "List", "[", "Dict", "]", ",", "tokenizer", ":", "AutoTokenizer", ",", "row_idx_mapping", ":", "Dict", ",", "max_seq_length", ":", "int", "=", "512", ")", "->", "TensorDataset", ":", "\n", "    ", "\"\"\"Converts raw data (in the form of text/label pairs) into a binarized, training-ready Torch TensorDataset.\n\n    Args:\n        data: List of dictionaries, each containing a string of entity-marked text and a discrete label\n        tokenizer: Huggingface tokenizer, to perform word segmentation\n        row_idx_mapping: Maps each unique row identifier to an integer.\n        max_seq_length: Fixed length (in subwords) to use for representing all documents\n\n    Returns:\n        dataset: TensorDataset containing numerical representation of the dataset's text strings and discrete labels.\n    \"\"\"", "\n", "targets", "=", "[", "]", "\n", "max_entities_length", "=", "-", "1", "\n", "# Store subwords and entity positions for each document in the first pass over the dataset.", "\n", "all_doc_subwords", "=", "[", "]", "\n", "all_doc_entity_start_positions", "=", "[", "]", "\n", "all_row_ids", "=", "[", "]", "\n", "tokenizer_cache", "=", "{", "}", "\n", "for", "doc", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "targets", ".", "append", "(", "doc", "[", "\"target\"", "]", ")", "\n", "doc_subwords", ",", "entity_start_token_idxs", "=", "tokenize_sentence", "(", "doc", "[", "\"text\"", "]", ",", "tokenizer", ",", "tokenizer_cache", ")", "\n", "all_doc_subwords", ".", "append", "(", "doc_subwords", ")", "\n", "all_doc_entity_start_positions", ".", "append", "(", "entity_start_token_idxs", ")", "\n", "max_entities_length", "=", "max", "(", "max_entities_length", ",", "len", "(", "entity_start_token_idxs", ")", ")", "\n", "all_row_ids", ".", "append", "(", "row_idx_mapping", "[", "doc", "[", "\"row_id\"", "]", "]", ")", "\n", "\n", "", "all_entity_idx_weights", "=", "[", "]", "# Used to compute an average of embeddings for the document.", "\n", "all_input_ids", "=", "[", "]", "\n", "all_token_type_ids", "=", "[", "]", "\n", "all_attention_masks", "=", "[", "]", "\n", "\n", "for", "i", ",", "doc_subwords", "in", "enumerate", "(", "all_doc_subwords", ")", ":", "\n", "        ", "entity_start_token_idxs", "=", "all_doc_entity_start_positions", "[", "i", "]", "\n", "entity_idx_weights", "=", "np", ".", "zeros", "(", "(", "1", ",", "max_seq_length", ")", ")", "\n", "for", "start_token_idx", "in", "entity_start_token_idxs", ":", "\n", "            ", "assert", "start_token_idx", "<", "max_seq_length", ",", "\"Entity is out of bounds in truncated text seqence, make --max-seq-length larger\"", "\n", "entity_idx_weights", "[", "0", "]", "[", "start_token_idx", "]", "=", "1.0", "/", "len", "(", "entity_start_token_idxs", ")", "\n", "", "all_entity_idx_weights", ".", "append", "(", "entity_idx_weights", ".", "tolist", "(", ")", ")", "\n", "row", "=", "vectorize_subwords", "(", "tokenizer", ",", "doc_subwords", ",", "max_seq_length", ")", "\n", "all_input_ids", ".", "append", "(", "row", ".", "input_ids", ")", "\n", "all_token_type_ids", ".", "append", "(", "row", ".", "segment_ids", ")", "\n", "all_attention_masks", ".", "append", "(", "row", ".", "attention_mask", ")", "\n", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "all_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "all_token_type_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_masks", "=", "torch", ".", "tensor", "(", "all_attention_masks", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "targets", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_entity_idx_weights", "=", "torch", ".", "tensor", "(", "all_entity_idx_weights", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "all_row_ids", "=", "torch", ".", "tensor", "(", "all_row_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "targets", ",", "all_entity_idx_weights", ",", "all_row_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.pairset": [[12, 26], ["enumerate", "enumerate", "pairset.append", "set"], "function", ["None"], ["def", "pairset", "(", "iterable", ":", "Iterable", ")", "->", "List", "[", "Set", "]", ":", "\n", "    ", "\"\"\"Return the set of pairs of an iterable.\n    Args:\n        iterable: The iterable to take the set of pairs of.\n\n    Returns:\n        pairset: A list containing the set of pairs of `iterable`.\n    \"\"\"", "\n", "pairset", "=", "[", "]", "\n", "for", "i", ",", "item_i", "in", "enumerate", "(", "iterable", ")", ":", "\n", "        ", "for", "j", ",", "item_j", "in", "enumerate", "(", "iterable", ")", ":", "\n", "            ", "if", "j", ">", "i", ":", "\n", "                ", "pairset", ".", "append", "(", "set", "(", "[", "item_i", ",", "item_j", "]", ")", ")", "\n", "", "", "", "return", "pairset", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.powerset": [[27, 41], ["list", "itertools.chain.from_iterable", "set", "itertools.combinations", "range", "len", "len"], "function", ["None"], ["", "def", "powerset", "(", "iterable", ":", "Iterable", ")", "->", "List", "[", "Set", "]", ":", "\n", "    ", "\"\"\"Return the powerset of an iterable.\n    Adapted from https://docs.python.org/3/library/itertools.html#itertools-recipes.\n\n    Args:\n        iterable: The iterable to take the powerset of.\n\n    Returns:\n        powerset: A list containing the powerset of `iterable`.\n    \"\"\"", "\n", "s", "=", "list", "(", "iterable", ")", "\n", "powerset", "=", "chain", ".", "from_iterable", "(", "combinations", "(", "s", ",", "r", ")", "for", "r", "in", "range", "(", "len", "(", "s", ")", "+", "1", ")", ")", "\n", "powerset", "=", "[", "set", "(", "subset", ")", "for", "subset", "in", "powerset", "if", "len", "(", "subset", ")", ">", "1", "]", "\n", "return", "powerset", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.find_no_combination_examples": [[42, 81], ["range", "len", "preprocess.pairset", "preprocess.powerset", "sorted", "entity_cooccurrences.append", "no_comb_relations.append", "set", "list", "candidate.issubset"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.pairset", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.powerset"], ["", "def", "find_no_combination_examples", "(", "relations", ":", "List", "[", "Dict", "]", ",", "entities", ":", "List", "[", "DrugEntity", "]", ",", "only_include_binary_no_comb_relations", ":", "bool", "=", "True", ",", "produce_all_subsets", ":", "bool", "=", "False", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "\"\"\"Construct NOT-COMB relations - relations that are not mentioned as being used in combination.\n    We do this by exclusion - any set of entities that are not explicitly mentioned as being combined,\n    are treated as NO_COMB.\n\n    Args:\n        relations: list of relations (each represented as a dict), directly taken from annotated data.\n        entities: list of all drugs mentioned in the sentence of interest.\n\n    Returns:\n        no_comb_relations: list of relations between entities implicitly labeled as NO_COMB (by exclusion).\n    \"\"\"", "\n", "# Find the set of all pairs of entities that belong in some relation (other than NO_COMB) together in the same sentence.", "\n", "entity_cooccurrences", "=", "[", "]", "\n", "for", "relation", "in", "relations", ":", "\n", "        ", "if", "relation", "[", "\"class\"", "]", "!=", "NOT_COMB", ":", "\n", "            ", "span_idxs", "=", "sorted", "(", "relation", "[", "\"spans\"", "]", ")", "\n", "entity_cooccurrences", ".", "append", "(", "set", "(", "span_idxs", ")", ")", "\n", "\n", "", "", "entity_idxs", "=", "range", "(", "len", "(", "entities", ")", ")", "\n", "if", "only_include_binary_no_comb_relations", ":", "\n", "# Under this option, construct only binary no-comb relations", "\n", "        ", "candidate_no_combinations", "=", "pairset", "(", "entity_idxs", ")", "\n", "", "else", ":", "\n", "        ", "candidate_no_combinations", "=", "powerset", "(", "entity_idxs", ")", "\n", "\n", "", "no_comb_relations", "=", "[", "]", "\n", "# Add implicit NO_COMB relations.", "\n", "for", "candidate", "in", "candidate_no_combinations", ":", "\n", "        ", "entity_found", "=", "False", "\n", "for", "c", "in", "entity_cooccurrences", ":", "\n", "            ", "if", "(", "not", "produce_all_subsets", "and", "candidate", ".", "issubset", "(", "c", ")", ")", "or", "(", "candidate", "==", "c", ")", ":", "\n", "                ", "entity_found", "=", "True", "\n", "# If a set of drugs is not contained in any other relation, then consider it as an implicit", "\n", "# NO_COMB relation.", "\n", "", "", "if", "not", "entity_found", ":", "\n", "            ", "no_comb_relation", "=", "{", "'class'", ":", "NOT_COMB", ",", "'spans'", ":", "list", "(", "candidate", ")", "}", "\n", "no_comb_relations", ".", "append", "(", "no_comb_relation", ")", "\n", "", "", "return", "no_comb_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc": [[82, 137], ["enumerate", "common.types.Document", "text.find", "breakpoint", "common.types.DrugEntity", "drug_entities.append", "len", "preprocess.powerset", "final_relations.append", "range", "relation_label_mapping.get", "relations.append", "common.types.DrugRelation", "len", "tuple", "list", "preprocess.find_no_combination_examples", "sorted", "tuple", "sorted"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.powerset", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.find_no_combination_examples"], ["", "def", "process_doc", "(", "raw", ":", "Dict", ",", "label2idx", ":", "Dict", ",", "add_no_combination_relations", ":", "bool", "=", "True", ",", "only_include_binary_no_comb_relations", ":", "bool", "=", "False", ",", "include_paragraph_context", ":", "bool", "=", "True", ",", "produce_all_subsets", ":", "bool", "=", "False", ",", "max_candidate_entities", ":", "int", "=", "15", ")", "->", "Document", ":", "\n", "    ", "\"\"\"Convert a raw annotated document into a Document class.\n\n    Args:\n        raw: Document from the Drug Synergy dataset, corresponding to one annotated sentence.\n        label2idx: Mapping from relation class strings to integer values.\n        add_no_combination_relations: Whether to add implicit NO_COMB relations.\n        only_include_binary_no_comb_relations: If true, ignore n-ary no-comb relations.\n        include_paragraph_context: Whether to include full-paragraph context around each drug-mention sentence\n        produce_all_subsets: Whether to include all subsets of existing relations as NO_COMB or not\n\n    Returns:\n        document: Processed version of the input document.\n    \"\"\"", "\n", "if", "include_paragraph_context", ":", "\n", "        ", "text", "=", "raw", "[", "'paragraph'", "]", "\n", "sentence_start_idx", "=", "text", ".", "find", "(", "raw", "[", "'sentence'", "]", ")", "\n", "assert", "sentence_start_idx", "!=", "-", "1", ",", "breakpoint", "(", ")", "\n", "", "else", ":", "\n", "        ", "text", "=", "raw", "[", "'sentence'", "]", "\n", "sentence_start_idx", "=", "0", "\n", "\n", "# Construct DrugEntity objects.", "\n", "", "drug_entities", "=", "[", "]", "\n", "for", "idx", ",", "span", "in", "enumerate", "(", "raw", "[", "'spans'", "]", ")", ":", "\n", "        ", "entity", "=", "DrugEntity", "(", "span", "[", "'text'", "]", ",", "idx", ",", "span", "[", "'start'", "]", "+", "sentence_start_idx", ",", "span", "[", "'end'", "]", "+", "sentence_start_idx", ")", "\n", "drug_entities", ".", "append", "(", "entity", ")", "\n", "\n", "", "if", "len", "(", "drug_entities", ")", ">", "max_candidate_entities", ":", "\n", "        ", "return", "None", "\n", "\n", "", "if", "produce_all_subsets", ":", "\n", "        ", "relation_label_mapping", "=", "{", "}", "\n", "if", "'rels'", "in", "raw", ":", "\n", "            ", "for", "rel", "in", "raw", "[", "'rels'", "]", ":", "\n", "                ", "relation_label_mapping", "[", "tuple", "(", "sorted", "(", "rel", "[", "\"spans\"", "]", ")", ")", "]", "=", "rel", "[", "\"class\"", "]", "\n", "", "", "relations", "=", "[", "]", "\n", "for", "candidate", "in", "powerset", "(", "range", "(", "len", "(", "drug_entities", ")", ")", ")", ":", "\n", "            ", "relation_class", "=", "relation_label_mapping", ".", "get", "(", "tuple", "(", "sorted", "(", "candidate", ")", ")", ",", "NOT_COMB", ")", "\n", "relation_dict", "=", "{", "'class'", ":", "relation_class", ",", "'spans'", ":", "list", "(", "candidate", ")", "}", "\n", "relations", ".", "append", "(", "relation_dict", ")", "\n", "", "", "else", ":", "\n", "        ", "relations", "=", "raw", "[", "'rels'", "]", "\n", "if", "add_no_combination_relations", ":", "\n", "# Construct \"NOT-COMB\" relation pairs from pairs of annotated entities that do not co-occur in any other relation.", "\n", "            ", "relations", "=", "relations", "+", "find_no_combination_examples", "(", "relations", ",", "drug_entities", ",", "only_include_binary_no_comb_relations", "=", "only_include_binary_no_comb_relations", ",", "produce_all_subsets", "=", "produce_all_subsets", ")", "\n", "\n", "# Construct DrugRelation objects, which contain full information about the document's annotations.", "\n", "", "", "final_relations", "=", "[", "]", "\n", "for", "relation", "in", "relations", ":", "\n", "        ", "entities", "=", "[", "drug_entities", "[", "entity_idx", "]", "for", "entity_idx", "in", "relation", "[", "'spans'", "]", "]", "\n", "rel_label", "=", "label2idx", "[", "relation", "[", "'class'", "]", "]", "\n", "final_relations", ".", "append", "(", "DrugRelation", "(", "entities", ",", "rel_label", ")", ")", "\n", "", "document", "=", "Document", "(", "raw", "[", "\"doc_id\"", "]", ",", "final_relations", ",", "text", ")", "\n", "return", "document", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc_with_unknown_relations": [[138, 148], ["raw.copy", "preprocess.process_doc"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc"], ["", "def", "process_doc_with_unknown_relations", "(", "raw", ":", "Dict", ",", "label2idx", ":", "Dict", ",", "include_paragraph_context", ":", "bool", "=", "True", ")", "->", "Document", ":", "\n", "    ", "doc_with_no_relations", "=", "raw", ".", "copy", "(", ")", "\n", "doc_with_no_relations", "[", "'rels'", "]", "=", "[", "]", "\n", "document_with_unknown_relations", "=", "process_doc", "(", "raw", ",", "label2idx", ",", "add_no_combination_relations", "=", "True", ",", "include_paragraph_context", "=", "include_paragraph_context", ",", "produce_all_subsets", "=", "True", ")", "\n", "if", "document_with_unknown_relations", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "for", "relation", "in", "document_with_unknown_relations", ".", "relations", ":", "\n", "# Set all relation labels to be UNKNOWN_RELATION, to ensure no confusion", "\n", "        ", "relation", ".", "relation_label", "=", "RELATION_UNKNOWN", "\n", "", "return", "document_with_unknown_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.add_entity_markers": [[149, 187], ["sorted", "sum", "breakpoint", "position_offsets.append", "sum", "position_offsets.append", "len", "len", "len"], "function", ["None"], ["", "def", "add_entity_markers", "(", "text", ":", "str", ",", "relation_entities", ":", "List", "[", "DrugEntity", "]", ")", "->", "str", ":", "\n", "    ", "\"\"\"Add special entity tokens around each drug entity in the annotated text.\n    We specifically add \"<<m>>\" and \"<</m>>\" before and after (respectively) each drug entity span,\n    and construct these tokens in such a way that they are always delimited by whitespace from the\n    surrounding text.\n\n    Args:\n        text: Raw, un-tokenized text that has been annotated with relations and entity spans.\n        relation_entities: List of entity objects, each describing the span of a drug mention.\n\n    Returns:\n        text: Raw text, with special entity tokens inserted around drug entities.\n    \"\"\"", "\n", "\n", "relation_entities", ":", "List", "=", "sorted", "(", "relation_entities", ",", "key", "=", "lambda", "entity", ":", "entity", ".", "span_start", ")", "\n", "# This list keeps track of all the indices where special entity marker tokens were inserted.", "\n", "position_offsets", "=", "[", "]", "\n", "for", "drug", "in", "relation_entities", ":", "\n", "# Insert \"<m> \" before each entity. Assuming that each entity is preceded by a whitespace, this will neatly", "\n", "# result in a whitespace-delimited \"<m>\" token before the entity.", "\n", "        ", "position_offset", "=", "sum", "(", "[", "offset", "for", "idx", ",", "offset", "in", "position_offsets", "if", "idx", "<=", "drug", ".", "span_start", "]", ")", "\n", "if", "not", "(", "drug", ".", "span_start", "+", "position_offset", "==", "0", "or", "text", "[", "drug", ".", "span_start", "+", "position_offset", "-", "1", "]", "==", "\" \"", ")", ":", "\n", "            ", "start_marker", "=", "\" \"", "+", "ENTITY_START_MARKER", "\n", "", "else", ":", "\n", "            ", "start_marker", "=", "ENTITY_START_MARKER", "\n", "", "assert", "drug", ".", "span_start", "+", "position_offset", "==", "0", "or", "text", "[", "drug", ".", "span_start", "+", "position_offset", "-", "1", "]", "==", "\" \"", ",", "breakpoint", "(", ")", "\n", "text", "=", "text", "[", ":", "drug", ".", "span_start", "+", "position_offset", "]", "+", "start_marker", "+", "\" \"", "+", "text", "[", "drug", ".", "span_start", "+", "position_offset", ":", "]", "\n", "position_offsets", ".", "append", "(", "(", "drug", ".", "span_start", ",", "len", "(", "start_marker", "+", "\" \"", ")", ")", ")", "\n", "\n", "# Insert \"</m> \" after each entity.", "\n", "position_offset", "=", "sum", "(", "[", "offset", "for", "idx", ",", "offset", "in", "position_offsets", "if", "idx", "<=", "drug", ".", "span_end", "]", ")", "\n", "if", "not", "(", "drug", ".", "span_end", "+", "position_offset", "==", "len", "(", "text", ")", "or", "text", "[", "drug", ".", "span_end", "+", "position_offset", "]", "==", "\" \"", ")", ":", "\n", "            ", "end_marker", "=", "ENTITY_END_MARKER", "+", "\" \"", "\n", "", "else", ":", "\n", "            ", "end_marker", "=", "ENTITY_END_MARKER", "\n", "", "text", "=", "text", "[", ":", "drug", ".", "span_end", "+", "position_offset", "]", "+", "\" \"", "+", "end_marker", "+", "text", "[", "drug", ".", "span_end", "+", "position_offset", ":", "]", "\n", "position_offsets", ".", "append", "(", "(", "drug", ".", "span_end", ",", "len", "(", "end_marker", "+", "\" \"", ")", ")", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.truncate_text_into_window": [[188, 198], ["text.split", "min", "max", "max", "min", "len", "enumerate", "enumerate"], "function", ["None"], ["", "def", "truncate_text_into_window", "(", "text", ",", "context_window_size", ")", ":", "\n", "    ", "tokens", "=", "text", ".", "split", "(", ")", "\n", "first_entity_start_token", "=", "min", "(", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ")", "if", "t", "==", "\"<<m>>\"", "]", ")", "\n", "final_entity_end_token", "=", "max", "(", "[", "i", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ")", "if", "t", "==", "\"<</m>>\"", "]", ")", "\n", "entity_distance", "=", "final_entity_end_token", "-", "first_entity_start_token", "\n", "add_left", "=", "(", "context_window_size", "-", "entity_distance", ")", "//", "2", "\n", "start_window_left", "=", "max", "(", "0", ",", "first_entity_start_token", "-", "add_left", ")", "\n", "add_right", "=", "(", "context_window_size", "-", "entity_distance", ")", "-", "add_left", "\n", "start_window_right", "=", "min", "(", "len", "(", "tokens", ")", ",", "final_entity_end_token", "+", "add_right", ")", "\n", "return", "\" \"", ".", "join", "(", "tokens", "[", "start_window_left", ":", "start_window_right", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.create_datapoints": [[199, 238], ["preprocess.process_doc", "sorted", "json.dumps", "samples.append", "preprocess.add_entity_markers", "preprocess.truncate_text_into_window"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.add_entity_markers", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.truncate_text_into_window"], ["", "def", "create_datapoints", "(", "raw", ":", "Dict", ",", "label2idx", ":", "Dict", ",", "mark_entities", ":", "bool", "=", "True", ",", "add_no_combination_relations", "=", "True", ",", "only_include_binary_no_comb_relations", ":", "bool", "=", "False", ",", "include_paragraph_context", "=", "True", ",", "context_window_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "produce_all_subsets", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Given a single document, process it, add entity markers, and return a (text, relation label) pair.\n\n    Args:\n        raw: Dictionary of key-value pairs representing raw annotated document.\n        label2idx: Mapping from relation class strings to integer values.\n        mark_entities: Whether or not to add special entity token markers around each drug entity (default: True).\n        add_no_combination_relations: If true, identify implicit \"No-Combination\" relations by negation.\n        only_include_binary_no_comb_relations: If true, ignore n-ary no-comb relations.\n        include_paragraph_context: If true, include paragraph context around each entity-bearing sentence.\n        context_window_size: If set, we limit our paragraph context to this number of words\n        produce_all_subsets: Whether to include all subsets of existing relations as NO_COMB or not\n\n    Returns:\n        samples: List of (text, relation label) pairs representing all positive/negative relations\n                 contained in the sentence.\n    \"\"\"", "\n", "processed_document", "=", "process_doc", "(", "raw", ",", "\n", "label2idx", ",", "\n", "add_no_combination_relations", "=", "add_no_combination_relations", ",", "\n", "only_include_binary_no_comb_relations", "=", "only_include_binary_no_comb_relations", ",", "\n", "include_paragraph_context", "=", "include_paragraph_context", ",", "\n", "produce_all_subsets", "=", "produce_all_subsets", ")", "\n", "if", "processed_document", "is", "None", ":", "\n", "        ", "return", "[", "]", "\n", "", "samples", "=", "[", "]", "\n", "for", "relation", "in", "processed_document", ".", "relations", ":", "\n", "# Mark drug entities with special tokens.", "\n", "        ", "if", "mark_entities", ":", "\n", "            ", "text", "=", "add_entity_markers", "(", "processed_document", ".", "text", ",", "relation", ".", "drug_entities", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "processed_document", ".", "text", "\n", "", "if", "context_window_size", "is", "not", "None", ":", "\n", "            ", "text", "=", "truncate_text_into_window", "(", "text", ",", "context_window_size", ")", "\n", "", "drug_idxs", "=", "sorted", "(", "[", "drug", ".", "drug_idx", "for", "drug", "in", "relation", ".", "drug_entities", "]", ")", "\n", "row_metadata", "=", "{", "\"doc_id\"", ":", "raw", "[", "\"doc_id\"", "]", ",", "\"drug_idxs\"", ":", "drug_idxs", ",", "\"relation_label\"", ":", "relation", ".", "relation_label", "}", "\n", "row_id", "=", "json", ".", "dumps", "(", "row_metadata", ")", "\n", "samples", ".", "append", "(", "{", "\"text\"", ":", "text", ",", "\"target\"", ":", "relation", ".", "relation_label", ",", "\"row_id\"", ":", "row_id", ",", "\"drug_indices\"", ":", "drug_idxs", "}", ")", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.create_dataset": [[239, 288], ["sorted", "tqdm.tqdm", "list", "preprocess.create_datapoints", "dataset.extend", "set", "random.shuffle", "set", "random.choices", "upsampled_dataset.extend", "label2idx.values", "int", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.create_datapoints"], ["", "def", "create_dataset", "(", "raw_data", ":", "List", "[", "Dict", "]", ",", "\n", "label2idx", ":", "Dict", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "label_sampling_ratios", "=", "[", "1.0", ",", "1.0", "]", ",", "\n", "add_no_combination_relations", "=", "True", ",", "\n", "only_include_binary_no_comb_relations", ":", "bool", "=", "False", ",", "\n", "include_paragraph_context", "=", "True", ",", "\n", "context_window_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "produce_all_subsets", ":", "bool", "=", "False", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "\"\"\"Given the raw Drug Synergy dataset (directly read from JSON), convert it to a list of pairs\n    consisting of marked text and a relation label, for each candidate relation in each document.\n\n    Args:\n        raw_data: List of documents in the dataset.\n        label2idx: Mapping from relation class strings to integer values.\n        shuffle: Whether or not to randomly reorder the relation instances in the dataset before returning.\n        label_sampling_ratios: Ratio at which to downsample/upsample each class, to mitigate label imbalance.\n        add_no_combination_relations: If true, identify implicit \"No-Combination\" relations by negation.\n        only_include_binary_no_comb_relations: If true, ignore n-ary no-comb relations.\n        include_paragraph_context: If true, include paragraph context around each entity-bearing sentence.\n        context_window_size: If set, we limit our paragraph context to this number of words\n        produce_all_subsets: Whether to include all subsets of existing relations as NO_COMB or not\n\n    Returns:\n        dataset: A list of text, label pairs (represented as a dictionary), ready to be consumed by a model.\n    \"\"\"", "\n", "label_values", "=", "sorted", "(", "list", "(", "set", "(", "label2idx", ".", "values", "(", ")", ")", ")", ")", "\n", "dataset", "=", "[", "]", "\n", "for", "row", "in", "tqdm", "(", "raw_data", ")", ":", "\n", "        ", "datapoints", "=", "create_datapoints", "(", "row", ",", "\n", "label2idx", ",", "\n", "add_no_combination_relations", "=", "add_no_combination_relations", ",", "\n", "only_include_binary_no_comb_relations", "=", "only_include_binary_no_comb_relations", ",", "\n", "include_paragraph_context", "=", "include_paragraph_context", ",", "\n", "context_window_size", "=", "context_window_size", ",", "\n", "produce_all_subsets", "=", "produce_all_subsets", ")", "\n", "dataset", ".", "extend", "(", "datapoints", ")", "\n", "", "if", "set", "(", "label_sampling_ratios", ")", "!=", "{", "1.0", "}", ":", "\n", "# If all classes' sampling ratios are uniform, then we can simply use the dataset as is.", "\n", "# Otherwise, sample points from each class and then accumulate them all together.", "\n", "        ", "upsampled_dataset", "=", "[", "]", "\n", "for", "class_label", "in", "label_values", ":", "\n", "            ", "matching_points", "=", "[", "d", "for", "d", "in", "dataset", "if", "d", "[", "\"target\"", "]", "==", "class_label", "]", "\n", "upsampled_points", "=", "random", ".", "choices", "(", "matching_points", ",", "k", "=", "int", "(", "len", "(", "matching_points", ")", "*", "label_sampling_ratios", "[", "class_label", "]", ")", ")", "\n", "upsampled_dataset", ".", "extend", "(", "upsampled_points", ")", "\n", "", "dataset", "=", "upsampled_dataset", "\n", "", "if", "shuffle", ":", "\n", "        ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "", "return", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.TestDataset.__init__": [[15, 27], ["random.Random", "range", "test_balanced_batch_sampler.TestDataset.rand.shuffle", "test_balanced_batch_sampler.TestDataset.data.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_samples", "=", "1000", ",", "imbalance_ratio", "=", "7", ",", "seed", "=", "1", ")", ":", "\n", "        ", "self", ".", "rand", "=", "random", ".", "Random", "(", "seed", ")", "\n", "self", ".", "imbalance_ratio", "=", "imbalance_ratio", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_samples", ")", ":", "\n", "            ", "if", "i", "%", "(", "self", ".", "imbalance_ratio", "+", "1", ")", "==", "0", ":", "\n", "                ", "label", "=", "1", "\n", "", "else", ":", "\n", "                ", "label", "=", "0", "\n", "", "row", "=", "(", "i", ",", "None", ",", "None", ",", "label", ",", "None", ")", "\n", "self", ".", "data", ".", "append", "(", "row", ")", "\n", "", "self", ".", "rand", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.TestDataset.__iter__": [[28, 30], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "d", "for", "d", "in", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.TestDataset.__len__": [[31, 33], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_dataset": [[34, 38], ["test_balanced_batch_sampler.TestDataset"], "function", ["None"], ["", "", "@", "pytest", ".", "fixture", "\n", "def", "test_dataset", "(", ")", ":", "\n", "    ", "dataset", "=", "TestDataset", "(", "num_samples", "=", "TEST_DATASET_SIZE", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.count_labels_in_batch": [[39, 45], ["collections.Counter", "labels.append", "test_balanced_batch_sampler.test_dataset", "test_balanced_batch_sampler.test_dataset"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_dataset", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_dataset"], ["", "def", "count_labels_in_batch", "(", "batch", ",", "dataset", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "for", "row_idx", "in", "batch", ":", "\n", "        ", "(", "_", ",", "_", ",", "_", ",", "label", ",", "_", ")", "=", "dataset", ".", "data", "[", "row_idx", "]", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "return", "Counter", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_construct_balanced_batch_sampler": [[46, 49], ["balanced_batch_sampler.BalancedBatchSampler"], "function", ["None"], ["", "def", "test_construct_balanced_batch_sampler", "(", "test_dataset", ")", ":", "\n", "    ", "batch_size", "=", "8", "\n", "batch_sampler", "=", "BalancedBatchSampler", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_batch_size_too_small": [[50, 58], ["pytest.raises", "balanced_batch_sampler.BalancedBatchSampler"], "function", ["None"], ["", "def", "test_batch_size_too_small", "(", "test_dataset", ")", ":", "\n", "    ", "'''\n    If the batch size supplied to the batch sampler is too small, then we can't guarantee that each batch\n    will contain both labels. Test that an error is thrown in this case.\n    '''", "\n", "batch_size", "=", "7", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "BalancedBatchSampler", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_balanced_batch_sampler_perfect_batches": [[59, 79], ["balanced_batch_sampler.BalancedBatchSampler", "test_balanced_batch_sampler.count_labels_in_batch", "batches.append", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.count_labels_in_batch"], ["", "", "def", "test_balanced_batch_sampler_perfect_batches", "(", "test_dataset", ")", ":", "\n", "    ", "'''\n    Test that if we have a label imbalance ratio of 7:1, and we sample batches of 8 samples, each\n    batch will contain exactly 7 negatives and 1 positive.\n    '''", "\n", "batch_size", "=", "8", "\n", "batch_sampler", "=", "BalancedBatchSampler", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n", "num_batches", "=", "TEST_DATASET_SIZE", "/", "batch_size", "\n", "batches", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "batch", "in", "batch_sampler", ":", "\n", "        ", "i", "+=", "1", "\n", "batch_label_counts", "=", "count_labels_in_batch", "(", "batch", ",", "test_dataset", ")", "\n", "assert", "batch_label_counts", "[", "0", "]", "==", "7", "\n", "assert", "batch_label_counts", "[", "1", "]", "==", "1", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "\n", "# In this situation, the dataset perfectly divides into the number of batches. Verify this.", "\n", "", "assert", "len", "(", "batches", ")", "==", "TEST_DATASET_SIZE", "/", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.test_balanced_batch_sampler_imperfect_batches": [[80, 104], ["balanced_batch_sampler.BalancedBatchSampler", "batches.append", "test_balanced_batch_sampler.count_labels_in_batch", "numpy.abs", "absolute_minority_ratio_errors.append", "numpy.mean", "len", "numpy.ceil", "float", "len", "float"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.test_balanced_batch_sampler.count_labels_in_batch"], ["", "def", "test_balanced_batch_sampler_imperfect_batches", "(", "test_dataset", ",", "tolerance", "=", "0.1", ")", ":", "\n", "    ", "'''\n    Test that even if we can't perfectly distribute minority class points across batches, the mean\n    absolute error of the imbalance ratio in each batch (compared to the entire dataset) is small.\n    '''", "\n", "batch_size", "=", "15", "\n", "batch_sampler", "=", "BalancedBatchSampler", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "batches", "=", "[", "]", "\n", "\n", "true_minority_ratio", "=", "1.0", "/", "(", "1", "+", "test_dataset", ".", "imbalance_ratio", ")", "\n", "absolute_minority_ratio_errors", "=", "[", "]", "\n", "for", "batch", "in", "batch_sampler", ":", "\n", "        ", "batches", ".", "append", "(", "batch", ")", "\n", "batch_label_counts", "=", "count_labels_in_batch", "(", "batch", ",", "test_dataset", ")", "\n", "minority_imbalance_ratio", "=", "float", "(", "batch_label_counts", "[", "1", "]", ")", "/", "(", "batch_label_counts", "[", "0", "]", "+", "batch_label_counts", "[", "1", "]", ")", "\n", "# Each batch should still contain samples from both classes", "\n", "assert", "len", "(", "batch_label_counts", ")", "==", "2", "\n", "absolute_minority_ratio_error", "=", "np", ".", "abs", "(", "minority_imbalance_ratio", "-", "true_minority_ratio", ")", "\n", "absolute_minority_ratio_errors", ".", "append", "(", "absolute_minority_ratio_error", ")", "\n", "\n", "# The mean average error in the proportion of each batch consisting of negative examples should be close", "\n", "# to the full-dataset proportion of negative examples.", "\n", "", "assert", "np", ".", "mean", "(", "absolute_minority_ratio_errors", ")", "<", "tolerance", "\n", "assert", "len", "(", "batches", ")", "==", "np", ".", "ceil", "(", "float", "(", "TEST_DATASET_SIZE", ")", "/", "batch_size", ")", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.get_xml_files": [[27, 51], ["os.path.join", "os.listdir", "os.path.join.startswith", "os.listdir", "os.listdir", "f.endswith", "subdir.startswith", "parent_dirs.append", "parent_dir.startswith", "os.listdir", "xml_files.append", "os.path.join", "os.path.join", "os.path.join", "subdir.startswith", "parent_dirs.append", "os.path.join"], "function", ["None"], ["def", "get_xml_files", "(", "parent_dir", ",", "split", ")", ":", "\n", "    ", "dir", "=", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "split", ")", "\n", "xml_files", "=", "[", "]", "\n", "\n", "if", "split", "==", "\"Train\"", ":", "\n", "        ", "parent_dirs", "=", "[", "]", "\n", "for", "subdir", "in", "os", ".", "listdir", "(", "dir", ")", ":", "\n", "            ", "if", "not", "subdir", ".", "startswith", "(", "'.'", ")", ":", "\n", "                ", "parent_dirs", ".", "append", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "subdir", ")", ")", "\n", "", "", "", "elif", "split", "==", "\"Test\"", ":", "\n", "        ", "parent_dirs", "=", "[", "]", "\n", "for", "parent_dir", "in", "os", ".", "listdir", "(", "dir", ")", ":", "\n", "            ", "if", "parent_dir", ".", "startswith", "(", "'.'", ")", ":", "\n", "                ", "continue", "\n", "", "for", "subdir", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "parent_dir", ")", ")", ":", "\n", "                ", "if", "not", "subdir", ".", "startswith", "(", "'.'", ")", ":", "\n", "                    ", "parent_dirs", ".", "append", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "parent_dir", ",", "subdir", ")", ")", "\n", "", "", "", "", "for", "dir", "in", "parent_dirs", ":", "\n", "        ", "if", "dir", ".", "startswith", "(", "'.'", ")", ":", "\n", "            ", "continue", "\n", "", "for", "f", "in", "os", ".", "listdir", "(", "dir", ")", ":", "\n", "            ", "if", "f", ".", "endswith", "(", "\".xml\"", ")", ":", "\n", "                ", "xml_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "f", ")", ")", "\n", "", "", "", "return", "xml_files", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.split_tokens_from_whitespace": [[52, 54], ["re.split"], "function", ["None"], ["", "def", "split_tokens_from_whitespace", "(", "str", ")", ":", "\n", "    ", "return", "re", ".", "split", "(", "\"(\\s+)\"", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.char_to_token_mapping": [[55, 69], ["convert_ddi.split_tokens_from_whitespace", "enumerate", "len", "len", "token.split"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.split_tokens_from_whitespace"], ["", "def", "char_to_token_mapping", "(", "sentence", ")", ":", "\n", "    ", "start_char_to_token", "=", "{", "}", "\n", "end_char_to_token", "=", "{", "}", "\n", "tokens_and_whitespace", "=", "split_tokens_from_whitespace", "(", "sentence", ")", "\n", "char_counter", "=", "0", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens_and_whitespace", ")", ":", "\n", "        ", "start_counter", "=", "char_counter", "\n", "char_counter", "+=", "len", "(", "token", ")", "\n", "end_counter", "=", "char_counter", "\n", "if", "len", "(", "token", ".", "split", "(", ")", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "start_char_to_token", "[", "start_counter", "]", "=", "i", "\n", "end_char_to_token", "[", "end_counter", "]", "=", "i", "\n", "", "return", "start_char_to_token", ",", "end_char_to_token", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.retokenize_sentence": [[70, 116], ["sentence.find", "convert_ddi.split_tokens_from_whitespace", "enumerate", "position_offsets.append", "len", "list", "len", "sum", "position_offsets.append", "sum", "position_offsets.append", "token.split", "tok_seg", "len", "len", "enumerate", "len", "len", "len", "sum", "position_offsets.append", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.split_tokens_from_whitespace"], ["", "def", "retokenize_sentence", "(", "sentence", ",", "entity_idxs", ")", ":", "\n", "    ", "position_offsets", "=", "[", "]", "\n", "truncation_string_start_idx", "=", "sentence", ".", "find", "(", "\"(ABSTRACT TRUNCATED\"", ")", "\n", "if", "truncation_string_start_idx", "!=", "-", "1", ":", "\n", "        ", "sentence", "=", "sentence", "[", ":", "truncation_string_start_idx", "]", "+", "\" \"", "+", "sentence", "[", "truncation_string_start_idx", ":", "]", "\n", "position_offsets", ".", "append", "(", "(", "truncation_string_start_idx", ",", "1", ")", ")", "\n", "\n", "", "retokenized", "=", "\"\"", "\n", "tokens_and_whitespace", "=", "split_tokens_from_whitespace", "(", "sentence", ")", "\n", "original_char_counter", "=", "0", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens_and_whitespace", ")", ":", "\n", "        ", "if", "len", "(", "token", ".", "split", "(", ")", ")", ">", "0", ":", "\n", "            ", "subtokens", "=", "list", "(", "tok_seg", "(", "token", ")", ")", "\n", "if", "len", "(", "subtokens", ")", "==", "1", ":", "\n", "                ", "retokenized", "+=", "token", "\n", "original_char_counter", "+=", "len", "(", "token", ")", "\n", "", "else", ":", "\n", "                ", "for", "i", ",", "subtoken_tok", "in", "enumerate", "(", "subtokens", ")", ":", "\n", "                    ", "subtoken", "=", "subtoken_tok", ".", "text", "\n", "retokenized", "+=", "subtoken", "\n", "offsetted_length", "=", "len", "(", "retokenized", ")", "\n", "subtoken_in_entity", "=", "False", "\n", "for", "entity", "in", "entity_idxs", ":", "\n", "                        ", "if", "original_char_counter", "+", "len", "(", "subtoken", ")", ">=", "entity", "[", "1", "]", "and", "original_char_counter", "+", "len", "(", "subtoken", ")", "<=", "entity", "[", "2", "]", "and", "i", "+", "1", "<", "len", "(", "subtokens", ")", "and", "original_char_counter", "+", "len", "(", "subtoken", ")", "+", "len", "(", "subtokens", "[", "i", "+", "1", "]", ")", "<=", "entity", "[", "2", "]", ":", "\n", "# TODO(Vijay): ensure this end-index is correct.", "\n", "                            ", "subtoken_in_entity", "=", "True", "\n", "", "", "original_char_counter", "+=", "len", "(", "subtoken", ")", "\n", "if", "not", "subtoken_in_entity", "and", "i", "<", "len", "(", "subtokens", ")", "-", "1", ":", "\n", "                        ", "retokenized", "+=", "\" \"", "\n", "previous_offset", "=", "sum", "(", "[", "offset", "for", "j", ",", "offset", "in", "position_offsets", "if", "j", "<", "original_char_counter", "]", ")", "\n", "position_offsets", ".", "append", "(", "(", "offsetted_length", "-", "previous_offset", ",", "1", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "retokenized", "+=", "token", "\n", "original_char_counter", "+=", "len", "(", "token", ")", "\n", "\n", "", "", "for", "_", ",", "entity_start", ",", "entity_end", "in", "entity_idxs", ":", "\n", "        ", "offsetted_start", "=", "entity_start", "+", "sum", "(", "[", "offset", "for", "j", ",", "offset", "in", "position_offsets", "if", "j", "<", "entity_start", "]", ")", "\n", "if", "offsetted_start", ">", "0", "and", "retokenized", "[", "offsetted_start", "-", "1", "]", "!=", "\" \"", ":", "\n", "            ", "retokenized", "=", "retokenized", "[", ":", "offsetted_start", "]", "+", "\" \"", "+", "retokenized", "[", "offsetted_start", ":", "]", "\n", "position_offsets", ".", "append", "(", "(", "entity_start", "-", "1", ",", "1", ")", ")", "\n", "", "offsetted_end", "=", "entity_end", "+", "sum", "(", "[", "offset", "for", "j", ",", "offset", "in", "position_offsets", "if", "j", "<", "entity_end", "]", ")", "\n", "if", "offsetted_end", "<", "len", "(", "retokenized", ")", "and", "retokenized", "[", "offsetted_end", "]", "!=", "\" \"", ":", "\n", "            ", "retokenized", "=", "retokenized", "[", ":", "offsetted_end", "]", "+", "\" \"", "+", "retokenized", "[", "offsetted_end", ":", "]", "\n", "position_offsets", ".", "append", "(", "(", "entity_end", ",", "1", ")", ")", "\n", "", "", "return", "retokenized", ",", "position_offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.get_char_indices": [[117, 128], ["entity.get", "entity.get().split", "entity.get().split", "int", "first_chunk.split", "last_chunk.split", "int", "entity.get", "entity.get"], "function", ["None"], ["", "def", "get_char_indices", "(", "entity", ")", ":", "\n", "    ", "if", "\";\"", "in", "entity", ".", "get", "(", "'charOffset'", ")", ":", "\n", "        ", "chunks", "=", "entity", ".", "get", "(", "'charOffset'", ")", ".", "split", "(", "';'", ")", "\n", "first_chunk", "=", "chunks", "[", "0", "]", "\n", "last_chunk", "=", "chunks", "[", "-", "1", "]", "\n", "char_start_str", "=", "first_chunk", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "char_end_str", "=", "last_chunk", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "char_start_str", ",", "char_end_str", "=", "entity", ".", "get", "(", "'charOffset'", ")", ".", "split", "(", "'-'", ")", "\n", "", "char_start", ",", "char_end", "=", "int", "(", "char_start_str", ")", ",", "int", "(", "char_end_str", ")", "+", "1", "\n", "return", "char_start", ",", "char_end", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.parse_xml": [[129, 214], ["xml.parse", "ET.parse.getroot", "range", "child_sentence.get", "int", "child_sentence.get", "convert_ddi.retokenize_sentence", "convert_ddi.char_to_token_mapping", "sentences.append", "len", "convert_ddi.get_char_indices", "entity_idxs.append", "convert_ddi.get_char_indices", "sum", "sum", "len", "converted_spans.append", "len", "rows.append", "entity.get", "converted_relations.append", "child_sentence.get.split", "entity.get", "entity.get", "relation.get", "relation.get", "int", "span_ids.append", "relation.get", "entity_id.split"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.retokenize_sentence", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.char_to_token_mapping", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.get_char_indices", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.get_char_indices"], ["", "def", "parse_xml", "(", "xml_file", ")", ":", "\n", "    ", "tree", "=", "ET", ".", "parse", "(", "xml_file", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "assert", "root", ".", "tag", "==", "\"document\"", "\n", "rows", "=", "[", "]", "\n", "sentences", "=", "[", "]", "\n", "for", "child_sentence", "in", "root", ":", "\n", "        ", "sentence_id", "=", "child_sentence", ".", "get", "(", "'id'", ")", "\n", "sentence_idx", "=", "int", "(", "sentence_id", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "[", "1", ":", "]", ")", "\n", "assert", "child_sentence", ".", "tag", "==", "\"sentence\"", "\n", "sentence", "=", "child_sentence", ".", "get", "(", "'text'", ")", "\n", "\n", "entity_idxs", "=", "[", "]", "\n", "for", "entity", "in", "child_sentence", ":", "\n", "            ", "assert", "entity", ".", "tag", "in", "[", "\"entity\"", ",", "\"pair\"", "]", "\n", "if", "entity", ".", "tag", "!=", "\"entity\"", ":", "\n", "                ", "continue", "\n", "", "char_start", ",", "char_end", "=", "get_char_indices", "(", "entity", ")", "\n", "entity_idxs", ".", "append", "(", "(", "entity", ".", "get", "(", "'text'", ")", ",", "char_start", ",", "char_end", ")", ")", "\n", "\n", "\n", "", "retokenized_sentence", ",", "position_offsets", "=", "retokenize_sentence", "(", "sentence", ",", "entity_idxs", ")", "\n", "start_char_to_token", ",", "end_char_to_token", "=", "char_to_token_mapping", "(", "retokenized_sentence", ")", "\n", "\n", "\n", "converted_spans", "=", "[", "]", "\n", "entity_id_to_span_id", "=", "{", "}", "\n", "skip_sentence", "=", "False", "\n", "for", "entity", "in", "child_sentence", ":", "\n", "            ", "assert", "entity", ".", "tag", "in", "[", "\"entity\"", ",", "\"pair\"", "]", "\n", "if", "entity", ".", "tag", "!=", "\"entity\"", ":", "\n", "                ", "continue", "\n", "", "char_start", ",", "char_end", "=", "get_char_indices", "(", "entity", ")", "\n", "char_start", "+=", "sum", "(", "[", "offset", "for", "idx", ",", "offset", "in", "position_offsets", "if", "idx", "<=", "char_start", "]", ")", "\n", "char_end", "+=", "sum", "(", "[", "offset", "for", "idx", ",", "offset", "in", "position_offsets", "if", "idx", "<", "char_end", "]", ")", "\n", "\n", "if", "char_start", "not", "in", "start_char_to_token", "or", "char_end", "not", "in", "end_char_to_token", ":", "\n", "                ", "skip_sentence", "=", "True", "\n", "break", "\n", "", "token_start", "=", "start_char_to_token", "[", "char_start", "]", "\n", "token_end", "=", "end_char_to_token", "[", "char_end", "]", "\n", "\n", "span_id", "=", "len", "(", "converted_spans", ")", "\n", "span", "=", "{", "\n", "\"span_id\"", ":", "span_id", ",", "\n", "\"text\"", ":", "entity", ".", "get", "(", "'text'", ")", ",", "\n", "\"start\"", ":", "char_start", ",", "\n", "\"end\"", ":", "char_end", ",", "\n", "\"token_start\"", ":", "token_start", ",", "\n", "\"token_end\"", ":", "token_end", "\n", "}", "\n", "entity_id_to_span_id", "[", "entity", ".", "get", "(", "'id'", ")", "]", "=", "span_id", "\n", "converted_spans", ".", "append", "(", "span", ")", "\n", "", "if", "skip_sentence", ":", "\n", "            ", "converted_spans", "=", "[", "]", "\n", "continue", "\n", "\n", "", "converted_relations", "=", "[", "]", "\n", "if", "not", "skip_sentence", ":", "\n", "            ", "for", "relation", "in", "child_sentence", ":", "\n", "                ", "assert", "relation", ".", "tag", "in", "[", "\"entity\"", ",", "\"pair\"", "]", "\n", "if", "relation", ".", "tag", "!=", "\"pair\"", ":", "\n", "                    ", "continue", "\n", "", "entity_ids", "=", "[", "relation", ".", "get", "(", "'e1'", ")", ",", "relation", ".", "get", "(", "'e2'", ")", "]", "\n", "span_ids", "=", "[", "]", "\n", "for", "entity_id", "in", "entity_ids", ":", "\n", "                    ", "relation_sentence_idx", "=", "int", "(", "entity_id", ".", "split", "(", "'.'", ")", "[", "-", "2", "]", "[", "1", ":", "]", ")", "\n", "assert", "relation_sentence_idx", "==", "sentence_idx", "\n", "span_ids", ".", "append", "(", "entity_id_to_span_id", "[", "entity_id", "]", ")", "\n", "", "converted_relation", "=", "{", "\"class\"", ":", "relation", ".", "get", "(", "'ddi'", ")", ",", "\"spans\"", ":", "span_ids", "}", "\n", "converted_relations", ".", "append", "(", "converted_relation", ")", "\n", "\n", "", "", "if", "len", "(", "converted_relations", ")", ">", "0", ":", "\n", "            ", "converted_row", "=", "{", "\n", "\"sentence\"", ":", "sentence", ",", "\n", "\"spans\"", ":", "converted_spans", ",", "\n", "\"rels\"", ":", "converted_relations", ",", "\n", "\"paragraph\"", ":", "None", ",", "\n", "}", "\n", "rows", ".", "append", "(", "converted_row", ")", "\n", "", "sentences", ".", "append", "(", "sentence", ")", "\n", "", "paragraph", "=", "\" \"", ".", "join", "(", "sentences", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "rows", ")", ")", ":", "\n", "        ", "rows", "[", "i", "]", "[", "\"paragraph\"", "]", "=", "paragraph", "\n", "", "return", "rows", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.load_relation_annotations": [[215, 220], ["tqdm.tqdm", "enumerate", "rows.extend", "convert_ddi.parse_xml"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_ddi.parse_xml"], ["", "def", "load_relation_annotations", "(", "xml_files", ")", ":", "\n", "    ", "rows", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "tqdm", "(", "enumerate", "(", "xml_files", ")", ")", ":", "\n", "        ", "rows", ".", "extend", "(", "parse_xml", "(", "f", ")", ")", "\n", "", "return", "rows", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.detokenize_sentence": [[20, 46], ["enumerate", "len", "len"], "function", ["None"], ["def", "detokenize_sentence", "(", "tokens", ":", "List", "[", "str", "]", ",", "token_index_offset", ":", "int", ")", "->", "Tuple", "[", "str", ",", "Dict", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "]", ":", "\n", "    ", "\"\"\"Converts a list of tokens into a sentence, which can be tokenized later by applications.\n    To comply with this, update entity span indices to be span character indices instead of token indices.\n\n    Args:\n        tokens: List of tokens (representing a tokenized sentence)\n        token_index_offset: Number of tokens prior to this sentence in the containing paragraph, because our token-character index\n                            mapping must correspond to positions in the entire paragraph.\n        char_index_offset: Number of characters prior to this sentence in the containing paragraph.\n\n    Returns:\n        detokenized_sentence: Single string representing the detokenized sentence.\n        token_char_mapping: Mapping from paragraph-level token indices to character indices for each token in the sentence.\n    \"\"\"", "\n", "\n", "detokenized_sentence", "=", "\"\"", "\n", "token_char_mapping", "=", "{", "}", "\n", "token_start_idx", "=", "0", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "paragraph_idx", "=", "token_index_offset", "+", "i", "\n", "token_end_idx", "=", "token_start_idx", "+", "len", "(", "token", ")", "\n", "token_char_mapping", "[", "paragraph_idx", "]", "=", "(", "token_start_idx", ",", "token_end_idx", ")", "\n", "detokenized_sentence", "=", "detokenized_sentence", "+", "token", "+", "\" \"", "\n", "token_start_idx", "+=", "len", "(", "token", ")", "+", "1", "\n", "", "detokenized_sentence", "=", "detokenized_sentence", "[", ":", "-", "1", "]", "\n", "return", "detokenized_sentence", ",", "token_char_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.update_entity_indices": [[48, 89], ["enumerate", "converted_spans.append", "len", "breakpoint", "text.split", "text.split"], "function", ["None"], ["", "def", "update_entity_indices", "(", "entities", ":", "List", "[", "List", "]", ",", "sentence", ":", "str", ",", "paragraph_tokens", ":", "List", "[", "str", "]", ",", "token_index_mapping", ":", "Dict", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "entities_seen", ":", "int", ",", "token_offset", ":", "int", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "\"\"\"Convert SciERC entity objects within a sentence into Drug Synergy Dataset entity span objects. In addition to\n    converting the data format, also update all token spans in each entity to be paragraph-level character spans.\n\n    Args:\n        entities: SciERC entity annotations within a single sentence\n        sentence: String containing full text in the detokenized sentence\n        sentence_tokens: Tokens in the sentence\n        token_index_mapping: Mapping from the index of each token to its start and end character indices (to construct character spans)\n        entities_seen: Number of entities observed in previous sentences (for the purposes of constructing unique entity IDs)\n        token_offset: Number of tokens observed in previous sentences\n\n    Returns:\n        converted_spans: SciERC entity annotations within a sentence, converted into the Drug Synergy Dataset format\n    \"\"\"", "\n", "converted_spans", "=", "[", "]", "\n", "\n", "for", "i", ",", "entity", "in", "enumerate", "(", "entities", ")", ":", "\n", "        ", "[", "start_token_idx", ",", "end_token_idx", ",", "entity_type", "]", "=", "entity", "\n", "start_char_idx", ",", "_", "=", "token_index_mapping", "[", "start_token_idx", "]", "\n", "_", ",", "end_char_idx", "=", "token_index_mapping", "[", "end_token_idx", "]", "\n", "text", "=", "sentence", "[", "start_char_idx", ":", "end_char_idx", "]", "\n", "\n", "word", "=", "paragraph_tokens", "[", "start_token_idx", ":", "end_token_idx", "+", "1", "]", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "# As a sanity check, verify that all single token entities match perfectly here", "\n", "# between the token-indexed and char-indexed entities.", "\n", "            ", "assert", "word", "[", "0", "]", "==", "text", ",", "breakpoint", "(", ")", "\n", "\n", "", "token_start_string", "=", "text", ".", "split", "(", ")", "[", "0", "]", "\n", "token_end_string", "=", "text", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "span", "=", "{", "\n", "\"span_id\"", ":", "i", "+", "entities_seen", ",", "\n", "\"text\"", ":", "text", ",", "\n", "\"start\"", ":", "start_char_idx", ",", "\n", "\"end\"", ":", "end_char_idx", ",", "\n", "\"token_start\"", ":", "start_token_idx", "-", "token_offset", ",", "\n", "\"token_end\"", ":", "end_token_idx", "-", "token_offset", "\n", "}", "\n", "converted_spans", ".", "append", "(", "span", ")", "\n", "", "return", "converted_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.update_relation_indices": [[90, 126], ["converted_relations.append", "len", "enumerate", "spans.append"], "function", ["None"], ["", "def", "update_relation_indices", "(", "relations", ":", "List", "[", "List", "]", ",", "entities", ":", "List", "[", "Dict", "]", ",", "token_index_mapping", ":", "Dict", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "\"\"\"Convert SciERC relation annotations within a sentence into Drug Synergy Dataset relation objects. While SciERC\n    represents the entities in each span by their token indices, the Synergy Dataset refers to each entity by its index in the entities list.\n\n    Args:\n        relations: SciERC relation annotations within a sentence\n        entities: SciERC entities (converted into Synergy Dataset format) within a sentence\n        token_index_mapping: Mapping from the index of each token to its start and end character indices (to construct character spans)\n\n    Returns:\n        converted_relations: SciERC relation annotations within a sentence, converted into the Drug Synergy Dataset format\n    \"\"\"", "\n", "converted_relations", "=", "[", "]", "\n", "for", "relation", "in", "relations", ":", "\n", "        ", "if", "len", "(", "relation", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "entity_a_token_start", ",", "entity_a_token_end", ",", "entity_b_token_start", ",", "entity_b_token_end", ",", "relation_class", "=", "relation", "\n", "entity_a_char_start", "=", "token_index_mapping", "[", "entity_a_token_start", "]", "[", "0", "]", "\n", "entity_a_char_end", "=", "token_index_mapping", "[", "entity_a_token_end", "]", "[", "1", "]", "\n", "entity_b_char_start", "=", "token_index_mapping", "[", "entity_b_token_start", "]", "[", "0", "]", "\n", "entity_b_char_end", "=", "token_index_mapping", "[", "entity_b_token_end", "]", "[", "1", "]", "\n", "\n", "# Match the entity character indices to the `entities` list.        ", "\n", "spans", "=", "[", "]", "\n", "for", "entity_span", "in", "[", "(", "entity_a_char_start", ",", "entity_a_char_end", ")", ",", "(", "entity_b_char_start", ",", "entity_b_char_end", ")", "]", ":", "\n", "            ", "entity_matched", "=", "False", "\n", "for", "i", ",", "entity", "in", "enumerate", "(", "entities", ")", ":", "\n", "                ", "marker", "=", "2", "\n", "if", "entity", "[", "\"start\"", "]", "==", "entity_span", "[", "0", "]", "and", "entity", "[", "\"end\"", "]", "==", "entity_span", "[", "1", "]", ":", "\n", "                    ", "spans", ".", "append", "(", "i", ")", "\n", "entity_matched", "=", "True", "\n", "break", "\n", "", "", "assert", "entity_matched", "is", "True", "\n", "", "converted_relation", "=", "{", "\"class\"", ":", "relation_class", ",", "\"spans\"", ":", "spans", "}", "\n", "converted_relations", ".", "append", "(", "converted_relation", ")", "\n", "", "return", "converted_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.convert_scierc_rows": [[128, 176], ["enumerate", "range", "convert_scierc.detokenize_sentence", "sentences.append", "token_index_mapping.update", "all_tokens.extend", "len", "token_offsets.append", "len", "convert_scierc.update_entity_indices", "convert_scierc.update_relation_indices", "rows_converted.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.detokenize_sentence", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.update_entity_indices", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.update_relation_indices"], ["", "def", "convert_scierc_rows", "(", "row", ":", "Dict", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"Convert a single row from SciERC (containing a document with entities and relations annotated at each sentence)\n    into a set of Drug Synergy rows (each containing a sentence with entities and relations).\n\n    Args:\n        row: Raw annotated SciERC document\n\n    Returns:\n        rows_converted: SciERC document converted into a list of sentence-level Synergy Dataset rows\n    \"\"\"", "\n", "paragraph", "=", "\"\"", "\n", "token_index_offset", "=", "0", "\n", "token_index_mapping", "=", "{", "}", "\n", "sentences", "=", "[", "]", "\n", "\n", "# In a first pass of the paragraph, convert each entity span (originally represented as a span of tokens)", "\n", "# into a span of characters, indexed over all characters in the paragraph.", "\n", "all_tokens", "=", "[", "]", "\n", "token_offsets", "=", "[", "0", "]", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "row", "[", "\"sentences\"", "]", ")", ":", "\n", "        ", "detokenized_sentence", ",", "sentence_token_index_mapping", "=", "detokenize_sentence", "(", "sentence", ",", "token_index_offset", ")", "\n", "sentences", ".", "append", "(", "detokenized_sentence", ")", "\n", "token_index_mapping", ".", "update", "(", "sentence_token_index_mapping", ")", "\n", "paragraph", "=", "paragraph", "+", "detokenized_sentence", "+", "\" \"", "\n", "all_tokens", ".", "extend", "(", "sentence", ")", "\n", "token_index_offset", "+=", "len", "(", "sentence", ")", "\n", "token_offsets", ".", "append", "(", "token_index_offset", ")", "\n", "", "token_offsets", "=", "token_offsets", "[", ":", "-", "1", "]", "\n", "\n", "paragraph", "=", "paragraph", "[", ":", "-", "1", "]", "# remove trailing space from the paragraph text.", "\n", "rows_converted", "=", "[", "]", "\n", "entities_seen", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "row", "[", "\"sentences\"", "]", ")", ")", ":", "\n", "        ", "sentence", "=", "sentences", "[", "i", "]", "\n", "converted_entities", "=", "update_entity_indices", "(", "row", "[", "\"ner\"", "]", "[", "i", "]", ",", "sentences", "[", "i", "]", ",", "all_tokens", ",", "token_index_mapping", ",", "entities_seen", ",", "token_offsets", "[", "i", "]", ")", "\n", "converted_relations", "=", "update_relation_indices", "(", "row", "[", "\"relations\"", "]", "[", "i", "]", ",", "converted_entities", ",", "token_index_mapping", ")", "\n", "converted_row", "=", "{", "\n", "\"sentence\"", ":", "sentence", ",", "\n", "\"spans\"", ":", "converted_entities", ",", "\n", "\"rels\"", ":", "converted_relations", ",", "\n", "\"paragraph\"", ":", "paragraph", ",", "\n", "}", "\n", "if", "len", "(", "converted_relations", ")", "==", "0", ":", "\n", "# Ignore sentences with no relations annotated.", "\n", "            ", "continue", "\n", "", "rows_converted", ".", "append", "(", "converted_row", ")", "\n", "entities_seen", "+=", "len", "(", "converted_entities", ")", "\n", "", "return", "rows_converted", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.convert_scierc_split": [[177, 190], ["converted_rows.extend", "convert_scierc.convert_scierc_rows"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.convert_scierc_rows"], ["", "def", "convert_scierc_split", "(", "split_data", ":", "List", "[", "Dict", "]", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "\"\"\"Convert a split of SciERC data (dev, train, or test) into Drug Synergy Dataset format.\n\n    Args:\n        split_data: SciERC split\n\n    Returns:\n        converted_rows: SciERC split converted into Synergy Dataset format\n    \"\"\"", "\n", "converted_rows", "=", "[", "]", "\n", "for", "raw_row", "in", "split_data", ":", "\n", "        ", "converted_rows", ".", "extend", "(", "convert_scierc_rows", "(", "raw_row", ")", ")", "\n", "", "return", "converted_rows", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.accumulate_relation_labels": [[191, 199], ["len"], "function", ["None"], ["", "def", "accumulate_relation_labels", "(", "dataset", ":", "List", "[", "Dict", "]", ")", "->", "List", "[", "Dict", "]", ":", "\n", "    ", "label2idx", "=", "{", "}", "\n", "for", "document", "in", "dataset", ":", "\n", "        ", "for", "relation", "in", "document", "[", "\"rels\"", "]", ":", "\n", "            ", "relation_label", "=", "relation", "[", "\"class\"", "]", "\n", "if", "relation_label", "not", "in", "label2idx", ":", "\n", "                ", "label2idx", "[", "relation_label", "]", "=", "len", "(", "label2idx", ")", "+", "1", "\n", "", "", "", "return", "label2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.test_convert_scierc.test_detokenize_sentence": [[3, 10], ["convert_scierc.detokenize_sentence"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.detokenize_sentence"], ["def", "test_detokenize_sentence", "(", ")", ":", "\n", "    ", "tokens", "=", "[", "\"This\"", ",", "\"is\"", ",", "\"a\"", ",", "\"test\"", ",", "\"sentence\"", ",", "\".\"", "]", "\n", "detokenized_sentence", ",", "token_char_mapping", "=", "detokenize_sentence", "(", "tokens", ",", "20", ")", "\n", "correct_detokenized_sentence", "=", "\"This is a test sentence .\"", "\n", "assert", "detokenized_sentence", "==", "correct_detokenized_sentence", "\n", "correct_token_char_mapping", "=", "{", "20", ":", "(", "0", ",", "4", ")", ",", "21", ":", "(", "5", ",", "7", ")", ",", "22", ":", "(", "8", ",", "9", ")", ",", "23", ":", "(", "10", ",", "14", ")", ",", "24", ":", "(", "15", ",", "23", ")", ",", "25", ":", "(", "24", ",", "25", ")", "}", "\n", "assert", "token_char_mapping", "==", "correct_token_char_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.test_convert_scierc.test_convert_scierc_rows": [[11, 66], ["convert_scierc.convert_scierc_rows"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.dataset_conversion.convert_scierc.convert_scierc_rows"], ["", "def", "test_convert_scierc_rows", "(", ")", ":", "\n", "    ", "sentences", "=", "[", "[", "\"Self-attention\"", ",", "\"models\"", ",", "\"are\"", ",", "\"used\"", ",", "\"for\"", ",", "\"NLP\"", ",", "\".\"", "]", ",", "[", "\"Moreover\"", ",", "\",\"", ",", "\"self-attention\"", ",", "\"is\"", ",", "\"one\"", ",", "\"kind\"", ",", "\"of\"", ",", "\"neural\"", ",", "\"network\"", ",", "\"component\"", ",", "\".\"", "]", "]", "\n", "test_scierc_row", "=", "{", "\n", "\"sentences\"", ":", "sentences", ",", "\n", "\"ner\"", ":", "[", "[", "[", "0", ",", "0", ",", "\"Method\"", "]", ",", "[", "5", ",", "5", ",", "\"OtherScientificTerm\"", "]", "]", ",", "[", "[", "9", ",", "9", ",", "\"Method\"", "]", ",", "[", "14", ",", "16", ",", "\"OtherScientificTerm\"", "]", "]", "]", ",", "\n", "\"relations\"", ":", "[", "[", "[", "0", ",", "0", ",", "5", ",", "5", ",", "\"USED-FOR\"", "]", "]", ",", "[", "[", "9", ",", "9", ",", "14", ",", "16", ",", "\"HYPONYM-OF\"", "]", "]", "]", ",", "\n", "\"doc_key\"", ":", "\"test\"", "\n", "}", "\n", "\n", "converted_row", "=", "convert_scierc_rows", "(", "test_scierc_row", ")", "\n", "correct_paragraph", "=", "\"Self-attention models are used for NLP . Moreover , self-attention is one kind of neural network component .\"", "\n", "correct_first_sentence", "=", "\"Self-attention models are used for NLP .\"", "\n", "correct_second_sentence", "=", "\"Moreover , self-attention is one kind of neural network component .\"", "\n", "assert", "converted_row", "[", "0", "]", "[", "\"paragraph\"", "]", "==", "correct_paragraph", "\n", "assert", "converted_row", "[", "1", "]", "[", "\"paragraph\"", "]", "==", "correct_paragraph", "\n", "assert", "converted_row", "[", "0", "]", "[", "\"sentence\"", "]", "==", "correct_first_sentence", "\n", "assert", "converted_row", "[", "1", "]", "[", "\"sentence\"", "]", "==", "correct_second_sentence", "\n", "correct_spans", "=", "[", "[", "{", "\n", "\"span_id\"", ":", "0", ",", "\n", "\"text\"", ":", "\"Self-attention\"", ",", "\n", "\"start\"", ":", "0", ",", "\n", "\"end\"", ":", "14", ",", "\n", "\"token_start\"", ":", "0", ",", "\n", "\"token_end\"", ":", "0", "\n", "}", ",", "\n", "{", "\n", "\"span_id\"", ":", "1", ",", "\n", "\"text\"", ":", "\"NLP\"", ",", "\n", "\"start\"", ":", "35", ",", "\n", "\"end\"", ":", "38", ",", "\n", "\"token_start\"", ":", "5", ",", "\n", "\"token_end\"", ":", "5", "\n", "}", "]", ",", "\n", "[", "{", "\n", "\"span_id\"", ":", "2", ",", "\n", "\"text\"", ":", "\"self-attention\"", ",", "\n", "\"start\"", ":", "11", ",", "\n", "\"end\"", ":", "25", ",", "\n", "\"token_start\"", ":", "2", ",", "\n", "\"token_end\"", ":", "2", "\n", "}", ",", "\n", "{", "\n", "\"span_id\"", ":", "3", ",", "\n", "\"text\"", ":", "\"neural network component\"", ",", "\n", "\"start\"", ":", "41", ",", "\n", "\"end\"", ":", "65", ",", "\n", "\"token_start\"", ":", "7", ",", "\n", "\"token_end\"", ":", "9", "\n", "}", "]", "]", "\n", "assert", "converted_row", "[", "0", "]", "[", "\"spans\"", "]", "==", "correct_spans", "[", "0", "]", "\n", "assert", "converted_row", "[", "1", "]", "[", "\"spans\"", "]", "==", "correct_spans", "[", "1", "]", "\n", "assert", "converted_row", "[", "0", "]", "[", "\"sentence\"", "]", "[", "0", ":", "14", "]", "==", "\"Self-attention\"", "\n", "assert", "converted_row", "[", "0", "]", "[", "\"sentence\"", "]", "[", "35", ":", "38", "]", "==", "\"NLP\"", "\n", "assert", "converted_row", "[", "1", "]", "[", "\"sentence\"", "]", "[", "11", ":", "25", "]", "==", "\"self-attention\"", "\n", "assert", "converted_row", "[", "1", "]", "[", "\"sentence\"", "]", "[", "41", ":", "65", "]", "==", "\"neural network component\"", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.utils.tokenizer.make_tok_seg": [[4, 84], ["spacy.Language.component", "spacy.load", "spacy.load.add_pipe", "enumerate", "spacy.load.tokenizer.add_special_case", "special_case.upper", "spacy.load.tokenizer.add_special_case", "special_case.capitalize", "spacy.load.tokenizer.add_special_case", "spacy.load.tokenizer.add_special_case", "dict", "dict", "dict", "dict", "dict", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["def", "make_tok_seg", "(", ")", ":", "\n", "    ", "'''\n    Add a few special cases to spacy tokenizer so it works with ACe mistakes.\n    '''", "\n", "# Prevent edge case where there are sentence breaks in bad places", "\n", "@", "Language", ".", "component", "(", "'custom_seg'", ")", "\n", "def", "custom_seg", "(", "doc", ")", ":", "\n", "        ", "for", "index", ",", "token", "in", "enumerate", "(", "doc", ")", ":", "\n", "            ", "if", "'--'", "in", "token", ".", "text", ":", "\n", "                ", "doc", "[", "index", "]", ".", "sent_start", "=", "False", "\n", "if", "index", "<", "len", "(", "doc", ")", "-", "1", ":", "\n", "                    ", "doc", "[", "index", "+", "1", "]", ".", "sent_start", "=", "False", "\n", "# Comma followed by whitespace doesn't end a sentence.", "\n", "", "", "if", "token", ".", "text", "==", "\",\"", "and", "index", "<", "len", "(", "doc", ")", "-", "2", "and", "doc", "[", "index", "+", "1", "]", ".", "is_space", ":", "\n", "                ", "doc", "[", "index", "+", "2", "]", ".", "sent_start", "=", "False", "\n", "# \"And\" only starts a sentence if preceded by period or question mark.", "\n", "", "if", "token", ".", "text", "in", "[", "\"and\"", ",", "\"but\"", "]", "and", "index", ">=", "1", "and", "doc", "[", "index", "-", "1", "]", ".", "text", "not", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n", "                ", "doc", "[", "index", "]", ".", "sent_start", "=", "False", "\n", "", "if", "(", "not", "(", "(", "token", ".", "is_punct", "and", "token", ".", "text", "not", "in", "[", "\",\"", ",", "\"_\"", ",", "\";\"", ",", "\"...\"", ",", "\":\"", ",", "\"(\"", ",", "\")\"", ",", "'\"'", "]", ")", "or", "token", ".", "is_space", ")", "\n", "and", "index", "<", "len", "(", "doc", ")", "-", "1", ")", ":", "\n", "                ", "doc", "[", "index", "+", "1", "]", ".", "sent_start", "=", "False", "\n", "", "if", "\"\\n\"", "in", "token", ".", "text", ":", "\n", "                ", "if", "index", "+", "1", "<", "len", "(", "doc", ")", ":", "\n", "                    ", "next_token", "=", "doc", "[", "index", "+", "1", "]", "\n", "if", "len", "(", "token", ")", ">", "1", ":", "\n", "                        ", "next_token", ".", "sent_start", "=", "True", "\n", "", "else", ":", "\n", "                        ", "next_token", ".", "sent_start", "=", "False", "\n", "", "", "", "if", "token", ".", "text", "==", "\"-\"", ":", "\n", "                ", "if", "index", ">", "0", "and", "index", "<", "len", "(", "doc", ")", "-", "1", ":", "\n", "                    ", "before", "=", "doc", "[", "index", "-", "1", "]", "\n", "after", "=", "doc", "[", "index", "+", "1", "]", "\n", "if", "not", "(", "before", ".", "is_space", "or", "before", ".", "is_punct", "or", "after", ".", "is_space", "or", "after", ".", "is_punct", ")", ":", "\n", "                        ", "after", ".", "sent_start", "=", "False", "\n", "", "", "", "", "return", "doc", "\n", "\n", "", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "nlp", ".", "add_pipe", "(", "'custom_seg'", ",", "before", "=", "'parser'", ")", "\n", "\n", "single_tokens", "=", "[", "'sgt.'", ",", "\n", "'sen.'", ",", "\n", "'col.'", ",", "\n", "'brig.'", ",", "\n", "'gen.'", ",", "\n", "'maj.'", ",", "\n", "'sr.'", ",", "\n", "'lt.'", ",", "\n", "'cmdr.'", ",", "\n", "'u.s.'", ",", "\n", "'mr.'", ",", "\n", "'p.o.w.'", ",", "\n", "'u.k.'", ",", "\n", "'u.n.'", ",", "\n", "'ft.'", ",", "\n", "'dr.'", ",", "\n", "'d.c.'", ",", "\n", "'mt.'", ",", "\n", "'st.'", ",", "\n", "'snr.'", ",", "\n", "'rep.'", ",", "\n", "'ms.'", ",", "\n", "'capt.'", ",", "\n", "'sq.'", ",", "\n", "'jr.'", ",", "\n", "'ave.'", "]", "\n", "for", "special_case", "in", "single_tokens", ":", "\n", "        ", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "special_case", ",", "[", "dict", "(", "ORTH", "=", "special_case", ")", "]", ")", "\n", "upped", "=", "special_case", ".", "upper", "(", ")", "\n", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "upped", ",", "[", "dict", "(", "ORTH", "=", "upped", ")", "]", ")", "\n", "capped", "=", "special_case", ".", "capitalize", "(", ")", "\n", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "capped", ",", "[", "dict", "(", "ORTH", "=", "capped", ")", "]", ")", "\n", "\n", "", "split_tokens", "=", "[", "\n", "(", "\"Fe.\"", ",", "(", "\"Fe\"", ",", "\".\"", ")", ")", ",", "\n", "(", "\"A.\"", ",", "(", "\"A\"", ",", "\".\"", ")", ")", ",", "\n", "]", "\n", "for", "(", "orig", ",", "(", "split_a", ",", "split_b", ")", ")", "in", "split_tokens", ":", "\n", "        ", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "orig", ",", "[", "dict", "(", "ORTH", "=", "split_a", ")", ",", "dict", "(", "ORTH", "=", "split_b", ")", "]", ")", "\n", "\n", "", "return", "nlp", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.ModelOutput.__init__": [[22, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ",", "loss", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "self", ".", "loss", "=", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.BertForRelation.__init__": [[28, 61], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "model.BertForRelation.bert.named_parameters", "torch.nn.Dropout", "torch.nn.Dropout", "BertLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "model.BertForRelation.init_weights"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "config", ":", "PretrainedConfig", ",", "\n", "num_rel_labels", ":", "int", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "unfreeze_all_bert_layers", ":", "bool", "=", "False", ",", "\n", "unfreeze_final_bert_layer", ":", "bool", "=", "False", ",", "\n", "unfreeze_bias_terms_only", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"Initialize simple BERT-based relation extraction model\n\n        Args:\n            config: Pretrained model config (loaded from model)\n            num_rel_labels: Size of label set that each relation could take\n            unfreeze_all_bert_layers: Finetune all layers of BERT\n            unfreeze_final_bert_layer: Finetune only the final encoder layer of BERT\n            unfreeze_bias_terms_only: Finetune only the bias terms in BERT (aka BitFit)\n        \"\"\"", "\n", "super", "(", "BertForRelation", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_rel_labels", "=", "num_rel_labels", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "bert", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "unfreeze_final_bert_layer", ":", "\n", "                ", "if", "\"encoder.layer.11\"", "not", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "elif", "unfreeze_bias_terms_only", ":", "\n", "                ", "if", "\"bias\"", "not", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "elif", "not", "unfreeze_all_bert_layers", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "num_rel_labels", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.BertForRelation.forward": [[63, 101], ["model.BertForRelation.bert", "sequence_output.transpose", "all_entity_idxs.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "entity_vectors.squeeze.squeeze.squeeze", "model.BertForRelation.layer_norm", "model.BertForRelation.dropout", "model.BertForRelation.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "input_ids", ":", "torch", ".", "Tensor", ",", "\n", "token_type_ids", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "labels", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "all_entity_idxs", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "input_position", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "ModelOutput", ":", "\n", "        ", "\"\"\"BertForRelation model, forward pass.\n\n        Args:\n            input_ids: Subword indices in the vocabulary for words in the document\n            token_type_ids: Sequence segment IDs (currently set to all 0's) - TODO(Vijay): update this\n            attention_mask: Mask which describes which tokens should be ignored (i.e. padding tokens)\n            labels: Tensor of numerical labels\n            all_entity_idxs: Tensor of indices of each drug entity's special start token in each document\n            input_position: Just here to satisfy the interface (TODO(Vijay): remove this if possible)\n        \"\"\"", "\n", "# TODO(Vijay): delete input_positions, since it's seemingly not used", "\n", "# TODO(Vijay): analyze the output with the `output_attentions` flag, to help interpret the model's predictions.", "\n", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "output_attentions", "=", "False", ",", "\n", "position_ids", "=", "input_position", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output_transposed", "=", "sequence_output", ".", "transpose", "(", "1", ",", "2", ")", "\n", "all_entity_idxs_transposed", "=", "all_entity_idxs", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# all_entity_idxs_transposed contains weighted values of each entity in the document, giving effectively", "\n", "# a weightec average of entity embeddings across the document.", "\n", "entity_vectors", "=", "torch", ".", "matmul", "(", "sequence_output_transposed", ",", "all_entity_idxs_transposed", ")", "\n", "entity_vectors", "=", "entity_vectors", ".", "squeeze", "(", "2", ")", "# Squeeze 768 x 1 vector into a single row of dimension 768", "\n", "\n", "rep", "=", "self", ".", "layer_norm", "(", "entity_vectors", ")", "\n", "rep", "=", "self", ".", "dropout", "(", "rep", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "rep", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.BertForRelation.make_predictions": [[102, 107], ["model.BertForRelation.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["None"], ["", "def", "make_predictions", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "labels", ",", "all_entity_idxs", ",", "_", "=", "inputs", "\n", "logits", "=", "self", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ",", "labels", "=", "labels", ",", "all_entity_idxs", "=", "all_entity_idxs", ")", "\n", "predictions", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.BertForRelation.predict_probabilities": [[108, 113], ["model.BertForRelation.", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax"], "methods", ["None"], ["", "def", "predict_probabilities", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "labels", ",", "all_entity_idxs", ",", "_", "=", "inputs", "\n", "logits", "=", "self", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ",", "labels", "=", "labels", ",", "all_entity_idxs", "=", "all_entity_idxs", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.__init__": [[115, 155], ["pytorch_lightning.LightningModule.__init__", "model.RelationExtractor.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ":", "BertForRelation", ",", "\n", "num_train_optimization_steps", ":", "int", ",", "\n", "tokenizer", ":", "AutoTokenizer", ",", "\n", "lr", ":", "float", "=", "5e-4", ",", "\n", "correct_bias", ":", "bool", "=", "True", ",", "\n", "warmup_proportion", ":", "float", "=", "0.1", ",", "\n", "optimizer_strategy", ":", "Callable", "=", "simple_adamw", ",", "\n", "label_weights", ":", "Optional", "[", "List", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"PyTorch Lightning module which wraps the BERT-based model.\n\n        Args:\n            model: Base BERT model for relation classification\n            num_train_optimization_steps: Number of optimization steps in training\n            lr: Learning rate\n            correct_bias: Whether to correct bias in AdamW\n            warmup_proportion: How much data to reserve for linear learning rate warmup (https://paperswithcode.com/method/linear-warmup)\n            optimizer_strategy: Constructor to create an optimizer to use (e.g. AdamW with a linear warmup schedule)\n        \"\"\"", "\n", "# TODO(Vijay): configure these parameters via command line arguments.", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "num_train_optimization_steps", "=", "num_train_optimization_steps", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "correct_bias", "=", "correct_bias", "\n", "self", ".", "warmup_proportion", "=", "warmup_proportion", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "test_sentences", "=", "[", "]", "\n", "self", ".", "test_row_idxs", "=", "[", "]", "\n", "self", ".", "test_predictions", "=", "[", "]", "\n", "self", ".", "test_pred_probas", "=", "[", "]", "\n", "self", ".", "test_batch_idxs", "=", "[", "]", "\n", "self", ".", "optimizer_strategy", "=", "optimizer_strategy", "\n", "if", "label_weights", "is", "not", "None", ":", "\n", "# This defines a class variable, but automatically moves the tensor to the", "\n", "# device that the module trains on.", "\n", "            ", "self", ".", "register_buffer", "(", "\"label_weights\"", ",", "torch", ".", "tensor", "(", "label_weights", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "label_weights", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.configure_optimizers": [[156, 158], ["model.RelationExtractor.optimizer_strategy", "model.RelationExtractor.named_parameters"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "optimizer_strategy", "(", "self", ".", "named_parameters", "(", ")", ",", "self", ".", "lr", ",", "self", ".", "correct_bias", ",", "self", ".", "num_train_optimization_steps", ",", "self", ".", "warmup_proportion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.forward": [[159, 163], ["model.RelationExtractor.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "pass_text", "=", "True", ")", ":", "\n", "        ", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "labels", ",", "all_entity_idxs", ",", "_", "=", "inputs", "\n", "logits", "=", "self", ".", "model", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ",", "labels", "=", "labels", ",", "all_entity_idxs", "=", "all_entity_idxs", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.training_step": [[164, 189], ["model.RelationExtractor.", "torch.cross_entropy", "torch.cross_entropy", "model.RelationExtractor.log", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "common.utils.accuracy", "common.utils.compute_f1", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.view", "labels.view"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.accuracy", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.compute_f1"], ["", "def", "training_step", "(", "self", ",", "inputs", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"Training step in PyTorch Lightning.\n\n        Args:\n            inputs: Batch of data points\n            batch_idx: Not used in this model (just here to satisfy the interface)\n\n        Return:\n            Loss tensor\n        \"\"\"", "\n", "# outputs: TokenClassifierOutput", "\n", "_", ",", "_", ",", "_", ",", "labels", ",", "_", ",", "_", "=", "inputs", "\n", "logits", "=", "self", "(", "inputs", ",", "pass_text", "=", "True", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "model", ".", "num_rel_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ",", "weight", "=", "self", ".", "label_weights", ")", "\n", "self", ".", "log", "(", "\"loss\"", ",", "loss", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "\n", "predictions", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "acc", "=", "accuracy", "(", "predictions", ",", "labels", ")", "\n", "metrics_dict", "=", "compute_f1", "(", "predictions", ",", "labels", ")", "\n", "f", ",", "prec", ",", "rec", "=", "metrics_dict", "[", "\"f1\"", "]", ",", "metrics_dict", "[", "\"precision\"", "]", ",", "metrics_dict", "[", "\"recall\"", "]", "\n", "self", ".", "log", "(", "\"accuracy\"", ",", "acc", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "self", ".", "log", "(", "\"precision\"", ",", "prec", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "self", ".", "log", "(", "\"recall\"", ",", "rec", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "self", ".", "log", "(", "\"f1\"", ",", "f", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ",", "on_step", "=", "True", ",", "on_epoch", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.validation_step": [[190, 207], ["model.RelationExtractor.", "torch.cross_entropy", "torch.cross_entropy", "model.RelationExtractor.log", "model.RelationExtractor.view", "labels.view"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "inputs", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"Validation step in PyTorch Lightning.\n\n        Args:\n            inputs: Batch of data points\n            batch_idx: Not used in this model (just here to satisfy the interface)\n\n        Return:\n            Loss tensor\n        \"\"\"", "\n", "# outputs: TokenClassifierOutput", "\n", "_", ",", "_", ",", "_", ",", "labels", ",", "_", ",", "_", "=", "inputs", "\n", "logits", "=", "self", "(", "inputs", ",", "pass_text", "=", "True", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "model", ".", "num_rel_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ",", "weight", "=", "self", ".", "label_weights", ")", "\n", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss", ",", "prog_bar", "=", "False", ",", "logger", "=", "True", ",", "on_step", "=", "False", ",", "on_epoch", "=", "False", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.RelationExtractor.test_step": [[208, 238], ["model.RelationExtractor.", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.cross_entropy", "torch.cross_entropy", "model.RelationExtractor.log", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "model.RelationExtractor.test_sentences.extend", "model.RelationExtractor.test_row_idxs.extend", "model.RelationExtractor.test_predictions.extend", "model.RelationExtractor.test_pred_probas.extend", "model.RelationExtractor.test_batch_idxs.extend", "common.utils.accuracy", "common.utils.compute_f1", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.log", "model.RelationExtractor.tokenizer.convert_ids_to_tokens", "model.RelationExtractor.view", "labels.view", "row_ids.tolist", "torch.argmax.tolist", "torch.argmax.tolist", "torch.nn.functional.softmax.tolist", "torch.nn.functional.softmax.tolist", "torch.argmax.tolist", "torch.argmax.tolist"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.accuracy", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.compute_f1"], ["", "def", "test_step", "(", "self", ",", "inputs", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"Testing step in PyTorch Lightning.\n\n        Args:\n            inputs: Batch of data points\n            batch_idx: Not used in this model (just here to satisfy the interface)\n\n        Return:\n            Accuracy value (float) on the test set\n        \"\"\"", "\n", "input_ids", ",", "_", ",", "_", ",", "labels", ",", "_", ",", "row_ids", "=", "inputs", "\n", "logits", "=", "self", "(", "inputs", ",", "pass_text", "=", "True", ")", "\n", "softmaxes", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "raw_text", "=", "[", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "for", "ids", "in", "input_ids", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "model", ".", "num_rel_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ",", "weight", "=", "self", ".", "label_weights", ")", "\n", "\n", "self", ".", "log", "(", "\"test_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "predictions", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "self", ".", "test_sentences", ".", "extend", "(", "raw_text", ")", "\n", "self", ".", "test_row_idxs", ".", "extend", "(", "row_ids", ".", "tolist", "(", ")", ")", "\n", "self", ".", "test_predictions", ".", "extend", "(", "predictions", ".", "tolist", "(", ")", ")", "\n", "self", ".", "test_pred_probas", ".", "extend", "(", "softmaxes", ".", "tolist", "(", ")", ")", "\n", "self", ".", "test_batch_idxs", ".", "extend", "(", "[", "batch_idx", "for", "_", "in", "predictions", ".", "tolist", "(", ")", "]", ")", "\n", "acc", "=", "accuracy", "(", "predictions", ",", "labels", ")", "\n", "metrics_dict", "=", "compute_f1", "(", "predictions", ",", "labels", ")", "\n", "f", ",", "prec", ",", "rec", "=", "metrics_dict", "[", "\"f1\"", "]", ",", "metrics_dict", "[", "\"precision\"", "]", ",", "metrics_dict", "[", "\"recall\"", "]", "\n", "self", ".", "log", "(", "\"accuracy\"", ",", "acc", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "self", ".", "log", "(", "\"precision\"", ",", "prec", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "self", ".", "log", "(", "\"recall\"", ",", "rec", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "self", ".", "log", "(", "\"f1\"", ",", "f", ",", "prog_bar", "=", "True", ",", "logger", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.load_model": [[239, 263], ["common.utils.load_metadata", "BertForRelation.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoTokenizer.from_pretrained.from_pretrained", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.load_metadata"], ["", "", "def", "load_model", "(", "checkpoint_directory", ":", "str", ")", "->", "Tuple", "[", "BertForRelation", ",", "AutoTokenizer", ",", "int", ",", "Dict", ",", "bool", "]", ":", "\n", "    ", "'''Given a directory containing a model checkpoint, return the model, and other metadata regarding the data\n    preprocessing that the model expects.\n\n    Args:\n        checkpoint_directory: Path to local directory where model is serialized\n\n    Returns:\n        model: Pretrained BertForRelation model\n        tokenizer: Hugging Face tokenizer loaded from disk\n        max_seq_length: Maximum number of subwords in a document allowed by the model (if longer, truncate input)\n        label2idx: Mapping from label strings to numerical label indices\n        include_paragraph_context: Whether or not to include paragraph context in addition to the relation-bearing sentence\n    '''", "\n", "metadata", "=", "load_metadata", "(", "checkpoint_directory", ")", "\n", "model", "=", "BertForRelation", ".", "from_pretrained", "(", "\n", "checkpoint_directory", ",", "\n", "cache_dir", "=", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", ",", "\n", "num_rel_labels", "=", "metadata", ".", "num_labels", ",", "\n", "max_seq_length", "=", "metadata", ".", "max_seq_length", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "metadata", ".", "model_name", ",", "do_lower_case", "=", "True", ")", "\n", "tokenizer", ".", "from_pretrained", "(", "os", ".", "path", ".", "join", "(", "checkpoint_directory", ",", "\"tokenizer\"", ")", ")", "\n", "return", "model", ",", "tokenizer", ",", "metadata", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.optimizers.adamw_with_linear_warmup": [[3, 21], ["list", "transformers.AdamW", "int", "transformers.get_linear_schedule_with_warmup", "any", "any"], "function", ["None"], ["def", "adamw_with_linear_warmup", "(", "named_parameters", ",", "lr", ",", "correct_bias", ",", "num_train_optimization_steps", ",", "warmup_proportion", ")", ":", "\n", "# Decay scheme taken from https://github.com/princeton-nlp/PURE/blob/main/run_relation.py#L384.", "\n", "        ", "param_optimizer", "=", "list", "(", "named_parameters", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "correct_bias", "=", "correct_bias", ")", "\n", "optimization_steps", "=", "int", "(", "num_train_optimization_steps", "*", "warmup_proportion", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "optimization_steps", ",", "\n", "num_train_optimization_steps", ")", "\n", "return", "{", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.optimizers.simple_adamw": [[23, 26], ["transformers.AdamW"], "function", ["None"], ["", "def", "simple_adamw", "(", "named_parameters", ",", "lr", ",", "correct_bias", ",", "num_train_optimization_steps", "=", "None", ",", "warmup_proportion", "=", "None", ")", ":", "\n", "    ", "parameters", "=", "[", "p", "for", "n", ",", "p", "in", "named_parameters", "]", "\n", "return", "AdamW", "(", "parameters", ",", "lr", "=", "lr", ",", "correct_bias", "=", "correct_bias", ")", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.construct_filter_map": [[61, 93], ["context_required.append", "set", "preprocessing.preprocess.powerset", "list.get", "len", "set", "set", "list", "tuple", "set.add", "[].lower", "sorted", "len", "tuple", "[].lower", "sorted", "str", "str"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.powerset"], ["def", "construct_filter_map", "(", "raw_test_data", ",", "raw_train_data", ",", "bucket_type", ")", ":", "\n", "    ", "relation_mapping", "=", "{", "}", "\n", "if", "bucket_type", "==", "\"context_required\"", ":", "\n", "        ", "for", "doc", "in", "raw_test_data", ":", "\n", "            ", "context_required", "=", "[", "]", "\n", "for", "rel", "in", "doc", "[", "\"rels\"", "]", ":", "\n", "                ", "context_required", ".", "append", "(", "rel", ".", "get", "(", "\"is_context_needed\"", ",", "False", ")", ")", "\n", "", "if", "len", "(", "context_required", ")", "==", "0", "or", "set", "(", "context_required", ")", "==", "{", "False", "}", ":", "\n", "                ", "relation_mapping", "[", "(", "doc", "[", "\"doc_id\"", "]", ",", "\"*\"", ")", "]", "=", "False", "\n", "", "elif", "set", "(", "context_required", ")", "==", "{", "True", "}", ":", "\n", "                ", "relation_mapping", "[", "(", "doc", "[", "\"doc_id\"", "]", ",", "\"*\"", ")", "]", "=", "True", "\n", "", "", "", "elif", "bucket_type", "in", "[", "\"arity\"", ",", "\"relations_seen_in_training\"", "]", ":", "\n", "        ", "if", "bucket_type", "==", "\"relations_seen_in_training\"", ":", "\n", "            ", "training_relations", "=", "set", "(", ")", "\n", "for", "doc", "in", "raw_train_data", ":", "\n", "                ", "for", "rel", "in", "doc", "[", "\"rels\"", "]", ":", "\n", "                    ", "rel_drugs", "=", "[", "doc", "[", "\"spans\"", "]", "[", "entity_idx", "]", "[", "\"text\"", "]", ".", "lower", "(", ")", "for", "entity_idx", "in", "rel", "[", "\"spans\"", "]", "]", "\n", "rel_drugs", "=", "tuple", "(", "sorted", "(", "rel_drugs", ")", ")", "\n", "training_relations", ".", "add", "(", "rel_drugs", ")", "\n", "", "", "", "for", "doc", "in", "raw_test_data", ":", "\n", "            ", "rel_powerset", "=", "powerset", "(", "[", "span", "[", "\"span_id\"", "]", "for", "span", "in", "doc", "[", "\"spans\"", "]", "]", ")", "\n", "for", "rel", "in", "rel_powerset", ":", "\n", "                ", "rel", "=", "list", "(", "rel", ")", "\n", "if", "bucket_type", "==", "\"arity\"", ":", "\n", "# split relations on whether the arity is 2 or greater than 2", "\n", "                    ", "relation_mapping", "[", "(", "doc", "[", "\"doc_id\"", "]", ",", "str", "(", "rel", ")", ")", "]", "=", "len", "(", "rel", ")", ">", "2", "\n", "", "elif", "bucket_type", "==", "\"relations_seen_in_training\"", ":", "\n", "# split relations on whether the relation was observed as is in training", "\n", "                    ", "rel_drugs", "=", "[", "doc", "[", "\"spans\"", "]", "[", "entity_idx", "]", "[", "\"text\"", "]", ".", "lower", "(", ")", "for", "entity_idx", "in", "rel", "]", "\n", "rel_drugs", "=", "tuple", "(", "sorted", "(", "rel_drugs", ")", ")", "\n", "relation_mapping", "[", "(", "doc", "[", "\"doc_id\"", "]", ",", "str", "(", "rel", ")", ")", "]", "=", "rel_drugs", "in", "training_relations", "\n", "", "", "", "", "return", "relation_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.split_data": [[94, 132], ["range", "len", "len", "len", "single_gold.items", "single_pred.items", "all_preds_a.append", "all_preds_b.append", "all_golds_a.append", "all_golds_b.append", "filter_map.get", "filter_map.get", "filter_map.get", "filter_map.get", "list", "list", "list", "list", "single_pred_split_a.items", "single_pred_split_b.items", "single_gold_split_a.items", "single_gold_split_b.items"], "function", ["None"], ["", "def", "split_data", "(", "all_golds", ",", "all_preds", ",", "filter_map", ")", ":", "\n", "    ", "all_golds_a", "=", "[", "]", "\n", "all_golds_b", "=", "[", "]", "\n", "all_preds_a", "=", "[", "]", "\n", "all_preds_b", "=", "[", "]", "\n", "assert", "len", "(", "all_golds", ")", "==", "len", "(", "all_preds", ")", "\n", "for", "seed", "in", "range", "(", "len", "(", "all_golds", ")", ")", ":", "\n", "        ", "single_pred", "=", "all_preds", "[", "seed", "]", "\n", "\n", "single_gold", "=", "all_golds", "[", "seed", "]", "\n", "single_gold_split_a", "=", "{", "}", "\n", "single_gold_split_b", "=", "{", "}", "\n", "\n", "for", "k", ",", "v", "in", "single_gold", ".", "items", "(", ")", ":", "\n", "            ", "(", "docid", ",", "drug_idxs_str", ",", "_", ")", "=", "k", "\n", "in_filter", "=", "filter_map", ".", "get", "(", "(", "docid", ",", "drug_idxs_str", ")", ",", "None", ")", "\n", "in_wildcard", "=", "filter_map", ".", "get", "(", "(", "docid", ",", "\"*\"", ")", ",", "None", ")", "\n", "if", "in_filter", "is", "False", "or", "in_wildcard", "is", "False", ":", "\n", "                ", "single_gold_split_a", "[", "k", "]", "=", "v", "\n", "", "elif", "in_filter", "is", "True", "or", "in_wildcard", "is", "True", ":", "\n", "                ", "single_gold_split_b", "[", "k", "]", "=", "v", "\n", "\n", "", "", "single_pred_split_a", "=", "{", "}", "\n", "single_pred_split_b", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "single_pred", ".", "items", "(", ")", ":", "\n", "            ", "(", "docid", ",", "drug_idxs_str", ",", "_", ")", "=", "k", "\n", "in_filter", "=", "filter_map", ".", "get", "(", "(", "docid", ",", "drug_idxs_str", ")", ",", "None", ")", "\n", "in_wildcard", "=", "filter_map", ".", "get", "(", "(", "docid", ",", "\"*\"", ")", ",", "None", ")", "\n", "if", "in_filter", "is", "False", "or", "in_wildcard", "is", "False", ":", "\n", "                ", "single_pred_split_a", "[", "k", "]", "=", "v", "\n", "", "elif", "in_filter", "is", "True", "or", "in_wildcard", "is", "True", ":", "\n", "                ", "single_pred_split_b", "[", "k", "]", "=", "v", "\n", "\n", "", "", "all_preds_a", ".", "append", "(", "list", "(", "single_pred_split_a", ".", "items", "(", ")", ")", ")", "\n", "all_preds_b", ".", "append", "(", "list", "(", "single_pred_split_b", ".", "items", "(", ")", ")", ")", "\n", "all_golds_a", ".", "append", "(", "list", "(", "single_gold_split_a", ".", "items", "(", ")", ")", ")", "\n", "all_golds_b", ".", "append", "(", "list", "(", "single_gold_split_b", ".", "items", "(", ")", ")", ")", "\n", "", "return", "(", "all_preds_a", ",", "all_preds_b", ")", ",", "(", "all_golds_a", ",", "all_golds_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.doc_construct_multibootstrap": [[133, 143], ["list", "eval.get_max_sum_score", "range", "rng.choice", "samples.extend", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_max_sum_score"], ["", "def", "doc_construct_multibootstrap", "(", "rng", ",", "multiseed_samples", ",", "doc_ids", ",", "labeled_score", ")", ":", "\n", "    ", "samples", "=", "[", "]", "\n", "seed_idxs", "=", "list", "(", "range", "(", "len", "(", "multiseed_samples", ")", ")", ")", "\n", "multiseed_docids", "=", "[", "row", "[", "0", "]", "[", "0", "]", "for", "row", "in", "multiseed_samples", "[", "0", "]", "]", "\n", "for", "docid", "in", "doc_ids", ":", "\n", "        ", "seed_idx", "=", "rng", ".", "choice", "(", "seed_idxs", ")", "\n", "# Each row in multiseed_samples consists of ((docid, drug_idxs, true label/predicted label), [(predicted label/true label, score)])", "\n", "doc_samples", "=", "[", "row", "for", "row", "in", "multiseed_samples", "[", "seed_idx", "]", "if", "row", "[", "0", "]", "[", "0", "]", "==", "docid", "]", "\n", "samples", ".", "extend", "(", "doc_samples", ")", "\n", "", "return", "get_max_sum_score", "(", "samples", ",", "labeled", "=", "labeled_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.doc_bootstrap_comparison": [[144, 158], ["numpy.zeros", "numpy.zeros", "range", "len", "len", "len", "bucketing_analysis.doc_construct_multibootstrap", "bucketing_analysis.doc_construct_multibootstrap"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.doc_construct_multibootstrap", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.doc_construct_multibootstrap"], ["", "def", "doc_bootstrap_comparison", "(", "multiseeds_a", ",", "multiseeds_b", ",", "doc_samples_a", ",", "doc_samples_b", ",", "nboot", "=", "1000", ",", "labeled_score", "=", "True", ")", ":", "\n", "    ", "'''\n    Adapted from\n    https://openreview.net/pdf?id=K0E_F0gFDgA\n    '''", "\n", "thetas_a", "=", "np", ".", "zeros", "(", "nboot", ")", "\n", "thetas_b", "=", "np", ".", "zeros", "(", "nboot", ")", "\n", "assert", "len", "(", "doc_samples_a", ")", "==", "len", "(", "doc_samples_b", ")", "\n", "for", "boot_ix", "in", "range", "(", "len", "(", "doc_samples_a", ")", ")", ":", "\n", "        ", "theta_a", "=", "doc_construct_multibootstrap", "(", "rng", ",", "multiseeds_a", ",", "doc_samples_a", "[", "boot_ix", "]", ",", "labeled_score", ")", "\n", "thetas_a", "[", "boot_ix", "]", "=", "theta_a", "\n", "theta_b", "=", "doc_construct_multibootstrap", "(", "rng", ",", "multiseeds_b", ",", "doc_samples_b", "[", "boot_ix", "]", ",", "labeled_score", ")", "\n", "thetas_b", "[", "boot_ix", "]", "=", "theta_b", "\n", "", "return", "thetas_a", ",", "thetas_b", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.sample_random_multibootstrap": [[159, 168], ["list", "range", "eval.get_max_sum_score", "range", "rng.choice", "rng.choice", "samples.append", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_max_sum_score"], ["", "def", "sample_random_multibootstrap", "(", "rng", ",", "multiseed_samples", ",", "num_samples", ",", "labeled_score", ")", ":", "\n", "    ", "samples", "=", "[", "]", "\n", "seed_idxs", "=", "list", "(", "range", "(", "len", "(", "multiseed_samples", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "num_samples", ")", ":", "\n", "        ", "seed_idx", "=", "rng", ".", "choice", "(", "seed_idxs", ")", "\n", "# Each row in multiseed_samples consists of ((docid, drug_idxs, true label/predicted label), [(predicted label/true label, score)])", "\n", "sample", "=", "rng", ".", "choice", "(", "multiseed_samples", "[", "seed_idx", "]", ")", "\n", "samples", ".", "append", "(", "sample", ")", "\n", "", "return", "get_max_sum_score", "(", "samples", ",", "labeled", "=", "labeled_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.random_bootstrap_comparison": [[169, 184], ["numpy.zeros", "numpy.zeros", "min", "min", "range", "bucketing_analysis.sample_random_multibootstrap", "bucketing_analysis.sample_random_multibootstrap", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.sample_random_multibootstrap", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.sample_random_multibootstrap"], ["", "def", "random_bootstrap_comparison", "(", "rng", ",", "multiseeds_a", ",", "multiseeds_b", ",", "nboot", "=", "1000", ",", "labeled_score", "=", "True", ")", ":", "\n", "    ", "'''\n    Adapted from\n    https://openreview.net/pdf?id=K0E_F0gFDgA\n    '''", "\n", "thetas_a", "=", "np", ".", "zeros", "(", "nboot", ")", "\n", "thetas_b", "=", "np", ".", "zeros", "(", "nboot", ")", "\n", "num_samples_a", "=", "min", "(", "[", "len", "(", "multiseed", ")", "for", "multiseed", "in", "multiseeds_a", "]", ")", "\n", "num_samples_b", "=", "min", "(", "[", "len", "(", "multiseed", ")", "for", "multiseed", "in", "multiseeds_b", "]", ")", "\n", "for", "boot_ix", "in", "range", "(", "nboot", ")", ":", "\n", "        ", "theta_a", "=", "sample_random_multibootstrap", "(", "rng", ",", "multiseeds_a", ",", "num_samples_a", ",", "labeled_score", ")", "\n", "thetas_a", "[", "boot_ix", "]", "=", "theta_a", "\n", "theta_b", "=", "sample_random_multibootstrap", "(", "rng", ",", "multiseeds_b", ",", "num_samples_b", ",", "labeled_score", ")", "\n", "thetas_b", "[", "boot_ix", "]", "=", "theta_b", "\n", "", "return", "thetas_a", ",", "thetas_b", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.subsample_doc_ids": [[185, 190], ["range", "sampled_doc_sets.append", "rng.sample", "len"], "function", ["None"], ["", "def", "subsample_doc_ids", "(", "docids", ",", "rng", ",", "nboot", "=", "1000", ")", ":", "\n", "    ", "sampled_doc_sets", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "nboot", ")", ":", "\n", "        ", "sampled_doc_sets", ".", "append", "(", "rng", ".", "sample", "(", "docids", ",", "k", "=", "len", "(", "docids", ")", ")", ")", "\n", "", "return", "sampled_doc_sets", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.compute_f1": [[191, 194], ["None"], "function", ["None"], ["", "def", "compute_f1", "(", "precisions", ",", "recalls", ")", ":", "\n", "    ", "f1", "=", "(", "2", "*", "precisions", "*", "recalls", ")", "/", "(", "precisions", "+", "recalls", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.bucketing_analysis.summarize_parameter_differences": [[195, 198], ["len", "print", "range", "round", "round", "round", "round", "len", "len", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "summarize_parameter_differences", "(", "bootstrap_samples_a", ",", "bootstrap_samples_b", ",", "metric_name", ")", ":", "\n", "    ", "num_better", "=", "len", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "bootstrap_samples_a", ")", ")", "if", "bootstrap_samples_b", "[", "i", "]", ">", "bootstrap_samples_a", "[", "i", "]", "]", ")", "\n", "print", "(", "f\"{metric_name}: Split A has mean {round(np.mean(bootstrap_samples_a), 4)} and std {round(np.std(bootstrap_samples_a), 4)}. Split B has mean {round(np.mean(bootstrap_samples_b), 4)} and std {round(np.std(bootstrap_samples_b), 4)}. Split B is better {num_better} out of {len(bootstrap_samples_a)} times.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.extract_all_candidate_relations_for_document": [[15, 71], ["preprocessing.preprocess.process_doc_with_unknown_relations", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "preprocessing.preprocess.add_entity_markers", "marked_sentences.append", "relations.append", "preprocessing.data_loader.tokenize_sentence", "preprocessing.data_loader.vectorize_subwords", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "numpy.zeros", "torch.tensor.append", "len", "preprocessing.preprocess.truncate_text_into_window", "tuple", "np.zeros.tolist", "sorted", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc_with_unknown_relations", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.add_entity_markers", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.tokenize_sentence", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.vectorize_subwords", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.truncate_text_into_window"], ["def", "extract_all_candidate_relations_for_document", "(", "message", ":", "Dict", ",", "\n", "tokenizer", ":", "AutoTokenizer", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "label2idx", ":", "Dict", ",", "\n", "context_window_size", ":", "int", ",", "\n", "include_paragraph_context", ":", "bool", "=", "True", ",", "\n", "max_num_candidate_relations", ":", "int", "=", "100", ")", ":", "\n", "    ", "'''Given a row from the Drug Synergy dataset, find and display all relations with probability greater than some threshold,\n    by making multiple calls to the relation classifier.\n\n    Args:\n        message: JSON row from the Drug Synergy dataset\n        model: Pretrained BertForRelation model object\n        tokenizer: Hugging Face tokenizer loaded from disk\n        max_seq_length: Maximum number of subwords in a document allowed by the model (if longer, truncate input)\n        label2idx: Mapping from label strings to numerical label indices\n        label_of_interest: Return relations that maximize the probability of this label (typically, this should be 1 for the POS label)\n        include_paragraph_context: Whether or not to include paragraph context in addition to the relation-bearing sentence\n    '''", "\n", "doc_with_unknown_relations", "=", "process_doc_with_unknown_relations", "(", "message", ",", "label2idx", ",", "include_paragraph_context", "=", "include_paragraph_context", ")", "\n", "if", "doc_with_unknown_relations", "is", "None", "or", "len", "(", "doc_with_unknown_relations", ".", "relations", ")", ">", "max_num_candidate_relations", ":", "\n", "        ", "return", "None", ",", "None", "\n", "", "marked_sentences", "=", "[", "]", "\n", "relations", "=", "[", "]", "\n", "\n", "tokenizer_cache", "=", "{", "}", "\n", "\n", "for", "relation", "in", "doc_with_unknown_relations", ".", "relations", ":", "\n", "# Mark drug entities with special tokens.", "\n", "        ", "marked_sentence", "=", "add_entity_markers", "(", "doc_with_unknown_relations", ".", "text", ",", "relation", ".", "drug_entities", ")", "\n", "marked_sentences", ".", "append", "(", "truncate_text_into_window", "(", "marked_sentence", ",", "context_window_size", ")", ")", "\n", "relations", ".", "append", "(", "tuple", "(", "sorted", "(", "[", "drug", ".", "drug_name", "for", "drug", "in", "relation", ".", "drug_entities", "]", ")", ")", ")", "\n", "\n", "", "all_entity_idxs", "=", "[", "]", "\n", "all_input_ids", "=", "[", "]", "\n", "all_token_type_ids", "=", "[", "]", "\n", "all_attention_masks", "=", "[", "]", "\n", "for", "sentence", "in", "marked_sentences", ":", "\n", "        ", "subwords", ",", "entity_start_tokens", "=", "tokenize_sentence", "(", "sentence", ",", "tokenizer", ",", "tokenizer_cache", ")", "\n", "vectorized_row", "=", "vectorize_subwords", "(", "tokenizer", ",", "subwords", ",", "max_seq_length", ")", "\n", "all_input_ids", ".", "append", "(", "vectorized_row", ".", "input_ids", ")", "\n", "all_token_type_ids", ".", "append", "(", "vectorized_row", ".", "attention_mask", ")", "\n", "all_attention_masks", ".", "append", "(", "vectorized_row", ".", "segment_ids", ")", "\n", "\n", "entity_idx_weights", "=", "np", ".", "zeros", "(", "(", "1", ",", "max_seq_length", ")", ")", "\n", "for", "start_token_idx", "in", "entity_start_tokens", ":", "\n", "            ", "if", "start_token_idx", ">=", "max_seq_length", ":", "\n", "                ", "return", "None", ",", "None", "\n", "", "entity_idx_weights", "[", "0", "]", "[", "start_token_idx", "]", "=", "1.0", "/", "len", "(", "entity_start_tokens", ")", "\n", "", "all_entity_idxs", ".", "append", "(", "entity_idx_weights", ".", "tolist", "(", ")", ")", "\n", "\n", "", "all_entity_idxs", "=", "torch", ".", "tensor", "(", "all_entity_idxs", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "all_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "all_token_type_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_masks", "=", "torch", ".", "tensor", "(", "all_attention_masks", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "relations", ",", "(", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "all_entity_idxs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.hash_string": [[72, 74], ["hashlib.md5().hexdigest", "hashlib.md5", "string.encode"], "function", ["None"], ["", "def", "hash_string", "(", "string", ")", ":", "\n", "    ", "return", "hashlib", ".", "md5", "(", "(", "string", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.concate_tensors": [[75, 83], ["range", "enumerate", "len", "torch.cat", "range", "tuple_of_lists[].append", "len"], "function", ["None"], ["", "def", "concate_tensors", "(", "list_of_tuples", ")", ":", "\n", "    ", "tuple_of_lists", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "list_of_tuples", "[", "0", "]", ")", ")", "]", "\n", "for", "tup", "in", "list_of_tuples", ":", "\n", "        ", "for", "i", ",", "val", "in", "enumerate", "(", "tup", ")", ":", "\n", "            ", "tuple_of_lists", "[", "i", "]", ".", "append", "(", "val", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "tuple_of_lists", ")", ")", ":", "\n", "        ", "tuple_of_lists", "[", "i", "]", "=", "torch", ".", "cat", "(", "tuple_of_lists", "[", "i", "]", ")", "\n", "", "return", "tuple_of_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.find_all_relations": [[84, 107], ["model", "torch.nn.functional.softmax", "probability[].tolist", "enumerate", "sorted", "sorted.append"], "function", ["None"], ["", "def", "find_all_relations", "(", "model_inputs", ":", "Tuple", "[", "torch", ".", "Tensor", "]", ",", "\n", "model", ":", "BertForRelation", ",", "\n", "threshold", ":", "float", ",", "\n", "label_of_interest", ":", "int", "=", "1", ")", ":", "\n", "    ", "'''Given a row from the Drug Synergy dataset, find and display all relations with probability greater than some threshold,\n    by making multiple calls to the relation classifier.\n\n    Args:\n        model: Pretrained BertForRelation model object\n        threshold: Classifier threshold\n        label_of_interest: Return relations that maximize the probability of this label (typically, this should be 1 for the POS label)\n    '''", "\n", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "all_entity_idxs", "=", "model_inputs", "\n", "logits", "=", "model", "(", "all_input_ids", ",", "token_type_ids", "=", "all_token_type_ids", ",", "attention_mask", "=", "all_attention_masks", ",", "all_entity_idxs", "=", "all_entity_idxs", ")", "\n", "probability", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ")", "\n", "label_probabilities", "=", "probability", "[", ":", ",", "label_of_interest", "]", ".", "tolist", "(", ")", "\n", "\n", "relation_probabilities", "=", "[", "]", "\n", "for", "i", ",", "probability", "in", "enumerate", "(", "label_probabilities", ")", ":", "\n", "        ", "if", "probability", ">", "threshold", ":", "\n", "            ", "relation_probabilities", ".", "append", "(", "{", "\"drugs\"", ":", "relations", "[", "i", "]", ",", "\"positive probability\"", ":", "probability", "}", ")", "\n", "", "", "relation_probabilities", "=", "sorted", "(", "relation_probabilities", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"positive probability\"", "]", ",", "reverse", "=", "True", ")", "\n", "return", "{", "'relations'", ":", "relation_probabilities", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.load_spike_rows": [[32, 34], ["csv.DictReader", "open"], "function", ["None"], ["def", "load_spike_rows", "(", "spike_file", ")", ":", "\n", "    ", "return", "csv", ".", "DictReader", "(", "open", "(", "spike_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.convert_spike_row_to_model_input": [[35, 55], ["common.utils.find_sent_in_para", "postprocessing.hash_string", "common.utils.find_mentions_in_sentence", "enumerate", "len", "spans_object.append", "[].strip", "[].strip"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.find_sent_in_para", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.data.add_document_ids_to_dataset.hash_string", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.find_mentions_in_sentence"], ["", "def", "convert_spike_row_to_model_input", "(", "row", ",", "drugs_list", ")", ":", "\n", "    ", "sentence_start_idx", ",", "sentence_end_idx", "=", "find_sent_in_para", "(", "row", "[", "\"sentence_text\"", "]", ",", "row", "[", "\"paragraph_text\"", "]", ")", "\n", "doc_id", "=", "hash_string", "(", "row", "[", "\"paragraph_text\"", "]", ")", "\n", "# Update document to insert processed sentence into unprocessed paragraph", "\n", "row", "[", "\"paragraph_text\"", "]", "=", "\" \"", ".", "join", "(", "[", "row", "[", "\"paragraph_text\"", "]", "[", ":", "sentence_start_idx", "]", ".", "strip", "(", ")", ",", "row", "[", "\"sentence_text\"", "]", ",", "row", "[", "\"paragraph_text\"", "]", "[", "sentence_end_idx", ":", "]", ".", "strip", "(", ")", "]", ")", "\n", "matched_drugs", ",", "_", "=", "find_mentions_in_sentence", "(", "row", "[", "\"sentence_text\"", "]", ",", "drugs_list", ")", "\n", "if", "len", "(", "matched_drugs", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "spans_object", "=", "[", "]", "\n", "for", "i", ",", "drug", "in", "enumerate", "(", "matched_drugs", ")", ":", "\n", "        ", "spans_object", ".", "append", "(", "{", "\"span_id\"", ":", "i", ",", "\n", "\"start\"", ":", "drug", ".", "span_start", ",", "\n", "\"end\"", ":", "drug", ".", "span_end", ",", "\n", "\"text\"", ":", "drug", ".", "drug_name", ",", "\n", "\"token_start\"", ":", "-", "1", ",", "# To be lazy, don't populate these two fields since it's not used by our model.", "\n", "\"token_end\"", ":", "-", "1", "}", ")", "\n", "\n", "# Need to have `spans`, `paragraph`, `sentence`", "\n", "", "model_friendly_format", "=", "{", "\"doc_id\"", ":", "doc_id", ",", "\"sentence\"", ":", "row", "[", "\"sentence_text\"", "]", ",", "\"paragraph\"", ":", "row", "[", "\"paragraph_text\"", "]", ",", "\"spans\"", ":", "spans_object", "}", "\n", "return", "model_friendly_format", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.divide_into_batches": [[56, 68], ["range", "math.ceil", "batches.append"], "function", ["None"], ["", "def", "divide_into_batches", "(", "model_inputs", ",", "batch_size", "=", "32", ")", ":", "\n", "    ", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "all_entity_idxs", "=", "model_inputs", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "math", ".", "ceil", "(", "all_input_ids", ".", "shape", "[", "0", "]", "/", "batch_size", ")", ")", ":", "\n", "        ", "start_idx", "=", "i", "*", "batch_size", "\n", "end_idx", "=", "(", "i", "+", "1", ")", "*", "batch_size", "\n", "batch_input_ids", "=", "all_input_ids", "[", "start_idx", ":", "end_idx", "]", "\n", "batch_token_type_ids", "=", "all_token_type_ids", "[", "start_idx", ":", "end_idx", "]", "\n", "batch_attention_masks", "=", "all_attention_masks", "[", "start_idx", ":", "end_idx", "]", "\n", "batch_entity_idxs", "=", "all_entity_idxs", "[", "start_idx", ":", "end_idx", "]", "\n", "batches", ".", "append", "(", "[", "batch_input_ids", ",", "batch_token_type_ids", ",", "batch_attention_masks", ",", "batch_entity_idxs", "]", ")", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.process_batch": [[69, 132], ["postprocessing.concate_tensors", "extract_relations_from_spike.divide_into_batches", "breakpoint", "range", "extract_relations_from_spike.convert_spike_row_to_model_input", "postprocessing.extract_all_candidate_relations_for_document", "batch_candidate_relations.extend", "batch_doc_ids.extend", "batch_texts.extend", "batch_sentences.extend", "tensors.append", "all_input_ids.cuda.cuda", "all_token_type_ids.cuda.cuda", "all_attention_masks.cuda.cuda", "all_entity_idxs.cuda.cuda", "all_relation_probs.extend", "torch.cuda.empty_cache", "len", "len", "len", "dict", "jlines.append", "batch_drug_idxs.append", "torch.cuda.amp.autocast", "model.predict_probabilities", "model.predict_probabilities.detach().cpu().tolist", "zip", "list", "str", "relation_drug_idxs.append", "sorted", "len", "model.predict_probabilities.detach().cpu", "model.predict_probabilities.detach"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.concate_tensors", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.divide_into_batches", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.extract_relations_from_spike.convert_spike_row_to_model_input", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.postprocessing.extract_all_candidate_relations_for_document", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.modeling.model.BertForRelation.predict_probabilities"], ["", "def", "process_batch", "(", "batch", ",", "model", ",", "tokenizer", ",", "relation_labels", ",", "model_metadata", ",", "drugs_list", ",", "batch_size", ")", ":", "\n", "    ", "batch_doc_ids", "=", "[", "]", "\n", "batch_texts", "=", "[", "]", "\n", "batch_sentences", "=", "[", "]", "\n", "batch_candidate_relations", "=", "[", "]", "\n", "batch_drug_idxs", "=", "[", "]", "\n", "tensors", "=", "[", "]", "\n", "for", "row", "in", "batch", ":", "\n", "        ", "message", "=", "convert_spike_row_to_model_input", "(", "row", ",", "drugs_list", ")", "\n", "if", "message", "==", "None", ":", "\n", "            ", "continue", "\n", "", "candidate_relations", ",", "row_tensors", "=", "extract_all_candidate_relations_for_document", "(", "message", ",", "tokenizer", ",", "model_metadata", ".", "max_seq_length", ",", "model_metadata", ".", "label2idx", ",", "model_metadata", ".", "context_window_size", ",", "model_metadata", ".", "include_paragraph_context", ")", "\n", "if", "candidate_relations", "is", "None", "and", "row_tensors", "is", "None", ":", "\n", "# Skip doc.", "\n", "            ", "continue", "\n", "\n", "", "batch_candidate_relations", ".", "extend", "(", "[", "list", "(", "r", ")", "for", "r", "in", "candidate_relations", "]", ")", "\n", "batch_doc_ids", ".", "extend", "(", "[", "str", "(", "message", "[", "\"doc_id\"", "]", ")", "for", "_", "in", "candidate_relations", "]", ")", "\n", "batch_texts", ".", "extend", "(", "[", "message", "[", "\"paragraph\"", "]", "for", "_", "in", "candidate_relations", "]", ")", "\n", "batch_sentences", ".", "extend", "(", "[", "message", "[", "\"sentence\"", "]", "for", "_", "in", "candidate_relations", "]", ")", "\n", "for", "relation", "in", "candidate_relations", ":", "\n", "            ", "relation_drug_idxs", "=", "[", "]", "\n", "for", "drug_name", "in", "relation", ":", "\n", "                ", "matching_span_idxs", "=", "[", "span", "[", "\"span_id\"", "]", "for", "span", "in", "message", "[", "\"spans\"", "]", "if", "span", "[", "\"text\"", "]", "==", "drug_name", "]", "\n", "assert", "len", "(", "matching_span_idxs", ")", ">", "0", "\n", "relation_drug_idxs", ".", "append", "(", "matching_span_idxs", "[", "0", "]", ")", "\n", "", "batch_drug_idxs", ".", "append", "(", "sorted", "(", "relation_drug_idxs", ")", ")", "\n", "", "tensors", ".", "append", "(", "row_tensors", ")", "\n", "\n", "", "model_inputs", "=", "concate_tensors", "(", "tensors", ")", "\n", "input_batches", "=", "divide_into_batches", "(", "model_inputs", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "all_relation_probs", "=", "[", "]", "\n", "for", "batch", "in", "input_batches", ":", "\n", "        ", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "all_entity_idxs", "=", "batch", "\n", "all_input_ids", "=", "all_input_ids", ".", "cuda", "(", ")", "\n", "all_token_type_ids", "=", "all_token_type_ids", ".", "cuda", "(", ")", "\n", "all_attention_masks", "=", "all_attention_masks", ".", "cuda", "(", ")", "\n", "all_entity_idxs", "=", "all_entity_idxs", ".", "cuda", "(", ")", "\n", "\n", "model_inputs", "=", "[", "all_input_ids", ",", "all_token_type_ids", ",", "all_attention_masks", ",", "None", ",", "all_entity_idxs", ",", "None", "]", "\n", "with", "torch", ".", "cuda", ".", "amp", ".", "autocast", "(", ")", ":", "\n", "            ", "softmaxes", "=", "model", ".", "predict_probabilities", "(", "model_inputs", ")", "\n", "", "all_relation_probs", ".", "extend", "(", "softmaxes", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "del", "all_input_ids", "\n", "del", "all_token_type_ids", "\n", "del", "all_attention_masks", "\n", "del", "all_entity_idxs", "\n", "del", "model_inputs", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "assert", "len", "(", "all_relation_probs", ")", "==", "len", "(", "batch_doc_ids", ")", ",", "breakpoint", "(", ")", "\n", "\n", "jlines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "all_relation_probs", ")", ")", ":", "\n", "        ", "relation_probabilities", "=", "dict", "(", "zip", "(", "relation_labels", ",", "all_relation_probs", "[", "i", "]", ")", ")", "\n", "line", "=", "{", "\"drug_combination\"", ":", "batch_candidate_relations", "[", "i", "]", ",", "\n", "\"relation_probabilities\"", ":", "relation_probabilities", ",", "\n", "\"paragraph\"", ":", "batch_texts", "[", "i", "]", ",", "\n", "\"sentence\"", ":", "batch_sentences", "[", "i", "]", ",", "\n", "\"doc_id\"", ":", "batch_doc_ids", "[", "i", "]", ",", "\n", "\"drug_idxs\"", ":", "batch_drug_idxs", "[", "i", "]", "}", "\n", "jlines", ".", "append", "(", "line", ")", "\n", "", "return", "jlines", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.high_confidence_precision.generate_high_confidence_predictions": [[31, 42], ["range", "len", "numpy.argmax", "predictions.append", "predictions.append", "predictions.append"], "function", ["None"], ["def", "generate_high_confidence_predictions", "(", "pred_proba", ",", "label2idx", ",", "pos_threshold", ",", "comb_threshold", ")", ":", "\n", "    ", "predictions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "pred_proba", ")", ")", ":", "\n", "        ", "pred_idx", "=", "np", ".", "argmax", "(", "pred_proba", "[", "i", "]", ")", "\n", "if", "pred_idx", "==", "label2idx", "[", "\"POS\"", "]", "and", "pred_proba", "[", "i", "]", "[", "pred_idx", "]", ">", "pos_threshold", ":", "\n", "            ", "predictions", ".", "append", "(", "label2idx", "[", "\"POS\"", "]", ")", "\n", "", "elif", "pred_idx", "==", "label2idx", "[", "\"COMB\"", "]", "and", "pred_proba", "[", "i", "]", "[", "pred_idx", "]", ">", "comb_threshold", ":", "\n", "            ", "predictions", ".", "append", "(", "label2idx", "[", "\"COMB\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "predictions", ".", "append", "(", "label2idx", "[", "\"NO_COMB\"", "]", ")", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.scripts.high_confidence_precision.compute_high_confidence_precision": [[43, 65], ["range", "len", "json.loads", "true_labels.get", "float", "tuple", "tuple", "sorted", "sorted"], "function", ["None"], ["", "def", "compute_high_confidence_precision", "(", "test_data", ",", "fixed_high_confidence", ",", "label2idx", ")", ":", "\n", "    ", "true_positives", "=", "0", "\n", "false_positives", "=", "0", "\n", "\n", "true_labels", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "test_data", ")", ")", ":", "\n", "        ", "test_row", "=", "test_data", "[", "i", "]", "\n", "row_meta", "=", "json", ".", "loads", "(", "test_row", "[", "\"row_id\"", "]", ")", "\n", "true_label", "=", "row_meta", "[", "\"relation_label\"", "]", "\n", "true_labels", "[", "(", "row_meta", "[", "\"doc_id\"", "]", ",", "tuple", "(", "sorted", "(", "row_meta", "[", "\"drug_idxs\"", "]", ")", ")", ")", "]", "=", "true_label", "\n", "\n", "", "for", "high_confidence_pred", "in", "fixed_high_confidence", ":", "\n", "        ", "true_label", "=", "true_labels", ".", "get", "(", "(", "high_confidence_pred", "[", "\"doc_id\"", "]", ",", "tuple", "(", "sorted", "(", "high_confidence_pred", "[", "\"drug_idxs\"", "]", ")", ")", ")", ",", "label2idx", "[", "\"NO_COMB\"", "]", ")", "\n", "if", "high_confidence_pred", "[", "\"relation_label\"", "]", "in", "[", "label2idx", "[", "\"POS\"", "]", ",", "label2idx", "[", "\"COMB\"", "]", "]", ":", "\n", "            ", "if", "true_label", "==", "high_confidence_pred", "[", "\"relation_label\"", "]", ":", "\n", "                ", "true_positives", "+=", "1", "\n", "", "else", ":", "\n", "                ", "false_positives", "+=", "1", "\n", "\n", "", "", "", "num_high_confidence_predictions", "=", "true_positives", "+", "false_positives", "\n", "precision", "=", "float", "(", "true_positives", ")", "/", "num_high_confidence_predictions", "\n", "return", "precision", ",", "num_high_confidence_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_label_pos_comb": [[19, 27], ["type"], "function", ["None"], ["", "def", "get_label_pos_comb", "(", "rel", ")", ":", "\n", "    ", "str_label2idx", "=", "{", "\"POS\"", ":", "1", ",", "\"NEG\"", ":", "0", ",", "\"COMB\"", ":", "0", ",", "\"NO_COMB\"", ":", "0", "}", "\n", "int_label2idx", "=", "{", "2", ":", "1", ",", "1", ":", "0", ",", "0", ":", "0", "}", "\n", "if", "type", "(", "rel", "[", "'relation_label'", "]", ")", "==", "str", ":", "\n", "        ", "idx_label", "=", "str_label2idx", "[", "rel", "[", "'relation_label'", "]", "]", "\n", "", "else", ":", "\n", "        ", "idx_label", "=", "int_label2idx", "[", "rel", "[", "'relation_label'", "]", "]", "\n", "", "return", "idx_label", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_label_any_comb": [[29, 37], ["type"], "function", ["None"], ["", "def", "get_label_any_comb", "(", "rel", ")", ":", "\n", "    ", "str_label2idx", "=", "{", "\"POS\"", ":", "1", ",", "\"NEG\"", ":", "1", ",", "\"COMB\"", ":", "1", ",", "\"NO_COMB\"", ":", "0", "}", "\n", "int_label2idx", "=", "{", "2", ":", "1", ",", "1", ":", "1", ",", "0", ":", "0", "}", "\n", "if", "type", "(", "rel", "[", "'relation_label'", "]", ")", "==", "str", ":", "\n", "        ", "idx_label", "=", "str_label2idx", "[", "rel", "[", "'relation_label'", "]", "]", "\n", "", "else", ":", "\n", "        ", "idx_label", "=", "int_label2idx", "[", "rel", "[", "'relation_label'", "]", "]", "\n", "", "return", "idx_label", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.create_vectors": [[39, 97], ["collections.defaultdict", "collections.defaultdict", "set", "enumerate", "enumerate", "len", "g_out[].append", "t_out[].append", "set().intersection", "len", "g_out[].append", "t_out[].append", "set.add", "set", "set", "set", "get_label", "get_label", "str", "get_label", "str", "get_label", "str", "get_label", "str", "get_label"], "function", ["None"], ["", "def", "create_vectors", "(", "gold", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "test", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "exact_match", ":", "bool", ",", "any_comb", ":", "bool", ")", "->", "Tuple", "[", "Dict", "[", "Tuple", "[", "str", ",", "str", ",", "int", "]", ",", "List", "[", "Tuple", "[", "int", ",", "float", "]", "]", "]", ",", "\n", "Dict", "[", "Tuple", "[", "str", ",", "str", ",", "int", "]", ",", "List", "[", "Tuple", "[", "int", ",", "float", "]", "]", "]", "]", ":", "\n", "    ", "\"\"\"This function constructs the gold and predicted vectors such that each gold/prediction,\n        would be mapped to a list of its aligned counterparts. this alignment is needed for later metrics.\n\n    Args:\n        gold: a list of gold dictionaries each of which stands for a relation.\n            each has a doc_id to identify which doc did it came from, drug_idxs to pinpoint the drugs participating in this relation,\n            and a relation_label to state the gold labels.\n        test: the same as gold but having the predicted labels instead.\n        exact_match: if True, restricts the matching criteria to have the same spans in both relations.\n            default is False, which gives the partial matching behavior in which we require at least two spans in common\n\n    Example:\n        gold: [{'doc_id': 1, 'drug_idxs': [1, 2], 'relation_label': 3}, {'doc_id': 2, 'drug_idxs': [0, 1], 'relation_label': 1}]\n        test: [{'doc_id': 1, 'drug_idxs': [0, 1, 2], 'relation_label': 3}, {'doc_id': 2, 'drug_idxs': [0, 1], 'relation_label': 0}]\n        unify negs: False\n        exact match: False\n        =>\n        g_out: {(1, '[1, 2]', 3): [(3, 0.666)], (2, '[0, 1]', 1): [(0, 0)]}\n        t_out: {(1, '[0, 1, 2]', 3): [(3, 0.666)]}\n\n    Returns:\n        gold and test dictionaries that map from each relation to its (partial/exact) matched labels and their scores\n    \"\"\"", "\n", "g_out", "=", "defaultdict", "(", "list", ")", "\n", "t_out", "=", "defaultdict", "(", "list", ")", "\n", "if", "any_comb", ":", "\n", "        ", "get_label", "=", "get_label_any_comb", "\n", "", "else", ":", "\n", "        ", "get_label", "=", "get_label_pos_comb", "\n", "\n", "", "matched", "=", "set", "(", ")", "\n", "for", "rel1", "in", "gold", ":", "\n", "        ", "found", "=", "False", "\n", "for", "k", ",", "rel2", "in", "enumerate", "(", "test", ")", ":", "\n", "            ", "if", "rel1", "[", "'doc_id'", "]", "!=", "rel2", "[", "'doc_id'", "]", ":", "\n", "                ", "continue", "\n", "# count matching entity-spans", "\n", "", "spans_intersecting", "=", "len", "(", "set", "(", "rel1", "[", "'drug_idxs'", "]", ")", ".", "intersection", "(", "set", "(", "rel2", "[", "'drug_idxs'", "]", ")", ")", ")", "\n", "score", "=", "spans_intersecting", "/", "len", "(", "set", "(", "rel1", "[", "'drug_idxs'", "]", "+", "rel2", "[", "'drug_idxs'", "]", ")", ")", "\n", "# if we have partial matching (when allowed) or exact matching (when required) add the aligned relations", "\n", "if", "(", "(", "spans_intersecting", ">=", "2", ")", "and", "(", "not", "exact_match", ")", ")", "or", "(", "score", "==", "1", ")", ":", "\n", "# we use as mapping the \"row id\" (sentence hash, drug indices, and the label). and we map a list", "\n", "#   of aligned relations (+ scores) of the other vector", "\n", "                ", "g_out", "[", "(", "rel1", "[", "\"doc_id\"", "]", ",", "str", "(", "rel1", "[", "\"drug_idxs\"", "]", ")", ",", "get_label", "(", "rel1", ")", ")", "]", ".", "append", "(", "(", "get_label", "(", "rel2", ")", ",", "score", ")", ")", "\n", "t_out", "[", "(", "rel2", "[", "\"doc_id\"", "]", ",", "str", "(", "rel2", "[", "\"drug_idxs\"", "]", ")", ",", "get_label", "(", "rel2", ")", ")", "]", ".", "append", "(", "(", "get_label", "(", "rel1", ")", ",", "score", ")", ")", "\n", "found", "=", "True", "\n", "matched", ".", "add", "(", "k", ")", "\n", "# if a gold positive not found by test, add a false negative pair", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "g_out", "[", "(", "rel1", "[", "\"doc_id\"", "]", ",", "str", "(", "rel1", "[", "\"drug_idxs\"", "]", ")", ",", "get_label", "(", "rel1", ")", ")", "]", ".", "append", "(", "(", "Label", ".", "NO_COMB", ".", "value", ",", "0", ")", ")", "\n", "# now we iterate on the remaining relations in the test, and add the false positives", "\n", "", "", "for", "k", ",", "rel2", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "if", "k", "not", "in", "matched", ":", "\n", "            ", "t_out", "[", "(", "rel2", "[", "\"doc_id\"", "]", ",", "str", "(", "rel2", "[", "\"drug_idxs\"", "]", ")", ",", "get_label", "(", "rel2", ")", ")", "]", ".", "append", "(", "(", "Label", ".", "NO_COMB", ".", "value", ",", "0", ")", ")", "\n", "", "", "return", "g_out", ",", "t_out", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_max_sum_score": [[99, 107], ["max"], "function", ["None"], ["", "def", "get_max_sum_score", "(", "v", ",", "labeled", ")", ":", "\n", "    ", "interesting", "=", "0", "\n", "score", "=", "0", "\n", "for", "(", "_", ",", "_", ",", "label", ")", ",", "matched", "in", "v", ":", "\n", "        ", "if", "label", "!=", "Label", ".", "NO_COMB", ".", "value", ":", "\n", "            ", "interesting", "+=", "1", "\n", "score", "+=", "max", "(", "[", "s", "if", "(", "(", "not", "labeled", "and", "other", "!=", "Label", ".", "NO_COMB", ".", "value", ")", "or", "(", "other", "==", "label", ")", ")", "else", "0", "for", "other", ",", "s", "in", "matched", "]", ")", "\n", "", "", "return", "score", "/", "interesting", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.f_from_p_r": [[109, 113], ["eval.get_max_sum_score", "eval.get_max_sum_score", "ts.items", "gs.items"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_max_sum_score", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.get_max_sum_score"], ["", "def", "f_from_p_r", "(", "gs", ",", "ts", ",", "labeled", "=", "False", ")", ":", "\n", "    ", "p", "=", "get_max_sum_score", "(", "ts", ".", "items", "(", ")", ",", "labeled", ")", "\n", "r", "=", "get_max_sum_score", "(", "gs", ".", "items", "(", ")", ",", "labeled", ")", "\n", "return", "(", "2", "*", "p", "*", "r", ")", "/", "(", "p", "+", "r", ")", ",", "p", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.f_score": [[115, 119], ["eval.create_vectors", "eval.f_from_p_r"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.create_vectors", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.leaderboard.eval.f_from_p_r"], ["", "def", "f_score", "(", "gold", ",", "test", ",", "exact_match", "=", "False", ",", "any_comb", "=", "False", ")", ":", "\n", "    ", "gs", ",", "ts", "=", "create_vectors", "(", "gold", ",", "test", ",", "exact_match", ",", "any_comb", "=", "any_comb", ")", "\n", "f", ",", "p", ",", "r", "=", "f_from_p_r", "(", "gs", ",", "ts", ")", "\n", "return", "f", ",", "p", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.load_model": [[15, 39], ["streamlit.cache", "common.utils.load_metadata", "modeling.model.BertForRelation.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoTokenizer.from_pretrained.from_pretrained", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.load_metadata"], ["@", "st", ".", "cache", "(", "allow_output_mutation", "=", "True", ")", "\n", "def", "load_model", "(", "checkpoint_directory", ":", "str", ")", "->", "Tuple", "[", "BertForRelation", ",", "AutoTokenizer", ",", "int", ",", "Dict", ",", "bool", "]", ":", "\n", "    ", "'''Given a directory containing a model checkpoint, return the model, and other metadata regarding the data\n    preprocessing that the model expects.\n\n    Args:\n        checkpoint_directory: Path to local directory where model is serialized\n\n    Returns:\n        model: Pretrained BertForRelation model\n        tokenizer: Hugging Face tokenizer loaded from disk\n        max_seq_length: Maximum number of subwords in a document allowed by the model (if longer, truncate input)\n        label2idx: Mapping from label strings to numerical label indices\n        include_paragraph_context: Whether or not to include paragraph context in addition to the relation-bearing sentence\n    '''", "\n", "metadata", "=", "load_metadata", "(", "checkpoint_directory", ")", "\n", "model", "=", "BertForRelation", ".", "from_pretrained", "(", "\n", "checkpoint_directory", ",", "\n", "cache_dir", "=", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", ",", "\n", "num_rel_labels", "=", "metadata", ".", "num_labels", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "metadata", ".", "model_name", ",", "do_lower_case", "=", "True", ")", "\n", "tokenizer", ".", "from_pretrained", "(", "os", ".", "path", ".", "join", "(", "checkpoint_directory", ",", "\"tokenizer\"", ")", ")", "\n", "return", "model", ",", "tokenizer", ",", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.find_all_relations": [[40, 95], ["preprocessing.preprocess.process_doc_with_unknown_relations", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model", "torch.nn.functional.softmax", "probability[].tolist", "enumerate", "sorted", "preprocessing.preprocess.add_entity_markers", "marked_sentences.append", "relations.append", "preprocessing.data_loader.tokenize_sentence", "preprocessing.data_loader.vectorize_subwords", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "tuple", "preprocessing.data_loader.make_fixed_length", "sorted.append", "len"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.process_doc_with_unknown_relations", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.preprocess.add_entity_markers", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.tokenize_sentence", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.vectorize_subwords", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.preprocessing.data_loader.make_fixed_length"], ["", "def", "find_all_relations", "(", "message", ":", "Dict", ",", "\n", "model", ":", "BertForRelation", ",", "\n", "tokenizer", ":", "AutoTokenizer", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "threshold", ":", "float", ",", "\n", "label2idx", ":", "Dict", ",", "\n", "label_of_interest", ":", "int", "=", "1", ",", "\n", "include_paragraph_context", ":", "bool", "=", "True", ")", ":", "\n", "    ", "'''Given a row from the Drug Synergy dataset, find and display all relations with probability greater than some threshold.\n\n    Args:\n        message: JSON row from the Drug Synergy dataset\n        model: Pretrained BertForRelation model object\n        tokenizer: Hugging Face tokenizer loaded from disk\n        max_seq_length: Maximum number of subwords in a document allowed by the model (if longer, truncate input)\n        label2idx: Mapping from label strings to numerical label indices\n        label_of_interest: Return relations that maximize the probability of this label (typically, this should be 1 for the POS label)\n        include_paragraph_context: Whether or not to include paragraph context in addition to the relation-bearing sentence\n    '''", "\n", "doc_with_unknown_relations", "=", "process_doc_with_unknown_relations", "(", "message", ",", "label2idx", ",", "include_paragraph_context", "=", "include_paragraph_context", ")", "\n", "marked_sentences", "=", "[", "]", "\n", "relations", "=", "[", "]", "\n", "for", "relation", "in", "doc_with_unknown_relations", ".", "relations", ":", "\n", "# Mark drug entities with special tokens.", "\n", "        ", "marked_sentence", "=", "add_entity_markers", "(", "doc_with_unknown_relations", ".", "text", ",", "relation", ".", "drug_entities", ")", "\n", "marked_sentences", ".", "append", "(", "marked_sentence", ")", "\n", "relations", ".", "append", "(", "tuple", "(", "[", "f\"{drug.drug_name} ({drug.span_start} - {drug.span_end})\"", "for", "drug", "in", "relation", ".", "drug_entities", "]", ")", ")", "\n", "\n", "", "all_entity_idxs", "=", "[", "]", "\n", "all_input_ids", "=", "[", "]", "\n", "all_token_type_ids", "=", "[", "]", "\n", "all_attention_masks", "=", "[", "]", "\n", "for", "sentence", "in", "marked_sentences", ":", "\n", "        ", "subwords", ",", "entity_start_tokens", "=", "tokenize_sentence", "(", "sentence", ",", "tokenizer", ")", "\n", "vectorized_row", "=", "vectorize_subwords", "(", "tokenizer", ",", "subwords", ",", "max_seq_length", ")", "\n", "all_input_ids", ".", "append", "(", "vectorized_row", ".", "input_ids", ")", "\n", "all_token_type_ids", ".", "append", "(", "vectorized_row", ".", "attention_mask", ")", "\n", "all_attention_masks", ".", "append", "(", "vectorized_row", ".", "segment_ids", ")", "\n", "all_entity_idxs", ".", "append", "(", "make_fixed_length", "(", "entity_start_tokens", ",", "len", "(", "message", "[", "\"spans\"", "]", ")", ",", "padding_value", "=", "ENTITY_PAD_IDX", ")", ")", "\n", "\n", "", "all_entity_idxs", "=", "torch", ".", "tensor", "(", "all_entity_idxs", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "all_input_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "all_token_type_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_masks", "=", "torch", ".", "tensor", "(", "all_attention_masks", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "logits", "=", "model", "(", "all_input_ids", ",", "token_type_ids", "=", "all_token_type_ids", ",", "attention_mask", "=", "all_attention_masks", ",", "all_entity_idxs", "=", "all_entity_idxs", ")", "\n", "probability", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ")", "\n", "label_probabilities", "=", "probability", "[", ":", ",", "label_of_interest", "]", ".", "tolist", "(", ")", "\n", "\n", "relation_probabilities", "=", "[", "]", "\n", "for", "i", ",", "probability", "in", "enumerate", "(", "label_probabilities", ")", ":", "\n", "        ", "if", "probability", ">", "threshold", ":", "\n", "            ", "relation_probabilities", ".", "append", "(", "{", "\"drugs\"", ":", "relations", "[", "i", "]", ",", "\"positive probability\"", ":", "probability", "}", ")", "\n", "", "", "relation_probabilities", "=", "sorted", "(", "relation_probabilities", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"positive probability\"", "]", ",", "reverse", "=", "True", ")", "\n", "return", "{", "'relations'", ":", "relation_probabilities", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.get_ground_truth_relations": [[96, 115], ["formatted_relations.append", "relation_drugs.append"], "function", ["None"], ["", "def", "get_ground_truth_relations", "(", "message", ")", ":", "\n", "    ", "'''Parse the document's annotation to return the ground truth relations in a human-readable format\n\n    Args:\n        message: JSON row from the Drug Synergy dataset\n    '''", "\n", "relations", "=", "message", "[", "\"rels\"", "]", "\n", "formatted_relations", "=", "[", "]", "\n", "for", "relation", "in", "relations", ":", "\n", "        ", "relation_drugs", "=", "[", "]", "\n", "for", "span_idx", "in", "relation", "[", "\"spans\"", "]", ":", "\n", "            ", "span", "=", "message", "[", "\"spans\"", "]", "[", "span_idx", "]", "\n", "drug_name", "=", "span", "[", "\"text\"", "]", "\n", "span_start", "=", "span", "[", "\"start\"", "]", "\n", "span_end", "=", "span", "[", "\"end\"", "]", "\n", "drug_identifier", "=", "f\"{drug_name} ({span_start} - {span_end})\"", "\n", "relation_drugs", ".", "append", "(", "drug_identifier", ")", "\n", "", "formatted_relations", ".", "append", "(", "{", "\"drugs\"", ":", "relation_drugs", ",", "\"label\"", ":", "relation", "[", "\"class\"", "]", "}", ")", "\n", "", "return", "formatted_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.app": [[116, 137], ["streamlit.write", "streamlit.text_area", "json.loads", "streamlit_all_relations_app.get_ground_truth_relations", "streamlit.slider", "streamlit.write", "streamlit.write", "streamlit_all_relations_app.load_model", "streamlit_all_relations_app.find_all_relations", "streamlit.write", "streamlit.write"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.get_ground_truth_relations", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.load_model", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.web_ui.streamlit_all_relations_app.find_all_relations"], ["", "def", "app", "(", ")", ":", "\n", "    ", "example_dataset_row", "=", "'{\"sentence\": \"Phase Ib Study of the Oral Proteasome Inhibitor Ixazomib ( MLN9708 ) and Fulvestrant in Advanced ER+ Breast Cancer Progressing on Fulvestrant .\", \"spans\": [{\"span_id\": 0, \"text\": \"Ixazomib\", \"start\": 48, \"end\": 56, \"token_start\": 8, \"token_end\": 9}, {\"span_id\": 1, \"text\": \"Fulvestrant\", \"start\": 73, \"end\": 84, \"token_start\": 13, \"token_end\": 14}, {\"span_id\": 2, \"text\": \"Fulvestrant\", \"start\": 130, \"end\": 141, \"token_start\": 21, \"token_end\": 22}], \"rels\": [{\"class\": \"POS\", \"spans\": [0, 1]}], \"paragraph\": \"Phase Ib Study of the Oral Proteasome Inhibitor Ixazomib ( MLN9708 ) and Fulvestrant in Advanced ER+ Breast Cancer Progressing on Fulvestrant . fulvestrant is a selective estrogen receptor (ER)-downregulating anti-estrogen that blocks ER transcriptional activity and is approved for ER+ breast cancer. fulvestrant also induces accumulation of insoluble ER and activates an unfolded protein response; proteasome inhibitors have been shown to enhance these effects in preclinical models. ### background fulvestrant is a selective estrogen receptor (ER)-downregulating anti-estrogen that blocks ER transcriptional activity and is approved for ER+ breast cancer. fulvestrant also induces accumulation of insoluble ER and activates an unfolded protein response; proteasome inhibitors have been shown to enhance these effects in preclinical models. ### methods This is a single-center phase Ib study with a 3+3 design of fulvestrant and the proteasome inhibitor ixazomib (MLN9708) in patients with advanced ER+ breast cancer that was progressing on fulvestrant. A dose-escalation design allowed establishment of the ixazomib maximum tolerated dose (MTD). Secondary objectives included progression-free survival, pharmacokinetics, and tumor molecular analyses. ### results Among nine evaluable subjects, treatment was well-tolerated without dose-limiting toxicities The MTD of ixazomib was 4 mg in combination with fulvestrant. Plasma concentrations of the active form of ixazomib (MLN2238) in the 4-mg dose cohort had a median (range) Cmax of 155 (122-171) ng/mL; Tmax of 1 (1-1.5) h; terminal elimination half-life of 66.6 (57.3-102.6) hr after initial dose; AUC of 5,025 (4,160-5,345) ng*h/mL. One partial response was observed, and median progression-free survival was 51\\u2009days (range 47-137). ### conclusion This drug combination has a favorable safety profile and anti-tumor activity in patients with fulvestrant-resistant advanced ER+ breast cancer that justifies future testing.\", \"source\": \"https://pubmed.ncbi.nlm.nih.gov/33641211/\"}'", "\n", "st", ".", "write", "(", "\"Copy and paste a row from the Drug Synergy Dataset:\"", ")", "\n", "message_json", "=", "st", ".", "text_area", "(", "\"Copy-and-paste a dataset row (in JSON format)\"", ",", "\n", "example_dataset_row", ",", "\n", "height", "=", "500", ")", "\n", "message", "=", "json", ".", "loads", "(", "message_json", ")", "\n", "ground_truth_relations", "=", "get_ground_truth_relations", "(", "message", ")", "\n", "\n", "DEFAULT_THRESHOLD", "=", "0.3", "\n", "threshold", "=", "st", ".", "slider", "(", "'Relation Threshold'", ",", "min_value", "=", "0.0", ",", "max_value", "=", "1.0", ",", "value", "=", "DEFAULT_THRESHOLD", ",", "step", "=", "0.01", ")", "\n", "if", "threshold", ">", "0.0", ":", "\n", "        ", "CHECKPOINT_DIRECTORY", "=", "\"checkpoints\"", "\n", "model", ",", "tokenizer", ",", "metadata", "=", "load_model", "(", "CHECKPOINT_DIRECTORY", ")", "\n", "\n", "model_output", "=", "find_all_relations", "(", "message", ",", "model", ",", "tokenizer", ",", "metadata", ".", "max_seq_length", ",", "threshold", ",", "metadata", ".", "label2idx", ",", "label_of_interest", "=", "1", ",", "include_paragraph_context", "=", "metadata", ".", "include_paragraph_context", ")", "\n", "st", ".", "write", "(", "\"Predicted Relations:\"", ")", "\n", "st", ".", "write", "(", "model_output", ")", "\n", "\n", "", "st", ".", "write", "(", "\"Ground Truth Relations:\"", ")", "\n", "st", ".", "write", "(", "ground_truth_relations", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.data.add_document_ids_to_dataset.hash_string": [[19, 21], ["hashlib.md5().hexdigest", "hashlib.md5", "string.encode"], "function", ["None"], ["def", "hash_string", "(", "string", ")", ":", "\n", "    ", "return", "hashlib", ".", "md5", "(", "(", "string", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.data.add_document_ids_to_dataset.add_document_id_to_doc": [[22, 29], ["add_document_ids_to_dataset.hash_string"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.data.add_document_ids_to_dataset.hash_string"], ["", "def", "add_document_id_to_doc", "(", "doc", ":", "Dict", ",", "document_id_field", ":", "str", "=", "\"doc_id\"", ")", "->", "Tuple", "[", "Dict", ",", "bool", "]", ":", "\n", "    ", "if", "document_id_field", "in", "doc", ":", "\n", "        ", "return", "doc", ",", "False", "\n", "", "else", ":", "\n", "        ", "doc_id", "=", "hash_string", "(", "doc", "[", "\"sentence\"", "]", ")", "\n", "doc", "[", "document_id_field", "]", "=", "doc_id", "\n", "return", "doc", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.types.DrugEntity.__init__": [[4, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "drug_name", ",", "drug_idx", ",", "span_start", ",", "span_end", ")", ":", "\n", "        ", "self", ".", "drug_name", ":", "str", "=", "drug_name", "\n", "self", ".", "drug_idx", ":", "int", "=", "drug_idx", "\n", "self", ".", "span_start", ":", "int", "=", "span_start", "\n", "self", ".", "span_end", ":", "int", "=", "span_end", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.types.DrugRelation.__init__": [[11, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "drug_entities", ",", "relation_label", ")", ":", "\n", "        ", "self", ".", "drug_entities", ":", "List", "[", "DrugEntity", "]", "=", "drug_entities", "\n", "self", ".", "relation_label", ":", "int", "=", "relation_label", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.types.Document.__init__": [[16, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "doc_id", ",", "relations", ",", "text", ")", ":", "\n", "        ", "self", ".", "doc_id", ":", "str", "=", "doc_id", "\n", "self", ".", "relations", ":", "List", "[", "DrugRelation", "]", "=", "relations", "\n", "self", ".", "text", ":", "str", "=", "text", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.test_utils.test_is_sublist": [[10, 25], ["utils.is_sublist", "utils.is_sublist"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.is_sublist", "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.is_sublist"], ["def", "test_is_sublist", "(", ")", ":", "\n", "    ", "superlist", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", "]", "\n", "sublist_1", "=", "[", "\"a\"", ",", "\"b\"", "]", "\n", "sublist_2", "=", "[", "\"b\"", ",", "\"c\"", ",", "\"d\"", "]", "\n", "sublist_3", "=", "[", "\"d\"", "]", "\n", "sublist_4", "=", "[", "]", "\n", "not_sublist_1", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"c\"", ",", "\"d\"", ",", "\"e\"", "]", "\n", "not_sublist_2", "=", "[", "\"a\"", ",", "\"b\"", ",", "\"e\"", "]", "\n", "not_sublist_3", "=", "[", "\"f\"", "]", "\n", "\n", "for", "sublist", "in", "[", "sublist_1", ",", "sublist_2", ",", "sublist_3", ",", "sublist_4", "]", ":", "\n", "        ", "assert", "is_sublist", "(", "sublist", ",", "superlist", ")", "\n", "\n", "", "for", "not_sublist", "in", "[", "not_sublist_1", ",", "not_sublist_2", ",", "not_sublist_3", "]", ":", "\n", "        ", "assert", "not", "is_sublist", "(", "not_sublist", ",", "superlist", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ModelMetadata.__init__": [[122, 139], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model_name", ":", "str", ",", "\n", "max_seq_length", ":", "int", ",", "\n", "num_labels", ":", "int", ",", "\n", "label2idx", ":", "Dict", ",", "\n", "add_no_combination_relations", ":", "bool", ",", "\n", "only_include_binary_no_comb_relations", ":", "bool", ",", "\n", "include_paragraph_context", ":", "bool", ",", "\n", "context_window_size", ":", "int", ")", ":", "\n", "        ", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "label2idx", "=", "label2idx", "\n", "self", ".", "add_no_combination_relations", "=", "add_no_combination_relations", "\n", "self", ".", "only_include_binary_no_comb_relations", "=", "only_include_binary_no_comb_relations", "\n", "self", ".", "include_paragraph_context", "=", "include_paragraph_context", "\n", "self", ".", "context_window_size", "=", "context_window_size", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.__init__": [[225, 240], ["len", "len", "len", "utils.average_pairwise_distance", "full_document[].split", "full_document[].split"], "methods", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.average_pairwise_distance"], ["    ", "def", "__init__", "(", "self", ",", "dataset_row", ":", "Dict", ",", "full_document", ":", "Dict", ",", "prediction", ":", "int", ")", ":", "\n", "        ", "self", ".", "row_id", "=", "dataset_row", "[", "\"row_id\"", "]", "\n", "self", ".", "sentence", "=", "full_document", "[", "\"sentence\"", "]", "\n", "self", ".", "paragraph", "=", "full_document", "[", "\"paragraph\"", "]", "\n", "self", ".", "sentence_length", "=", "len", "(", "full_document", "[", "\"sentence\"", "]", ".", "split", "(", ")", ")", "\n", "self", ".", "paragraph_length", "=", "len", "(", "full_document", "[", "\"paragraph\"", "]", ".", "split", "(", ")", ")", "\n", "spans", "=", "full_document", "[", "\"spans\"", "]", "\n", "\n", "self", ".", "entities", "=", "[", "span", "[", "\"text\"", "]", "for", "span", "in", "spans", "]", "\n", "spans_in_relation", "=", "[", "spans", "[", "idx", "]", "for", "idx", "in", "dataset_row", "[", "\"drug_indices\"", "]", "]", "\n", "\n", "self", ".", "num_spans_in_ground_truth_relation", "=", "len", "(", "spans_in_relation", ")", "\n", "self", ".", "avg_span_distance_in_ground_truth_relation", "=", "average_pairwise_distance", "(", "spans_in_relation", ")", "\n", "self", ".", "ground_truth_label", "=", "dataset_row", "[", "\"target\"", "]", "\n", "self", ".", "predicted_label", "=", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.get_row": [[241, 243], ["None"], "methods", ["None"], ["", "def", "get_row", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "row_id", ",", "self", ".", "sentence", ",", "self", ".", "entities", ",", "self", ".", "paragraph", ",", "self", ".", "ground_truth_label", ",", "self", ".", "predicted_label", ",", "self", ".", "sentence_length", ",", "self", ".", "paragraph_length", ",", "self", ".", "num_spans_in_ground_truth_relation", ",", "self", ".", "avg_span_distance_in_ground_truth_relation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.accuracy": [[14, 26], ["float", "len", "torch.sum().item", "torch.sum"], "function", ["None"], ["def", "accuracy", "(", "predictions", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute accuracy of predictions against ground truth.\n\n    Args:\n        Predictions: tensor of binary predictions\n        Labels: tensor of binary ground truth labels\n\n    Returns:\n        acc: Accuracy of predictions\n    \"\"\"", "\n", "acc", "=", "float", "(", "torch", ".", "sum", "(", "predictions", "==", "labels", ")", ".", "item", "(", ")", ")", "/", "len", "(", "predictions", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.true_positives": [[27, 40], ["float", "torch.sum().item", "torch.sum", "torch.logical_and"], "function", ["None"], ["", "def", "true_positives", "(", "predictions", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", "->", "float", ":", "\n", "    ", "\"\"\"Helper function to compute number of true positives (which is the\n    numerator for both precision and recall).\n\n    Args:\n        Predictions: tensor of binary predictions\n        Labels: tensor of binary ground truth labels\n\n    Returns:\n        tps: Number of true positives\n    \"\"\"", "\n", "tps", "=", "float", "(", "torch", ".", "sum", "(", "torch", ".", "logical_and", "(", "predictions", "==", "1.0", ",", "labels", "==", "1.0", ")", ")", ".", "item", "(", ")", ")", "\n", "return", "tps", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.precision": [[41, 56], ["float", "utils.true_positives", "torch.sum"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.true_positives"], ["", "def", "precision", "(", "predictions", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute precision of predictions against ground truth.\n\n    Args:\n        Predictions: tensor of binary predictions\n        Labels: tensor of binary ground truth labels\n\n    Returns:\n        acc: Precision of predictions\n    \"\"\"", "\n", "predicted_pos", "=", "float", "(", "torch", ".", "sum", "(", "predictions", ")", ")", "\n", "true_pos", "=", "true_positives", "(", "predictions", ",", "labels", ")", "\n", "if", "true_pos", "==", "0.0", ":", "\n", "        ", "return", "0.0", "\n", "", "return", "true_pos", "/", "predicted_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.recall": [[57, 72], ["float", "utils.true_positives", "torch.sum"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.true_positives"], ["", "def", "recall", "(", "predictions", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute recall of predictions against ground truth.\n\n    Args:\n        Predictions: tensor of binary predictions\n        Labels: tensor of binary ground truth labels\n\n    Returns:\n        acc: Recall of predictions\n    \"\"\"", "\n", "gt_pos", "=", "float", "(", "torch", ".", "sum", "(", "labels", ")", ")", "\n", "true_pos", "=", "true_positives", "(", "predictions", ",", "labels", ")", "\n", "if", "gt_pos", "==", "0.0", ":", "\n", "        ", "return", "0.0", "\n", "", "return", "true_pos", "/", "gt_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.compute_f1": [[73, 106], ["zip"], "function", ["None"], ["", "def", "compute_f1", "(", "preds", ":", "torch", ".", "Tensor", ",", "labels", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Compute the F1 score of predictions against ground truth. Return as a dictionary including precision\n    and recall, since these must be computed to calculate F1.\n    Exact f1 calculation was copied almost verbatim from\n    https://github.com/princeton-nlp/PURE/blob/8517005d947afedcbb2b04df9d8de18fa1ca9b04/run_relation.py#L164-L189.\n\n    Args:\n        Predictions: tensor of binary predictions\n        Labels: tensor of binary ground truth labels\n\n    Returns:\n        F1: F1 score of predictions\n        prec: Precision of predictions\n        rec: Recall of predictions\n    \"\"\"", "\n", "n_gold", "=", "n_pred", "=", "n_correct", "=", "0", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "        ", "if", "pred", "!=", "0", ":", "\n", "            ", "n_pred", "+=", "1", "\n", "", "if", "label", "!=", "0", ":", "\n", "            ", "n_gold", "+=", "1", "\n", "", "if", "(", "pred", "!=", "0", ")", "and", "(", "label", "!=", "0", ")", "and", "(", "pred", "==", "label", ")", ":", "\n", "            ", "n_correct", "+=", "1", "\n", "", "", "if", "n_correct", "==", "0", ":", "\n", "        ", "return", "{", "'precision'", ":", "0.0", ",", "'recall'", ":", "0.0", ",", "'f1'", ":", "0.0", "}", "\n", "", "else", ":", "\n", "        ", "prec", "=", "n_correct", "*", "1.0", "/", "n_pred", "\n", "recall", "=", "n_correct", "*", "1.0", "/", "n_gold", "\n", "if", "prec", "+", "recall", ">", "0", ":", "\n", "            ", "f1", "=", "2.0", "*", "prec", "*", "recall", "/", "(", "prec", "+", "recall", ")", "\n", "", "else", ":", "\n", "            ", "f1", "=", "0.0", "\n", "", "return", "{", "'precision'", ":", "prec", ",", "'recall'", ":", "recall", ",", "'f1'", ":", "f1", ",", "'n_correct'", ":", "n_correct", ",", "'n_pred'", ":", "n_pred", ",", "'task_ngold'", ":", "n_gold", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.read_jsonl": [[107, 109], ["list", "jsonlines.open"], "function", ["None"], ["", "", "def", "read_jsonl", "(", "fname", ":", "str", ")", ":", "\n", "    ", "return", "list", "(", "jsonlines", ".", "open", "(", "fname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.write_jsonl": [[110, 116], ["jsonlines.Writer.close", "print", "open", "jsonlines.Writer", "jsonlines.Writer.write_all", "len"], "function", ["None"], ["", "def", "write_jsonl", "(", "data", ":", "List", "[", "Dict", "]", ",", "fname", ":", "str", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "writer", "=", "jsonlines", ".", "Writer", "(", "fp", ")", "\n", "writer", ".", "write_all", "(", "data", ")", "\n", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "f\"Wrote {len(data)} json lines to {fname}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.write_json": [[117, 120], ["json.dump", "print", "open"], "function", ["None"], ["", "def", "write_json", "(", "data", ":", "Dict", ",", "fname", ":", "str", ")", ":", "\n", "    ", "json", ".", "dump", "(", "data", ",", "open", "(", "fname", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "print", "(", "f\"Wrote json file to {fname}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.save_metadata": [[141, 160], ["os.path.join", "json.dump", "open"], "function", ["None"], ["", "", "def", "save_metadata", "(", "metadata", ":", "ModelMetadata", ",", "checkpoint_directory", ":", "str", ")", ":", "\n", "    ", "'''Serialize metadata about a model and the data preprocessing that it expects, to allow easy model usage at a later time.\n\n    Args:\n        metadata: ModelMetadata object containing information needed to use the model after loading a checkpoint.\n        checkpoint_directory: Directory name in which to save the metadata file ($checkpoint_directory/metadata.json)\n    '''", "\n", "metadata_dict", "=", "{", "\n", "\"model_name\"", ":", "metadata", ".", "model_name", ",", "\n", "\"max_seq_length\"", ":", "metadata", ".", "max_seq_length", ",", "\n", "\"num_labels\"", ":", "metadata", ".", "num_labels", ",", "\n", "\"label2idx\"", ":", "metadata", ".", "label2idx", ",", "\n", "\"add_no_combination_relations\"", ":", "metadata", ".", "add_no_combination_relations", ",", "\n", "\"only_include_binary_no_comb_relations\"", ":", "metadata", ".", "only_include_binary_no_comb_relations", ",", "\n", "\"include_paragraph_context\"", ":", "metadata", ".", "include_paragraph_context", ",", "\n", "\"context_window_size\"", ":", "metadata", ".", "context_window_size", "\n", "}", "\n", "metadata_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_directory", ",", "\"metadata.json\"", ")", "\n", "json", ".", "dump", "(", "metadata_dict", ",", "open", "(", "metadata_file", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.load_metadata": [[161, 181], ["os.path.join", "json.load", "utils.ModelMetadata", "open"], "function", ["None"], ["", "def", "load_metadata", "(", "checkpoint_directory", ":", "str", ")", "->", "ModelMetadata", ":", "\n", "    ", "'''Given a directory containing a model checkpoint, metadata regarding the model and data preprocessing that the model expects.\n\n    Args:\n        checkpoint_directory: Path to local directory where model is serialized\n\n    Returns:\n        metadata: ModelMetadata object containing information needed to use the model after loading a checkpoint.\n    '''", "\n", "metadata_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_directory", ",", "\"metadata.json\"", ")", "\n", "metadata_dict", "=", "json", ".", "load", "(", "open", "(", "metadata_file", ")", ")", "\n", "metadata", "=", "ModelMetadata", "(", "metadata_dict", "[", "\"model_name\"", "]", ",", "\n", "metadata_dict", "[", "\"max_seq_length\"", "]", ",", "\n", "metadata_dict", "[", "\"num_labels\"", "]", ",", "\n", "metadata_dict", "[", "\"label2idx\"", "]", ",", "\n", "metadata_dict", "[", "\"add_no_combination_relations\"", "]", ",", "\n", "metadata_dict", "[", "\"only_include_binary_no_comb_relations\"", "]", ",", "\n", "metadata_dict", "[", "\"include_paragraph_context\"", "]", ",", "\n", "metadata_dict", "[", "\"context_window_size\"", "]", ")", "\n", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.construct_row_id_idx_mapping": [[182, 200], ["len"], "function", ["None"], ["", "def", "construct_row_id_idx_mapping", "(", "dataset", ":", "List", "[", "Dict", "]", ")", "->", "Tuple", "[", "Dict", ",", "Dict", "]", ":", "\n", "    ", "'''For a list of dataset rows, which contain string-hash row IDs, map these\n    into integers (for the purposes of tensorization), and return the mapping.\n\n    Args:\n        dataset: list of JSON rows, representing individual relations in our dataset (each containing a row_id field)\n\n    Returns:\n        row_id_idx_mapping: mapping from row_id strings to integer indices\n        idx_row_id_mapping: reverse mapping from integer indices to row_id strings\n    '''", "\n", "row_id_idx_mapping", "=", "{", "}", "\n", "idx_row_id_mapping", "=", "{", "}", "\n", "for", "doc", "in", "dataset", ":", "\n", "        ", "idx", "=", "len", "(", "row_id_idx_mapping", ")", "\n", "row_id_idx_mapping", "[", "doc", "[", "\"row_id\"", "]", "]", "=", "idx", "\n", "idx_row_id_mapping", "[", "idx", "]", "=", "doc", "[", "\"row_id\"", "]", "\n", "", "return", "row_id_idx_mapping", ",", "idx_row_id_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.average_pairwise_distance": [[201, 223], ["range", "numpy.mean", "len", "range", "len", "len", "distances.append", "distances.append"], "function", ["None"], ["", "def", "average_pairwise_distance", "(", "spans", ":", "List", "[", "Dict", "]", ")", "->", "float", ":", "\n", "    ", "'''This function calculates the average distance between pairs of spans in a relation, which may be a useful\n    bucketing attribute for error analysis.\n\n    Args:\n        spans: List of spans (each represented as a dictionary)\n\n    Returns:\n        average pairwise distance between spans in the provided list\n    '''", "\n", "distances", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "spans", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "spans", ")", ")", ":", "\n", "            ", "span_distance", "=", "spans", "[", "j", "]", "[", "\"token_start\"", "]", ">", "spans", "[", "i", "]", "[", "\"token_end\"", "]", "\n", "if", "span_distance", ">=", "0", ":", "\n", "                ", "distances", ".", "append", "(", "span_distance", ")", "\n", "", "else", ":", "\n", "                ", "span_distance", "=", "spans", "[", "i", "]", "[", "\"token_start\"", "]", "-", "spans", "[", "j", "]", "[", "\"token_end\"", "]", "\n", "assert", "span_distance", ">=", "0", "\n", "distances", ".", "append", "(", "span_distance", ")", "\n", "", "", "", "assert", "len", "(", "distances", ")", ">=", "1", "\n", "return", "np", ".", "mean", "(", "distances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.write_error_analysis_file": [[245, 280], ["dict", "print", "zip", "open", "csv.writer", "csv.writer.writerow", "utils.ErrorAnalysisAttributes", "csv.writer.writerow", "json.loads", "utils.ErrorAnalysisAttributes.get_row"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.ErrorAnalysisAttributes.get_row"], ["", "", "def", "write_error_analysis_file", "(", "dataset", ":", "List", "[", "Dict", "]", ",", "test_data_raw", ":", "List", "[", "Dict", "]", ",", "test_row_ids", ":", "List", "[", "str", "]", ",", "test_predictions", ":", "List", "[", "int", "]", ",", "fname", ":", "str", ")", ":", "\n", "    ", "'''Write out all test set rows and their predictions to a TSV file, which will let us connect easily with ExplainaBoard.\n\n    Args:\n        dataset: List of row dictionaries representing the test dataset\n        test_row_ids: List of row identifiers in the test set\n        test_predictions: List of integer predictions corresponding to the test rows\n        fname: String file to write the TSV output\n    '''", "\n", "test_data_raw", "=", "{", "doc", "[", "\"doc_id\"", "]", ":", "doc", "for", "doc", "in", "test_data_raw", "}", "\n", "row_predictions", "=", "dict", "(", "zip", "(", "test_row_ids", ",", "test_predictions", ")", ")", "\n", "\n", "header", "=", "[", "\n", "\"Row ID\"", ",", "\n", "\"Sentence\"", ",", "\n", "\"Entities\"", ",", "\n", "\"Paragraph\"", ",", "\n", "\"True Relation Label\"", ",", "\n", "\"Predicted Relation Label\"", ",", "\n", "\"Sentence Length\"", ",", "\n", "\"Paragraph Length\"", ",", "\n", "\"Number of Entities in Ground Truth Relation\"", ",", "\n", "\"Average Distance of Entities\"", "\n", "]", "\n", "\n", "with", "open", "(", "fname", ",", "'w'", ")", "as", "out_file", ":", "\n", "        ", "tsv_writer", "=", "csv", ".", "writer", "(", "out_file", ",", "delimiter", "=", "'\\t'", ")", "\n", "tsv_writer", ".", "writerow", "(", "header", ")", "\n", "for", "dataset_row", "in", "dataset", ":", "\n", "            ", "prediction", "=", "row_predictions", "[", "dataset_row", "[", "\"row_id\"", "]", "]", "\n", "doc_id", "=", "json", ".", "loads", "(", "dataset_row", "[", "\"row_id\"", "]", ")", "[", "\"doc_id\"", "]", "\n", "full_document", "=", "test_data_raw", "[", "doc_id", "]", "\n", "error_analysis_attributes", "=", "ErrorAnalysisAttributes", "(", "dataset_row", ",", "full_document", ",", "prediction", ")", "\n", "tsv_writer", ".", "writerow", "(", "error_analysis_attributes", ".", "get_row", "(", ")", ")", "\n", "", "", "print", "(", "f\"Wrote error analysis file to {fname}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.set_seed": [[281, 290], ["numpy.random.seed", "random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "# set seed for all possible avenues of stochasticity", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", "=", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.adjust_data": [[292, 311], ["enumerate", "zip", "fix_t.append", "json.loads"], "function", ["None"], ["", "def", "adjust_data", "(", "gold", ":", "List", "[", "str", "]", ",", "test", ":", "List", "[", "int", "]", ")", "->", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "    ", "\"\"\"Given a list of row id strings and their corresponding predicted labels, convert the prediction list\n        to a list of the same format as the gold, where the only difference would be the predicted label.\n\n    Args:\n        gold: List of Dictionary object, each of which represents a row_id.\n            A row ID contains a sentence hash, a list of drug indices, and a gold relation label.\n        test: List of integers representing a predicted relation label\n\n    Returns:\n        fixed test lists of \"row id\" dictionary\n    \"\"\"", "\n", "fix_t", "=", "[", "]", "\n", "for", "i", ",", "(", "g", ",", "t", ")", "in", "enumerate", "(", "zip", "(", "gold", ",", "test", ")", ")", ":", "\n", "# for the test/pred we want to the copied information from the gold list,", "\n", "#   except for the relation label itself", "\n", "        ", "fix_t", ".", "append", "(", "json", ".", "loads", "(", "g", ")", ")", "\n", "fix_t", "[", "i", "]", "[", "\"relation_label\"", "]", "=", "t", "\n", "", "return", "fix_t", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.filter_overloaded_predictions": [[313, 349], ["sorted", "enumerate", "enumerate", "doc.append", "final_test.extend", "sorted", "len", "send_to_further.append", "utils.filter_overloaded_predictions.do_filtering"], "function", ["None"], ["", "def", "filter_overloaded_predictions", "(", "preds", ")", ":", "\n", "    ", "def", "do_filtering", "(", "d", ")", ":", "\n", "# our filtering algorithm:", "\n", "#   1. we assume each sentence gets predictions for each subset of drugs in the sentence", "\n", "#   2. we assume these are too many and probably conflicting predictions, so they need to be filtered", "\n", "#   3. we use a very simple (greedy) heuristic in which we look for the biggest (by drug-count) combination,", "\n", "#       that has a non NO_COMB prediction, and we take it.", "\n", "#   4. we try to get as large a coverage (on the drugs) as possible while maintaining", "\n", "#       a minimalistic list of predictions as possible, so we do this repeatedly on the remaining drugs", "\n", "        ", "out", "=", "d", "[", "0", "]", "\n", "for", "j", ",", "e", "in", "d", ":", "\n", "            ", "if", "e", "[", "\"relation_label\"", "]", ":", "\n", "                ", "out", "=", "(", "j", ",", "e", ")", "\n", "break", "\n", "", "", "send_to_further", "=", "[", "]", "\n", "for", "j", ",", "e", "in", "d", ":", "\n", "# store all non intersecting predictions with the chosen one, so we can repeat the filtering process on them", "\n", "            ", "if", "len", "(", "set", "(", "out", "[", "1", "]", "[", "\"drug_idxs\"", "]", ")", ".", "intersection", "(", "set", "(", "e", "[", "\"drug_idxs\"", "]", ")", ")", ")", "==", "0", ":", "\n", "                ", "send_to_further", ".", "append", "(", "(", "j", ",", "e", ")", ")", "\n", "", "", "return", "[", "out", "]", "+", "(", "do_filtering", "(", "send_to_further", ")", "if", "send_to_further", "else", "[", "]", ")", "\n", "\n", "# we sort here so it would be easier to group by sentence,", "\n", "#   and to have the high-drug-count examples first for the filtering process", "\n", "", "sorted_test", "=", "sorted", "(", "enumerate", "(", "preds", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", "[", "\"doc_id\"", "]", ",", "len", "(", "x", "[", "1", "]", "[", "\"drug_idxs\"", "]", ")", ",", "str", "(", "x", "[", "1", "]", "[", "\"drug_idxs\"", "]", ")", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "# aggregate predictions by the sentence and filter each prediction group", "\n", "final_test", "=", "[", "]", "\n", "doc", "=", "[", "]", "\n", "for", "i", ",", "(", "original_idx", ",", "example", ")", "in", "enumerate", "(", "sorted_test", ")", ":", "\n", "        ", "doc", ".", "append", "(", "(", "original_idx", ",", "example", ")", ")", "\n", "# reached the last one in the list, or last one for this sentence", "\n", "if", "(", "i", "+", "1", "==", "len", "(", "sorted_test", ")", ")", "or", "(", "sorted_test", "[", "i", "+", "1", "]", "[", "1", "]", "[", "\"doc_id\"", "]", "!=", "example", "[", "\"doc_id\"", "]", ")", ":", "\n", "            ", "final_test", ".", "extend", "(", "do_filtering", "(", "doc", ")", ")", "\n", "doc", "=", "[", "]", "\n", "# reorder the filtered list according to original indices, and get rid of the these indices", "\n", "", "", "return", "[", "x", "[", "1", "]", "for", "x", "in", "sorted", "(", "final_test", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.find_sent_in_para": [[350, 362], ["para.replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "para.replace().replace().replace().replace().replace.replace().find", "range", "range", "sent.replace", "len", "para.replace().replace().replace().replace().replace.replace().replace().replace().replace", "para.replace().replace().replace().replace().replace.replace", "sent.replace", "len", "len", "sent.replace", "para.replace().replace().replace().replace().replace.replace().replace().replace", "para.replace().replace().replace().replace().replace.replace().replace", "para.replace().replace().replace().replace().replace.replace"], "function", ["None"], ["", "def", "find_sent_in_para", "(", "sent", ",", "para", ")", ":", "\n", "    ", "para", "=", "para", ".", "replace", "(", "\"\\u2009\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\u00a0\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\u202f\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\u2003\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\u200a\"", ",", "\" \"", ")", "\n", "idx", "=", "para", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "find", "(", "sent", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "\n", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "idx", ")", ":", "\n", "        ", "while", "para", "[", "i", "+", "c", "]", "==", "\" \"", ":", "\n", "            ", "c", "+=", "1", "\n", "", "", "c2", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "sent", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", ")", ":", "\n", "        ", "while", "i", "+", "idx", "+", "c", "+", "c2", "<", "len", "(", "para", ")", "and", "para", "[", "i", "+", "idx", "+", "c", "+", "c2", "]", "==", "\" \"", ":", "\n", "            ", "c2", "+=", "1", "\n", "", "", "return", "idx", "+", "c", ",", "idx", "+", "c", "+", "c2", "+", "len", "(", "sent", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.is_sublist": [[363, 376], ["range", "len", "range", "len", "len", "len"], "function", ["None"], ["", "def", "is_sublist", "(", "list_a", ",", "list_b", ")", ":", "\n", "    ", "if", "len", "(", "list_a", ")", "==", "0", ":", "\n", "        ", "return", "True", "\n", "", "for", "i", "in", "range", "(", "len", "(", "list_b", ")", "-", "len", "(", "list_a", ")", "+", "1", ")", ":", "\n", "        ", "if", "list_b", "[", "i", "]", "==", "list_a", "[", "0", "]", ":", "\n", "            ", "matched", "=", "True", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "list_a", ")", ")", ":", "\n", "                ", "if", "list_a", "[", "j", "]", "!=", "list_b", "[", "i", "+", "j", "]", ":", "\n", "                    ", "matched", "=", "False", "\n", "break", "\n", "", "", "if", "matched", ":", "\n", "                ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.find_mentions_in_sentence": [[377, 410], ["sentence.lower", "sentence.lower.split", "utils.is_sublist", "drug.split", "re.finditer", "random.choice", "common.types.DrugEntity", "drug_mentions.append", "drug_repetition_idxs.append", "re.escape", "len", "list", "entity_occurrences.append", "range", "len", "entity_occurrence.start", "entity_occurrence.end", "len", "occurrence.start", "occurrence.end", "len", "occurrence.end", "occurrence.start"], "function", ["home.repos.pwc.inspect_result.allenai_drug-combo-extraction.common.utils.is_sublist"], ["", "def", "find_mentions_in_sentence", "(", "sentence", ",", "drug_list", ")", ":", "\n", "    ", "drug_mentions", "=", "[", "]", "\n", "drug_repetition_idxs", "=", "[", "]", "\n", "sentence_lower", "=", "sentence", ".", "lower", "(", ")", "\n", "sentence_tokens", "=", "sentence_lower", ".", "split", "(", ")", "\n", "for", "drug", "in", "drug_list", ":", "\n", "        ", "skip_drug", "=", "False", "\n", "for", "existing_drug", "in", "drug_mentions", ":", "\n", "            ", "if", "drug", "in", "existing_drug", ".", "drug_name", "or", "existing_drug", ".", "drug_name", "in", "drug", ":", "\n", "# Having overlapping drug names makes it difficult to preprocess; omit these", "\n", "                ", "skip_drug", "=", "True", "\n", "break", "\n", "", "", "if", "skip_drug", ":", "\n", "            ", "continue", "\n", "", "if", "is_sublist", "(", "drug", ".", "split", "(", ")", ",", "sentence_tokens", ")", ":", "\n", "# Sample one instance of the drug in this sentence, if it occurs multiple times.", "\n", "            ", "entity_occurrences", "=", "[", "]", "\n", "for", "occurrence", "in", "re", ".", "finditer", "(", "re", ".", "escape", "(", "drug", ")", ",", "sentence_lower", ")", ":", "\n", "# Want to find drug mentions that are standalone tokens, not contained in other entities", "\n", "                ", "if", "(", "occurrence", ".", "start", "(", ")", "==", "0", "or", "sentence_lower", "[", "occurrence", ".", "start", "(", ")", "-", "1", "]", "==", "\" \"", ")", "and", "(", "occurrence", ".", "end", "(", ")", "==", "len", "(", "sentence_lower", ")", "or", "sentence_lower", "[", "occurrence", ".", "end", "(", ")", "]", "==", "\" \"", ")", ":", "\n", "                    ", "entity_occurrences", ".", "append", "(", "occurrence", ")", "\n", "", "", "if", "len", "(", "entity_occurrences", ")", "==", "0", ":", "\n", "                ", "return", "[", "]", ",", "[", "]", "\n", "", "entity_occurrence_idx", "=", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "entity_occurrences", ")", ")", ")", ")", "\n", "entity_occurrence", "=", "entity_occurrences", "[", "entity_occurrence_idx", "]", "\n", "drug_entity", "=", "DrugEntity", "(", "drug_name", "=", "drug", ",", "\n", "drug_idx", "=", "len", "(", "drug_mentions", ")", ",", "\n", "span_start", "=", "entity_occurrence", ".", "start", "(", ")", ",", "\n", "span_end", "=", "entity_occurrence", ".", "end", "(", ")", ")", "\n", "drug_mentions", ".", "append", "(", "drug_entity", ")", "\n", "drug_repetition_idxs", ".", "append", "(", "entity_occurrence_idx", ")", "\n", "", "", "return", "drug_mentions", ",", "drug_repetition_idxs", "\n", "", ""]]}