{"home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_rnn.DomainRNN.__init__": [[18, 60], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.ModuleDict", "torch.ModuleDict", "torch.Linear", "torch.Linear", "os.path.exists", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding", "torch.Embedding", "domain_rnn.DomainRNN.wemb.reset_parameters", "torch.init.kaiming_uniform_", "torch.init.kaiming_uniform_", "torch.GRU", "torch.GRU", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.load", "numpy.sqrt", "len"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "DomainRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "\n", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "params", "[", "'max_feature'", "]", ",", "self", ".", "params", "[", "'emb_dim'", "]", "\n", ")", "\n", "self", ".", "wemb", ".", "reset_parameters", "(", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "wemb", ".", "weight", ",", "a", "=", "np", ".", "sqrt", "(", "5", ")", ")", "\n", "\n", "", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "\n", "# domain adaptation", "\n", "", "self", ".", "doc_net_general", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "wemb", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "self", ".", "doc_net_domain", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "for", "domain", "in", "self", ".", "params", "[", "'unique_domains'", "]", ":", "\n", "            ", "self", ".", "doc_net_domain", "[", "'domain_{}'", ".", "format", "(", "domain", ")", "]", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "wemb", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "# prediction", "\n", "", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "params", "[", "'emb_dim'", "]", "*", "(", "1", "+", "len", "(", "self", ".", "params", "[", "'unique_domains'", "]", ")", ")", ",", "self", ".", "params", "[", "'num_label'", "]", ")", "\n", "\n", "# mode setting", "\n", "self", ".", "mode", "=", "'train'", "\n", "self", ".", "lambda_v", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_rnn.DomainRNN.change_mode": [[61, 63], ["None"], "methods", ["None"], ["", "def", "change_mode", "(", "self", ",", "mode", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_rnn.DomainRNN.change_lambda": [[64, 66], ["None"], "methods", ["None"], ["", "def", "change_lambda", "(", "self", ",", "lambda_v", ")", ":", "\n", "        ", "self", ".", "lambda_v", "=", "lambda_v", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_rnn.DomainRNN.forward": [[67, 111], ["domain_rnn.DomainRNN.wemb", "domain_rnn.DomainRNN.doc_net_general", "domain_rnn.DomainRNN.predictor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.squeeze", "torch.cat.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doc_domain.squeeze.squeeze.squeeze", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "int", "domain.split"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_docs", ",", "input_domains", "=", "None", ")", ":", "\n", "# encode the document from different perspectives", "\n", "        ", "doc_embs", "=", "self", ".", "wemb", "(", "input_docs", ")", "\n", "_", ",", "doc_general", "=", "self", ".", "doc_net_general", "(", "doc_embs", ")", "# omit hidden vectors", "\n", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", "[", "0", ",", ":", ",", ":", "]", ",", "doc_general", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "# mask out unnecessary features", "\n", "", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "for", "domain", "in", "self", ".", "doc_net_domain", ":", "\n", "                ", "domain_mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "1", "if", "int", "(", "domain", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "==", "item", "else", "0", "for", "item", "in", "input_domains", "]", ",", "\n", ")", ".", "to", "(", "self", ".", "params", "[", "'device'", "]", ")", "\n", "_", ",", "doc_domain", "=", "self", ".", "doc_net_domain", "[", "domain", "]", "(", "doc_embs", ")", "# omit hidden vectors", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "                    ", "doc_domain", "=", "torch", ".", "cat", "(", "(", "doc_domain", "[", "0", ",", ":", ",", ":", "]", ",", "doc_domain", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "", "if", "doc_domain", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                    ", "doc_domain", "=", "doc_domain", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "# mask out features if domains do not match", "\n", "", "doc_domain", "=", "torch", ".", "mul", "(", "doc_domain", ",", "domain_mask", "[", ":", ",", "None", "]", ")", "\n", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", ",", "doc_domain", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# because domain encoder share the same shape with the general domain", "\n", "            ", "tensor_shape", "=", "doc_general", ".", "shape", "\n", "doc_general", "=", "torch", ".", "cat", "(", "\n", "(", "\n", "doc_general", ",", "\n", "torch", ".", "zeros", "(", "\n", "tensor_shape", "[", "0", "]", ",", "\n", "tensor_shape", "[", "1", "]", "*", "len", "(", "self", ".", "params", "[", "'unique_domains'", "]", ")", "\n", ")", ".", "to", "(", "self", ".", "params", "[", "'device'", "]", ")", "\n", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "doc_general", "*=", "self", ".", "lambda_v", "\n", "\n", "# prediction", "\n", "", "doc_preds", "=", "self", ".", "predictor", "(", "doc_general", ")", "\n", "return", "doc_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_rnn.domain_rnn": [[113, 307], ["utils.data_loader", "numpy.unique", "utils.build_tok", "utils.data_split", "utils.DataEncoder", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "domain_rnn.DomainRNN", "rnn_model.to.to", "torch.CrossEntropyLoss().to", "torch.KLDivLoss().to", "torch.optim.RMSprop", "torch.optim.RMSprop", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "os.path.exists", "utils.build_wt", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "rnn_model.to.parameters", "range", "rnn_model.to.train", "rnn_model.to.change_mode", "enumerate", "rnn_model.to.change_mode", "sklearn.metrics.f1_score", "os.path.join", "range", "torch.CrossEntropyLoss", "torch.KLDivLoss", "tuple", "torch.optim.RMSprop.zero_grad", "rnn_model.to.", "nn.CrossEntropyLoss().to.", "criterion.item", "criterion.backward", "torch.optim.RMSprop.step", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "rnn_model.view", "input_labels.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "print", "print", "print", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "sklearn.metrics.classification_report", "print", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "input_labels.to", "os.path.basename", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "utils.fair_eval", "rnn_model.detach", "input_labels.to", "input_domains.detach().cpu", "rnn_model.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_mode", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_mode", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "domain_rnn", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok", "=", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'.tok'", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "        ", "utils", ".", "build_wt", "(", "tok", ",", "params", "[", "'emb_path'", "]", ",", "params", "[", "'word_emb_path'", "]", ")", "\n", "\n", "", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "rnn_model", "=", "DomainRNN", "(", "params", ")", "\n", "rnn_model", "=", "rnn_model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "kl_loss", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'batchmean'", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "rnn_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "rnn_model", ".", "train", "(", ")", "\n", "rnn_model", ".", "change_mode", "(", "'train'", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "view", "(", "-", "1", ",", "params", "[", "'num_label'", "]", ")", ",", "input_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "for", "domain", "in", "params", "[", "'unique_domains'", "]", ":", "\n", "                ", "domain_kl", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "\n", "rnn_model", ".", "doc_net_general", ".", "weight_ih_l0", "-", "rnn_model", ".", "doc_net_domain", "[", "'domain_{}'", ".", "format", "(", "domain", ")", "]", ".", "weight_ih_l0", "\n", ")", ")", "\n", "domain_kl", "+=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "\n", "rnn_model", ".", "doc_net_general", ".", "weight_hh_l0", "-", "rnn_model", ".", "doc_net_domain", "[", "'domain_{}'", ".", "format", "(", "domain", ")", "]", ".", "weight_hh_l0", "\n", ")", ")", "\n", "domain_kl", "=", "params", "[", "'kl_score'", "]", "*", "domain_kl", "\n", "# print(domain_kl)", "\n", "loss", "+=", "domain_kl", "\n", "", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "rnn_model", ".", "change_mode", "(", "'valid'", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "rnn_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "report", "=", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", "\n", ")", "\n", "print", "(", "report", ")", "\n", "wfile", ".", "write", "(", "report", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.__init__": [[19, 40], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ModuleDict", "torch.ModuleDict", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "DomainBERT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "self", ".", "bert_model", "=", "AutoModel", ".", "from_pretrained", "(", "self", ".", "params", "[", "'bert_name'", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "params", "[", "'dp_rate'", "]", ")", "\n", "\n", "# domain adaptation", "\n", "self", ".", "doc_net_general", "=", "nn", ".", "Linear", "(", "self", ".", "bert_model", ".", "config", ".", "hidden_size", ",", "self", ".", "params", "[", "'emb_dim'", "]", ")", "\n", "\n", "self", ".", "doc_net_domain", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "for", "domain", "in", "self", ".", "params", "[", "'unique_domains'", "]", ":", "\n", "            ", "self", ".", "doc_net_domain", "[", "'domain_{}'", ".", "format", "(", "domain", ")", "]", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "bert_model", ".", "config", ".", "hidden_size", ",", "self", ".", "params", "[", "'emb_dim'", "]", ")", "\n", "\n", "# prediction", "\n", "", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "self", ".", "params", "[", "'emb_dim'", "]", "*", "3", ",", "self", ".", "params", "[", "'num_label'", "]", ")", "\n", "\n", "# mode setting", "\n", "self", ".", "mode", "=", "'train'", "\n", "self", ".", "lambda_v", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_mode": [[41, 43], ["None"], "methods", ["None"], ["", "def", "change_mode", "(", "self", ",", "mode", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_lambda": [[44, 46], ["None"], "methods", ["None"], ["", "def", "change_lambda", "(", "self", ",", "lambda_v", ")", ":", "\n", "        ", "self", ".", "lambda_v", "=", "lambda_v", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.forward": [[47, 80], ["domain_bert.DomainBERT.bert_model", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "domain_bert.DomainBERT.doc_net_general", "domain_bert.DomainBERT.dropout", "domain_bert.DomainBERT.predictor", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.cat.squeeze", "torch.cat.squeeze", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "domain_bert.DomainBERT.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "int", "domain.split"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_docs", ",", "input_domains", "=", "None", ")", ":", "\n", "# encode the document from different perspectives", "\n", "        ", "doc_embs", "=", "self", ".", "bert_model", "(", "\n", "input_docs", ",", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", "\n", ")", "\n", "doc_embs", "=", "torch", ".", "mean", "(", "doc_embs", "[", "0", "]", ",", "dim", "=", "1", ")", "# take average of outputs from bert", "\n", "doc_general", "=", "self", ".", "doc_net_general", "(", "doc_embs", ")", "\n", "doc_general", "=", "self", ".", "dropout", "(", "torch", ".", "relu", "(", "doc_general", ")", ")", "\n", "\n", "# mask out unnecessary features", "\n", "if", "self", ".", "mode", "==", "'train'", ":", "\n", "            ", "for", "domain", "in", "self", ".", "doc_net_domain", ":", "\n", "                ", "domain_mask", "=", "torch", ".", "Tensor", "(", "\n", "[", "1", "if", "int", "(", "domain", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "==", "item", "else", "0", "for", "item", "in", "input_domains", "]", ")", ".", "to", "(", "self", ".", "params", "[", "'device'", "]", ")", "\n", "doc_domain", "=", "self", ".", "doc_net_domain", "[", "domain", "]", "(", "doc_embs", ")", "\n", "# mask out features if domains do not match", "\n", "doc_domain", "=", "torch", ".", "mul", "(", "doc_domain", ",", "domain_mask", "[", ":", ",", "None", "]", ")", "\n", "doc_domain", "=", "self", ".", "dropout", "(", "torch", ".", "relu", "(", "doc_domain", ")", ")", "\n", "\n", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", ",", "doc_domain", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# because domain encoder share the same shape with the general domain", "\n", "            ", "tensor_shape", "=", "doc_general", ".", "shape", "\n", "for", "_", "in", "self", ".", "doc_net_domain", ":", "\n", "                ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", ",", "torch", ".", "zeros", "(", "tensor_shape", "[", "0", "]", ",", "tensor_shape", "[", "1", "]", ")", ".", "to", "(", "self", ".", "params", "[", "'device'", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "doc_general", "*=", "self", ".", "lambda_v", "\n", "\n", "# prediction", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "", "doc_preds", "=", "self", ".", "predictor", "(", "doc_general", ")", "\n", "return", "doc_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.domain_bert": [[82, 269], ["utils.DataEncoder", "utils.data_loader", "numpy.unique", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "domain_bert.DomainBERT", "bert_model.to.change_lambda", "bert_model.to.to", "torch.CrossEntropyLoss().to", "torch.optim.Adam", "torch.optim.Adam", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "bert_model.to.parameters", "range", "bert_model.to.train", "bert_model.to.change_mode", "enumerate", "bert_model.to.change_mode", "sklearn.metrics.f1_score", "range", "torch.CrossEntropyLoss", "tuple", "torch.optim.Adam.zero_grad", "bert_model.to.", "nn.CrossEntropyLoss().to.", "criterion.item", "criterion.backward", "torch.optim.Adam.step", "tuple", "bert_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "bert_model.view", "input_labels.view", "torch.mean", "torch.mean", "print", "print", "print", "torch.no_grad", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "tuple", "bert_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "torch.abs", "torch.abs", "t.to", "bert_model.detach().cpu", "numpy.argmax", "torch.no_grad", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "input_labels.to", "os.path.basename", "t.to", "bert_model.detach().cpu", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "bert_model.detach", "input_labels.to", "input_domains.detach().cpu", "bert_model.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_lambda", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_mode", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_bert.DomainBERT.change_mode", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "domain_bert", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'bert'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "bert_model", "=", "DomainBERT", "(", "params", ")", "\n", "bert_model", ".", "change_lambda", "(", "params", "[", "'lambda_v'", "]", ")", "\n", "bert_model", "=", "bert_model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "# kl_loss = nn.KLDivLoss().to(device)", "\n", "# param_optimizer = list(bert_model.named_parameters())", "\n", "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "bert_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "bert_model", ".", "train", "(", ")", "\n", "bert_model", ".", "change_mode", "(", "'train'", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "view", "(", "-", "1", ",", "params", "[", "'num_label'", "]", ")", ",", "input_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "for", "domain", "in", "params", "[", "'unique_domains'", "]", ":", "\n", "                ", "domain_kl", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "\n", "torch", ".", "cumsum", "(", "bert_model", ".", "doc_net_general", ".", "weight", ",", "dim", "=", "-", "1", ")", "-", "torch", ".", "cumsum", "(", "\n", "bert_model", ".", "doc_net_domain", "[", "\n", "'domain_{}'", ".", "format", "(", "domain", ")", "]", ".", "weight", ",", "dim", "=", "-", "1", "\n", ")", "\n", ")", ")", "\n", "# print(domain_kl)", "\n", "domain_kl", "=", "params", "[", "'kl_score'", "]", "*", "domain_kl", "\n", "loss", "+=", "domain_kl", "\n", "", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "bert_model", ".", "change_mode", "(", "'valid'", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "bert_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "'input_domains'", ":", "input_domains", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.__init__": [[28, 33], ["domain_lr.DomainVectorizer.params.get"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "uniq_domains", "=", "None", "\n", "self", ".", "tfidf_vec_da", "=", "None", "\n", "self", ".", "use_large", "=", "self", ".", "params", ".", "get", "(", "'use_large'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit": [[34, 89], ["print", "sorted", "dict.fromkeys", "set", "numpy.unique", "sklearn.feature_extraction.text.TfidfVectorizer", "domain_lr.DomainVectorizer.tfidf_vec_da[].fit", "sklearn.feature_extraction.text.TfidfVectorizer", "os.path.join", "sklearn.feature_extraction.text.TfidfVectorizer.fit", "pickle.dump", "nltk.corpus.stopwords.words", "print", "sklearn.feature_extraction.text.TfidfVectorizer", "domain_lr.DomainVectorizer.tfidf_vec_da[].fit", "print", "os.path.join", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit", "pickle.dump", "open", "open", "str", "enumerate", "str", "str", "enumerate"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit"], ["", "def", "fit", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n\n        :param dataset: a dictionary with x, y, and domain labels\n        :return:\n        \"\"\"", "\n", "# if len(dataset) > 15469:  # this number is length of \"./yelp/yelp_Hotels_year_sample.tsv\"", "\n", "#     self.use_large = True", "\n", "print", "(", "'start to fit'", ")", "\n", "try", ":", "\n", "            ", "spw_set", "=", "set", "(", "stopwords", ".", "words", "(", "self", ".", "params", "[", "'lang'", "]", ")", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "spw_set", "=", "None", "\n", "", "self", ".", "uniq_domains", "=", "sorted", "(", "\n", "np", ".", "unique", "(", "[", "item", "for", "item", "in", "dataset", "[", "self", ".", "params", "[", "'domain_name'", "]", "]", "if", "item", "!=", "'docs'", "]", ")", ")", "\n", "self", ".", "tfidf_vec_da", "=", "dict", ".", "fromkeys", "(", "self", ".", "uniq_domains", ")", "\n", "\n", "if", "not", "self", ".", "use_large", ":", "\n", "            ", "for", "key", "in", "self", ".", "uniq_domains", ":", "\n", "                ", "print", "(", "'Domain:'", "+", "str", "(", "key", ")", ")", "\n", "self", ".", "tfidf_vec_da", "[", "key", "]", "=", "TfidfVectorizer", "(", "\n", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "min_df", "=", "2", ",", "max_features", "=", "self", ".", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", "\n", ")", "\n", "new_docs", "=", "[", "\n", "item", "for", "idx", ",", "item", "in", "enumerate", "(", "dataset", "[", "'docs'", "]", ")", "\n", "if", "dataset", "[", "self", ".", "params", "[", "'domain_name'", "]", "]", "[", "idx", "]", "==", "key", "]", "\n", "self", ".", "tfidf_vec_da", "[", "key", "]", ".", "fit", "(", "new_docs", ")", "\n", "", "self", ".", "tfidf_vec_da", "[", "\"general\"", "]", "=", "TfidfVectorizer", "(", "\n", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "min_df", "=", "2", ",", "max_features", "=", "self", ".", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", "\n", ")", "\n", "self", ".", "tfidf_vec_da", "[", "\"general\"", "]", ".", "fit", "(", "dataset", "[", "'docs'", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "key", "in", "self", ".", "tfidf_vec_da", ":", "\n", "                ", "print", "(", "'Domain:'", "+", "str", "(", "key", ")", ")", "\n", "self", ".", "tfidf_vec_da", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "self", ".", "params", "[", "'model_dir'", "]", ",", "str", "(", "key", ")", "+", "'.pkl'", ")", "\n", "tmp_vect", "=", "TfidfVectorizer", "(", "\n", "min_df", "=", "3", ",", "max_features", "=", "self", ".", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", ",", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "\n", ")", "\n", "tmp_vect", ".", "fit", "(", "\n", "[", "item", "for", "idx", ",", "item", "in", "enumerate", "(", "dataset", "[", "'docs'", "]", ")", "\n", "if", "dataset", "[", "self", ".", "params", "[", "'domain_name'", "]", "]", "[", "idx", "]", "==", "key", "]", "\n", ")", "\n", "pickle", ".", "dump", "(", "tmp_vect", ",", "open", "(", "self", ".", "tfidf_vec_da", "[", "key", "]", ",", "'wb'", ")", ")", "\n", "\n", "", "tmp_vect", "=", "TfidfVectorizer", "(", "\n", "min_df", "=", "3", ",", "max_features", "=", "self", ".", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", ",", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "\n", ")", "\n", "self", ".", "tfidf_vec_da", "[", "\"general\"", "]", "=", "os", ".", "path", ".", "join", "(", "self", ".", "params", "[", "'model_dir'", "]", ",", "'general.pkl'", ")", "\n", "tmp_vect", ".", "fit", "(", "dataset", "[", "'docs'", "]", ")", "\n", "pickle", ".", "dump", "(", "tmp_vect", ",", "open", "(", "self", ".", "tfidf_vec_da", "[", "'general'", "]", ",", "'wb'", ")", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform": [[90, 111], ["scipy.sparse.csc_matrix", "numpy.zeros", "scipy.sparse.csc_matrix", "scipy.sparse.hstack", "pickle.load", "scipy.sparse.csc_matrix", "scipy.sparse.hstack", "scipy.sparse.csc_matrix", "scipy.sparse.hstack", "domain_lr.DomainVectorizer.tfidf_vec_da[].transform", "pickle.load", "scipy.sparse.csc_matrix", "scipy.sparse.hstack", "open", "pickle.load.transform", "domain_lr.DomainVectorizer.tfidf_vec_da[].transform", "open", "pickle.load.transform", "len"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform"], ["", "def", "transform", "(", "self", ",", "docs", ")", ":", "\n", "        ", "fvs", "=", "csc_matrix", "(", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "docs", ")", ",", "1", ")", ")", ")", "\n", "\n", "if", "not", "self", ".", "use_large", ":", "\n", "            ", "for", "domain", "in", "self", ".", "uniq_domains", ":", "\n", "                ", "tmp_fvs", "=", "csc_matrix", "(", "self", ".", "tfidf_vec_da", "[", "domain", "]", ".", "transform", "(", "docs", ")", ")", "\n", "fvs", "=", "hstack", "(", "[", "fvs", ",", "tmp_fvs", "]", ")", "\n", "", "fvs", "=", "fvs", "[", ":", ",", "1", ":", "]", "\n", "tmp_fvs", "=", "csc_matrix", "(", "self", ".", "tfidf_vec_da", "[", "'general'", "]", ".", "transform", "(", "docs", ")", ")", "\n", "fvs", "=", "hstack", "(", "[", "fvs", ",", "tmp_fvs", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "domain", "in", "self", ".", "uniq_domains", ":", "\n", "                ", "dm_vect", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "tfidf_vec_da", "[", "domain", "]", ",", "'rb'", ")", ")", "\n", "tmp_fvs", "=", "csc_matrix", "(", "dm_vect", ".", "transform", "(", "docs", ")", ")", "\n", "fvs", "=", "hstack", "(", "[", "fvs", ",", "tmp_fvs", "]", ")", "\n", "", "fvs", "=", "fvs", "[", ":", ",", "1", ":", "]", "\n", "\n", "dm_vect", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "tfidf_vec_da", "[", "'general'", "]", ",", "'rb'", ")", ")", "\n", "tmp_fvs", "=", "csc_matrix", "(", "dm_vect", ".", "transform", "(", "docs", ")", ")", "\n", "fvs", "=", "hstack", "(", "[", "fvs", ",", "tmp_fvs", "]", ")", "\n", "", "return", "fvs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform_test": [[112, 121], ["scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "scipy.sparse.hstack", "domain_lr.DomainVectorizer.tfidf_vec_da[].transform", "len", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform"], ["", "def", "transform_test", "(", "self", ",", "docs", ")", ":", "# test data only keeps the general features", "\n", "        ", "fvs", "=", "csc_matrix", "(", "(", "\n", "len", "(", "docs", ")", ",", "\n", "sum", "(", "[", "len", "(", "self", ".", "tfidf_vec_da", "[", "domain", "]", ".", "vocabulary_", ")", "for", "domain", "in", "self", ".", "uniq_domains", "]", ")", ")", "\n", ")", "\n", "# only for the small data", "\n", "tmp_fvs", "=", "csc_matrix", "(", "self", ".", "tfidf_vec_da", "[", "'general'", "]", ".", "transform", "(", "docs", ")", ")", "\n", "fvs", "=", "hstack", "(", "[", "fvs", ",", "tmp_fvs", "]", ")", "\n", "return", "fvs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.da_tokenizer": [[23, 25], ["text.split"], "function", ["None"], ["def", "da_tokenizer", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.domain_lr": [[123, 244], ["print", "utils.data_loader", "print", "os.path.join", "os.path.exists", "utils.data_split", "print", "domain_lr.DomainVectorizer.transform", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "print", "print", "domain_lr.DomainVectorizer.transform_test", "scipy.sparse.lil_matrix", "print", "print", "print", "domain_lr.DomainVectorizer.transform_test", "scipy.sparse.lil_matrix", "print", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.roc_curve", "pickle.load", "domain_lr.DomainVectorizer", "domain_lr.DomainVectorizer.fit", "pickle.dump", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "len", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.f1_score", "open", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "open", "open", "range", "range", "len", "sklearn.linear_model.LogisticRegression.predict_proba", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "len"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform_test", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform_test", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "domain_lr", "(", "params", ")", ":", "\n", "    ", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "print", "(", "'Building Domain Vectorizer...'", ")", "\n", "\n", "da_path", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'-da_vect.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "da_path", ")", ":", "\n", "        ", "da_vect", "=", "pickle", ".", "load", "(", "open", "(", "da_path", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "da_vect", "=", "DomainVectorizer", "(", "params", ")", "\n", "da_vect", ".", "fit", "(", "data", ")", "\n", "pickle", ".", "dump", "(", "da_vect", ",", "open", "(", "da_path", ",", "'wb'", ")", ")", "\n", "", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "\n", "# train classifier", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "input_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "input_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "input_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "input_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "print", "(", "'Training Classifier...'", ")", "\n", "input_feats", "=", "da_vect", ".", "transform", "(", "input_data", "[", "'docs'", "]", ")", "\n", "clf", "=", "LogisticRegression", "(", "max_iter", "=", "2000", ",", "n_jobs", "=", "-", "1", ")", "\n", "clf", ".", "fit", "(", "input_feats", ",", "input_data", "[", "'labels'", "]", ")", "\n", "\n", "# parameter tuning", "\n", "general_len", "=", "-", "1", "*", "len", "(", "da_vect", ".", "tfidf_vec_da", "[", "'general'", "]", ".", "vocabulary_", ")", "\n", "best_lambda", "=", "1", "\n", "best_valid", "=", "0", "\n", "lambda_list", "=", "[", "0.3", ",", "1", ",", "10", ",", "30", ",", "100", ",", "300", "]", "\n", "print", "(", "'Loading Valid data'", ")", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "print", "(", "'Transforming valid data....................'", ")", "\n", "input_feats", "=", "da_vect", ".", "transform_test", "(", "input_data", "[", "'docs'", "]", ")", "\n", "# for using only general features", "\n", "input_feats", "=", "lil_matrix", "(", "input_feats", ")", "\n", "# because the general features were appended finally, previous features are all domain features.", "\n", "input_feats", "[", ":", ",", ":", "general_len", "]", "=", "0", "\n", "\n", "for", "lambda_item", "in", "lambda_list", ":", "\n", "        ", "exp_data", "=", "input_feats", "*", "lambda_item", "\n", "pred_label", "=", "clf", ".", "predict", "(", "exp_data", ")", "\n", "report_da", "=", "metrics", ".", "f1_score", "(", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "average", "=", "'weighted'", ")", "\n", "if", "report_da", ">", "best_valid", ":", "\n", "            ", "best_valid", "=", "report_da", "\n", "best_lambda", "=", "lambda_item", "\n", "\n", "", "", "print", "(", "'BEST Valid Performancel: '", ",", "best_valid", ")", "\n", "# load test", "\n", "print", "(", "'Loading Test data'", ")", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "\n", "print", "(", "'Transforming test data....................'", ")", "\n", "input_feats", "=", "da_vect", ".", "transform_test", "(", "input_data", "[", "'docs'", "]", ")", "\n", "# for using only general features", "\n", "input_feats", "=", "lil_matrix", "(", "input_feats", ")", "\n", "input_feats", "[", ":", ",", ":", "general_len", "]", "=", "0", "\n", "input_feats", "=", "input_feats", "*", "best_lambda", "\n", "\n", "print", "(", "'Testing.............................'", ")", "\n", "pred_label", "=", "clf", ".", "predict", "(", "input_feats", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_score", "=", "clf", ".", "predict_proba", "(", "input_feats", ")", "[", ":", ",", "1", "]", ",", "\n", ")", "\n", "\n", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "        ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "input_data", "[", "'labels'", "]", ",", "\n", "pred_labels", "=", "pred_label", ",", "\n", "domain_labels", "=", "input_data", "[", "params", "[", "'domain_name'", "]", "]", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.TorchDataset.__init__": [[85, 88], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "domain_name", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "domain_name", "=", "domain_name", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.TorchDataset.__len__": [[89, 91], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", "[", "'docs'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.TorchDataset.__getitem__": [[92, 97], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "domain_name", "in", "self", ".", "dataset", ":", "\n", "            ", "return", "self", ".", "dataset", "[", "'docs'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'labels'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "self", ".", "domain_name", "]", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "dataset", "[", "'docs'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'labels'", "]", "[", "idx", "]", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.DataEncoder.__init__": [[230, 245], ["pickle.load", "open", "transformers.BertTokenizer.from_pretrained", "ValueError", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "mtype", "=", "'rnn'", ")", ":", "\n", "        ", "\"\"\"\n\n        :param params:\n        :param mtype: Model type, rnn or bert\n        \"\"\"", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "mtype", "=", "mtype", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "            ", "self", ".", "tok", "=", "pickle", ".", "load", "(", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'.tok'", ")", ",", "'rb'", ")", ")", "\n", "", "elif", "self", ".", "mtype", "==", "'bert'", ":", "\n", "            ", "self", ".", "tok", "=", "BertTokenizer", ".", "from_pretrained", "(", "params", "[", "'bert_name'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Only support BERT and RNN data encoders'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.DataEncoder.__call__": [[246, 273], ["torch.tensor", "torch.tensor", "torch.tensor.append", "torch.tensor.append", "utils.DataEncoder.tok.texts_to_sequences", "keras.preprocessing.sequence.pad_sequences", "torch.Tensor().long", "torch.stack().long", "utils.DataEncoder.tok.encode_plus", "torch.stack().long.append", "torch.stack().long.append", "torch.Tensor", "torch.stack"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "docs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "domains", "=", "[", "]", "\n", "for", "text", ",", "label", ",", "domain", "in", "batch", ":", "\n", "            ", "if", "self", ".", "mtype", "==", "'bert'", ":", "\n", "                ", "text", "=", "self", ".", "tok", ".", "encode_plus", "(", "\n", "text", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "self", ".", "params", "[", "'max_len'", "]", ",", "\n", "return_tensors", "=", "'pt'", ",", "return_token_type_ids", "=", "False", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "docs", ".", "append", "(", "text", "[", "'input_ids'", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "docs", ".", "append", "(", "text", ")", "\n", "", "labels", ".", "append", "(", "label", ")", "\n", "domains", ".", "append", "(", "domain", ")", "\n", "\n", "", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "domains", "=", "torch", ".", "tensor", "(", "domains", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "# padding and tokenize", "\n", "            ", "docs", "=", "self", ".", "tok", ".", "texts_to_sequences", "(", "docs", ")", "\n", "docs", "=", "pad_sequences", "(", "docs", ")", "\n", "docs", "=", "torch", ".", "Tensor", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "            ", "docs", "=", "torch", ".", "stack", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "return", "docs", ",", "labels", ",", "domains", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.data_loader": [[17, 82], ["open", "dfile.readline().strip().split", "dfile.readline().strip().split.index", "dfile.readline().strip().split.index", "dfile.readline().strip().split.index", "enumerate", "line.strip().lower().split.strip().lower().split", "line[].strip", "data[].append", "data[].append", "data[].append", "dfile.readline().strip", "len", "len", "len", "int", "line.strip().lower().split.strip().lower", "line[].strip().split", "int", "nltk.tokenize.word_tokenize", "dfile.readline", "line.strip().lower().split.strip", "line[].strip"], "function", ["None"], ["def", "data_loader", "(", "dpath", ",", "domain_name", "=", "'gender'", ",", "filter_null", "=", "True", ",", "lang", "=", "'english'", ")", ":", "\n", "    ", "\"\"\"\n    Default data format, tsv\n    :param domain_name:\n    :param lang: Language of the corpus, currently only supports languages defined by punkt\n    :param filter_null: if filter out gender is empty or not.\n    :param dpath:\n    :return:\n    \"\"\"", "\n", "data", "=", "{", "\n", "'docs'", ":", "[", "]", ",", "\n", "'labels'", ":", "[", "]", ",", "\n", "'gender'", ":", "[", "]", ",", "\n", "}", "\n", "with", "open", "(", "dpath", ")", "as", "dfile", ":", "\n", "        ", "cols", "=", "dfile", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "doc_idx", "=", "cols", ".", "index", "(", "'text'", ")", "\n", "domain_idx", "=", "cols", ".", "index", "(", "domain_name", ")", "\n", "label_idx", "=", "cols", ".", "index", "(", "'label'", ")", "\n", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "dfile", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "line", ")", "!=", "len", "(", "cols", ")", ":", "\n", "                ", "continue", "\n", "", "if", "len", "(", "line", "[", "doc_idx", "]", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "<", "10", ":", "\n", "                ", "continue", "\n", "\n", "# print(idx, line)", "\n", "", "if", "filter_null", "and", "line", "[", "domain_idx", "]", "==", "'x'", ":", "\n", "                ", "continue", "\n", "\n", "# binarize labels in the trustpilot dataset to keep the same format.", "\n", "", "try", ":", "\n", "                ", "label", "=", "int", "(", "line", "[", "label_idx", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "# encode hate speech data", "\n", "                ", "if", "line", "[", "label_idx", "]", "in", "[", "'0'", ",", "'no'", ",", "'neither'", ",", "'normal'", "]", ":", "\n", "                    ", "label", "=", "0", "\n", "", "else", ":", "\n", "                    ", "label", "=", "1", "\n", "\n", "# label trustpilot review scores", "\n", "", "", "if", "'trustpilot'", "in", "dpath", ":", "\n", "                ", "if", "label", "==", "3", ":", "\n", "                    ", "continue", "\n", "", "elif", "label", ">", "3", ":", "\n", "                    ", "label", "=", "1", "\n", "", "else", ":", "\n", "                    ", "label", "=", "0", "\n", "\n", "# encode gender.", "\n", "", "", "gender", "=", "line", "[", "domain_idx", "]", ".", "strip", "(", ")", "\n", "if", "gender", "!=", "'x'", ":", "\n", "                ", "if", "gender", "not", "in", "[", "'1'", ",", "'0'", "]", ":", "\n", "                    ", "if", "'f'", "in", "gender", ":", "\n", "                        ", "gender", "=", "1", "\n", "", "else", ":", "\n", "                        ", "gender", "=", "0", "\n", "", "", "else", ":", "\n", "                    ", "gender", "=", "int", "(", "gender", ")", "\n", "\n", "", "", "data", "[", "'docs'", "]", ".", "append", "(", "' '", ".", "join", "(", "word_tokenize", "(", "line", "[", "doc_idx", "]", ",", "language", "=", "lang", ")", ")", ")", "\n", "data", "[", "'labels'", "]", ".", "append", "(", "label", ")", "\n", "data", "[", "domain_name", "]", ".", "append", "(", "gender", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.data_split": [[99, 113], ["list", "numpy.random.seed", "numpy.random.shuffle", "range", "len", "int", "int", "int", "int", "len", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "data_split", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n\n    :param data:\n    :return:\n    \"\"\"", "\n", "data_indices", "=", "list", "(", "range", "(", "len", "(", "data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "33", ")", "# for reproductive results", "\n", "np", ".", "random", ".", "shuffle", "(", "data_indices", ")", "\n", "\n", "train_indices", "=", "data_indices", "[", ":", "int", "(", ".8", "*", "len", "(", "data_indices", ")", ")", "]", "\n", "dev_indices", "=", "data_indices", "[", "int", "(", ".8", "*", "len", "(", "data_indices", ")", ")", ":", "int", "(", ".9", "*", "len", "(", "data_indices", ")", ")", "]", "\n", "test_indices", "=", "data_indices", "[", "int", "(", ".9", "*", "len", "(", "data_indices", ")", ")", ":", "]", "\n", "return", "train_indices", ",", "dev_indices", ",", "test_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.cal_fpr": [[115, 118], ["None"], "function", ["None"], ["", "def", "cal_fpr", "(", "fp", ",", "tn", ")", ":", "\n", "    ", "\"\"\"False positive rate\"\"\"", "\n", "return", "fp", "/", "(", "fp", "+", "tn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.cal_fnr": [[120, 123], ["None"], "function", ["None"], ["", "def", "cal_fnr", "(", "fn", ",", "tp", ")", ":", "\n", "    ", "\"\"\"False negative rate\"\"\"", "\n", "return", "fn", "/", "(", "fn", "+", "tp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.cal_tpr": [[125, 128], ["None"], "function", ["None"], ["", "def", "cal_tpr", "(", "tp", ",", "fn", ")", ":", "\n", "    ", "\"\"\"True positive rate\"\"\"", "\n", "return", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.cal_tnr": [[130, 133], ["None"], "function", ["None"], ["", "def", "cal_tnr", "(", "tn", ",", "fp", ")", ":", "\n", "    ", "\"\"\"True negative rate\"\"\"", "\n", "return", "tn", "/", "(", "tn", "+", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.fair_eval": [[135, 174], ["sklearn.metrics.confusion_matrix().ravel", "numpy.unique", "json.dumps", "sklearn.metrics.confusion_matrix().ravel", "sklearn.metrics.confusion_matrix", "abs", "abs", "abs", "abs", "range", "sklearn.metrics.confusion_matrix", "len", "utils.cal_fnr", "utils.cal_fnr", "utils.cal_fpr", "utils.cal_fpr", "utils.cal_tpr", "utils.cal_tpr", "utils.cal_tnr", "utils.cal_tnr"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tnr"], ["", "def", "fair_eval", "(", "true_labels", ",", "pred_labels", ",", "domain_labels", ")", ":", "\n", "    ", "scores", "=", "{", "\n", "'fned'", ":", "0.0", ",", "# gap between fnr", "\n", "'fped'", ":", "0.0", ",", "# gap between fpr", "\n", "'tped'", ":", "0.0", ",", "# gap between tpr", "\n", "'tned'", ":", "0.0", ",", "# gap between tnr", "\n", "}", "\n", "\n", "# get overall confusion matrix", "\n", "tn", ",", "fp", ",", "fn", ",", "tp", "=", "metrics", ".", "confusion_matrix", "(", "\n", "y_true", "=", "true_labels", ",", "y_pred", "=", "pred_labels", "\n", ")", ".", "ravel", "(", ")", "\n", "\n", "# get the unique types of demographic groups", "\n", "uniq_types", "=", "np", ".", "unique", "(", "domain_labels", ")", "\n", "for", "group", "in", "uniq_types", ":", "\n", "# calculate group specific confusion matrix", "\n", "        ", "group_indices", "=", "[", "item", "for", "item", "in", "range", "(", "len", "(", "domain_labels", ")", ")", "if", "domain_labels", "[", "item", "]", "==", "group", "]", "\n", "group_labels", "=", "[", "true_labels", "[", "item", "]", "for", "item", "in", "group_indices", "]", "\n", "group_preds", "=", "[", "pred_labels", "[", "item", "]", "for", "item", "in", "group_indices", "]", "\n", "\n", "g_tn", ",", "g_fp", ",", "g_fn", ",", "g_tp", "=", "metrics", ".", "confusion_matrix", "(", "\n", "y_true", "=", "group_labels", ",", "y_pred", "=", "group_preds", "\n", ")", ".", "ravel", "(", ")", "\n", "\n", "# calculate and accumulate the gaps", "\n", "scores", "[", "'fned'", "]", "=", "scores", "[", "'fned'", "]", "+", "abs", "(", "\n", "cal_fnr", "(", "fn", ",", "tp", ")", "-", "cal_fnr", "(", "g_fn", ",", "g_tp", ")", "\n", ")", "\n", "scores", "[", "'fped'", "]", "=", "scores", "[", "'fped'", "]", "+", "abs", "(", "\n", "cal_fpr", "(", "fp", ",", "tn", ")", "-", "cal_fpr", "(", "g_fp", ",", "g_tn", ")", "\n", ")", "\n", "scores", "[", "'tped'", "]", "=", "scores", "[", "'tped'", "]", "+", "abs", "(", "\n", "cal_tpr", "(", "tp", ",", "fn", ")", "-", "cal_tpr", "(", "g_tp", ",", "g_fn", ")", "\n", ")", "\n", "scores", "[", "'tned'", "]", "=", "scores", "[", "'tned'", "]", "+", "abs", "(", "\n", "cal_tnr", "(", "tn", ",", "fp", ")", "-", "cal_tnr", "(", "g_tn", ",", "g_fp", ")", "\n", ")", "\n", "", "return", "json", ".", "dumps", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.build_wt": [[176, 214], ["len", "emb_path.endswith", "numpy.save", "gensim.models.KeyedVectors.load_word2vec_format", "list", "zip", "open", "open.readline().strip().split", "len", "list", "open.close", "numpy.zeros", "len", "open.readline().strip().split", "numpy.zeros", "open", "numpy.asarray", "open.readline().strip", "line.strip().split.strip().split", "open.readline().strip", "numpy.asarray", "float", "open.readline", "line.strip().split.strip", "open.readline", "float"], "function", ["None"], ["", "def", "build_wt", "(", "tkn", ",", "emb_path", ",", "opath", ")", ":", "\n", "    ", "\"\"\"Build weight using word embedding\"\"\"", "\n", "embed_len", "=", "len", "(", "tkn", ".", "word_index", ")", "\n", "if", "embed_len", ">", "tkn", ".", "num_words", ":", "\n", "        ", "embed_len", "=", "tkn", ".", "num_words", "\n", "\n", "", "emb_size", "=", "200", "\n", "if", "emb_path", ".", "endswith", "(", "'.bin'", ")", ":", "\n", "        ", "embeds", "=", "gensim", ".", "models", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "\n", "emb_path", ",", "binary", "=", "True", ",", "unicode_errors", "=", "'ignore'", "\n", ")", "\n", "emb_size", "=", "embeds", ".", "vector_size", "\n", "emb_matrix", "=", "list", "(", "np", ".", "zeros", "(", "(", "embed_len", "+", "1", ",", "emb_size", ")", ")", ")", "\n", "for", "pair", "in", "zip", "(", "embeds", ".", "wv", ".", "index2word", ",", "embeds", ".", "wv", ".", "syn0", ")", ":", "\n", "            ", "if", "pair", "[", "0", "]", "in", "tkn", ".", "word_index", "and", "tkn", ".", "word_index", "[", "pair", "[", "0", "]", "]", "<", "tkn", ".", "num_words", ":", "\n", "                ", "emb_matrix", "[", "tkn", ".", "word_index", "[", "pair", "[", "0", "]", "]", "]", "=", "np", ".", "asarray", "(", "[", "\n", "float", "(", "item", ")", "for", "item", "in", "pair", "[", "1", "]", "\n", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "", "else", ":", "\n", "        ", "dfile", "=", "open", "(", "emb_path", ")", "\n", "line", "=", "dfile", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "line", ")", "<", "5", ":", "\n", "            ", "line", "=", "dfile", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "", "emb_size", "=", "len", "(", "line", "[", "1", ":", "]", ")", "\n", "emb_matrix", "=", "list", "(", "np", ".", "zeros", "(", "(", "embed_len", "+", "1", ",", "emb_size", ")", ")", ")", "\n", "dfile", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "emb_path", ")", "as", "dfile", ":", "\n", "            ", "for", "line", "in", "dfile", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "line", "[", "0", "]", "in", "tkn", ".", "word_index", "and", "tkn", ".", "word_index", "[", "line", "[", "0", "]", "]", "<", "tkn", ".", "num_words", ":", "\n", "                    ", "emb_matrix", "[", "tkn", ".", "word_index", "[", "line", "[", "0", "]", "]", "]", "=", "np", ".", "asarray", "(", "[", "\n", "float", "(", "item", ")", "for", "item", "in", "line", "[", "1", ":", "]", "\n", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "# emb_matrix = np.array(emb_matrix, dtype=np.float32)", "\n", "", "", "", "", "np", ".", "save", "(", "opath", ",", "emb_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.utils.build_tok": [[216, 227], ["os.path.exists", "pickle.load", "keras_preprocessing.text.Tokenizer", "keras_preprocessing.text.Tokenizer.fit_on_texts", "open", "open", "pickle.dump"], "function", ["None"], ["", "def", "build_tok", "(", "docs", ",", "max_feature", ",", "opath", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "opath", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "opath", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "# load corpus", "\n", "        ", "tkn", "=", "Tokenizer", "(", "num_words", "=", "max_feature", ")", "\n", "tkn", ".", "fit_on_texts", "(", "docs", ")", "\n", "\n", "with", "open", "(", "opath", ",", "'wb'", ")", "as", "wfile", ":", "\n", "            ", "pickle", ".", "dump", "(", "tkn", ",", "wfile", ")", "\n", "", "return", "tkn", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn.RegularRNN.__init__": [[20, 51], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "os.path.exists", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding", "torch.Embedding", "rnn.RegularRNN.wemb.reset_parameters", "torch.init.kaiming_uniform_", "torch.init.kaiming_uniform_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.load", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "RegularRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "\n", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "params", "[", "'max_feature'", "]", ",", "self", ".", "params", "[", "'emb_dim'", "]", "\n", ")", "\n", "self", ".", "wemb", ".", "reset_parameters", "(", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "wemb", ".", "weight", ",", "a", "=", "np", ".", "sqrt", "(", "5", ")", ")", "\n", "\n", "", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "\n", "# domain adaptation", "\n", "", "self", ".", "doc_net_general", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "wemb", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "# prediction", "\n", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "params", "[", "'emb_dim'", "]", ",", "self", ".", "params", "[", "'num_label'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn.RegularRNN.forward": [[52, 67], ["rnn.RegularRNN.wemb", "rnn.RegularRNN.doc_net_general", "rnn.RegularRNN.predictor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doc_general.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_docs", ")", ":", "\n", "# encode the document from different perspectives", "\n", "        ", "doc_embs", "=", "self", ".", "wemb", "(", "input_docs", ")", "\n", "_", ",", "doc_general", "=", "self", ".", "doc_net_general", "(", "doc_embs", ")", "# omit hidden vectors", "\n", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", "[", "0", ",", ":", ",", ":", "]", ",", "doc_general", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "# prediction", "\n", "", "doc_preds", "=", "self", ".", "predictor", "(", "doc_general", ")", "\n", "return", "doc_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn.build_model": [[69, 253], ["print", "utils.data_loader", "numpy.unique", "os.path.dirname", "os.path.join", "utils.build_tok", "utils.DataEncoder", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "rnn.RegularRNN", "rnn_model.to.to", "torch.CrossEntropyLoss().to", "torch.optim.RMSprop", "torch.optim.RMSprop", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "os.path.exists", "utils.build_wt", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "rnn_model.to.parameters", "range", "rnn_model.to.train", "enumerate", "rnn_model.to.eval", "sklearn.metrics.f1_score", "os.path.join", "range", "torch.CrossEntropyLoss", "tuple", "torch.optim.RMSprop.zero_grad", "rnn_model.to.", "nn.CrossEntropyLoss().to.", "criterion.item", "criterion.backward", "torch.optim.RMSprop.step", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "rnn_model.view", "input_labels.view", "print", "print", "print", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "sklearn.metrics.classification_report", "print", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "input_labels.to", "os.path.basename", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "utils.fair_eval", "rnn_model.detach", "input_labels.to", "input_domains.detach().cpu", "rnn_model.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "build_model", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "tok", "=", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "        ", "utils", ".", "build_wt", "(", "tok", ",", "params", "[", "'emb_path'", "]", ",", "params", "[", "'word_emb_path'", "]", ")", "\n", "", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "rnn_model", "=", "RegularRNN", "(", "params", ")", "\n", "rnn_model", "=", "rnn_model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "rnn_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "rnn_model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", "\n", "}", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "view", "(", "-", "1", ",", "params", "[", "'num_label'", "]", ")", ",", "input_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "rnn_model", ".", "eval", "(", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "rnn_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "report", "=", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", "\n", ")", "\n", "print", "(", "report", ")", "\n", "wfile", ".", "write", "(", "report", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.bert_blind.replace_words": [[17, 24], ["re.sub", "re.sub.split"], "function", ["None"], ["def", "replace_words", "(", "doc", ",", "replace", ")", ":", "\n", "# replace numbers", "\n", "    ", "doc", "=", "re", ".", "sub", "(", "'^[0-9]+'", ",", "'number'", ",", "doc", ")", "\n", "# replace words", "\n", "doc", "=", "[", "word", "if", "word", "not", "in", "replace", "else", "'identity'", "for", "word", "in", "doc", ".", "split", "(", ")", "]", "\n", "\n", "return", "' '", ".", "join", "(", "doc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.bert_blind.build_bert": [[26, 205], ["set", "utils.DataEncoder", "utils.data_loader", "numpy.unique", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "transformers.BertForSequenceClassification.from_pretrained", "bert_model.to.to", "torch.optim.Adam", "print", "print", "tqdm.tqdm", "open", "torch.cuda.is_available", "torch.device", "torch.device", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "bert_model.to.parameters", "range", "bert_model.to.train", "enumerate", "bert_model.to.eval", "sklearn.metrics.f1_score", "set.add", "bert_blind.replace_words", "bert_blind.replace_words", "bert_blind.replace_words", "range", "tuple", "torch.optim.Adam.zero_grad", "bert_model.to.", "loss.item", "loss.backward", "torch.optim.Adam.step", "tuple", "torch.sigmoid().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "len", "line.strip", "range", "len", "print", "print", "print", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "tuple", "torch.sigmoid().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "line.split", "len", "t.to", "t.to", "torch.sigmoid", "numpy.argmax", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "bert_model.logits.detach().cpu", "input_labels.to", "os.path.basename", "t.to", "torch.sigmoid", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "bert_model.logits.detach().cpu", "input_labels.to", "input_domains.detach().cpu", "bert_model.logits.detach", "bert_model.logits.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "def", "build_bert", "(", "params", ")", ":", "\n", "# load the replacement words", "\n", "    ", "replaces", "=", "set", "(", ")", "\n", "with", "open", "(", "'../resources/lexicons/replace_{}.txt'", ".", "format", "(", "params", "[", "'lang'", "]", ")", ")", "as", "dfile", ":", "\n", "        ", "for", "line", "in", "dfile", ":", "\n", "# only use unigram", "\n", "            ", "if", "len", "(", "line", ".", "split", "(", "' '", ")", ")", ">", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "replaces", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'bert'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "bert_model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "params", "[", "'bert_name'", "]", ")", "\n", "bert_model", "=", "bert_model", ".", "to", "(", "device", ")", "\n", "# param_optimizer = list(bert_model.named_parameters())", "\n", "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "bert_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "bert_model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "_", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ",", "labels", "=", "input_labels", ")", "\n", "loss", "=", "predictions", ".", "loss", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "bert_model", ".", "eval", "(", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "bert_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.bert.build_bert": [[16, 185], ["utils.DataEncoder", "utils.data_loader", "numpy.unique", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "transformers.BertForSequenceClassification.from_pretrained", "bert_model.to.to", "torch.optim.Adam", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.device", "torch.device", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "bert_model.to.parameters", "range", "bert_model.to.train", "enumerate", "bert_model.to.eval", "sklearn.metrics.f1_score", "range", "tuple", "torch.optim.Adam.zero_grad", "bert_model.to.", "loss.item", "loss.backward", "torch.optim.Adam.step", "tuple", "torch.sigmoid().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "range", "len", "print", "print", "print", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "tuple", "torch.sigmoid().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "t.to", "torch.sigmoid", "numpy.argmax", "torch.no_grad", "bert_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "bert_model.logits.detach().cpu", "input_labels.to", "os.path.basename", "t.to", "torch.sigmoid", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "bert_model.logits.detach().cpu", "input_labels.to", "input_domains.detach().cpu", "bert_model.logits.detach", "bert_model.logits.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["def", "build_bert", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'bert'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "bert_model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "params", "[", "'bert_name'", "]", ")", "\n", "bert_model", "=", "bert_model", ".", "to", "(", "device", ")", "\n", "# param_optimizer = list(bert_model.named_parameters())", "\n", "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "bert_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "bert_model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "_", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ",", "labels", "=", "input_labels", ")", "\n", "loss", "=", "predictions", ".", "loss", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "bert_model", ".", "eval", "(", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "bert_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "bert_model", "(", "**", "{", "\n", "'input_ids'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.DeepMojiModel.__init__": [[26, 73], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Tanh", "torch.Tanh", "torch.ReLU", "torch.ReLU", "torch.Tanh", "torch.Tanh", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "adversarial_rnn.DeepMojiModel.params.get", "os.path.exists", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding", "torch.Embedding", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "DeepMojiModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "emb_size", "=", "self", ".", "params", "[", "'max_feature'", "]", "\n", "self", ".", "hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "self", ".", "num_classes", "=", "self", ".", "params", "[", "'num_label'", "]", "\n", "if", "self", ".", "num_classes", "<=", "3", ":", "\n", "            ", "self", ".", "num_classes", "=", "1", "\n", "\n", "", "self", ".", "adv_level", "=", "self", ".", "params", "[", "'adv_level'", "]", "\n", "self", ".", "n_hidden", "=", "self", ".", "params", "[", "'n_hidden'", "]", "\n", "self", ".", "device", "=", "self", ".", "params", "[", "'device'", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "params", "[", "'dp_rate'", "]", ")", "\n", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "ReLU", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "AF", "=", "nn", ".", "Tanh", "(", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'AF'", ",", "\"\"", ")", "==", "\"relu\"", ":", "\n", "            ", "self", ".", "AF", "=", "self", ".", "ReLU", "\n", "\n", "# embedding layer, original implementation uses a linear layer to randomly initialize embeddings", "\n", "", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "# self.dense1 = nn.EmbeddingBag.from_pretrained(", "\n", "#     torch.FloatTensor(np.load(self.params['word_emb_path'], allow_pickle=True))", "\n", "# )", "\n", "            ", "self", ".", "dense1", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "# self.dense1 = nn.EmbeddingBag(", "\n", "#     self.emb_size, self.hidden_size", "\n", "# )", "\n", "            ", "self", ".", "dense1", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "emb_size", ",", "self", ".", "hidden_size", "\n", ")", "\n", "\n", "", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "", "self", ".", "dense2", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "dense1", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "# self.dense2 = [nn.Linear(self.dense1.embedding_dim, self.hidden_size).to(self.device) for _ in range(self.n_hidden)]", "\n", "self", ".", "dense3", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.DeepMojiModel.forward": [[74, 92], ["adversarial_rnn.DeepMojiModel.dense1", "adversarial_rnn.DeepMojiModel.dense2", "adversarial_rnn.DeepMojiModel.dense3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doc_general.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "out", "=", "self", ".", "dense1", "(", "inputs", ")", "\n", "#out = self.AF(out)", "\n", "#for hl in self.dense2:", "\n", "#    out = self.dropout(out)", "\n", "#    out = hl(out)", "\n", "#    out = self.tanh(out)", "\n", "# RNN-version", "\n", "_", ",", "doc_general", "=", "self", ".", "dense2", "(", "out", ")", "# omit hidden vectors", "\n", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", "[", "0", ",", ":", ",", ":", "]", ",", "doc_general", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "", "out", "=", "self", ".", "dense3", "(", "doc_general", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.DeepMojiModel.hidden": [[93, 115], ["adversarial_rnn.DeepMojiModel.dense1", "adversarial_rnn.DeepMojiModel.dense2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "adversarial_rnn.DeepMojiModel.squeeze", "adversarial_rnn.DeepMojiModel.dense3"], "methods", ["None"], ["", "def", "hidden", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "adv_level", "in", "{", "0", ",", "-", "1", ",", "-", "2", "}", "\n", "out", "=", "self", ".", "dense1", "(", "inputs", ")", "\n", "#out = self.AF(out)", "\n", "if", "self", ".", "adv_level", "==", "-", "2", ":", "\n", "            ", "return", "out", "\n", "", "else", ":", "\n", "#for hl in self.dense2:", "\n", "#    out = self.dropout(out)", "\n", "#    out = hl(out)", "\n", "#    out = self.tanh(out)", "\n", "            ", "_", ",", "out", "=", "self", ".", "dense2", "(", "out", ")", "# omit hidden vectors", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "                ", "out", "=", "torch", ".", "cat", "(", "(", "out", "[", "0", ",", ":", ",", ":", "]", ",", "out", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "", "if", "out", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                ", "out", "=", "out", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "", "if", "self", ".", "adv_level", "==", "-", "1", ":", "\n", "                ", "return", "out", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "dense3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.GradientReversalFunction.forward": [[127, 131], ["x.clone"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "lambda_", ")", ":", "\n", "        ", "ctx", ".", "lambda_", "=", "lambda_", "\n", "return", "x", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.GradientReversalFunction.backward": [[132, 138], ["grads.new_tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grads", ")", ":", "\n", "        ", "lambda_", "=", "ctx", ".", "lambda_", "\n", "lambda_", "=", "grads", ".", "new_tensor", "(", "lambda_", ")", "\n", "dx", "=", "-", "lambda_", "*", "grads", "\n", "return", "dx", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.GradientReversal.__init__": [[141, 144], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lambda_", ")", ":", "\n", "        ", "super", "(", "GradientReversal", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.GradientReversal.forward": [[145, 147], ["GradientReversalFunction.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "GradientReversalFunction", ".", "apply", "(", "x", ",", "self", ".", "lambda_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.Discriminator.__init__": [[150, 169], ["torch.Module.__init__", "adversarial_rnn.GradientReversal", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "GR", "=", "False", "\n", "self", ".", "grad_rev", "=", "GradientReversal", "(", "params", "[", "'LAMBDA'", "]", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "params", "[", "'emb_dim'", "]", ",", "params", "[", "'adv_units'", "]", ")", "\n", "#if 'word_emb_path' in params and os.path.exists(params['word_emb_path']):", "\n", "#    emb_dim = np.load(params['word_emb_path'], allow_pickle=True)", "\n", "#    emb_dim = emb_dim.shape[1]", "\n", "#    self.fc1 = nn.Linear(emb_dim, params['adv_units'])", "\n", "#else:", "\n", "#    self.fc1 = nn.Linear(params['emb_dim'], params['adv_units'])", "\n", "\n", "self", ".", "LeakyReLU", "=", "nn", ".", "LeakyReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "params", "[", "'adv_units'", "]", ")", "\n", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", ">", "2", ":", "\n", "            ", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "len", "(", "params", "[", "'unique_domains'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.Discriminator.forward": [[170, 178], ["adversarial_rnn.Discriminator.fc1", "adversarial_rnn.Discriminator.LeakyReLU", "adversarial_rnn.Discriminator.fc2", "adversarial_rnn.Discriminator.fc3", "adversarial_rnn.Discriminator.grad_rev"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "GR", ":", "\n", "            ", "inputs", "=", "self", ".", "grad_rev", "(", "inputs", ")", "\n", "", "out", "=", "self", ".", "fc1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "out", "=", "self", ".", "fc3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.Discriminator.hidden_representation": [[179, 188], ["adversarial_rnn.Discriminator.fc1", "adversarial_rnn.Discriminator.LeakyReLU", "adversarial_rnn.Discriminator.fc2", "adversarial_rnn.Discriminator.grad_rev"], "methods", ["None"], ["", "def", "hidden_representation", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "GR", ":", "\n", "            ", "inputs", "=", "self", ".", "grad_rev", "(", "inputs", ")", "\n", "", "out", "=", "self", ".", "fc1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "# out = self.fc3(out)", "\n", "# Return the hidden representation from the second last layer", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.Discriminator.change_gradient_eversal": [[189, 191], ["None"], "methods", ["None"], ["", "def", "change_gradient_eversal", "(", "self", ",", "State", "=", "True", ")", ":", "\n", "        ", "self", ".", "GR", "=", "State", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.Discriminator.get_weights": [[192, 198], ["dense_parameter[].detach().cpu().numpy", "adversarial_rnn.Discriminator.fc3.named_parameters", "dense_parameter[].detach().cpu", "dense_parameter[].detach"], "methods", ["None"], ["", "def", "get_weights", "(", "self", ")", ":", "\n", "# return coef as numpy array", "\n", "        ", "dense_parameter", "=", "{", "name", ":", "param", "for", "name", ",", "param", "in", "self", ".", "fc3", ".", "named_parameters", "(", ")", "}", "\n", "# get coef and covert to numpy", "\n", "# return dense_parameter[\"weight\"].cpu().numpy()", "\n", "return", "dense_parameter", "[", "\"weight\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial_rnn.build_base": [[200, 434], ["utils.data_loader", "numpy.unique", "os.path.dirname", "os.path.join", "utils.build_tok", "utils.DataEncoder", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "adversarial_rnn.DeepMojiModel", "base_model.to.to", "adversarial_rnn.Discriminator", "discriminator.to.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "base_model.to.parameters", "filter", "torch.CrossEntropyLoss().to", "torch.BCEWithLogitsLoss().to", "range", "base_model.to.train", "discriminator.to.train", "enumerate", "range", "base_model.to.eval", "discriminator.to.eval", "torch.optim.lr_scheduler.ReduceLROnPlateau.step", "sklearn.metrics.f1_score", "os.path.join", "range", "discriminator.to.parameters", "tuple", "torch.optim.Adam.zero_grad", "torch.optim.Adam.zero_grad", "base_model.to.", "nn.BCEWithLogitsLoss().to.", "criterion.item", "base_model.to.hidden", "discriminator.to.", "nn.BCEWithLogitsLoss().to.", "criterion.backward", "torch.optim.Adam.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "tuple", "nn.BCEWithLogitsLoss().to.", "criterion.item", "torch.sigmoid", "torch.sigmoid", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "torch.CrossEntropyLoss", "torch.BCEWithLogitsLoss", "input_labels.float.float", "len", "input_domains.float.float", "base_model.squeeze", "discriminator.squeeze", "print", "print", "print", "discriminator.to.parameters", "torch.optim.Adam.zero_grad", "tuple", "base_model.to.hidden", "discriminator.to.", "nn.BCEWithLogitsLoss().to.", "criterion.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "torch.no_grad", "torch.no_grad", "base_model.to.", "input_labels.float.float", "base_model.squeeze", "base_model.detach().cpu", "numpy.argmax().flatten", "input_labels.float.to().numpy", "len", "tuple", "torch.sigmoid", "torch.sigmoid", "y_preds.extend", "y_trues.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "input_labels.float.float", "len", "input_domains.float.float", "discriminator.squeeze", "discriminator.to.parameters", "t.to", "torch.no_grad", "torch.no_grad", "base_model.to.", "base_model.squeeze().detach().cpu", "numpy.argmax().flatten", "input_labels.float.to().numpy", "y_probs.extend", "y_probs.extend", "input_domains.float.detach().cpu().numpy", "t.to", "base_model.detach", "numpy.argmax", "input_labels.float.to", "os.path.basename", "t.to", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "torch.sigmoid.numpy", "base_model.squeeze().detach", "numpy.argmax", "input_labels.float.to", "input_domains.float.detach().cpu", "torch.sigmoid.numpy", "base_model.squeeze", "input_domains.float.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.hidden", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.hidden", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "build_base", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "\n", "# if not os.path.exists(params['word_emb_path']):", "\n", "#     utils.build_wt(tok, params['emb_path'], params['word_emb_path'])", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "base_model", "=", "DeepMojiModel", "(", "params", ")", "\n", "base_model", "=", "base_model", ".", "to", "(", "device", ")", "\n", "discriminator", "=", "Discriminator", "(", "params", ")", "\n", "discriminator", "=", "discriminator", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "base_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "adv_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "filter", "(", "\n", "lambda", "p", ":", "p", ".", "requires_grad", ",", "discriminator", ".", "parameters", "(", ")", ")", ",", "lr", "=", "1e-1", "*", "params", "[", "'lr'", "]", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'max'", ",", "factor", "=", "0.5", ",", "patience", "=", "2", ")", "\n", "if", "params", "[", "'num_label'", "]", ">", "2", ":", "\n", "        ", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# train the networks", "\n", "", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "base_model", ".", "train", "(", ")", "\n", "discriminator", ".", "train", "(", ")", "\n", "discriminator", ".", "GR", "=", "True", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", "<", "3", ":", "\n", "                ", "input_domains", "=", "input_domains", ".", "float", "(", ")", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "adv_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "squeeze", "(", ")", ",", "input_labels", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "hs", "=", "base_model", ".", "hidden", "(", "input_docs", ")", "\n", "adv_predictions", "=", "discriminator", "(", "hs", ")", "\n", "loss", "+=", "criterion", "(", "adv_predictions", ".", "squeeze", "(", ")", ",", "input_domains", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "discriminator", ".", "parameters", "(", ")", ",", "params", "[", "'clipping_value'", "]", ")", "\n", "adv_optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "discriminator", ".", "GR", "=", "False", "\n", "# converge the discriminator first", "\n", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "            ", "for", "valid_batch", "in", "train_data_loader", ":", "\n", "                ", "adv_optimizer", ".", "zero_grad", "(", ")", "\n", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", "<", "3", ":", "\n", "                    ", "input_domains", "=", "input_domains", ".", "float", "(", ")", "\n", "", "hs", "=", "base_model", ".", "hidden", "(", "input_docs", ")", "\n", "adv_predictions", "=", "discriminator", "(", "hs", ")", "\n", "adv_loss_item", "=", "criterion", "(", "adv_predictions", ".", "squeeze", "(", ")", ",", "input_domains", ")", "\n", "adv_loss_item", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "discriminator", ".", "parameters", "(", ")", ",", "params", "[", "'clipping_value'", "]", ")", "\n", "adv_optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "base_model", ".", "eval", "(", ")", "\n", "discriminator", ".", "eval", "(", ")", "\n", "valid_loss", "=", "0.0", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "valid_loss_batch", "=", "criterion", "(", "predictions", ".", "squeeze", "(", ")", ",", "input_labels", ")", "\n", "valid_loss", "+=", "valid_loss_batch", ".", "item", "(", ")", "\n", "\n", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "pred_flat", "=", "(", "logits", ">", "0.5", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "", "scheduler", ".", "step", "(", "valid_loss", "/", "len", "(", "valid_data_loader", ")", ")", "\n", "\n", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'macro'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "base_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "pred_flat", "=", "(", "logits", ">", "0.5", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "y_probs", ".", "extend", "(", "[", "item", "for", "item", "in", "logits", "]", ")", "\n", "", "else", ":", "\n", "                    ", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn_blind.RegularRNN.__init__": [[30, 61], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "os.path.exists", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding", "torch.Embedding", "rnn_blind.RegularRNN.wemb.reset_parameters", "torch.init.kaiming_uniform_", "torch.init.kaiming_uniform_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.load", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "RegularRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "\n", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "params", "[", "'max_feature'", "]", ",", "self", ".", "params", "[", "'emb_dim'", "]", "\n", ")", "\n", "self", ".", "wemb", ".", "reset_parameters", "(", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "wemb", ".", "weight", ",", "a", "=", "np", ".", "sqrt", "(", "5", ")", ")", "\n", "\n", "", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "\n", "# domain adaptation", "\n", "", "self", ".", "doc_net_general", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "wemb", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "# prediction", "\n", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "params", "[", "'emb_dim'", "]", ",", "self", ".", "params", "[", "'num_label'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn_blind.RegularRNN.forward": [[62, 77], ["rnn_blind.RegularRNN.wemb", "rnn_blind.RegularRNN.doc_net_general", "rnn_blind.RegularRNN.predictor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doc_general.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_docs", ")", ":", "\n", "# encode the document from different perspectives", "\n", "        ", "doc_embs", "=", "self", ".", "wemb", "(", "input_docs", ")", "\n", "_", ",", "doc_general", "=", "self", ".", "doc_net_general", "(", "doc_embs", ")", "# omit hidden vectors", "\n", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", "[", "0", ",", ":", ",", ":", "]", ",", "doc_general", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "# prediction", "\n", "", "doc_preds", "=", "self", ".", "predictor", "(", "doc_general", ")", "\n", "return", "doc_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn_blind.replace_words": [[20, 27], ["re.sub", "re.sub.split"], "function", ["None"], ["def", "replace_words", "(", "doc", ",", "replace", ")", ":", "\n", "# replace numbers", "\n", "    ", "doc", "=", "re", ".", "sub", "(", "'^[0-9]+'", ",", "'number'", ",", "doc", ")", "\n", "# replace words", "\n", "doc", "=", "[", "word", "if", "word", "not", "in", "replace", "else", "'identity'", "for", "word", "in", "doc", ".", "split", "(", ")", "]", "\n", "\n", "return", "' '", ".", "join", "(", "doc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.rnn_blind.build_rnn_blind": [[79, 273], ["print", "utils.data_loader", "numpy.unique", "os.path.dirname", "os.path.join", "utils.build_tok", "utils.DataEncoder", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "rnn_blind.RegularRNN", "rnn_model.to.to", "torch.CrossEntropyLoss().to", "torch.optim.RMSprop", "torch.optim.RMSprop", "print", "print", "tqdm.tqdm", "open", "set", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "os.path.exists", "utils.build_wt", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "rnn_model.to.parameters", "range", "rnn_model.to.train", "enumerate", "rnn_model.to.eval", "sklearn.metrics.f1_score", "set.add", "os.path.join", "rnn_blind.replace_words", "rnn_blind.replace_words", "rnn_blind.replace_words", "range", "torch.CrossEntropyLoss", "tuple", "torch.optim.RMSprop.zero_grad", "rnn_model.to.", "nn.CrossEntropyLoss().to.", "criterion.item", "criterion.backward", "torch.optim.RMSprop.step", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "len", "line.strip", "range", "len", "rnn_model.view", "input_labels.view", "print", "print", "print", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "sklearn.metrics.classification_report", "print", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "line.split", "len", "t.to", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "input_labels.to", "os.path.basename", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "utils.fair_eval", "rnn_model.detach", "input_labels.to", "input_domains.detach().cpu", "rnn_model.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "build_rnn_blind", "(", "params", ")", ":", "\n", "# load the replacement words", "\n", "    ", "with", "open", "(", "'../resources/lexicons/replace_{}.txt'", ".", "format", "(", "params", "[", "'lang'", "]", ")", ")", "as", "dfile", ":", "\n", "        ", "replaces", "=", "set", "(", ")", "\n", "for", "line", "in", "dfile", ":", "\n", "# only use unigram", "\n", "            ", "if", "len", "(", "line", ".", "split", "(", "' '", ")", ")", ">", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "replaces", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "tok", "=", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "        ", "utils", ".", "build_wt", "(", "tok", ",", "params", "[", "'emb_path'", "]", ",", "params", "[", "'word_emb_path'", "]", ")", "\n", "", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "rnn_model", "=", "RegularRNN", "(", "params", ")", "\n", "rnn_model", "=", "rnn_model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "rnn_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "rnn_model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", "\n", "}", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "view", "(", "-", "1", ",", "params", "[", "'num_label'", "]", ")", ",", "input_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "rnn_model", ".", "eval", "(", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "rnn_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "report", "=", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", "\n", ")", "\n", "print", "(", "report", ")", "\n", "wfile", ".", "write", "(", "report", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.data_gen": [[35, 69], ["int", "range", "list", "numpy.random.shuffle", "range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "range", "len", "len", "np.asarray.append", "np.asarray.append", "len", "numpy.asarray", "np.asarray.append", "len"], "function", ["None"], ["def", "data_gen", "(", "docs", ",", "labels", ",", "weights", "=", "None", ",", "batch_size", "=", "64", ")", ":", "\n", "    ", "\"\"\"\n        Batch generator\n    \"\"\"", "\n", "if", "weights", "is", "not", "None", ":", "\n", "        ", "data_indices", "=", "list", "(", "range", "(", "len", "(", "docs", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "data_indices", ")", "# random shuffle the training documents", "\n", "docs", "=", "[", "docs", "[", "idx", "]", "for", "idx", "in", "data_indices", "]", "\n", "labels", "=", "[", "labels", "[", "idx", "]", "for", "idx", "in", "data_indices", "]", "\n", "weights", "=", "[", "weights", "[", "idx", "]", "for", "idx", "in", "data_indices", "]", "\n", "\n", "", "steps", "=", "int", "(", "len", "(", "docs", ")", "/", "batch_size", ")", "\n", "if", "len", "(", "docs", ")", "%", "batch_size", "!=", "0", ":", "\n", "        ", "steps", "+=", "1", "\n", "\n", "", "for", "step", "in", "range", "(", "steps", ")", ":", "\n", "        ", "batch_docs", "=", "[", "]", "\n", "batch_labels", "=", "[", "]", "\n", "batch_weights", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "step", "*", "batch_size", ",", "(", "step", "+", "1", ")", "*", "batch_size", ")", ":", "\n", "            ", "if", "idx", ">", "len", "(", "docs", ")", "-", "1", ":", "\n", "                ", "break", "\n", "", "batch_docs", ".", "append", "(", "np", ".", "asarray", "(", "docs", "[", "idx", "]", ")", ")", "\n", "batch_labels", ".", "append", "(", "labels", "[", "idx", "]", ")", "\n", "if", "weights", "is", "not", "None", ":", "\n", "                ", "batch_weights", ".", "append", "(", "weights", "[", "idx", "]", ")", "\n", "\n", "# convert to array", "\n", "", "", "batch_docs", "=", "np", ".", "asarray", "(", "batch_docs", ")", "\n", "batch_labels", "=", "np", ".", "asarray", "(", "batch_labels", ")", "\n", "batch_weights", "=", "np", ".", "asarray", "(", "batch_weights", ")", "\n", "\n", "yield", "batch_docs", ",", "batch_labels", ",", "batch_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.get_model": [[71, 108], ["keras.layers.Input", "keras.layers.Embedding", "keras.layers.Embedding.", "range", "range", "keras.models.Model", "keras.models.Model.compile", "keras.layers.Bidirectional", "keras.layers.Bidirectional.", "keras.layers.Dropout", "rnn_cell", "keras.layers.Dense", "keras.layers.BatchNormalization", "keras.layers.Dense", "keras.layers.Dense", "keras.optimizers.RMSprop"], "function", ["None"], ["", "", "def", "get_model", "(", "embedding", ",", "\n", "num_lstm", "=", "1", ",", "\n", "num_hidden", "=", "1", ",", "\n", "dim_hidden", "=", "128", ",", "\n", "num_classes", "=", "2", ",", "\n", "max_seq_len", "=", "35", ",", "\n", "dropout_rate", "=", "0.5", ",", "\n", "lr", "=", "1e-3", ",", "\n", "clipping", "=", "0.5", ")", ":", "\n", "    ", "model_in", "=", "Input", "(", "shape", "=", "(", "max_seq_len", ",", ")", ",", "dtype", "=", "'int32'", ")", "\n", "embedding_layer", "=", "Embedding", "(", "embedding", ".", "shape", "[", "0", "]", ",", "\n", "embedding", ".", "shape", "[", "1", "]", ",", "\n", "mask_zero", "=", "False", ",", "\n", "weights", "=", "[", "embedding", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "input_length", "=", "max_seq_len", ")", "\n", "hidden", "=", "embedding_layer", "(", "model_in", ")", "\n", "\n", "for", "j", "in", "range", "(", "num_lstm", ")", ":", "\n", "        ", "rnn_cell", "=", "LSTM", "\n", "lstm_layer", "=", "Bidirectional", "(", "rnn_cell", "(", "dim_hidden", ",", "return_sequences", "=", "(", "j", "!=", "num_lstm", "-", "1", ")", ")", ")", "\n", "hidden", "=", "lstm_layer", "(", "hidden", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "num_hidden", ")", ":", "\n", "        ", "hidden", "=", "Dense", "(", "dim_hidden", ",", "activation", "=", "'relu'", ")", "(", "hidden", ")", "\n", "hidden", "=", "BatchNormalization", "(", ")", "(", "hidden", ")", "\n", "", "hidden", "=", "Dropout", "(", "dropout_rate", ")", "(", "hidden", ")", "\n", "\n", "if", "num_classes", "<", "3", ":", "\n", "        ", "model_out", "=", "Dense", "(", "1", ",", "activation", "=", "'softmax'", ")", "(", "hidden", ")", "\n", "", "else", ":", "\n", "        ", "model_out", "=", "Dense", "(", "num_classes", ",", "activation", "=", "'softmax'", ")", "(", "hidden", ")", "\n", "\n", "", "ret_model", "=", "Model", "(", "model_in", ",", "model_out", ")", "\n", "ret_model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "optimizer", "=", "RMSprop", "(", "lr", "=", "lr", ",", "clipnorm", "=", "clipping", ")", ")", "\n", "\n", "return", "ret_model", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.get_tfidf": [[110, 128], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "range", "range", "len", "len", "range", "len", "numpy.log", "len", "range", "len", "len", "len", "len", "len", "sum", "tf[].sum", "idxs_sens.append", "len", "len", "docs[].split"], "function", ["None"], ["", "def", "get_tfidf", "(", "docs", ",", "sensitive_words", ")", ":", "\n", "    ", "tf", "=", "np", ".", "zeros", "(", "[", "len", "(", "docs", ")", ",", "len", "(", "sensitive_words", ")", "]", ")", "\n", "idf", "=", "np", ".", "zeros", "(", "len", "(", "sensitive_words", ")", ")", "\n", "tfidf", "=", "np", ".", "zeros", "(", "[", "len", "(", "docs", ")", ",", "len", "(", "sensitive_words", ")", "]", ")", "\n", "idxs_sens", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "docs", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "sensitive_words", ")", ")", ":", "\n", "            ", "tf", "[", "i", ",", "j", "]", "=", "sum", "(", "[", "(", "1", "if", "word", "==", "sensitive_words", "[", "j", "]", "else", "0", ")", "for", "word", "in", "docs", "[", "i", "]", ".", "split", "(", ")", "]", ")", "\n", "if", "tf", "[", "i", ",", "j", "]", ">", "0", ":", "\n", "                ", "idf", "[", "j", "]", "+=", "1", "\n", "", "", "if", "tf", "[", "i", "]", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "idxs_sens", ".", "append", "(", "i", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "sensitive_words", ")", ")", ":", "\n", "        ", "idf", "[", "i", "]", "=", "np", ".", "log", "(", "len", "(", "idxs_sens", ")", "/", "(", "idf", "[", "i", "]", "+", "1", ")", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "docs", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "sensitive_words", ")", ")", ":", "\n", "            ", "tfidf", "[", "i", ",", "j", "]", "=", "tf", "[", "i", ",", "j", "]", "*", "idf", "[", "j", "]", "\n", "", "", "return", "tfidf", ",", "idxs_sens", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.make_weights": [[130, 185], ["list", "list", "utils.data_loader", "numpy.unique", "utils.data_split", "instant_weight.get_tfidf", "sklearn.ensemble.RandomForestClassifier", "sklearn.model_selection.cross_val_predict", "print", "print", "numpy.array", "numpy.array", "numpy.save", "numpy.asarray", "numpy.mean", "numpy.mean", "numpy.array", "np.array.mean", "numpy.zeros", "numpy.save", "open", "set", "numpy.asarray", "sum", "len", "sklearn.metrics.roc_auc_score", "sklearn.metrics.accuracy_score", "max", "sum", "len", "numpy.array", "numpy.array", "len", "list.append", "keras.utils.to_categorical", "numpy.argmax", "line.strip().lower", "range", "range", "range", "len", "len", "range", "range", "len", "line.strip", "len", "len"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.get_tfidf"], ["", "def", "make_weights", "(", "params", ")", ":", "\n", "    ", "sensitive_words", "=", "list", "(", ")", "\n", "with", "open", "(", "'../resources/lexicons/replace_{}.txt'", ".", "format", "(", "params", "[", "'lang'", "]", ")", ")", "as", "dfile", ":", "\n", "        ", "for", "line", "in", "dfile", ":", "\n", "            ", "sensitive_words", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ")", "\n", "", "", "sensitive_words", "=", "list", "(", "set", "(", "sensitive_words", ")", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "+", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "+", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "+", "val_indices", "]", ",", "\n", "}", "\n", "\n", "sensitive_z", ",", "idxs_sens", "=", "get_tfidf", "(", "train_data", "[", "'docs'", "]", ",", "sensitive_words", ")", "\n", "sensitive_labels", "=", "np", ".", "asarray", "(", "train_data", "[", "'labels'", "]", ")", "[", "idxs_sens", "]", "\n", "# obtaining the weights", "\n", "clf", "=", "RandomForestClassifier", "(", "\n", "n_estimators", "=", "1000", ",", "class_weight", "=", "'balanced'", ",", "max_depth", "=", "27", ",", "random_state", "=", "233", ",", "n_jobs", "=", "-", "1", ",", "criterion", "=", "'entropy'", ")", "\n", "y_pred", "=", "cross_val_predict", "(", "\n", "clf", ",", "sensitive_z", "[", "idxs_sens", "]", ",", "sensitive_labels", ",", "\n", "cv", "=", "5", ",", "n_jobs", "=", "-", "1", ",", "method", "=", "'predict_proba'", "\n", ")", "\n", "# print('Refit log loss: %.5f' % (log_loss(sensitive_z[idxs_sens], y_pred[:, 1])))", "\n", "\n", "p1", "=", "sum", "(", "sensitive_labels", ")", "/", "len", "(", "sensitive_labels", ")", "\n", "p0", "=", "1", "-", "p1", "\n", "print", "(", "roc_auc_score", "(", "to_categorical", "(", "sensitive_labels", ")", ",", "y_pred", ")", ")", "\n", "print", "(", "accuracy_score", "(", "sensitive_labels", ",", "np", ".", "argmax", "(", "y_pred", ",", "1", ")", ")", ",", "max", "(", "p0", ",", "p1", ")", ")", "\n", "\n", "p1", "=", "sum", "(", "train_data", "[", "'labels'", "]", ")", "/", "len", "(", "train_data", "[", "'labels'", "]", ")", "\n", "p0", "=", "1", "-", "p1", "\n", "propensity", "=", "np", ".", "array", "(", "[", "\n", "(", "p1", "if", "train_data", "[", "'labels'", "]", "[", "i", "]", "==", "1", "else", "p0", ")", "for", "i", "in", "range", "(", "len", "(", "train_data", "[", "'labels'", "]", ")", ")", "]", ")", "\n", "propensity", "[", "idxs_sens", "]", "=", "np", ".", "array", "(", "[", "\n", "y_pred", "[", "i", ",", "train_data", "[", "'labels'", "]", "[", "idxs_sens", "[", "i", "]", "]", "]", "for", "i", "in", "range", "(", "len", "(", "idxs_sens", ")", ")", "]", ")", "\n", "# normalize the propensity", "\n", "# propensity = np.asanyarray([item if item != 0 else 1. for item in propensity])", "\n", "np", ".", "save", "(", "params", "[", "'model_dir'", "]", "+", "\"propensity_%s.npy\"", "%", "params", "[", "'dname'", "]", ",", "propensity", ")", "\n", "# propensity = np.load(dir_processed + \"propensity_%s.npy\" % name_dataset)", "\n", "\n", "weights", "=", "np", ".", "asarray", "(", "[", "1", "/", "item", "if", "item", ">", "0", "else", "0", "for", "item", "in", "propensity", "]", ")", "\n", "a", "=", "np", ".", "mean", "(", "\n", "np", ".", "array", "(", "[", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "weights", ")", ")", "if", "train_data", "[", "'labels'", "]", "[", "i", "]", "==", "0", "]", ")", ")", "\n", "b", "=", "np", ".", "mean", "(", "\n", "np", ".", "array", "(", "[", "weights", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "weights", ")", ")", "if", "train_data", "[", "'labels'", "]", "[", "i", "]", "==", "1", "]", ")", ")", "\n", "weights", "=", "np", ".", "array", "(", "[", "\n", "(", "weights", "[", "i", "]", "/", "a", "if", "train_data", "[", "'labels'", "]", "[", "i", "]", "==", "0", "else", "weights", "[", "i", "]", "/", "b", ")", "for", "i", "in", "range", "(", "len", "(", "weights", ")", ")", "]", ")", "\n", "weights", "/=", "weights", ".", "mean", "(", ")", "\n", "\n", "ret", "=", "np", ".", "zeros", "(", "len", "(", "data", "[", "'docs'", "]", ")", ")", "\n", "ret", "[", "train_indices", "+", "val_indices", "]", "=", "weights", "\n", "np", ".", "save", "(", "params", "[", "'model_dir'", "]", "+", "\"weights_{}.npy\"", ".", "format", "(", "params", "[", "'dname'", "]", ")", ",", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.build_weight": [[187, 339], ["print", "utils.data_loader", "numpy.load", "os.path.dirname", "os.path.join", "utils.build_tok", "keras_preprocessing.sequence.pad_sequences", "utils.data_split", "instant_weight.get_model", "sklearn.utils.class_weight.compute_class_weight", "dict", "tqdm.tqdm", "os.path.exists", "utils.build_wt", "numpy.load", "utils.build_tok.texts_to_sequences", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "numpy.exp", "enumerate", "range", "instant_weight.data_gen", "instant_weight.data_gen", "sklearn.metrics.f1_score", "os.path.join", "range", "numpy.unique", "get_model.train_on_batch", "numpy.asarray", "get_model.predict", "instant_weight.data_gen", "range", "len", "sum", "y_preds_dev.append", "y_devs.append", "numpy.asarray", "get_model.predict", "print", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "sklearn.metrics.classification_report", "print", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "numpy.round", "int", "y_probs.append", "y_preds.append", "y_trues.append", "numpy.round", "int", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "utils.fair_eval"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.get_model", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.data_gen", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.data_gen", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_weight.data_gen", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "def", "build_weight", "(", "params", ")", ":", "\n", "    ", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "debias_weights", "=", "np", ".", "load", "(", "params", "[", "'model_dir'", "]", "+", "\"weights_{}.npy\"", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "tok", "=", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "        ", "emb", "=", "utils", ".", "build_wt", "(", "tok", ",", "params", "[", "'emb_path'", "]", ",", "params", "[", "'word_emb_path'", "]", ")", "\n", "", "else", ":", "\n", "        ", "emb", "=", "np", ".", "load", "(", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "# tokenization and fill", "\n", "", "data", "[", "'docs'", "]", "=", "pad_sequences", "(", "tok", ".", "texts_to_sequences", "(", "data", "[", "'docs'", "]", ")", ",", "maxlen", "=", "params", "[", "'max_len'", "]", ")", "\n", "\n", "# split", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "debias_weights", "=", "debias_weights", "[", "train_indices", "]", "\n", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "debias_weights", "=", "debias_weights", "[", "sample_indices", "]", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "debias_weights", "=", "debias_weights", "[", "indices", "]", "\n", "\n", "# train", "\n", "", "model", "=", "get_model", "(", "\n", "emb", ",", "num_lstm", "=", "1", ",", "max_seq_len", "=", "params", "[", "'max_len'", "]", ",", "\n", "dim_hidden", "=", "params", "[", "'emb_dim'", "]", ",", "num_classes", "=", "params", "[", "'num_label'", "]", ",", "\n", "dropout_rate", "=", "params", "[", "'dp_rate'", "]", ",", "lr", "=", "params", "[", "'lr'", "]", ",", "clipping", "=", "0.5", "\n", ")", "\n", "best_valid", "=", "0.0", "\n", "cl_weights", "=", "class_weight", ".", "compute_class_weight", "(", "\n", "class_weight", "=", "'balanced'", ",", "classes", "=", "np", ".", "unique", "(", "train_data", "[", "'labels'", "]", ")", ",", "\n", "y", "=", "train_data", "[", "'labels'", "]", "\n", ")", "\n", "cl_weights", "=", "[", "np", ".", "exp", "(", "item", "/", "sum", "(", "cl_weights", ")", ")", "for", "item", "in", "cl_weights", "]", "\n", "cl_weights", "=", "dict", "(", "enumerate", "(", "cl_weights", ")", ")", "\n", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_iter", "=", "data_gen", "(", "train_data", "[", "'docs'", "]", ",", "train_data", "[", "'labels'", "]", ",", "debias_weights", ",", "params", "[", "'batch_size'", "]", ")", "\n", "\n", "for", "x_train", ",", "y_labels", ",", "x_weights", "in", "train_iter", ":", "\n", "            ", "model", ".", "train_on_batch", "(", "\n", "x", "=", "x_train", ",", "y", "=", "y_labels", ",", "#sample_weight=x_weights,", "\n", "#class_weight=cl_weights", "\n", "class_weight", "=", "{", "1", ":", "1", ",", "0", ":", "3", "}", "\n", ")", "\n", "\n", "# valid", "\n", "", "y_preds_dev", "=", "[", "]", "\n", "y_devs", "=", "[", "]", "\n", "dev_iter", "=", "data_gen", "(", "valid_data", "[", "'docs'", "]", ",", "valid_data", "[", "'labels'", "]", ",", "None", ",", "params", "[", "'batch_size'", "]", ")", "\n", "for", "x_dev", ",", "y_dev", ",", "_", "in", "dev_iter", ":", "\n", "            ", "x_dev", "=", "np", ".", "asarray", "(", "x_dev", ")", "\n", "tmp_preds", "=", "model", ".", "predict", "(", "x_dev", ")", "\n", "for", "item_tmp", "in", "tmp_preds", ":", "\n", "                ", "y_preds_dev", ".", "append", "(", "np", ".", "round", "(", "item_tmp", "[", "0", "]", ")", ")", "\n", "", "for", "item_tmp", "in", "y_dev", ":", "\n", "                ", "y_devs", ".", "append", "(", "int", "(", "item_tmp", ")", ")", "\n", "\n", "# test", "\n", "", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds_dev", ",", "y_true", "=", "y_devs", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_valid", ":", "\n", "            ", "best_valid", "=", "eval_score", "\n", "test_iter", "=", "data_gen", "(", "test_data", "[", "'docs'", "]", ",", "test_data", "[", "'labels'", "]", ",", "None", ",", "params", "[", "'batch_size'", "]", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "x_test", ",", "y_test", ",", "_", "in", "test_iter", ":", "\n", "                ", "x_test", "=", "np", ".", "asarray", "(", "x_test", ")", "\n", "tmp_preds", "=", "model", ".", "predict", "(", "x_test", ")", "\n", "print", "(", "tmp_preds", ")", "\n", "for", "item_tmp", "in", "tmp_preds", ":", "\n", "                    ", "y_probs", ".", "append", "(", "item_tmp", "[", "0", "]", ")", "\n", "y_preds", ".", "append", "(", "np", ".", "round", "(", "item_tmp", "[", "0", "]", ")", ")", "\n", "", "for", "item_tmp", "in", "y_test", ":", "\n", "                    ", "y_trues", ".", "append", "(", "int", "(", "item_tmp", ")", ")", "\n", "\n", "", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "report", "=", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", "\n", ")", "\n", "print", "(", "report", ")", "\n", "wfile", ".", "write", "(", "report", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "test_data", "[", "params", "[", "'domain_name'", "]", "]", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.__init__": [[26, 58], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Tanh", "torch.Tanh", "torch.ReLU", "torch.ReLU", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "adversarial.DeepMojiModel.params.get", "os.path.exists", "torch.EmbeddingBag.from_pretrained", "torch.EmbeddingBag.from_pretrained", "torch.EmbeddingBag", "torch.EmbeddingBag", "torch.Linear().to", "torch.Linear().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "numpy.load", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "DeepMojiModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "emb_size", "=", "self", ".", "params", "[", "'max_feature'", "]", "\n", "self", ".", "hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "self", ".", "num_classes", "=", "self", ".", "params", "[", "'num_label'", "]", "\n", "if", "self", ".", "num_classes", "<=", "3", ":", "\n", "            ", "self", ".", "num_classes", "=", "1", "\n", "\n", "", "self", ".", "adv_level", "=", "self", ".", "params", "[", "'adv_level'", "]", "\n", "self", ".", "n_hidden", "=", "self", ".", "params", "[", "'n_hidden'", "]", "\n", "self", ".", "device", "=", "self", ".", "params", "[", "'device'", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "params", "[", "'dp_rate'", "]", ")", "\n", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "ReLU", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "AF", "=", "nn", ".", "Tanh", "(", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'AF'", ",", "\"\"", ")", "==", "\"relu\"", ":", "\n", "            ", "self", ".", "AF", "=", "self", ".", "ReLU", "\n", "\n", "# embedding layer, original implementation uses a linear layer to randomly initialize embeddings", "\n", "", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "self", ".", "dense1", "=", "nn", ".", "EmbeddingBag", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dense1", "=", "nn", ".", "EmbeddingBag", "(", "\n", "self", ".", "emb_size", ",", "self", ".", "hidden_size", "\n", ")", "\n", "\n", "", "self", ".", "dense2", "=", "[", "nn", ".", "Linear", "(", "self", ".", "dense1", ".", "embedding_dim", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "self", ".", "device", ")", "for", "_", "in", "range", "(", "self", ".", "n_hidden", ")", "]", "\n", "self", ".", "dense3", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.forward": [[59, 68], ["adversarial.DeepMojiModel.dense1", "adversarial.DeepMojiModel.AF", "adversarial.DeepMojiModel.dense3", "adversarial.DeepMojiModel.dropout", "hl", "adversarial.DeepMojiModel.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "out", "=", "self", ".", "dense1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "AF", "(", "out", ")", "\n", "for", "hl", "in", "self", ".", "dense2", ":", "\n", "            ", "out", "=", "self", ".", "dropout", "(", "out", ")", "\n", "out", "=", "hl", "(", "out", ")", "\n", "out", "=", "self", ".", "tanh", "(", "out", ")", "\n", "", "out", "=", "self", ".", "dense3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.hidden": [[69, 85], ["adversarial.DeepMojiModel.dense1", "adversarial.DeepMojiModel.AF", "adversarial.DeepMojiModel.dropout", "hl", "adversarial.DeepMojiModel.tanh", "adversarial.DeepMojiModel.dense3"], "methods", ["None"], ["", "def", "hidden", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "assert", "self", ".", "adv_level", "in", "{", "0", ",", "-", "1", ",", "-", "2", "}", "\n", "out", "=", "self", ".", "dense1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "AF", "(", "out", ")", "\n", "if", "self", ".", "adv_level", "==", "-", "2", ":", "\n", "            ", "return", "out", "\n", "", "else", ":", "\n", "            ", "for", "hl", "in", "self", ".", "dense2", ":", "\n", "                ", "out", "=", "self", ".", "dropout", "(", "out", ")", "\n", "out", "=", "hl", "(", "out", ")", "\n", "out", "=", "self", ".", "tanh", "(", "out", ")", "\n", "", "if", "self", ".", "adv_level", "==", "-", "1", ":", "\n", "                ", "return", "out", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "dense3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.forward": [[97, 101], ["x.clone"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "lambda_", ")", ":", "\n", "        ", "ctx", ".", "lambda_", "=", "lambda_", "\n", "return", "x", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward": [[102, 108], ["grads.new_tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grads", ")", ":", "\n", "        ", "lambda_", "=", "ctx", ".", "lambda_", "\n", "lambda_", "=", "grads", ".", "new_tensor", "(", "lambda_", ")", "\n", "dx", "=", "-", "lambda_", "*", "grads", "\n", "return", "dx", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversal.__init__": [[111, 114], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lambda_", ")", ":", "\n", "        ", "super", "(", "GradientReversal", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversal.forward": [[115, 117], ["GradientReversalFunction.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "GradientReversalFunction", ".", "apply", "(", "x", ",", "self", ".", "lambda_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.Discriminator.__init__": [[120, 138], ["torch.Module.__init__", "adversarial.GradientReversal", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "os.path.exists", "numpy.load", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "GR", "=", "False", "\n", "self", ".", "grad_rev", "=", "GradientReversal", "(", "params", "[", "'LAMBDA'", "]", ")", "\n", "if", "'word_emb_path'", "in", "params", "and", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "emb_dim", "=", "np", ".", "load", "(", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", "\n", "emb_dim", "=", "emb_dim", ".", "shape", "[", "1", "]", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "emb_dim", ",", "params", "[", "'adv_units'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "params", "[", "'emb_dim'", "]", ",", "params", "[", "'adv_units'", "]", ")", "\n", "\n", "", "self", ".", "LeakyReLU", "=", "nn", ".", "LeakyReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "params", "[", "'adv_units'", "]", ")", "\n", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", ">", "2", ":", "\n", "            ", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "len", "(", "params", "[", "'unique_domains'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "params", "[", "'adv_units'", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.Discriminator.forward": [[139, 147], ["adversarial.Discriminator.fc1", "adversarial.Discriminator.LeakyReLU", "adversarial.Discriminator.fc2", "adversarial.Discriminator.fc3", "adversarial.Discriminator.grad_rev"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "GR", ":", "\n", "            ", "inputs", "=", "self", ".", "grad_rev", "(", "inputs", ")", "\n", "", "out", "=", "self", ".", "fc1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "out", "=", "self", ".", "fc3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.Discriminator.hidden_representation": [[148, 157], ["adversarial.Discriminator.fc1", "adversarial.Discriminator.LeakyReLU", "adversarial.Discriminator.fc2", "adversarial.Discriminator.grad_rev"], "methods", ["None"], ["", "def", "hidden_representation", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "GR", ":", "\n", "            ", "inputs", "=", "self", ".", "grad_rev", "(", "inputs", ")", "\n", "", "out", "=", "self", ".", "fc1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "LeakyReLU", "(", "out", ")", "\n", "out", "=", "self", ".", "fc2", "(", "out", ")", "\n", "# out = self.fc3(out)", "\n", "# Return the hidden representation from the second last layer", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.Discriminator.change_gradient_eversal": [[158, 160], ["None"], "methods", ["None"], ["", "def", "change_gradient_eversal", "(", "self", ",", "State", "=", "True", ")", ":", "\n", "        ", "self", ".", "GR", "=", "State", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.Discriminator.get_weights": [[161, 167], ["dense_parameter[].detach().cpu().numpy", "adversarial.Discriminator.fc3.named_parameters", "dense_parameter[].detach().cpu", "dense_parameter[].detach"], "methods", ["None"], ["", "def", "get_weights", "(", "self", ")", ":", "\n", "# return coef as numpy array", "\n", "        ", "dense_parameter", "=", "{", "name", ":", "param", "for", "name", ",", "param", "in", "self", ".", "fc3", ".", "named_parameters", "(", ")", "}", "\n", "# get coef and covert to numpy", "\n", "# return dense_parameter[\"weight\"].cpu().numpy()", "\n", "return", "dense_parameter", "[", "\"weight\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.build_base": [[169, 403], ["utils.data_loader", "numpy.unique", "os.path.dirname", "os.path.join", "utils.build_tok", "utils.DataEncoder", "utils.data_split", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "adversarial.DeepMojiModel", "base_model.to.to", "adversarial.Discriminator", "discriminator.to.to", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "base_model.to.parameters", "filter", "torch.CrossEntropyLoss().to", "torch.BCEWithLogitsLoss().to", "range", "base_model.to.train", "discriminator.to.train", "enumerate", "base_model.to.eval", "discriminator.to.eval", "range", "torch.optim.lr_scheduler.ReduceLROnPlateau.step", "sklearn.metrics.f1_score", "os.path.join", "range", "discriminator.to.parameters", "tuple", "torch.optim.Adam.zero_grad", "torch.optim.Adam.zero_grad", "base_model.to.", "nn.BCEWithLogitsLoss().to.", "criterion.item", "base_model.to.hidden", "discriminator.to.", "nn.BCEWithLogitsLoss().to.", "criterion.backward", "torch.optim.Adam.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "tuple", "nn.BCEWithLogitsLoss().to.", "criterion.item", "torch.sigmoid", "torch.sigmoid", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "torch.CrossEntropyLoss", "torch.BCEWithLogitsLoss", "input_labels.float.float", "len", "input_domains.float.float", "base_model.squeeze", "discriminator.squeeze", "print", "print", "print", "discriminator.to.parameters", "torch.optim.Adam.zero_grad", "tuple", "base_model.to.hidden", "discriminator.to.", "nn.BCEWithLogitsLoss().to.", "criterion.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.optim.Adam.step", "torch.no_grad", "torch.no_grad", "base_model.to.", "input_labels.float.float", "base_model.squeeze", "base_model.detach().cpu", "numpy.argmax().flatten", "input_labels.float.to().numpy", "len", "tuple", "torch.sigmoid", "torch.sigmoid", "y_preds.extend", "y_trues.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "input_labels.float.float", "len", "input_domains.float.float", "discriminator.squeeze", "discriminator.to.parameters", "t.to", "torch.no_grad", "torch.no_grad", "base_model.to.", "base_model.squeeze().detach().cpu", "numpy.argmax().flatten", "input_labels.float.to().numpy", "y_probs.extend", "y_probs.extend", "input_domains.float.detach().cpu().numpy", "t.to", "base_model.detach", "numpy.argmax", "input_labels.float.to", "os.path.basename", "t.to", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "torch.sigmoid.numpy", "base_model.squeeze().detach", "numpy.argmax", "input_labels.float.to", "input_domains.float.detach().cpu", "torch.sigmoid.numpy", "base_model.squeeze", "input_domains.float.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.hidden", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.DeepMojiModel.hidden", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "build_base", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "# load data", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "\n", "# if not os.path.exists(params['word_emb_path']):", "\n", "#     utils.build_wt(tok, params['emb_path'], params['word_emb_path'])", "\n", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "train_data", "=", "utils", ".", "TorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "base_model", "=", "DeepMojiModel", "(", "params", ")", "\n", "base_model", "=", "base_model", ".", "to", "(", "device", ")", "\n", "discriminator", "=", "Discriminator", "(", "params", ")", "\n", "discriminator", "=", "discriminator", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "base_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "adv_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "filter", "(", "\n", "lambda", "p", ":", "p", ".", "requires_grad", ",", "discriminator", ".", "parameters", "(", ")", ")", ",", "lr", "=", "1e-1", "*", "params", "[", "'lr'", "]", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'max'", ",", "factor", "=", "0.5", ",", "patience", "=", "2", ")", "\n", "if", "params", "[", "'num_label'", "]", ">", "2", ":", "\n", "        ", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# train the networks", "\n", "", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "base_model", ".", "train", "(", ")", "\n", "discriminator", ".", "train", "(", ")", "\n", "discriminator", ".", "GR", "=", "True", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "train_batch", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", "<", "3", ":", "\n", "                ", "input_domains", "=", "input_domains", ".", "float", "(", ")", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "adv_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "squeeze", "(", ")", ",", "input_labels", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "hs", "=", "base_model", ".", "hidden", "(", "input_docs", ")", "\n", "adv_predictions", "=", "discriminator", "(", "hs", ")", "\n", "loss", "+=", "criterion", "(", "adv_predictions", ".", "squeeze", "(", ")", ",", "input_domains", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "discriminator", ".", "parameters", "(", ")", ",", "params", "[", "'clipping_value'", "]", ")", "\n", "adv_optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "discriminator", ".", "GR", "=", "False", "\n", "base_model", ".", "eval", "(", ")", "\n", "discriminator", ".", "eval", "(", ")", "\n", "# converge the discriminator first", "\n", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "            ", "for", "valid_batch", "in", "train_data_loader", ":", "\n", "                ", "adv_optimizer", ".", "zero_grad", "(", ")", "\n", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "if", "len", "(", "params", "[", "'unique_domains'", "]", ")", "<", "3", ":", "\n", "                    ", "input_domains", "=", "input_domains", ".", "float", "(", ")", "\n", "", "hs", "=", "base_model", ".", "hidden", "(", "input_docs", ")", "\n", "adv_predictions", "=", "discriminator", "(", "hs", ")", "\n", "adv_loss_item", "=", "criterion", "(", "adv_predictions", ".", "squeeze", "(", ")", ",", "input_domains", ")", "\n", "adv_loss_item", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "discriminator", ".", "parameters", "(", ")", ",", "params", "[", "'clipping_value'", "]", ")", "\n", "adv_optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "valid_loss", "=", "0.0", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "input_labels", "=", "input_labels", ".", "float", "(", ")", "\n", "", "valid_loss_batch", "=", "criterion", "(", "predictions", ".", "squeeze", "(", ")", ",", "input_labels", ")", "\n", "valid_loss", "+=", "valid_loss_batch", ".", "item", "(", ")", "\n", "\n", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                ", "pred_flat", "=", "(", "logits", ">", "0.5", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "", "scheduler", ".", "step", "(", "valid_loss", "/", "len", "(", "valid_data_loader", ")", ")", "\n", "\n", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'macro'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "base_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "base_model", "(", "input_docs", ")", "\n", "", "logits", "=", "torch", ".", "sigmoid", "(", "predictions", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "pred_flat", "=", "(", "logits", ">", "0.5", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "if", "params", "[", "'num_label'", "]", "<", "3", ":", "\n", "                    ", "y_probs", ".", "extend", "(", "[", "item", "for", "item", "in", "logits", "]", ")", "\n", "", "else", ":", "\n", "                    ", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words": [[25, 32], ["re.sub", "re.sub.split"], "function", ["None"], ["def", "replace_words", "(", "doc", ",", "replace", ")", ":", "\n", "# replace numbers", "\n", "    ", "doc", "=", "re", ".", "sub", "(", "'^[0-9]+'", ",", "'number'", ",", "doc", ")", "\n", "# replace words", "\n", "doc", "=", "[", "word", "if", "word", "not", "in", "replace", "else", "'identity'", "for", "word", "in", "doc", ".", "split", "(", ")", "]", "\n", "\n", "return", "' '", ".", "join", "(", "doc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.build_lr_blind": [[34, 137], ["print", "utils.data_loader", "print", "os.path.join", "os.path.exists", "utils.data_split", "print", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "print", "print", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.roc_curve", "open", "set", "pickle.load", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit", "pickle.dump", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "open", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "set.add", "open", "set", "open", "lr_blind.replace_words", "range", "lr_blind.replace_words", "len", "line.strip", "nltk.corpus.stopwords.words", "range", "len", "sklearn.linear_model.LogisticRegression.predict_proba", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "line.split", "len"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr_blind.replace_words", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "def", "build_lr_blind", "(", "params", ")", ":", "\n", "# load the replacement words", "\n", "    ", "with", "open", "(", "'../resources/lexicons/replace_{}.txt'", ".", "format", "(", "params", "[", "'lang'", "]", ")", ")", "as", "dfile", ":", "\n", "        ", "replaces", "=", "set", "(", ")", "\n", "for", "line", "in", "dfile", ":", "\n", "# only use unigram", "\n", "            ", "if", "len", "(", "line", ".", "split", "(", "' '", ")", ")", ">", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "replaces", ".", "add", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "print", "(", "'Building Domain Vectorizer...'", ")", "\n", "\n", "# build vectorizer", "\n", "vect_path", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'-lr_vect.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "vect_path", ")", ":", "\n", "        ", "lr_vect", "=", "pickle", ".", "load", "(", "open", "(", "vect_path", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "spw_set", "=", "set", "(", "stopwords", ".", "words", "(", "params", "[", "'lang'", "]", ")", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "spw_set", "=", "None", "\n", "", "lr_vect", "=", "TfidfVectorizer", "(", "\n", "min_df", "=", "3", ",", "max_features", "=", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", ",", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "\n", ")", "\n", "lr_vect", ".", "fit", "(", "data", "[", "'docs'", "]", ")", "\n", "pickle", ".", "dump", "(", "lr_vect", ",", "open", "(", "vect_path", ",", "'wb'", ")", ")", "\n", "", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "\n", "# train classifier", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "input_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "input_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "input_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "input_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "print", "(", "'Training Classifier...'", ")", "\n", "input_feats", "=", "lr_vect", ".", "transform", "(", "input_data", "[", "'docs'", "]", ")", "\n", "clf", "=", "LogisticRegression", "(", "max_iter", "=", "2000", ",", "n_jobs", "=", "-", "1", ")", "\n", "clf", ".", "fit", "(", "input_feats", ",", "input_data", "[", "'labels'", "]", ")", "\n", "\n", "# load test", "\n", "print", "(", "'Loading Test data'", ")", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "replace_words", "(", "data", "[", "'docs'", "]", "[", "item", "]", ",", "replaces", ")", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "\n", "print", "(", "'Testing.............................'", ")", "\n", "input_feats", "=", "lr_vect", ".", "transform", "(", "input_data", "[", "'docs'", "]", ")", "\n", "pred_label", "=", "clf", ".", "predict", "(", "input_feats", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_score", "=", "clf", ".", "predict_proba", "(", "input_feats", ")", "[", ":", ",", "1", "]", ",", "\n", ")", "\n", "\n", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "        ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "input_data", "[", "'labels'", "]", ",", "\n", "pred_labels", "=", "pred_label", ",", "\n", "domain_labels", "=", "input_data", "[", "params", "[", "'domain_name'", "]", "]", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.TrainTorchDataset.__init__": [[24, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "domain_name", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "domain_name", "=", "domain_name", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.TrainTorchDataset.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", "[", "'docs'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.TrainTorchDataset.__getitem__": [[31, 36], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "domain_name", "in", "self", ".", "dataset", ":", "\n", "            ", "return", "self", ".", "dataset", "[", "'docs'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'labels'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "self", ".", "domain_name", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'weights'", "]", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "dataset", "[", "'docs'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'labels'", "]", "[", "idx", "]", ",", "-", "1", ",", "self", ".", "dataset", "[", "'weights'", "]", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.TrainDataEncoder.__init__": [[39, 54], ["pickle.load", "open", "transformers.BertTokenizer.from_pretrained", "ValueError", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "mtype", "=", "'rnn'", ")", ":", "\n", "        ", "\"\"\"\n\n        :param params:\n        :param mtype: Model type, rnn or bert\n        \"\"\"", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "mtype", "=", "mtype", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "            ", "self", ".", "tok", "=", "pickle", ".", "load", "(", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "'tok_dir'", "]", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", ",", "'rb'", ")", ")", "\n", "", "elif", "self", ".", "mtype", "==", "'bert'", ":", "\n", "            ", "self", ".", "tok", "=", "BertTokenizer", ".", "from_pretrained", "(", "params", "[", "'bert_name'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Only support BERT and RNN data encoders'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.TrainDataEncoder.__call__": [[55, 86], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "instant_rnn_torch.TrainDataEncoder.tok.texts_to_sequences", "keras.preprocessing.sequence.pad_sequences", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.stack().long", "torch.stack().long", "torch.stack().long", "torch.stack().long", "instant_rnn_torch.TrainDataEncoder.tok.encode_plus", "torch.stack().long.append", "torch.stack().long.append", "torch.stack().long.append", "torch.stack().long.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "docs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "domains", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "text", ",", "label", ",", "domain", ",", "weight", "in", "batch", ":", "\n", "            ", "if", "self", ".", "mtype", "==", "'bert'", ":", "\n", "                ", "text", "=", "self", ".", "tok", ".", "encode_plus", "(", "\n", "text", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "self", ".", "params", "[", "'max_len'", "]", ",", "\n", "return_tensors", "=", "'pt'", ",", "return_token_type_ids", "=", "False", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "docs", ".", "append", "(", "text", "[", "'input_ids'", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "docs", ".", "append", "(", "text", ")", "\n", "\n", "", "labels", ".", "append", "(", "label", ")", "\n", "domains", ".", "append", "(", "domain", ")", "\n", "weights", ".", "append", "(", "weight", ")", "\n", "\n", "", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "domains", "=", "torch", ".", "tensor", "(", "domains", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "weights", "=", "torch", ".", "tensor", "(", "weights", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "# padding and tokenize", "\n", "            ", "docs", "=", "self", ".", "tok", ".", "texts_to_sequences", "(", "docs", ")", "\n", "docs", "=", "pad_sequences", "(", "docs", ")", "\n", "docs", "=", "torch", ".", "Tensor", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "            ", "docs", "=", "torch", ".", "stack", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "return", "docs", ",", "labels", ",", "domains", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.RegularRNN.__init__": [[90, 121], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "os.path.exists", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding", "torch.Embedding", "instant_rnn_torch.RegularRNN.wemb.reset_parameters", "torch.init.kaiming_uniform_", "torch.init.kaiming_uniform_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.load", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "super", "(", "RegularRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "if", "'word_emb_path'", "in", "self", ".", "params", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "\n", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "\n", "self", ".", "params", "[", "'word_emb_path'", "]", ",", "allow_pickle", "=", "True", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wemb", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "params", "[", "'max_feature'", "]", ",", "self", ".", "params", "[", "'emb_dim'", "]", "\n", ")", "\n", "self", ".", "wemb", ".", "reset_parameters", "(", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "wemb", ".", "weight", ",", "a", "=", "np", ".", "sqrt", "(", "5", ")", ")", "\n", "\n", "", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_hidden_size", "=", "self", ".", "params", "[", "'emb_dim'", "]", "\n", "\n", "# domain adaptation", "\n", "", "self", ".", "doc_net_general", "=", "nn", ".", "GRU", "(", "\n", "self", ".", "wemb", ".", "embedding_dim", ",", "self", ".", "word_hidden_size", ",", "\n", "bidirectional", "=", "self", ".", "params", "[", "'bidirectional'", "]", ",", "dropout", "=", "self", ".", "params", "[", "'dp_rate'", "]", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "# prediction", "\n", "self", ".", "predictor", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "params", "[", "'emb_dim'", "]", ",", "self", ".", "params", "[", "'num_label'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.RegularRNN.forward": [[122, 137], ["instant_rnn_torch.RegularRNN.wemb", "instant_rnn_torch.RegularRNN.doc_net_general", "instant_rnn_torch.RegularRNN.predictor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "doc_general.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_docs", ")", ":", "\n", "# encode the document from different perspectives", "\n", "        ", "doc_embs", "=", "self", ".", "wemb", "(", "input_docs", ")", "\n", "_", ",", "doc_general", "=", "self", ".", "doc_net_general", "(", "doc_embs", ")", "# omit hidden vectors", "\n", "\n", "# concatenate hidden state", "\n", "if", "self", ".", "params", "[", "'bidirectional'", "]", ":", "\n", "            ", "doc_general", "=", "torch", ".", "cat", "(", "(", "doc_general", "[", "0", ",", ":", ",", ":", "]", ",", "doc_general", "[", "1", ",", ":", ",", ":", "]", ")", ",", "-", "1", ")", "\n", "\n", "", "if", "doc_general", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "doc_general", "=", "doc_general", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "\n", "# prediction", "\n", "", "doc_preds", "=", "self", ".", "predictor", "(", "doc_general", ")", "\n", "return", "doc_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.instant_rnn_torch.build_model": [[139, 330], ["print", "utils.data_loader", "numpy.load", "numpy.unique", "os.path.dirname", "os.path.join", "utils.build_tok", "utils.DataEncoder", "instant_rnn_torch.TrainDataEncoder", "utils.data_split", "instant_rnn_torch.TrainTorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "utils.TorchDataset", "torch.utils.data.DataLoader", "instant_rnn_torch.RegularRNN", "rnn_model.to.to", "torch.CrossEntropyLoss().to", "torch.optim.RMSprop", "torch.optim.RMSprop", "print", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "os.path.exists", "utils.build_wt", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "rnn_model.to.parameters", "range", "rnn_model.to.train", "enumerate", "rnn_model.to.eval", "sklearn.metrics.f1_score", "os.path.join", "range", "torch.CrossEntropyLoss", "tuple", "torch.optim.RMSprop.zero_grad", "rnn_model.to.", "nn.CrossEntropyLoss().to.", "loss.mean.mean", "loss.mean.item", "loss.mean.backward", "torch.optim.RMSprop.step", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "torch.save", "torch.save", "range", "len", "rnn_model.view", "input_labels.view", "print", "print", "print", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "tuple", "rnn_model.detach().cpu().numpy", "numpy.argmax().flatten", "y_preds.extend", "y_trues.extend", "y_probs.extend", "y_domains.extend", "open", "wfile.write", "wfile.write", "wfile.write", "sklearn.metrics.roc_curve", "wfile.write", "sklearn.metrics.classification_report", "print", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "len", "t.to", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "torch.no_grad", "torch.no_grad", "rnn_model.to.", "input_labels.to().numpy", "input_domains.detach().cpu().numpy", "input_labels.to", "os.path.basename", "t.to", "rnn_model.detach().cpu", "numpy.argmax", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "utils.fair_eval", "rnn_model.detach", "input_labels.to", "input_domains.detach().cpu", "rnn_model.detach", "input_domains.detach"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.adversarial.GradientReversalFunction.backward", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["", "", "def", "build_model", "(", "params", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "params", "[", "'device'", "]", "!=", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "params", "[", "'device'", "]", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "params", "[", "'device'", "]", "=", "device", "\n", "\n", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "debias_weights", "=", "np", ".", "load", "(", "params", "[", "'model_dir'", "]", "+", "\"weights_{}.npy\"", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "params", "[", "'unique_domains'", "]", "=", "np", ".", "unique", "(", "data", "[", "params", "[", "'domain_name'", "]", "]", ")", "\n", "\n", "# build tokenizer and weight", "\n", "tok_dir", "=", "os", ".", "path", ".", "dirname", "(", "params", "[", "'dpath'", "]", ")", "\n", "params", "[", "'tok_dir'", "]", "=", "tok_dir", "\n", "params", "[", "'word_emb_path'", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "tok_dir", ",", "params", "[", "'dname'", "]", "+", "'.npy'", "\n", ")", "\n", "tok", "=", "utils", ".", "build_tok", "(", "\n", "data", "[", "'docs'", "]", ",", "max_feature", "=", "params", "[", "'max_feature'", "]", ",", "\n", "opath", "=", "os", ".", "path", ".", "join", "(", "tok_dir", ",", "'{}-{}.tok'", ".", "format", "(", "params", "[", "'dname'", "]", ",", "params", "[", "'lang'", "]", ")", ")", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", "[", "'word_emb_path'", "]", ")", ":", "\n", "        ", "utils", ".", "build_wt", "(", "tok", ",", "params", "[", "'emb_path'", "]", ",", "params", "[", "'word_emb_path'", "]", ")", "\n", "", "data_encoder", "=", "utils", ".", "DataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "train_data_encoder", "=", "TrainDataEncoder", "(", "params", ",", "mtype", "=", "'rnn'", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "valid_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "val_indices", "]", ",", "\n", "}", "\n", "test_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "train_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "debias_weights", "=", "debias_weights", "[", "sample_indices", "]", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "train_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "train_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "train_data", "=", "{", "\n", "'docs'", ":", "[", "train_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "train_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "train_data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "debias_weights", "=", "debias_weights", "[", "indices", "]", "\n", "\n", "", "train_data", "[", "'weights'", "]", "=", "debias_weights", "\n", "train_data", "=", "TrainTorchDataset", "(", "train_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "train_data_loader", "=", "DataLoader", "(", "\n", "train_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "train_data_encoder", "\n", ")", "\n", "valid_data", "=", "utils", ".", "TorchDataset", "(", "valid_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "valid_data_loader", "=", "DataLoader", "(", "\n", "valid_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "test_data", "=", "utils", ".", "TorchDataset", "(", "test_data", ",", "params", "[", "'domain_name'", "]", ")", "\n", "test_data_loader", "=", "DataLoader", "(", "\n", "test_data", ",", "batch_size", "=", "params", "[", "'batch_size'", "]", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "data_encoder", "\n", ")", "\n", "\n", "# build model", "\n", "rnn_model", "=", "RegularRNN", "(", "params", ")", "\n", "rnn_model", "=", "rnn_model", ".", "to", "(", "device", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", ".", "to", "(", "device", ")", "# we will multiply with sample weights later", "\n", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "rnn_model", ".", "parameters", "(", ")", ",", "lr", "=", "params", "[", "'lr'", "]", ")", "\n", "\n", "# train the networks", "\n", "print", "(", "'Start to train...'", ")", "\n", "print", "(", "params", ")", "\n", "best_score", "=", "0.", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "params", "[", "'epochs'", "]", ")", ")", ":", "\n", "        ", "train_loss", "=", "0", "\n", "rnn_model", ".", "train", "(", ")", "\n", "\n", "for", "step", ",", "train_batch", "in", "enumerate", "(", "train_data_loader", ")", ":", "\n", "            ", "train_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "train_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", ",", "input_weights", "=", "train_batch", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", "\n", "}", ")", "\n", "loss", "=", "criterion", "(", "predictions", ".", "view", "(", "-", "1", ",", "params", "[", "'num_label'", "]", ")", ",", "input_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "input_weights", "*", "loss", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss_avg", "=", "train_loss", "/", "(", "step", "+", "1", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "101", "==", "0", ":", "\n", "                ", "print", "(", "'Epoch: {}, Step: {}'", ".", "format", "(", "epoch", ",", "step", ")", ")", "\n", "print", "(", "'\\tLoss: {}.'", ".", "format", "(", "loss_avg", ")", ")", "\n", "print", "(", "'-------------------------------------------------'", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), 0.5)", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# evaluate on the valid set", "\n", "", "y_preds", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "rnn_model", ".", "eval", "(", ")", "\n", "for", "valid_batch", "in", "valid_data_loader", ":", "\n", "            ", "valid_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "valid_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "valid_batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "eval_score", "=", "metrics", ".", "f1_score", "(", "y_pred", "=", "y_preds", ",", "y_true", "=", "y_trues", ",", "average", "=", "'weighted'", ")", "\n", "if", "eval_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "eval_score", "\n", "torch", ".", "save", "(", "rnn_model", ",", "params", "[", "'model_dir'", "]", "+", "'{}.pth'", ".", "format", "(", "os", ".", "path", ".", "basename", "(", "__file__", ")", ")", ")", "\n", "\n", "y_preds", "=", "[", "]", "\n", "y_probs", "=", "[", "]", "\n", "y_trues", "=", "[", "]", "\n", "y_domains", "=", "[", "]", "\n", "# evaluate on the test set", "\n", "for", "test_batch", "in", "test_data_loader", ":", "\n", "                ", "test_batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "test_batch", ")", "\n", "input_docs", ",", "input_labels", ",", "input_domains", "=", "test_batch", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "predictions", "=", "rnn_model", "(", "**", "{", "\n", "'input_docs'", ":", "input_docs", ",", "\n", "}", ")", "\n", "", "logits", "=", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_flat", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", ".", "flatten", "(", ")", "\n", "y_preds", ".", "extend", "(", "pred_flat", ")", "\n", "y_trues", ".", "extend", "(", "input_labels", ".", "to", "(", "'cpu'", ")", ".", "numpy", "(", ")", ")", "\n", "y_probs", ".", "extend", "(", "[", "item", "[", "1", "]", "for", "item", "in", "logits", "]", ")", "\n", "y_domains", ".", "extend", "(", "input_domains", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "                ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "y_true", "=", "y_trues", ",", "y_score", "=", "y_probs", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "report", "=", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "y_trues", ",", "y_pred", "=", "y_preds", ",", "digits", "=", "3", "\n", ")", "\n", "print", "(", "report", ")", "\n", "wfile", ".", "write", "(", "report", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "y_trues", ",", "\n", "pred_labels", "=", "y_preds", ",", "\n", "domain_labels", "=", "y_domains", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.TorchDataset.__init__": [[163, 166], ["None"], "methods", ["None"], [")", "\n", "scores", "[", "'fped'", "]", "=", "scores", "[", "'fped'", "]", "+", "abs", "(", "\n", "cal_fpr", "(", "fp", ",", "tn", ")", "-", "cal_fpr", "(", "g_fp", ",", "g_tn", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.TorchDataset.__len__": [[167, 169], ["len"], "methods", ["None"], ["scores", "[", "'tped'", "]", "=", "scores", "[", "'tped'", "]", "+", "abs", "(", "\n", "cal_tpr", "(", "tp", ",", "fn", ")", "-", "cal_tpr", "(", "g_tp", ",", "g_fn", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.TorchDataset.__getitem__": [[170, 175], ["None"], "methods", ["None"], ["scores", "[", "'tned'", "]", "=", "scores", "[", "'tned'", "]", "+", "abs", "(", "\n", "cal_tnr", "(", "tn", ",", "fp", ")", "-", "cal_tnr", "(", "g_tn", ",", "g_fp", ")", "\n", ")", "\n", "", "return", "json", ".", "dumps", "(", "scores", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__init__": [[308, 323], ["pickle.load", "open", "transformers.BertTokenizer.from_pretrained", "ValueError", "os.path.join"], "methods", ["None"], []], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.DataEncoder.__call__": [[324, 351], ["torch.tensor", "torch.tensor", "torch.tensor.append", "torch.tensor.append", "utils.DataEncoder.tok.texts_to_sequences", "keras.preprocessing.sequence.pad_sequences", "torch.Tensor().long", "torch.stack().long", "utils.DataEncoder.tok.encode_plus", "torch.stack().long.append", "torch.stack().long.append", "torch.Tensor", "torch.stack"], "methods", ["None"], []], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.swap_gender": [[17, 84], ["range", "len", "new_docs.append", "new_labels.append", "new_idx.append", "new_docs.append", "new_labels.append", "new_idx.append", "m2f.get", "f2m.get", "docs[].split", "docs[].split"], "function", ["None"], ["def", "data_loader", "(", "dpath", ",", "domain_name", "=", "'gender'", ",", "filter_null", "=", "True", ",", "lang", "=", "'english'", ")", ":", "\n", "    ", "\"\"\"\n    Default data format, tsv\n    :param domain_name:\n    :param lang: Language of the corpus, currently only supports languages defined by punkt\n    :param filter_null: if filter out gender is empty or not.\n    :param dpath:\n    :return:\n    \"\"\"", "\n", "data", "=", "{", "\n", "'docs'", ":", "[", "]", ",", "\n", "'labels'", ":", "[", "]", ",", "\n", "'gender'", ":", "[", "]", ",", "\n", "}", "\n", "with", "open", "(", "dpath", ")", "as", "dfile", ":", "\n", "        ", "cols", "=", "dfile", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "doc_idx", "=", "cols", ".", "index", "(", "'text'", ")", "\n", "domain_idx", "=", "cols", ".", "index", "(", "domain_name", ")", "\n", "label_idx", "=", "cols", ".", "index", "(", "'label'", ")", "\n", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "dfile", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "line", ")", "!=", "len", "(", "cols", ")", ":", "\n", "                ", "continue", "\n", "", "if", "len", "(", "line", "[", "doc_idx", "]", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "<", "10", ":", "\n", "                ", "continue", "\n", "\n", "# print(idx, line)", "\n", "", "if", "filter_null", "and", "line", "[", "domain_idx", "]", "==", "'x'", ":", "\n", "                ", "continue", "\n", "\n", "# binarize labels in the trustpilot dataset to keep the same format.", "\n", "", "try", ":", "\n", "                ", "label", "=", "int", "(", "line", "[", "label_idx", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "# encode hate speech data", "\n", "                ", "if", "line", "[", "label_idx", "]", "in", "[", "'0'", ",", "'no'", ",", "'neither'", ",", "'normal'", "]", ":", "\n", "                    ", "label", "=", "0", "\n", "", "else", ":", "\n", "                    ", "label", "=", "1", "\n", "\n", "# label trustpilot review scores", "\n", "", "", "if", "'trustpilot'", "in", "dpath", ":", "\n", "                ", "if", "label", "==", "3", ":", "\n", "                    ", "continue", "\n", "", "elif", "label", ">", "3", ":", "\n", "                    ", "label", "=", "1", "\n", "", "else", ":", "\n", "                    ", "label", "=", "0", "\n", "\n", "# encode gender.", "\n", "", "", "gender", "=", "line", "[", "domain_idx", "]", ".", "strip", "(", ")", "\n", "if", "gender", "!=", "'x'", ":", "\n", "                ", "if", "gender", "not", "in", "[", "'1'", ",", "'0'", "]", ":", "\n", "                    ", "if", "'f'", "in", "gender", ":", "\n", "                        ", "gender", "=", "1", "\n", "", "else", ":", "\n", "                        ", "gender", "=", "0", "\n", "", "", "else", ":", "\n", "                    ", "gender", "=", "int", "(", "gender", ")", "\n", "\n", "", "", "data", "[", "'docs'", "]", ".", "append", "(", "' '", ".", "join", "(", "word_tokenize", "(", "line", "[", "doc_idx", "]", ",", "language", "=", "lang", ")", ")", ")", "\n", "data", "[", "'labels'", "]", ".", "append", "(", "label", ")", "\n", "data", "[", "domain_name", "]", ".", "append", "(", "gender", ")", "\n", "", "", "return", "data", "\n", "\n", "\n", "", "class", "TorchDataset", "(", "Dataset", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.stopwords": [[86, 92], ["None"], "function", ["None"], ["        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "domain_name", "=", "domain_name", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", "[", "'docs'", "]", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader": [[95, 160], ["open", "dfile.readline().strip().split", "dfile.readline().strip().split.index", "dfile.readline().strip().split.index", "dfile.readline().strip().split.index", "enumerate", "line.strip().lower().split.strip().lower().split", "line[].strip", "data[].append", "data[].append", "data[].append", "dfile.readline().strip", "len", "len", "len", "int", "line.strip().lower().split.strip().lower", "line[].strip().split", "int", "nltk.tokenize.word_tokenize", "dfile.readline", "line.strip().lower().split.strip", "line[].strip"], "function", ["None"], ["", "else", ":", "\n", "            ", "return", "self", ".", "dataset", "[", "'docs'", "]", "[", "idx", "]", ",", "self", ".", "dataset", "[", "'labels'", "]", "[", "idx", "]", ",", "-", "1", "\n", "\n", "\n", "", "", "", "def", "data_split", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n\n    :param data:\n    :return:\n    \"\"\"", "\n", "data_indices", "=", "list", "(", "range", "(", "len", "(", "data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "seed", "(", "33", ")", "# for reproductive results", "\n", "np", ".", "random", ".", "shuffle", "(", "data_indices", ")", "\n", "\n", "train_indices", "=", "data_indices", "[", ":", "int", "(", ".8", "*", "len", "(", "data_indices", ")", ")", "]", "\n", "dev_indices", "=", "data_indices", "[", "int", "(", ".8", "*", "len", "(", "data_indices", ")", ")", ":", "int", "(", ".9", "*", "len", "(", "data_indices", ")", ")", "]", "\n", "test_indices", "=", "data_indices", "[", "int", "(", ".9", "*", "len", "(", "data_indices", ")", ")", ":", "]", "\n", "return", "train_indices", ",", "dev_indices", ",", "test_indices", "\n", "\n", "\n", "", "def", "cal_fpr", "(", "fp", ",", "tn", ")", ":", "\n", "    ", "\"\"\"False positive rate\"\"\"", "\n", "return", "fp", "/", "(", "fp", "+", "tn", ")", "\n", "\n", "\n", "", "def", "cal_fnr", "(", "fn", ",", "tp", ")", ":", "\n", "    ", "\"\"\"False negative rate\"\"\"", "\n", "return", "fn", "/", "(", "fn", "+", "tp", ")", "\n", "\n", "\n", "", "def", "cal_tpr", "(", "tp", ",", "fn", ")", ":", "\n", "    ", "\"\"\"True positive rate\"\"\"", "\n", "return", "tp", "/", "(", "tp", "+", "fn", ")", "\n", "\n", "\n", "", "def", "cal_tnr", "(", "tn", ",", "fp", ")", ":", "\n", "    ", "\"\"\"True negative rate\"\"\"", "\n", "return", "tn", "/", "(", "tn", "+", "fp", ")", "\n", "\n", "\n", "", "def", "fair_eval", "(", "true_labels", ",", "pred_labels", ",", "domain_labels", ")", ":", "\n", "    ", "scores", "=", "{", "\n", "'fned'", ":", "0.0", ",", "# gap between fnr", "\n", "'fped'", ":", "0.0", ",", "# gap between fpr", "\n", "'tped'", ":", "0.0", ",", "# gap between tpr", "\n", "'tned'", ":", "0.0", ",", "# gap between tnr", "\n", "}", "\n", "\n", "# get overall confusion matrix", "\n", "tn", ",", "fp", ",", "fn", ",", "tp", "=", "metrics", ".", "confusion_matrix", "(", "\n", "y_true", "=", "true_labels", ",", "y_pred", "=", "pred_labels", "\n", ")", ".", "ravel", "(", ")", "\n", "\n", "# get the unique types of demographic groups", "\n", "uniq_types", "=", "np", ".", "unique", "(", "domain_labels", ")", "\n", "for", "group", "in", "uniq_types", ":", "\n", "# calculate group specific confusion matrix", "\n", "        ", "group_indices", "=", "[", "item", "for", "item", "in", "range", "(", "len", "(", "domain_labels", ")", ")", "if", "domain_labels", "[", "item", "]", "==", "group", "]", "\n", "group_labels", "=", "[", "true_labels", "[", "item", "]", "for", "item", "in", "group_indices", "]", "\n", "group_preds", "=", "[", "pred_labels", "[", "item", "]", "for", "item", "in", "group_indices", "]", "\n", "\n", "g_tn", ",", "g_fp", ",", "g_fn", ",", "g_tp", "=", "metrics", ".", "confusion_matrix", "(", "\n", "y_true", "=", "group_labels", ",", "y_pred", "=", "group_preds", "\n", ")", ".", "ravel", "(", ")", "\n", "\n", "# calculate and accumulate the gaps", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split": [[177, 191], ["list", "numpy.random.seed", "numpy.random.shuffle", "range", "len", "int", "int", "int", "int", "len", "len", "len", "len"], "function", ["None"], ["    ", "\"\"\"Build weight using word embedding\"\"\"", "\n", "embed_len", "=", "len", "(", "tkn", ".", "word_index", ")", "\n", "if", "embed_len", ">", "tkn", ".", "num_words", ":", "\n", "        ", "embed_len", "=", "tkn", ".", "num_words", "\n", "\n", "", "emb_size", "=", "200", "\n", "if", "emb_path", ".", "endswith", "(", "'.bin'", ")", ":", "\n", "        ", "embeds", "=", "gensim", ".", "models", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "\n", "emb_path", ",", "binary", "=", "True", ",", "unicode_errors", "=", "'ignore'", "\n", ")", "\n", "emb_size", "=", "embeds", ".", "vector_size", "\n", "emb_matrix", "=", "list", "(", "np", ".", "zeros", "(", "(", "embed_len", "+", "1", ",", "emb_size", ")", ")", ")", "\n", "for", "pair", "in", "zip", "(", "embeds", ".", "wv", ".", "index2word", ",", "embeds", ".", "wv", ".", "syn0", ")", ":", "\n", "            ", "if", "pair", "[", "0", "]", "in", "tkn", ".", "word_index", "and", "tkn", ".", "word_index", "[", "pair", "[", "0", "]", "]", "<", "tkn", ".", "num_words", ":", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fpr": [[193, 196], ["None"], "function", ["None"], ["float", "(", "item", ")", "for", "item", "in", "pair", "[", "1", "]", "\n", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "", "else", ":", "\n", "        ", "dfile", "=", "open", "(", "emb_path", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fnr": [[198, 201], ["None"], "function", ["None"], ["if", "len", "(", "line", ")", "<", "5", ":", "\n", "            ", "line", "=", "dfile", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "", "emb_size", "=", "len", "(", "line", "[", "1", ":", "]", ")", "\n", "emb_matrix", "=", "list", "(", "np", ".", "zeros", "(", "(", "embed_len", "+", "1", ",", "emb_size", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tpr": [[203, 206], ["None"], "function", ["None"], ["\n", "with", "open", "(", "emb_path", ")", "as", "dfile", ":", "\n", "            ", "for", "line", "in", "dfile", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tnr": [[208, 211], ["None"], "function", ["None"], ["tkn", ".", "word_index", "[", "line", "[", "0", "]", "]", "<", "tkn", ".", "num_words", ":", "\n", "                    ", "emb_matrix", "[", "tkn", ".", "word_index", "[", "line", "[", "0", "]", "]", "]", "=", "np", ".", "asarray", "(", "[", "\n", "float", "(", "item", ")", "for", "item", "in", "line", "[", "1", ":", "]", "\n", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval": [[213, 252], ["sklearn.metrics.confusion_matrix().ravel", "numpy.unique", "json.dumps", "sklearn.metrics.confusion_matrix().ravel", "sklearn.metrics.confusion_matrix", "abs", "abs", "abs", "abs", "range", "sklearn.metrics.confusion_matrix", "len", "utils.cal_fnr", "utils.cal_fnr", "utils.cal_fpr", "utils.cal_fpr", "utils.cal_tpr", "utils.cal_tpr", "utils.cal_tnr", "utils.cal_tnr"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_fpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tpr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tnr", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.cal_tnr"], ["", "", "", "", "np", ".", "save", "(", "opath", ",", "emb_matrix", ")", "\n", "\n", "\n", "", "def", "build_tok", "(", "docs", ",", "max_feature", ",", "opath", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "opath", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "opath", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "# load corpus", "\n", "        ", "tkn", "=", "Tokenizer", "(", "num_words", "=", "max_feature", ")", "\n", "tkn", ".", "fit_on_texts", "(", "docs", ")", "\n", "\n", "with", "open", "(", "opath", ",", "'wb'", ")", "as", "wfile", ":", "\n", "            ", "pickle", ".", "dump", "(", "tkn", ",", "wfile", ")", "\n", "", "return", "tkn", "\n", "\n", "\n", "", "", "class", "DataEncoder", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "params", ",", "mtype", "=", "'rnn'", ")", ":", "\n", "        ", "\"\"\"\n\n        :param params:\n        :param mtype: Model type, rnn or bert\n        \"\"\"", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "mtype", "=", "mtype", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "            ", "self", ".", "tok", "=", "pickle", ".", "load", "(", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'.tok'", ")", ",", "'rb'", ")", ")", "\n", "", "elif", "self", ".", "mtype", "==", "'bert'", ":", "\n", "            ", "self", ".", "tok", "=", "BertTokenizer", ".", "from_pretrained", "(", "params", "[", "'bert_name'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Only support BERT and RNN data encoders'", ")", "\n", "\n", "", "", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "docs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "domains", "=", "[", "]", "\n", "for", "text", ",", "label", ",", "domain", "in", "batch", ":", "\n", "            ", "if", "self", ".", "mtype", "==", "'bert'", ":", "\n", "                ", "text", "=", "self", ".", "tok", ".", "encode_plus", "(", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_wt": [[254, 292], ["len", "emb_path.endswith", "numpy.save", "gensim.models.KeyedVectors.load_word2vec_format", "list", "zip", "open", "open.readline().strip().split", "len", "list", "open.close", "numpy.zeros", "len", "open.readline().strip().split", "numpy.zeros", "open", "numpy.asarray", "open.readline().strip", "line.strip().split.strip().split", "open.readline().strip", "numpy.asarray", "float", "open.readline", "line.strip().split.strip", "open.readline", "float"], "function", ["None"], ["return_tensors", "=", "'pt'", ",", "return_token_type_ids", "=", "False", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "docs", ".", "append", "(", "text", "[", "'input_ids'", "]", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "docs", ".", "append", "(", "text", ")", "\n", "", "labels", ".", "append", "(", "label", ")", "\n", "domains", ".", "append", "(", "domain", ")", "\n", "\n", "", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "domains", "=", "torch", ".", "tensor", "(", "domains", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "mtype", "==", "'rnn'", ":", "\n", "# padding and tokenize", "\n", "            ", "docs", "=", "self", ".", "tok", ".", "texts_to_sequences", "(", "docs", ")", "\n", "docs", "=", "pad_sequences", "(", "docs", ")", "\n", "docs", "=", "torch", ".", "Tensor", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "            ", "docs", "=", "torch", ".", "stack", "(", "docs", ")", ".", "long", "(", ")", "\n", "", "return", "docs", ",", "labels", ",", "domains", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.build_tok": [[294, 305], ["os.path.exists", "pickle.load", "keras.preprocessing.text.Tokenizer", "keras.preprocessing.text.Tokenizer.fit_on_texts", "open", "open", "pickle.dump"], "function", ["None"], []], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.lr.build_lr": [[20, 115], ["print", "utils.data_loader", "print", "os.path.join", "os.path.exists", "utils.data_split", "print", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "print", "print", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "sklearn.linear_model.LogisticRegression.predict", "sklearn.metrics.roc_curve", "pickle.load", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit", "pickle.dump", "imblearn.over_sampling.RandomOverSampler", "imblearn.over_sampling.RandomOverSampler.fit_resample", "len", "numpy.random.seed", "list", "numpy.random.shuffle", "open", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.write", "wfile.flush", "open", "set", "open", "range", "nltk.corpus.stopwords.words", "range", "len", "sklearn.linear_model.LogisticRegression.predict_proba", "datetime.datetime.now", "sklearn.metrics.f1_score", "sklearn.metrics.auc", "sklearn.metrics.classification_report", "utils.fair_eval", "len"], "function", ["home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_loader", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.data_split", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.transform", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.model.domain_lr.DomainVectorizer.fit", "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.baseline.utils.fair_eval"], ["def", "build_lr", "(", "params", ")", ":", "\n", "    ", "\"\"\"Obtain Test Results of prediction\n    \"\"\"", "\n", "print", "(", "'Loading Data...'", ")", "\n", "data", "=", "utils", ".", "data_loader", "(", "dpath", "=", "params", "[", "'dpath'", "]", ",", "lang", "=", "params", "[", "'lang'", "]", ")", "\n", "print", "(", "'Building Domain Vectorizer...'", ")", "\n", "\n", "# build vectorizer", "\n", "vect_path", "=", "os", ".", "path", ".", "join", "(", "params", "[", "'model_dir'", "]", ",", "params", "[", "'dname'", "]", "+", "'-lr_vect.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "vect_path", ")", ":", "\n", "        ", "lr_vect", "=", "pickle", ".", "load", "(", "open", "(", "vect_path", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "spw_set", "=", "set", "(", "stopwords", ".", "words", "(", "params", "[", "'lang'", "]", ")", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "spw_set", "=", "None", "\n", "", "lr_vect", "=", "TfidfVectorizer", "(", "\n", "min_df", "=", "3", ",", "max_features", "=", "params", "[", "'max_feature'", "]", ",", "\n", "stop_words", "=", "spw_set", ",", "max_df", "=", "0.9", ",", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "\n", ")", "\n", "lr_vect", ".", "fit", "(", "data", "[", "'docs'", "]", ")", "\n", "pickle", ".", "dump", "(", "lr_vect", ",", "open", "(", "vect_path", ",", "'wb'", ")", ")", "\n", "", "train_indices", ",", "val_indices", ",", "test_indices", "=", "utils", ".", "data_split", "(", "data", ")", "\n", "\n", "# train classifier", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "train_indices", "]", ",", "\n", "}", "\n", "if", "params", "[", "'over_sample'", "]", ":", "\n", "        ", "ros", "=", "RandomOverSampler", "(", "random_state", "=", "33", ")", "\n", "sample_indices", "=", "[", "[", "item", "]", "for", "item", "in", "range", "(", "len", "(", "input_data", "[", "'docs'", "]", ")", ")", "]", "\n", "sample_indices", ",", "_", "=", "ros", ".", "fit_resample", "(", "sample_indices", ",", "input_data", "[", "'labels'", "]", ")", "\n", "sample_indices", "=", "[", "item", "[", "0", "]", "for", "item", "in", "sample_indices", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "sample_indices", "]", ",", "\n", "}", "\n", "\n", "# too large data to fit memory, remove some", "\n", "# training data size: 200000", "\n", "", "if", "len", "(", "input_data", "[", "'docs'", "]", ")", ">", "200000", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "33", ")", "\n", "indices", "=", "list", "(", "range", "(", "len", "(", "input_data", "[", "'docs'", "]", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "indices", "=", "indices", "[", ":", "200000", "]", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "input_data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "'labels'", ":", "[", "input_data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "indices", "]", ",", "\n", "}", "\n", "\n", "", "print", "(", "'Training Classifier...'", ")", "\n", "input_feats", "=", "lr_vect", ".", "transform", "(", "input_data", "[", "'docs'", "]", ")", "\n", "clf", "=", "LogisticRegression", "(", "max_iter", "=", "2000", ",", "n_jobs", "=", "-", "1", ")", "\n", "clf", ".", "fit", "(", "input_feats", ",", "input_data", "[", "'labels'", "]", ")", "\n", "\n", "# load test", "\n", "print", "(", "'Loading Test data'", ")", "\n", "input_data", "=", "{", "\n", "'docs'", ":", "[", "data", "[", "'docs'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "'labels'", ":", "[", "data", "[", "'labels'", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "params", "[", "'domain_name'", "]", ":", "[", "data", "[", "params", "[", "'domain_name'", "]", "]", "[", "item", "]", "for", "item", "in", "test_indices", "]", ",", "\n", "}", "\n", "\n", "print", "(", "'Testing.............................'", ")", "\n", "input_feats", "=", "lr_vect", ".", "transform", "(", "input_data", "[", "'docs'", "]", ")", "\n", "pred_label", "=", "clf", ".", "predict", "(", "input_feats", ")", "\n", "fpr", ",", "tpr", ",", "_", "=", "metrics", ".", "roc_curve", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_score", "=", "clf", ".", "predict_proba", "(", "input_feats", ")", "[", ":", ",", "1", "]", ",", "\n", ")", "\n", "\n", "with", "open", "(", "params", "[", "'result_path'", "]", ",", "'a'", ")", "as", "wfile", ":", "\n", "        ", "wfile", ".", "write", "(", "'{}...............................\\n'", ".", "format", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "wfile", ".", "write", "(", "'Performance Evaluation for the task: {}\\n'", ".", "format", "(", "params", "[", "'dname'", "]", ")", ")", "\n", "wfile", ".", "write", "(", "'F1-weighted score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "f1_score", "(", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "average", "=", "'weighted'", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "'AUC score: {}\\n'", ".", "format", "(", "\n", "metrics", ".", "auc", "(", "fpr", ",", "tpr", ")", "\n", ")", ")", "\n", "wfile", ".", "write", "(", "metrics", ".", "classification_report", "(", "\n", "y_true", "=", "input_data", "[", "'labels'", "]", ",", "y_pred", "=", "pred_label", ",", "digits", "=", "3", ")", "+", "'\\n'", ")", "\n", "wfile", ".", "write", "(", "'\\n'", ")", "\n", "\n", "wfile", ".", "write", "(", "'Fairness Evaluation\\n'", ")", "\n", "wfile", ".", "write", "(", "\n", "utils", ".", "fair_eval", "(", "\n", "true_labels", "=", "input_data", "[", "'labels'", "]", ",", "\n", "pred_labels", "=", "pred_label", ",", "\n", "domain_labels", "=", "input_data", "[", "params", "[", "'domain_name'", "]", "]", "\n", ")", "+", "'\\n'", "\n", ")", "\n", "\n", "wfile", ".", "write", "(", "'...............................\\n\\n'", ")", "\n", "wfile", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaoleihuang_domainfairness.data.trustpilot_extractor.extract_trustpilot": [[9, 94], ["dict", "open", "wfile.write", "open", "wfile.write", "open", "wfile.write", "ast.literal_eval", "str().strip", "ast.literal_eval.get", "gender.strip().lower.strip().lower", "ast.literal_eval.get", "enumerate", "len", "dict", "len", "ast.literal_eval.get", "review.get", "dateutil.parser.parse", "date.strftime.strftime", "text.strip().replace().replace.strip().replace().replace", "str", "wfile.write", "int", "len", "str", "str", "gender.strip().lower.strip", "country.strip.strip().split", "country.strip.strip", "int", "[].append", "str", "numpy.mean", "word.capitalize", "len", "text.strip().replace().replace.strip().replace", "country.strip.strip", "country.strip.split", "text.strip().replace().replace.strip"], "function", ["None"], ["def", "extract_trustpilot", "(", "dpath", ",", "opath", ",", "utable_path", ")", ":", "\n", "    ", "utable", "=", "dict", "(", ")", "\n", "\n", "with", "open", "(", "opath", ",", "'w'", ")", "as", "wfile", ":", "\n", "        ", "wfile", ".", "write", "(", "'\\t'", ".", "join", "(", "\n", "[", "'did'", ",", "'uid'", ",", "'text'", ",", "'date'", ",", "'gender'", ",", "'age'", ",", "'country'", ",", "'label'", "]", "\n", ")", "+", "'\\n'", ")", "\n", "with", "open", "(", "dpath", ")", "as", "dfile", ":", "\n", "            ", "for", "line", "in", "dfile", ":", "\n", "# line = json.loads(line)", "\n", "                ", "line", "=", "ast", ".", "literal_eval", "(", "line", ")", "\n", "uid", "=", "str", "(", "line", "[", "'user_id'", "]", ")", ".", "strip", "(", ")", "\n", "if", "len", "(", "uid", ")", "<", "2", ":", "\n", "                    ", "continue", "\n", "", "if", "uid", "not", "in", "utable", ":", "\n", "                    ", "utable", "[", "uid", "]", "=", "dict", "(", ")", "\n", "utable", "[", "uid", "]", "[", "'age'", "]", "=", "[", "]", "\n", "\n", "", "gender", "=", "line", ".", "get", "(", "'gender'", ",", "''", ")", "\n", "if", "gender", "is", "None", ":", "\n", "                    ", "gender", "=", "'x'", "\n", "", "gender", "=", "gender", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "if", "len", "(", "gender", ")", "==", "0", ":", "\n", "                    ", "gender", "=", "'x'", "\n", "", "utable", "[", "uid", "]", "[", "'gender'", "]", "=", "gender", "\n", "\n", "age", "=", "line", ".", "get", "(", "'birth_year'", ",", "'x'", ")", "\n", "if", "age", "is", "None", ":", "\n", "                    ", "age", "=", "'x'", "\n", "\n", "", "if", "'country'", "in", "line", ":", "\n", "                    ", "country", "=", "line", "[", "'country'", "]", "\n", "if", "country", "is", "None", ":", "\n", "                        ", "country", "=", "'x'", "\n", "", "else", ":", "\n", "                        ", "country", "=", "country", ".", "strip", "(", ")", ".", "split", "(", "'_'", ")", "\n", "country", "=", "[", "word", ".", "capitalize", "(", ")", "for", "word", "in", "country", "]", "\n", "country", "=", "' '", ".", "join", "(", "country", ")", "\n", "", "", "else", ":", "\n", "                    ", "country", "=", "line", ".", "get", "(", "'location'", ",", "'x'", ")", "\n", "if", "country", "is", "None", ":", "\n", "                        ", "country", "=", "'x'", "\n", "", "else", ":", "\n", "                        ", "country", "=", "country", ".", "strip", "(", ")", "\n", "if", "len", "(", "country", ")", "==", "0", ":", "\n", "                            ", "country", "=", "'x'", "\n", "", "else", ":", "\n", "                            ", "country", "=", "country", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "utable", "[", "uid", "]", "[", "'country'", "]", "=", "country", "\n", "\n", "for", "idx", ",", "review", "in", "enumerate", "(", "line", "[", "'reviews'", "]", ")", ":", "\n", "                    ", "date", "=", "review", ".", "get", "(", "'date'", ",", "None", ")", "\n", "if", "date", "is", "None", ":", "\n", "                        ", "continue", "\n", "", "date", "=", "parse", "(", "date", ")", "\n", "if", "age", "!=", "'x'", ":", "\n", "                        ", "age", "=", "int", "(", "age", ")", "\n", "cur_age", "=", "date", ".", "year", "-", "age", "\n", "utable", "[", "uid", "]", "[", "'age'", "]", ".", "append", "(", "cur_age", ")", "\n", "cur_age", "=", "str", "(", "cur_age", ")", "\n", "", "else", ":", "\n", "                        ", "cur_age", "=", "'x'", "\n", "", "date", "=", "date", ".", "strftime", "(", "'%Y-%m-%d'", ")", "\n", "\n", "text", "=", "''", ".", "join", "(", "review", "[", "'text'", "]", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", ".", "replace", "(", "'\\t'", ",", "''", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "did", "=", "'{}_{}'", ".", "format", "(", "review", "[", "'company_id'", "]", ",", "idx", ")", "\n", "label", "=", "str", "(", "review", "[", "'rating'", "]", ")", "\n", "\n", "wfile", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "\n", "did", ",", "uid", ",", "text", ",", "date", ",", "gender", ",", "cur_age", ",", "country", ",", "label", "\n", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "utable", "[", "uid", "]", "[", "'age'", "]", "=", "[", "int", "(", "item", ")", "for", "item", "in", "utable", "[", "uid", "]", "[", "'age'", "]", "if", "item", "!=", "'x'", "]", "\n", "if", "len", "(", "utable", "[", "uid", "]", "[", "'age'", "]", ")", "==", "0", ":", "\n", "                    ", "utable", "[", "uid", "]", "[", "'age'", "]", "=", "'x'", "\n", "", "else", ":", "\n", "                    ", "utable", "[", "uid", "]", "[", "'age'", "]", "=", "str", "(", "np", ".", "mean", "(", "utable", "[", "uid", "]", "[", "'age'", "]", ")", ")", "\n", "\n", "", "", "", "", "with", "open", "(", "utable_path", ",", "'w'", ")", "as", "wfile", ":", "\n", "        ", "wfile", ".", "write", "(", "'uid\\tgender\\tage\\tcountry\\n'", ")", "\n", "for", "uid", "in", "utable", ":", "\n", "            ", "wfile", ".", "write", "(", "'\\t'", ".", "join", "(", "\n", "[", "uid", ",", "utable", "[", "uid", "]", "[", "'gender'", "]", ",", "utable", "[", "uid", "]", "[", "'age'", "]", ",", "utable", "[", "uid", "]", "[", "'country'", "]", "]", "\n", ")", "+", "'\\n'", ")", "\n", "\n"]]}