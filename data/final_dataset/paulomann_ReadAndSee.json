{"home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.plot_evp": [[11, 45], ["expected_max_performance.samplemax", "plot_emp.one_plot", "plot_emp.one_plot", "plot_emp.one_plot", "plot_emp.one_plot"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance.samplemax", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.one_plot", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.one_plot", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.one_plot", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.one_plot"], ["def", "plot_evp", "(", "example_valid_perf", "=", "None", ",", "experiment_name", "=", "\"Experiment Name\"", ")", ":", "\n", "# The N validation accuracies can go here:", "\n", "    ", "if", "example_valid_perf", "is", "None", ":", "\n", "        ", "example_valid_perf", "=", "[", "\n", "0.8", ",", "\n", "0.75", ",", "\n", "0.9", ",", "\n", "0.24", ",", "\n", "0.45", ",", "\n", "0.6", ",", "\n", "0.65", ",", "\n", "0.67", ",", "\n", "0.49", ",", "\n", "0.49", ",", "\n", "0.59", ",", "\n", "0.52", ",", "\n", "0.78", ",", "\n", "0.84", ",", "\n", "0.63", ",", "\n", "0.42", ",", "\n", "0.85", ",", "\n", "0.76", ",", "\n", "0.68", ",", "\n", "0.6", ",", "\n", "]", "\n", "\n", "", "data", "=", "expected_max_performance", ".", "samplemax", "(", "example_valid_perf", ")", "\n", "# In most cases only one plot will be necessary.", "\n", "# These examples are meant to show what the plots look like with and without log-scaling the X-axis and", "\n", "# shading +/- the standard error (similar to standard deviation).", "\n", "one_plot", "(", "data", ",", "experiment_name", ",", "logx", "=", "False", ",", "plot_errorbar", "=", "False", ",", "avg_time", "=", "0", ")", "\n", "one_plot", "(", "data", ",", "experiment_name", ",", "logx", "=", "True", ",", "plot_errorbar", "=", "False", ",", "avg_time", "=", "0", ")", "\n", "one_plot", "(", "data", ",", "experiment_name", ",", "logx", "=", "False", ",", "plot_errorbar", "=", "True", ",", "avg_time", "=", "0", ")", "\n", "one_plot", "(", "data", ",", "experiment_name", ",", "logx", "=", "True", ",", "plot_errorbar", "=", "True", ",", "avg_time", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.plot_emp.one_plot": [[51, 108], ["matplotlib.subplots", "cur_ax.set_title", "cur_ax.set_ylabel", "cur_ax.plot", "cur_ax.get_xlim", "matplotlib.xlim", "matplotlib.locator_params", "matplotlib.tight_layout", "cur_ax.set_xlabel", "cur_ax.set_xlabel", "cur_ax.set_xscale", "matplotlib.fill_between", "cur_ax.errorbar", "range", "range", "len", "len", "zip", "zip"], "function", ["None"], ["", "def", "one_plot", "(", "\n", "data", ",", "\n", "data_name", ",", "\n", "logx", "=", "False", ",", "\n", "plot_errorbar", "=", "True", ",", "\n", "avg_time", "=", "0", ",", "\n", "performance_metric", "=", "\"accuracy\"", ",", "\n", ")", ":", "\n", "# to set default values", "\n", "    ", "linestyle", "=", "\"-\"", "\n", "linewidth", "=", "3", "\n", "errorbar_kind", "=", "\"shade\"", "\n", "errorbar_alpha", "=", "0.1", "\n", "fontsize", "=", "16", "\n", "x_axis_time", "=", "avg_time", "!=", "0", "\n", "\n", "_", ",", "cur_ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ")", "\n", "cur_ax", ".", "set_title", "(", "data_name", ",", "fontsize", "=", "fontsize", ")", "\n", "cur_ax", ".", "set_ylabel", "(", "\"Expected validation \"", "+", "performance_metric", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "if", "x_axis_time", ":", "\n", "        ", "cur_ax", ".", "set_xlabel", "(", "\"Training duration\"", ",", "fontsize", "=", "fontsize", ")", "\n", "", "else", ":", "\n", "        ", "cur_ax", ".", "set_xlabel", "(", "\"Hyperparameter assignments\"", ",", "fontsize", "=", "fontsize", ")", "\n", "\n", "", "if", "logx", ":", "\n", "        ", "cur_ax", ".", "set_xscale", "(", "\"log\"", ")", "\n", "", "means", "=", "data", "[", "\"mean\"", "]", "\n", "vars", "=", "data", "[", "\"var\"", "]", "\n", "max_acc", "=", "data", "[", "\"max\"", "]", "\n", "min_acc", "=", "data", "[", "\"min\"", "]", "\n", "\n", "if", "x_axis_time", ":", "\n", "        ", "x_axis", "=", "[", "avg_time", "*", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "len", "(", "means", ")", ")", "]", "\n", "", "else", ":", "\n", "        ", "x_axis", "=", "[", "i", "+", "1", "for", "i", "in", "range", "(", "len", "(", "means", ")", ")", "]", "\n", "\n", "", "if", "plot_errorbar", ":", "\n", "        ", "if", "errorbar_kind", "==", "\"shade\"", ":", "\n", "            ", "minus_vars", "=", "[", "\n", "x", "-", "y", "if", "(", "x", "-", "y", ")", ">=", "min_acc", "else", "min_acc", "for", "x", ",", "y", "in", "zip", "(", "means", ",", "vars", ")", "\n", "]", "\n", "plus_vars", "=", "[", "\n", "x", "+", "y", "if", "(", "x", "+", "y", ")", "<=", "max_acc", "else", "max_acc", "for", "x", ",", "y", "in", "zip", "(", "means", ",", "vars", ")", "\n", "]", "\n", "plt", ".", "fill_between", "(", "x_axis", ",", "minus_vars", ",", "plus_vars", ",", "alpha", "=", "errorbar_alpha", ")", "\n", "", "else", ":", "\n", "            ", "cur_ax", ".", "errorbar", "(", "\n", "x_axis", ",", "means", ",", "yerr", "=", "vars", ",", "linestyle", "=", "linestyle", ",", "linewidth", "=", "linewidth", "\n", ")", "\n", "", "", "cur_ax", ".", "plot", "(", "x_axis", ",", "means", ",", "linestyle", "=", "linestyle", ",", "linewidth", "=", "linewidth", ")", "\n", "\n", "left", ",", "right", "=", "cur_ax", ".", "get_xlim", "(", ")", "\n", "\n", "plt", ".", "xlim", "(", "(", "left", ",", "right", ")", ")", "\n", "plt", ".", "locator_params", "(", "axis", "=", "\"y\"", ",", "nbins", "=", "10", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance._cdf_with_replacement": [[4, 6], ["None"], "function", ["None"], ["def", "_cdf_with_replacement", "(", "i", ",", "n", ",", "N", ")", ":", "\n", "    ", "return", "(", "i", "/", "N", ")", "**", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance._compute_variance": [[7, 23], ["range", "range", "numpy.sqrt", "variance_of_max_cond_n.append"], "function", ["None"], ["", "def", "_compute_variance", "(", "N", ",", "cur_data", ",", "expected_max_cond_n", ",", "pdfs", ")", ":", "\n", "    ", "\"\"\"\n    this computes the standard error of the max.\n    this is what the std dev of the bootstrap estimates of the mean of the max converges to, as\n    is stated in the last sentence of the summary on page 10 of \n    http://www.stat.cmu.edu/~larry/=stat705/Lecture13.pdf\n    \"\"\"", "\n", "variance_of_max_cond_n", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "N", ")", ":", "\n", "# for a given n, estimate variance with \\sum(p(x) * (x-mu)^2), where mu is \\sum(p(x) * x).", "\n", "        ", "cur_var", "=", "0", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "cur_var", "+=", "(", "cur_data", "[", "i", "]", "-", "expected_max_cond_n", "[", "n", "]", ")", "**", "2", "*", "pdfs", "[", "n", "]", "[", "i", "]", "\n", "", "cur_var", "=", "np", ".", "sqrt", "(", "cur_var", ")", "\n", "variance_of_max_cond_n", ".", "append", "(", "cur_var", ")", "\n", "", "return", "variance_of_max_cond_n", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance.samplemax": [[26, 59], ["list", "list.sort", "len", "range", "range", "expected_max_performance._compute_variance", "range", "range", "pdfs.append", "range", "expected_max_cond_n.append", "numpy.max", "numpy.min", "F_Y_of_y.append", "len", "f_Y_of_y.append", "expected_max_performance._cdf_with_replacement"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance._compute_variance", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.notebooks.expected_max_performance._cdf_with_replacement"], ["", "def", "samplemax", "(", "validation_performance", ")", ":", "\n", "    ", "validation_performance", "=", "list", "(", "validation_performance", ")", "\n", "validation_performance", ".", "sort", "(", ")", "\n", "N", "=", "len", "(", "validation_performance", ")", "\n", "pdfs", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "N", "+", "1", ")", ":", "\n", "# the CDF of the max", "\n", "        ", "F_Y_of_y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "N", "+", "1", ")", ":", "\n", "            ", "F_Y_of_y", ".", "append", "(", "_cdf_with_replacement", "(", "i", ",", "n", ",", "N", ")", ")", "\n", "\n", "\n", "", "f_Y_of_y", "=", "[", "]", "\n", "cur_cdf_val", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "F_Y_of_y", ")", ")", ":", "\n", "            ", "f_Y_of_y", ".", "append", "(", "F_Y_of_y", "[", "i", "]", "-", "cur_cdf_val", ")", "\n", "cur_cdf_val", "=", "F_Y_of_y", "[", "i", "]", "\n", "\n", "", "pdfs", ".", "append", "(", "f_Y_of_y", ")", "\n", "\n", "", "expected_max_cond_n", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "N", ")", ":", "\n", "# for a given n, estimate expected value with \\sum(x * p(x)), where p(x) is prob x is max.", "\n", "        ", "cur_expected", "=", "0", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "cur_expected", "+=", "validation_performance", "[", "i", "]", "*", "pdfs", "[", "n", "]", "[", "i", "]", "\n", "", "expected_max_cond_n", ".", "append", "(", "cur_expected", ")", "\n", "\n", "\n", "", "var_of_max_cond_n", "=", "_compute_variance", "(", "N", ",", "validation_performance", ",", "expected_max_cond_n", ",", "pdfs", ")", "\n", "\n", "return", "{", "\"mean\"", ":", "expected_max_cond_n", ",", "\"var\"", ":", "var_of_max_cond_n", ",", "\"max\"", ":", "np", ".", "max", "(", "validation_performance", ")", ",", "\n", "\"min\"", ":", "np", ".", "min", "(", "validation_performance", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_only.get_dataset": [[17, 20], ["transformers.LineByLineTextDataset"], "function", ["None"], ["def", "get_dataset", "(", "file_path", ":", "Path", ",", "tokenizer", ":", "BertTokenizer", ")", "->", "LineByLineTextDataset", ":", "\n", "# block_size = the number of tokens we are going to use for the sequence.", "\n", "    ", "return", "LineByLineTextDataset", "(", "tokenizer", "=", "tokenizer", ",", "file_path", "=", "file_path", ",", "block_size", "=", "150", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_only.get_data_collator": [[22, 29], ["transformers.DataCollatorForLanguageModeling"], "function", ["None"], ["", "def", "get_data_collator", "(", "\n", "tokenizer", ":", "BertTokenizer", ",", "mlm", ":", "bool", "=", "True", ",", "mlm_prob", ":", "float", "=", "0.15", "\n", ")", "->", "DataCollatorForLanguageModeling", ":", "\n", "    ", "data_collator", "=", "DataCollatorForLanguageModeling", "(", "\n", "tokenizer", "=", "tokenizer", ",", "mlm", "=", "mlm", ",", "mlm_probability", "=", "mlm_prob", "\n", ")", "\n", "return", "data_collator", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.stream_tweets_without_hashtags.StdOutListener.on_data": [[60, 75], ["json.loads", "json.loads.get().get", "json.loads.get().replace().replace().replace().strip", "json.loads.get", "json.loads.get", "json.loads.get", "json.loads.get", "len", "original_file.write", "json.loads.get().replace().replace().replace", "json.loads.get().replace().replace", "json.loads.get().replace", "json.loads.get"], "methods", ["None"], ["def", "on_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "global", "PUT_TO_SLEEP", "\n", "PUT_TO_SLEEP", "=", "False", "\n", "json_obj", "=", "json", ".", "loads", "(", "data", ")", "\n", "hashtags", "=", "json_obj", ".", "get", "(", "\"entities\"", ",", "{", "}", ")", ".", "get", "(", "\"hashtags\"", ",", "[", "]", ")", "\n", "if", "(", "not", "json_obj", ".", "get", "(", "\"retweeted\"", ",", "False", ")", "\n", "and", "not", "json_obj", ".", "get", "(", "\"truncated\"", ",", "False", ")", "\n", "and", "json_obj", ".", "get", "(", "\"retweeted_status\"", ",", "None", ")", "is", "None", "\n", "and", "len", "(", "hashtags", ")", "==", "0", ")", ":", "\n", "\n", "            ", "text", "=", "json_obj", ".", "get", "(", "\"text\"", ",", "\"\"", ")", ".", "replace", "(", "\n", "'\\r'", ",", "''", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "replace", "(", "'\t'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "if", "text", ":", "\n", "                ", "original_file", ".", "write", "(", "text", "+", "\"\\n\"", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.stream_tweets_without_hashtags.StdOutListener.on_error": [[76, 80], ["None"], "methods", ["None"], ["", "def", "on_error", "(", "self", ",", "status", ")", ":", "\n", "        ", "if", "status", "==", "420", ":", "\n", "            ", "global", "PUT_TO_SLEEP", "\n", "PUT_TO_SLEEP", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.stream_tweets_without_hashtags.get_twitter_auth": [[82, 101], ["dotenv.find_dotenv", "dotenv.load_dotenv", "os.environ.get", "os.environ.get", "os.environ.get", "os.environ.get", "tweepy.OAuthHandler", "tweepy.OAuthHandler.set_access_token", "print", "sys.exit"], "function", ["None"], ["", "", "", "def", "get_twitter_auth", "(", ")", ":", "\n", "\n", "    ", "env_variables_path", "=", "config", ".", "ENV_VARIABLES", "\n", "dotenv_path", "=", "find_dotenv", "(", "env_variables_path", ")", "\n", "load_dotenv", "(", "dotenv_path", ")", "\n", "\n", "try", ":", "\n", "        ", "CONSUMER_KEY", "=", "os", ".", "environ", ".", "get", "(", "\"TWITTER_CONSUMER_KEY\"", ")", "\n", "CONSUMER_SECRET", "=", "os", ".", "environ", ".", "get", "(", "\"TWITTER_CONSUMER_SECRET\"", ")", "\n", "ACCESS_TOKEN", "=", "os", ".", "environ", ".", "get", "(", "\"TWITTER_ACCESS_TOKEN\"", ")", "\n", "ACCESS_SECRET", "=", "os", ".", "environ", ".", "get", "(", "\"TWITTER_ACCESS_SECRET\"", ")", "\n", "auth", "=", "OAuthHandler", "(", "CONSUMER_KEY", ",", "CONSUMER_SECRET", ")", "\n", "auth", ".", "set_access_token", "(", "ACCESS_TOKEN", ",", "ACCESS_SECRET", ")", "\n", "\n", "", "except", "KeyError", ":", "\n", "        ", "print", "(", "\"TWITTER_* environment variables not set\\n\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "return", "auth", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.__init__": [[15, 32], ["tempfile.TemporaryDirectory", "pathlib.Path", "shelve.open", "str"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "reduce_memory", "=", "False", ")", ":", "\n", "        ", "if", "reduce_memory", ":", "\n", "            ", "self", ".", "temp_dir", "=", "TemporaryDirectory", "(", ")", "\n", "self", ".", "working_dir", "=", "Path", "(", "self", ".", "temp_dir", ".", "name", ")", "\n", "self", ".", "document_shelf_filepath", "=", "self", ".", "working_dir", "/", "'shelf.db'", "\n", "self", ".", "document_shelf", "=", "shelve", ".", "open", "(", "str", "(", "self", ".", "document_shelf_filepath", ")", ",", "\n", "flag", "=", "'n'", ",", "protocol", "=", "-", "1", ")", "\n", "self", ".", "documents", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "documents", "=", "[", "]", "\n", "self", ".", "document_shelf", "=", "None", "\n", "self", ".", "document_shelf_filepath", "=", "None", "\n", "self", ".", "temp_dir", "=", "None", "\n", "", "self", ".", "doc_lengths", "=", "[", "]", "\n", "self", ".", "doc_cumsum", "=", "None", "\n", "self", ".", "cumsum_max", "=", "None", "\n", "self", ".", "reduce_memory", "=", "reduce_memory", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.add_document": [[33, 42], ["pregenerate_training_data.DocumentDatabase.doc_lengths.append", "len", "pregenerate_training_data.DocumentDatabase.documents.append", "len", "str"], "methods", ["None"], ["", "def", "add_document", "(", "self", ",", "document", ")", ":", "\n", "        ", "if", "not", "document", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "reduce_memory", ":", "\n", "            ", "current_idx", "=", "len", "(", "self", ".", "doc_lengths", ")", "\n", "self", ".", "document_shelf", "[", "str", "(", "current_idx", ")", "]", "=", "document", "\n", "", "else", ":", "\n", "            ", "self", ".", "documents", ".", "append", "(", "document", ")", "\n", "", "self", ".", "doc_lengths", ".", "append", "(", "len", "(", "document", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase._precalculate_doc_weights": [[43, 46], ["numpy.cumsum"], "methods", ["None"], ["", "def", "_precalculate_doc_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "doc_cumsum", "=", "np", ".", "cumsum", "(", "self", ".", "doc_lengths", ")", "\n", "self", ".", "cumsum_max", "=", "self", ".", "doc_cumsum", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.sample_doc": [[47, 65], ["numpy.searchsorted", "pregenerate_training_data.DocumentDatabase._precalculate_doc_weights", "random.random.randrange", "len", "len", "len", "random.random.randrange", "str", "len"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase._precalculate_doc_weights"], ["", "def", "sample_doc", "(", "self", ",", "current_idx", ",", "sentence_weighted", "=", "True", ")", ":", "\n", "# Uses the current iteration counter to ensure we don't sample the same doc twice", "\n", "        ", "if", "sentence_weighted", ":", "\n", "# With sentence weighting, we sample docs proportionally to their sentence length", "\n", "            ", "if", "self", ".", "doc_cumsum", "is", "None", "or", "len", "(", "self", ".", "doc_cumsum", ")", "!=", "len", "(", "self", ".", "doc_lengths", ")", ":", "\n", "                ", "self", ".", "_precalculate_doc_weights", "(", ")", "\n", "", "rand_start", "=", "self", ".", "doc_cumsum", "[", "current_idx", "]", "\n", "rand_end", "=", "rand_start", "+", "self", ".", "cumsum_max", "-", "self", ".", "doc_lengths", "[", "current_idx", "]", "\n", "sentence_index", "=", "randrange", "(", "rand_start", ",", "rand_end", ")", "%", "self", ".", "cumsum_max", "\n", "sampled_doc_index", "=", "np", ".", "searchsorted", "(", "self", ".", "doc_cumsum", ",", "sentence_index", ",", "side", "=", "'right'", ")", "\n", "", "else", ":", "\n", "# If we don't use sentence weighting, then every doc has an equal chance to be chosen", "\n", "            ", "sampled_doc_index", "=", "(", "current_idx", "+", "randrange", "(", "1", ",", "len", "(", "self", ".", "doc_lengths", ")", ")", ")", "%", "len", "(", "self", ".", "doc_lengths", ")", "\n", "", "assert", "sampled_doc_index", "!=", "current_idx", "\n", "if", "self", ".", "reduce_memory", ":", "\n", "            ", "return", "self", ".", "document_shelf", "[", "str", "(", "sampled_doc_index", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "documents", "[", "sampled_doc_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.__len__": [[66, 68], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "doc_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.__getitem__": [[69, 74], ["str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "self", ".", "reduce_memory", ":", "\n", "            ", "return", "self", ".", "document_shelf", "[", "str", "(", "item", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "documents", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.__enter__": [[75, 77], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.__exit__": [[78, 83], ["pregenerate_training_data.DocumentDatabase.document_shelf.close", "pregenerate_training_data.DocumentDatabase.temp_dir.cleanup"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "traceback", ")", ":", "\n", "        ", "if", "self", ".", "document_shelf", "is", "not", "None", ":", "\n", "            ", "self", ".", "document_shelf", ".", "close", "(", ")", "\n", "", "if", "self", ".", "temp_dir", "is", "not", "None", ":", "\n", "            ", "self", ".", "temp_dir", ".", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.truncate_seq_pair": [[85, 101], ["len", "len", "len", "random.random", "trunc_tokens.pop", "len", "len"], "function", ["None"], ["", "", "", "def", "truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_num_tokens", ")", ":", "\n", "    ", "\"\"\"Truncates a pair of sequences to a maximum sequence length. Lifted from Google's BERT repo.\"\"\"", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_num_tokens", ":", "\n", "            ", "break", "\n", "\n", "", "trunc_tokens", "=", "tokens_a", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", "else", "tokens_b", "\n", "assert", "len", "(", "trunc_tokens", ")", ">=", "1", "\n", "\n", "# We want to sometimes truncate from the front and sometimes from the", "\n", "# back to add more randomness and avoid biases.", "\n", "if", "random", "(", ")", "<", "0.5", ":", "\n", "            ", "del", "trunc_tokens", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "trunc_tokens", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_masked_lm_predictions": [[105, 168], ["enumerate", "min", "random.shuffle", "set", "sorted", "max", "len", "token.startswith", "cand_indices[].append", "cand_indices.append", "int", "len", "set.add", "sorted.append", "len", "round", "len", "len", "random.random", "MaskedLmInstance", "random.random", "random.choice", "len"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add"], ["def", "create_masked_lm_predictions", "(", "tokens", ",", "masked_lm_prob", ",", "max_predictions_per_seq", ",", "whole_word_mask", ",", "vocab_list", ")", ":", "\n", "    ", "\"\"\"Creates the predictions for the masked LM objective. This is mostly copied from the Google BERT repo, but\n    with several refactors to clean it up and remove a lot of unnecessary variables.\"\"\"", "\n", "cand_indices", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "if", "token", "==", "\"[CLS]\"", "or", "token", "==", "\"[SEP]\"", ":", "\n", "            ", "continue", "\n", "# Whole Word Masking means that if we mask all of the wordpieces", "\n", "# corresponding to an original word. When a word has been split into", "\n", "# WordPieces, the first token does not have any marker and any subsequence", "\n", "# tokens are prefixed with ##. So whenever we see the ## token, we", "\n", "# append it to the previous set of word indexes.", "\n", "#", "\n", "# Note that Whole Word Masking does *not* change the training code", "\n", "# at all -- we still predict each WordPiece independently, softmaxed", "\n", "# over the entire vocabulary.", "\n", "", "if", "(", "whole_word_mask", "and", "len", "(", "cand_indices", ")", ">=", "1", "and", "token", ".", "startswith", "(", "\"##\"", ")", ")", ":", "\n", "            ", "cand_indices", "[", "-", "1", "]", ".", "append", "(", "i", ")", "\n", "", "else", ":", "\n", "            ", "cand_indices", ".", "append", "(", "[", "i", "]", ")", "\n", "\n", "", "", "num_to_mask", "=", "min", "(", "max_predictions_per_seq", ",", "\n", "max", "(", "1", ",", "int", "(", "round", "(", "len", "(", "tokens", ")", "*", "masked_lm_prob", ")", ")", ")", ")", "\n", "shuffle", "(", "cand_indices", ")", "\n", "masked_lms", "=", "[", "]", "\n", "covered_indexes", "=", "set", "(", ")", "\n", "for", "index_set", "in", "cand_indices", ":", "\n", "        ", "if", "len", "(", "masked_lms", ")", ">=", "num_to_mask", ":", "\n", "            ", "break", "\n", "# If adding a whole-word mask would exceed the maximum number of", "\n", "# predictions, then just skip this candidate.", "\n", "", "if", "len", "(", "masked_lms", ")", "+", "len", "(", "index_set", ")", ">", "num_to_mask", ":", "\n", "            ", "continue", "\n", "", "is_any_index_covered", "=", "False", "\n", "for", "index", "in", "index_set", ":", "\n", "            ", "if", "index", "in", "covered_indexes", ":", "\n", "                ", "is_any_index_covered", "=", "True", "\n", "break", "\n", "", "", "if", "is_any_index_covered", ":", "\n", "            ", "continue", "\n", "", "for", "index", "in", "index_set", ":", "\n", "            ", "covered_indexes", ".", "add", "(", "index", ")", "\n", "\n", "masked_token", "=", "None", "\n", "# 80% of the time, replace with [MASK]", "\n", "if", "random", "(", ")", "<", "0.8", ":", "\n", "                ", "masked_token", "=", "\"[MASK]\"", "\n", "", "else", ":", "\n", "# 10% of the time, keep original", "\n", "                ", "if", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "masked_token", "=", "tokens", "[", "index", "]", "\n", "# 10% of the time, replace with random word", "\n", "", "else", ":", "\n", "                    ", "masked_token", "=", "choice", "(", "vocab_list", ")", "\n", "", "", "masked_lms", ".", "append", "(", "MaskedLmInstance", "(", "index", "=", "index", ",", "label", "=", "tokens", "[", "index", "]", ")", ")", "\n", "tokens", "[", "index", "]", "=", "masked_token", "\n", "\n", "", "", "assert", "len", "(", "masked_lms", ")", "<=", "num_to_mask", "\n", "masked_lms", "=", "sorted", "(", "masked_lms", ",", "key", "=", "lambda", "x", ":", "x", ".", "index", ")", "\n", "mask_indices", "=", "[", "p", ".", "index", "for", "p", "in", "masked_lms", "]", "\n", "masked_token_labels", "=", "[", "p", ".", "label", "for", "p", "in", "masked_lms", "]", "\n", "\n", "return", "tokens", ",", "mask_indices", ",", "masked_token_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_instances_from_document": [[170, 266], ["random.random", "random.randint", "len", "current_chunk.append", "len", "range", "pregenerate_training_data.truncate_seq_pair", "pregenerate_training_data.create_masked_lm_predictions", "instances.append", "len", "len", "random.randrange", "tokens_a.extend", "doc_database.sample_doc", "random.randrange", "range", "range", "len", "len", "len", "len", "random.random", "len", "len", "len", "tokens_b.extend", "len", "len", "tokens_b.extend", "len", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.truncate_seq_pair", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_masked_lm_predictions", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.sample_doc"], ["", "def", "create_instances_from_document", "(", "\n", "doc_database", ",", "doc_idx", ",", "max_seq_length", ",", "short_seq_prob", ",", "\n", "masked_lm_prob", ",", "max_predictions_per_seq", ",", "whole_word_mask", ",", "vocab_list", ")", ":", "\n", "    ", "\"\"\"This code is mostly a duplicate of the equivalent function from Google BERT's repo.\n    However, we make some changes and improvements. Sampling is improved and no longer requires a loop in this function.\n    Also, documents are sampled proportionally to the number of sentences they contain, which means each sentence\n    (rather than each document) has an equal chance of being sampled as a false example for the NextSentence task.\"\"\"", "\n", "document", "=", "doc_database", "[", "doc_idx", "]", "\n", "# Account for [CLS], [SEP], [SEP]", "\n", "max_num_tokens", "=", "max_seq_length", "-", "3", "\n", "\n", "# We *usually* want to fill up the entire sequence since we are padding", "\n", "# to `max_seq_length` anyways, so short sequences are generally wasted", "\n", "# computation. However, we *sometimes*", "\n", "# (i.e., short_seq_prob == 0.1 == 10% of the time) want to use shorter", "\n", "# sequences to minimize the mismatch between pre-training and fine-tuning.", "\n", "# The `target_seq_length` is just a rough target however, whereas", "\n", "# `max_seq_length` is a hard limit.", "\n", "target_seq_length", "=", "max_num_tokens", "\n", "if", "random", "(", ")", "<", "short_seq_prob", ":", "\n", "        ", "target_seq_length", "=", "randint", "(", "2", ",", "max_num_tokens", ")", "\n", "\n", "# We DON'T just concatenate all of the tokens from a document into a long", "\n", "# sequence and choose an arbitrary split point because this would make the", "\n", "# next sentence prediction task too easy. Instead, we split the input into", "\n", "# segments \"A\" and \"B\" based on the actual \"sentences\" provided by the user", "\n", "# input.", "\n", "", "instances", "=", "[", "]", "\n", "current_chunk", "=", "[", "]", "\n", "current_length", "=", "0", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "document", ")", ":", "\n", "        ", "segment", "=", "document", "[", "i", "]", "\n", "current_chunk", ".", "append", "(", "segment", ")", "\n", "current_length", "+=", "len", "(", "segment", ")", "\n", "if", "i", "==", "len", "(", "document", ")", "-", "1", "or", "current_length", ">=", "target_seq_length", ":", "\n", "            ", "if", "current_chunk", ":", "\n", "# `a_end` is how many segments from `current_chunk` go into the `A`", "\n", "# (first) sentence.", "\n", "                ", "a_end", "=", "1", "\n", "if", "len", "(", "current_chunk", ")", ">=", "2", ":", "\n", "                    ", "a_end", "=", "randrange", "(", "1", ",", "len", "(", "current_chunk", ")", ")", "\n", "\n", "", "tokens_a", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "a_end", ")", ":", "\n", "                    ", "tokens_a", ".", "extend", "(", "current_chunk", "[", "j", "]", ")", "\n", "\n", "", "tokens_b", "=", "[", "]", "\n", "\n", "# Random next", "\n", "if", "len", "(", "current_chunk", ")", "==", "1", "or", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "is_random_next", "=", "True", "\n", "target_b_length", "=", "target_seq_length", "-", "len", "(", "tokens_a", ")", "\n", "\n", "# Sample a random document, with longer docs being sampled more frequently", "\n", "random_document", "=", "doc_database", ".", "sample_doc", "(", "current_idx", "=", "doc_idx", ",", "sentence_weighted", "=", "True", ")", "\n", "\n", "random_start", "=", "randrange", "(", "0", ",", "len", "(", "random_document", ")", ")", "\n", "for", "j", "in", "range", "(", "random_start", ",", "len", "(", "random_document", ")", ")", ":", "\n", "                        ", "tokens_b", ".", "extend", "(", "random_document", "[", "j", "]", ")", "\n", "if", "len", "(", "tokens_b", ")", ">=", "target_b_length", ":", "\n", "                            ", "break", "\n", "# We didn't actually use these segments so we \"put them back\" so", "\n", "# they don't go to waste.", "\n", "", "", "num_unused_segments", "=", "len", "(", "current_chunk", ")", "-", "a_end", "\n", "i", "-=", "num_unused_segments", "\n", "# Actual next", "\n", "", "else", ":", "\n", "                    ", "is_random_next", "=", "False", "\n", "for", "j", "in", "range", "(", "a_end", ",", "len", "(", "current_chunk", ")", ")", ":", "\n", "                        ", "tokens_b", ".", "extend", "(", "current_chunk", "[", "j", "]", ")", "\n", "", "", "truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_num_tokens", ")", "\n", "\n", "assert", "len", "(", "tokens_a", ")", ">=", "1", "\n", "assert", "len", "(", "tokens_b", ")", ">=", "1", "\n", "\n", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "+", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "# The segment IDs are 0 for the [CLS] token, the A tokens and the first [SEP]", "\n", "# They are 1 for the B tokens and the final [SEP]", "\n", "segment_ids", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "tokens_a", ")", "+", "2", ")", "]", "+", "[", "1", "for", "_", "in", "range", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "]", "\n", "\n", "tokens", ",", "masked_lm_positions", ",", "masked_lm_labels", "=", "create_masked_lm_predictions", "(", "\n", "tokens", ",", "masked_lm_prob", ",", "max_predictions_per_seq", ",", "whole_word_mask", ",", "vocab_list", ")", "\n", "\n", "instance", "=", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"segment_ids\"", ":", "segment_ids", ",", "\n", "\"is_random_next\"", ":", "is_random_next", ",", "\n", "\"masked_lm_positions\"", ":", "masked_lm_positions", ",", "\n", "\"masked_lm_labels\"", ":", "masked_lm_labels", "}", "\n", "instances", ".", "append", "(", "instance", ")", "\n", "", "current_chunk", "=", "[", "]", "\n", "current_length", "=", "0", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_training_file": [[268, 288], ["epoch_filename.open", "tqdm.trange", "metrics_file.open", "metrics_file.write", "len", "pregenerate_training_data.create_instances_from_document", "json.dumps", "json.dumps", "epoch_file.write"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_instances_from_document"], ["", "def", "create_training_file", "(", "docs", ",", "vocab_list", ",", "args", ",", "epoch_num", ")", ":", "\n", "    ", "epoch_filename", "=", "args", ".", "output_dir", "/", "\"epoch_{}.json\"", ".", "format", "(", "epoch_num", ")", "\n", "num_instances", "=", "0", "\n", "with", "epoch_filename", ".", "open", "(", "'w'", ")", "as", "epoch_file", ":", "\n", "        ", "for", "doc_idx", "in", "trange", "(", "len", "(", "docs", ")", ",", "desc", "=", "\"Document\"", ")", ":", "\n", "            ", "doc_instances", "=", "create_instances_from_document", "(", "\n", "docs", ",", "doc_idx", ",", "max_seq_length", "=", "args", ".", "max_seq_len", ",", "short_seq_prob", "=", "args", ".", "short_seq_prob", ",", "\n", "masked_lm_prob", "=", "args", ".", "masked_lm_prob", ",", "max_predictions_per_seq", "=", "args", ".", "max_predictions_per_seq", ",", "\n", "whole_word_mask", "=", "args", ".", "do_whole_word_mask", ",", "vocab_list", "=", "vocab_list", ")", "\n", "doc_instances", "=", "[", "json", ".", "dumps", "(", "instance", ")", "for", "instance", "in", "doc_instances", "]", "\n", "for", "instance", "in", "doc_instances", ":", "\n", "                ", "epoch_file", ".", "write", "(", "instance", "+", "'\\n'", ")", "\n", "num_instances", "+=", "1", "\n", "", "", "", "metrics_file", "=", "args", ".", "output_dir", "/", "\"epoch_{}_metrics.json\"", ".", "format", "(", "epoch_num", ")", "\n", "with", "metrics_file", ".", "open", "(", "'w'", ")", "as", "metrics_file", ":", "\n", "        ", "metrics", "=", "{", "\n", "\"num_training_examples\"", ":", "num_instances", ",", "\n", "\"max_seq_len\"", ":", "args", ".", "max_seq_len", "\n", "}", "\n", "metrics_file", ".", "write", "(", "json", ".", "dumps", "(", "metrics", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.main": [[290, 349], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained", "list", "ValueError", "BertTokenizer.from_pretrained.vocab.keys", "pregenerate_training_data.DocumentDatabase", "parser.parse_args.output_dir.mkdir", "parser.parse_args.train_corpus.open", "tqdm.tqdm", "len", "exit", "multiprocessing.Pool", "multiprocessing.Pool.starmap", "tqdm.trange", "line.strip.strip", "docs.add_document", "min", "pregenerate_training_data.create_training_file", "docs.add_document", "BertTokenizer.from_pretrained.tokenize", "doc.append", "range"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.add_document", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.create_training_file", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.pregenerate_training_data.DocumentDatabase.add_document", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--train_corpus'", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_whole_word_mask\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use whole word masking rather than per-WordPiece masking.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--reduce_memory\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reduce memory usage for large datasets by keeping data on disc rather than in memory\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"The number of workers to use to write the files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs_to_generate\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"Number of epochs of data to pregenerate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_len\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--short_seq_prob\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"Probability of making a short sentence as a training example\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--masked_lm_prob\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Probability of masking each token for the LM task\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_predictions_per_seq\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "\"Maximum number of tokens to mask in each sequence\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "num_workers", ">", "1", "and", "args", ".", "reduce_memory", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot use multiple workers while reducing memory\"", ")", "\n", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "vocab_list", "=", "list", "(", "tokenizer", ".", "vocab", ".", "keys", "(", ")", ")", "\n", "with", "DocumentDatabase", "(", "reduce_memory", "=", "args", ".", "reduce_memory", ")", "as", "docs", ":", "\n", "        ", "with", "args", ".", "train_corpus", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "doc", "=", "[", "]", "\n", "for", "line", "in", "tqdm", "(", "f", ",", "desc", "=", "\"Loading Dataset\"", ",", "unit", "=", "\" lines\"", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                    ", "docs", ".", "add_document", "(", "doc", ")", "\n", "doc", "=", "[", "]", "\n", "", "else", ":", "\n", "                    ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "line", ")", "\n", "doc", ".", "append", "(", "tokens", ")", "\n", "", "", "if", "doc", ":", "\n", "                ", "docs", ".", "add_document", "(", "doc", ")", "# If the last doc didn't end on a newline, make sure it still gets added", "\n", "", "", "if", "len", "(", "docs", ")", "<=", "1", ":", "\n", "            ", "exit", "(", "\"ERROR: No document breaks were found in the input file! These are necessary to allow the script to \"", "\n", "\"ensure that random NextSentences are not sampled from the same document. Please add blank lines to \"", "\n", "\"indicate breaks between documents in your input file. If your dataset does not contain multiple \"", "\n", "\"documents, blank lines can be inserted at any natural boundary, such as the ends of chapters, \"", "\n", "\"sections or paragraphs.\"", ")", "\n", "\n", "", "args", ".", "output_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", ".", "num_workers", ">", "1", ":", "\n", "            ", "writer_workers", "=", "Pool", "(", "min", "(", "args", ".", "num_workers", ",", "args", ".", "epochs_to_generate", ")", ")", "\n", "arguments", "=", "[", "(", "docs", ",", "vocab_list", ",", "args", ",", "idx", ")", "for", "idx", "in", "range", "(", "args", ".", "epochs_to_generate", ")", "]", "\n", "writer_workers", ".", "starmap", "(", "create_training_file", ",", "arguments", ")", "\n", "", "else", ":", "\n", "            ", "for", "epoch", "in", "trange", "(", "args", ".", "epochs_to_generate", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "                ", "create_training_file", "(", "docs", ",", "vocab_list", ",", "args", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.scrape_data": [[7, 19], ["subprocess.Popen", "subprocess.Popen.wait"], "function", ["None"], ["def", "scrape_data", "(", "instagram_scraper", ",", "u_file", ",", "destination_path", ")", ":", "\n", "    ", "login", "=", "instagram_scraper", ".", "login", "\n", "password", "=", "instagram_scraper", ".", "password", "\n", "\"\"\" Create a console that runs the cmd_string command to scrape data. \"\"\"", "\n", "cmd_string", "=", "'instagram-scraper -f {0} -d {1} -n -u {2} -p {3} \\\n    --retry-forever --media-metadata -t image --profile-metadata'", ".", "format", "(", "u_file", ",", "destination_path", ",", "login", ",", "password", ")", "\n", "\n", "cmd_string", "=", "cmd_string", "+", "r' -T {urlname}'", "\n", "\n", "process", "=", "Popen", "(", "cmd_string", ",", "shell", "=", "True", ")", "\n", "process", ".", "wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.create_temp_file": [[21, 34], ["open", "f.write"], "function", ["None"], ["", "def", "create_temp_file", "(", "usernames", ")", ":", "\n", "    ", "\"\"\" Create temporary file with Instagram usernames.\n\n    We need this in order to feed the cmd_string for as the line argument,\n    since it needs a file path.\n\n    Return:\n    path -- path of the created file\n    \"\"\"", "\n", "with", "open", "(", "\".temp\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "item", "in", "usernames", ":", "\n", "            ", "f", ".", "write", "(", "\"%s\\n\"", "%", "item", ")", "\n", "", "", "return", "\".temp\"", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.delete_temp_file": [[36, 38], ["os.remove"], "function", ["None"], ["", "def", "delete_temp_file", "(", "file", ")", ":", "\n", "    ", "os", ".", "remove", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.main": [[40, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "readorsee.data.facade.InstagramScraperFacade", "facade.InstagramScraperFacade.get_non_scraped_users", "data_scraping.create_temp_file", "os.path.abspath", "os.path.join", "print", "data_scraping.scrape_data", "data_scraping.delete_temp_file", "data_scraping.delete_temp_file"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.get_non_scraped_users", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.create_temp_file", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.scrape_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.delete_temp_file", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.data_scraping.delete_temp_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"\"\" This is a simple algorithm to scrape Instagram\n                        User data. This algorithm downloads data from\n                        ReadOrSee/data/raw usersnames, excluding\n                        duplicates.\"\"\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--last\"", ",", "help", "=", "\"\"\"This will continue the data\n                                        scraping from the last downloaded\n                                        user.\"\"\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "required", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "last", ":", "\n", "        ", "instagram_scraper", "=", "facade", ".", "InstagramScraperFacade", "(", ")", "\n", "usernames_to_scrape", "=", "instagram_scraper", ".", "get_non_scraped_users", "(", ")", "\n", "u_file", "=", "create_temp_file", "(", "usernames_to_scrape", ")", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "__file__", ")", "\n", "destination_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"..\"", ",", "\"..\"", ",", "\"data\"", ",", "\n", "\"external\"", ",", "\"instagram\"", ")", "\n", "try", ":", "\n", "            ", "scrape_data", "(", "instagram_scraper", ",", "u_file", ",", "destination_path", ")", "\n", "delete_temp_file", "(", "u_file", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "delete_temp_file", "(", "u_file", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"Nothing to update.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.PregeneratedDataset.__init__": [[60, 113], ["json.loads", "logging.info", "logging.info", "data_file.is_file", "metrics_file.is_file", "metrics_file.read_text", "tempfile.TemporaryDirectory", "pathlib.Path", "numpy.memmap", "numpy.memmap", "numpy.memmap", "numpy.memmap", "numpy.memmap", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "data_file.open", "enumerate", "tqdm.tqdm.tqdm", "line.strip.strip.strip", "json.loads", "tapt_bert_mlm_nsp.convert_example_to_features"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.convert_example_to_features"], ["    ", "def", "__init__", "(", "self", ",", "training_path", ",", "epoch", ",", "tokenizer", ",", "num_data_epochs", ",", "reduce_memory", "=", "False", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "tokenizer", ".", "vocab", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "data_epoch", "=", "epoch", "%", "num_data_epochs", "\n", "data_file", "=", "training_path", "/", "f\"epoch_{self.data_epoch}.json\"", "\n", "metrics_file", "=", "training_path", "/", "f\"epoch_{self.data_epoch}_metrics.json\"", "\n", "assert", "data_file", ".", "is_file", "(", ")", "and", "metrics_file", ".", "is_file", "(", ")", "\n", "metrics", "=", "json", ".", "loads", "(", "metrics_file", ".", "read_text", "(", ")", ")", "\n", "num_samples", "=", "metrics", "[", "'num_training_examples'", "]", "\n", "seq_len", "=", "metrics", "[", "'max_seq_len'", "]", "\n", "self", ".", "temp_dir", "=", "None", "\n", "self", ".", "working_dir", "=", "None", "\n", "if", "reduce_memory", ":", "\n", "            ", "self", ".", "temp_dir", "=", "TemporaryDirectory", "(", ")", "\n", "self", ".", "working_dir", "=", "Path", "(", "self", ".", "temp_dir", ".", "name", ")", "\n", "input_ids", "=", "np", ".", "memmap", "(", "filename", "=", "self", ".", "working_dir", "/", "'input_ids.memmap'", ",", "\n", "mode", "=", "'w+'", ",", "dtype", "=", "np", ".", "int32", ",", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ")", "\n", "input_masks", "=", "np", ".", "memmap", "(", "filename", "=", "self", ".", "working_dir", "/", "'input_masks.memmap'", ",", "\n", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "mode", "=", "'w+'", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "segment_ids", "=", "np", ".", "memmap", "(", "filename", "=", "self", ".", "working_dir", "/", "'segment_ids.memmap'", ",", "\n", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "mode", "=", "'w+'", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "lm_label_ids", "=", "np", ".", "memmap", "(", "filename", "=", "self", ".", "working_dir", "/", "'lm_label_ids.memmap'", ",", "\n", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "mode", "=", "'w+'", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "lm_label_ids", "[", ":", "]", "=", "-", "1", "\n", "is_nexts", "=", "np", ".", "memmap", "(", "filename", "=", "self", ".", "working_dir", "/", "'is_nexts.memmap'", ",", "\n", "shape", "=", "(", "num_samples", ",", ")", ",", "mode", "=", "'w+'", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "input_masks", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "segment_ids", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "lm_label_ids", "=", "np", ".", "full", "(", "shape", "=", "(", "num_samples", ",", "seq_len", ")", ",", "dtype", "=", "np", ".", "int32", ",", "fill_value", "=", "-", "1", ")", "\n", "is_nexts", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_samples", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "", "logging", ".", "info", "(", "f\"Loading training examples for epoch {epoch}\"", ")", "\n", "with", "data_file", ".", "open", "(", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "tqdm", "(", "f", ",", "total", "=", "num_samples", ",", "desc", "=", "\"Training examples\"", ")", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "example", "=", "json", ".", "loads", "(", "line", ")", "\n", "features", "=", "convert_example_to_features", "(", "example", ",", "tokenizer", ",", "seq_len", ")", "\n", "input_ids", "[", "i", "]", "=", "features", ".", "input_ids", "\n", "segment_ids", "[", "i", "]", "=", "features", ".", "segment_ids", "\n", "input_masks", "[", "i", "]", "=", "features", ".", "input_mask", "\n", "lm_label_ids", "[", "i", "]", "=", "features", ".", "lm_label_ids", "\n", "is_nexts", "[", "i", "]", "=", "features", ".", "is_next", "\n", "", "", "assert", "i", "==", "num_samples", "-", "1", "# Assert that the sample count metric was true", "\n", "logging", ".", "info", "(", "\"Loading complete!\"", ")", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_masks", "=", "input_masks", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "lm_label_ids", "=", "lm_label_ids", "\n", "self", ".", "is_nexts", "=", "is_nexts", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.PregeneratedDataset.__len__": [[114, 116], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.PregeneratedDataset.__getitem__": [[117, 123], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tapt_bert_mlm_nsp.PregeneratedDataset.input_ids[].astype", "tapt_bert_mlm_nsp.PregeneratedDataset.input_masks[].astype", "tapt_bert_mlm_nsp.PregeneratedDataset.segment_ids[].astype", "tapt_bert_mlm_nsp.PregeneratedDataset.lm_label_ids[].astype", "tapt_bert_mlm_nsp.PregeneratedDataset.is_nexts[].astype"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "(", "torch", ".", "tensor", "(", "self", ".", "input_ids", "[", "item", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "input_masks", "[", "item", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "segment_ids", "[", "item", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "lm_label_ids", "[", "item", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "is_nexts", "[", "item", "]", ".", "astype", "(", "np", ".", "int64", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.convert_example_to_features": [[28, 57], ["tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "InputFeatures", "len", "len", "len", "len", "len"], "function", ["None"], ["def", "convert_example_to_features", "(", "example", ",", "tokenizer", ",", "max_seq_length", ")", ":", "\n", "    ", "tokens", "=", "example", "[", "\"tokens\"", "]", "\n", "segment_ids", "=", "example", "[", "\"segment_ids\"", "]", "\n", "is_random_next", "=", "example", "[", "\"is_random_next\"", "]", "\n", "masked_lm_positions", "=", "example", "[", "\"masked_lm_positions\"", "]", "\n", "masked_lm_labels", "=", "example", "[", "\"masked_lm_labels\"", "]", "\n", "\n", "assert", "len", "(", "tokens", ")", "==", "len", "(", "segment_ids", ")", "<=", "max_seq_length", "# The preprocessed data should be already truncated", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "masked_label_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "masked_lm_labels", ")", "\n", "\n", "input_array", "=", "np", ".", "zeros", "(", "max_seq_length", ",", "dtype", "=", "np", ".", "int", ")", "\n", "input_array", "[", ":", "len", "(", "input_ids", ")", "]", "=", "input_ids", "\n", "\n", "mask_array", "=", "np", ".", "zeros", "(", "max_seq_length", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "mask_array", "[", ":", "len", "(", "input_ids", ")", "]", "=", "1", "\n", "\n", "segment_array", "=", "np", ".", "zeros", "(", "max_seq_length", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "segment_array", "[", ":", "len", "(", "segment_ids", ")", "]", "=", "segment_ids", "\n", "\n", "lm_label_array", "=", "np", ".", "full", "(", "max_seq_length", ",", "dtype", "=", "np", ".", "int", ",", "fill_value", "=", "-", "1", ")", "\n", "lm_label_array", "[", "masked_lm_positions", "]", "=", "masked_label_ids", "\n", "\n", "features", "=", "InputFeatures", "(", "input_ids", "=", "input_array", ",", "\n", "input_mask", "=", "mask_array", ",", "\n", "segment_ids", "=", "segment_array", ",", "\n", "lm_label_ids", "=", "lm_label_array", ",", "\n", "is_next", "=", "is_random_next", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.tapt_bert_mlm_nsp.main": [[125, 339], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "parser.parse_args.pregenerated_data.is_dir", "range", "logging.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "parser.parse_args.output_dir.mkdir", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained", "range", "int", "pytorch_transformers.modeling_bert.BertForPreTraining.from_pretrained", "torch.nn.DataParallel.to", "list", "pytorch_transformers.optimization.WarmupLinearSchedule", "logging.info", "logging.info", "logging.info", "logging.info", "torch.nn.DataParallel.train", "wandb.init", "wandb.watch", "range", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "ValueError", "torch.cuda.manual_seed_all", "parser.parse_args.output_dir.is_dir", "list", "logging.warning", "torch.nn.DataParallel.half", "DDP", "torch.nn.DataParallel.named_parameters", "FusedAdam", "pytorch_transformers.optimization.AdamW", "tapt_bert_mlm_nsp.PregeneratedDataset", "torch.utils.data.DataLoader", "logging.info", "torch.nn.DataParallel.save_pretrained", "BertTokenizer.from_pretrained.save_pretrained", "epoch_file.is_file", "metrics_file.is_file", "json.loads", "samples_per_epoch.append", "print", "print", "bool", "parser.parse_args.output_dir.iterdir", "torch.distributed.get_world_size", "torch.nn.DataParallel", "FP16_Optimizer", "FP16_Optimizer", "vars", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "tqdm.tqdm", "enumerate", "metrics_file.read_text", "exit", "ImportError", "ImportError", "tuple", "torch.nn.DataParallel.", "loss.mean.item", "input_ids.size", "pbar.update", "pbar.set_postfix_str", "torch.distributed.get_rank", "torch.cuda.is_available", "len", "any", "len", "loss.mean.mean", "FP16_Optimizer.backward", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "pytorch_transformers.optimization.WarmupLinearSchedule.step", "FP16_Optimizer.step", "FP16_Optimizer.zero_grad", "wandb.log", "any", "t.to", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--pregenerated_data'", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "Path", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--reduce_memory\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Store training data as on-disc memmaps to massively reduce memory usage\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"Number of epochs to train for\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit float precision instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_scale'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"", "\n", "\"0 (default value): dynamic loss scaling.\\n\"", "\n", "\"Positive power of 2: static loss scaling value.\\n\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "\n", "default", "=", "1e-8", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "\n", "default", "=", "10", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of update steps between two logs.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "assert", "args", ".", "pregenerated_data", ".", "is_dir", "(", ")", ",", "\"--pregenerated_data should point to the folder of files made by pregenerate_training_data.py!\"", "\n", "\n", "samples_per_epoch", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "epoch_file", "=", "args", ".", "pregenerated_data", "/", "f\"epoch_{i}.json\"", "\n", "metrics_file", "=", "args", ".", "pregenerated_data", "/", "f\"epoch_{i}_metrics.json\"", "\n", "if", "epoch_file", ".", "is_file", "(", ")", "and", "metrics_file", ".", "is_file", "(", ")", ":", "\n", "            ", "metrics", "=", "json", ".", "loads", "(", "metrics_file", ".", "read_text", "(", ")", ")", "\n", "samples_per_epoch", ".", "append", "(", "metrics", "[", "'num_training_examples'", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "exit", "(", "\"No training data was found!\"", ")", "\n", "", "print", "(", "f\"Warning! There are fewer epochs of pregenerated data ({i}) than training epochs ({args.epochs}).\"", ")", "\n", "print", "(", "\"This script will loop over the available data, but training diversity may be negatively impacted.\"", ")", "\n", "num_data_epochs", "=", "i", "\n", "break", "\n", "", "", "else", ":", "\n", "        ", "num_data_epochs", "=", "args", ".", "epochs", "\n", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "n_gpu", "=", "1", "\n", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "", "logging", ".", "info", "(", "\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "gradient_accumulation_steps", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "args", ".", "output_dir", ".", "is_dir", "(", ")", "and", "list", "(", "args", ".", "output_dir", ".", "iterdir", "(", ")", ")", ":", "\n", "        ", "logging", ".", "warning", "(", "f\"Output directory ({args.output_dir}) already exists and is not empty!\"", ")", "\n", "", "args", ".", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "\n", "total_train_examples", "=", "0", "\n", "for", "i", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "# The modulo takes into account the fact that we may loop over limited epochs of data", "\n", "        ", "total_train_examples", "+=", "samples_per_epoch", "[", "i", "%", "len", "(", "samples_per_epoch", ")", "]", "\n", "\n", "", "num_train_optimization_steps", "=", "int", "(", "\n", "total_train_examples", "/", "args", ".", "train_batch_size", "/", "args", ".", "gradient_accumulation_steps", ")", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "num_train_optimization_steps", "=", "num_train_optimization_steps", "//", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "\n", "# Prepare model", "\n", "", "model", "=", "BertForPreTraining", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "parallel", "import", "DistributedDataParallel", "as", "DDP", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "", "model", "=", "DDP", "(", "model", ")", "\n", "", "elif", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Prepare optimizer", "\n", "", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "optimizers", "import", "FP16_Optimizer", "\n", "from", "apex", ".", "optimizers", "import", "FusedAdam", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "\n", "", "optimizer", "=", "FusedAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "bias_correction", "=", "False", ",", "\n", "max_grad_norm", "=", "1.0", ")", "\n", "if", "args", ".", "loss_scale", "==", "0", ":", "\n", "            ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "dynamic_loss_scale", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "static_loss_scale", "=", "args", ".", "loss_scale", ")", "\n", "", "", "else", ":", "\n", "        ", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "", "scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "warmup_steps", "=", "args", ".", "warmup_steps", ",", "t_total", "=", "num_train_optimization_steps", ")", "\n", "\n", "global_step", "=", "0", "\n", "logging", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logging", ".", "info", "(", "f\"  Num examples = {total_train_examples}\"", ")", "\n", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logging", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_optimization_steps", ")", "\n", "model", ".", "train", "(", ")", "\n", "wandb", ".", "init", "(", "project", "=", "\"huggingface\"", ",", "config", "=", "vars", "(", "args", ")", ")", "\n", "wandb", ".", "watch", "(", "model", ",", "log_freq", "=", "max", "(", "100", ",", "args", ".", "logging_steps", ")", ")", "\n", "logging_loss", "=", "0.0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "epoch_dataset", "=", "PregeneratedDataset", "(", "epoch", "=", "epoch", ",", "training_path", "=", "args", ".", "pregenerated_data", ",", "tokenizer", "=", "tokenizer", ",", "\n", "num_data_epochs", "=", "num_data_epochs", ",", "reduce_memory", "=", "args", ".", "reduce_memory", ")", "\n", "if", "args", ".", "local_rank", "==", "-", "1", ":", "\n", "            ", "train_sampler", "=", "RandomSampler", "(", "epoch_dataset", ")", "\n", "", "else", ":", "\n", "            ", "train_sampler", "=", "DistributedSampler", "(", "epoch_dataset", ")", "\n", "", "train_dataloader", "=", "DataLoader", "(", "epoch_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "tr_loss", "=", "0", "\n", "nb_tr_examples", ",", "nb_tr_steps", "=", "0", ",", "0", "\n", "with", "tqdm", "(", "total", "=", "len", "(", "train_dataloader", ")", ",", "desc", "=", "f\"Epoch {epoch}\"", ")", "as", "pbar", ":", "\n", "            ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "                ", "logs", "=", "{", "}", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "lm_label_ids", ",", "is_next", "=", "batch", "\n", "outputs", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "lm_label_ids", ",", "is_next", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "if", "n_gpu", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu.", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                    ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                    ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "else", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "nb_tr_examples", "+=", "input_ids", ".", "size", "(", "0", ")", "\n", "nb_tr_steps", "+=", "1", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "mean_loss", "=", "tr_loss", "*", "args", ".", "gradient_accumulation_steps", "/", "nb_tr_steps", "\n", "pbar", ".", "set_postfix_str", "(", "f\"Loss: {mean_loss:.5f}\"", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "\"loss\"", ":", "mean_loss", "}", ",", "step", "=", "global_step", ")", "\n", "\n", "# Save a trained model", "\n", "", "", "", "", "if", "n_gpu", ">", "1", "and", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", "or", "n_gpu", "<=", "1", ":", "\n", "        ", "logging", ".", "info", "(", "\"** ** * Saving fine-tuned model ** ** * \"", ")", "\n", "model", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.early_stop_fine_tuning_bert.set_seed": [[81, 91], ["torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "numpy.random.seed", "random.seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "# if you are using multi-GPU.", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "# Numpy module.", "\n", "random", ".", "seed", "(", "seed", ")", "# Python random module.", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.early_stop_fine_tuning_bert.get_lr_by_layer": [[92, 108], ["re.search", "int", "re.search.group"], "function", ["None"], ["", "def", "get_lr_by_layer", "(", "name", ":", "str", ",", "base_lr", ":", "float", "=", "2e-5", ",", "decay", ":", "int", "=", "0.9", ",", "bert_size", "=", "\"base\"", ")", ":", "\n", "    ", "match", "=", "re", ".", "search", "(", "\"^.*\\\\.(\\d+)\\\\..*$\"", ",", "name", ")", "\n", "last_layer_idx", "=", "23", "if", "bert_size", "==", "\"large\"", "else", "11", "\n", "if", "match", "is", "None", ":", "\n", "        ", "if", "\"embeddings\"", "in", "name", ":", "\n", "# last_layer_idx + 2 is because there is one more ", "\n", "# pooler and classifier layer on top of the 11", "\n", "# stack of encoders.", "\n", "            ", "return", "base_lr", "*", "(", "decay", "**", "(", "last_layer_idx", "+", "2", ")", ")", "\n", "", "elif", "\"pooler\"", "in", "name", ":", "\n", "            ", "return", "base_lr", "*", "(", "decay", "**", "1", ")", "\n", "", "elif", "\"classifier\"", "in", "name", ":", "\n", "            ", "return", "base_lr", "\n", "", "", "else", ":", "\n", "        ", "layer", "=", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "return", "base_lr", "*", "(", "decay", "**", "(", "last_layer_idx", "+", "2", "-", "layer", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.scripts.early_stop_fine_tuning_bert.predict": [[110, 217], ["print", "readorsee.models.models.BertForSequenceClassificationWithPooler.from_pretrained", "BertForSequenceClassificationWithPooler.from_pretrained.to", "BertForSequenceClassificationWithPooler.from_pretrained.eval", "readorsee.training.metrics.ConfusionMatrix", "readorsee.data.dataset.DepressionCorpusTransformer", "torch.utils.data.DataLoader", "torch.tensor().log", "torch.tensor().log", "print", "scipy.special.expit", "readorsee.training.metrics.ConfusionMatrix.add_experiment", "readorsee.training.metrics.ConfusionMatrix.get_mean_metrics_of_all_experiments", "print", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "list", "wandb.log", "scipy.special.expit.tolist", "numpy.empty", "enumerate", "wandb.log", "wandb.sklearn.plot_confusion_matrix", "torch.utils.data.RandomSampler", "torch.tensor", "torch.tensor", "tensor.numel", "tensor.cpu().detach().numpy", "torch.no_grad", "torch.no_grad", "batch_inputs[].squeeze().to", "batch_inputs[].squeeze().to", "batch_labels.float().to", "BertForSequenceClassificationWithPooler.from_pretrained.", "b_labels.int.int", "pred_labels.extend", "test_labels.extend", "u_names.extend", "scipy.special.expit.extend", "numpy.array", "numpy.array", "tensor.item", "b_input_ids.unsqueeze.dim", "b_input_ids.unsqueeze.unsqueeze", "b_input_mask.unsqueeze.dim", "b_input_mask.unsqueeze.unsqueeze", "early_stop_fine_tuning_bert.predict._list_from_tensor"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_experiment", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics_of_all_experiments", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.plot_confusion_matrix", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor._list_from_tensor"], ["", "", "def", "predict", "(", "\n", "model_path", ":", "Path", ",", "\n", "period", ":", "int", ",", "\n", "dataset", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "\n", "config", ":", "Config", ",", "\n", "threshold", "=", "0.50", "\n", ")", ":", "\n", "\n", "    ", "print", "(", "f\"====Loading model for testing\"", ")", "\n", "model", "=", "BertForSequenceClassificationWithPooler", ".", "from_pretrained", "(", "\n", "model_path", ",", "\n", "num_labels", "=", "2", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "True", ",", "\n", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "cm", "=", "ConfusionMatrix", "(", "[", "0", ",", "1", "]", ")", "\n", "test_corpus", "=", "DepressionCorpusTransformer", "(", "period", ",", "dataset", ",", "\"test\"", ",", "config", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "\n", "test_corpus", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "RandomSampler", "(", "test_corpus", ")", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "0", ",", "\n", "drop_last", "=", "True", "\n", ")", "\n", "pred_labels", "=", "[", "]", "\n", "test_labels", "=", "[", "]", "\n", "u_names", "=", "[", "]", "\n", "logits_list", "=", "[", "]", "\n", "threshold", "=", "0.50", "\n", "logit_threshold", "=", "torch", ".", "tensor", "(", "threshold", "/", "(", "1", "-", "threshold", ")", ",", "device", "=", "device", ")", ".", "log", "(", ")", "\n", "\n", "def", "_list_from_tensor", "(", "tensor", ")", ":", "\n", "        ", "if", "tensor", ".", "numel", "(", ")", "==", "1", ":", "\n", "            ", "return", "[", "tensor", ".", "item", "(", ")", "]", "\n", "", "return", "list", "(", "tensor", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "print", "(", "\"====Testing model...\"", ")", "\n", "for", "data", "in", "test_dataloader", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_inputs", ",", "batch_labels", ",", "u_name", "=", "data", "\n", "b_input_ids", "=", "batch_inputs", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", ".", "to", "(", "device", ")", "\n", "if", "b_input_ids", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "b_input_ids", "=", "b_input_ids", ".", "unsqueeze", "(", "0", ")", "\n", "", "b_input_mask", "=", "batch_inputs", "[", "\"attention_mask\"", "]", ".", "squeeze", "(", ")", ".", "to", "(", "device", ")", "\n", "if", "b_input_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "b_input_mask", "=", "b_input_mask", ".", "unsqueeze", "(", "0", ")", "\n", "", "b_labels", "=", "batch_labels", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "loss", ",", "logits", ",", "*", "_", "=", "model", "(", "\n", "b_input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "b_input_mask", ",", "\n", "labels", "=", "b_labels", ")", "\n", "\n", "preds", "=", "(", "(", "logits", ">", "logit_threshold", ")", ".", "squeeze", "(", ")", ")", ".", "int", "(", ")", "\n", "b_labels", "=", "b_labels", ".", "int", "(", ")", "\n", "pred_labels", ".", "extend", "(", "_list_from_tensor", "(", "preds", ")", ")", "\n", "test_labels", ".", "extend", "(", "_list_from_tensor", "(", "b_labels", ")", ")", "\n", "u_names", ".", "extend", "(", "u_name", ")", "\n", "logits_list", ".", "extend", "(", "_list_from_tensor", "(", "logits", ")", ")", "\n", "\n", "\n", "", "", "logits_list", "=", "expit", "(", "logits_list", ")", "\n", "cm", ".", "add_experiment", "(", "test_labels", ",", "pred_labels", ",", "logits_list", ",", "u_names", ",", "config", ")", "\n", "user_results", ",", "_", "=", "cm", ".", "get_mean_metrics_of_all_experiments", "(", "config", ")", "\n", "\n", "\n", "if", "log_wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "\n", "{", "\n", "\"precision\"", ":", "user_results", "[", "\"precision\"", "]", ",", "\n", "\"recall\"", ":", "user_results", "[", "\"recall\"", "]", ",", "\n", "\"f1\"", ":", "user_results", "[", "\"f1\"", "]", "\n", "}", "\n", ")", "\n", "probas", "=", "logits_list", ".", "tolist", "(", ")", "\n", "new_probas", "=", "np", ".", "empty", "(", "shape", "=", "(", "len", "(", "probas", ")", ",", "2", ")", ")", "\n", "for", "i", ",", "prob", "in", "enumerate", "(", "probas", ")", ":", "\n", "            ", "if", "prob", "[", "0", "]", ">", "0.5", ":", "\n", "                ", "new_probas", "[", "i", "]", "[", "1", "]", "=", "prob", "[", "0", "]", "\n", "new_probas", "[", "i", "]", "[", "0", "]", "=", "1", "-", "prob", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "new_probas", "[", "i", "]", "[", "0", "]", "=", "1", "-", "prob", "[", "0", "]", "\n", "new_probas", "[", "i", "]", "[", "1", "]", "=", "prob", "[", "0", "]", "\n", "\n", "", "", "wandb", ".", "log", "(", "\n", "{", "'roc'", ":", "wandb", ".", "plots", ".", "ROC", "(", "\n", "np", ".", "array", "(", "test_labels", ")", ",", "\n", "new_probas", ",", "\n", "[", "\"Not Depressed\"", ",", "\"Depressed\"", "]", "\n", ")", "\n", "}", "\n", ")", "\n", "wandb", ".", "sklearn", ".", "plot_confusion_matrix", "(", "\n", "np", ".", "array", "(", "test_labels", ")", ",", "\n", "np", ".", "array", "(", "pred_labels", ")", ",", "\n", "[", "\"Not Depressed\"", ",", "\"Depressed\"", "]", "\n", ")", "\n", "\n", "", "print", "(", "f\"====Model metrics: {user_results}\"", ")", "\n", "del", "model", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.__init__": [[58, 71], ["readorsee.data.models.Config", "getattr", "getattr", "experiment.DetectDepressionExperiment.get_embedder_names", "print", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.get_embedder_names"], ["def", "__init__", "(", "self", ",", "options_path", ":", "Path", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "Config", "(", "options_path", ")", "\n", "self", ".", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "self", ".", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "self", ".", "media_type", ")", "\n", "self", ".", "model_name", "=", "self", ".", "config", ".", "general", "[", "\"class_model\"", "]", "\n", "self", ".", "model", "=", "getattr", "(", "models", ",", "self", ".", "model_name", ")", "\n", "self", ".", "embedders", "=", "self", ".", "get_embedder_names", "(", ")", "\n", "print", "(", "\"======================\"", ")", "\n", "print", "(", "f\"Using {self.model.__name__} model\"", ")", "\n", "print", "(", "f\"General Configuration: {self.config.general}\"", ")", "\n", "print", "(", "f\"Media Configuration: {self.media_config}\"", ")", "\n", "print", "(", "f\"Embedders: {self.embedders}\"", ")", "\n", "print", "(", "\"======================\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment._list_from_tensor": [[72, 74], ["list", "tensor.cpu().detach().numpy", "tensor.cpu().detach", "tensor.cpu"], "methods", ["None"], ["", "def", "_list_from_tensor", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "list", "(", "tensor", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.get_embedder_names": [[75, 82], ["None"], "methods", ["None"], ["", "def", "get_embedder_names", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "media_type", "==", "\"both\"", ":", "\n", "            ", "return", "[", "self", ".", "media_config", "[", "\"txt_embedder\"", "]", ",", "self", ".", "media_config", "[", "\"img_embedder\"", "]", "]", "\n", "", "elif", "self", ".", "media_type", "==", "\"ftrs\"", ":", "\n", "            ", "return", "[", "\"MLPClf\"", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "media_config", "[", "self", ".", "media_type", "+", "\"_embedder\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.run": [[83, 124], ["list", "readorsee.training.metrics.ConfusionMatrix", "print", "experiment.DetectDepressionExperiment.print_metrics", "range", "experiment.DetectDepressionExperiment.load_fasttext_model", "experiment.DetectDepressionExperiment.get_experiment_name", "print", "readorsee.models.inference.Predictor.predict.get_mean_metrics_of_all_experiments", "readorsee.models.inference.Predictor.predict.save_experiments", "readorsee.models.inference.Predictor.predict.reset_experiments", "print", "print", "print", "experiment.DetectDepressionExperiment.instantiate_model", "readorsee.training.train_model", "experiment.DetectDepressionExperiment._get_loader", "readorsee.models.inference.Predictor", "readorsee.models.inference.Predictor.predict", "experiment.DetectDepressionExperiment.free_model_memory"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.print_metrics", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.load_fasttext_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.get_experiment_name", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics_of_all_experiments", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.save_experiments", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.reset_experiments", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.instantiate_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training.train_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment._get_loader", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor.predict", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.free_model_memory"], ["", "", "def", "run", "(", "self", ",", "\n", "threshold", "=", "0.5", ",", "\n", "training_verbose", "=", "True", ",", "\n", "periods", "=", "[", "60", ",", "212", ",", "365", "]", "\n", ")", ":", "\n", "\n", "        ", "datasets", "=", "list", "(", "range", "(", "0", ",", "10", ")", ")", "\n", "fasttext", "=", "(", "self", ".", "load_fasttext_model", "(", ")", "if", "\"fasttext\"", "in", "self", ".", "embedders", "\n", "else", "None", ")", "\n", "results", "=", "{", "self", ".", "media_type", ":", "{", "d", ":", "{", "}", "for", "d", "in", "periods", "}", "}", "\n", "cm", "=", "ConfusionMatrix", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "print", "(", "f\"===Using {self.media_type} media\"", ")", "\n", "for", "days", "in", "periods", ":", "\n", "            ", "for", "dataset", "in", "datasets", ":", "\n", "                ", "print", "(", "f\"Training model for {days} days and dataset {dataset}...\"", ")", "\n", "model", "=", "self", ".", "instantiate_model", "(", ")", "\n", "model", "=", "train_model", "(", "model", ",", "\n", "days", ",", "\n", "dataset", ",", "\n", "fasttext", ",", "\n", "self", ".", "config", ",", "\n", "training_verbose", ")", "\n", "test_loader", "=", "self", ".", "_get_loader", "(", "days", ",", "fasttext", ",", "dataset", ")", "\n", "predictor", "=", "Predictor", "(", "model", ",", "self", ".", "config", ")", "\n", "cm", "=", "predictor", ".", "predict", "(", "test_loader", ",", "cm", ",", "threshold", ")", "\n", "self", ".", "free_model_memory", "(", "model", ")", "\n", "", "experiment_name", "=", "self", ".", "get_experiment_name", "(", "self", ".", "media_type", ",", "days", ")", "\n", "print", "(", "experiment_name", ")", "\n", "user_results", ",", "post_results", "=", "cm", ".", "get_mean_metrics_of_all_experiments", "(", "\n", "self", ".", "config", "\n", ")", "\n", "cm", ".", "save_experiments", "(", "experiment_name", ")", "\n", "cm", ".", "reset_experiments", "(", ")", "\n", "results", "[", "self", ".", "media_type", "]", "[", "days", "]", "=", "{", "\"user\"", ":", "user_results", ",", "\"post\"", ":", "post_results", "}", "\n", "print", "(", "f\"===>For Class 1 [More depressed] with {days} days\"", ")", "\n", "print", "(", "f\"{results[self.media_type][days]}\"", ")", "\n", "\n", "", "self", ".", "print_metrics", "(", "results", ",", "self", ".", "media_type", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment._get_loader": [[125, 139], ["readorsee.data.dataset.DepressionCorpus", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "_get_loader", "(", "self", ",", "days", ",", "fasttext", ",", "dataset", ")", ":", "\n", "\n", "        ", "test", "=", "DepressionCorpus", "(", "observation_period", "=", "days", ",", "\n", "subset", "=", "\"test\"", ",", "\n", "fasttext", "=", "fasttext", ",", "\n", "dataset", "=", "dataset", ",", "\n", "config", "=", "self", ".", "config", ")", "\n", "\n", "test_loader", "=", "DataLoader", "(", "test", ",", "\n", "batch_size", "=", "self", ".", "config", ".", "general", "[", "\"batch_size\"", "]", ",", "\n", "shuffle", "=", "self", ".", "config", ".", "general", "[", "\"shuffle\"", "]", ",", "\n", "pin_memory", "=", "True", ",", "\n", "worker_init_fn", "=", "_init_fn", ")", "\n", "return", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.free_model_memory": [[140, 144], ["torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "os.remove"], "methods", ["None"], ["", "def", "free_model_memory", "(", "self", ",", "model", ")", ":", "\n", "        ", "del", "model", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "\"bow\"", "in", "self", ".", "embedders", ":", "os", ".", "remove", "(", "settings", ".", "PATH_TO_SERIALIZED_TFIDF", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.get_experiment_name": [[145, 161], ["getattr", "getattr.get", "embedder.lower.lower.lower", "getattr.get", "media_config[].replace"], "methods", ["None"], ["", "def", "get_experiment_name", "(", "self", ",", "media_type", ",", "days", ")", ":", "\n", "        ", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "use_lstm", "=", "media_config", ".", "get", "(", "\"use_lstm\"", ",", "False", ")", "\n", "embedder", "=", "\"-\"", ".", "join", "(", "self", ".", "embedders", ")", "+", "\"-\"", "+", "self", ".", "model_name", "\n", "embedder", "=", "embedder", ".", "lower", "(", ")", "\n", "aggregator", "=", "media_config", ".", "get", "(", "\"mean\"", ",", "\"\"", ")", "\n", "exp_name", "=", "f\"{media_type}_{days}_{embedder}\"", "\n", "\n", "if", "aggregator", "and", "\"bow\"", "not", "in", "self", ".", "embedders", ":", "\n", "            ", "if", "use_lstm", ":", "aggregator", "=", "\"LSTM\"", "\n", "exp_name", "=", "exp_name", "+", "f\"_{aggregator}\"", "\n", "", "if", "media_type", "==", "\"ftrs\"", ":", "\n", "            ", "features", "=", "media_config", "[", "\"features\"", "]", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", "\n", "exp_name", "=", "exp_name", "+", "f\"_{features}\"", "\n", "\n", "", "return", "exp_name", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.print_metrics": [[162, 173], ["print", "metrics.items", "print", "print", "print"], "methods", ["None"], ["", "def", "print_metrics", "(", "self", ",", "results", ",", "media_type", ")", ":", "\n", "        ", "print", "(", "f\"=====================>For {media_type}\"", ")", "\n", "metrics", "=", "results", "[", "media_type", "]", "\n", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "f\"===>For Class 1 [More depressed] with {k} days\"", ")", "\n", "u", "=", "v", "[", "\"user\"", "]", "\n", "p", "=", "v", "[", "\"post\"", "]", "\n", "print", "(", "f\">User:\\n\\t Precision: {u['precision']} \\t Recall: {u['recall']}\"", "f\"\\t F1: {u['f1']}\"", ")", "\n", "if", "p", ":", "\n", "                ", "print", "(", "f\">Post:\\n\\t Precision: {p['precision']} \\t Recall: {p['recall']}\"", "f\"\\t F1: {p['f1']}\"", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.load_fasttext_model": [[175, 179], ["gensim.models.fasttext.load_facebook_model"], "methods", ["None"], ["", "", "", "def", "load_fasttext_model", "(", "self", ")", ":", "\n", "        ", "fasttext", "=", "load_facebook_model", "(", "\n", "settings", ".", "PATH_TO_FASTTEXT_PT_EMBEDDINGS", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "return", "fasttext", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.DetectDepressionExperiment.instantiate_model": [[180, 183], ["experiment.DetectDepressionExperiment.model"], "methods", ["None"], ["", "def", "instantiate_model", "(", "self", ")", ":", "\n", "        ", "model", "=", "self", ".", "model", "(", "self", ".", "config", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.__init__": [[201, 225], ["glob.glob", "len", "os.path.join"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "logits_aggregator", ":", "str", ",", "experiments_folder", ":", "str", "=", "None", ",", "metrics", ":", "bool", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        logits_aggregator: metric to aggregate logits, possible values are: \n            mean, median, and vote\n        experiments_folder: folder name where the *.experiment files are stored\n        metrics: True if you want to get metrics, false if you want to get Y_true, Y_guess\n            logits and experiment name for each iteration\n        \"\"\"", "\n", "if", "experiments_folder", ":", "\n", "            ", "self", ".", "folder", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_EXPERIMENTS", ",", "experiments_folder", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "folder", "=", "settings", ".", "PATH_TO_EXPERIMENTS", "\n", "\n", "", "self", ".", "files_names", "=", "glob", ".", "glob", "(", "\n", "self", ".", "folder", "+", "os", ".", "sep", "+", "\"*.experiment\"", "\n", ")", "\n", "self", ".", "i", "=", "0", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "files_names", ")", "\n", "self", ".", "logits_aggregator", "=", "logits_aggregator", "\n", "self", ".", "metrics", "=", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.__iter__": [[226, 228], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.__next__": [[229, 243], ["os.path.basename", "pickle.load.ExperimentReader.experiment_metadata", "pickle.load.ExperimentReader.get_user_metrics", "pickle.load.ExperimentReader.update", "open", "pickle.load", "os.path.basename.split", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.experiment_metadata", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.get_user_metrics"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "i", ">=", "self", ".", "size", ":", "\n", "            ", "self", ".", "i", "=", "0", "\n", "raise", "StopIteration", "\n", "", "else", ":", "\n", "            ", "file_name", "=", "os", ".", "path", ".", "basename", "(", "self", ".", "files_names", "[", "self", ".", "i", "]", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "folder", ",", "file_name", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "experiment", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "self", ".", "i", "+=", "1", "\n", "exp_name", "=", "file_name", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "metadata", "=", "self", ".", "experiment_metadata", "(", "exp_name", ")", "\n", "result", "=", "self", ".", "get_user_metrics", "(", "experiment", ",", "exp_name", ")", "\n", "result", ".", "update", "(", "metadata", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.experiment_metadata": [[244, 252], ["experiment_name.split"], "methods", ["None"], ["", "", "def", "experiment_metadata", "(", "self", ",", "experiment_name", ")", ":", "\n", "        ", "tokens", "=", "experiment_name", ".", "split", "(", "\"_\"", ")", "\n", "_", ",", "days", ",", "embedder", ",", "*", "aggregator", "=", "tokens", "\n", "name", "=", "f\"{embedder}\"", "\n", "if", "aggregator", ":", "\n", "            ", "name", "+=", "f\"+{aggregator[0]}\"", "\n", "", "metadata", "=", "{", "\"name\"", ":", "name", ",", "\"days\"", ":", "days", "}", "\n", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader.get_user_metrics": [[253, 307], ["numpy.concatenate", "numpy.concatenate.append", "sklearn.metrics.precision_recall_fscore_support", "Y_true_user_list.append", "Y_guess_user_list.append", "aggregated_logits_list.append", "numpy.array", "numpy.array", "experiment.ExperimentReader._get_user_true_guess", "Y_true_user_list.append", "Y_guess_user_list.append", "aggregated_logits_list.append", "sklearn.metrics.precision_recall_fscore_support", "list", "numpy.mean", "numpy.std", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader._get_user_true_guess"], ["", "def", "get_user_metrics", "(", "self", ",", "experiment", ",", "exp_name", ")", ":", "\n", "        ", "user_metrics", "=", "[", "]", "\n", "Y_true_user_list", "=", "[", "]", "\n", "Y_guess_user_list", "=", "[", "]", "\n", "aggregated_logits_list", "=", "[", "]", "\n", "for", "exp_dataset", "in", "experiment", ":", "\n", "\n", "            ", "if", "\"post_params\"", "not", "in", "exp_dataset", ":", "\n", "                ", "post_params", "=", "exp_dataset", "[", "\"user_params\"", "]", "\n", "user_metric", "=", "precision_recall_fscore_support", "(", "\n", "y_true", "=", "np", ".", "array", "(", "post_params", "[", "\"truth\"", "]", ")", ",", "\n", "y_pred", "=", "np", ".", "array", "(", "post_params", "[", "\"guess\"", "]", ")", ",", "\n", "average", "=", "\"binary\"", "\n", ")", "\n", "Y_true_user_list", ".", "append", "(", "post_params", "[", "\"truth\"", "]", ")", "\n", "Y_guess_user_list", ".", "append", "(", "post_params", "[", "\"guess\"", "]", ")", "\n", "aggregated_logits_list", ".", "append", "(", "post_params", "[", "\"logits\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "post_params", "=", "exp_dataset", "[", "\"post_params\"", "]", "\n", "Y_true", "=", "np", ".", "array", "(", "post_params", "[", "\"truth\"", "]", ")", "\n", "Y_guess", "=", "np", ".", "array", "(", "post_params", "[", "\"guess\"", "]", ")", "\n", "logits", "=", "post_params", "[", "\"logits\"", "]", "\n", "ids", "=", "post_params", "[", "\"id\"", "]", "\n", "Y_true_user", ",", "Y_guess_user", ",", "aggregated_logits", "=", "self", ".", "_get_user_true_guess", "(", "\n", "Y_true", ",", "Y_guess", ",", "logits", ",", "ids", "\n", ")", "\n", "Y_true_user_list", ".", "append", "(", "Y_true_user", ")", "\n", "Y_guess_user_list", ".", "append", "(", "Y_guess_user", ")", "\n", "aggregated_logits_list", ".", "append", "(", "aggregated_logits", ")", "\n", "user_metric", "=", "precision_recall_fscore_support", "(", "\n", "y_true", "=", "Y_true_user", ",", "y_pred", "=", "Y_guess_user", ",", "average", "=", "\"binary\"", "\n", ")", "\n", "", "user_metrics", ".", "append", "(", "list", "(", "user_metric", "[", "0", ":", "-", "1", "]", ")", ")", "\n", "\n", "", "user_metrics", "=", "np", ".", "concatenate", "(", "\n", "[", "np", ".", "mean", "(", "user_metrics", ",", "axis", "=", "0", ")", ",", "np", ".", "std", "(", "user_metrics", ",", "axis", "=", "0", ")", "]", "\n", ")", "\n", "\n", "if", "self", ".", "metrics", ":", "\n", "            ", "result", "=", "{", "\n", "\"precision_mean\"", ":", "user_metrics", "[", "0", "]", ",", "\n", "\"recall_mean\"", ":", "user_metrics", "[", "1", "]", ",", "\n", "\"f1_mean\"", ":", "user_metrics", "[", "2", "]", ",", "\n", "\"precision_std\"", ":", "user_metrics", "[", "3", "]", ",", "\n", "\"recall_std\"", ":", "user_metrics", "[", "4", "]", ",", "\n", "\"f1_std\"", ":", "user_metrics", "[", "5", "]", "\n", "}", "\n", "", "else", ":", "\n", "            ", "result", "=", "{", "\n", "\"Y_true_user\"", ":", "Y_true_user_list", ",", "\n", "\"Y_guess_user\"", ":", "Y_guess_user_list", ",", "\n", "\"aggregated_logits\"", ":", "aggregated_logits_list", "\n", "}", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.ExperimentReader._get_user_true_guess": [[308, 345], ["set", "Y_true_user.append", "len", "len", "aggregated_user_logits.append", "Y_guess_user.append", "enumerate", "numpy.mean", "numpy.bincount", "Y_guess_user.append", "ValueError", "numpy.median", "numpy.argmax"], "methods", ["None"], ["", "def", "_get_user_true_guess", "(", "self", ",", "Y_true", ",", "Y_guess", ",", "logits", ",", "ids", ")", ":", "\n", "\n", "        ", "users", "=", "set", "(", "ids", ")", "\n", "Y_true_user", "=", "[", "]", "\n", "Y_guess_user", "=", "[", "]", "\n", "aggregated_user_logits", "=", "[", "]", "\n", "for", "user", "in", "users", ":", "\n", "\n", "            ", "user_indices", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "ids", ")", "if", "x", "==", "user", "]", "\n", "user_logits", "=", "logits", "[", "user_indices", "]", "\n", "user_true", "=", "Y_true", "[", "user_indices", "]", "[", "0", "]", "\n", "Y_true_user", ".", "append", "(", "user_true", ")", "\n", "user_guess", "=", "None", "\n", "\n", "if", "self", ".", "logits_aggregator", "==", "\"median\"", "or", "self", ".", "logits_aggregator", "==", "\"mean\"", ":", "\n", "\n", "                ", "if", "self", ".", "logits_aggregator", "==", "\"mean\"", ":", "\n", "                    ", "proba", "=", "np", ".", "mean", "(", "user_logits", ")", "\n", "", "elif", "self", ".", "logits_aggregator", "==", "\"median\"", ":", "\n", "                    ", "proba", "=", "np", ".", "median", "(", "user_logits", ")", "\n", "\n", "", "if", "proba", ">", "0.5", ":", "\n", "                    ", "user_guess", "=", "1", "\n", "", "else", ":", "\n", "                    ", "user_guess", "=", "0", "\n", "\n", "", "aggregated_user_logits", ".", "append", "(", "proba", ")", "\n", "Y_guess_user", ".", "append", "(", "user_guess", ")", "\n", "\n", "", "elif", "self", ".", "logits_aggregator", "==", "\"vote\"", ":", "\n", "                ", "bin_count", "=", "np", ".", "bincount", "(", "Y_guess", "[", "user_indices", "]", ")", "\n", "Y_guess_user", ".", "append", "(", "np", ".", "argmax", "(", "bin_count", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{self.logits_aggregator} is not valid.\"", ")", "\n", "\n", "", "", "assert", "len", "(", "Y_true_user", ")", "==", "len", "(", "Y_guess_user", ")", ",", "\"Incorrect shape between Y_true and Y_pred\"", "\n", "return", "Y_true_user", ",", "Y_guess_user", ",", "aggregated_user_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment._init_fn": [[42, 44], ["numpy.random.seed"], "function", ["None"], ["def", "_init_fn", "(", "worker_id", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "12", "+", "worker_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.run_all_experiments": [[184, 193], ["glob.glob", "range", "len", "experiment.DetectDepressionExperiment", "multiprocessing.Process", "jobs.append", "multiprocessing.Process.start"], "function", ["None"], ["", "", "def", "run_all_experiments", "(", ")", ":", "\n", "    ", "path", "=", "settings", ".", "PATH_TO_EXPERIMENTS_OPTIONS", "\n", "experiments_options", "=", "glob", ".", "glob", "(", "path", "+", "os", ".", "sep", "+", "\"*.json\"", ")", "\n", "jobs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "experiments_options", ")", ")", ":", "\n", "        ", "exp", "=", "DetectDepressionExperiment", "(", "experiments_options", "[", "i", "]", ")", "\n", "p", "=", "multiprocessing", ".", "Process", "(", "target", "=", "exp", ".", "run", ")", "\n", "jobs", ".", "append", "(", "p", ")", "\n", "p", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.get_experiments_results_df": [[346, 352], ["experiment.ExperimentReader", "pandas.DataFrame", "df.append"], "function", ["None"], ["", "", "def", "get_experiments_results_df", "(", "logits_aggregator", ",", "experiments_folder", "=", "\"\"", ")", ":", "\n", "    ", "exp_reader", "=", "ExperimentReader", "(", "logits_aggregator", ",", "experiments_folder", ",", "metrics", "=", "True", ")", "\n", "df", "=", "[", "]", "\n", "for", "experiment_metrics", "in", "exp_reader", ":", "\n", "        ", "df", ".", "append", "(", "experiment_metrics", ")", "\n", "", "return", "pd", ".", "DataFrame", "(", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.plot_roc_precision_curves_for_users": [[353, 361], ["experiment.ExperimentReader", "list", "experiment._plot_roc_and_pr_curves", "range"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment._plot_roc_and_pr_curves"], ["", "def", "plot_roc_precision_curves_for_users", "(", "logits_aggregator", ",", "experiments_folder", "=", "\"\"", ")", ":", "\n", "    ", "exp_reader", "=", "ExperimentReader", "(", "logits_aggregator", ",", "experiments_folder", ",", "metrics", "=", "False", ")", "\n", "for", "data", "in", "exp_reader", ":", "\n", "        ", "Y_true", "=", "data", "[", "\"Y_true_user\"", "]", "\n", "probas", "=", "data", "[", "\"aggregated_logits\"", "]", "\n", "name", "=", "data", "[", "\"name\"", "]", "+", "\"-\"", "+", "data", "[", "\"days\"", "]", "\n", "datasets", "=", "list", "(", "range", "(", "0", ",", "10", ")", ")", "\n", "_plot_roc_and_pr_curves", "(", "Y_true", ",", "probas", ",", "datasets", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment._plot_roc_and_pr_curves": [[379, 421], ["matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.set_xlim", "fig.add_subplot.set_ylim", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "plt.figure.add_subplot", "fig.add_subplot.set_xlim", "fig.add_subplot.set_ylim", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_title", "enumerate", "fig.add_subplot.legend", "fig.add_subplot.legend", "matplotlib.show", "zip", "sklearn.metrics.precision_recall_curve", "sklearn.metrics.average_precision_score", "sklearn.metrics.roc_curve", "sklearn.metrics.auc", "fig.add_subplot.plot", "fig.add_subplot.plot"], "function", ["None"], ["", "", "def", "_plot_roc_and_pr_curves", "(", "\n", "y_tests", ",", "\n", "probas", ",", "\n", "labels", ",", "\n", "title", ",", "\n", "save_name", "=", "\"\"", ",", "\n", "colors", "=", "[", "'b'", ",", "'g'", ",", "'r'", ",", "'c'", ",", "'m'", ",", "'y'", ",", "'k'", ",", "'C0'", ",", "'C1'", ",", "'C2'", "]", "\n", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "13", ",", "6", ")", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "1", ",", "2", ",", "1", ")", "\n", "ax1", ".", "set_xlim", "(", "[", "0.0", ",", "1.0", "]", ")", "\n", "ax1", ".", "set_ylim", "(", "[", "0.0", ",", "1.0", "]", ")", "\n", "ax1", ".", "set_xlabel", "(", "'Recall'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Precision'", ")", "\n", "ax1", ".", "set_title", "(", "'Precision-Recall Curve - '", "+", "title", ")", "\n", "\n", "ax2", "=", "fig", ".", "add_subplot", "(", "1", ",", "2", ",", "2", ")", "\n", "ax2", ".", "set_xlim", "(", "[", "0.0", ",", "1.0", "]", ")", "\n", "ax2", ".", "set_ylim", "(", "[", "0.0", ",", "1.0", "]", ")", "\n", "ax2", ".", "set_xlabel", "(", "\"False Positive Rate\"", ")", "\n", "ax2", ".", "set_ylabel", "(", "\"True Positive Rate\"", ")", "\n", "ax2", ".", "set_title", "(", "\"ROC Curve - \"", "+", "title", ")", "\n", "\n", "for", "i", ",", "lc", "in", "enumerate", "(", "zip", "(", "labels", ",", "colors", ")", ")", ":", "\n", "        ", "w", ",", "k", "=", "lc", "\n", "y_test", "=", "y_tests", "[", "i", "]", "\n", "pred_prob", "=", "probas", "[", "i", "]", "\n", "p", ",", "r", ",", "_", "=", "precision_recall_curve", "(", "y_test", ",", "pred_prob", ")", "\n", "average_precision", "=", "average_precision_score", "(", "y_test", ",", "pred_prob", ")", "\n", "\n", "fpr_rf", ",", "tpr_rf", ",", "_", "=", "roc_curve", "(", "y_test", ",", "pred_prob", ")", "\n", "\n", "roc_auc_rf", "=", "auc", "(", "fpr_rf", ",", "tpr_rf", ")", "\n", "\n", "ax1", ".", "plot", "(", "r", ",", "p", ",", "c", "=", "k", ",", "label", "=", "'{} (AP = {:0.2f})'", ".", "format", "(", "w", ",", "average_precision", ")", ")", "\n", "ax2", ".", "plot", "(", "fpr_rf", ",", "tpr_rf", ",", "c", "=", "k", ",", "label", "=", "'{} (AUC = {:0.2f})'", ".", "format", "(", "w", ",", "roc_auc_rf", ")", ")", "\n", "\n", "", "ax1", ".", "legend", "(", "loc", "=", "'lower right'", ",", "prop", "=", "{", "'size'", ":", "13", "}", ")", "\n", "ax2", ".", "legend", "(", "loc", "=", "'lower right'", ",", "prop", "=", "{", "'size'", ":", "12", "}", ")", "\n", "# fig.savefig(save_name + \".pdf\", dpi=300, bbox_inches=\"tight\")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.plot_precision_recall_scatter_plot": [[422, 428], ["experiment.get_experiments_results_df", "experiment.scatter_plot", "df[].astype"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.get_experiments_results_df", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.scatter_plot"], ["", "def", "plot_precision_recall_scatter_plot", "(", "\n", "logits_aggregator", ",", "experiments_folder", "=", "\"\"", ",", "title", "=", "\"\"", ",", "save_name", "=", "None", "\n", ")", ":", "\n", "    ", "df", "=", "get_experiments_results_df", "(", "logits_aggregator", ",", "experiments_folder", ")", "\n", "df", ".", "loc", "[", ":", ",", "\"days\"", "]", "=", "df", "[", "\"days\"", "]", ".", "astype", "(", "str", ")", "+", "\" days\"", "\n", "scatter_plot", "(", "df", ",", "title", ",", "save_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.readorsee.experiment.scatter_plot": [[429, 470], ["seaborn.set_style", "matplotlib.subplots", "df.sort_values.sort_values", "seaborn.scatterplot", "ax2.set_title", "ax2.get_legend_handles_labels", "ax2.legend", "ax2.yaxis.set_major_formatter", "ax2.set_yticks", "ax2.set_xlabel", "ax2.set_ylabel", "FormatStrFormatter", "numpy.linspace", "fig2.savefig"], "function", ["None"], ["", "def", "scatter_plot", "(", "df", ",", "title", ",", "save_name", "=", "None", ")", ":", "\n", "    ", "sns", ".", "set_style", "(", "\"whitegrid\"", ",", "{", "'grid.linestyle'", ":", "'--'", "}", ")", "\n", "fig2", ",", "ax2", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "by", "=", "[", "'days'", ",", "'name'", "]", ",", "ascending", "=", "False", ")", "\n", "filled_markers", "=", "(", "\n", "'o'", ",", "'v'", ",", "'^'", ",", "'<'", ",", "'>'", ",", "'*'", ",", "'s'", ",", "'p'", ",", "'8'", ",", "'h'", ",", "'H'", ",", "'D'", ",", "'d'", ",", "'P'", ",", "'X'", "\n", ")", "\n", "sns", ".", "scatterplot", "(", "\n", "x", "=", "\"precision_mean\"", ",", "\n", "y", "=", "\"recall_mean\"", ",", "\n", "hue", "=", "\"days\"", ",", "\n", "style", "=", "\"name\"", ",", "\n", "data", "=", "df", ",", "\n", "s", "=", "80", ",", "\n", "ax", "=", "ax2", ",", "\n", "markers", "=", "filled_markers", "\n", ")", "\n", "ax2", ".", "set_title", "(", "title", ")", "\n", "handles", ",", "labels", "=", "ax2", ".", "get_legend_handles_labels", "(", ")", "\n", "labels", "[", "0", "]", "=", "\"-- Obs. Period --\"", "\n", "labels", "[", "4", "]", "=", "\"-- Models --\"", "\n", "# ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5)) ", "\n", "ax2", ".", "legend", "(", "\n", "handles", ",", "\n", "labels", ",", "\n", "loc", "=", "\"lower center\"", ",", "\n", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.40", ")", ",", "\n", "# loc='center left', ", "\n", "# bbox_to_anchor=(1, 0.5),", "\n", "ncol", "=", "4", "\n", ")", "\n", "from", "matplotlib", ".", "ticker", "import", "FormatStrFormatter", "\n", "ax2", ".", "yaxis", ".", "set_major_formatter", "(", "FormatStrFormatter", "(", "'%.2f'", ")", ")", "\n", "# ax2.set_xticks(np.linspace(0.0, 1.0, num=10))", "\n", "ax2", ".", "set_yticks", "(", "np", ".", "linspace", "(", "0.50", ",", "1.0", ",", "num", "=", "9", ")", ")", "\n", "# ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))", "\n", "ax2", ".", "set_xlabel", "(", "\"Precision (mean)\"", ")", "\n", "ax2", ".", "set_ylabel", "(", "\"Recall (mean)\"", ")", "\n", "\n", "if", "save_name", ":", "\n", "        ", "fig2", ".", "savefig", "(", "save_name", "+", "\".pdf\"", ",", "dpi", "=", "300", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.adamw.mAdamW.__init__": [[19, 32], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ",", "\n", "local_normalization", "=", "False", ",", "max_grad_norm", "=", "-", "1", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "correct_bias", "=", "correct_bias", ",", "\n", "local_normalization", "=", "local_normalization", ",", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.adamw.mAdamW.step": [[33, 111], ["closure", "updates.append", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "group_updates.append", "torch.nn.utils.clip_grad_norm_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "updates", "=", "[", "]", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "group_updates", "=", "[", "]", "\n", "\n", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "# Normalize gradients locally (layer-wise)", "\n", "", "if", "group", "[", "\"local_normalization\"", "]", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "p", ",", "group", "[", "\"max_grad_norm\"", "]", ")", "\n", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adam does not support sparse gradients, please consider SparseAdam instead\"", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "# This is just m_t = beta_1 * m_t-1 + (1 - beta_1) * g_t", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1.0", "-", "beta1", ")", "\n", "# This is just v_t = beta_2 * v_t-1 + (1 - beta_2) * g_t^2", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1.0", "-", "beta2", ")", "\n", "# This is just sqrt(v_t) + eps", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "\n", "if", "group", "[", "\"correct_bias\"", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "=", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "# print(f\"Learning rate: {step_size}\")", "\n", "\n", "# This is just p.data[i] = p.data[i] + (-step_size) * exp_avg[i] / denom[i]", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "group", "[", "\"weight_decay\"", "]", ">", "0.0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "p", ".", "data", ",", "alpha", "=", "-", "group", "[", "\"lr\"", "]", "*", "group", "[", "\"weight_decay\"", "]", ")", "\n", "\n", "", "group_updates", ".", "append", "(", "(", "exp_avg", ",", "denom", ")", ")", "\n", "\n", "", "updates", ".", "append", "(", "group_updates", ")", "\n", "\n", "", "return", "loss", ",", "updates", "\n", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.SimpleSelfAttention.__init__": [[36, 45], ["torch.Module.__init__", "xresnet.conv1d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "tensor"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv1d"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ":", "int", ",", "ks", "=", "1", ",", "sym", "=", "False", ")", ":", "#, n_out:int):", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "conv1d", "(", "n_in", ",", "n_in", ",", "ks", ",", "padding", "=", "ks", "//", "2", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "tensor", "(", "[", "0.", "]", ")", ")", "\n", "\n", "self", ".", "sym", "=", "sym", "\n", "self", ".", "n_in", "=", "n_in", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.SimpleSelfAttention.forward": [[46, 70], ["x.view.view.size", "x.view.view.view", "xresnet.SimpleSelfAttention.conv", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.view().contiguous", "torch.bmm.view().contiguous", "torch.bmm.view().contiguous", "xresnet.SimpleSelfAttention.conv.weight.view", "xresnet.SimpleSelfAttention.view", "x.view.view.permute().contiguous", "torch.bmm.view", "torch.bmm.view", "torch.bmm.view", "xresnet.SimpleSelfAttention.t", "x.view.view.permute"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "\n", "        ", "if", "self", ".", "sym", ":", "\n", "# symmetry hack by https://github.com/mgrankin", "\n", "            ", "c", "=", "self", ".", "conv", ".", "weight", ".", "view", "(", "self", ".", "n_in", ",", "self", ".", "n_in", ")", "\n", "c", "=", "(", "c", "+", "c", ".", "t", "(", ")", ")", "/", "2", "\n", "self", ".", "conv", ".", "weight", "=", "c", ".", "view", "(", "self", ".", "n_in", ",", "self", ".", "n_in", ",", "1", ")", "\n", "\n", "", "size", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size", "[", ":", "2", "]", ",", "-", "1", ")", "# (C,N)", "\n", "\n", "# changed the order of mutiplication to avoid O(N^2) complexity", "\n", "# (x*xT)*(W*x) instead of (x*(xT*(W*x)))", "\n", "\n", "convx", "=", "self", ".", "conv", "(", "x", ")", "# (C,C) * (C,N) = (C,N)   => O(NC^2)", "\n", "xxT", "=", "torch", ".", "bmm", "(", "x", ",", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", ")", "# (C,N) * (N,C) = (C,C)   => O(NC^2)", "\n", "\n", "o", "=", "torch", ".", "bmm", "(", "xxT", ",", "convx", ")", "# (C,C) * (C,N) = (C,N)   => O(NC^2)", "\n", "\n", "o", "=", "self", ".", "gamma", "*", "o", "+", "x", "\n", "\n", "\n", "return", "o", ".", "view", "(", "*", "size", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.Flatten.forward": [[75, 76], ["x.view", "x.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.ResBlock.__init__": [[95, 112], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "xresnet.SimpleSelfAttention", "xresnet.conv_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "xresnet.conv_layer", "xresnet.conv_layer", "xresnet.conv_layer", "xresnet.conv_layer", "xresnet.conv_layer"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer"], ["    ", "def", "__init__", "(", "self", ",", "expansion", ",", "ni", ",", "nh", ",", "stride", "=", "1", ",", "sa", "=", "False", ",", "sym", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nf", ",", "ni", "=", "nh", "*", "expansion", ",", "ni", "*", "expansion", "\n", "layers", "=", "[", "conv_layer", "(", "ni", ",", "nh", ",", "3", ",", "stride", "=", "stride", ")", ",", "\n", "conv_layer", "(", "nh", ",", "nf", ",", "3", ",", "zero_bn", "=", "True", ",", "act", "=", "False", ")", "\n", "]", "if", "expansion", "==", "1", "else", "[", "\n", "conv_layer", "(", "ni", ",", "nh", ",", "1", ")", ",", "\n", "conv_layer", "(", "nh", ",", "nh", ",", "3", ",", "stride", "=", "stride", ")", ",", "\n", "conv_layer", "(", "nh", ",", "nf", ",", "1", ",", "zero_bn", "=", "True", ",", "act", "=", "False", ")", "\n", "]", "\n", "\n", "self", ".", "sa", "=", "SimpleSelfAttention", "(", "nf", ",", "ks", "=", "1", ",", "sym", "=", "sym", ")", "if", "sa", "else", "noop", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "# TODO: check whether act=True works better", "\n", "self", ".", "idconv", "=", "noop", "if", "ni", "==", "nf", "else", "conv_layer", "(", "ni", ",", "nf", ",", "1", ",", "act", "=", "False", ")", "\n", "self", ".", "pool", "=", "noop", "if", "stride", "==", "1", "else", "nn", ".", "AvgPool2d", "(", "2", ",", "ceil_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.ResBlock.forward": [[113, 114], ["act_fn", "xresnet.ResBlock.sa", "xresnet.ResBlock.idconv", "xresnet.ResBlock.convs", "xresnet.ResBlock.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "return", "act_fn", "(", "self", ".", "sa", "(", "self", ".", "convs", "(", "x", ")", ")", "+", "self", ".", "idconv", "(", "self", ".", "pool", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.XResNet.__init__": [[124, 145], ["range", "torch.Sequential.__init__", "xresnet.init_cnn", "stem.append", "xresnet.XResNet._make_layer", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "xresnet.Flatten", "torch.Linear", "torch.Linear", "torch.Linear", "xresnet.conv_layer", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.init_cnn", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.XResNet._make_layer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer"], ["    ", "def", "__init__", "(", "self", ",", "expansion", ",", "layers", ",", "c_in", "=", "3", ",", "c_out", "=", "1000", ",", "sa", "=", "False", ",", "sym", "=", "False", ")", ":", "\n", "\n", "        ", "stem", "=", "[", "]", "\n", "sizes", "=", "[", "c_in", ",", "32", ",", "32", ",", "64", "]", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "stem", ".", "append", "(", "conv_layer", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "stride", "=", "2", "if", "i", "==", "0", "else", "1", ")", ")", "\n", "#nf = filt_sz(c_in*9)", "\n", "#stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))", "\n", "#c_in = nf", "\n", "\n", "", "block_szs", "=", "[", "64", "//", "expansion", ",", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "blocks", "=", "[", "self", ".", "_make_layer", "(", "expansion", ",", "block_szs", "[", "i", "]", ",", "block_szs", "[", "i", "+", "1", "]", ",", "l", ",", "1", "if", "i", "==", "0", "else", "2", ",", "sa", "=", "sa", "if", "i", "in", "[", "len", "(", "layers", ")", "-", "4", "]", "else", "False", ",", "sym", "=", "sym", ")", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "layers", ")", "]", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "*", "stem", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "*", "blocks", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", ",", "Flatten", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "block_szs", "[", "-", "1", "]", "*", "expansion", ",", "c_out", ")", ",", "\n", ")", "\n", "init_cnn", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.XResNet._make_layer": [[146, 150], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "xresnet.ResBlock", "range"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "expansion", ",", "ni", ",", "nf", ",", "blocks", ",", "stride", ",", "sa", "=", "False", ",", "sym", "=", "False", ")", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "\n", "*", "[", "ResBlock", "(", "expansion", ",", "ni", "if", "i", "==", "0", "else", "nf", ",", "nf", ",", "stride", "if", "i", "==", "0", "else", "1", ",", "sa", "if", "i", "in", "[", "blocks", "-", "1", "]", "else", "False", ",", "sym", ")", "\n", "for", "i", "in", "range", "(", "blocks", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv1d": [[23, 29], ["torch.Conv1d", "torch.init.kaiming_normal_", "spectral_norm", "nn.Conv1d.bias.data.zero_"], "function", ["None"], ["def", "conv1d", "(", "ni", ":", "int", ",", "no", ":", "int", ",", "ks", ":", "int", "=", "1", ",", "stride", ":", "int", "=", "1", ",", "padding", ":", "int", "=", "0", ",", "bias", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"Create and initialize a `nn.Conv1d` layer with spectral normalization.\"", "\n", "conv", "=", "nn", ".", "Conv1d", "(", "ni", ",", "no", ",", "ks", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "bias", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "conv", ".", "weight", ")", "\n", "if", "bias", ":", "conv", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "spectral_norm", "(", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.init_cnn": [[77, 81], ["isinstance", "m.children", "getattr", "torch.init.constant_", "torch.init.kaiming_normal_", "xresnet.init_cnn"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.init_cnn"], ["", "def", "init_cnn", "(", "m", ")", ":", "\n", "    ", "if", "getattr", "(", "m", ",", "'bias'", ",", "None", ")", "is", "not", "None", ":", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "if", "isinstance", "(", "m", ",", "(", "nn", ".", "Conv2d", ",", "nn", ".", "Linear", ")", ")", ":", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ")", "\n", "for", "l", "in", "m", ".", "children", "(", ")", ":", "init_cnn", "(", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv": [[82, 84], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv", "(", "ni", ",", "nf", ",", "ks", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "ni", ",", "nf", ",", "kernel_size", "=", "ks", ",", "stride", "=", "stride", ",", "padding", "=", "ks", "//", "2", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.noop": [[85, 86], ["None"], "function", ["None"], ["", "def", "noop", "(", "x", ")", ":", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv_layer": [[87, 93], ["torch.BatchNorm2d", "torch.init.constant_", "torch.Sequential", "xresnet.conv", "layers.append"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.conv"], ["def", "conv_layer", "(", "ni", ",", "nf", ",", "ks", "=", "3", ",", "stride", "=", "1", ",", "zero_bn", "=", "False", ",", "act", "=", "True", ")", ":", "\n", "    ", "bn", "=", "nn", ".", "BatchNorm2d", "(", "nf", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "weight", ",", "0.", "if", "zero_bn", "else", "1.", ")", "\n", "layers", "=", "[", "conv", "(", "ni", ",", "nf", ",", "ks", ",", "stride", "=", "stride", ")", ",", "bn", "]", "\n", "if", "act", ":", "layers", ".", "append", "(", "act_fn", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.filt_sz": [[118, 119], ["min", "math.floor", "math.log2"], "function", ["None"], ["", "def", "filt_sz", "(", "recep", ")", ":", "return", "min", "(", "64", ",", "2", "**", "math", ".", "floor", "(", "math", ".", "log2", "(", "recep", "*", "0.75", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.xresnet.xresnet": [[151, 155], ["xresnet.XResNet", "XResNet.load_state_dict", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.load_state_dict"], ["", "", "def", "xresnet", "(", "expansion", ",", "n_layers", ",", "name", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "XResNet", "(", "expansion", ",", "n_layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "name", "]", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.over9000.Over9000": [[12, 15], ["ralamb.Ralamb", "lookahead.Lookahead"], "function", ["None"], ["def", "Over9000", "(", "params", ",", "alpha", "=", "0.5", ",", "k", "=", "6", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "     ", "ralamb", "=", "Ralamb", "(", "params", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "Lookahead", "(", "ralamb", ",", "alpha", ",", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.ralamb.Ralamb.__init__": [[7, 11], ["dict", "torch.optim.optimizer.Optimizer.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "self", ".", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "ind", "in", "range", "(", "10", ")", "]", "\n", "super", "(", "Ralamb", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.ralamb.Ralamb.__setstate__": [[12, 14], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "Ralamb", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.ralamb.Ralamb.step": [[15, 100], ["closure", "p.grad.data.float", "p.data.float", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.float.clone", "p.data.float.clone.pow().sum().sqrt", "p.data.pow().sum().sqrt().clamp", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.clone.addcdiv_", "p.data.float.clone.add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "int", "p.data.float.clone.pow().sum", "p.data.pow().sum().sqrt", "exp_avg_sq.sqrt", "math.sqrt", "p.data.float.clone.pow", "p.data.pow().sum", "p.data.pow"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Ralamb does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# m_t", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "# v_t", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "self", ".", "buffer", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "                    ", "N_sma", ",", "radam_step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "                    ", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                        ", "radam_step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "radam_step_size", "=", "group", "[", "'lr'", "]", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "buffered", "[", "2", "]", "=", "radam_step_size", "\n", "\n", "", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "radam_step", "=", "p_data_fp32", ".", "clone", "(", ")", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "radam_step", ".", "addcdiv_", "(", "-", "radam_step_size", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "radam_step", ".", "add_", "(", "-", "radam_step_size", ",", "exp_avg", ")", "\n", "\n", "", "radam_norm", "=", "radam_step", ".", "pow", "(", "2", ")", ".", "sum", "(", ")", ".", "sqrt", "(", ")", "\n", "weight_norm", "=", "p", ".", "data", ".", "pow", "(", "2", ")", ".", "sum", "(", ")", ".", "sqrt", "(", ")", ".", "clamp", "(", "0", ",", "10", ")", "\n", "if", "weight_norm", "==", "0", "or", "radam_norm", "==", "0", ":", "\n", "                    ", "trust_ratio", "=", "1", "\n", "", "else", ":", "\n", "                    ", "trust_ratio", "=", "weight_norm", "/", "radam_norm", "\n", "\n", "", "state", "[", "'weight_norm'", "]", "=", "weight_norm", "\n", "state", "[", "'adam_norm'", "]", "=", "radam_norm", "\n", "state", "[", "'trust_ratio'", "]", "=", "trust_ratio", "\n", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "p_data_fp32", ".", "addcdiv_", "(", "-", "radam_step_size", "*", "trust_ratio", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "radam_step_size", "*", "trust_ratio", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lamb.Lamb.__init__": [[49, 63], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "\n", "weight_decay", "=", "0", ",", "adam", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "self", ".", "adam", "=", "adam", "\n", "super", "(", "Lamb", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lamb.Lamb.step": [[64, 130], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.pow().sum().sqrt().clamp", "adam_step.pow().sum().sqrt", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "exp_avg_sq.sqrt().add", "adam_step.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "p.data.pow().sum().sqrt", "adam_step.pow().sum", "exp_avg_sq.sqrt", "p.data.pow().sum", "adam_step.pow", "p.data.pow"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Lamb does not support sparse gradients, consider SparseAdam instad.'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# m_t", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "# v_t", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "\n", "# Paper v3 does not use debiasing.", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "# Apply bias to lr to avoid broadcast.", "\n", "step_size", "=", "group", "[", "'lr'", "]", "# * math.sqrt(bias_correction2) / bias_correction1", "\n", "\n", "weight_norm", "=", "p", ".", "data", ".", "pow", "(", "2", ")", ".", "sum", "(", ")", ".", "sqrt", "(", ")", ".", "clamp", "(", "0", ",", "10", ")", "\n", "\n", "adam_step", "=", "exp_avg", "/", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add", "(", "group", "[", "'eps'", "]", ")", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "adam_step", ".", "add_", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "adam_norm", "=", "adam_step", ".", "pow", "(", "2", ")", ".", "sum", "(", ")", ".", "sqrt", "(", ")", "\n", "if", "weight_norm", "==", "0", "or", "adam_norm", "==", "0", ":", "\n", "                    ", "trust_ratio", "=", "1", "\n", "", "else", ":", "\n", "                    ", "trust_ratio", "=", "weight_norm", "/", "adam_norm", "\n", "", "state", "[", "'weight_norm'", "]", "=", "weight_norm", "\n", "state", "[", "'adam_norm'", "]", "=", "adam_norm", "\n", "state", "[", "'trust_ratio'", "]", "=", "trust_ratio", "\n", "if", "self", ".", "adam", ":", "\n", "                    ", "trust_ratio", "=", "1", "\n", "\n", "", "p", ".", "data", ".", "add_", "(", "-", "step_size", "*", "trust_ratio", ",", "adam_step", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.RAdam.__init__": [[9, 13], ["dict", "torch.optim.optimizer.Optimizer.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "self", ".", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "ind", "in", "range", "(", "10", ")", "]", "\n", "super", "(", "RAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.RAdam.__setstate__": [[14, 16], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "RAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.RAdam.step": [[17, 81], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "self", ".", "buffer", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "                    ", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "                    ", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                        ", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "step_size", "=", "group", "[", "'lr'", "]", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "step_size", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.PlainRAdam.__init__": [[84, 88], ["dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "\n", "super", "(", "PlainRAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.PlainRAdam.__setstate__": [[89, 91], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "PlainRAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.PlainRAdam.step": [[92, 145], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "math.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "step_size", "=", "group", "[", "'lr'", "]", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "p_data_fp32", ".", "add_", "(", "-", "step_size", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.AdamW.__init__": [[149, 153], ["dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "warmup", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ",", "use_variance", "=", "True", ",", "warmup", "=", "warmup", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.AdamW.__setstate__": [[154, 156], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdamW", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.radam.AdamW.step": [[157, 210], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "if", "group", "[", "'warmup'", "]", ">", "state", "[", "'step'", "]", ":", "\n", "                    ", "scheduled_lr", "=", "1e-8", "+", "state", "[", "'step'", "]", "*", "group", "[", "'lr'", "]", "/", "group", "[", "'warmup'", "]", "\n", "", "else", ":", "\n", "                    ", "scheduled_lr", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "scheduled_lr", ",", "p_data_fp32", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.__init__": [[12, 27], ["dict", "lookahead.Lookahead.defaults.update", "collections.defaultdict", "dict.items", "ValueError", "ValueError", "group.setdefault"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "base_optimizer", ",", "alpha", "=", "0.5", ",", "k", "=", "6", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "alpha", "<=", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid slow update rate: {alpha}'", ")", "\n", "", "if", "not", "1", "<=", "k", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid lookahead steps: {k}'", ")", "\n", "", "defaults", "=", "dict", "(", "lookahead_alpha", "=", "alpha", ",", "lookahead_k", "=", "k", ",", "lookahead_step", "=", "0", ")", "\n", "self", ".", "base_optimizer", "=", "base_optimizer", "\n", "self", ".", "param_groups", "=", "self", ".", "base_optimizer", ".", "param_groups", "\n", "self", ".", "defaults", "=", "base_optimizer", ".", "defaults", "\n", "self", ".", "defaults", ".", "update", "(", "defaults", ")", "\n", "self", ".", "state", "=", "defaultdict", "(", "dict", ")", "\n", "# manually add our defaults to the param groups", "\n", "for", "name", ",", "default", "in", "defaults", ".", "items", "(", ")", ":", "\n", "            ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "                ", "group", ".", "setdefault", "(", "name", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.update_slow": [[28, 39], ["slow.add_", "fast_p.data.copy_", "torch.empty_like", "param_state[].copy_"], "methods", ["None"], ["", "", "", "def", "update_slow", "(", "self", ",", "group", ")", ":", "\n", "        ", "for", "fast_p", "in", "group", "[", "\"params\"", "]", ":", "\n", "            ", "if", "fast_p", ".", "grad", "is", "None", ":", "\n", "                ", "continue", "\n", "", "param_state", "=", "self", ".", "state", "[", "fast_p", "]", "\n", "if", "'slow_buffer'", "not", "in", "param_state", ":", "\n", "                ", "param_state", "[", "'slow_buffer'", "]", "=", "torch", ".", "empty_like", "(", "fast_p", ".", "data", ")", "\n", "param_state", "[", "'slow_buffer'", "]", ".", "copy_", "(", "fast_p", ".", "data", ")", "\n", "", "slow", "=", "param_state", "[", "'slow_buffer'", "]", "\n", "slow", ".", "add_", "(", "group", "[", "'lookahead_alpha'", "]", ",", "fast_p", ".", "data", "-", "slow", ")", "\n", "fast_p", ".", "data", ".", "copy_", "(", "slow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.sync_lookahead": [[40, 43], ["lookahead.Lookahead.update_slow"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.update_slow"], ["", "", "def", "sync_lookahead", "(", "self", ")", ":", "\n", "        ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "self", ".", "update_slow", "(", "group", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.step": [[44, 53], ["lookahead.Lookahead.base_optimizer.step", "lookahead.Lookahead.update_slow"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.update_slow"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "# print(self.k)", "\n", "#assert id(self.param_groups) == id(self.base_optimizer.param_groups)", "\n", "        ", "loss", "=", "self", ".", "base_optimizer", ".", "step", "(", "closure", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", "[", "'lookahead_step'", "]", "+=", "1", "\n", "if", "group", "[", "'lookahead_step'", "]", "%", "group", "[", "'lookahead_k'", "]", "==", "0", ":", "\n", "                ", "self", ".", "update_slow", "(", "group", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.state_dict": [[54, 66], ["lookahead.Lookahead.base_optimizer.state_dict", "isinstance", "id", "lookahead.Lookahead.state.items"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "fast_state_dict", "=", "self", ".", "base_optimizer", ".", "state_dict", "(", ")", "\n", "slow_state", "=", "{", "\n", "(", "id", "(", "k", ")", "if", "isinstance", "(", "k", ",", "torch", ".", "Tensor", ")", "else", "k", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "self", ".", "state", ".", "items", "(", ")", "\n", "}", "\n", "fast_state", "=", "fast_state_dict", "[", "'state'", "]", "\n", "param_groups", "=", "fast_state_dict", "[", "'param_groups'", "]", "\n", "return", "{", "\n", "'state'", ":", "fast_state", ",", "\n", "'slow_state'", ":", "slow_state", ",", "\n", "'param_groups'", ":", "param_groups", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.load_state_dict": [[68, 93], ["lookahead.Lookahead.base_optimizer.load_state_dict", "super().load_state_dict", "print", "collections.defaultdict", "lookahead.Lookahead.defaults.items", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.load_state_dict", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "fast_state_dict", "=", "{", "\n", "'state'", ":", "state_dict", "[", "'state'", "]", ",", "\n", "'param_groups'", ":", "state_dict", "[", "'param_groups'", "]", ",", "\n", "}", "\n", "self", ".", "base_optimizer", ".", "load_state_dict", "(", "fast_state_dict", ")", "\n", "\n", "# We want to restore the slow state, but share param_groups reference", "\n", "# with base_optimizer. This is a bit redundant but least code", "\n", "slow_state_new", "=", "False", "\n", "if", "'slow_state'", "not", "in", "state_dict", ":", "\n", "            ", "print", "(", "'Loading state_dict from optimizer without Lookahead applied.'", ")", "\n", "state_dict", "[", "'slow_state'", "]", "=", "defaultdict", "(", "dict", ")", "\n", "slow_state_new", "=", "True", "\n", "", "slow_state_dict", "=", "{", "\n", "'state'", ":", "state_dict", "[", "'slow_state'", "]", ",", "\n", "'param_groups'", ":", "state_dict", "[", "'param_groups'", "]", ",", "# this is pointless but saves code", "\n", "}", "\n", "super", "(", "Lookahead", ",", "self", ")", ".", "load_state_dict", "(", "slow_state_dict", ")", "\n", "self", ".", "param_groups", "=", "self", ".", "base_optimizer", ".", "param_groups", "# make both ref same container", "\n", "if", "slow_state_new", ":", "\n", "# reapply defaults to catch missing lookahead specific ones", "\n", "            ", "for", "name", ",", "default", "in", "self", ".", "defaults", ".", "items", "(", ")", ":", "\n", "                ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "                    ", "group", ".", "setdefault", "(", "name", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.LookaheadAdam": [[94, 97], ["Adam", "lookahead.Lookahead"], "function", ["None"], ["", "", "", "", "", "def", "LookaheadAdam", "(", "params", ",", "alpha", "=", "0.5", ",", "k", "=", "6", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "     ", "adam", "=", "Adam", "(", "params", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "Lookahead", "(", "adam", ",", "alpha", ",", "k", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.ranger.Ranger": [[9, 12], ["radam.RAdam", "lookahead.Lookahead"], "function", ["None"], ["def", "Ranger", "(", "params", ",", "alpha", "=", "0.5", ",", "k", "=", "6", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "     ", "radam", "=", "RAdam", "(", "params", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "Lookahead", "(", "radam", ",", "alpha", ",", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.AdamW.__init__": [[42, 55], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "amsgrad", "=", "amsgrad", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.AdamW.__setstate__": [[56, 60], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdamW", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.AdamW.step": [[61, 117], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "torch.mul().addcdiv_", "torch.zeros_like", "exp_avg.mul_", "exp_avg_sq.mul_", "math.sqrt", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt", "torch.mul"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n  \n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "", "amsgrad", "=", "group", "[", "'amsgrad'", "]", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "'max_exp_avg_sq'", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "# Decay the first and second moment running average coefficient", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "p", ".", "data", ".", "add_", "(", "-", "step_size", ",", "torch", ".", "mul", "(", "p", ".", "data", ",", "group", "[", "'weight_decay'", "]", ")", ".", "addcdiv_", "(", "1", ",", "exp_avg", ",", "denom", ")", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__init__": [[137, 153], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.95", ",", "0", ")", ",", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "grad_averaging", "=", "False", ",", "amsgrad", "=", "False", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "grad_averaging", "=", "grad_averaging", ",", "\n", "amsgrad", "=", "amsgrad", ")", "\n", "\n", "super", "(", "Novograd", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__": [[154, 158], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "Novograd", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "'amsgrad'", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step": [[159, 224], ["closure", "torch.sum", "grad.div_", "exp_avg.mul_().add_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros().to", "torch.pow", "exp_avg_sq.copy_", "exp_avg_sq.mul_().add_", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "grad.add_", "grad.mul_", "torch.zeros().to", "exp_avg.mul_", "torch.zeros", "exp_avg_sq.mul_", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt", "torch.zeros"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n            and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Sparse gradients are not supported.'", ")", "\n", "", "amsgrad", "=", "group", "[", "'amsgrad'", "]", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros", "(", "[", "]", ")", ".", "to", "(", "state", "[", "'exp_avg'", "]", ".", "device", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp. moving avg. of sq. grad. values", "\n", "                        ", "state", "[", "'max_exp_avg_sq'", "]", "=", "torch", ".", "zeros", "(", "[", "]", ")", ".", "to", "(", "state", "[", "'exp_avg'", "]", ".", "device", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "'max_exp_avg_sq'", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "norm", "=", "torch", ".", "sum", "(", "torch", ".", "pow", "(", "grad", ",", "2", ")", ")", "\n", "\n", "if", "exp_avg_sq", "==", "0", ":", "\n", "                    ", "exp_avg_sq", ".", "copy_", "(", "norm", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "add_", "(", "1", "-", "beta2", ",", "norm", ")", "\n", "\n", "", "if", "amsgrad", ":", "\n", "# Maintains the maximum of all 2nd moment running avg. till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max. for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "", "grad", ".", "div_", "(", "denom", ")", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "grad", ".", "add_", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "", "if", "group", "[", "'grad_averaging'", "]", ":", "\n", "                    ", "grad", ".", "mul_", "(", "1", "-", "beta1", ")", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ")", "\n", "\n", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.__init__": [[8, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.get_weighted_average": [[11, 23], ["torch.zeros", "range", "sif_embeddings.div.div.div", "sif_weights.size", "x.size", "sif_weights.size", "x.size", "sif_weights.size", "masks.size", "sif_weights.size", "masks.size", "x.size", "masks.sum().view", "x.size", "x.size", "masks.sum"], "methods", ["None"], ["", "def", "get_weighted_average", "(", "self", ",", "x", ",", "masks", ",", "sif_weights", ")", ":", "\n", "        ", "assert", "sif_weights", ".", "size", "(", "0", ")", "==", "x", ".", "size", "(", "0", ")", "\n", "assert", "sif_weights", ".", "size", "(", "1", ")", "==", "x", ".", "size", "(", "1", ")", "\n", "assert", "sif_weights", ".", "size", "(", "0", ")", "==", "masks", ".", "size", "(", "0", ")", "\n", "assert", "sif_weights", ".", "size", "(", "1", ")", "==", "masks", ".", "size", "(", "1", ")", "\n", "sif_embeddings", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "2", ")", ")", ",", "\n", "device", "=", "sif_weights", ".", "device", ",", "dtype", "=", "sif_weights", ".", "dtype", ")", "\n", "for", "i", "in", "range", "(", "x", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "sif_embeddings", "[", "i", "]", "=", "sif_weights", "[", "i", "]", "@", "x", "[", "i", "]", "\n", "\n", "", "sif_embeddings", "=", "sif_embeddings", ".", "div", "(", "masks", ".", "sum", "(", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "return", "sif_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.remove_pc": [[24, 35], ["sif_embeddings.svd"], "methods", ["None"], ["", "def", "remove_pc", "(", "self", ",", "sif_embeddings", ")", ":", "\n", "        ", "\"\"\"\n        Remove the projection on the principal components\n        :param sif_embeddings: Is the data containing the weighted sif embedding\n        :return: is the data after removing its projection\n        \"\"\"", "\n", "_", ",", "_", ",", "V", "=", "sif_embeddings", ".", "svd", "(", ")", "\n", "V", "=", "-", "V", "[", ":", ",", "0", "]", "\n", "# Remove th first singular vector", "\n", "sif_embeddings", "=", "(", "sif_embeddings", "-", "(", "sif_embeddings", "@", "V", ")", ".", "view", "(", "-", "1", ",", "1", ")", "*", "V", ")", "\n", "return", "sif_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.SIF_embedding": [[36, 57], ["sentence_embeddings.SIF.get_weighted_average", "sentence_embeddings.SIF.remove_pc"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.get_weighted_average", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.remove_pc"], ["", "def", "SIF_embedding", "(", "self", ",", "embeddings", ",", "masks", ",", "sif_weights", ")", ":", "\n", "        ", "\"\"\"\n        Compute the scores between pairs of sentences using weighted average + \n        removing the projection on the first principal component\n        :param embeddings: tensor of size (A, B, C), where A is the number\n                           of sentences (batch), B is the length of the biggest\n                           sentence in sentences, and C is the embedding size\n        :param masks: tensor of size (A, B), exactly the same size as embeddings\n                      param, where masks[i,j] is 1 if a word j is in the sentece\n                      i, and 0 otherwise\n        :param sif_weights: tensor of size (A, B), exactly the same size as the\n                            masks param, but instead of 1 and 0, it contains the\n                            SIF weight for each word in the sentence, e.g.,\n                            sif_weights[i, :] contains the weights of words for\n                            the sentence i\n        :return: emb, emb[i, :] is the embedding for sentence i\n        \"\"\"", "\n", "\n", "emb", "=", "self", ".", "get_weighted_average", "(", "embeddings", ",", "masks", ",", "sif_weights", ")", "\n", "emb", "=", "self", ".", "remove_pc", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.SIF.get_SIF_weights": [[58, 94], ["collections.defaultdict", "collections.defaultdict.items", "collections.defaultdict.items", "torch.stack", "torch.tensor", "torch.cat.size", "torch.cat", "torch.stack.append", "len", "len", "torch.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_SIF_weights", "(", "sentences", ",", "a", "=", "1e-3", ")", ":", "\n", "        ", "\"\"\"\n        :return:    tensor of size (A, B), exactly the same size as the\n                    masks param of SIF_embedding function, but instead\n                    of 1 and 0, it contain the SIF weight for each word\n                    in the sentence, e.g., sif_weights[i, :] contains\n                    the weights of words for the sentence i.\n        \"\"\"", "\n", "word_freqs", "=", "defaultdict", "(", "int", ")", "\n", "vocab_size", "=", "0", "\n", "word2weight", "=", "{", "}", "\n", "max_sent_size", "=", "0", "\n", "for", "sent", "in", "sentences", ":", "\n", "            ", "if", "len", "(", "sent", ")", ">", "max_sent_size", ":", "\n", "                    ", "max_sent_size", "=", "len", "(", "sent", ")", "\n", "", "for", "token", "in", "sent", ":", "\n", "                ", "word_freqs", "[", "token", "]", "+=", "1", "\n", "\n", "", "", "for", "k", ",", "v", "in", "word_freqs", ".", "items", "(", ")", ":", "\n", "            ", "vocab_size", "+=", "v", "\n", "", "for", "k", ",", "v", "in", "word_freqs", ".", "items", "(", ")", ":", "\n", "            ", "word2weight", "[", "k", "]", "=", "a", "/", "(", "a", "+", "v", "/", "vocab_size", ")", "\n", "\n", "", "sif", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "            ", "sif_sent", "=", "[", "word2weight", "[", "token", "]", "for", "token", "in", "sent", "]", "\n", "sif_sent", "=", "torch", ".", "tensor", "(", "sif_sent", ")", "\n", "sent_size", "=", "sif_sent", ".", "size", "(", "0", ")", "\n", "sif_sent", "=", "torch", ".", "cat", "(", "\n", "[", "sif_sent", ",", "torch", ".", "zeros", "(", "max_sent_size", "-", "sent_size", ")", "]", ")", "\n", "sif", ".", "append", "(", "sif_sent", ")", "\n", "\n", "", "sif", "=", "torch", ".", "stack", "(", "sif", ")", "\n", "\n", "return", "sif", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.__init__": [[98, 110], ["dict", "torch.mean", "torch.max", "torch.min", "sentence_embeddings.PMEAN.gen_mean", "sentence_embeddings.PMEAN.gen_mean"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.gen_mean", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.gen_mean"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "operations", "=", "dict", "(", "[", "\n", "(", "'mean'", ",", "\n", "lambda", "word_emb", ":", "torch", ".", "mean", "(", "word_emb", ",", "dim", "=", "0", ")", ")", ",", "\n", "(", "'max'", ",", "\n", "lambda", "word_emb", ":", "torch", ".", "max", "(", "word_emb", ",", "dim", "=", "0", ")", "[", "0", "]", ")", ",", "\n", "(", "'min'", ",", "\n", "lambda", "word_emb", ":", "torch", ".", "min", "(", "word_emb", ",", "dim", "=", "0", ")", "[", "0", "]", ")", ",", "\n", "(", "'p_mean_2'", ",", "\n", "lambda", "word_emb", ":", "[", "self", ".", "gen_mean", "(", "word_emb", ",", "p", "=", "2.0", ")", ".", "real", "]", ")", ",", "\n", "(", "'p_mean_3'", ",", "\n", "lambda", "word_emb", ":", "[", "self", ".", "gen_mean", "(", "word_emb", ",", "p", "=", "3.0", ")", ".", "real", "]", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.gen_mean": [[112, 121], ["float", "numpy.power", "numpy.mean", "numpy.power", "numpy.array"], "methods", ["None"], ["", "def", "gen_mean", "(", "self", ",", "vals", ",", "p", ")", ":", "\n", "        ", "p", "=", "float", "(", "p", ")", "\n", "return", "np", ".", "power", "(", "\n", "np", ".", "mean", "(", "\n", "np", ".", "power", "(", "\n", "np", ".", "array", "(", "vals", ",", "dtype", "=", "complex", ")", ",", "\n", "p", ")", ",", "\n", "axis", "=", "0", ")", ",", "\n", "1", "/", "p", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.znorm": [[123, 132], ["embeddings.mean", "embeddings.std", "torch.isnan", "torch.isinf"], "methods", ["None"], ["", "def", "znorm", "(", "self", ",", "embeddings", ")", ":", "\n", "# Equivalent to https://github.com/UKPLab/arxiv2018-xling-sentence-embeddings/issues/3", "\n", "# without the normalization part", "\n", "        ", "mean", "=", "embeddings", ".", "mean", "(", "dim", "=", "0", ")", "\n", "std", "=", "embeddings", ".", "std", "(", "dim", "=", "0", ")", "\n", "embeddings", "=", "(", "embeddings", "-", "mean", ")", ".", "div", "(", "std", ")", "\n", "embeddings", "[", "torch", ".", "isnan", "(", "embeddings", ")", "]", "=", "0.", "\n", "embeddings", "[", "torch", ".", "isinf", "(", "embeddings", ")", "]", "=", "1.", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.PMEAN_embedding": [[133, 159], ["range", "torch.stack", "sentence_embeddings.PMEAN.znorm", "sentence_embeddings.PMEAN.size", "torch.index_select", "masks[].nonzero().squeeze", "torch.cat", "masks[].nonzero", "torch.isnan", "torch.isinf"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.znorm"], ["", "def", "PMEAN_embedding", "(", "self", ",", "embeddings", ",", "masks", ",", "\n", "chosen_operations", "=", "[", "\"mean\"", ",", "\"max\"", ",", "\"min\"", "]", ")", ":", "\n", "        ", "\"\"\"\n        :param embeddings: tensor of size (A, B, C), where A is the number\n                           of sentences (batch), B is the length of the biggest\n                           sentence in sentences, and C is the embedding size\n        :param masks: tensor of size (A, B), exactly the same size as embeddings\n                      param, where masks[i,j] is 1 if a word j is in the sentece\n                      i, and 0 otherwise\n        :param chosen_operations: operations to concatenate the power means\n        \"\"\"", "\n", "sent_embs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "embeddings", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "sent", "=", "torch", ".", "index_select", "(", "embeddings", "[", "i", ",", "...", "]", ",", "0", ",", "\n", "masks", "[", "i", ",", "...", "]", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", ")", "\n", "op_embs", "=", "[", "]", "\n", "for", "o", "in", "chosen_operations", ":", "\n", "                ", "emb", "=", "self", ".", "operations", "[", "o", "]", "(", "sent", ")", "\n", "emb", "[", "torch", ".", "isnan", "(", "emb", ")", "]", "=", "0", "\n", "emb", "[", "torch", ".", "isinf", "(", "emb", ")", "]", "=", "1", "\n", "op_embs", "+=", "[", "emb", "]", "\n", "", "sent_embs", "+=", "[", "torch", ".", "cat", "(", "op_embs", ",", "dim", "=", "0", ")", "]", "\n", "\n", "", "embeddings", "=", "torch", ".", "stack", "(", "sent_embs", ")", "\n", "embeddings", "=", "self", ".", "znorm", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.get_mean": [[161, 180], ["getattr", "sentence_embeddings.PMEAN", "sentence_embeddings.PMEAN.PMEAN_embedding", "torch.div.sum", "masks.sum().view().float.sum().view().float", "torch.div", "NotImplementedError", "masks.sum().view().float.sum().view", "torch.isnan", "torch.isinf", "masks.sum().view().float.sum"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.PMEAN.PMEAN_embedding"], ["", "", "def", "get_mean", "(", "x", ",", "masks", ",", "config", ")", ":", "\n", "    ", "config", "=", "config", "\n", "media_config", "=", "getattr", "(", "config", ",", "config", ".", "general", "[", "\"media_type\"", "]", ")", "\n", "\n", "if", "media_config", "[", "\"mean\"", "]", "==", "\"pmean\"", ":", "\n", "        ", "pmean", "=", "PMEAN", "(", ")", "\n", "means", "=", "media_config", "[", "\"pmean\"", "]", "\n", "pmean_embedding", "=", "pmean", ".", "PMEAN_embedding", "(", "x", ",", "masks", ",", "means", ")", "\n", "return", "pmean_embedding", "\n", "\n", "", "elif", "media_config", "[", "\"mean\"", "]", "==", "\"avg\"", ":", "\n", "        ", "x", "=", "x", ".", "sum", "(", "dim", "=", "1", ")", "\n", "masks", "=", "masks", ".", "sum", "(", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "x", "=", "torch", ".", "div", "(", "x", ",", "masks", ")", "\n", "x", "[", "torch", ".", "isnan", "(", "x", ")", "]", "=", "0", "\n", "x", "[", "torch", ".", "isinf", "(", "x", ")", "]", "=", "1", "\n", "return", "x", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"There is no {media_config['mean']} aggregator.\"", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_features": [[21, 53], ["profile.get_posts_from_qtnre_answer_date", "feature_engineering.get_textual_features", "feature_engineering.get_mean_std_from_ftrs", "feature_engineering.get_mean_std_from_ftrs", "faces.append", "likes.append", "captions.append", "comments.append", "feature_engineering.get_visual_features", "hue.append", "saturation.append", "value.append", "sum", "p.get_img_path_list", "p.get_face_count_list"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_textual_features", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_mean_std_from_ftrs", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_mean_std_from_ftrs", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_visual_features", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_face_count_list"], ["def", "get_features", "(", "\n", "profile", ":", "InstagramUser", ",", "period", ":", "int", "\n", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "float", "]", ",", "Dict", "[", "str", ",", "float", "]", ",", "Dict", "[", "str", ",", "float", "]", "]", ":", "\n", "    ", "posts", "=", "profile", ".", "get_posts_from_qtnre_answer_date", "(", "period", ")", "\n", "faces", "=", "[", "]", "\n", "likes", "=", "[", "]", "\n", "captions", "=", "[", "]", "\n", "comments", "=", "[", "]", "\n", "hue", "=", "[", "]", "\n", "saturation", "=", "[", "]", "\n", "value", "=", "[", "]", "\n", "post_features", "=", "{", "\"likes\"", ":", "likes", ",", "\"comments\"", ":", "comments", "}", "\n", "visual_features", "=", "{", "\n", "\"faces\"", ":", "faces", ",", "\n", "\"hue\"", ":", "hue", ",", "\n", "\"saturation\"", ":", "saturation", ",", "\n", "\"value\"", ":", "value", ",", "\n", "}", "\n", "for", "p", "in", "posts", ":", "\n", "        ", "faces", ".", "append", "(", "sum", "(", "p", ".", "get_face_count_list", "(", ")", ")", ")", "\n", "likes", ".", "append", "(", "p", ".", "likes_count", ")", "\n", "captions", ".", "append", "(", "p", ".", "caption", ")", "\n", "comments", ".", "append", "(", "p", ".", "comments_count", ")", "\n", "h", ",", "s", ",", "v", "=", "get_visual_features", "(", "p", ".", "get_img_path_list", "(", ")", ")", "\n", "hue", ".", "append", "(", "h", ")", "\n", "saturation", ".", "append", "(", "s", ")", "\n", "value", ".", "append", "(", "v", ")", "\n", "\n", "", "textual_features", "=", "get_textual_features", "(", "captions", ")", "\n", "visual_features", "=", "get_mean_std_from_ftrs", "(", "visual_features", ")", "\n", "post_features", "=", "get_mean_std_from_ftrs", "(", "post_features", ")", "\n", "return", "post_features", ",", "visual_features", ",", "textual_features", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_mean_std_from_ftrs": [[55, 65], ["dic.items", "new_dic.update", "numpy.mean", "numpy.std", "numpy.sum"], "function", ["None"], ["", "def", "get_mean_std_from_ftrs", "(", "dic", ")", ":", "\n", "    ", "new_dic", "=", "{", "}", "\n", "for", "name", ",", "ftrs", "in", "dic", ".", "items", "(", ")", ":", "\n", "        ", "d", "=", "{", "\n", "f\"{name}_mean\"", ":", "np", ".", "mean", "(", "ftrs", ")", ",", "\n", "f\"{name}_std\"", ":", "np", ".", "std", "(", "ftrs", ")", ",", "\n", "f\"{name}_count\"", ":", "np", ".", "sum", "(", "ftrs", ")", ",", "\n", "}", "\n", "new_dic", ".", "update", "(", "d", ")", "\n", "", "return", "new_dic", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_visual_features": [[67, 87], ["numpy.mean", "os.path.join", "skimage.io.imread", "skimage.color.rgb2hsv", "range", "hsv_list.append", "len", "numpy.mean", "hsv.append", "len", "len"], "function", ["None"], ["", "def", "get_visual_features", "(", "paths", ":", "List", "[", "Path", "]", ")", "->", "List", "[", "float", "]", ":", "\n", "    ", "\"\"\"\n    Returns the mean of hue, saturation and value (HSV) for a list of images paths.\n    The return value will always be of size 3.\n    \"\"\"", "\n", "hsv_list", "=", "[", "]", "\n", "for", "path", "in", "paths", ":", "\n", "        ", "img_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INSTAGRAM_DATA", ",", "path", ")", "\n", "img", "=", "io", ".", "imread", "(", "img_path", ")", "\n", "img", "=", "color", ".", "rgb2hsv", "(", "img", ")", "\n", "hsv", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "img", ".", "shape", ")", ")", ":", "\n", "            ", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "                ", "imdata", "=", "img", "[", ":", ",", "i", "]", "\n", "", "elif", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "                ", "imdata", "=", "img", "[", ":", ",", ":", ",", "i", "]", "\n", "", "avg", "=", "np", ".", "mean", "(", "imdata", ")", "\n", "hsv", ".", "append", "(", "avg", ")", "\n", "", "hsv_list", ".", "append", "(", "hsv", ")", "\n", "", "return", "np", ".", "mean", "(", "hsv_list", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_textual_features": [[89, 99], ["dict", "dict", "dict.items", "tokenizer.tokenize", "tokens_list.extend", "collections.Counter", "zip", "len", "len", "parse"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize"], ["", "def", "get_textual_features", "(", "captions", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "    ", "tokens_list", "=", "[", "]", "\n", "for", "c", "in", "captions", ":", "\n", "        ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "c", ")", "\n", "tokens_list", ".", "extend", "(", "tokens", ")", "\n", "", "counts", "=", "dict", "(", "Counter", "(", "category", "for", "token", "in", "tokens_list", "for", "category", "in", "parse", "(", "token", ")", ")", ")", "\n", "features", "=", "dict", "(", "zip", "(", "category_names", ",", "[", "0", "]", "*", "len", "(", "category_names", ")", ")", ")", "\n", "for", "k", ",", "v", "in", "counts", ".", "items", "(", ")", ":", "\n", "        ", "features", "[", "k", "]", "=", "v", "/", "len", "(", "captions", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_features_from_post": [[101, 111], ["dict", "feature_engineering.get_visual_features", "feature_engineering.get_textual_features", "feature_engineering.get_mean_std_from_ftrs", "get_mean_std_from_ftrs.update", "post.get_img_path_list"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_visual_features", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_textual_features", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_mean_std_from_ftrs", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "get_features_from_post", "(", "post", ":", "InstagramPost", ")", ":", "\n", "    ", "ftrs", "=", "dict", "(", "hue", "=", "0", ",", "saturation", "=", "0", ",", "value", "=", "0", ")", "\n", "h", ",", "s", ",", "v", "=", "get_visual_features", "(", "post", ".", "get_img_path_list", "(", ")", ")", "\n", "textual_ftrs", "=", "get_textual_features", "(", "[", "post", ".", "caption", "]", ")", "\n", "ftrs", "[", "\"hue\"", "]", "=", "h", "\n", "ftrs", "[", "\"saturation\"", "]", "=", "s", "\n", "ftrs", "[", "\"value\"", "]", "=", "v", "\n", "ftrs", "=", "get_mean_std_from_ftrs", "(", "ftrs", ")", "\n", "ftrs", ".", "update", "(", "textual_ftrs", ")", "\n", "return", "ftrs", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training.Trainer.__init__": [[17, 40], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "model.to", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "training.Trainer.logit_threshold.to", "len", "print", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "dataloaders", ",", "dataset_sizes", ",", "criterion", ",", "optimizer", ",", "\n", "scheduler", ",", "config", ",", "num_epochs", "=", "100", ",", "threshold", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "general_config", "=", "self", ".", "config", ".", "general", "\n", "gpus", "=", "general_config", "[", "\"gpus\"", "]", "\n", "self", ".", "acc_loss", "=", "{", "\"train\"", ":", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", "}", ",", "\n", "\"val\"", ":", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", "}", "}", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\n", "f\"cuda:{gpus[0]}\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "len", "(", "gpus", ")", ">", "1", ":", "\n", "           ", "print", "(", "f\"Using {gpus} GPUs!\"", ")", "\n", "self", ".", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "gpus", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Using device \"", ",", "self", ".", "device", ")", "\n", "", "self", ".", "dataset_sizes", "=", "dataset_sizes", "\n", "self", ".", "dataloaders", "=", "dataloaders", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "self", ".", "logit_threshold", "=", "torch", ".", "tensor", "(", "threshold", "/", "(", "1", "-", "threshold", ")", ")", ".", "log", "(", ")", "\n", "self", ".", "logit_threshold", "=", "self", ".", "logit_threshold", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training.Trainer.train_model": [[41, 117], ["time.time", "copy.deepcopy", "range", "print", "print", "training.Trainer.model.load_state_dict", "training.Trainer.model.state_dict", "time.time", "print", "print", "[].append", "[].append", "print", "training.Trainer.scheduler.step", "training.Trainer.model.train", "training.Trainer.model.eval", "labels.to.to.to", "training.Trainer.optimizer.zero_grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "running_corrects.double", "print", "copy.deepcopy", "i.to", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "training.Trainer.model", "training.Trainer.criterion", "training.Trainer.item", "inputs[].size", "training.Trainer.model.state_dict", "labels.to.to.float", "training.Trainer.backward", "training.Trainer.optimizer.step", "preds.long"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.load_state_dict", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.state_dict", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.lookahead.Lookahead.state_dict", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.optim.novograd.Novograd.step"], ["", "def", "train_model", "(", "self", ",", "verbose", "=", "True", ")", ":", "\n", "\n", "        ", "since", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "acc_loss", "=", "{", "\"train\"", ":", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", "}", ",", "\n", "\"val\"", ":", "{", "\"loss\"", ":", "[", "]", ",", "\"acc\"", ":", "[", "]", "}", "}", "\n", "\n", "best_model_wts", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "best_acc", "=", "0.0", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "num_epochs", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "self", ".", "num_epochs", "-", "1", ")", ")", "\n", "print", "(", "'-'", "*", "10", ")", "\n", "\n", "# Each epoch has a training and validation phase", "\n", "", "for", "phase", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "                ", "if", "phase", "==", "'train'", ":", "\n", "                    ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "# Set model to training mode", "\n", "", "else", ":", "\n", "                    ", "self", ".", "model", ".", "eval", "(", ")", "# Set model to evaluate mode", "\n", "\n", "", "running_loss", "=", "0.0", "\n", "running_corrects", "=", "0", "\n", "\n", "# Iterate over data.", "\n", "for", "*", "inputs", ",", "labels", "in", "self", ".", "dataloaders", "[", "phase", "]", ":", "\n", "                    ", "inputs", "=", "[", "i", ".", "to", "(", "self", ".", "device", ")", "for", "i", "in", "inputs", "]", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# zero the parameter gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# forward", "\n", "# track history if only in train", "\n", "with", "torch", ".", "set_grad_enabled", "(", "phase", "==", "'train'", ")", ":", "\n", "                        ", "outputs", "=", "self", ".", "model", "(", "*", "inputs", ")", "\n", "# _, preds = torch.max(outputs, 1)", "\n", "preds", "=", "outputs", ">", "self", ".", "logit_threshold", "\n", "loss", "=", "self", ".", "criterion", "(", "outputs", ",", "labels", ".", "float", "(", ")", ")", "\n", "\n", "# backward + optimize only if in training phase", "\n", "if", "phase", "==", "'train'", ":", "\n", "                            ", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# statistics", "\n", "", "", "running_loss", "+=", "loss", ".", "item", "(", ")", "*", "inputs", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "running_corrects", "+=", "torch", ".", "sum", "(", "preds", ".", "long", "(", ")", "==", "labels", ".", "data", ")", "\n", "\n", "", "epoch_loss", "=", "running_loss", "/", "self", ".", "dataset_sizes", "[", "phase", "]", "\n", "epoch_acc", "=", "(", "running_corrects", ".", "double", "(", ")", "/", "\n", "self", ".", "dataset_sizes", "[", "phase", "]", ")", "\n", "\n", "if", "verbose", ":", "\n", "                    ", "print", "(", "'{} Loss: {:.4f} Acc: {:.4f}'", ".", "format", "(", "\n", "phase", ",", "epoch_loss", ",", "epoch_acc", ")", ")", "\n", "", "self", ".", "acc_loss", "[", "phase", "]", "[", "\"loss\"", "]", ".", "append", "(", "epoch_loss", ")", "\n", "self", ".", "acc_loss", "[", "phase", "]", "[", "\"acc\"", "]", ".", "append", "(", "epoch_acc", ")", "\n", "\n", "# deep copy the model", "\n", "if", "phase", "==", "'val'", "and", "epoch_acc", ">", "best_acc", ":", "\n", "                    ", "best_acc", "=", "epoch_acc", "\n", "best_model_wts", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "", "", "if", "verbose", ":", "\n", "                ", "print", "(", ")", "\n", "\n", "", "", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "since", "\n", "print", "(", "'Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "\n", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ")", "\n", "print", "(", "'Best val Acc: {:4f}'", ".", "format", "(", "best_acc", ")", ")", "\n", "\n", "# load best model weights", "\n", "self", ".", "model", ".", "load_state_dict", "(", "best_model_wts", ")", "\n", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training._init_fn": [[118, 120], ["numpy.random.seed"], "function", ["None"], ["", "", "def", "_init_fn", "(", "worker_id", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "12", "+", "worker_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training.train_model": [[121, 181], ["print", "print", "getattr", "getattr.get().lower", "readorsee.data.dataset.DepressionCorpus", "torch.BCEWithLogitsLoss", "filter", "torch.optim.lr_scheduler.StepLR", "torch.utils.data.DataLoader", "readorsee.data.dataset.DepressionCorpus", "torch.utils.data.DataLoader", "training.Trainer", "training.Trainer.train_model", "model.set_out_ftrs", "model.parameters", "getattr", "len", "len", "getattr.get"], "function", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.training.training.train_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalClassifier.set_out_ftrs"], ["", "def", "train_model", "(", "model", ",", "days", ",", "dataset", ",", "fasttext", ",", "config", ",", "verbose", ")", ":", "\n", "    ", "print", "(", "\"======================\"", ")", "\n", "print", "(", "\"Training...\"", ")", "\n", "media_type", "=", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "config", ",", "media_type", ")", "\n", "embedder", "=", "media_config", ".", "get", "(", "\"txt_embedder\"", ",", "\"\"", ")", ".", "lower", "(", ")", "\n", "\n", "train", "=", "DepressionCorpus", "(", "\n", "observation_period", "=", "days", ",", "\n", "subset", "=", "\"train\"", ",", "\n", "fasttext", "=", "fasttext", ",", "\n", "dataset", "=", "dataset", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "if", "embedder", "==", "\"bow\"", ":", "\n", "        ", "model", ".", "set_out_ftrs", "(", "train", ".", "bow_ftrs_size", ")", "\n", "\n", "", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "general", "=", "config", ".", "general", "\n", "optimizer_name", "=", "media_config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "\n", "opt_params", "=", "media_config", "[", "\"optimizer\"", "]", "[", "\"params\"", "]", "\n", "scheduler", "=", "media_config", "[", "\"scheduler\"", "]", "\n", "optimizer_ft", "=", "getattr", "(", "optim", ",", "optimizer_name", ")", "(", "parameters", ",", "**", "opt_params", ")", "\n", "exp_lr_scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer_ft", ",", "**", "scheduler", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "train", ",", "\n", "batch_size", "=", "general", "[", "\"batch_size\"", "]", ",", "\n", "shuffle", "=", "general", "[", "\"shuffle\"", "]", ",", "\n", "pin_memory", "=", "True", ",", "\n", "worker_init_fn", "=", "_init_fn", ")", "\n", "\n", "val", "=", "DepressionCorpus", "(", "observation_period", "=", "days", ",", "\n", "subset", "=", "\"val\"", ",", "\n", "fasttext", "=", "fasttext", ",", "\n", "dataset", "=", "dataset", ",", "\n", "config", "=", "config", "\n", ")", "\n", "\n", "val_loader", "=", "DataLoader", "(", "val", ",", "\n", "batch_size", "=", "general", "[", "\"batch_size\"", "]", ",", "\n", "shuffle", "=", "general", "[", "\"shuffle\"", "]", ",", "\n", "pin_memory", "=", "True", ",", "\n", "worker_init_fn", "=", "_init_fn", ")", "\n", "\n", "dataloaders", "=", "{", "\"train\"", ":", "train_loader", ",", "\"val\"", ":", "val_loader", "}", "\n", "dataset_sizes", "=", "{", "\"train\"", ":", "len", "(", "train", ")", ",", "\"val\"", ":", "len", "(", "val", ")", "}", "\n", "\n", "trainer", "=", "Trainer", "(", "model", ",", "\n", "dataloaders", ",", "\n", "dataset_sizes", ",", "\n", "criterion", ",", "\n", "optimizer_ft", ",", "\n", "exp_lr_scheduler", ",", "\n", "config", ",", "\n", "general", "[", "\"epochs\"", "]", ")", "\n", "\n", "trained_model", "=", "trainer", ".", "train_model", "(", "verbose", ")", "\n", "return", "trained_model", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.__init__": [[22, 36], ["len", "numpy.zeros", "type", "range", "len", "confusion_matrix.ConfusionMatrix.labels.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Constructor with input labels\n\n        :param labels: Either a dictionary (`k=int,v=str`) or an array of labels\n        \"\"\"", "\n", "if", "type", "(", "labels", ")", "is", "dict", ":", "\n", "            ", "self", ".", "labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                ", "self", ".", "labels", ".", "append", "(", "labels", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "labels", "=", "labels", "\n", "", "nc", "=", "len", "(", "self", ".", "labels", ")", "\n", "self", ".", "_cm", "=", "np", ".", "zeros", "(", "(", "nc", ",", "nc", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "_experiments", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add": [[37, 45], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "truth", ",", "guess", ")", ":", "\n", "        ", "\"\"\"Add a single value to the confusion matrix based off `truth` and `guess`\n\n        :param truth: The real `y` value (or ground truth label)\n        :param guess: The guess for `y` value (or assertion)\n        \"\"\"", "\n", "\n", "self", ".", "_cm", "[", "truth", ",", "guess", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.__str__": [[46, 59], ["max", "enumerate", "enumerate", "range", "max", "len", "len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "values", "=", "[", "]", "\n", "width", "=", "max", "(", "8", ",", "max", "(", "len", "(", "x", ")", "for", "x", "in", "self", ".", "labels", ")", "+", "1", ")", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "[", "\"\"", "]", "+", "self", ".", "labels", ")", ":", "\n", "            ", "values", "+=", "[", "\"{:>{width}}\"", ".", "format", "(", "label", ",", "width", "=", "width", "+", "1", ")", "]", "\n", "", "values", "+=", "[", "\"\\n\"", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", ":", "\n", "            ", "values", "+=", "[", "\"{:>{width}}\"", ".", "format", "(", "label", ",", "width", "=", "width", "+", "1", ")", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "labels", ")", ")", ":", "\n", "                ", "values", "+=", "[", "\"{:{width}d}\"", ".", "format", "(", "self", ".", "_cm", "[", "i", ",", "j", "]", ",", "width", "=", "width", "+", "1", ")", "]", "\n", "", "values", "+=", "[", "\"\\n\"", "]", "\n", "", "values", "+=", "[", "\"\\n\"", "]", "\n", "return", "\"\"", ".", "join", "(", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.save": [[60, 71], ["collections.OrderedDict", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "enumerate", "row_dict.update", "csv.DictWriter.writerow", "enumerate"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "outfile", ")", ":", "\n", "        ", "ordered_fieldnames", "=", "OrderedDict", "(", "\n", "[", "(", "\"labels\"", ",", "None", ")", "]", "+", "[", "(", "l", ",", "None", ")", "for", "l", "in", "self", ".", "labels", "]", "\n", ")", "\n", "with", "open", "(", "outfile", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "dw", "=", "csv", ".", "DictWriter", "(", "f", ",", "delimiter", "=", "\",\"", ",", "fieldnames", "=", "ordered_fieldnames", ")", "\n", "dw", ".", "writeheader", "(", ")", "\n", "for", "index", ",", "row", "in", "enumerate", "(", "self", ".", "_cm", ")", ":", "\n", "                ", "row_dict", "=", "{", "l", ":", "row", "[", "i", "]", "for", "i", ",", "l", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "row_dict", ".", "update", "(", "{", "\"labels\"", ":", "self", ".", "labels", "[", "index", "]", "}", ")", "\n", "dw", ".", "writerow", "(", "row_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.reset": [[72, 76], ["None"], "methods", ["None"], ["", "", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the matrix\n        \"\"\"", "\n", "self", ".", "_cm", "*=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_correct": [[77, 83], ["confusion_matrix.ConfusionMatrix._cm.diagonal().sum", "confusion_matrix.ConfusionMatrix._cm.diagonal"], "methods", ["None"], ["", "def", "get_correct", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the diagonals of the confusion matrix\n\n        :return: (``int``) Number of correct classifications\n        \"\"\"", "\n", "return", "self", ".", "_cm", ".", "diagonal", "(", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_total": [[84, 90], ["confusion_matrix.ConfusionMatrix._cm.sum"], "methods", ["None"], ["", "def", "get_total", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get total classifications\n\n        :return: (``int``) total classifications\n        \"\"\"", "\n", "return", "self", ".", "_cm", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_acc": [[91, 97], ["float", "confusion_matrix.ConfusionMatrix.get_total", "confusion_matrix.ConfusionMatrix.get_correct"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_total", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_correct"], ["", "def", "get_acc", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the accuracy\n\n        :return: (``float``) accuracy\n        \"\"\"", "\n", "return", "float", "(", "self", ".", "get_correct", "(", ")", ")", "/", "self", ".", "get_total", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall": [[98, 106], ["numpy.sum", "numpy.diag", "numpy.sum.astype"], "methods", ["None"], ["", "def", "get_recall", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the recall\n\n        :return: (``float``) recall\n        \"\"\"", "\n", "total", "=", "np", ".", "sum", "(", "self", ".", "_cm", ",", "axis", "=", "1", ")", "\n", "total", "=", "(", "total", "==", "0", ")", "+", "total", "\n", "return", "np", ".", "diag", "(", "self", ".", "_cm", ")", "/", "total", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_support": [[107, 109], ["numpy.sum"], "methods", ["None"], ["", "def", "get_support", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "self", ".", "_cm", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision": [[110, 118], ["numpy.sum", "numpy.diag", "numpy.sum.astype"], "methods", ["None"], ["", "def", "get_precision", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the precision\n        :return: (``float``) precision\n        \"\"\"", "\n", "\n", "total", "=", "np", ".", "sum", "(", "self", ".", "_cm", ",", "axis", "=", "0", ")", "\n", "total", "=", "(", "total", "==", "0", ")", "+", "total", "\n", "return", "np", ".", "diag", "(", "self", ".", "_cm", ")", "/", "total", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_precision": [[119, 125], ["numpy.mean", "confusion_matrix.ConfusionMatrix.get_precision"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision"], ["", "def", "get_mean_precision", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the mean precision across labels\n\n        :return: (``float``) mean precision\n        \"\"\"", "\n", "return", "np", ".", "mean", "(", "self", ".", "get_precision", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_precision": [[126, 128], ["numpy.sum", "float", "confusion_matrix.ConfusionMatrix.get_total", "confusion_matrix.ConfusionMatrix.get_precision", "confusion_matrix.ConfusionMatrix.get_support"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_total", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_support"], ["", "def", "get_weighted_precision", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "self", ".", "get_precision", "(", ")", "*", "self", ".", "get_support", "(", ")", ")", "/", "float", "(", "self", ".", "get_total", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_recall": [[129, 135], ["numpy.mean", "confusion_matrix.ConfusionMatrix.get_recall"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall"], ["", "def", "get_mean_recall", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the mean recall across labels\n\n        :return: (``float``) mean recall\n        \"\"\"", "\n", "return", "np", ".", "mean", "(", "self", ".", "get_recall", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_recall": [[136, 138], ["numpy.sum", "float", "confusion_matrix.ConfusionMatrix.get_total", "confusion_matrix.ConfusionMatrix.get_recall", "confusion_matrix.ConfusionMatrix.get_support"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_total", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_support"], ["", "def", "get_weighted_recall", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "self", ".", "get_recall", "(", ")", "*", "self", ".", "get_support", "(", ")", ")", "/", "float", "(", "self", ".", "get_total", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_f": [[139, 142], ["numpy.sum", "float", "confusion_matrix.ConfusionMatrix.get_total", "confusion_matrix.ConfusionMatrix.get_class_f", "confusion_matrix.ConfusionMatrix.get_support"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_total", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_class_f", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_support"], ["", "def", "get_weighted_f", "(", "self", ",", "beta", "=", "1", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "self", ".", "get_class_f", "(", "beta", ")", "*", "self", ".", "get_support", "(", ")", ")", "/", "float", "(", "\n", "self", ".", "get_total", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_macro_f": [[144, 153], ["numpy.mean", "Exception", "confusion_matrix.ConfusionMatrix.get_class_f"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_class_f"], ["", "def", "get_macro_f", "(", "self", ",", "beta", "=", "1", ")", ":", "\n", "        ", "\"\"\"Get the macro F_b, with adjustable beta (defaulting to F1)\n\n        :param beta: (``float``) defaults to 1 (F1)\n        :return: (``float``) macro F_b\n        \"\"\"", "\n", "if", "beta", "<", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Beta must be greater than 0\"", ")", "\n", "", "return", "np", ".", "mean", "(", "self", ".", "get_class_f", "(", "beta", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_class_f": [[154, 163], ["confusion_matrix.ConfusionMatrix.get_precision", "confusion_matrix.ConfusionMatrix.get_recall"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall"], ["", "def", "get_class_f", "(", "self", ",", "beta", "=", "1", ")", ":", "\n", "        ", "p", "=", "self", ".", "get_precision", "(", ")", "\n", "r", "=", "self", ".", "get_recall", "(", ")", "\n", "\n", "b", "=", "beta", "*", "beta", "\n", "d", "=", "b", "*", "p", "+", "r", "\n", "d", "=", "(", "d", "==", "0", ")", "+", "d", "\n", "\n", "return", "(", "b", "+", "1", ")", "*", "p", "*", "r", "/", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_f": [[164, 178], ["confusion_matrix.ConfusionMatrix.get_precision", "confusion_matrix.ConfusionMatrix.get_recall", "Exception"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall"], ["", "def", "get_f", "(", "self", ",", "beta", "=", "1", ")", ":", "\n", "        ", "\"\"\"Get 2 class F_b, with adjustable beta (defaulting to F1)\n\n        :param beta: (``float``) defaults to 1 (F1)\n        :return: (``float``) 2-class F_b\n        \"\"\"", "\n", "p", "=", "self", ".", "get_precision", "(", ")", "[", "1", "]", "\n", "r", "=", "self", ".", "get_recall", "(", ")", "[", "1", "]", "\n", "if", "beta", "<", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Beta must be greater than 0\"", ")", "\n", "", "d", "=", "beta", "*", "beta", "*", "p", "+", "r", "\n", "if", "d", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "(", "beta", "*", "beta", "+", "1", ")", "*", "p", "*", "r", "/", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics": [[179, 198], ["confusion_matrix.ConfusionMatrix.get_acc", "len", "confusion_matrix.ConfusionMatrix.get_f", "confusion_matrix.ConfusionMatrix.get_mean_precision", "confusion_matrix.ConfusionMatrix.get_mean_recall", "confusion_matrix.ConfusionMatrix.get_macro_f", "confusion_matrix.ConfusionMatrix.get_weighted_precision", "confusion_matrix.ConfusionMatrix.get_weighted_recall", "confusion_matrix.ConfusionMatrix.get_weighted_f", "confusion_matrix.ConfusionMatrix.get_precision", "confusion_matrix.ConfusionMatrix.get_recall"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_acc", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_f", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_recall", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_macro_f", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_recall", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_weighted_f", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_precision", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_recall"], ["", "def", "get_all_metrics", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make a map of metrics suitable for reporting, keyed by metric name\n\n        :return: (``dict``) Map of metrics keyed by metric names\n        \"\"\"", "\n", "metrics", "=", "{", "\"acc\"", ":", "self", ".", "get_acc", "(", ")", "}", "\n", "# If 2 class, assume second class is positive AKA 1", "\n", "if", "len", "(", "self", ".", "labels", ")", "==", "2", ":", "\n", "            ", "metrics", "[", "\"precision\"", "]", "=", "self", ".", "get_precision", "(", ")", "[", "1", "]", "\n", "metrics", "[", "\"recall\"", "]", "=", "self", ".", "get_recall", "(", ")", "[", "1", "]", "\n", "metrics", "[", "\"f1\"", "]", "=", "self", ".", "get_f", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "metrics", "[", "\"mean_precision\"", "]", "=", "self", ".", "get_mean_precision", "(", ")", "\n", "metrics", "[", "\"mean_recall\"", "]", "=", "self", ".", "get_mean_recall", "(", ")", "\n", "metrics", "[", "\"macro_f1\"", "]", "=", "self", ".", "get_macro_f", "(", "1", ")", "\n", "metrics", "[", "\"weighted_precision\"", "]", "=", "self", ".", "get_weighted_precision", "(", ")", "\n", "metrics", "[", "\"weighted_recall\"", "]", "=", "self", ".", "get_weighted_recall", "(", ")", "\n", "metrics", "[", "\"weighted_f1\"", "]", "=", "self", ".", "get_weighted_f", "(", "1", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_batch": [[199, 208], ["zip", "confusion_matrix.ConfusionMatrix.add"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add"], ["", "def", "add_batch", "(", "self", ",", "truth", ",", "guess", ")", ":", "\n", "        ", "\"\"\"Add a batch of data to the confusion matrix\n\n        :param truth: The truth tensor\n        :param guess: The guess tensor\n        :return:\n        \"\"\"", "\n", "for", "truth_i", ",", "guess_i", "in", "zip", "(", "truth", ",", "guess", ")", ":", "\n", "            ", "self", ".", "add", "(", "truth_i", ",", "guess_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset": [[209, 214], ["confusion_matrix.ConfusionMatrix.add_batch", "confusion_matrix.ConfusionMatrix.get_all_metrics", "confusion_matrix.ConfusionMatrix.reset"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_batch", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.reset"], ["", "", "def", "get_all_metrics_and_reset", "(", "self", ",", "truth", ",", "guess", ")", ":", "\n", "        ", "self", ".", "add_batch", "(", "truth", ",", "guess", ")", "\n", "single_example_metrics", "=", "self", ".", "get_all_metrics", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "return", "single_example_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_experiment": [[215, 248], ["confusion_matrix.ConfusionMatrix.get_truth_and_guess_for_user", "confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset", "confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset", "confusion_matrix.ConfusionMatrix._experiments.append", "confusion_matrix.ConfusionMatrix.add_experiment_for_ftrs"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_truth_and_guess_for_user", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_experiment_for_ftrs"], ["", "def", "add_experiment", "(", "self", ",", "truth", ",", "guess", ",", "logits", ",", "u_id", ",", "config", ")", ":", "\n", "        ", "media_type", "=", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "\n", "if", "media_type", "==", "\"ftrs\"", ":", "\n", "            ", "self", ".", "add_experiment_for_ftrs", "(", "truth", ",", "guess", ",", "logits", ",", "u_id", ",", "config", ")", "\n", "return", "None", "\n", "\n", "", "post_params", "=", "{", "\"truth\"", ":", "truth", ",", "\"guess\"", ":", "guess", ",", "\"logits\"", ":", "logits", ",", "\"id\"", ":", "u_id", "}", "\n", "\n", "user_truth", ",", "user_guess", ",", "logits", ",", "ids", "=", "self", ".", "get_truth_and_guess_for_user", "(", "\n", "truth", ",", "guess", ",", "logits", ",", "u_id", "\n", ")", "\n", "user_params", "=", "{", "\n", "\"truth\"", ":", "user_truth", ",", "\n", "\"guess\"", ":", "user_guess", ",", "\n", "\"logits\"", ":", "logits", ",", "\n", "\"id\"", ":", "ids", ",", "\n", "}", "\n", "experiment", "=", "{", "\n", "\"user_metrics\"", ":", "None", ",", "\n", "\"post_metrics\"", ":", "None", ",", "\n", "\"user_params\"", ":", "None", ",", "\n", "\"post_params\"", ":", "None", ",", "\n", "\"config\"", ":", "config", ".", "__dict__", ",", "\n", "}", "\n", "experiment", "[", "\"user_metrics\"", "]", "=", "self", ".", "get_all_metrics_and_reset", "(", "\n", "user_truth", ",", "user_guess", "\n", ")", "\n", "experiment", "[", "\"post_metrics\"", "]", "=", "self", ".", "get_all_metrics_and_reset", "(", "truth", ",", "guess", ")", "\n", "experiment", "[", "\"user_params\"", "]", "=", "user_params", "\n", "experiment", "[", "\"post_params\"", "]", "=", "post_params", "\n", "\n", "self", ".", "_experiments", ".", "append", "(", "experiment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_experiment_for_ftrs": [[249, 261], ["confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset", "confusion_matrix.ConfusionMatrix._experiments.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_all_metrics_and_reset"], ["", "def", "add_experiment_for_ftrs", "(", "self", ",", "truth", ",", "guess", ",", "logits", ",", "u_id", ",", "config", ")", ":", "\n", "        ", "user_params", "=", "{", "\"truth\"", ":", "truth", ",", "\"guess\"", ":", "guess", ",", "\"logits\"", ":", "logits", ",", "\"id\"", ":", "u_id", "}", "\n", "experiment", "=", "{", "\n", "\"user_metrics\"", ":", "None", ",", "\n", "\"user_params\"", ":", "None", ",", "\n", "\"config\"", ":", "config", ".", "__dict__", ",", "\n", "}", "\n", "experiment", "[", "\"user_metrics\"", "]", "=", "self", ".", "get_all_metrics_and_reset", "(", "\n", "truth", ",", "guess", "\n", ")", "\n", "experiment", "[", "\"user_params\"", "]", "=", "user_params", "\n", "self", ".", "_experiments", ".", "append", "(", "experiment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_truth_and_guess_for_user": [[262, 284], ["numpy.array", "pandas.DataFrame", "numpy.unique", "len", "list", "numpy.unique", "int", "[].values.astype", "[].values.astype", "Y_true_per_user.append", "Y_pred_per_user.append", "arr_logits.append", "zip", "[].values.astype.mean"], "methods", ["None"], ["", "def", "get_truth_and_guess_for_user", "(", "self", ",", "post_truth", ",", "post_guess", ",", "post_logits", ",", "u_id", ")", ":", "\n", "        ", "samples", "=", "np", ".", "array", "(", "list", "(", "zip", "(", "post_truth", ",", "post_guess", ",", "post_logits", ",", "u_id", ")", ")", ")", "\n", "samples", "=", "pd", ".", "DataFrame", "(", "samples", ",", "columns", "=", "[", "\"true\"", ",", "\"pred\"", ",", "\"logits\"", ",", "\"id\"", "]", ")", "\n", "users", "=", "np", ".", "unique", "(", "samples", "[", "\"id\"", "]", ")", "\n", "n_classes", "=", "len", "(", "np", ".", "unique", "(", "samples", "[", "\"true\"", "]", ")", ")", "\n", "\n", "Y_true_per_user", "=", "[", "]", "\n", "Y_pred_per_user", "=", "[", "]", "\n", "arr_logits", "=", "[", "]", "\n", "for", "u", "in", "users", ":", "\n", "            ", "real_class", "=", "int", "(", "samples", "[", "samples", "[", "\"id\"", "]", "==", "u", "]", "[", "\"true\"", "]", ".", "values", "[", "0", "]", ")", "\n", "preds", "=", "samples", "[", "samples", "[", "\"id\"", "]", "==", "u", "]", "[", "\"pred\"", "]", ".", "values", ".", "astype", "(", "int", ")", "\n", "logits", "=", "samples", "[", "samples", "[", "\"id\"", "]", "==", "u", "]", "[", "\"logits\"", "]", ".", "values", ".", "astype", "(", "float", ")", "\n", "pred_class", "=", "1", "if", "logits", ".", "mean", "(", ")", ">", "0.5", "else", "0", "\n", "# print(f\"=====>Logits: {logits}\\nType of logits: {type(logits)}\")", "\n", "# counts = np.bincount(preds)", "\n", "# pred_class = len(counts) - np.argmax(counts[::-1]) - 1", "\n", "Y_true_per_user", ".", "append", "(", "real_class", ")", "\n", "Y_pred_per_user", ".", "append", "(", "pred_class", ")", "\n", "arr_logits", ".", "append", "(", "logits", ")", "\n", "\n", "", "return", "Y_true_per_user", ",", "Y_pred_per_user", ",", "arr_logits", ",", "users", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics_of_all_experiments": [[285, 293], ["ValueError", "confusion_matrix.ConfusionMatrix.get_mean_metrics", "confusion_matrix.ConfusionMatrix.get_mean_metrics", "confusion_matrix.ConfusionMatrix.get_mean_metrics"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics"], ["", "def", "get_mean_metrics_of_all_experiments", "(", "self", ",", "config", ")", ":", "\n", "        ", "if", "not", "self", ".", "_experiments", ":", "\n", "            ", "raise", "ValueError", "(", "\"There are no experiments to take the mean.\"", ")", "\n", "\n", "", "if", "config", ".", "general", "[", "\"media_type\"", "]", "==", "\"ftrs\"", ":", "\n", "            ", "return", "self", ".", "get_mean_metrics", "(", "\"user_metrics\"", ")", ",", "None", "\n", "\n", "", "return", "self", ".", "get_mean_metrics", "(", "\"user_metrics\"", ")", ",", "self", ".", "get_mean_metrics", "(", "\"post_metrics\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.get_mean_metrics": [[294, 308], ["precision.append", "recall.append", "f1.append", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["None"], ["", "def", "get_mean_metrics", "(", "self", ",", "name", ")", ":", "\n", "        ", "precision", "=", "[", "]", "\n", "recall", "=", "[", "]", "\n", "f1", "=", "[", "]", "\n", "for", "exp", "in", "self", ".", "_experiments", ":", "\n", "            ", "precision", ".", "append", "(", "exp", "[", "name", "]", "[", "\"precision\"", "]", ")", "\n", "recall", ".", "append", "(", "exp", "[", "name", "]", "[", "\"recall\"", "]", ")", "\n", "f1", ".", "append", "(", "exp", "[", "name", "]", "[", "\"f1\"", "]", ")", "\n", "", "results", "=", "{", "\n", "\"precision\"", ":", "np", ".", "mean", "(", "precision", ")", ",", "\n", "\"recall\"", ":", "np", ".", "mean", "(", "recall", ")", ",", "\n", "\"f1\"", ":", "np", ".", "mean", "(", "f1", ")", "\n", "}", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.save_experiments": [[309, 316], ["os.path.join", "os.path.isdir", "os.mkdir", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save_experiments", "(", "self", ",", "experiment_name", ")", ":", "\n", "        ", "path", "=", "settings", ".", "PATH_TO_EXPERIMENTS", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "path", ")", "\n", "", "exp_file_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "experiment_name", ")", "\n", "with", "open", "(", "f\"{exp_file_path}.experiment\"", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "_experiments", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.reset_experiments": [[317, 319], ["None"], "methods", ["None"], ["", "", "def", "reset_experiments", "(", "self", ")", ":", "\n", "        ", "self", ".", "_experiments", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.delete_saved_experiments": [[320, 326], ["os.path.isdir", "glob.glob", "os.remove"], "methods", ["None"], ["", "def", "delete_saved_experiments", "(", "self", ")", ":", "\n", "        ", "path", "=", "settings", ".", "PATH_TO_EXPERIMENTS", "\n", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "files", "=", "glob", ".", "glob", "(", "path", "+", "os", ".", "sep", "+", "\"*.experiment\"", ")", "\n", "for", "f", "in", "files", ":", "\n", "                ", "os", ".", "remove", "(", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ImgFCBlock.__init__": [[10, 13], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ftrs", ",", "out_ftrs", "=", "1", ")", ":", "\n", "        ", "super", "(", "ImgFCBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Dropout", "(", "0.5", ")", ",", "nn", ".", "Linear", "(", "n_ftrs", ",", "out_ftrs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ImgFCBlock.forward": [[14, 16], ["torchvision.models.ImgFCBlock.fc().squeeze", "torchvision.models.ImgFCBlock.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ResNet.__init__": [[28, 40], ["torch.Module.__init__", "print", "torchvision.models.ResNet.get_model", "models.freeze_resnet_layers", "torchvision.models.ImgFCBlock", "getattr", "img_embedder.lower"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ResNet.get_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.freeze_resnet_layers"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "img_embedder", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "[", "\"img_embedder\"", "]", "\n", "print", "(", "f\"Using {img_embedder} embedder.\"", ")", "\n", "\n", "self", ".", "resnet", "=", "self", ".", "get_model", "(", "img_embedder", ".", "lower", "(", ")", ")", "\n", "freeze_resnet_layers", "(", "7", ",", "self", ".", "resnet", ")", "\n", "n_ftrs", "=", "self", ".", "resnet", ".", "fc", ".", "in_features", "\n", "self", ".", "out_ftrs", "=", "n_ftrs", "\n", "self", ".", "resnet", ".", "fc", "=", "ImgFCBlock", "(", "n_ftrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ResNet.forward": [[41, 44], ["torchvision.models.ResNet.resnet", "torchvision.models.ResNet.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "resnet", "(", "x", ")", "\n", "return", "x", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ResNet.get_model": [[45, 50], ["torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "getattr"], "methods", ["None"], ["", "def", "get_model", "(", "self", ",", "embedder_name", ")", ":", "\n", "        ", "if", "embedder_name", "==", "\"resnext\"", ":", "\n", "            ", "return", "torch", ".", "hub", ".", "load", "(", "\"facebookresearch/WSL-Images\"", ",", "\"resnext101_32x8d_wsl\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "getattr", "(", "models", ",", "embedder_name", ")", "(", "pretrained", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.TxtFCBlock.__init__": [[61, 68], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ftrs", ",", "final_ftrs", "=", "1", ")", ":", "\n", "        ", "super", "(", "TxtFCBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "n_ftrs", ",", "n_ftrs", "//", "2", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "n_ftrs", "//", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "n_ftrs", "//", "2", ",", "final_ftrs", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.TxtFCBlock.forward": [[70, 72], ["torchvision.models.TxtFCBlock.fc().squeeze", "torchvision.models.TxtFCBlock.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ELMo.__init__": [[75, 90], ["torch.Module.__init__", "allennlp.modules.elmo.Elmo", "torchvision.models.ELMo.embedding.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "ELMo", ",", "self", ")", ".", "__init__", "(", ")", "\n", "options_path", "=", "settings", ".", "PATH_TO_ELMO_OPTIONS", "\n", "weights_path", "=", "settings", ".", "PATH_TO_ELMO_WEIGHTS", "\n", "\n", "self", ".", "embedding", "=", "Elmo", "(", "\n", "options_path", ",", "\n", "weights_path", ",", "\n", "num_output_representations", "=", "1", ",", "\n", "dropout", "=", "0.5", ",", "\n", "scalar_mix_parameters", "=", "[", "-", "9e10", ",", "1", ",", "-", "9e10", "]", "\n", ")", "\n", "# scalar_mix_parameters=[-9e10, -9e10, 1]", "\n", "self", ".", "out_ftrs", "=", "self", ".", "embedding", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.ELMo.forward": [[91, 96], ["torchvision.models.ELMo.embedding", "x[].float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "\n", "masks", "=", "x", "[", "\"mask\"", "]", ".", "float", "(", ")", "\n", "x", "=", "x", "[", "\"elmo_representations\"", "]", "[", "0", "]", "\n", "return", "{", "\"representation\"", ":", "x", ",", "\"masks\"", ":", "masks", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.FastText.__init__": [[99, 102], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "FastText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "out_ftrs", "=", "300", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.FastText.forward": [[103, 105], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "masks", ")", ":", "\n", "        ", "return", "{", "\"representation\"", ":", "x", ",", "\"masks\"", ":", "masks", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BoW.__init__": [[108, 111], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BoW", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BoW.forward": [[111, 114], ["torchvision.models.BoW.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "return", "{", "\"representation\"", ":", "x", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MeanTxtClassifier.__init__": [[128, 144], ["torch.Module.__init__", "getattr", "print", "models.get_txt_embedder", "hasattr", "torchvision.models.TxtFCBlock", "len"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.get_txt_embedder"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MeanTxtClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "txt_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", "\n", "print", "(", "f\"Using {txt_embedder} embedder.\"", ")", "\n", "\n", "self", ".", "model", "=", "get_txt_embedder", "(", "txt_embedder", ")", "\n", "\n", "if", "hasattr", "(", "self", ".", "model", ",", "\"out_ftrs\"", ")", ":", "\n", "            ", "self", ".", "out_ftrs", "=", "self", ".", "model", ".", "out_ftrs", "\n", "if", "media_config", "[", "\"mean\"", "]", "==", "\"pmean\"", ":", "\n", "                ", "self", ".", "out_ftrs", "=", "self", ".", "out_ftrs", "*", "len", "(", "media_config", "[", "\"pmean\"", "]", ")", "\n", "\n", "", "self", ".", "fc", "=", "TxtFCBlock", "(", "self", ".", "out_ftrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MeanTxtClassifier.forward": [[145, 155], ["torchvision.models.MeanTxtClassifier.fc().squeeze", "torchvision.models.MeanTxtClassifier.model", "torchvision.models.MeanTxtClassifier.model", "readorsee.get_mean", "torchvision.models.MeanTxtClassifier.fc"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.sentence_embeddings.get_mean"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "masks", "=", "None", ")", ":", "\n", "        ", "if", "masks", "is", "None", ":", "\n", "            ", "res", "=", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "model", "(", "x", ",", "masks", ")", "\n", "", "emb", "=", "res", "[", "\"representation\"", "]", "\n", "if", "\"masks\"", "in", "res", ":", "\n", "            ", "masks", "=", "res", "[", "\"masks\"", "]", "\n", "emb", "=", "embed_sentence", ".", "get_mean", "(", "emb", ",", "masks", ",", "self", ".", "config", ")", "\n", "", "return", "self", ".", "fc", "(", "emb", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MeanTxtClassifier.set_out_ftrs": [[156, 158], ["torchvision.models.TxtFCBlock"], "methods", ["None"], ["", "def", "set_out_ftrs", "(", "self", ",", "out_ftrs", ",", "final_ftrs", "=", "1", ")", ":", "\n", "        ", "self", ".", "fc", "=", "TxtFCBlock", "(", "out_ftrs", ",", "final_ftrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.LSTMTxtClassifier.__init__": [[161, 189], ["torch.Module.__init__", "getattr", "print", "models.get_txt_embedder", "print", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "ValueError"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.get_txt_embedder"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "LSTMTxtClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "txt_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", "\n", "print", "(", "f\"Using {txt_embedder} embedder.\"", ")", "\n", "if", "txt_embedder", "not", "in", "[", "\"elmo\"", ",", "\"fasttext\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"LSTMClassifier only supports elmo and fasttext.\"", ")", "\n", "", "self", ".", "hidden_units", "=", "124", "\n", "self", ".", "embedder", "=", "get_txt_embedder", "(", "txt_embedder", ")", "\n", "self", ".", "embed_dims", "=", "self", ".", "embedder", ".", "out_ftrs", "\n", "self", ".", "num_layers", "=", "media_config", "[", "\"LSTM\"", "]", "[", "\"num_layers\"", "]", "\n", "self", ".", "bidirectional", "=", "media_config", "[", "\"LSTM\"", "]", "[", "\"bidirectional\"", "]", "\n", "self", ".", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "self", ".", "out_ftrs", "=", "self", ".", "hidden_units", "*", "self", ".", "num_directions", "\n", "self", ".", "dropout_value", "=", "media_config", "[", "\"LSTM\"", "]", "[", "\"dropout\"", "]", "\n", "print", "(", "f\"===LSTM params {media_config['LSTM']}\"", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "self", ".", "embed_dims", ",", "\n", "self", ".", "hidden_units", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "dropout_value", ",", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "out_ftrs", ",", "1", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "lstm", ".", "weight_hh_l0", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "lstm", ".", "weight_ih_l0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.LSTMTxtClassifier.forward": [[190, 225], ["masks.sum", "len", "masks.sum.sort", "sorted", "emb.permute.permute.permute", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torchvision.models.LSTMTxtClassifier.lstm", "torchvision.models.LSTMTxtClassifier.fc", "torchvision.models.LSTMTxtClassifier.squeeze", "torchvision.models.LSTMTxtClassifier.embedder", "torchvision.models.LSTMTxtClassifier.embedder", "range", "masks.sum.tolist", "torchvision.models.LSTMTxtClassifier.forward.combine_bidir"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "masks", "=", "None", ")", ":", "\n", "        ", "if", "masks", "is", "None", ":", "\n", "            ", "res", "=", "self", ".", "embedder", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "embedder", "(", "x", ",", "masks", ")", "\n", "", "emb", "=", "res", "[", "\"representation\"", "]", "\n", "if", "\"masks\"", "in", "res", ":", "\n", "            ", "masks", "=", "res", "[", "\"masks\"", "]", "\n", "", "lengths", "=", "masks", ".", "sum", "(", "dim", "=", "1", ")", "\n", "bsz", "=", "len", "(", "lengths", ")", "\n", "lengths", ",", "perm_idx", "=", "lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "orig_idx", "=", "sorted", "(", "range", "(", "len", "(", "perm_idx", ")", ")", ",", "key", "=", "perm_idx", ".", "__getitem__", ")", "\n", "emb", "=", "emb", "[", "perm_idx", "]", "\n", "emb", "=", "emb", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "packed", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "emb", ",", "lengths", ".", "tolist", "(", ")", ")", "\n", "_", ",", "(", "hidden", ",", "_", ")", "=", "self", ".", "lstm", "(", "packed", ")", "\n", "\n", "if", "self", ".", "bidirectional", ":", "\n", "\n", "            ", "def", "combine_bidir", "(", "outs", ")", ":", "\n", "                ", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "cat", "(", "[", "outs", "[", "2", "*", "i", "]", ",", "outs", "[", "2", "*", "i", "+", "1", "]", "]", ",", "dim", "=", "0", ")", ".", "view", "(", "\n", "1", ",", "bsz", ",", "self", ".", "out_ftrs", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "", "hidden", "=", "combine_bidir", "(", "hidden", ")", "\n", "# Always take the output from the last LSTM layer", "\n", "", "hidden", "=", "hidden", "[", "-", "1", "]", "\n", "linear", "=", "self", ".", "fc", "(", "hidden", ")", "\n", "linear", "=", "linear", "[", "orig_idx", "]", "\n", "return", "linear", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MLPClassifier.__init__": [[228, 238], ["torch.Module.__init__", "print", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torchvision.models.TxtFCBlock", "getattr"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MLPClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "features", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "[", "\"features\"", "]", "\n", "ftrs_map_n_ftrs", "=", "{", "\"vis_ftrs\"", ":", "20", ",", "\"txt_ftrs\"", ":", "72", ",", "\"both\"", ":", "84", "}", "\n", "n_ftrs", "=", "ftrs_map_n_ftrs", "[", "features", "]", "\n", "print", "(", "\"FEATURES SIZE:\"", ",", "n_ftrs", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc", "=", "TxtFCBlock", "(", "n_ftrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MLPClassifier.forward": [[239, 243], ["torchvision.models.MLPClassifier.dropout", "torchvision.models.MLPClassifier.fc().squeeze", "torchvision.models.MLPClassifier.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalClassifier.__init__": [[246, 268], ["torch.Module.__init__", "getattr", "hasattr", "torchvision.models.ResNet", "torchvision.models.ImgFCBlock", "torch.Linear", "torch.Linear", "torch.Linear", "torchvision.models.MeanTxtClassifier", "torchvision.models.LSTMTxtClassifier", "torchvision.models.TxtFCBlock"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultimodalClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "use_lstm", "=", "media_config", "[", "\"use_lstm\"", "]", "\n", "self", ".", "common_hidden_units", "=", "64", "\n", "\n", "if", "not", "use_lstm", ":", "\n", "            ", "self", ".", "txt_embedder", "=", "MeanTxtClassifier", "(", "self", ".", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "txt_embedder", "=", "LSTMTxtClassifier", "(", "self", ".", "config", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ".", "txt_embedder", ",", "\"out_ftrs\"", ")", ":", "\n", "            ", "self", ".", "txt_embedder", ".", "fc", "=", "TxtFCBlock", "(", "\n", "self", ".", "txt_embedder", ".", "out_ftrs", ",", "self", ".", "common_hidden_units", "\n", ")", "\n", "", "self", ".", "img_embedder", "=", "ResNet", "(", "self", ".", "config", ")", "\n", "self", ".", "img_embedder", ".", "resnet", ".", "fc", "=", "ImgFCBlock", "(", "\n", "self", ".", "img_embedder", ".", "out_ftrs", ",", "self", ".", "common_hidden_units", "\n", ")", "\n", "self", ".", "final_fc", "=", "nn", ".", "Linear", "(", "self", ".", "common_hidden_units", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalClassifier.forward": [[269, 275], ["torchvision.models.MultimodalClassifier.txt_embedder", "torchvision.models.MultimodalClassifier.img_embedder", "torchvision.models.MultimodalClassifier.final_fc", "torchvision.models.MultimodalClassifier.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "txt", ",", "mask", "=", "None", ")", ":", "\n", "        ", "txt", "=", "self", ".", "txt_embedder", "(", "txt", ",", "mask", ")", "\n", "img", "=", "self", ".", "img_embedder", "(", "img", ")", "\n", "x", "=", "txt", "*", "img", "\n", "x", "=", "self", ".", "final_fc", "(", "x", ")", "\n", "return", "x", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalClassifier.set_out_ftrs": [[276, 278], ["torchvision.models.MultimodalClassifier.txt_embedder.set_out_ftrs"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalClassifier.set_out_ftrs"], ["", "def", "set_out_ftrs", "(", "self", ",", "out_ftrs", ")", ":", "\n", "        ", "self", ".", "txt_embedder", ".", "set_out_ftrs", "(", "out_ftrs", ",", "self", ".", "common_hidden_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.Identity.__init__": [[280, 282], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.Identity.forward": [[283, 285], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalConcatClassifier.__init__": [[287, 303], ["torch.Module.__init__", "getattr", "torchvision.models.ResNet", "torchvision.models.Identity", "torchvision.models.Identity", "print", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torchvision.models.MeanTxtClassifier", "torchvision.models.LSTMTxtClassifier", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultimodalConcatClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "use_lstm", "=", "media_config", "[", "\"use_lstm\"", "]", "\n", "self", ".", "img_embedder", "=", "ResNet", "(", "self", ".", "config", ")", "\n", "self", ".", "img_embedder", ".", "resnet", ".", "fc", "=", "Identity", "(", ")", "\n", "if", "not", "use_lstm", ":", "\n", "            ", "self", ".", "txt_embedder", "=", "MeanTxtClassifier", "(", "self", ".", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "txt_embedder", "=", "LSTMTxtClassifier", "(", "self", ".", "config", ")", "\n", "", "self", ".", "txt_embedder", ".", "fc", "=", "Identity", "(", ")", "\n", "self", ".", "out_ftrs", "=", "self", ".", "img_embedder", ".", "out_ftrs", "+", "self", ".", "txt_embedder", ".", "out_ftrs", "\n", "print", "(", "\"MULTIMODAL OUT FEATURES:\"", ",", "self", ".", "out_ftrs", ")", "\n", "self", ".", "final_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Dropout", "(", "0.5", ")", ",", "nn", ".", "Linear", "(", "self", ".", "out_ftrs", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.MultimodalConcatClassifier.forward": [[304, 311], ["torchvision.models.MultimodalConcatClassifier.final_fc", "torch.cat.squeeze", "torch.cat.squeeze", "torch.cat.squeeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torchvision.models.MultimodalConcatClassifier.txt_embedder", "torchvision.models.MultimodalConcatClassifier.img_embedder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "txt", ",", "mask", "=", "None", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "txt", "=", "self", ".", "txt_embedder", "(", "txt", ",", "mask", ")", "\n", "img", "=", "self", ".", "img_embedder", "(", "img", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "txt", ",", "img", "]", ",", "dim", "=", "1", ")", "\n", "", "x", "=", "self", ".", "final_fc", "(", "x", ")", "\n", "return", "x", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertPoolerBase.__init__": [[329, 338], ["transformers.modeling_bert.BertPooler.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "transformers.modeling_bert.BertLayerNorm", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "# this we don't have in default BertPooler", "\n", "self", ".", "distribution", "=", "\"normal\"", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "pooler_activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "# if config.pooler_activation == 'tanh':", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertPoolerBase.reset_parameters": [[345, 360], ["print", "torchvision.models.BertPoolerBase.dense.weight.data.uniform_", "torchvision.models.BertPoolerBase.dense.bias.data.uniform_", "torchvision.models.BertPoolerBase.dense.weight.data.normal_", "torchvision.models.BertPoolerBase.dense.bias.data.zero_", "KeyError"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "print", "(", "f'Re-initializing pooler weights from {self.distribution} distribution'", ")", "\n", "\n", "bound", "=", "0.03125", "\n", "if", "self", ".", "distribution", "==", "'uniform'", ":", "\n", "            ", "self", ".", "dense", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "bound", ",", "bound", ")", "\n", "self", ".", "dense", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "bound", ",", "bound", ")", "\n", "# self.dense.bias.data.zero_()", "\n", "", "elif", "self", ".", "distribution", "==", "'normal'", ":", "\n", "# BERT initializes linear layers with: module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)", "\n", "# where self.config.initializer_range = 0.02", "\n", "            ", "self", ".", "dense", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "self", ".", "dense", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "f\"Unknown distribution {self.distribution}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertCLSPooler.__init__": [[363, 368], ["torchvision.models.BertPoolerBase.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "batch_id", "=", "0", "\n", "self", ".", "pooler_dropout", "=", "False", "\n", "self", ".", "pooler_layer_norm", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertCLSPooler.forward": [[369, 396], ["torchvision.models.BertCLSPooler.dense", "torchvision.models.BertCLSPooler.pooler_activation", "torchvision.models.BertCLSPooler.dropout", "torchvision.models.BertCLSPooler.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token ([CLS])", "\n", "        ", "token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "\n", "# Save token_tensor to disk", "\n", "# token_tensor_np = token_tensor.detach().cpu().numpy()", "\n", "# filename = '/logfiles/dodge-et-al-2020/' + f'token_tensor_{self.batch_id}.npy'", "\n", "# np.save(filename, token_tensor_np, allow_pickle=True)", "\n", "# self.batch_id += 1", "\n", "\n", "# RoBERTa uses an additional dropout here (before the linear transformation)", "\n", "if", "self", ".", "pooler_dropout", ":", "\n", "            ", "token_tensor_dropout", "=", "self", ".", "dropout", "(", "token_tensor", ")", "# this we don't have in default BertPooler", "\n", "", "else", ":", "\n", "            ", "token_tensor_dropout", "=", "token_tensor", "\n", "\n", "", "pooled_linear_transform", "=", "self", ".", "dense", "(", "token_tensor_dropout", ")", "\n", "\n", "if", "self", ".", "pooler_layer_norm", ":", "# apply LayerNorm to tanh pre-activations", "\n", "            ", "normalized_pooled_linear_transform", "=", "self", ".", "LayerNorm", "(", "pooled_linear_transform", ")", "\n", "", "else", ":", "\n", "            ", "normalized_pooled_linear_transform", "=", "pooled_linear_transform", "\n", "\n", "", "pooled_activation", "=", "self", ".", "pooler_activation", "(", "normalized_pooled_linear_transform", ")", "\n", "\n", "return", "pooled_activation", ",", "normalized_pooled_linear_transform", ",", "pooled_linear_transform", ",", "token_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertModelWithPooler.__init__": [[399, 402], ["transformers.modeling_bert.BertModel.__init__", "torchvision.models.BertCLSPooler"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertCLSPooler", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertModelWithPooler.forward": [[403, 528], ["extended_attention_mask.to.to.to", "torchvision.models.BertModelWithPooler.embeddings", "torchvision.models.BertModelWithPooler.encoder", "torchvision.models.BertModelWithPooler.pooler", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones.dim", "torch.ones.dim", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.dim", "torch.ones.dim", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones.dim", "torch.ones.dim", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "torch.ones.dim", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "torchvision.models.BertModelWithPooler.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "torchvision.models.BertModelWithPooler.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "torchvision.models.BertModelWithPooler.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "\n", "attention_mask", ".", "dtype", "\n", ")", "# causal and attention masks must have same type with pytorch version < 1.3", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "\n", "pooled_activation", ",", "normalized_pooled_linear_transform", ",", "pooled_linear_transform", ",", "token_tensor", "=", "self", ".", "pooler", "(", "sequence_output", ",", "attention_mask", ")", "\n", "# pooled activation is the results of the applying the pooler's tanh", "\n", "# pooler_output is the input to the pooler's tanh", "\n", "# token_tensor is the pooled vector, either CLS, 5th token, or mean over tokens", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_activation", ",", "normalized_pooled_linear_transform", ",", "pooled_linear_transform", ",", "token_tensor", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "\n", "return", "outputs", "# sequence_output, pooled_activation, pooled_linear_transform, token_tensor, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertForSequenceClassificationWithPooler.__init__": [[531, 537], ["transformers.modeling_bert.BertForSequenceClassification.__init__", "torchvision.models.BertModelWithPooler", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModelWithPooler", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "# self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertForSequenceClassificationWithPooler.forward": [[538, 575], ["torchvision.models.BertForSequenceClassificationWithPooler.bert", "torchvision.models.BertForSequenceClassificationWithPooler.dropout", "torchvision.models.BertForSequenceClassificationWithPooler.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torchvision.models.BertForSequenceClassificationWithPooler.view", "labels.view", "torchvision.models.BertForSequenceClassificationWithPooler.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_activation", ",", "normalized_pooled_linear_transform", ",", "pooled_linear_transform", ",", "token_tensor", "=", "outputs", "[", "1", ":", "5", "]", "# get outputs from the pooler", "\n", "pooled_activation_dropout", "=", "self", ".", "dropout", "(", "pooled_activation", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_activation_dropout", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", "pooled_activation_dropout", ",", "pooled_activation", ",", "normalized_pooled_linear_transform", ",", "pooled_linear_transform", ",", "token_tensor", ")", "+", "outputs", "[", "5", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "BCEWithLogitsLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ")", "\n", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.BertForSequenceClassificationWithPooler.manually_init_weights": [[576, 581], ["print", "torchvision.models.BertForSequenceClassificationWithPooler.classifier.weight.data.normal_", "torchvision.models.BertForSequenceClassificationWithPooler.classifier.bias.data.zero_"], "methods", ["None"], ["", "def", "manually_init_weights", "(", "self", ",", "std", ")", ":", "\n", "# Initialize weights following: https://arxiv.org/abs/2002.06305", "\n", "        ", "print", "(", "f'Initializing weights of linear classifier: mean = 0.0, std = {std}'", ")", "\n", "self", ".", "classifier", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "self", ".", "classifier", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "# self.classifier.bias.data.normal_(mean=0.0, std=std)", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.freeze_resnet_layers": [[18, 25], ["model.children", "child.parameters"], "function", ["None"], ["", "", "def", "freeze_resnet_layers", "(", "up_to_10", ",", "model", ")", ":", "\n", "    ", "c", "=", "0", "\n", "for", "child", "in", "model", ".", "children", "(", ")", ":", "\n", "        ", "c", "+=", "1", "\n", "if", "c", "<", "up_to_10", ":", "\n", "            ", "for", "param", "in", "child", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.models.get_txt_embedder": [[116, 125], ["models.ELMo", "models.FastText", "models.BoW"], "function", ["None"], ["", "", "def", "get_txt_embedder", "(", "txt_embedder", ")", ":", "\n", "    ", "model", "=", "None", "\n", "if", "txt_embedder", "==", "\"elmo\"", ":", "\n", "        ", "model", "=", "ELMo", "(", ")", "\n", "", "elif", "txt_embedder", "==", "\"fasttext\"", ":", "\n", "        ", "model", "=", "FastText", "(", ")", "\n", "", "elif", "txt_embedder", "==", "\"bow\"", ":", "\n", "        ", "model", "=", "BoW", "(", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor.__init__": [[24, 37], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "inference.Predictor.model.to", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "next", "model.parameters"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "config", ")", ":", "\n", "        ", "\"\"\" \n        model   = the model class to be instantiated, not the instantiated \n                  class itself\n        \"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "configuration", "=", "config", "\n", "general_config", "=", "self", ".", "configuration", ".", "general", "\n", "gpus", "=", "general_config", "[", "\"gpus\"", "]", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\n", "f\"cuda:{gpus[0]}\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "if", "not", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor._list_from_tensor": [[38, 42], ["list", "tensor.numel", "tensor.cpu().detach().numpy", "tensor.item", "tensor.cpu().detach", "tensor.cpu"], "methods", ["None"], ["", "", "def", "_list_from_tensor", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "if", "tensor", ".", "numel", "(", ")", "==", "1", ":", "\n", "            ", "return", "[", "tensor", ".", "item", "(", ")", "]", "\n", "", "return", "list", "(", "tensor", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor.predict": [[43, 64], ["inference.Predictor.model.eval", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "torch.tensor().log", "logit_threshold.to.to.to", "scipy.special.expit", "cm.add_experiment", "labels.to.to.to", "inference.Predictor.model", "pred_labels.extend", "test_labels.extend", "u_names.extend", "scipy.special.expit.extend", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "i.to", "inference.Predictor._list_from_tensor", "inference.Predictor._list_from_tensor", "inference.Predictor._list_from_tensor"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.metrics.confusion_matrix.ConfusionMatrix.add_experiment", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor._list_from_tensor", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor._list_from_tensor", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.Predictor._list_from_tensor"], ["", "def", "predict", "(", "self", ",", "dataloader", ",", "cm", ",", "threshold", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "logit_threshold", "=", "torch", ".", "tensor", "(", "threshold", "/", "(", "1", "-", "threshold", ")", ")", ".", "log", "(", ")", "\n", "logit_threshold", "=", "logit_threshold", ".", "to", "(", "self", ".", "device", ")", "\n", "pred_labels", "=", "[", "]", "\n", "test_labels", "=", "[", "]", "\n", "u_names", "=", "[", "]", "\n", "logits", "=", "[", "]", "\n", "for", "*", "inputs", ",", "labels", ",", "u_name", "in", "dataloader", ":", "\n", "            ", "inputs", "=", "[", "i", ".", "to", "(", "self", ".", "device", ")", "for", "i", "in", "inputs", "]", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "outputs", "=", "self", ".", "model", "(", "*", "inputs", ")", "\n", "preds", "=", "outputs", ">", "logit_threshold", "\n", "pred_labels", ".", "extend", "(", "self", ".", "_list_from_tensor", "(", "preds", ")", ")", "\n", "test_labels", ".", "extend", "(", "self", ".", "_list_from_tensor", "(", "labels", ")", ")", "\n", "u_names", ".", "extend", "(", "u_name", ")", "\n", "logits", ".", "extend", "(", "self", ".", "_list_from_tensor", "(", "outputs", ")", ")", "\n", "#Take probabilities and not logit", "\n", "", "logits", "=", "expit", "(", "logits", ")", "\n", "cm", ".", "add_experiment", "(", "test_labels", ",", "pred_labels", ",", "logits", ",", "u_names", ",", "self", ".", "configuration", ")", "\n", "return", "cm", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.models.inference.plot_confusion_matrix": [[66, 122], ["numpy.array", "sklearn.metrics.confusion_matrix", "matplotlib.subplots", "ax.imshow", "ax.figure.colorbar", "ax.set", "matplotlib.setp", "range", "fig.tight_layout", "sklearn.metrics.precision_recall_fscore_support", "print", "print", "print", "print", "ax.get_xticklabels", "sklearn.metrics.confusion_matrix.max", "range", "sklearn.utils.multiclass.unique_labels", "sklearn.metrics.confusion_matrix.astype", "numpy.arange", "numpy.arange", "ax.text", "sklearn.metrics.confusion_matrix.sum", "format"], "function", ["None"], ["", "", "def", "plot_confusion_matrix", "(", "y_true", ",", "y_pred", ",", "classes", "=", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", ",", "\n", "normalize", "=", "False", ",", "\n", "title", "=", "None", ",", "\n", "cmap", "=", "plt", ".", "cm", ".", "Blues", ")", ":", "\n", "    ", "\"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"", "\n", "if", "not", "title", ":", "\n", "        ", "if", "normalize", ":", "\n", "            ", "title", "=", "'Normalized confusion matrix'", "\n", "", "else", ":", "\n", "            ", "title", "=", "'Confusion matrix, without normalization'", "\n", "\n", "# Compute confusion matrix", "\n", "", "", "cm", "=", "confusion_matrix", "(", "y_true", ",", "y_pred", ")", "\n", "# Only use the labels that appear in the data", "\n", "classes", "=", "classes", "[", "unique_labels", "(", "y_true", ",", "y_pred", ")", "]", "\n", "if", "normalize", ":", "\n", "        ", "cm", "=", "cm", ".", "astype", "(", "'float'", ")", "/", "cm", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "print", "(", "\"Normalized confusion matrix\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Confusion matrix, without normalization'", ")", "\n", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "cm", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cmap", ")", "\n", "ax", ".", "figure", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "# We want to show all ticks...", "\n", "ax", ".", "set", "(", "xticks", "=", "np", ".", "arange", "(", "cm", ".", "shape", "[", "1", "]", ")", ",", "\n", "yticks", "=", "np", ".", "arange", "(", "cm", ".", "shape", "[", "0", "]", ")", ",", "\n", "# ... and label them with the respective list entries", "\n", "xticklabels", "=", "classes", ",", "yticklabels", "=", "classes", ",", "\n", "title", "=", "title", ",", "\n", "ylabel", "=", "'True label'", ",", "\n", "xlabel", "=", "'Predicted label'", ")", "\n", "\n", "# Rotate the tick labels and set their alignment.", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "45", ",", "ha", "=", "\"right\"", ",", "\n", "rotation_mode", "=", "\"anchor\"", ")", "\n", "\n", "# Loop over data dimensions and create text annotations.", "\n", "fmt", "=", "'.2f'", "if", "normalize", "else", "'d'", "\n", "thresh", "=", "cm", ".", "max", "(", ")", "/", "2.", "\n", "for", "i", "in", "range", "(", "cm", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "cm", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "ax", ".", "text", "(", "j", ",", "i", ",", "format", "(", "cm", "[", "i", ",", "j", "]", ",", "fmt", ")", ",", "\n", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "\n", "color", "=", "\"white\"", "if", "cm", "[", "i", ",", "j", "]", ">", "thresh", "else", "\"black\"", ")", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "metrics", "=", "precision_recall_fscore_support", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "y_pred", ",", "\n", "average", "=", "\"binary\"", ")", "\n", "print", "(", ")", "\n", "print", "(", "\"\\tPrecision \\t{}\\n\\tRecall \\t{}\\n\\tF1-score \\t{}\"", ".", "format", "(", "\n", "metrics", "[", "0", "]", ",", "metrics", "[", "1", "]", ",", "metrics", "[", "2", "]", ")", ")", "\n", "#print(scores)", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.__init__": [[13, 39], ["datetime.datetime.datetime.strptime().date", "datetime.datetime.datetime.strptime"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "\n", "\n", "", "", "def", "freeze_resnet_layers", "(", "up_to_10", ",", "model", ")", ":", "\n", "    ", "c", "=", "0", "\n", "for", "child", "in", "model", ".", "children", "(", ")", ":", "\n", "        ", "c", "+=", "1", "\n", "if", "c", "<", "up_to_10", ":", "\n", "            ", "for", "param", "in", "child", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "", "", "", "class", "ResNet", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "img_embedder", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "[", "\"img_embedder\"", "]", "\n", "print", "(", "f\"Using {img_embedder} embedder.\"", ")", "\n", "\n", "self", ".", "resnet", "=", "self", ".", "get_model", "(", "img_embedder", ".", "lower", "(", ")", ")", "\n", "freeze_resnet_layers", "(", "7", ",", "self", ".", "resnet", ")", "\n", "n_ftrs", "=", "self", ".", "resnet", ".", "fc", ".", "in_features", "\n", "self", ".", "out_ftrs", "=", "n_ftrs", "\n", "self", ".", "resnet", ".", "fc", "=", "ImgFCBlock", "(", "n_ftrs", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_bdi": [[40, 63], ["None"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "resnet", "(", "x", ")", "\n", "return", "x", ".", "squeeze", "(", ")", "\n", "\n", "", "def", "get_model", "(", "self", ",", "embedder_name", ")", ":", "\n", "        ", "if", "embedder_name", "==", "\"resnext\"", ":", "\n", "            ", "return", "torch", ".", "hub", ".", "load", "(", "\"facebookresearch/WSL-Images\"", ",", "\"resnext101_32x8d_wsl\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "getattr", "(", "models", ",", "embedder_name", ")", "(", "pretrained", "=", "True", ")", "\n", "\n", "\n", "# =======================================================================================", "\n", "# =======================================================================================", "\n", "# ===============================END OF VISUAL MODELS====================================", "\n", "# ===============================BEGIN OF TEXT MODELS====================================", "\n", "# =======================================================================================", "\n", "# =======================================================================================", "\n", "\n", "\n", "", "", "", "class", "TxtFCBlock", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "n_ftrs", ",", "final_ftrs", "=", "1", ")", ":", "\n", "        ", "super", "(", "TxtFCBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi": [[64, 74], ["None"], "methods", ["None"], ["nn", ".", "Linear", "(", "n_ftrs", ",", "n_ftrs", "//", "2", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "n_ftrs", "//", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "n_ftrs", "//", "2", ",", "final_ftrs", ")", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fc", "(", "x", ")", ".", "squeeze", "(", ")", "\n", "\n", "\n", "", "", "class", "ELMo", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.__init__": [[83, 87], ["None"], "methods", ["None"], ["weights_path", ",", "\n", "num_output_representations", "=", "1", ",", "\n", "dropout", "=", "0.5", ",", "\n", "scalar_mix_parameters", "=", "[", "-", "9e10", ",", "1", ",", "-", "9e10", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_answer_dict": [[88, 90], ["None"], "methods", ["None"], ["# scalar_mix_parameters=[-9e10, -9e10, 1]", "\n", "self", ".", "out_ftrs", "=", "self", ".", "embedding", ".", "get_output_dim", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date": [[91, 101], ["datetime.datetime.timedelta", "post.date.date", "posts_in_range.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "\n", "masks", "=", "x", "[", "\"mask\"", "]", ".", "float", "(", ")", "\n", "x", "=", "x", "[", "\"elmo_representations\"", "]", "[", "0", "]", "\n", "return", "{", "\"representation\"", ":", "x", ",", "\"masks\"", ":", "masks", "}", "\n", "\n", "\n", "", "", "class", "FastText", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "FastText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "out_ftrs", "=", "300", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramUser.__init__": [[110, 132], ["models.Participant.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "return", "{", "\"representation\"", ":", "x", "}", "\n", "\n", "\n", "", "", "def", "get_txt_embedder", "(", "txt_embedder", ")", ":", "\n", "    ", "model", "=", "None", "\n", "if", "txt_embedder", "==", "\"elmo\"", ":", "\n", "        ", "model", "=", "ELMo", "(", ")", "\n", "", "elif", "txt_embedder", "==", "\"fasttext\"", ":", "\n", "        ", "model", "=", "FastText", "(", ")", "\n", "", "elif", "txt_embedder", "==", "\"bow\"", ":", "\n", "        ", "model", "=", "BoW", "(", ")", "\n", "", "return", "model", "\n", "\n", "\n", "", "class", "MeanTxtClassifier", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MeanTxtClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramUser.get_answer_dict": [[133, 152], ["models.InstagramUser.questionnaire.get_binary_bdi", "dict", "super().get_answer_dict().copy", "super().get_answer_dict().copy.update", "list", "models.Participant.get_answer_dict", "dict.keys"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramUser.get_answer_dict"], ["txt_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", "\n", "print", "(", "f\"Using {txt_embedder} embedder.\"", ")", "\n", "\n", "self", ".", "model", "=", "get_txt_embedder", "(", "txt_embedder", ")", "\n", "\n", "if", "hasattr", "(", "self", ".", "model", ",", "\"out_ftrs\"", ")", ":", "\n", "            ", "self", ".", "out_ftrs", "=", "self", ".", "model", ".", "out_ftrs", "\n", "if", "media_config", "[", "\"mean\"", "]", "==", "\"pmean\"", ":", "\n", "                ", "self", ".", "out_ftrs", "=", "self", ".", "out_ftrs", "*", "len", "(", "media_config", "[", "\"pmean\"", "]", ")", "\n", "\n", "", "self", ".", "fc", "=", "TxtFCBlock", "(", "self", ".", "out_ftrs", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "masks", "=", "None", ")", ":", "\n", "        ", "if", "masks", "is", "None", ":", "\n", "            ", "res", "=", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "model", "(", "x", ",", "masks", ")", "\n", "", "emb", "=", "res", "[", "\"representation\"", "]", "\n", "if", "\"masks\"", "in", "res", ":", "\n", "            ", "masks", "=", "res", "[", "\"masks\"", "]", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.__init__": [[163, 176], ["datetime.datetime.datetime.fromtimestamp"], "methods", ["None"], ["self", ".", "config", "=", "config", "\n", "media_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "media_type", ")", "\n", "txt_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", "\n", "print", "(", "f\"Using {txt_embedder} embedder.\"", ")", "\n", "if", "txt_embedder", "not", "in", "[", "\"elmo\"", ",", "\"fasttext\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"LSTMClassifier only supports elmo and fasttext.\"", ")", "\n", "", "self", ".", "hidden_units", "=", "124", "\n", "self", ".", "embedder", "=", "get_txt_embedder", "(", "txt_embedder", ")", "\n", "self", ".", "embed_dims", "=", "self", ".", "embedder", ".", "out_ftrs", "\n", "self", ".", "num_layers", "=", "media_config", "[", "\"LSTM\"", "]", "[", "\"num_layers\"", "]", "\n", "self", ".", "bidirectional", "=", "media_config", "[", "\"LSTM\"", "]", "[", "\"bidirectional\"", "]", "\n", "self", ".", "num_directions", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "self", ".", "out_ftrs", "=", "self", ".", "hidden_units", "*", "self", ".", "num_directions", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list": [[178, 180], ["None"], "methods", ["None"], ["print", "(", "f\"===LSTM params {media_config['LSTM']}\"", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "self", ".", "embed_dims", ",", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_face_count_list": [[181, 183], ["None"], "methods", ["None"], ["self", ".", "hidden_units", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.calculate_face_count_list": [[184, 198], ["models.InstagramPost._load_image", "models.InstagramPost._get_face_count", "models.InstagramPost._face_count_list.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost._load_image", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost._get_face_count"], ["dropout", "=", "self", ".", "dropout_value", ",", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "out_ftrs", ",", "1", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "lstm", ".", "weight_hh_l0", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "lstm", ".", "weight_ih_l0", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "masks", "=", "None", ")", ":", "\n", "        ", "if", "masks", "is", "None", ":", "\n", "            ", "res", "=", "self", ".", "embedder", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "embedder", "(", "x", ",", "masks", ")", "\n", "", "emb", "=", "res", "[", "\"representation\"", "]", "\n", "if", "\"masks\"", "in", "res", ":", "\n", "            ", "masks", "=", "res", "[", "\"masks\"", "]", "\n", "", "lengths", "=", "masks", ".", "sum", "(", "dim", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost._load_image": [[199, 202], ["os.path.join", "face_recognition.load_image_file"], "methods", ["None"], ["bsz", "=", "len", "(", "lengths", ")", "\n", "lengths", ",", "perm_idx", "=", "lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "orig_idx", "=", "sorted", "(", "range", "(", "len", "(", "perm_idx", ")", ")", ",", "key", "=", "perm_idx", ".", "__getitem__", ")", "\n", "emb", "=", "emb", "[", "perm_idx", "]", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost._get_face_count": [[203, 206], ["face_recognition.face_locations", "len"], "methods", ["None"], ["emb", "=", "emb", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "packed", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "emb", ",", "lengths", ".", "tolist", "(", ")", ")", "\n", "_", ",", "(", "hidden", ",", "_", ")", "=", "self", ".", "lstm", "(", "packed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_dict_representation": [[207, 217], ["dict", "sum", "len"], "methods", ["None"], ["if", "self", ".", "bidirectional", ":", "\n", "\n", "            ", "def", "combine_bidir", "(", "outs", ")", ":", "\n", "                ", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "cat", "(", "[", "outs", "[", "2", "*", "i", "]", ",", "outs", "[", "2", "*", "i", "+", "1", "]", "]", ",", "dim", "=", "0", ")", ".", "view", "(", "\n", "1", ",", "bsz", ",", "self", ".", "out_ftrs", "\n", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Config.__init__": [[220, 227], ["open", "json.load"], "methods", ["None"], ["# Always take the output from the last LSTM layer", "\n", "", "hidden", "=", "hidden", "[", "-", "1", "]", "\n", "linear", "=", "self", ".", "fc", "(", "hidden", ")", "\n", "linear", "=", "linear", "[", "orig_idx", "]", "\n", "return", "linear", ".", "squeeze", "(", ")", "\n", "\n", "\n", "", "", "class", "MLPClassifier", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch.__init__": [[10, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tr_size", "=", "0.6", ",", "val_size", "=", "0.2", ",", "te_size", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "tr_size", "=", "tr_size", "\n", "self", ".", "te_size", "=", "te_size", "\n", "self", ".", "val_size", "=", "val_size", "\n", "if", "tr_size", "+", "te_size", "+", "val_size", "!=", "1.0", ":", "\n", "            ", "raise", "ValueError", "\n", "", "self", ".", "_original_bdi_qty", "=", "{", "0", ":", "0", ",", "1", ":", "0", "}", "\n", "self", ".", "_original_size", "=", "-", "1", "\n", "self", ".", "_days", "=", "60", "\n", "self", ".", "_timer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch.stratify": [[21, 63], ["print", "time.time", "numpy.array", "stratification.LocalSearch._calculate_bdi_qty", "tuple", "int", "stratification.LocalSearch._get_subsets", "stratification.LocalSearch._get_participants_with_posts", "range", "hash", "stratification.LocalSearch._stopping_condition", "stratification.LocalSearch._get_neighbors", "tabuList.append", "len", "len", "stratification.LocalSearch._fitness", "stratification.LocalSearch._fitness", "random.random", "random.choice", "hash", "len", "tabuList.pop", "hash", "stratification.LocalSearch._fitness", "stratification.LocalSearch._fitness"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._calculate_bdi_qty", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_subsets", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_participants_with_posts", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._stopping_condition", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_neighbors", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness"], ["", "def", "stratify", "(", "self", ",", "participants", ",", "days", ")", ":", "\n", "        ", "\"\"\" Return the participants list stratified through train/val/test\n        size, class, and number of examples for each participant.\n\n        We stratify by 3 levels: train/test/val size, class, and examples\n\n        Params:\n        participants -- A list of models.Participant subclasses\n        Return:\n        the stratified participants list\n        \"\"\"", "\n", "print", "(", "\"Stratifying...\"", ")", "\n", "self", ".", "_timer", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "_days", "=", "days", "\n", "prtcpts", "=", "np", ".", "array", "(", "self", ".", "_get_participants_with_posts", "(", "participants", ")", ")", "\n", "self", ".", "_original_bdi_qty", ",", "self", ".", "_original_size", "=", "self", ".", "_calculate_bdi_qty", "(", "\n", "prtcpts", ")", "\n", "best", "=", "tuple", "(", "range", "(", "len", "(", "prtcpts", ")", ")", ")", "\n", "best_candidate", "=", "best", "\n", "tabuList", "=", "[", "hash", "(", "best", ")", "]", "\n", "TABU_SIZE", "=", "int", "(", "0.3", "*", "len", "(", "prtcpts", ")", ")", "\n", "\n", "while", "not", "self", ".", "_stopping_condition", "(", "prtcpts", ",", "best", ")", ":", "\n", "            ", "neighbors", "=", "self", ".", "_get_neighbors", "(", "prtcpts", ",", "best_candidate", ")", "\n", "for", "n", "in", "neighbors", ":", "\n", "                ", "if", "(", "hash", "(", "n", ")", "not", "in", "tabuList", "\n", "and", "self", ".", "_fitness", "(", "prtcpts", ",", "n", ")", "\n", "<", "self", ".", "_fitness", "(", "prtcpts", ",", "best_candidate", ")", ")", ":", "\n", "                    ", "best_candidate", "=", "n", "\n", "\n", "", "", "if", "(", "self", ".", "_fitness", "(", "prtcpts", ",", "best_candidate", ")", "\n", "<", "self", ".", "_fitness", "(", "prtcpts", ",", "best", ")", ")", ":", "\n", "                ", "best", "=", "best_candidate", "\n", "\n", "", "if", "random", ".", "random", "(", ")", "<", "0.30", ":", "\n", "                ", "best_candidate", "=", "random", ".", "choice", "(", "neighbors", ")", "\n", "\n", "", "tabuList", ".", "append", "(", "hash", "(", "best_candidate", ")", ")", "\n", "if", "len", "(", "tabuList", ")", ">", "TABU_SIZE", ":", "\n", "                ", "tabuList", ".", "pop", "(", "0", ")", "\n", "\n", "", "", "return", "self", ".", "_get_subsets", "(", "prtcpts", ",", "best", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_participants_with_posts": [[64, 74], ["p.get_posts_from_qtnre_answer_date", "len", "participants_with_posts.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date"], ["", "def", "_get_participants_with_posts", "(", "self", ",", "participants", ")", ":", "\n", "        ", "\"\"\" Return participants that have, at least, one post in the previous\n        days' from the questionnaire answer. \"\"\"", "\n", "participants_with_posts", "=", "[", "]", "\n", "for", "p", "in", "participants", ":", "\n", "            ", "posts", "=", "p", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_days", ")", "\n", "if", "len", "(", "posts", ")", ">", "0", ":", "\n", "                ", "participants_with_posts", ".", "append", "(", "p", ")", "\n", "\n", "", "", "return", "participants_with_posts", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._stopping_condition": [[75, 84], ["stratification.LocalSearch._fitness", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness"], ["", "def", "_stopping_condition", "(", "self", ",", "participants", ",", "best", ")", ":", "\n", "\n", "        ", "fit_value", "=", "self", ".", "_fitness", "(", "participants", ",", "best", ")", "\n", "\n", "epsilon", "=", "0.08", "\n", "print", "(", "\"Fit Value : {}\"", ".", "format", "(", "fit_value", ")", ")", "\n", "if", "fit_value", "<=", "epsilon", "or", "time", ".", "time", "(", ")", "-", "self", ".", "_timer", ">=", "300", ":", "# 300", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_neighbors": [[85, 106], ["stratification.LocalSearch._get_indexes", "range", "neighbors.append", "random.sample", "list", "random.sample", "tuple", "random.randrange", "random.randrange", "random.randrange", "len", "len"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_indexes"], ["", "def", "_get_neighbors", "(", "self", ",", "participants", ",", "best_candidate", ")", ":", "\n", "        ", "NEIGHBORS", "=", "15", "\n", "\n", "tr_idx", ",", "val_idx", "=", "self", ".", "_get_indexes", "(", "participants", ")", "\n", "neighbors", "=", "[", "]", "\n", "\n", "for", "n", "in", "range", "(", "NEIGHBORS", ")", ":", "\n", "            ", "if", "n", "%", "2", "==", "0", ":", "\n", "                ", "indexes", "=", "[", "random", ".", "randrange", "(", "0", ",", "tr_idx", ")", ",", "\n", "random", ".", "randrange", "(", "tr_idx", ",", "val_idx", ")", ",", "\n", "random", ".", "randrange", "(", "val_idx", ",", "len", "(", "participants", ")", ")", "]", "\n", "swap_idx", "=", "random", ".", "sample", "(", "indexes", ",", "2", ")", "\n", "neighbor", "=", "list", "(", "best_candidate", ")", "\n", "temp", "=", "neighbor", "[", "swap_idx", "[", "0", "]", "]", "\n", "neighbor", "[", "swap_idx", "[", "0", "]", "]", "=", "neighbor", "[", "swap_idx", "[", "1", "]", "]", "\n", "neighbor", "[", "swap_idx", "[", "1", "]", "]", "=", "temp", "\n", "", "else", ":", "\n", "                ", "neighbor", "=", "random", ".", "sample", "(", "best_candidate", ",", "len", "(", "best_candidate", ")", ")", "\n", "", "neighbors", ".", "append", "(", "tuple", "(", "neighbor", ")", ")", "\n", "\n", "", "return", "neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._fitness": [[107, 153], ["stratification.LocalSearch._get_subsets", "stratification.LocalSearch._fitness.get_bdi_fraction"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_subsets"], ["", "def", "_fitness", "(", "self", ",", "participants", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Return the sum of differences of the maximum and minimum of: (1)\n        proportions of examples for each BDI category, and (2) proportion of\n        examples in each generated set (test, train, and validation)\n        \"\"\"", "\n", "tr_subset", ",", "val_subset", ",", "test_subset", "=", "self", ".", "_get_subsets", "(", "participants", ",", "\n", "mask", ")", "\n", "\n", "def", "get_bdi_fraction", "(", "bdi_qty", ",", "qty", ")", ":", "\n", "            ", "return", "(", "bdi_qty", "[", "0", "]", "/", "qty", ")", ",", "qty", "\n", "\n", "", "original_bdi_0_frac", ",", "total_qty", "=", "get_bdi_fraction", "(", "\n", "self", ".", "_original_bdi_qty", ",", "\n", "self", ".", "_original_size", ")", "\n", "\n", "original_tr_size", "=", "total_qty", "*", "self", ".", "tr_size", "\n", "original_val_size", "=", "total_qty", "*", "self", ".", "val_size", "\n", "original_test_size", "=", "total_qty", "*", "self", ".", "te_size", "\n", "\n", "tr_bdi_0_frac", ",", "tr_qty", "=", "get_bdi_fraction", "(", "\n", "*", "self", ".", "_calculate_bdi_qty", "(", "tr_subset", ")", ")", "\n", "val_bdi_0_frac", ",", "val_qty", "=", "get_bdi_fraction", "(", "\n", "*", "self", ".", "_calculate_bdi_qty", "(", "val_subset", ")", ")", "\n", "test_bdi_0_frac", ",", "test_qty", "=", "get_bdi_fraction", "(", "\n", "*", "self", ".", "_calculate_bdi_qty", "(", "test_subset", ")", ")", "\n", "\n", "bdi_proportions", "=", "[", "np", ".", "abs", "(", "tr_bdi_0_frac", "-", "original_bdi_0_frac", ")", ",", "\n", "np", ".", "abs", "(", "val_bdi_0_frac", "-", "original_bdi_0_frac", ")", ",", "\n", "np", ".", "abs", "(", "test_bdi_0_frac", "-", "original_bdi_0_frac", ")", "]", "\n", "\n", "sets_proportions", "=", "[", "np", ".", "abs", "(", "tr_qty", "-", "original_tr_size", ")", ",", "\n", "np", ".", "abs", "(", "val_qty", "-", "original_val_size", ")", ",", "\n", "np", ".", "abs", "(", "test_qty", "-", "original_test_size", ")", "]", "\n", "\n", "# Normalization process. Necessary due to the discrepancies between", "\n", "# bdi_proportions and sets_proportions values.", "\n", "bdi_proportions", "=", "bdi_proportions", "/", "np", ".", "linalg", ".", "norm", "(", "bdi_proportions", ",", "\n", "ord", "=", "1", ")", "\n", "sets_proportions", "=", "sets_proportions", "/", "np", ".", "linalg", ".", "norm", "(", "sets_proportions", ",", "\n", "ord", "=", "1", ")", "\n", "\n", "# Here, we use the difference between the max and the min value to", "\n", "# weight the generated solutions. More discrepancies in the generated", "\n", "# set, more weighted they become.", "\n", "return", "(", "(", "np", ".", "max", "(", "bdi_proportions", ")", "-", "np", ".", "min", "(", "bdi_proportions", ")", ")", "\n", "+", "(", "np", ".", "max", "(", "sets_proportions", ")", "-", "np", ".", "min", "(", "sets_proportions", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_subsets": [[154, 161], ["stratification.LocalSearch._get_indexes", "list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_indexes"], ["", "def", "_get_subsets", "(", "self", ",", "participants", ",", "mask", ")", ":", "\n", "        ", "tr_idx", ",", "val_idx", "=", "self", ".", "_get_indexes", "(", "participants", ")", "\n", "chosen_sets", "=", "participants", "[", "list", "(", "mask", ")", "]", "\n", "tr_subset", "=", "chosen_sets", "[", ":", "tr_idx", "]", "\n", "val_subset", "=", "chosen_sets", "[", "tr_idx", ":", "val_idx", "]", "\n", "test_subset", "=", "chosen_sets", "[", "val_idx", ":", "]", "\n", "return", "tr_subset", ",", "val_subset", ",", "test_subset", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_indexes": [[162, 175], ["int", "int", "numpy.floor", "numpy.floor", "len", "len"], "methods", ["None"], ["", "def", "_get_indexes", "(", "self", ",", "participants", ")", ":", "\n", "        ", "\"\"\" Return the maximum index for training and val sets.\n\n        It's not necessary to return training index since it's the last element\n        in the array. Typically:\n        training set = [00% - 60%)\n        val set      = [60% - 80%)\n        training set = [80% - 100%]\n        \"\"\"", "\n", "tr_idx", "=", "int", "(", "np", ".", "floor", "(", "self", ".", "tr_size", "*", "len", "(", "participants", ")", ")", ")", "\n", "j", "=", "self", ".", "val_size", "+", "self", ".", "tr_size", "\n", "val_idx", "=", "int", "(", "np", ".", "floor", "(", "j", "*", "len", "(", "participants", ")", ")", ")", "\n", "return", "tr_idx", ",", "val_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._calculate_bdi_qty": [[176, 186], ["participant.get_posts_from_qtnre_answer_date", "stratification.LocalSearch._get_total_number_of_images", "participant.questionnaire.get_binary_bdi"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_total_number_of_images", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi"], ["", "def", "_calculate_bdi_qty", "(", "self", ",", "subset", ")", ":", "\n", "        ", "bdi_fraction", "=", "{", "0", ":", "0", ",", "1", ":", "0", "}", "\n", "for", "participant", "in", "subset", ":", "\n", "            ", "posts", "=", "participant", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_days", ")", "\n", "# qty = len(posts)", "\n", "qty", "=", "self", ".", "_get_total_number_of_images", "(", "posts", ")", "\n", "bdi", "=", "participant", ".", "questionnaire", ".", "get_binary_bdi", "(", ")", "\n", "bdi_fraction", "[", "bdi", "]", "+=", "qty", "\n", "\n", "", "return", "bdi_fraction", ",", "(", "bdi_fraction", "[", "0", "]", "+", "bdi_fraction", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.stratification.LocalSearch._get_total_number_of_images": [[187, 192], ["len", "p.get_img_path_list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "_get_total_number_of_images", "(", "self", ",", "posts", ")", ":", "\n", "        ", "total", "=", "0", "\n", "for", "p", "in", "posts", ":", "\n", "            ", "total", "+=", "len", "(", "p", ".", "get_img_path_list", "(", ")", ")", "\n", "", "return", "total", "\n", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.__init__": [[31, 103], ["getattr", "int", "readorsee.data.preprocessing.NLTKTokenizer", "readorsee.data.facade.StratifyFacade().load_stratified_data", "dataset.DepressionCorpus._get_posts_list_from_users", "dataset.DepressionCorpus.slice_if_rest_one", "pandas.DataFrame", "pandas.DataFrame", "media_config[].lower", "ValueError", "torchvision.transforms.Compose", "readorsee.data.facade.StratifyFacade", "dataset.DepressionCorpus.preprocess_elmo", "dataset.DepressionCorpus.slice_ftrs", "ValueError", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "dataset.DepressionCorpus.preprocess_fasttext", "dataset.DepressionCorpus._get_features", "str", "dataset.DepressionCorpus.preprocess_bow"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.load_stratified_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset._get_posts_list_from_users", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.slice_if_rest_one", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_elmo", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.slice_ftrs", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_fasttext", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._get_features", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_bow"], ["    ", "def", "__init__", "(", "\n", "self", ",", "observation_period", ",", "dataset", ",", "subset", ",", "config", ",", "fasttext", "=", "None", ",", "transform", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Params:\n        subset: Can take three possible values: (train, test, val)\n        observation_period: number of days for the period\n        transform: the transformation method for images\n        data_type: The type of training, with \"img\", \"txt\", or \"both\"\n        text_embedder: [\"fasttext\", \"elmo\"]\n\n        Observation: The best datasets for each period are :\n            {'data_60': 1, 'data_212': 1, 'data_365': 5}\n        \"\"\"", "\n", "self", ".", "config", "=", "config", "\n", "text_embedder", "=", "\"\"", "\n", "data_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "data_type", ")", "\n", "\n", "if", "data_type", "in", "[", "\"txt\"", ",", "\"both\"", "]", ":", "\n", "            ", "text_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", ".", "lower", "(", ")", "\n", "if", "text_embedder", "==", "\"fasttext\"", ":", "\n", "                ", "if", "fasttext", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "\n", "", "else", ":", "\n", "                    ", "self", ".", "fasttext", "=", "fasttext", "\n", "", "", "elif", "text_embedder", "not", "in", "[", "\"elmo\"", ",", "\"bow\"", "]", ":", "\n", "                ", "raise", "ValueError", "(", "f\"{text_embedder} is not a valid embedder\"", ")", "\n", "\n", "", "", "if", "data_type", "not", "in", "[", "\"img\"", ",", "\"txt\"", ",", "\"both\"", ",", "\"ftrs\"", "]", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "if", "data_type", "in", "[", "\"img\"", "]", "and", "text_embedder", "in", "[", "\"elmo\"", ",", "\"fasttext\"", ",", "\"bow\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Do not use text_embedder with image only dset.\"", ")", "\n", "\n", "", "if", "transform", "is", "None", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "[", "224", ",", "224", "]", ",", "interpolation", "=", "Image", ".", "LANCZOS", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", ",", "\n", "]", "\n", ")", "\n", "", "self", ".", "_transform", "=", "transform", "\n", "subset_to_index", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "1", ",", "\"test\"", ":", "2", "}", "\n", "subset_idx", "=", "subset_to_index", "[", "subset", "]", "\n", "self", ".", "text_embedder", "=", "text_embedder", "\n", "self", ".", "_data_type", "=", "data_type", "\n", "self", ".", "_subset", "=", "subset", "\n", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_ob_period", "=", "int", "(", "observation_period", ")", "\n", "self", ".", "_tokenizer", "=", "NLTKTokenizer", "(", ")", "\n", "# A list of datasets which in turn are a list", "\n", "self", ".", "_raw", "=", "StratifyFacade", "(", ")", ".", "load_stratified_data", "(", ")", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "\"data_\"", "+", "str", "(", "self", ".", "_ob_period", ")", "]", "[", "self", ".", "_dataset", "]", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "subset_idx", "]", "\n", "self", ".", "_data", "=", "self", ".", "_get_posts_list_from_users", "(", "self", ".", "_raw", ")", "\n", "self", ".", "_data", "=", "self", ".", "slice_if_rest_one", "(", "self", ".", "_data", ")", "\n", "self", ".", "_users_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "_posts_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "if", "data_type", "in", "[", "\"txt\"", ",", "\"both\"", "]", ":", "\n", "            ", "if", "text_embedder", "==", "\"elmo\"", ":", "\n", "                ", "self", ".", "_elmo", "=", "self", ".", "preprocess_elmo", "(", ")", "\n", "", "elif", "text_embedder", "==", "\"fasttext\"", ":", "\n", "                ", "self", ".", "_fasttext", "=", "self", ".", "preprocess_fasttext", "(", ")", "\n", "", "elif", "text_embedder", "==", "\"bow\"", ":", "\n", "                ", "self", ".", "_bow", "=", "self", ".", "preprocess_bow", "(", ")", "\n", "", "", "elif", "data_type", "==", "\"ftrs\"", ":", "\n", "            ", "self", ".", "_ftrs", "=", "self", ".", "slice_ftrs", "(", "self", ".", "_get_features", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.slice_if_rest_one": [[104, 113], ["len", "len"], "methods", ["None"], ["", "", "def", "slice_if_rest_one", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "==", "\"ftrs\"", ":", "\n", "            ", "return", "data", "\n", "", "size", "=", "len", "(", "data", ")", "\n", "bs", "=", "self", ".", "config", ".", "general", "[", "\"batch_size\"", "]", "\n", "bs", "=", "bs", "/", "len", "(", "self", ".", "config", ".", "general", "[", "\"gpus\"", "]", ")", "\n", "if", "size", "%", "bs", "==", "1", ":", "\n", "            ", "return", "data", "[", ":", "-", "1", "]", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.slice_ftrs": [[114, 121], ["ftrs.size", "len"], "methods", ["None"], ["", "def", "slice_ftrs", "(", "self", ",", "ftrs", ")", ":", "\n", "        ", "size", "=", "ftrs", ".", "size", "(", "0", ")", "\n", "bs", "=", "self", ".", "config", ".", "general", "[", "\"batch_size\"", "]", "\n", "bs", "=", "bs", "/", "len", "(", "self", ".", "config", ".", "general", "[", "\"gpus\"", "]", ")", "\n", "if", "size", "%", "bs", "==", "1", ":", "\n", "            ", "return", "ftrs", "[", ":", "-", "1", ",", "...", "]", "\n", "", "return", "ftrs", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.raw": [[122, 125], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "raw", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_raw", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.users_df": [[126, 129], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "users_df", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_users_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.posts_df": [[130, 133], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "posts_df", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_posts_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_users_features_names": [[134, 136], ["None"], "methods", ["None"], ["", "def", "get_users_features_names", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "users_df", ".", "columns", ".", "levels", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_posts_features_names": [[137, 139], ["None"], "methods", ["None"], ["", "def", "get_posts_features_names", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "posts_df", ".", "columns", ".", "levels", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.__len__": [[140, 144], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_data_type", "==", "\"ftrs\"", ":", "\n", "            ", "return", "self", ".", "_ftrs", ".", "shape", "[", "0", "]", "\n", "", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.__getitem__": [[145, 174], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\" Returns a 4-tuple with img, caption, label, u_name \"\"\"", "\n", "img", ",", "caption", ",", "label", ",", "u_name", "=", "self", ".", "_data", "[", "idx", "]", "\n", "\n", "if", "self", ".", "_data_type", "==", "\"ftrs\"", ":", "\n", "            ", "u_name", "=", "self", ".", "_users_df", ".", "loc", "[", "idx", ",", "(", "\"questionnaire_ftrs\"", ",", "\"id\"", ")", "]", "\n", "label", "=", "self", ".", "_users_df", ".", "loc", "[", "idx", ",", "(", "\"questionnaire_ftrs\"", ",", "\"label\"", ")", "]", "\n", "if", "self", ".", "_subset", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "                ", "return", "(", "self", ".", "_ftrs", "[", "idx", "]", ",", "label", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "self", ".", "_ftrs", "[", "idx", "]", ",", "label", ",", "u_name", ")", "\n", "\n", "", "", "if", "self", ".", "text_embedder", "==", "\"elmo\"", ":", "\n", "            ", "caption", "=", "(", "self", ".", "_elmo", "[", "idx", "]", ",", ")", "\n", "", "elif", "self", ".", "text_embedder", "==", "\"fasttext\"", ":", "\n", "            ", "caption", "=", "self", ".", "_fasttext", "[", "idx", "]", "\n", "", "elif", "self", ".", "text_embedder", "==", "\"bow\"", ":", "\n", "            ", "caption", "=", "(", "self", ".", "_bow", "[", "idx", "]", ",", ")", "\n", "\n", "", "if", "self", ".", "_data_type", "==", "\"txt\"", ":", "\n", "            ", "data", "=", "caption", "\n", "", "elif", "self", ".", "_data_type", "==", "\"both\"", ":", "\n", "            ", "data", "=", "(", "img", ",", ")", "+", "caption", "\n", "", "elif", "self", ".", "_data_type", "==", "\"img\"", ":", "\n", "            ", "data", "=", "(", "img", ",", ")", "\n", "\n", "", "if", "self", ".", "_subset", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "            ", "return", "data", "+", "(", "label", ",", ")", "\n", "", "return", "data", "+", "(", "label", ",", "u_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._get_posts_list_from_users": [[175, 198], ["u.get_posts_from_qtnre_answer_date", "u.questionnaire.get_binary_bdi", "os.path.join", "dataset.DepressionCorpus.preprocess_data", "data.append", "post.get_img_path_list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.preprocess_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "_get_posts_list_from_users", "(", "self", ",", "user_list", ")", ":", "\n", "        ", "\"\"\" Return a list of posts from a user_list\n        \n        This function consider an instagram post with multiples images as \n        multiples posts with the same caption for all images in the same post.\n        \"\"\"", "\n", "data", "=", "[", "]", "\n", "for", "u", "in", "user_list", ":", "\n", "            ", "for", "post", "in", "u", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_ob_period", ")", ":", "\n", "                ", "images_paths", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INSTAGRAM_DATA", ",", "p", ")", "\n", "for", "p", "in", "post", ".", "get_img_path_list", "(", ")", "\n", "]", "\n", "if", "self", ".", "_data_type", "in", "[", "\"both\"", ",", "\"txt\"", "]", ":", "\n", "                    ", "images_paths", "=", "[", "images_paths", "[", "0", "]", "]", "\n", "", "text", "=", "post", ".", "caption", "\n", "label", "=", "u", ".", "questionnaire", ".", "get_binary_bdi", "(", ")", "\n", "u_name", "=", "u", ".", "username", "\n", "for", "img_path", "in", "images_paths", ":", "\n", "                    ", "img", ",", "txt", "=", "self", ".", "preprocess_data", "(", "img_path", ",", "text", ")", "\n", "data", ".", "append", "(", "(", "img", ",", "txt", ",", "label", ",", "u_name", ")", ")", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_data": [[199, 213], ["dataset.DepressionCorpus._tokenizer.tokenize", "PIL.Image.open", "PIL.Image.open.copy", "PIL.Image.open.close", "dataset.DepressionCorpus._transform"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize"], ["", "def", "preprocess_data", "(", "self", ",", "img_path", ",", "text", ")", ":", "\n", "        ", "text", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "text", ")", "[", ":", "100", "]", "\n", "text", "=", "[", "\"\"", "]", "if", "not", "text", "else", "text", "\n", "\n", "if", "self", ".", "_data_type", "in", "[", "\"img\"", ",", "\"both\"", "]", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "img", "=", "image", ".", "copy", "(", ")", "\n", "image", ".", "close", "(", ")", "\n", "if", "self", ".", "_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "img", "=", "img_path", "\n", "\n", "", "return", "img", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_elmo": [[214, 217], ["zip", "allennlp.modules.elmo.batch_to_ids"], "methods", ["None"], ["", "def", "preprocess_elmo", "(", "self", ")", ":", "\n", "        ", "_", ",", "text", ",", "_", ",", "_", "=", "zip", "(", "*", "self", ".", "_data", ")", "\n", "return", "batch_to_ids", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_fasttext": [[218, 242], ["zip", "numpy.max", "torch.stack", "torch.stack", "list", "numpy.array", "torch.stack.append", "torch.cat", "zip", "torch.from_numpy", "e.size", "torch.cat", "torch.ones", "torch.zeros", "e.size", "torch.zeros", "e.size", "e.size"], "methods", ["None"], ["", "def", "preprocess_fasttext", "(", "self", ")", ":", "\n", "        ", "_", ",", "texts", ",", "_", ",", "_", "=", "zip", "(", "*", "self", ".", "_data", ")", "\n", "\n", "embeddings", "=", "[", "]", "\n", "for", "txt", "in", "texts", ":", "\n", "            ", "text", "=", "np", ".", "array", "(", "[", "self", ".", "fasttext", ".", "wv", "[", "token", "]", "for", "token", "in", "txt", "]", ")", "\n", "embeddings", ".", "append", "(", "torch", ".", "from_numpy", "(", "text", ")", ")", "\n", "\n", "", "max_size", "=", "np", ".", "max", "(", "[", "e", ".", "size", "(", "0", ")", "for", "e", "in", "embeddings", "]", ")", "\n", "masks", "=", "[", "\n", "torch", ".", "cat", "(", "[", "torch", ".", "ones", "(", "e", ".", "size", "(", "0", ")", ")", ",", "torch", ".", "zeros", "(", "max_size", "-", "e", ".", "size", "(", "0", ")", ")", "]", ")", "\n", "for", "e", "in", "embeddings", "\n", "]", "\n", "masks", "=", "torch", ".", "stack", "(", "masks", ",", "dim", "=", "0", ")", "\n", "\n", "embeddings", "=", "torch", ".", "stack", "(", "\n", "[", "\n", "torch", ".", "cat", "(", "[", "e", ",", "torch", ".", "zeros", "(", "(", "max_size", "-", "e", ".", "size", "(", "0", ")", ",", "300", ")", ")", "]", ",", "0", ")", "\n", "for", "e", "in", "embeddings", "\n", "]", ",", "\n", "dim", "=", "0", ",", "\n", ")", "\n", "\n", "return", "list", "(", "zip", "(", "embeddings", ",", "masks", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.preprocess_bow": [[243, 258], ["zip", "torch.from_numpy().float", "pickle.load.transform.size", "sklearn.feature_extraction.text.TfidfVectorizer", "pickle.load.fit_transform", "pickle.load.transform", "open", "pickle.dump", "open", "pickle.load", "torch.from_numpy", "pickle.load.transform.toarray"], "methods", ["None"], ["", "def", "preprocess_bow", "(", "self", ")", ":", "\n", "        ", "_", ",", "texts", ",", "_", ",", "_", "=", "zip", "(", "*", "self", ".", "_data", ")", "\n", "corpus", "=", "[", "\" \"", ".", "join", "(", "tokens", ")", "for", "tokens", "in", "texts", "]", "\n", "if", "self", ".", "_subset", "==", "\"train\"", ":", "\n", "            ", "tfidf_vectorizer", "=", "TfidfVectorizer", "(", "max_df", "=", "0.95", ",", "min_df", "=", "2", ")", "\n", "corpus", "=", "tfidf_vectorizer", ".", "fit_transform", "(", "corpus", ")", "\n", "with", "open", "(", "settings", ".", "PATH_TO_SERIALIZED_TFIDF", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "tfidf_vectorizer", ",", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "settings", ".", "PATH_TO_SERIALIZED_TFIDF", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "tfidf_vectorizer", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "corpus", "=", "tfidf_vectorizer", ".", "transform", "(", "corpus", ")", "\n", "", "corpus", "=", "torch", ".", "from_numpy", "(", "corpus", ".", "toarray", "(", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "bow_ftrs_size", "=", "corpus", ".", "size", "(", "1", ")", "\n", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_posts_dataframes": [[259, 262], ["dataset.DepressionCorpus._get_users_posts_dfs"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._get_users_posts_dfs"], ["", "def", "get_posts_dataframes", "(", "self", ")", ":", "\n", "        ", "self", ".", "_posts_df", "=", "self", ".", "_get_users_posts_dfs", "(", "self", ".", "_raw", ")", "\n", "return", "self", ".", "_posts_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._get_users_posts_dfs": [[263, 275], ["pandas.DataFrame", "u.get_posts_from_qtnre_answer_date", "post.get_dict_representation", "u.questionnaire.get_binary_bdi", "u.questionnaire.get_bdi", "readorsee.features.feature_engineering.get_features_from_post", "post.get_dict_representation.update", "posts_dicts.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_dict_representation", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.features.feature_engineering.get_features_from_post"], ["", "def", "_get_users_posts_dfs", "(", "self", ",", "user_list", ")", ":", "\n", "        ", "posts_dicts", "=", "[", "]", "\n", "for", "u", "in", "user_list", ":", "\n", "            ", "for", "post", "in", "u", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_ob_period", ")", ":", "\n", "                ", "d", "=", "post", ".", "get_dict_representation", "(", ")", "\n", "d", "[", "\"instagram_username\"", "]", "=", "u", ".", "username", "\n", "d", "[", "\"binary_bdi\"", "]", "=", "u", ".", "questionnaire", ".", "get_binary_bdi", "(", ")", "\n", "d", "[", "\"BDI\"", "]", "=", "u", ".", "questionnaire", ".", "get_bdi", "(", "category", "=", "False", ")", "\n", "ftrs", "=", "get_features_from_post", "(", "post", ")", "\n", "d", ".", "update", "(", "ftrs", ")", "\n", "posts_dicts", ".", "append", "(", "d", ")", "\n", "", "", "return", "pd", ".", "DataFrame", "(", "posts_dicts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_participants_dataframes": [[276, 279], ["dataset.DepressionCorpus._create_instagram_user_df"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._create_instagram_user_df"], ["", "def", "get_participants_dataframes", "(", "self", ")", ":", "\n", "        ", "self", ".", "_users_df", "=", "self", ".", "_create_instagram_user_df", "(", "self", ".", "_raw", ")", "\n", "return", "self", ".", "_users_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._create_instagram_user_df": [[280, 327], ["dataset.DepressionCorpus._create_instagram_user_df.get_original_csv_cols_order"], "methods", ["None"], ["", "def", "_create_instagram_user_df", "(", "self", ",", "subset", ")", ":", "\n", "        ", "\"\"\" Valid user profiles are (1) open profiles, and (2) profiles with\n        at least one post.\"\"\"", "\n", "\n", "def", "get_original_csv_cols_order", "(", ")", ":", "\n", "            ", "\"\"\" Get the original answers cols order to keep it normalized\n            in the new dataframe. \"\"\"", "\n", "qtnre_answers", "=", "self", ".", "_load_instagram_questionnaire_answers", "(", ")", "\n", "cols_order", "=", "qtnre_answers", ".", "columns", ".", "tolist", "(", ")", "\n", "return", "cols_order", "\n", "\n", "", "cols_order", "=", "get_original_csv_cols_order", "(", ")", "\n", "\n", "def", "get_answers_df", "(", "participants", ")", ":", "\n", "            ", "questionnaire_features", "=", "[", "]", "\n", "post_ftrs_list", "=", "[", "]", "\n", "txt_ftrs_list", "=", "[", "]", "\n", "vis_ftrs_list", "=", "[", "]", "\n", "for", "profile", "in", "participants", ":", "\n", "                ", "answer_dict", ",", "keys", "=", "profile", ".", "get_answer_dict", "(", ")", "\n", "answer_dict", "[", "\"BDI\"", "]", "=", "profile", ".", "questionnaire", ".", "get_bdi", "(", "category", "=", "False", ")", "\n", "# keys.append(\"BDI\")", "\n", "post_ftrs", ",", "vis_ftrs", ",", "txt_ftrs", "=", "get_features", "(", "profile", ",", "self", ".", "_ob_period", ")", "\n", "self", ".", "swap_features", "(", "answer_dict", ",", "post_ftrs", ")", "\n", "post_ftrs_list", ".", "append", "(", "post_ftrs", ")", "\n", "txt_ftrs_list", ".", "append", "(", "txt_ftrs", ")", "\n", "vis_ftrs_list", ".", "append", "(", "vis_ftrs", ")", "\n", "questionnaire_features", ".", "append", "(", "answer_dict", ")", "\n", "", "post_ftrs", "=", "pd", ".", "DataFrame", "(", "post_ftrs_list", ")", "\n", "txt_ftrs", "=", "pd", ".", "DataFrame", "(", "txt_ftrs_list", ")", "\n", "vis_ftrs", "=", "pd", ".", "DataFrame", "(", "vis_ftrs_list", ")", "\n", "questionnaire_features", "=", "pd", ".", "DataFrame", "(", "\n", "questionnaire_features", ",", "columns", "=", "cols_order", "+", "keys", "\n", ")", "\n", "questionnaire_features", ".", "drop", "(", "\n", "[", "\"following_count\"", ",", "\"followers_count\"", "]", ",", "inplace", "=", "True", ",", "axis", "=", "1", "\n", ")", "\n", "questionnaire_features", "=", "self", ".", "delete_rename_and_categorize_cols", "(", "\n", "questionnaire_features", "\n", ")", "\n", "return", "pd", ".", "concat", "(", "\n", "[", "questionnaire_features", ",", "post_ftrs", ",", "vis_ftrs", ",", "txt_ftrs", "]", ",", "\n", "keys", "=", "[", "\"questionnaire_ftrs\"", ",", "\"post_ftrs\"", ",", "\"vis_ftrs\"", ",", "\"txt_ftrs\"", "]", ",", "\n", "axis", "=", "1", ",", "\n", ")", "\n", "\n", "", "return", "get_answers_df", "(", "subset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._load_instagram_questionnaire_answers": [[328, 331], ["os.path.join", "pandas.read_csv"], "methods", ["None"], ["", "def", "_load_instagram_questionnaire_answers", "(", "self", ")", ":", "\n", "        ", "answers_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INTERIM_DATA", ",", "\"instagram.csv\"", ")", "\n", "return", "pd", ".", "read_csv", "(", "answers_path", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.delete_rename_and_categorize_cols": [[332, 359], ["df.drop", "df.drop.rename", "pandas.factorize"], "methods", ["None"], ["", "def", "delete_rename_and_categorize_cols", "(", "self", ",", "df", ")", ":", "\n", "        ", "remove_columns", "=", "[", "\n", "\"email\"", ",", "\n", "\"course_name\"", ",", "\n", "\"form_application_date\"", ",", "\n", "\"birth_date\"", ",", "\n", "\"course_name\"", ",", "\n", "\"twitter_user_name\"", ",", "\n", "\"accommodation\"", ",", "\n", "]", "\n", "new_df", "=", "df", ".", "drop", "(", "remove_columns", ",", "axis", "=", "1", ")", "\n", "convert_cols", "=", "[", "\n", "\"sex\"", ",", "\n", "\"household_income\"", ",", "\n", "\"academic_degree\"", ",", "\n", "\"scholarship\"", ",", "\n", "\"works\"", ",", "\n", "\"depression_diagnosed\"", ",", "\n", "\"in_therapy\"", ",", "\n", "\"antidepressants\"", ",", "\n", "]", "\n", "for", "col", "in", "convert_cols", ":", "\n", "            ", "new_df", "[", "col", "]", "=", "pd", ".", "factorize", "(", "new_df", "[", "col", "]", ",", "sort", "=", "True", ")", "[", "0", "]", "\n", "", "new_df", ".", "rename", "(", "\n", "{", "\"instagram_user_name\"", ":", "\"id\"", ",", "\"binary_bdi\"", ":", "\"label\"", "}", ",", "axis", "=", "1", ",", "inplace", "=", "True", "\n", ")", "\n", "return", "new_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.swap_features": [[360, 365], ["None"], "methods", ["None"], ["", "def", "swap_features", "(", "self", ",", "bio_ftrs", ",", "data_ftrs", ")", ":", "\n", "        ", "data_ftrs", "[", "\"following_count\"", "]", "=", "bio_ftrs", "[", "\"following_count\"", "]", "\n", "data_ftrs", "[", "\"followers_count\"", "]", "=", "bio_ftrs", "[", "\"followers_count\"", "]", "\n", "del", "bio_ftrs", "[", "\"following_count\"", "]", "\n", "del", "bio_ftrs", "[", "\"followers_count\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_normalized_df": [[366, 385], ["getattr", "dataset.DepressionCorpus.get_participants_dataframes", "dataset.DepressionCorpus.get_normalized_df.remove_cols"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_participants_dataframes"], ["", "def", "get_normalized_df", "(", "self", ")", "->", "pd", ".", "DataFrame", ":", "\n", "        ", "def", "remove_cols", "(", "df", ")", ":", "\n", "            ", "df", "=", "df", ".", "drop", "(", "[", "(", "\"questionnaire_ftrs\"", ",", "\"id\"", ")", "]", ",", "axis", "=", "1", ")", "\n", "df", "=", "df", ".", "drop", "(", "[", "(", "\"questionnaire_ftrs\"", ",", "\"label\"", ")", "]", ",", "axis", "=", "1", ")", "\n", "df", "=", "df", ".", "drop", "(", "[", "(", "\"questionnaire_ftrs\"", ",", "\"BDI\"", ")", "]", ",", "axis", "=", "1", ")", "\n", "return", "df", "\n", "\n", "", "params", "=", "getattr", "(", "self", ".", "config", ",", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", ")", "\n", "users_df", "=", "self", ".", "get_participants_dataframes", "(", ")", "\n", "users_df", "=", "remove_cols", "(", "users_df", ")", "\n", "if", "params", "[", "\"features\"", "]", "==", "\"vis_ftrs\"", "or", "params", "[", "\"features\"", "]", "==", "\"txt_ftrs\"", ":", "\n", "            ", "users_df", "=", "users_df", "[", "[", "params", "[", "\"features\"", "]", ",", "\"post_ftrs\"", "]", "]", "\n", "", "elif", "params", "[", "\"features\"", "]", "==", "\"both\"", ":", "\n", "            ", "users_df", "=", "users_df", "[", "[", "\"txt_ftrs\"", ",", "\"vis_ftrs\"", ",", "\"post_ftrs\"", "]", "]", "\n", "", "elif", "params", "[", "\"features\"", "]", "==", "\"form_ftrs\"", ":", "\n", "            ", "return", "users_df", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Incorrect feature type value.\"", ")", "\n", "", "return", "users_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus._get_features": [[386, 390], ["dataset.DepressionCorpus.get_normalized_df", "torch.from_numpy().float", "torch.from_numpy", "dataset.DepressionCorpus.to_numpy"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpus.get_normalized_df"], ["", "def", "_get_features", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "users_df", "=", "self", ".", "get_normalized_df", "(", ")", "\n", "X", "=", "torch", ".", "from_numpy", "(", "users_df", ".", "to_numpy", "(", ")", ")", ".", "float", "(", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer.__init__": [[393, 432], ["getattr", "media_config[].lower", "int", "dataset.DepressionCorpusTransformer._initialize_tokenizer", "readorsee.data.facade.StratifyFacade().load_stratified_data", "dataset.DepressionCorpusTransformer._get_posts_list_from_users", "ValueError", "ValueError", "torchvision.transforms.Compose", "readorsee.data.facade.StratifyFacade", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "str"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer._initialize_tokenizer", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.load_stratified_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset._get_posts_list_from_users"], ["    ", "def", "__init__", "(", "self", ",", "observation_period", ",", "dataset", ",", "subset", ",", "config", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "text_embedder", "=", "\"\"", "\n", "data_type", "=", "self", ".", "config", ".", "general", "[", "\"media_type\"", "]", "\n", "media_config", "=", "getattr", "(", "self", ".", "config", ",", "data_type", ")", "\n", "text_embedder", "=", "media_config", "[", "\"txt_embedder\"", "]", ".", "lower", "(", ")", "\n", "if", "text_embedder", "not", "in", "[", "\"xlm\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"{text_embedder} must be the 'xlm' embedder to be using DepressionCorpusXLM dataset.\"", "\n", ")", "\n", "\n", "", "if", "data_type", "not", "in", "[", "\"txt\"", ",", "\"both\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Data type '{data_type}' is not valid. It must be one of ['txt', 'both']\"", "\n", ")", "\n", "", "if", "transform", "is", "None", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "[", "224", ",", "224", "]", ",", "interpolation", "=", "Image", ".", "LANCZOS", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", ",", "\n", "]", "\n", ")", "\n", "", "self", ".", "_transform", "=", "transform", "\n", "subset_to_index", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "1", ",", "\"test\"", ":", "2", "}", "\n", "subset_idx", "=", "subset_to_index", "[", "subset", "]", "\n", "self", ".", "text_embedder", "=", "text_embedder", "\n", "self", ".", "_data_type", "=", "data_type", "\n", "self", ".", "_subset", "=", "subset", "\n", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_ob_period", "=", "int", "(", "observation_period", ")", "\n", "self", ".", "_tokenizer", "=", "self", ".", "_initialize_tokenizer", "(", ")", "\n", "# A list of datasets which in turn are a list", "\n", "self", ".", "_raw", "=", "StratifyFacade", "(", ")", ".", "load_stratified_data", "(", ")", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "\"data_\"", "+", "str", "(", "self", ".", "_ob_period", ")", "]", "[", "self", ".", "_dataset", "]", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "subset_idx", "]", "\n", "self", ".", "_data", "=", "self", ".", "_get_posts_list_from_users", "(", "self", ".", "_raw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer._initialize_tokenizer": [[433, 446], ["dataset.DepressionCorpusTransformer.config.general[].lower", "dataset.DepressionCorpusTransformer.config.general[].lower", "transformers.BertTokenizer.from_pretrained", "ValueError", "ValueError"], "methods", ["None"], ["", "def", "_initialize_tokenizer", "(", "self", ")", "->", "BertTokenizer", ":", "\n", "        ", "class_model", "=", "self", ".", "config", ".", "general", "[", "\"class_model\"", "]", ".", "lower", "(", ")", "\n", "bert_size", "=", "self", ".", "config", ".", "general", "[", "\"bert_size\"", "]", ".", "lower", "(", ")", "\n", "if", "\"bert\"", "not", "in", "class_model", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The parameter 'class_model' should be one of the BERT models, not {class_model}.\"", "\n", ")", "\n", "", "if", "bert_size", "not", "in", "[", "\"large\"", ",", "\"base\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The parameter 'bert_size' should be 'large' or 'base', not {bert_size}\"", "\n", ")", "\n", "\n", "", "return", "BertTokenizer", ".", "from_pretrained", "(", "settings", ".", "PATH_TO_BERT", "[", "bert_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer._get_posts_list_from_users": [[447, 470], ["u.get_posts_from_qtnre_answer_date", "u.questionnaire.get_binary_bdi", "os.path.join", "dataset.DepressionCorpusTransformer.preprocess_data", "data.append", "post.get_img_path_list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.preprocess_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "_get_posts_list_from_users", "(", "self", ",", "user_list", ")", ":", "\n", "        ", "\"\"\" Return a list of posts from a user_list\n        \n        This function consider an instagram post with multiples images as \n        multiples posts with the same caption for all images in the same post.\n        \"\"\"", "\n", "data", "=", "[", "]", "\n", "for", "u", "in", "user_list", ":", "\n", "            ", "for", "post", "in", "u", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_ob_period", ")", ":", "\n", "                ", "images_paths", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INSTAGRAM_DATA", ",", "p", ")", "\n", "for", "p", "in", "post", ".", "get_img_path_list", "(", ")", "\n", "]", "\n", "if", "self", ".", "_data_type", "in", "[", "\"both\"", ",", "\"txt\"", "]", ":", "\n", "                    ", "images_paths", "=", "[", "images_paths", "[", "0", "]", "]", "\n", "", "text", "=", "post", ".", "caption", "\n", "label", "=", "u", ".", "questionnaire", ".", "get_binary_bdi", "(", ")", "\n", "u_name", "=", "u", ".", "username", "\n", "for", "img_path", "in", "images_paths", ":", "\n", "                    ", "img", ",", "txt", "=", "self", ".", "preprocess_data", "(", "img_path", ",", "text", ")", "\n", "data", ".", "append", "(", "(", "img", ",", "txt", ",", "label", ",", "u_name", ")", ")", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer.preprocess_data": [[471, 495], ["dataset.DepressionCorpusTransformer._tokenizer.encode_plus", "ftfy.fix_text", "PIL.Image.open", "PIL.Image.open.copy", "PIL.Image.open.close", "dataset.DepressionCorpusTransformer._transform"], "methods", ["None"], ["", "def", "preprocess_data", "(", "self", ",", "img_path", ",", "text", ")", ":", "\n", "# Token indices sequence length is longer than the specified maximum sequence", "\n", "# length for this model (530 > 512). Running this sequence through the model", "\n", "# will result in indexing errors", "\n", "# text = self._tokenizer.encode(text, max_length=511, return_tensors=\"pt\")", "\n", "# text = self._tokenizer.tokenize(ftfy.fix_text(text))", "\n", "        ", "text", "=", "self", ".", "_tokenizer", ".", "encode_plus", "(", "\n", "ftfy", ".", "fix_text", "(", "text", ")", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "150", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", ")", "\n", "if", "self", ".", "_data_type", "in", "[", "\"img\"", ",", "\"both\"", "]", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "img", "=", "image", ".", "copy", "(", ")", "\n", "image", ".", "close", "(", ")", "\n", "if", "self", ".", "_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "img", "=", "img_path", "\n", "\n", "", "return", "img", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer.__len__": [[496, 498], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.DepressionCorpusTransformer.__getitem__": [[499, 510], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "img", ",", "caption", ",", "label", ",", "u_name", "=", "self", ".", "_data", "[", "i", "]", "\n", "\n", "if", "self", ".", "_data_type", "==", "\"txt\"", ":", "\n", "            ", "data", "=", "(", "caption", ",", ")", "\n", "", "elif", "self", ".", "_data_type", "==", "\"both\"", ":", "\n", "            ", "data", "=", "(", "img", ",", ")", "+", "caption", "\n", "\n", "", "if", "self", ".", "_subset", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "            ", "return", "data", "+", "(", "label", ",", ")", "\n", "", "return", "data", "+", "(", "label", ",", "u_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.__init__": [[513, 552], ["int", "readorsee.data.preprocessing.NLTKTokenizer", "readorsee.data.facade.StratifyFacade().load_stratified_data", "dataset.IterableDataset._get_posts_list_from_users", "ValueError", "torchvision.transforms.Compose", "readorsee.data.facade.StratifyFacade", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "str"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.load_stratified_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset._get_posts_list_from_users"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "observation_period", ",", "\n", "data_type", ",", "\n", "dataset", ",", "\n", "subset", ",", "\n", "transform", "=", "None", ",", "\n", "preprocess_text", "=", "True", ",", "\n", "preprocess_img", "=", "True", "\n", ")", ":", "\n", "        ", "if", "data_type", "not", "in", "[", "\"img\"", ",", "\"txt\"", ",", "\"both\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Data type '{data_type}' is not valid. It must be one of ['txt', 'both']\"", "\n", ")", "\n", "", "if", "transform", "is", "None", ":", "\n", "            ", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "[", "224", ",", "224", "]", ",", "interpolation", "=", "Image", ".", "LANCZOS", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", ",", "\n", "]", "\n", ")", "\n", "", "self", ".", "preprocess_text", "=", "preprocess_text", "\n", "self", ".", "preprocess_img", "=", "preprocess_img", "\n", "self", ".", "_transform", "=", "transform", "\n", "subset_to_index", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "1", ",", "\"test\"", ":", "2", "}", "\n", "subset_idx", "=", "subset_to_index", "[", "subset", "]", "\n", "self", ".", "_data_type", "=", "data_type", "\n", "self", ".", "_subset", "=", "subset", "\n", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_ob_period", "=", "int", "(", "observation_period", ")", "\n", "self", ".", "_tokenizer", "=", "NLTKTokenizer", "(", ")", "\n", "# A list of datasets which in turn are a list", "\n", "self", ".", "_raw", "=", "StratifyFacade", "(", ")", ".", "load_stratified_data", "(", ")", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "\"data_\"", "+", "str", "(", "self", ".", "_ob_period", ")", "]", "[", "self", ".", "_dataset", "]", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "subset_idx", "]", "\n", "self", ".", "_data", "=", "self", ".", "_get_posts_list_from_users", "(", "self", ".", "_raw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset._get_posts_list_from_users": [[553, 576], ["u.get_posts_from_qtnre_answer_date", "u.questionnaire.get_binary_bdi", "os.path.join", "dataset.IterableDataset.preprocess_data", "data.append", "post.get_img_path_list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_binary_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.preprocess_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "_get_posts_list_from_users", "(", "self", ",", "user_list", ")", ":", "\n", "        ", "\"\"\" Return a list of posts from a user_list\n        \n        This function consider an instagram post with multiples images as \n        multiples posts with the same caption for all images in the same post.\n        \"\"\"", "\n", "data", "=", "[", "]", "\n", "for", "u", "in", "user_list", ":", "\n", "            ", "for", "post", "in", "u", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_ob_period", ")", ":", "\n", "                ", "images_paths", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INSTAGRAM_DATA", ",", "p", ")", "\n", "for", "p", "in", "post", ".", "get_img_path_list", "(", ")", "\n", "]", "\n", "if", "self", ".", "_data_type", "in", "[", "\"both\"", ",", "\"txt\"", "]", ":", "\n", "                    ", "images_paths", "=", "[", "images_paths", "[", "0", "]", "]", "\n", "", "text", "=", "post", ".", "caption", "\n", "label", "=", "u", ".", "questionnaire", ".", "get_binary_bdi", "(", ")", "\n", "u_name", "=", "u", ".", "username", "\n", "for", "img_path", "in", "images_paths", ":", "\n", "                    ", "img", ",", "txt", "=", "self", ".", "preprocess_data", "(", "img_path", ",", "text", ")", "\n", "data", ".", "append", "(", "(", "img", ",", "txt", ",", "label", ",", "u_name", ")", ")", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.preprocess_data": [[577, 597], ["PIL.Image.open", "PIL.Image.open.copy", "PIL.Image.open.close", "dataset.IterableDataset._tokenizer.tokenize", "ftfy.fix_text", "dataset.IterableDataset._transform"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize"], ["", "def", "preprocess_data", "(", "self", ",", "img_path", ",", "text", ")", ":", "\n", "# Token indices sequence length is longer than the specified maximum sequence", "\n", "# length for this model (530 > 512). Running this sequence through the model", "\n", "# will result in indexing errors", "\n", "# text = self._tokenizer.encode(text, max_length=511, return_tensors=\"pt\")", "\n", "        ", "text", "=", "(", "\n", "self", ".", "_tokenizer", ".", "tokenize", "(", "ftfy", ".", "fix_text", "(", "text", ")", ")", "[", ":", "511", "]", "\n", "if", "self", ".", "preprocess_text", "\n", "else", "text", "\n", ")", "\n", "if", "self", ".", "_data_type", "in", "[", "\"img\"", ",", "\"both\"", "]", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "img", "=", "image", ".", "copy", "(", ")", "\n", "image", ".", "close", "(", ")", "\n", "if", "self", ".", "_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "_transform", "(", "img", ")", "if", "self", ".", "preprocess_img", "else", "img", "\n", "", "", "else", ":", "\n", "            ", "img", "=", "img_path", "\n", "\n", "", "return", "img", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.__len__": [[598, 600], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.IterableDataset.__getitem__": [[601, 614], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "img", ",", "caption", ",", "label", ",", "u_name", "=", "self", ".", "_data", "[", "i", "]", "\n", "\n", "if", "self", ".", "_data_type", "==", "\"txt\"", ":", "\n", "            ", "data", "=", "(", "caption", ",", ")", "\n", "", "elif", "self", ".", "_data_type", "==", "\"img\"", ":", "\n", "            ", "data", "=", "(", "img", ",", ")", "\n", "", "elif", "self", ".", "_data_type", "==", "\"both\"", ":", "\n", "            ", "data", "=", "(", "img", ",", ")", "+", "(", "caption", ")", "\n", "\n", "", "if", "self", ".", "_subset", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "            ", "return", "data", "+", "(", "label", ",", ")", "\n", "", "return", "data", "+", "(", "label", ",", "u_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset.__init__": [[618, 634], ["int", "readorsee.data.facade.StratifyFacade().load_stratified_data", "dataset.TransferDataset._get_posts_list_from_users", "readorsee.data.facade.StratifyFacade", "str"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.load_stratified_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset._get_posts_list_from_users"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "observation_period", ",", "\n", "dataset", ",", "\n", "subset", ",", "\n", ")", ":", "\n", "        ", "subset_to_index", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "1", ",", "\"test\"", ":", "2", "}", "\n", "subset_idx", "=", "subset_to_index", "[", "subset", "]", "\n", "self", ".", "_subset", "=", "subset", "\n", "self", ".", "_dataset", "=", "dataset", "\n", "self", ".", "_ob_period", "=", "int", "(", "observation_period", ")", "\n", "# A list of datasets which in turn are a list", "\n", "self", ".", "_raw", "=", "StratifyFacade", "(", ")", ".", "load_stratified_data", "(", ")", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "\"data_\"", "+", "str", "(", "self", ".", "_ob_period", ")", "]", "[", "self", ".", "_dataset", "]", "\n", "self", ".", "_raw", "=", "self", ".", "_raw", "[", "subset_idx", "]", "\n", "self", ".", "_data", "=", "self", ".", "_get_posts_list_from_users", "(", "self", ".", "_raw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset._get_posts_list_from_users": [[635, 651], ["u.get_posts_from_qtnre_answer_date", "u.questionnaire.get_bdi", "data.append", "post.get_img_path_list"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Participant.get_posts_from_qtnre_answer_date", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.Questionnaire.get_bdi", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.models.InstagramPost.get_img_path_list"], ["", "def", "_get_posts_list_from_users", "(", "self", ",", "user_list", ")", ":", "\n", "        ", "\"\"\" Return a list of posts from a user_list\n        \n        This function consider an instagram post with multiples images as \n        multiples posts with the same caption for all images in the same post.\n        \"\"\"", "\n", "data", "=", "[", "]", "\n", "for", "u", "in", "user_list", ":", "\n", "            ", "for", "post", "in", "u", ".", "get_posts_from_qtnre_answer_date", "(", "self", ".", "_ob_period", ")", ":", "\n", "                ", "images_paths", "=", "[", "p", "for", "p", "in", "post", ".", "get_img_path_list", "(", ")", "]", "\n", "text", "=", "post", ".", "caption", "\n", "label", "=", "u", ".", "questionnaire", ".", "get_bdi", "(", "category", "=", "False", ")", "\n", "u_name", "=", "u", ".", "username", "\n", "data", ".", "append", "(", "(", "images_paths", ",", "text", ",", "label", ",", "u_name", ")", ")", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset.__len__": [[652, 654], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.dataset.TransferDataset.__getitem__": [[655, 658], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "img", ",", "caption", ",", "label", ",", "u_name", "=", "self", ".", "_data", "[", "i", "]", "\n", "return", "(", "img", ",", "caption", ",", "label", ",", "u_name", ")", "\n", "# print(self._data[i])", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.PreProcess.__init__": [[38, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.PreProcess._load_data": [[41, 43], ["None"], "methods", ["None"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.PreProcess.preprocess": [[44, 46], ["None"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.PreProcess.save_processed": [[47, 49], ["None"], "methods", ["None"], ["", "def", "save_processed", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess.__init__": [[64, 71], ["preprocessing.PreProcess.__init__", "preprocessing.RawPreProcess._load_data"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._load_data"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize all dataframes used in this class. \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataframe", "=", "self", ".", "_load_data", "(", ")", "\n", "self", ".", "_out_instagram_df", "=", "None", "\n", "self", ".", "_out_twitter_df", "=", "None", "\n", "self", ".", "_out_all_participants_df", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess.preprocess": [[72, 76], ["print", "preprocessing.RawPreProcess._preprocess_questionnaire", "preprocessing.RawPreProcess.dataframe.copy"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._preprocess_questionnaire"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Preprocessing raw data...\"", ")", "\n", "\"\"\" Preprocess the questionnaire data to normalize it. \"\"\"", "\n", "return", "self", ".", "_preprocess_questionnaire", "(", "self", ".", "dataframe", ".", "copy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._load_data": [[77, 81], ["pandas.read_csv"], "methods", ["None"], ["", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the questionnaire DataFrame. \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "settings", ".", "PATH_TO_QUESTIONNAIRE", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess.save_processed": [[82, 100], ["preprocessing.RawPreProcess._save_dataframe", "preprocessing.RawPreProcess._save_dataframe", "preprocessing.RawPreProcess._save_dataframe", "dict"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._save_dataframe", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._save_dataframe", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._save_dataframe"], ["", "def", "save_processed", "(", "self", ")", ":", "\n", "        ", "\"\"\" Save all three generated DataFrames after preprocessing.\n\n        DataFrames:\n        1. Instagram : Contains only valid instagram useranems\n        2. Twitter   : Contains only valid Twitter usernames\n        3. All Participants : Contains all participants data\n        \"\"\"", "\n", "self", ".", "_save_dataframe", "(", "self", ".", "_out_instagram_df", ",", "\"instagram.csv\"", ")", "\n", "self", ".", "_save_dataframe", "(", "self", ".", "_out_twitter_df", ",", "\"twitter.csv\"", ")", "\n", "self", ".", "_save_dataframe", "(", "self", ".", "_out_all_participants_df", ",", "\n", "\"all_participants.csv\"", ")", "\n", "\n", "data", "=", "dict", "(", "instagram_df", "=", "self", ".", "_out_instagram_df", ",", "\n", "twitter_df", "=", "self", ".", "_out_twitter_df", ",", "\n", "all_participants_df", "=", "self", ".", "_out_all_participants_df", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._get_number": [[101, 105], ["re.compile", "re.match", "int", "re.match.group"], "methods", ["None"], ["", "def", "_get_number", "(", "self", ",", "choice", ")", ":", "\n", "        ", "pattern", "=", "re", ".", "compile", "(", "r\"(\\d)(\\.|\\w)\"", ",", "re", ".", "UNICODE", ")", "\n", "match", "=", "re", ".", "match", "(", "pattern", ",", "choice", ")", "\n", "return", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._salary_normalization": [[106, 117], ["None"], "methods", ["None"], ["", "def", "_salary_normalization", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "text", "==", "\"At\u00e9 R$ 1.874,00\"", ":", "\n", "            ", "return", "\"E\"", "\n", "", "elif", "text", "==", "\"R$ 1.874,01 a R$ 3.748,00\"", ":", "\n", "            ", "return", "\"D\"", "\n", "", "elif", "text", "==", "\"R$ 3.748,01 a R$ 9.370,00\"", ":", "\n", "            ", "return", "\"C\"", "\n", "", "elif", "text", "==", "\"R$ 9.370,01 a R$ 18.740,00\"", ":", "\n", "            ", "return", "\"B\"", "\n", "", "else", ":", "\n", "            ", "return", "\"A\"", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._rename_columns": [[118, 142], ["columns.copy"], "methods", ["None"], ["", "", "def", "_rename_columns", "(", "self", ",", "columns", ")", ":", "\n", "        ", "\"\"\" Return a list of new column names. \"\"\"", "\n", "new_columns", "=", "columns", ".", "copy", "(", ")", "\n", "new_columns", "[", "0", "]", "=", "\"form_application_date\"", "\n", "new_columns", "[", "1", "]", "=", "\"email\"", "\n", "new_columns", "[", "5", "]", "=", "\"sex\"", "\n", "new_columns", "[", "6", "]", "=", "\"birth_date\"", "\n", "new_columns", "[", "7", "]", "=", "\"household_income\"", "\n", "new_columns", "[", "9", "]", "=", "\"facebook_hours\"", "\n", "new_columns", "[", "10", "]", "=", "\"twitter_hours\"", "\n", "new_columns", "[", "11", "]", "=", "\"instagram_hours\"", "\n", "new_columns", "[", "12", "]", "=", "\"academic_degree\"", "\n", "new_columns", "[", "13", "]", "=", "\"course_name\"", "\n", "new_columns", "[", "14", "]", "=", "\"semesters\"", "\n", "new_columns", "[", "15", "]", "=", "\"scholarship\"", "\n", "new_columns", "[", "16", "]", "=", "\"accommodation\"", "\n", "new_columns", "[", "17", "]", "=", "\"works\"", "\n", "new_columns", "[", "20", "]", "=", "\"depression_diagnosed\"", "\n", "new_columns", "[", "21", "]", "=", "\"in_therapy\"", "\n", "new_columns", "[", "22", "]", "=", "\"antidepressants\"", "\n", "new_columns", "[", "45", "]", "=", "\"twitter_user_name\"", "\n", "new_columns", "[", "46", "]", "=", "\"instagram_user_name\"", "\n", "\n", "return", "new_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._normalize_usernames": [[143, 152], ["df[].map", "df[].map", "str().lower().replace().strip", "str().lower().replace().strip", "str().lower().replace", "str().lower().replace", "str().lower", "str().lower", "str", "str"], "methods", ["None"], ["", "def", "_normalize_usernames", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\" Put usernames to lowercase and remove @ from username. \"\"\"", "\n", "df", "[", "\"instagram_user_name\"", "]", "=", "(", "df", "[", "\"instagram_user_name\"", "]", "\n", ".", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ".", "lower", "(", ")", "\n", ".", "replace", "(", "\"@\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", ")", "\n", "df", "[", "\"twitter_user_name\"", "]", "=", "(", "df", "[", "\"twitter_user_name\"", "]", "\n", ".", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ".", "lower", "(", ")", "\n", ".", "replace", "(", "\"@\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._remove_malformed_usernames": [[153, 178], ["list", "preprocessing.RawPreProcess._normalize_usernames", "df.drop_duplicates.drop_duplicates.drop_duplicates", "uname.strip.strip.strip", "map", "pandas.notnull", "uname.strip.strip.isdigit", "preprocessing.RawPreProcess._remove_malformed_usernames.check_validity"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._normalize_usernames"], ["", "def", "_remove_malformed_usernames", "(", "self", ",", "df", ",", "column", ")", ":", "\n", "        ", "\"\"\" Return a new DataFrame without\n        Instagram and Twitter malformed unames.\n\n        Keyword arguments:\n        df -- DataFrame\n        column -- Username column to check\n        \"\"\"", "\n", "def", "check_validity", "(", "uname", ")", ":", "\n", "            ", "\"\"\" Return True if uname is a valid username. False otherwise. \"\"\"", "\n", "uname", "=", "uname", ".", "strip", "(", ")", "\n", "if", "\" \"", "in", "uname", ":", "\n", "                ", "return", "False", "\n", "", "elif", "not", "uname", ":", "\n", "                ", "return", "False", "\n", "", "elif", "uname", ".", "isdigit", "(", ")", ":", "\n", "                ", "return", "False", "\n", "", "return", "True", "\n", "\n", "", "df", "=", "df", "[", "pd", ".", "notnull", "(", "df", "[", "column", "]", ")", "]", "\n", "mask", "=", "list", "(", "map", "(", "lambda", "x", ":", "check_validity", "(", "x", ")", ",", "df", "[", "column", "]", ")", ")", "\n", "df", "=", "df", "[", "mask", "]", "\n", "df", "=", "self", ".", "_normalize_usernames", "(", "df", ")", "\n", "df", "=", "df", ".", "drop_duplicates", "(", "subset", "=", "column", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._save_dataframe": [[179, 183], ["os.path.join", "dataframe.to_csv"], "methods", ["None"], ["", "def", "_save_dataframe", "(", "self", ",", "dataframe", ",", "filename", ")", ":", "\n", "        ", "\"\"\" Save the dataframe with the filename name. \"\"\"", "\n", "data_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INTERIM_DATA", ",", "filename", ")", "\n", "dataframe", ".", "to_csv", "(", "data_path", ",", "encoding", "=", "\"utf-8\"", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._preprocess_questionnaire": [[184, 232], ["df.drop.drop.iloc[].applymap", "df.drop.drop.iloc[].apply", "df.drop.drop.iloc[].transform", "preprocessing.RawPreProcess._rename_columns", "list", "df.drop.drop.drop", "pandas.to_datetime", "df[].apply", "df[].transform", "df.drop.drop.copy", "df.drop.drop.copy", "preprocessing.RawPreProcess._remove_malformed_usernames", "preprocessing.RawPreProcess._remove_malformed_usernames", "dict", "range", "x.lower"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._rename_columns", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._remove_malformed_usernames", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.RawPreProcess._remove_malformed_usernames"], ["", "def", "_preprocess_questionnaire", "(", "self", ",", "df", ")", ":", "\n", "        ", "\"\"\" Pre-process the questionnaire data and return it.\n\n        We have Instagram and Twitter dataframes because of username\n        malformation. Since it is possible for users to input malformed\n        usernames while answering the questionnaire, we remove answers (rows)\n        with malformed usernames.\n\n        Return:\n        instagram_df -- Instagram dataframe\n        twitter_df -- Twitter dataframe\n        all_participants_df -- All participants dataframe\n        \"\"\"", "\n", "df", ".", "iloc", "[", ":", ",", "24", ":", "45", "]", "=", "df", ".", "iloc", "[", ":", ",", "24", ":", "45", "]", ".", "applymap", "(", "self", ".", "_get_number", ")", "\n", "df", "[", "\"BDI\"", "]", "=", "df", ".", "iloc", "[", ":", ",", "24", ":", "45", "]", ".", "apply", "(", "np", ".", "sum", ",", "axis", "=", "1", ")", "\n", "df", ".", "iloc", "[", ":", ",", "7", "]", "=", "df", ".", "iloc", "[", ":", ",", "7", "]", ".", "transform", "(", "self", ".", "_salary_normalization", ")", "\n", "\n", "new_columns", "=", "self", ".", "_rename_columns", "(", "df", ".", "columns", ".", "values", ")", "\n", "df", ".", "columns", "=", "new_columns", "\n", "\n", "bdi_range", "=", "list", "(", "range", "(", "24", ",", "45", ")", ")", "\n", "drop_columns", "=", "[", "2", ",", "3", ",", "4", ",", "8", ",", "18", ",", "19", ",", "23", ",", "47", "]", "+", "bdi_range", "\n", "\n", "df", "=", "df", ".", "drop", "(", "df", ".", "columns", "[", "drop_columns", "]", ",", "axis", "=", "1", ")", "\n", "\n", "df", "[", "\"form_application_date\"", "]", "=", "(", "\n", "pd", ".", "to_datetime", "(", "df", "[", "\"form_application_date\"", "]", ")", ")", "\n", "df", "[", "\"form_application_date\"", "]", "=", "df", "[", "\"form_application_date\"", "]", ".", "apply", "(", "\n", "lambda", "x", ":", "x", ".", "date", ")", "\n", "df", "[", "\"email\"", "]", "=", "df", "[", "\"email\"", "]", ".", "transform", "(", "lambda", "x", ":", "x", ".", "lower", "(", ")", ")", "\n", "\n", "instagram_df", "=", "df", ".", "copy", "(", ")", "\n", "twitter_df", "=", "df", ".", "copy", "(", ")", "\n", "\n", "instagram_df", "=", "self", ".", "_remove_malformed_usernames", "(", "instagram_df", ",", "\n", "\"instagram_user_name\"", ")", "\n", "twitter_df", "=", "self", ".", "_remove_malformed_usernames", "(", "twitter_df", ",", "\n", "\"twitter_user_name\"", ")", "\n", "\n", "self", ".", "_out_instagram_df", "=", "instagram_df", "\n", "self", ".", "_out_twitter_df", "=", "twitter_df", "\n", "self", ".", "_out_all_participants_df", "=", "df", "\n", "\n", "data", "=", "dict", "(", "instagram_df", "=", "self", ".", "_out_instagram_df", ",", "\n", "twitter_df", "=", "self", ".", "_out_twitter_df", ",", "\n", "all_participants_df", "=", "self", ".", "_out_all_participants_df", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess.__init__": [[248, 253], ["preprocessing.PreProcess.__init__"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_out_instagram_df", "=", "None", "\n", "self", ".", "_valid_participants", "=", "None", "\n", "self", ".", "_blocked_profiles", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess.preprocess": [[254, 292], ["print", "preprocessing.InstagramExternalPreProcess._load_instagram_questionnaire_answers", "preprocessing.InstagramExternalPreProcess._load_data", "preprocessing.InstagramExternalPreProcess._blocked_profiles.remove", "preprocessing.InstagramExternalPreProcess._create_instagram_df", "dict", "preprocessing.InstagramExternalPreProcess._has_at_least_one_post", "preprocessing.InstagramExternalPreProcess._get_instagram_models", "preprocessing.InstagramExternalPreProcess._blocked_profiles.append", "os.path.join", "preprocessing.InstagramExternalPreProcess._blocked_profiles.append", "preprocessing.InstagramExternalPreProcess._valid_participants.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._load_instagram_questionnaire_answers", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._load_data", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._create_instagram_df", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._has_at_least_one_post", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_models"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "\"\"\" Load and preprocess all instagram posts from all participants\n        (external folder) with valid and open instagram profiles. Only users\n        with at least 1 post are considered in this study.\n\n        Return:\n        valid_participants -- All valid participants (at least 1 post)\n        blocked_profiles -- All blocked instagram profiles\n        \"\"\"", "\n", "print", "(", "\"Preprocessing external data...\"", ")", "\n", "answers_df", "=", "self", ".", "_load_instagram_questionnaire_answers", "(", ")", "\n", "\n", "self", ".", "_blocked_profiles", "=", "[", "]", "\n", "self", ".", "_valid_participants", "=", "[", "]", "\n", "\n", "for", "user", "in", "self", ".", "_load_data", "(", "settings", ".", "PATH_TO_INSTAGRAM_DATA", ")", ":", "\n", "\n", "            ", "if", "self", ".", "_has_at_least_one_post", "(", "user", "[", "\"json\"", "]", ")", ":", "\n", "                ", "instagram_user", ",", "instagram_posts", "=", "self", ".", "_get_instagram_models", "(", "\n", "os", ".", "path", ".", "join", "(", "user", "[", "\"folder_path\"", "]", ")", ",", "user", "[", "\"username\"", "]", ",", "\n", "user", "[", "\"json\"", "]", ",", "answers_df", ")", "\n", "\n", "if", "(", "instagram_user", "is", "None", ")", "or", "(", "instagram_posts", "is", "None", ")", ":", "\n", "                    ", "self", ".", "_blocked_profiles", ".", "append", "(", "user", "[", "\"username\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "_valid_participants", ".", "append", "(", "instagram_user", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "_blocked_profiles", ".", "append", "(", "user", "[", "\"username\"", "]", ")", "\n", "\n", "", "", "self", ".", "_blocked_profiles", ".", "remove", "(", "\"instagram\"", ")", "\n", "self", ".", "_out_instagram_df", "=", "self", ".", "_create_instagram_df", "(", "\n", "self", ".", "_valid_participants", ")", "\n", "\n", "data", "=", "dict", "(", "valid_participants", "=", "self", ".", "_valid_participants", ",", "\n", "blocked_profiles", "=", "self", ".", "_blocked_profiles", ",", "\n", "instagram_df", "=", "self", ".", "_out_instagram_df", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._load_data": [[293, 299], ["os.walk", "os.path.basename", "preprocessing.InstagramExternalPreProcess._get_user_json", "dict"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_user_json"], ["", "def", "_load_data", "(", "self", ",", "data_folder", ")", ":", "\n", "        ", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "data_folder", ")", ":", "\n", "            ", "username", "=", "os", ".", "path", ".", "basename", "(", "root", ")", "\n", "user_json", "=", "self", ".", "_get_user_json", "(", "root", ",", "username", ")", "\n", "data", "=", "dict", "(", "json", "=", "user_json", ",", "username", "=", "username", ",", "folder_path", "=", "root", ")", "\n", "yield", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._load_instagram_questionnaire_answers": [[300, 304], ["os.path.join", "pandas.read_csv"], "methods", ["None"], ["", "", "def", "_load_instagram_questionnaire_answers", "(", "self", ")", ":", "\n", "        ", "answers_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_INTERIM_DATA", ",", "\n", "\"instagram.csv\"", ")", "\n", "return", "pd", ".", "read_csv", "(", "answers_path", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_user_json": [[305, 323], ["os.path.join", "json.loads", "open", "f.read"], "methods", ["None"], ["", "def", "_get_user_json", "(", "self", ",", "root", ",", "username", ")", ":", "\n", "        ", "\"\"\" Return the JSON that contains the user information.\n\n        Return:\n        user_json -- JSON object with Instagram posts and user profile data\n        \"\"\"", "\n", "json_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "username", "+", "\".json\"", ")", "\n", "\n", "try", ":", "\n", "\n", "            ", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "user_json", "=", "f", ".", "read", "(", ")", "\n", "", "user_json", "=", "json", ".", "loads", "(", "user_json", ")", "\n", "\n", "", "except", "Exception", ":", "\n", "            ", "user_json", "=", "None", "\n", "\n", "", "return", "user_json", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._has_at_least_one_post": [[324, 334], ["user_json.get", "len"], "methods", ["None"], ["", "def", "_has_at_least_one_post", "(", "self", ",", "user_json", ")", ":", "\n", "        ", "\"\"\" Check if this user profile is not blocked for public view.\n\n        We only need to check if the \"GraphImages\" object exists inside the\n        JSON file and then check if it has at least 1 post.\n        \"\"\"", "\n", "if", "user_json", ":", "\n", "            ", "graph_images", "=", "user_json", ".", "get", "(", "\"GraphImages\"", ",", "[", "]", ")", "\n", "return", "True", "if", "len", "(", "graph_images", ")", ">", "0", "else", "False", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_models": [[335, 369], ["preprocessing.InstagramExternalPreProcess._get_qtnre_model", "preprocessing.InstagramExternalPreProcess._get_instagram_user_model", "preprocessing.InstagramExternalPreProcess._get_instagram_post_model", "instagram_posts.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_qtnre_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_user_model", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_post_model"], ["", "def", "_get_instagram_models", "(", "self", ",", "root_path", ",", "username", ",", "user_json", ",", "\n", "answers_df", ")", ":", "\n", "        ", "\"\"\" Uses the models written in models.py file to model\n        instagram posts into proper classes. It assumes that the user_json\n        was already checked to have the GraphImages object.\n\n        Return:\n        instagram_user -- InstagramUser model\n        instagram_posts -- A list of InstagramPost classes\n        None -- if there is no post objects\n        \"\"\"", "\n", "posts_json", "=", "user_json", "[", "\"GraphImages\"", "]", "\n", "profile_json", "=", "user_json", "[", "\"GraphProfileInfo\"", "]", "\n", "instagram_posts", "=", "[", "]", "\n", "\n", "qtnre_answer", "=", "self", ".", "_get_qtnre_model", "(", "username", ",", "answers_df", ")", "\n", "\n", "for", "post", "in", "posts_json", ":", "\n", "            ", "instagram_post", "=", "self", ".", "_get_instagram_post_model", "(", "root_path", ",", "post", ")", "\n", "\n", "if", "instagram_post", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "instagram_posts", ".", "append", "(", "instagram_post", ")", "\n", "\n", "", "if", "not", "instagram_posts", ":", "\n", "            ", "return", "None", ",", "None", "\n", "\n", "", "instagram_user", "=", "self", ".", "_get_instagram_user_model", "(", "username", ",", "\n", "profile_json", ",", "\n", "qtnre_answer", ",", "\n", "instagram_posts", ")", "\n", "\n", "return", "instagram_user", ",", "instagram_posts", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_qtnre_model": [[370, 375], ["readorsee.data.models.Questionnaire", "answer_df[].to_dict"], "methods", ["None"], ["", "def", "_get_qtnre_model", "(", "self", ",", "username", ",", "answer_df", ")", ":", "\n", "        ", "mask", "=", "answer_df", "[", "\"instagram_user_name\"", "]", "==", "username", "\n", "answer_dict", "=", "answer_df", "[", "mask", "]", ".", "to_dict", "(", "\"records\"", ")", "[", "0", "]", "\n", "qtnre", "=", "Questionnaire", "(", "answer_dict", ")", "\n", "return", "qtnre", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_post_model": [[376, 409], ["preprocessing.InstagramExternalPreProcess._process_post_images", "readorsee.data.models.InstagramPost.get().get", "preprocessing.InstagramExternalPreProcess._get_instagram_post_model.get_caption"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._process_post_images"], ["", "def", "_get_instagram_post_model", "(", "self", ",", "root_path", ",", "post", ")", ":", "\n", "        ", "\"\"\" Return the InstagramPost model for this post.\n\n        Return:\n        instagram_post -- InstagramPost instance or None if this post contains\n            no images\n        \"\"\"", "\n", "\n", "imgs_paths", "=", "self", ".", "_process_post_images", "(", "root_path", ",", "post", ")", "\n", "\n", "if", "not", "imgs_paths", ":", "\n", "            ", "return", "None", "\n", "\n", "", "likes_count", "=", "post", ".", "get", "(", "\"edge_media_preview_like\"", ")", ".", "get", "(", "\"count\"", ",", "0", ")", "\n", "\n", "def", "get_caption", "(", "post", ")", ":", "\n", "            ", "caption", "=", "post", "[", "\"edge_media_to_caption\"", "]", "[", "\"edges\"", "]", "\n", "if", "len", "(", "caption", ")", ":", "\n", "                ", "caption", "=", "caption", "[", "0", "]", ".", "get", "(", "\"node\"", ")", ".", "get", "(", "\"text\"", ",", "\"\"", ")", "\n", "", "else", ":", "\n", "                ", "caption", "=", "\"\"", "\n", "", "return", "caption", "\n", "\n", "", "caption", "=", "get_caption", "(", "post", ")", "\n", "comments_count", "=", "post", "[", "\"edge_media_to_comment\"", "]", ".", "get", "(", "\"count\"", ",", "0", ")", "\n", "timestamp", "=", "post", "[", "\"taken_at_timestamp\"", "]", "\n", "\n", "post", "=", "InstagramPost", "(", "imgs_paths", ",", "caption", ",", "likes_count", ",", "timestamp", ",", "\n", "comments_count", ")", "\n", "\n", "post", ".", "calculate_face_count_list", "(", ")", "\n", "\n", "return", "post", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._process_post_images": [[410, 436], ["list", "re.compile", "re.search", "re.search.group", "filter", "os.path.join", "os.path.isfile", "map", "os.path.join", "img_path_list.append", "post.get", "os.path.basename"], "methods", ["None"], ["", "def", "_process_post_images", "(", "self", ",", "root_path", ",", "post", ")", ":", "\n", "        ", "\"\"\" Return images paths for this specific post.\n\n        For Instagram, one post can possibly have two or more pictures. Return\n        paths that are found in directory.\n        \"\"\"", "\n", "def", "process_url", "(", "url", ")", ":", "\n", "            ", "if", "not", "url", ":", "\n", "                ", "return", "\"\"", "\n", "", "pattern", "=", "re", ".", "compile", "(", "r\"/(\\d*_\\d*_\\d*_\\w\\.jpg)\\?\"", ",", "re", ".", "UNICODE", ")", "\n", "match", "=", "re", ".", "search", "(", "pattern", ",", "url", ")", "\n", "if", "match", "is", "None", ":", "\n", "                ", "return", "\"\"", "\n", "", "return", "match", ".", "group", "(", "1", ")", "\n", "\n", "", "pic_ids", "=", "list", "(", "filter", "(", "None", ",", "map", "(", "process_url", ",", "\n", "post", ".", "get", "(", "\"urls\"", ",", "[", "]", ")", ")", ")", ")", "\n", "img_path_list", "=", "[", "]", "\n", "\n", "for", "pid", "in", "pic_ids", ":", "\n", "            ", "image_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "pid", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "image_path", ")", ":", "\n", "                ", "img_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "basename", "(", "root_path", ")", ",", "pid", ")", "\n", "img_path_list", ".", "append", "(", "img_path", ")", "\n", "\n", "", "", "return", "img_path_list", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._get_instagram_user_model": [[437, 450], ["profile_info.get", "profile_info.get", "profile_info.get", "profile_info.get", "profile_info.get", "readorsee.data.models.InstagramUser"], "methods", ["None"], ["", "def", "_get_instagram_user_model", "(", "self", ",", "username", ",", "profile", ",", "qtnre_answer", ",", "\n", "instagram_posts", ")", ":", "\n", "        ", "\"\"\" Create and return an InstagramUser model. \"\"\"", "\n", "profile_info", "=", "profile", "[", "\"info\"", "]", "\n", "biography", "=", "profile_info", ".", "get", "(", "\"biography\"", ",", "\"\"", ")", "\n", "followers_count", "=", "profile_info", ".", "get", "(", "\"followers_count\"", ",", "0", ")", "\n", "following_count", "=", "profile_info", ".", "get", "(", "\"following_count\"", ",", "0", ")", "\n", "is_private", "=", "profile_info", ".", "get", "(", "\"is_private\"", ",", "True", ")", "\n", "posts_count", "=", "profile_info", ".", "get", "(", "\"posts_count\"", ",", "0", ")", "\n", "user", "=", "InstagramUser", "(", "biography", ",", "followers_count", ",", "following_count", ",", "\n", "is_private", ",", "posts_count", ",", "qtnre_answer", ",", "username", ",", "\n", "instagram_posts", ")", "\n", "return", "user", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess._create_instagram_df": [[451, 476], ["preprocessing.InstagramExternalPreProcess._create_instagram_df.get_original_csv_cols_order"], "methods", ["None"], ["", "def", "_create_instagram_df", "(", "self", ",", "valid_participants", ")", ":", "\n", "        ", "\"\"\" Valid user profiles are (1) open profiles, and (2) profiles with\n        at least one post.\"\"\"", "\n", "\n", "if", "not", "valid_participants", ":", "\n", "            ", "raise", "PreProcessingError", "\n", "\n", "", "def", "get_original_csv_cols_order", "(", ")", ":", "\n", "            ", "\"\"\" Get the original answers cols order to keep it normalized\n            in the new dataframe. \"\"\"", "\n", "qtnre_answers", "=", "self", ".", "_load_instagram_questionnaire_answers", "(", ")", "\n", "cols_order", "=", "qtnre_answers", ".", "columns", ".", "tolist", "(", ")", "\n", "return", "cols_order", "\n", "\n", "", "cols_order", "=", "get_original_csv_cols_order", "(", ")", "\n", "\n", "questionnaire_answers", "=", "[", "]", "\n", "for", "profile", "in", "valid_participants", ":", "\n", "            ", "answer_dict", ",", "keys", "=", "profile", ".", "get_answer_dict", "(", ")", "\n", "questionnaire_answers", ".", "append", "(", "answer_dict", ")", "\n", "\n", "", "self", ".", "_out_instagram_df", "=", "pd", ".", "DataFrame", "(", "questionnaire_answers", ",", "\n", "columns", "=", "cols_order", "+", "keys", ")", "\n", "\n", "return", "self", ".", "_out_instagram_df", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.InstagramExternalPreProcess.save_processed": [[477, 484], ["dict"], "methods", ["None"], ["", "def", "save_processed", "(", "self", ")", ":", "\n", "\n", "        ", "data", "=", "dict", "(", "participants", "=", "self", ".", "_valid_participants", ",", "\n", "blocked_profiles", "=", "self", ".", "_blocked_profiles", ",", "\n", "instagram_df", "=", "self", ".", "_out_instagram_df", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.__init__": [[488, 498], ["preprocessing.PreProcess.__init__", "preprocessing.Tokenizer", "collections.defaultdict", "sum", "print", "open"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_files", "=", "100", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tokenizer", "=", "Tokenizer", "(", ")", "\n", "self", ".", "_vocabulary", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_n_files", "=", "n_files", "\n", "count", "=", "sum", "(", "1", "for", "line", "in", "open", "(", "settings", ".", "PATH_TO_EXTERNAL_TWITTER_DATA", ")", ")", "\n", "self", ".", "_total_lines", "=", "count", "\n", "self", ".", "_block_size", "=", "self", ".", "_total_lines", "//", "self", ".", "_n_files", "\n", "print", "(", "\"Total tweets: {} \\nTweets per batch: {}\"", ".", "format", "(", "\n", "count", ",", "self", ".", "_block_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._read_large_file": [[499, 509], ["block.append", "len"], "methods", ["None"], ["", "def", "_read_large_file", "(", "self", ",", "file_handler", ",", "block_size", "=", "10000", ")", ":", "\n", "        ", "block", "=", "[", "]", "\n", "for", "line", "in", "file_handler", ":", "\n", "            ", "block", ".", "append", "(", "line", ")", "\n", "if", "len", "(", "block", ")", "==", "block_size", ":", "\n", "                ", "yield", "block", "\n", "block", "=", "[", "]", "\n", "\n", "", "", "if", "block", ":", "\n", "            ", "yield", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._load_data": [[510, 512], ["None"], "methods", ["None"], ["", "", "def", "_load_data", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.preprocess": [[517, 540], ["print", "preprocessing.TweetsExternalPreProcess.save_vocabulary", "open", "preprocessing.TweetsExternalPreProcess._read_large_file", "print", "print", "preprocessing.TweetsExternalPreProcess.save_processed", "preprocessing.TweetsExternalPreProcess.tokenizer.tokenize", "preprocessing.TweetsExternalPreProcess._add_to_vocabulary", "batch_tokens.append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.save_vocabulary", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._read_large_file", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.save_processed", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._add_to_vocabulary"], ["", "@", "track_time", "\n", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"Preprocessing tweets...\"", ")", "\n", "batch_tokens", "=", "[", "]", "\n", "batch_count", "=", "0", "\n", "\n", "with", "open", "(", "settings", ".", "PATH_TO_EXTERNAL_TWITTER_DATA", ")", "as", "infile", ":", "\n", "\n", "            ", "for", "block", "in", "self", ".", "_read_large_file", "(", "infile", ",", "self", ".", "_block_size", ")", ":", "\n", "                ", "print", "(", "\"Processing batch {}...\"", ".", "format", "(", "batch_count", ")", ")", "\n", "for", "text", "in", "block", ":", "\n", "                    ", "tokenized", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "_add_to_vocabulary", "(", "tokenized", ")", "\n", "batch_tokens", ".", "append", "(", "tokenized", ")", "\n", "\n", "", "print", "(", "\"Saving batch {}\"", ".", "format", "(", "batch_count", ")", ")", "\n", "self", ".", "save_processed", "(", "\n", "batch_count", ",", "batch_tokens", ",", "\n", "settings", ".", "PATH_TO_PROCESSED_TO_TRAIN_TWEETS", ")", "\n", "batch_tokens", "=", "[", "]", "\n", "batch_count", "+=", "1", "\n", "\n", "", "", "self", ".", "save_vocabulary", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._add_to_vocabulary": [[541, 544], ["None"], "methods", ["None"], ["", "def", "_add_to_vocabulary", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "for", "t", "in", "tokens", ":", "\n", "            ", "self", ".", "_vocabulary", "[", "t", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.save_processed": [[545, 553], ["os.path.join", "open", "f.write"], "methods", ["None"], ["", "", "def", "save_processed", "(", "self", ",", "file_number", ",", "batch_tokens", ",", "f_path", ")", ":", "\n", "        ", "file_name", "=", "\"tweets.pt-{:05d}-of-{:05d}\"", ".", "format", "(", "file_number", ",", "\n", "self", ".", "_n_files", "-", "1", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "f_path", ",", "file_name", ")", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "tweet_tokens", "in", "batch_tokens", ":", "\n", "                ", "tweet_str", "=", "\" \"", ".", "join", "(", "tweet_tokens", ")", "\n", "f", ".", "write", "(", "tweet_str", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.save_vocabulary": [[554, 561], ["preprocessing.TweetsExternalPreProcess._sort_vocabulary_by_value", "print", "print", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._sort_vocabulary_by_value"], ["", "", "", "def", "save_vocabulary", "(", "self", ")", ":", "\n", "        ", "sorted_tokens", "=", "self", ".", "_sort_vocabulary_by_value", "(", ")", "\n", "print", "(", "\"Most common words: \"", ",", "sorted_tokens", "[", ":", "10", "]", ")", "\n", "print", "(", "\"Saving Vocabulary...\"", ")", "\n", "with", "open", "(", "settings", ".", "PATH_TO_VOCABULARY_DATA", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "token", ",", "_", "in", "sorted_tokens", ":", "\n", "                ", "f", ".", "write", "(", "token", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess._sort_vocabulary_by_value": [[562, 566], ["sorted", "preprocessing.TweetsExternalPreProcess._vocabulary.items", "operator.itemgetter"], "methods", ["None"], ["", "", "", "def", "_sort_vocabulary_by_value", "(", "self", ")", ":", "\n", "        ", "sorted_vocabulary", "=", "sorted", "(", "\n", "self", ".", "_vocabulary", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "return", "sorted_vocabulary", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.Tokenizer.__init__": [[570, 572], ["spacy.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_nlp", "=", "spacy", ".", "load", "(", "\"pt_core_news_sm\"", ",", "disable", "=", "[", "\"ner\"", ",", "\"tagger\"", ",", "\"parser\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.Tokenizer.tokenize": [[573, 577], ["text.lower().replace().replace.lower().replace().replace.lower().replace().replace", "preprocessing.Tokenizer._nlp", "preprocessing.Tokenizer._normalize", "text.lower().replace().replace.lower().replace().replace.lower().replace", "text.lower().replace().replace.lower().replace().replace.lower"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.Tokenizer._normalize"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "remove_hashtags", "=", "True", ")", ":", "\n", "        ", "text", "=", "text", ".", "lower", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\r\"", ",", "\"\"", ")", "\n", "doc", "=", "self", ".", "_nlp", "(", "text", ")", "\n", "return", "self", ".", "_normalize", "(", "doc", ",", "remove_hashtags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.Tokenizer._normalize": [[578, 609], ["re.compile", "re.compile", "re.compile", "re.compile", "re.escape", "re.compile", "re.compile.sub", "re.compile.sub", "re.compile.sub", "re.compile.sub", "re.compile.sub", "tokens.append"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "doc", ",", "remove_hashtags", ")", ":", "\n", "        ", "tokens", "=", "[", "]", "\n", "\n", "remove_next", "=", "False", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "tk", "=", "token", ".", "text", "\n", "re_username", "=", "re", ".", "compile", "(", "r\"^@\\w+|\\s@\\w+\"", ",", "re", ".", "UNICODE", ")", "\n", "re_transform_url", "=", "re", ".", "compile", "(", "r'(http|https)://[^\\s]+'", ",", "re", ".", "UNICODE", ")", "\n", "re_transform_emails", "=", "re", ".", "compile", "(", "r'[^\\s]+@[^\\s]+'", ",", "re", ".", "UNICODE", ")", "\n", "re_transform_numbers", "=", "re", ".", "compile", "(", "r'\\d+'", ",", "re", ".", "UNICODE", ")", "\n", "punctuations", "=", "re", ".", "escape", "(", "r'\"_#\u00b0%\\'()\\*\\+/=@\\|{}~'", ")", "\n", "re_punctuations", "=", "re", ".", "compile", "(", "r'[%s]'", "%", "(", "punctuations", ")", ",", "re", ".", "UNICODE", ")", "\n", "\n", "tk", "=", "re_username", ".", "sub", "(", "\"username\"", ",", "tk", ")", "\n", "tk", "=", "re_transform_url", ".", "sub", "(", "\"url\"", ",", "tk", ")", "\n", "tk", "=", "re_transform_emails", ".", "sub", "(", "\"email\"", ",", "tk", ")", "\n", "\n", "if", "remove_next", ":", "\n", "                ", "tk", "=", "\"\"", "\n", "remove_next", "=", "False", "\n", "\n", "", "if", "remove_hashtags", "and", "tk", "==", "\"#\"", ":", "\n", "                ", "remove_next", "=", "True", "\n", "\n", "", "tk", "=", "re_transform_numbers", ".", "sub", "(", "\"0\"", ",", "tk", ")", "\n", "\n", "tk", "=", "re_punctuations", ".", "sub", "(", "\"\"", ",", "tk", ")", "\n", "\n", "if", "tk", "and", "(", "\" \"", "not", "in", "tk", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "tk", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.NLTKTokenizer.__init__": [[612, 614], ["nltk.tokenize.TweetTokenizer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "nltk", "=", "TweetTokenizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.NLTKTokenizer.tokenize": [[615, 618], ["preprocessing.NLTKTokenizer.nltk.tokenize"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "remove_hashtags", "=", "True", ")", ":", "\n", "        ", "tokens", "=", "self", ".", "nltk", ".", "tokenize", "(", "text", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.__init__": [[621, 623], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.MyBERTTokenizer.tokenize": [[624, 626], ["None"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "remove_hashtags", "=", "True", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.track_time": [[15, 25], ["time.time", "func", "time.time", "print"], "function", ["None"], ["def", "track_time", "(", "func", ")", ":", "\n", "    ", "\"\"\" Decorator to track functions time executions'. \"\"\"", "\n", "def", "wrapper", "(", "*", "arg", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "ret", "=", "func", "(", "*", "arg", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Function {} took : {}s\"", ".", "format", "(", "func", ".", "__name__", ",", "end", "-", "start", ")", ")", "\n", "return", "ret", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.PreProcessFacade.__init__": [[11, 24], ["readorsee.data.preprocessing.RawPreProcess", "readorsee.data.preprocessing.InstagramExternalPreProcess", "readorsee.data.preprocessing.RawPreProcess", "readorsee.data.preprocessing.InstagramExternalPreProcess", "readorsee.data.preprocessing.TweetsExternalPreProcess"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "process_method", ",", "save", "=", "True", ")", ":", "\n", "        ", "if", "process_method", "==", "\"complete\"", ":", "\n", "            ", "self", ".", "_pipeline", "=", "[", "preprocessing", ".", "RawPreProcess", "(", ")", ",", "\n", "preprocessing", ".", "InstagramExternalPreProcess", "(", ")", "]", "\n", "", "elif", "process_method", "==", "\"raw\"", ":", "\n", "            ", "self", ".", "_pipeline", "=", "[", "preprocessing", ".", "RawPreProcess", "(", ")", "]", "\n", "", "elif", "process_method", "==", "\"instagram_external\"", ":", "\n", "            ", "self", ".", "_pipeline", "=", "[", "preprocessing", ".", "InstagramExternalPreProcess", "(", ")", "]", "\n", "", "elif", "process_method", "==", "\"twitter_external\"", ":", "\n", "            ", "self", ".", "_pipeline", "=", "[", "preprocessing", ".", "TweetsExternalPreProcess", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "self", ".", "_save", "=", "save", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.PreProcessFacade.process_pipeline": [[25, 39], ["pre_process.preprocess", "pre_process.save_processed"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.preprocess", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.preprocessing.TweetsExternalPreProcess.save_processed"], ["", "def", "process_pipeline", "(", "self", ")", ":", "\n", "        ", "\"\"\" Preprocess pipeline and return the last generated dataset in\n        the pipeline\n\n        Return:\n            data -- if the process is successful, the data will be returned.\n                    if save = False, then no data will be returned.\n        \"\"\"", "\n", "final_dataset", "=", "None", "\n", "for", "pre_process", "in", "self", ".", "_pipeline", ":", "\n", "            ", "pre_process", ".", "preprocess", "(", ")", "\n", "if", "self", ".", "_save", ":", "\n", "                ", "final_dataset", "=", "pre_process", ".", "save_processed", "(", ")", "\n", "", "", "return", "final_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.__init__": [[43, 46], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "algorithm", "=", "\"local_search\"", ")", ":", "\n", "        ", "self", ".", "_data", "=", "{", "}", "\n", "self", ".", "_algorithm", "=", "algorithm", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.stratify": [[47, 70], ["facade.PreProcessFacade", "facade.PreProcessFacade.process_pipeline", "readorsee.data.stratification.LocalSearch", "range", "str", "print", "readorsee.data.stratification.LocalSearch.stratify", "facade.StratifyFacade._data[].append"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.PreProcessFacade.process_pipeline", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.stratify"], ["", "def", "stratify", "(", "self", ",", "tr_size", "=", "0.6", ",", "val_size", "=", "0.2", ",", "te_size", "=", "0.2", ",", "\n", "n_sets", "=", "10", ",", "days", "=", "[", "60", ",", "212", ",", "365", "]", ",", "save", "=", "True", ")", ":", "\n", "        ", "\"\"\" Stratify data according to params \"\"\"", "\n", "self", ".", "_data", "=", "{", "}", "\n", "\n", "pprocess_facade", "=", "PreProcessFacade", "(", "\"complete\"", ",", "save", ")", "\n", "data", "=", "pprocess_facade", ".", "process_pipeline", "(", ")", "\n", "participants", "=", "data", "[", "\"participants\"", "]", "\n", "\n", "if", "self", ".", "_algorithm", "==", "\"local_search\"", ":", "\n", "            ", "stratification_algorithm", "=", "stratification", ".", "LocalSearch", "(", "\n", "tr_size", ",", "val_size", ",", "te_size", ")", "\n", "\n", "", "for", "d", "in", "days", ":", "\n", "            ", "attr_name", "=", "\"data_\"", "+", "str", "(", "d", ")", "\n", "self", ".", "_data", "[", "attr_name", "]", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "n_sets", ")", ":", "\n", "                ", "print", "(", "\"Dataset {} : \"", ".", "format", "(", "n", ")", ",", "end", "=", "\"\"", ")", "\n", "stratified", "=", "stratification_algorithm", ".", "stratify", "(", "\n", "participants", ",", "d", ")", "\n", "self", ".", "_data", "[", "attr_name", "]", ".", "append", "(", "stratified", ")", "\n", "\n", "", "", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.save": [[71, 81], ["os.path.join", "facade.StratifyFacade._data.keys", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ")", ":", "\n", "        ", "stratified_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_PROCESSED_DATA", ",", "\n", "\"stratified_data.pickle\"", ")", "\n", "if", "self", ".", "_data", ".", "keys", "(", ")", ":", "\n", "            ", "with", "open", "(", "stratified_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "_data", ",", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.StratifyFacade.load_stratified_data": [[82, 91], ["os.path.join", "open", "pickle.load"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_stratified_data", "(", ")", ":", "\n", "        ", "stratified_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "PATH_TO_PROCESSED_DATA", ",", "\n", "\"stratified_data.pickle\"", ")", "\n", "\n", "data", "=", "None", "\n", "with", "open", "(", "stratified_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.__init__": [[95, 98], ["facade.InstagramScraperFacade._load_env_variables", "facade.InstagramScraperFacade._get_instagram_credentials"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._load_env_variables", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._get_instagram_credentials"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_load_env_variables", "(", ")", "\n", "self", ".", "_login", ",", "self", ".", "_password", "=", "self", ".", "_get_instagram_credentials", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.login": [[99, 102], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "login", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_login", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.password": [[103, 106], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "password", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_password", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._load_env_variables": [[107, 112], ["dotenv.find_dotenv", "dotenv.load_dotenv"], "methods", ["None"], ["", "def", "_load_env_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\" Load environment variables in file to module. \"\"\"", "\n", "env_variables_path", "=", "settings", ".", "ENV_VARIABLES", "\n", "dotenv_path", "=", "find_dotenv", "(", "env_variables_path", ")", "\n", "load_dotenv", "(", "dotenv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._get_instagram_credentials": [[113, 118], ["os.environ.get", "os.environ.get"], "methods", ["None"], ["", "def", "_get_instagram_credentials", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return Instagram credentials (username, password). \"\"\"", "\n", "instagram_username", "=", "os", ".", "environ", ".", "get", "(", "\"INSTAGRAM_USERNAME\"", ")", "\n", "instagram_password", "=", "os", ".", "environ", ".", "get", "(", "\"INSTAGRAM_PASSWORD\"", ")", "\n", "return", "instagram_username", ",", "instagram_password", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade.get_non_scraped_users": [[119, 124], ["facade.InstagramScraperFacade._scraped_users_list", "facade.InstagramScraperFacade._get_all_instagram_users"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._scraped_users_list", "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._get_all_instagram_users"], ["", "def", "get_non_scraped_users", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a list of instagram usrenames not scraped yet. \"\"\"", "\n", "scraped_usernames", "=", "self", ".", "_scraped_users_list", "(", ")", "\n", "all_usernames", "=", "self", ".", "_get_all_instagram_users", "(", ")", "\n", "return", "all_usernames", "-", "scraped_usernames", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._scraped_users_list": [[125, 129], ["set", "os.listdir"], "methods", ["None"], ["", "def", "_scraped_users_list", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return a set of scrapped Instagram usernames. \"\"\"", "\n", "data_path", "=", "settings", ".", "PATH_TO_INSTAGRAM_DATA", "\n", "return", "set", "(", "os", ".", "listdir", "(", "data_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.InstagramScraperFacade._get_all_instagram_users": [[130, 143], ["facade.PreProcessFacade", "facade.PreProcessFacade.process_pipeline", "set", "print"], "methods", ["home.repos.pwc.inspect_result.paulomann_ReadAndSee.data.facade.PreProcessFacade.process_pipeline"], ["", "def", "_get_all_instagram_users", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a set of all valid instagram usernames.\n\n        Side effect:\n        1. Update the interim/ folder with new preprocessed data\n        \"\"\"", "\n", "pprocess_facade", "=", "PreProcessFacade", "(", "\"raw\"", ")", "\n", "data", "=", "pprocess_facade", ".", "process_pipeline", "(", ")", "\n", "instagram_df", "=", "data", "[", "\"instagram_df\"", "]", "\n", "if", "instagram_df", ".", "empty", ":", "\n", "            ", "print", "(", "\"Result from raw preprocessing is empty.\"", ")", "\n", "raise", "Exception", "\n", "", "return", "set", "(", "instagram_df", "[", "\"instagram_user_name\"", "]", ")", "\n", "", "", ""]]}