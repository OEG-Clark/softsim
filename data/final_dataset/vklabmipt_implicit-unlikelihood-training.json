{"home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.unlikelihood.ul_loss": [[17, 36], ["completions[].contiguous", "utils.ngram_repeat_mask().type_as", "torch.log_softmax", "F.log_softmax.view().gather", "torch.clamp().view", "torch.clamp().view", "loss.sum.sum", "completions[].contiguous.numel", "completions[].contiguous.view", "completions[].contiguous.size", "completions[].contiguous.size", "utils.ngram_repeat_mask", "F.log_softmax.view", "torch.clamp", "torch.clamp", "torch.log", "torch.log", "F.log_softmax.size", "lprobs.view().gather.exp"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_repeat_mask"], ["def", "ul_loss", "(", "completions", ",", "continuation_logits", ",", "prefix_length", ",", "sequence_ngram_n", ")", ":", "\n", "    ", "pred_toks", "=", "completions", "[", ":", ",", "prefix_length", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "mask", "=", "ngram_repeat_mask", "(", "\n", "pred_toks", ",", "\n", "sequence_ngram_n", ")", ".", "type_as", "(", "continuation_logits", ")", "\n", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "continuation_logits", ",", "dim", "=", "-", "1", ")", "\n", "pred_lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "2", ")", "\n", ")", ".", "gather", "(", "1", ",", "pred_toks", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "one_minus_probs", "=", "torch", ".", "clamp", "(", "\n", "(", "1.0", "-", "pred_lprobs", ".", "exp", "(", ")", ")", ",", "min", "=", "1e-20", ")", ".", "view", "(", "pred_toks", ".", "size", "(", "0", ")", ",", "pred_toks", ".", "size", "(", "1", ")", ")", "\n", "loss", "=", "-", "torch", ".", "log", "(", "one_minus_probs", ")", "*", "mask", "\n", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "ntokens", "=", "pred_toks", ".", "numel", "(", ")", "# number of output tokens (tokens in completions)", "\n", "\n", "loss", "=", "loss", "/", "ntokens", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.unlikelihood.ul_seq": [[38, 86], ["batch[].to", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length", "utils.sample_sequence", "completions[].contiguous", "utils.ngram_repeat_mask().type_as", "torch.log_softmax", "F.log_softmax.view().gather", "torch.clamp().view", "torch.clamp().view", "loss.sum.sum", "completions[].contiguous.numel", "collections.defaultdict", "completions[].contiguous.cpu().tolist", "collections.defaultdict.items", "completions[].contiguous.view", "completions[].contiguous.size", "completions[].contiguous.size", "loss.sum.item", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length.size", "ngram_repeat_mask().type_as.sum().item", "fairseq.custom.metrics.ngram_metrics", "fairseq.custom.metrics.ngram_metrics.items", "utils.ngram_repeat_mask", "F.log_softmax.view", "torch.clamp", "torch.clamp", "torch.log", "torch.log", "completions[].contiguous.cpu", "F.log_softmax.size", "ngram_repeat_mask().type_as.sum", "lprobs.view().gather.exp"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.sample_sequence", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_metrics", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_repeat_mask"], ["", "def", "ul_seq", "(", "model", ",", "batch", ",", "args", ")", ":", "\n", "    ", "input_sequence", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "batch", "=", "batch_input_sequence_by_prefix_length", "(", "\n", "input_sequence", ",", "args", ".", "prefix_length", ")", "\n", "batch", "=", "batch", "[", ":", "args", ".", "mini_batch_size", "]", "\n", "completions", ",", "_", ",", "continuation_logits", ",", "_", "=", "sample_sequence", "(", "model", ",", "\n", "batch", ",", "\n", "args", ".", "prefix_length", ",", "\n", "args", ".", "continuation_length", ",", "\n", "num_samples", "=", "1", ",", "\n", "top_k", "=", "args", ".", "top_k", ",", "\n", "top_p", "=", "args", ".", "top_p", ")", "\n", "pred_toks", "=", "completions", "[", ":", ",", "args", ".", "prefix_length", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "mask", "=", "ngram_repeat_mask", "(", "\n", "pred_toks", ",", "\n", "args", ".", "sequence_ngram_n", ")", ".", "type_as", "(", "continuation_logits", ")", "\n", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "continuation_logits", ",", "dim", "=", "-", "1", ")", "\n", "pred_lprobs", "=", "lprobs", ".", "view", "(", "-", "1", ",", "lprobs", ".", "size", "(", "2", ")", "\n", ")", ".", "gather", "(", "1", ",", "pred_toks", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "one_minus_probs", "=", "torch", ".", "clamp", "(", "\n", "(", "1.0", "-", "pred_lprobs", ".", "exp", "(", ")", ")", ",", "min", "=", "1e-20", ")", ".", "view", "(", "pred_toks", ".", "size", "(", "0", ")", ",", "pred_toks", ".", "size", "(", "1", ")", ")", "\n", "loss", "=", "-", "torch", ".", "log", "(", "one_minus_probs", ")", "*", "mask", "\n", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "ntokens", "=", "pred_toks", ".", "numel", "(", ")", "# number of output tokens (tokens in completions)", "\n", "\n", "logging_output", "=", "{", "\n", "'seq_loss'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'seq_sample_size'", ":", "ntokens", ",", "\n", "'seq_ntokens'", ":", "ntokens", ",", "\n", "'seq_nsentences'", ":", "batch", ".", "size", "(", "0", ")", ",", "\n", "'seq_repeat_mask'", ":", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "# Sum each statistic, which will be normalized by the number of sentences", "\n", "# in `aggregate_logging_outputs`.", "\n", "stats", "=", "defaultdict", "(", "float", ")", "\n", "for", "tok_list", "in", "pred_toks", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ":", "\n", "        ", "ms", "=", "ngram_metrics", "(", "tok_list", ")", "\n", "for", "k", ",", "v", "in", "ms", ".", "items", "(", ")", ":", "\n", "            ", "stats", "[", "k", "]", "+=", "v", "\n", "", "", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", ":", "\n", "        ", "logging_output", "[", "k", "]", "=", "v", "\n", "\n", "", "loss", "=", "loss", "/", "ntokens", "\n", "return", "loss", ",", "logging_output", "\n", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.tldr.tldr_loss": [[29, 58], ["batch[].to", "model", "torch.log_softmax", "torch.nll_loss", "numpy.arange", "print", "inp.numel", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "F.nll_loss.item", "loss.item", "F.log_softmax.size", "torch.sum", "torch.sum", "torch.nll_loss", "logits[].float", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "lprobs_y.exp", "lprobs_y.exp"], "function", ["None"], ["def", "tldr_loss", "(", "model", ",", "batch", ",", "args", ")", ":", "\n", "    ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "train_batch_size", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "args", ".", "train_batch_size", "+", "1", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "assert", "lprobs", ".", "size", "(", "0", ")", "==", "1", ",", "'We work on flat sequences'", "\n", "nll_loss", "=", "F", ".", "nll_loss", "(", "lprobs", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'sum'", ")", "\n", "arange", "=", "np", ".", "arange", "(", "args", ".", "train_batch_size", ")", "\n", "lprobs_y", "=", "lprobs", "[", ":", ",", "arange", ",", "target", "]", "\n", "print", "(", "torch", ".", "sum", "(", "torch", ".", "cos", "(", "np", ".", "pi", "*", "lprobs_y", ".", "exp", "(", ")", ")", "+", "1", "<", "0.5", ")", ")", "\n", "loss", "=", "(", "(", "torch", ".", "cos", "(", "np", ".", "pi", "*", "lprobs_y", ".", "exp", "(", ")", ")", "+", "1", ")", "\n", "**", "args", ".", "focal_gamma", "*", "(", "-", "lprobs_y", ")", ")", ".", "sum", "(", ")", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "nll_loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'tldr_loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "\n", "loss", "=", "loss", "/", "ntokens", "\n", "\n", "return", "loss", ",", "logging_output", "\n", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.__init__": [[14, 31], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "range", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "gpt2_model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "gpt2_model", "=", "gpt2_model", "\n", "\n", "self", ".", "value_head1", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "3", "*", "config", ".", "n_embd", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "3", "*", "config", ".", "n_embd", ",", "config", ".", "n_embd", "//", "4", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "n_embd", "//", "4", ",", "1", ")", "\n", ")", "for", "_", "in", "range", "(", "self", ".", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "value_head2", "=", "nn", ".", "Linear", "(", "self", ".", "config", ".", "n_layer", ",", "1", ")", "\n", "\n", "self", ".", "hidden_states_weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "ones", "(", "(", "self", ".", "config", ".", "n_layer", ")", ")", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value": [[32, 41], ["policy_value.PolicyValueModel.value_head2().squeeze", "policy_value.PolicyValueModel.value_head2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "hidden_states", ".", "data", "\n", "hidden_states", ".", "requires_grad", "=", "False", "\n", "value", "=", "self", ".", "value_head2", "(", "\n", "torch", ".", "cat", "(", "[", "\n", "self", ".", "value_head1", "[", "i", "]", "(", "hidden_states", "[", "...", ",", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "config", ".", "n_layer", ")", "\n", "]", ",", "-", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.forward": [[42, 54], ["policy_value.PolicyValueModel.gpt2_model", "policy_value.PolicyValueModel.value", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value"], ["", "def", "forward", "(", "self", ",", "input_ids", ":", "torch", ".", "LongTensor", ",", "\n", "past", ":", "torch", ".", "FloatTensor", "=", "None", ",", "\n", "return_value", ":", "bool", "=", "False", ")", ":", "\n", "        ", "output", "=", "self", ".", "gpt2_model", "(", "input_ids", "=", "input_ids", ",", "past", "=", "past", ")", "\n", "lm_logits", ",", "presents", ",", "hidden_states", "=", "output", "[", ":", "3", "]", "\n", "\n", "pi", "=", "None", "\n", "if", "return_value", ":", "\n", "            ", "value", "=", "self", ".", "value", "(", "torch", ".", "stack", "(", "hidden_states", "[", "1", ":", "]", ",", "-", "1", ")", ")", "\n", "return", "(", "lm_logits", ",", "presents", ",", "hidden_states", ",", "value", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "lm_logits", ",", "presents", ",", "hidden_states", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_evaluation.main": [[20, 148], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.cuda.device_count", "logger.info", "os.path.join", "pathlib.Path().exists", "ValueError", "pathlib.Path().exists", "ValueError", "parser.parse_args.path_to_script.endswith", "ValueError", "subprocess.call", "subprocess.call", "pathlib.Path().is_dir", "ValueError", "subprocess.call", "pathlib.Path", "pathlib.Path", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "subprocess.call", "subprocess.call", "subprocess.call", "subprocess.call", "pathlib.Path", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.parse_args"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--path_to_script'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'run_gpt2.py'", ",", "\n", "help", "=", "'script to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_folder'", ",", "\n", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'cuda:0'", ")", "\n", "parser", ".", "add_argument", "(", "'--algorithm'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'ul'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'completion'", ",", "\n", "'singletoken'", ",", "\n", "'singletoken_sampling'", ",", "\n", "'all'", "]", ",", "default", "=", "'all'", ")", "\n", "parser", ".", "add_argument", "(", "'--adress'", ",", "type", "=", "str", ",", "default", "=", "'tcp://127.0.0.1:4444'", ")", "\n", "parser", ".", "add_argument", "(", "'--model-name'", ",", "type", "=", "str", ",", "default", "=", "'gpt2'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--alpha_entmax'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "1.2", ")", "\n", "parser", ".", "add_argument", "(", "'--laplas_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_split'", ",", "type", "=", "str", ",", "default", "=", "'valid'", ",", "choices", "=", "[", "'valid'", ",", "'test'", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "device", "=", "args", ".", "device", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "\"device: {}, n_gpu {}\"", ".", "format", "(", "device", ",", "n_gpu", ")", ")", "\n", "\n", "full_path_to_checkpoint", "=", "os", ".", "path", ".", "join", "(", "\n", "CHECKPONT_PATH", ",", "args", ".", "checkpoint_folder", ")", "\n", "if", "not", "Path", "(", "full_path_to_checkpoint", ")", ".", "exists", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'path {full_path_to_checkpoint} doesn\\'t exists'", ")", "\n", "", "elif", "not", "Path", "(", "full_path_to_checkpoint", ")", ".", "is_dir", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'{full_path_to_checkpoint} is not a directory'", ")", "\n", "\n", "", "if", "not", "Path", "(", "args", ".", "path_to_script", ")", ".", "exists", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'file {args.path_to_script} doesn\\'t exists'", ")", "\n", "", "if", "not", "args", ".", "path_to_script", ".", "endswith", "(", "'.py'", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f'file {args.path_to_script} should be a python script'", ")", "\n", "\n", "", "if", "args", ".", "alpha_entmax", "is", "True", ":", "\n", "        ", "subprocess", ".", "call", "(", "[", "'./evaluate_singletoken_alpha_entmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "args", ".", "algorithm", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "args", ".", "alpha", ")", ",", "\n", "str", "(", "args", ".", "laplas_eps", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n", "subprocess", ".", "call", "(", "[", "'./evaluate_completion_alpha_entmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "args", ".", "algorithm", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "args", ".", "alpha", ")", ",", "\n", "str", "(", "args", ".", "laplas_eps", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "eval_mode", "==", "'singletoken_argmax'", "or", "args", ".", "eval_mode", "==", "'all'", ":", "\n", "            ", "subprocess", ".", "call", "(", "[", "'./evaluate_singletoken_argmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "str", "(", "args", ".", "algorithm", ")", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n", "", "if", "args", ".", "eval_mode", "==", "'singletoken'", "or", "args", ".", "eval_mode", "==", "'all'", ":", "\n", "            ", "for", "(", "p", ",", "laplas_eps", ")", "in", "SINGLETOKEN_TOPP", ":", "\n", "                ", "subprocess", ".", "call", "(", "[", "'./evaluate_singletoken_softmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "str", "(", "args", ".", "algorithm", ")", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "'0'", ",", "\n", "str", "(", "p", ")", ",", "\n", "str", "(", "laplas_eps", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n", "", "for", "(", "k", ",", "laplas_eps", ")", "in", "SINGLETOKEN_TOPK", ":", "\n", "                ", "subprocess", ".", "call", "(", "[", "'./evaluate_singletoken_softmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "str", "(", "args", ".", "algorithm", ")", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "k", ")", ",", "\n", "'0.0'", ",", "\n", "str", "(", "laplas_eps", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n", "", "", "if", "args", ".", "eval_mode", "==", "'completion'", "or", "args", ".", "eval_mode", "==", "'all'", ":", "\n", "            ", "for", "k", "in", "TOPK_PARAMETERS", ":", "\n", "                ", "subprocess", ".", "call", "(", "[", "'./evaluate_completion_softmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "str", "(", "k", ")", ",", "\n", "'0.'", ",", "\n", "args", ".", "algorithm", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "", "for", "p", "in", "TOPP_PARAMETERS", ":", "\n", "                ", "subprocess", ".", "call", "(", "[", "'./evaluate_completion_softmax.sh'", ",", "\n", "args", ".", "path_to_script", ",", "\n", "str", "(", "full_path_to_checkpoint", ")", ",", "\n", "str", "(", "device", ")", ",", "\n", "'0'", ",", "\n", "str", "(", "p", ")", ",", "\n", "args", ".", "algorithm", ",", "\n", "str", "(", "args", ".", "adress", ")", ",", "\n", "str", "(", "args", ".", "model_name", ")", ",", "\n", "str", "(", "args", ".", "eval_split", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer.__init__": [[29, 53], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "ValueModel().to", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "ValueModel"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "config", ",", "tokenizer", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "device", "=", "kwargs", ".", "get", "(", "'device'", ",", "'cpu'", ")", "\n", "self", ".", "mini_batch_size", "=", "kwargs", ".", "get", "(", "'mini_batch_size'", ",", "4", ")", "\n", "self", ".", "prefix_length", "=", "kwargs", ".", "get", "(", "'prefix_length'", ",", "50", ")", "\n", "self", ".", "continuation_length", "=", "kwargs", ".", "get", "(", "'continuation_length'", ",", "100", ")", "\n", "self", ".", "top_k", "=", "kwargs", ".", "get", "(", "'top_k'", ",", "1", ")", "\n", "self", ".", "top_p", "=", "kwargs", ".", "get", "(", "'top_p'", ",", "0.", ")", "\n", "self", ".", "temperature", "=", "kwargs", ".", "get", "(", "'temperature'", ",", "1.", ")", "\n", "self", ".", "n_samples", "=", "kwargs", ".", "get", "(", "'n_samples'", ",", "1", ")", "\n", "self", ".", "ngram_reward", "=", "kwargs", ".", "get", "(", "'ngram_reward'", ",", "4", ")", "\n", "self", ".", "max_grad_norm", "=", "kwargs", ".", "get", "(", "'max_grad_norm'", ",", "10", ")", "\n", "self", ".", "psy_type", "=", "kwargs", ".", "get", "(", "'psy_type'", ",", "'reward'", ")", "\n", "self", ".", "repetition_penalty", "=", "kwargs", ".", "get", "(", "'repetition_penalty'", ",", "1.0", ")", "\n", "\n", "if", "self", ".", "psy_type", "not", "in", "[", "'reward'", ",", "'advantage'", "]", ":", "\n", "            ", "raise", "ValueError", "\n", "", "elif", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "            ", "self", ".", "value_model", "=", "ValueModel", "(", "\n", "config", ".", "n_embd", ",", "config", ".", "n_layer", ")", ".", "to", "(", "\n", "self", ".", "device", ")", "\n", "self", ".", "value_loss_f", "=", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "'sum'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer.sample": [[54, 121], ["batch_[].to", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length.size", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "completions.tolist", "once_reward_pg.OnceRewardTrainer._calc_rewards", "print", "once_reward_pg.OnceRewardTrainer._calc_psy", "completions[].contiguous", "completions[].contiguous.numel", "collections.defaultdict", "completions[].contiguous.cpu().tolist", "collections.defaultdict.items", "utils.sample_sequence", "bpe_continuations.append", "text_continuations.append", "utils.ngram_metrics", "utils.ngram_metrics.items", "utils.get_text_continuation", "completions[].contiguous.cpu", "len"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_rewards", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer._calc_psy", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.sample_sequence", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_metrics", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_text_continuation"], ["", "", "def", "sample", "(", "self", ",", "batch_", ",", "args", ")", ":", "\n", "        ", "prefix_hidden", "=", "None", "\n", "input_sequence", "=", "batch_", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "batch", "=", "batch_input_sequence_by_prefix_length", "(", "\n", "input_sequence", ",", "args", ".", "prefix_length", ")", "\n", "batch", "=", "batch", "[", ":", "self", ".", "mini_batch_size", "]", "\n", "batch_size", "=", "batch", ".", "size", "(", "0", ")", "\n", "\n", "output_prefix_hidden", "=", "True", "if", "self", ".", "psy_type", "==", "'advantage'", "else", "False", "\n", "completions", "=", "sample_sequence", "(", "\n", "self", ".", "model", ",", "\n", "batch", ",", "\n", "args", ".", "prefix_length", ",", "\n", "args", ".", "continuation_length", ",", "\n", "num_samples", "=", "self", ".", "n_samples", ",", "\n", "top_k", "=", "self", ".", "top_k", ",", "\n", "top_p", "=", "self", ".", "top_p", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "output_prefix_hidden", "=", "output_prefix_hidden", ",", "\n", "repetition_penalty", "=", "args", ".", "repetition_penalty", ")", "[", "0", "]", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "ntokens", "=", "0", "\n", "pred_toks", "=", "[", "]", "\n", "bpe_completions", "=", "completions", ".", "tolist", "(", ")", "\n", "bpe_continuations", "=", "[", "]", "\n", "text_continuations", "=", "[", "]", "\n", "for", "bpe_completion", "in", "bpe_completions", ":", "\n", "            ", "bpe_continuations", ".", "append", "(", "bpe_completion", "[", "self", ".", "prefix_length", ":", "]", ")", "\n", "text_continuations", ".", "append", "(", "\n", "get_text_continuation", "(", "\n", "bpe_completion", ",", "self", ".", "tokenizer", ",", "args", ")", ")", "\n", "\n", "", "rep_rewards", "=", "self", ".", "_calc_rewards", "(", "bpe_continuations", ")", "\n", "print", "(", "'Repetition reward: '", ",", "rep_rewards", ")", "\n", "\n", "rewards", "=", "rep_rewards", "\n", "psy", ",", "value", "=", "self", ".", "_calc_psy", "(", "rewards", ",", "prefix_hidden", ",", "args", ")", "\n", "\n", "text_continuations", "=", "[", "c", "for", "c", "in", "text_continuations", "if", "len", "(", "c", ")", ">", "3", "]", "\n", "\n", "pred_toks", "=", "completions", "[", ":", ",", "self", ".", "prefix_length", ":", "]", ".", "contiguous", "(", ")", "\n", "ntokens", "+=", "pred_toks", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "{", "\n", "'seq_sample_size'", ":", "ntokens", ",", "\n", "'seq_ntokens'", ":", "ntokens", ",", "\n", "'seq_nsentences'", ":", "self", ".", "n_samples", "*", "batch_size", "\n", "}", "\n", "\n", "stats", "=", "defaultdict", "(", "float", ")", "\n", "for", "tok_list", "in", "pred_toks", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ":", "\n", "            ", "ms", "=", "ngram_metrics", "(", "tok_list", ",", "pad", "=", "-", "1", ")", "\n", "for", "k", ",", "v", "in", "ms", ".", "items", "(", ")", ":", "\n", "                ", "stats", "[", "k", "]", "+=", "v", "\n", "", "", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", ":", "\n", "            ", "logging_output", "[", "k", "]", "=", "v", "\n", "\n", "", "samples", "=", "{", "\n", "'batch'", ":", "batch_", ",", "\n", "'completions'", ":", "completions", ",", "\n", "'rewards'", ":", "rewards", ",", "\n", "'psy'", ":", "psy", ",", "\n", "'value'", ":", "value", "\n", "}", "\n", "\n", "return", "samples", ",", "logging_output", ",", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer._calc_rewards": [[122, 130], ["np.array", "np.mean", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "utils.ngram_metrics"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_metrics"], ["", "def", "_calc_rewards", "(", "self", ",", "bpe_continuations", ")", ":", "\n", "        ", "seq_rep_ns", "=", "np", ".", "array", "(", "[", "ngram_metrics", "(", "\n", "x", ",", "pad", "=", "-", "1", ",", "n", "=", "self", ".", "ngram_reward", ")", "[", "'pct_repeat_ngrams'", "]", "for", "x", "in", "bpe_continuations", "]", ")", "\n", "rep", "=", "np", ".", "mean", "(", "[", "1", "-", "y", "for", "y", "in", "seq_rep_ns", "]", ")", "\n", "rewards", "=", "torch", ".", "FloatTensor", "(", "\n", "[", "1", "-", "y", "for", "y", "in", "seq_rep_ns", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer._calc_psy": [[131, 154], ["rewards.clone().detach", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "once_reward_pg.OnceRewardTrainer.value_model", "rewards.clone().detach", "rewards.clone().detach.mean", "std.sum", "rewards.clone", "rewards.clone"], "methods", ["None"], ["", "def", "_calc_psy", "(", "self", ",", "rewards", ",", "prefix_hidden", ",", "args", ")", ":", "\n", "        ", "value", "=", "None", "\n", "if", "self", ".", "psy_type", "==", "'reward'", ":", "\n", "            ", "mean", "=", "rewards", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "std", "=", "rewards", ".", "clone", "(", ")", ".", "detach", "(", ")", "**", "2", "\n", "dist", ".", "all_reduce", "(", "\n", "mean", ",", "\n", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ",", "\n", "group", "=", "dist", ".", "group", ".", "WORLD", ",", "\n", "async_op", "=", "False", ")", "\n", "dist", ".", "all_reduce", "(", "\n", "std", ",", "\n", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ",", "\n", "group", "=", "dist", ".", "group", ".", "WORLD", ",", "\n", "async_op", "=", "False", ")", "\n", "mean", "=", "mean", ".", "mean", "(", ")", "/", "args", ".", "world_size", "\n", "std", "=", "std", ".", "sum", "(", ")", "**", "0.5", "\n", "psy", "=", "rewards", "-", "mean", "\n", "", "else", ":", "\n", "            ", "value", "=", "self", ".", "value_model", "(", "prefix_hidden", ")", "\n", "psy", "=", "rewards", "-", "value", ".", "data", "\n", "\n", "", "return", "psy", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer.ppo_step": [[155, 213], ["samples[].to", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "[].reshape", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "[].reshape.sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "torch.min().sum", "unlikelihood.ul_loss", "ent.item", "loss.item", "rewards.mean().item", "[].reshape", "utils.mle_loss", "loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "once_reward_pg.OnceRewardTrainer.optimizer.step", "once_reward_pg.OnceRewardTrainer.model", "torch.log_softmax.reshape", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "[].reshape.size", "once_reward_pg.OnceRewardTrainer.model.parameters", "print", "rewards.mean", "once_reward_pg.OnceRewardTrainer.model", "torch.log_softmax.size", "[].reshape.sum", "log_pis_old.sum", "torch.log_softmax.reshape", "np.arange", "input_ids[].reshape", "torch.log_softmax.size", "torch.log_softmax.exp", "np.arange", "input_ids[].reshape", "torch.log_softmax.size", "torch.log_softmax.size", "torch.log_softmax.exp", "torch.log_softmax.size", "torch.log_softmax.size"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.unlikelihood.ul_loss", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.mle_loss", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step"], ["", "def", "ppo_step", "(", "self", ",", "samples", ",", "args", ",", "make_step", "=", "True", ")", ":", "\n", "        ", "psy", "=", "samples", "[", "'psy'", "]", "\n", "batch", "=", "samples", "[", "'batch'", "]", "\n", "rewards", "=", "samples", "[", "'rewards'", "]", "\n", "input_ids", "=", "samples", "[", "'completions'", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "ppo_epoch", ">", "1", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "vocab_log_pis_old", "=", "F", ".", "log_softmax", "(", "self", ".", "model", "(", "\n", "input_ids", ")", "[", "0", "]", "[", ":", ",", "self", ".", "prefix_length", "-", "1", ":", "-", "1", ",", ":", "]", ",", "dim", "=", "-", "1", ")", "\n", "log_pis_old", "=", "vocab_log_pis_old", ".", "reshape", "(", "-", "1", ",", "vocab_log_pis_old", ".", "size", "(", "-", "1", ")", ")", "[", "\n", "np", ".", "arange", "(", "vocab_log_pis_old", ".", "size", "(", "0", ")", "*", "vocab_log_pis_old", ".", "size", "(", "1", ")", ")", ",", "input_ids", "[", ":", ",", "self", ".", "prefix_length", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "]", ".", "reshape", "(", "vocab_log_pis_old", ".", "shape", "[", ":", "-", "1", "]", ")", ".", "data", "\n", "\n", "", "", "for", "k", "in", "range", "(", "args", ".", "ppo_epoch", ")", ":", "\n", "            ", "vocab_log_pis", "=", "F", ".", "log_softmax", "(", "self", ".", "model", "(", "\n", "input_ids", ")", "[", "0", "]", "[", ":", ",", "self", ".", "prefix_length", "-", "1", ":", "-", "1", ",", ":", "]", ",", "dim", "=", "-", "1", ")", "\n", "log_pis", "=", "vocab_log_pis", ".", "reshape", "(", "-", "1", ",", "vocab_log_pis", ".", "size", "(", "-", "1", ")", ")", "[", "\n", "np", ".", "arange", "(", "vocab_log_pis", ".", "size", "(", "0", ")", "*", "vocab_log_pis", ".", "size", "(", "1", ")", ")", ",", "input_ids", "[", ":", ",", "self", ".", "prefix_length", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "]", ".", "reshape", "(", "vocab_log_pis", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "\n", "if", "args", ".", "ppo_epoch", "==", "1", ":", "\n", "                ", "ratio", "=", "(", "log_pis", ".", "sum", "(", "-", "1", ")", ")", "\n", "j", "=", "(", "ratio", "*", "psy", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "                ", "ratio", "=", "(", "log_pis", ".", "sum", "(", "-", "1", ")", "-", "log_pis_old", ".", "sum", "(", "-", "1", ")", ")", ".", "exp", "(", ")", "\n", "clipped_ratio", "=", "torch", ".", "clamp", "(", "\n", "ratio", ",", "1", "-", "args", ".", "clip_range", ",", "1", "+", "args", ".", "clip_range", ")", "\n", "j", "=", "torch", ".", "min", "(", "clipped_ratio", "*", "psy", ",", "ratio", "*", "psy", ")", ".", "sum", "(", ")", "\n", "\n", "", "loss", "=", "args", ".", "pg_coef", "*", "(", "-", "j", ")", "/", "(", "log_pis", ".", "size", "(", "1", ")", "\n", "*", "args", ".", "mini_batch_size", "*", "args", ".", "world_size", ")", "\n", "if", "args", ".", "add_mle_loss_to_pg", "is", "True", ":", "\n", "                ", "loss", "+=", "mle_loss", "(", "self", ".", "model", ",", "batch", ",", "args", ")", "[", "0", "]", "\n", "", "if", "args", ".", "add_kl_loss_to_pg", ":", "\n", "                ", "kl", "=", "(", "vocab_log_pis", ".", "exp", "(", ")", "*", "(", "vocab_log_pis", "-", "vocab_log_pis_old", ")", ")", ".", "sum", "(", "-", "1", ")", ".", "mean", "(", "-", "1", ")", ".", "mean", "(", ")", "\n", "loss", "+=", "kl", "\n", "", "if", "args", ".", "add_ul_loss_to_pg", ":", "\n", "                ", "loss", "+=", "ul_loss", "(", "samples", "[", "'completions'", "]", ",", "\n", "samples", "[", "'continuation_logits'", "]", ",", "\n", "self", ".", "prefix_length", ",", "\n", "4", ")", "\n", "", "loss", "=", "loss", "/", "args", ".", "ppo_epoch", "\n", "\n", "ent", "=", "(", "-", "vocab_log_pis", ".", "exp", "(", ")", "*", "vocab_log_pis", ")", ".", "sum", "(", "-", "1", ")", ".", "mean", "(", ")", "\n", "print", "(", "'Entropy: '", ",", "ent", ".", "item", "(", ")", ")", "\n", "\n", "if", "make_step", "is", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "max_norm", "=", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "except", "BaseException", ":", "\n", "                    ", "print", "(", "'Oopds... backward exception'", ")", "\n", "\n", "", "", "", "return", "torch", ".", "tensor", "(", "[", "loss", ".", "item", "(", ")", ",", "rewards", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "0", ",", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.gelu_new": [[20, 23], ["torch.tanh", "torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "\n", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3.0", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.jensen_shannon_divergence": [[16, 29], ["torch.one_hot().float", "js1.sum.sum", "js2.sum.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.one_hot", "probs.size"], "function", ["None"], ["def", "jensen_shannon_divergence", "(", "probs", ",", "target", ")", ":", "\n", "    ", "target_dist", "=", "F", ".", "one_hot", "(", "target", ",", "num_classes", "=", "probs", ".", "size", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "mixture", "=", "(", "probs", "+", "target_dist", ")", "/", "2", "\n", "js1", "=", "1", "/", "2", "*", "probs", "*", "torch", ".", "log", "(", "probs", "/", "mixture", ")", "\n", "js1", "[", "probs", "==", "0.", "]", "=", "0.", "\n", "js1", "=", "js1", ".", "sum", "(", "-", "1", ")", "\n", "js2", "=", "1", "/", "2", "*", "target_dist", "*", "torch", ".", "log", "(", "target_dist", "/", "mixture", ")", "\n", "js2", "[", "target_dist", "==", "0.", "]", "=", "0.", "\n", "js2", "=", "js2", ".", "sum", "(", "-", "1", ")", "\n", "\n", "js", "=", "(", "js1", "+", "js2", ")", "\n", "\n", "return", "js", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.alpha_entropy": [[31, 37], ["torch.log", "torch.log"], "function", ["None"], ["", "def", "alpha_entropy", "(", "probs", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", "==", "1.", ":", "\n", "        ", "ent", "=", "-", "(", "probs", "*", "torch", ".", "log", "(", "probs", ")", ")", ".", "sum", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "ent", "=", "(", "probs", "-", "probs", "**", "alpha", ")", ".", "sum", "(", "-", "1", ")", "/", "(", "alpha", "*", "(", "alpha", "-", "1", ")", ")", "\n", "", "return", "ent", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.alpha_entmax_loss": [[39, 76], ["batch[].to", "model", "torch.tensor", "torch.tensor", "entmax.entmax_bisect", "alpha_entmax_training.alpha_entropy", "loss.sum.sum", "inp.numel", "numpy.arange", "entmax.entmax_bisect.size", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "loss.sum.item", "smoothed_nll.item", "jensen_shannon_divergence().mean().item", "print", "torch.nll_loss", "entmax.entmax_bisect.size", "torch.mean", "torch.mean", "logits[].float", "torch.device", "torch.device", "torch.log", "torch.log", "jensen_shannon_divergence().mean", "target.squeeze().tolist", "torch.one_hot", "alpha_entmax_training.jensen_shannon_divergence", "target.squeeze", "entmax.entmax_bisect.size"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.alpha_entropy", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.jensen_shannon_divergence"], ["", "def", "alpha_entmax_loss", "(", "model", ",", "batch", ",", "args", ")", ":", "\n", "    ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "train_batch_size", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "args", ".", "train_batch_size", "+", "1", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "alpha", "=", "torch", ".", "tensor", "(", "[", "args", ".", "alpha", "]", ",", "requires_grad", "=", "True", ",", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "gpu", ")", ")", "\n", "probs", "=", "entmax_bisect", "(", "logits", ",", "alpha", ")", "\n", "loss", "=", "(", "(", "probs", "-", "F", ".", "one_hot", "(", "target", ",", "num_classes", "=", "probs", ".", "size", "(", "-", "1", ")", ")", ")", "*", "logits", ")", ".", "sum", "(", "-", "1", ")", "\n", "loss", "+=", "alpha_entropy", "(", "probs", ",", "args", ".", "alpha", ")", "\n", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "arange", "=", "np", ".", "arange", "(", "probs", ".", "size", "(", "1", ")", ")", "\n", "next_token_probs", "=", "probs", "[", ":", ",", "arange", ",", "target", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", "\n", "voc_sizes", "=", "probs", ".", "size", "(", "-", "1", ")", "\n", "smoothed_nll", "=", "-", "torch", ".", "mean", "(", "torch", ".", "log", "(", "\n", "(", "next_token_probs", "+", "args", ".", "laplas_eps", ")", "/", "(", "1", "+", "args", ".", "laplas_eps", "*", "voc_sizes", ")", "\n", ")", ")", "\n", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'smoothed_nll_loss'", "]", "=", "smoothed_nll", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "logging_output", "[", "'js_div'", "]", "=", "jensen_shannon_divergence", "(", "\n", "probs", ",", "target", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "print", "(", "logging_output", "[", "'js_div'", "]", ")", "\n", "\n", "loss", "=", "loss", "/", "ntokens", "\n", "\n", "return", "loss", ",", "logging_output", "\n", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.top_k_top_p_filtering": [[36, 76], ["logits_.clone", "min", "float", "logits_.clone.size", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "torch.softmax", "torch.topk", "torch.topk"], "function", ["None"], ["def", "top_k_top_p_filtering", "(", "logits_", ",", "n", "=", "1", ",", "top_k", "=", "0", ",", "top_p", "=", "0.0", ",", "temperature", "=", "1.0", ",", "\n", "filter_value", "=", "-", "float", "(", "'Inf'", ")", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size x vocabulary size)\n            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "logits", "=", "logits_", ".", "clone", "(", ")", "\n", "top_k", "=", "min", "(", "top_k", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "if", "temperature", "!=", "1.0", ":", "\n", "        ", "logits", "=", "logits", "/", "temperature", "\n", "", "if", "top_k", ">", "0", ":", "\n", "# Remove all tokens with a probability less than the last token of the", "\n", "# top-k", "\n", "        ", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "\n", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", ">", "0.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "\n", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "# Shift the indices to the right to keep also the first token above the", "\n", "# threshold", "\n", "sorted_indices_to_remove", "[", "...", ",", "\n", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", "\n", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "\n", "dim", "=", "1", ",", "index", "=", "sorted_indices", ",", "src", "=", "sorted_indices_to_remove", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_metrics": [[78, 102], ["collections.defaultdict", "range", "collections.Counter", "collections.Counter", "token_list.index", "nltk.ngrams", "print", "nltk.ngrams", "print", "nltk.ngrams", "len", "len", "nltk.ngrams", "len", "len"], "function", ["None"], ["", "def", "ngram_metrics", "(", "token_list", ",", "pad", "=", "1", ",", "n", "=", "None", ")", ":", "\n", "    ", "if", "pad", "in", "token_list", ":", "\n", "# remove possible padding", "\n", "        ", "token_list", "=", "token_list", "[", ":", "token_list", ".", "index", "(", "pad", ")", "]", "\n", "", "stats", "=", "defaultdict", "(", "float", ")", "\n", "if", "n", "is", "None", ":", "\n", "        ", "for", "n", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "            ", "ngs", "=", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", "\n", "counter", "=", "Counter", "(", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", ")", "\n", "try", ":", "\n", "                ", "stats", "[", "f'pct_repeat_{n}grams'", "]", "=", "1.0", "-", "len", "(", "counter", ")", "/", "len", "(", "ngs", ")", "\n", "", "except", "BaseException", ":", "\n", "                ", "stats", "[", "f'pct_repeat_{n}grams'", "]", "=", "1.0", "\n", "print", "(", "'exception'", ")", "\n", "", "", "", "else", ":", "\n", "        ", "ngs", "=", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", "\n", "counter", "=", "Counter", "(", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", ")", "\n", "try", ":", "\n", "            ", "stats", "[", "'pct_repeat_ngrams'", "]", "=", "1.0", "-", "len", "(", "counter", ")", "/", "len", "(", "ngs", ")", "\n", "", "except", "BaseException", ":", "\n", "            ", "stats", "[", "'pct_repeat_ngrams'", "]", "=", "1.0", "\n", "print", "(", "'exception'", ")", "\n", "\n", "", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets": [[104, 117], ["dataset_paths.items", "torch.load", "torch.load", "torch.utils.data.TensorDataset", "tensor[].view", "torch.load.size"], "function", ["None"], ["", "def", "get_datasets", "(", "dataset_paths", ",", "max_len", "=", "1536", ")", ":", "\n", "    ", "\"\"\"Args:\n        dataset_paths: {'train': str, 'valid': str, 'test': str}\n    \"\"\"", "\n", "datasets", "=", "{", "}", "\n", "\n", "for", "split", ",", "fname", "in", "dataset_paths", ".", "items", "(", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "load", "(", "fname", ")", "\n", "right_bound", "=", "(", "tensor", ".", "size", "(", "0", ")", "//", "(", "max_len", "+", "1", ")", ")", "*", "(", "max_len", "+", "1", ")", "\n", "dataset", "=", "TensorDataset", "(", "tensor", "[", ":", "right_bound", "]", ".", "view", "(", "-", "1", ",", "(", "max_len", "+", "1", ")", ")", ")", "\n", "datasets", "[", "split", "]", "=", "dataset", "\n", "\n", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.sample_sequence": [[119, 213], ["torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat.size", "torch.stack.append", "torch.cat", "torch.cat", "numpy.arange", "filtered_logits[].squeeze", "log_prob[].squeeze", "torch.stack.append", "model", "enumerate", "torch.log_softmax", "kwargs.get", "entmax.entmax_bisect", "torch.log", "torch.log", "entmax.entmax_bisect.multinomial", "top_k_top_p_filtering.size", "torch.log.squeeze", "prefix_batch.size", "set", "logits.float().argmax", "utils.top_k_top_p_filtering", "torch.softmax().multinomial", "torch.tensor().float", "torch.tensor().float", "output[].tolist", "logits.float", "torch.softmax", "torch.tensor", "torch.tensor", "F.softmax().multinomial.squeeze().tolist", "F.softmax().multinomial.squeeze().tolist", "F.softmax().multinomial.squeeze", "F.softmax().multinomial.squeeze"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.top_k_top_p_filtering"], ["", "def", "sample_sequence", "(", "model", ",", "\n", "prefix_batch", ",", "\n", "prefix_length", ",", "\n", "continuation_length", ",", "\n", "num_samples", "=", "1", ",", "\n", "top_k", "=", "0", ",", "\n", "top_p", "=", "0.0", ",", "\n", "temperature", "=", "1.0", ",", "\n", "alpha_entmax", "=", "False", ",", "\n", "output_prefix_hidden", "=", "False", ",", "\n", "repetition_penalty", "=", "1.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "continuation_logits", "=", "[", "]", "\n", "context", "=", "prefix_batch", "\n", "context", "=", "torch", ".", "cat", "(", "[", "context", "]", "*", "num_samples", ",", "0", ")", "\n", "assert", "context", ".", "size", "(", "1", ")", "==", "prefix_length", "\n", "\n", "prev", "=", "context", "\n", "output", "=", "context", "\n", "past", "=", "None", "\n", "\n", "log_probs", "=", "torch", ".", "zeros", "(", "\n", "(", "num_samples", "*", "\n", "prefix_batch", ".", "size", "(", "0", ")", ",", "\n", "continuation_length", ")", ")", "\n", "\n", "policy_pis", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "continuation_length", ")", ":", "\n", "        ", "logits", ",", "past", "=", "model", "(", "input_ids", "=", "prev", ",", "past", "=", "past", ")", "[", ":", "2", "]", "\n", "if", "i", "==", "0", "and", "output_prefix_hidden", ":", "\n", "            ", "prefix_hidden", "=", "out", "[", "2", "]", "\n", "\n", "", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "logits", "/", "temperature", "\n", "\n", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "            ", "for", "ex_id", ",", "pert_logits", "in", "enumerate", "(", "logits", ")", ":", "\n", "                ", "for", "token_idx", "in", "set", "(", "output", "[", "ex_id", "]", ".", "tolist", "(", ")", ")", ":", "\n", "                    ", "if", "pert_logits", "[", "token_idx", "]", "<", "0", ":", "\n", "                        ", "pert_logits", "[", "token_idx", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                        ", "pert_logits", "[", "token_idx", "]", "/=", "repetition_penalty", "\n", "", "", "", "", "if", "alpha_entmax", "is", "False", ":", "\n", "            ", "if", "top_k", "==", "1", "and", "top_p", "==", "0", ":", "\n", "                ", "filtered_logits", "=", "logits", "\n", "prev", "=", "logits", ".", "float", "(", ")", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "filtered_logits", "=", "top_k_top_p_filtering", "(", "\n", "logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "prev", "=", "F", ".", "softmax", "(", "\n", "filtered_logits", ",", "\n", "dim", "=", "-", "\n", "1", ")", ".", "multinomial", "(", "\n", "num_samples", "=", "1", ")", "\n", "\n", "#log_prob = F.log_softmax(filtered_logits, dim=-1)", "\n", "", "log_prob", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "kwargs", ".", "get", "(", "'alpha'", ",", "1.0", ")", "\n", "prob", "=", "entmax_bisect", "(", "\n", "logits", ",", "\n", "torch", ".", "tensor", "(", "\n", "[", "alpha", "]", ",", "\n", "requires_grad", "=", "True", ",", "\n", "device", "=", "logits", ".", "device", ")", ".", "float", "(", ")", ")", "\n", "log_prob", "=", "torch", ".", "log", "(", "prob", ")", "\n", "prev", "=", "prob", ".", "multinomial", "(", "num_samples", "=", "1", ")", "\n", "filtered_logits", "=", "logits", "\n", "\n", "", "continuation_logits", ".", "append", "(", "logits", ")", "\n", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "prev", ")", ",", "dim", "=", "1", ")", "\n", "\n", "arange", "=", "np", ".", "arange", "(", "filtered_logits", ".", "size", "(", "0", ")", ")", "\n", "next_token_logit", "=", "filtered_logits", "[", "arange", ",", "\n", "prev", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", ".", "squeeze", "(", ")", "\n", "\n", "next_token_log_prob", "=", "log_prob", "[", "arange", ",", "\n", "prev", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", ".", "squeeze", "(", ")", "\n", "log_probs", "[", ":", ",", "i", "]", "=", "next_token_log_prob", "\n", "policy_pis", ".", "append", "(", "log_prob", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "policy_pis", "=", "torch", ".", "stack", "(", "policy_pis", ",", "1", ")", "\n", "\n", "continuation_logits", "=", "torch", ".", "stack", "(", "continuation_logits", ",", "1", ")", "\n", "if", "output_prefix_hidden", ":", "\n", "        ", "result", "=", "(", "\n", "output", ",", "\n", "log_probs", ",", "\n", "continuation_logits", ",", "\n", "policy_pis", ",", "\n", "prefix_hidden", ")", "\n", "", "else", ":", "\n", "        ", "result", "=", "(", "output", ",", "log_probs", ",", "continuation_logits", ",", "policy_pis", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.mle_loss": [[215, 238], ["batch[].to", "model", "torch.log_softmax", "torch.nll_loss", "inp.numel", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "F.nll_loss.item", "F.log_softmax.size", "torch.nll_loss", "logits[].float"], "function", ["None"], ["", "def", "mle_loss", "(", "model", ",", "batch", ",", "args", ")", ":", "\n", "    ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "train_batch_size", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "args", ".", "train_batch_size", "+", "1", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "assert", "lprobs", ".", "size", "(", "0", ")", "==", "1", ",", "'We work on flat sequences'", "\n", "loss", "=", "F", ".", "nll_loss", "(", "lprobs", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'sum'", ")", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "\n", "loss", "=", "loss", "/", "ntokens", "\n", "\n", "return", "loss", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_count": [[240, 250], ["range", "collections.Counter", "counters.append", "token_list.index", "nltk.ngrams", "nltk.ngrams"], "function", ["None"], ["", "def", "ngram_count", "(", "token_list", ",", "pad", "=", "1", ")", ":", "\n", "    ", "if", "pad", "in", "token_list", ":", "\n", "# remove possible padding", "\n", "        ", "token_list", "=", "token_list", "[", ":", "token_list", ".", "index", "(", "pad", ")", "]", "\n", "", "counters", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "        ", "ngs", "=", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", "\n", "counter", "=", "Counter", "(", "[", "ng", "for", "ng", "in", "ngrams", "(", "token_list", ",", "n", ")", "]", ")", "\n", "counters", ".", "append", "(", "counter", ")", "\n", "", "return", "counters", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_repeat_mask": [[252, 263], ["torch.zeros_like", "torch.zeros_like", "enumerate", "set", "x.tolist", "range", "tuple", "set.add", "len"], "function", ["None"], ["", "def", "ngram_repeat_mask", "(", "xs", ",", "n", ")", ":", "\n", "    ", "mask", "=", "torch", ".", "zeros_like", "(", "xs", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "seen", "=", "set", "(", ")", "\n", "xl", "=", "x", ".", "tolist", "(", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "x", ")", "-", "n", ")", ":", "\n", "            ", "ng", "=", "tuple", "(", "xl", "[", "j", ":", "j", "+", "n", "]", ")", "\n", "if", "ng", "in", "seen", ":", "\n", "                ", "mask", "[", "i", ",", "j", ":", "j", "+", "n", "]", "=", "1", "\n", "", "seen", ".", "add", "(", "ng", ")", "\n", "", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.tokenize": [[265, 269], ["RETOK.findall"], "function", ["None"], ["", "def", "tokenize", "(", "text", ")", ":", "\n", "# ref:", "\n", "# https://github.com/facebookresearch/ParlAI/blob/4da3ec0bdcf1db2c3a5bd5723d1275c32a891192/parlai/core/dict.py#L451", "\n", "    ", "return", "RETOK", ".", "findall", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_text_continuation": [[271, 285], ["tokenizer.decode", "tokenizer.decode", "utils.tokenize", "tokenizer.decode.replace", "tokenizer.decode.replace", "tokenizer.decode.split"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.tokenize"], ["", "def", "get_text_continuation", "(", "bpe_completion", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "completion", "=", "tokenizer", ".", "decode", "(", "bpe_completion", ")", "\n", "bpe_prefix", ",", "bpe_continuation", "=", "bpe_completion", "[", ":", "\n", "args", ".", "prefix_length", "]", ",", "bpe_completion", "[", "args", ".", "prefix_length", ":", "]", "\n", "prefix", "=", "tokenizer", ".", "decode", "(", "bpe_prefix", ")", "\n", "\n", "if", "prefix", "in", "completion", ":", "\n", "        ", "continuation", "=", "completion", ".", "replace", "(", "prefix", ",", "''", ")", "\n", "", "else", ":", "\n", "        ", "prefix_", "=", "' '", ".", "join", "(", "prefix", ".", "split", "(", "' '", ")", "[", ":", "-", "2", "]", ")", "\n", "continuation", "=", "completion", ".", "replace", "(", "prefix_", ",", "''", ")", "\n", "\n", "", "continuation_tokens", "=", "tokenize", "(", "continuation", ")", "\n", "return", "continuation_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_completion_metrics": [[287, 320], ["os.path.join", "json.dump", "print", "open"], "function", ["None"], ["", "def", "save_completion_metrics", "(", "\n", "bpe_metrics", ",", "word_metrics", ",", "text_completions", ",", "config", ",", "args", ",", "add", "=", "None", ")", ":", "\n", "    ", "add", "=", "''", "if", "add", "is", "None", "else", "add", "\n", "if", "add", "!=", "''", ":", "\n", "        ", "add", "=", "f'_{add}'", "if", "add", "[", "0", "]", "!=", "'_'", "else", "add", "\n", "\n", "", "if", "args", ".", "num_beams", "==", "1", ":", "\n", "        ", "file_name", "=", "'completion__{model}__spl_{split}__topk_{topk}__topp_{topp}__pfl_{pfl}__cnl_{cnl}'", ".", "format", "(", "\n", "model", "=", "args", ".", "model_name", ",", "\n", "split", "=", "args", ".", "eval_split", ",", "\n", "topk", "=", "args", ".", "top_k", ",", "\n", "topp", "=", "args", ".", "top_p", ",", "\n", "pfl", "=", "args", ".", "prefix_length", ",", "\n", "cnl", "=", "args", ".", "continuation_length", "\n", ")", "\n", "", "else", ":", "\n", "        ", "file_name", "=", "'completion__{model}__spl_{split}__beam_{beam}__pfl_{pfl}__cnl_{cnl}'", ".", "format", "(", "\n", "model", "=", "args", ".", "model_name", ",", "\n", "split", "=", "args", ".", "eval_split", ",", "\n", "beam", "=", "args", ".", "num_beams", ",", "\n", "pfl", "=", "args", ".", "prefix_length", ",", "\n", "cnl", "=", "args", ".", "continuation_length", "\n", ")", "\n", "", "outfile", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "file_name", ")", "\n", "\n", "json", ".", "dump", "(", "{", "'bpe_metrics'", ":", "bpe_metrics", ",", "\n", "'word_metrics'", ":", "word_metrics", ",", "\n", "'config'", ":", "config", ",", "\n", "'completions'", ":", "text_completions", "}", ",", "\n", "open", "(", "outfile", "+", "add", "+", "'.json'", ",", "\n", "'w'", ")", ")", "\n", "print", "(", "\"%s metrics written to %s\"", "%", "(", "args", ".", "mode", ",", "outfile", "+", "add", "+", "'.json'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_singletoken_metrics": [[322, 339], ["os.path.join", "json.dump", "print", "os.path.join", "open"], "function", ["None"], ["", "def", "save_singletoken_metrics", "(", "\n", "metrics", ",", "config", ",", "args", ",", "best", "=", "False", ",", "train_iter", "=", "None", ")", ":", "\n", "    ", "output_dir", "=", "args", ".", "output_dir", "if", "not", "best", "else", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'best'", ")", "\n", "outfile", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "'singletoken__{model}__spl_{split}__bsz_{bsz}{iter}.json'", ".", "format", "(", "\n", "model", "=", "args", ".", "model_name", ",", "\n", "split", "=", "args", ".", "eval_split", ",", "\n", "bsz", "=", "args", ".", "batch_size_singletoken", ",", "\n", "iter", "=", "'_%d'", "%", "\n", "train_iter", "if", "train_iter", "is", "not", "None", "else", "''", ",", "\n", ")", ")", "\n", "\n", "json", ".", "dump", "(", "{", "'metrics'", ":", "metrics", ",", "\n", "'config'", ":", "config", "}", ",", "open", "(", "outfile", ",", "'w'", ")", ")", "\n", "print", "(", "\"%s metrics written to %s\"", "%", "(", "args", ".", "mode", ",", "outfile", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_singletoken_sampling_metrics": [[341, 366], ["os.path.join", "json.dump", "print", "os.path.join", "open"], "function", ["None"], ["", "def", "save_singletoken_sampling_metrics", "(", "\n", "metrics", ",", "\n", "config", ",", "\n", "args", ",", "\n", "top_k", "=", "1", ",", "\n", "top_p", "=", "0.0", ",", "\n", "best", "=", "False", ",", "\n", "train_iter", "=", "None", ")", ":", "\n", "    ", "output_dir", "=", "args", ".", "output_dir", "if", "not", "best", "else", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'best'", ")", "\n", "outfile", "=", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "\n", "'singletoken_{model}__topk_{topk}_topp_{topp}_spl_{split}__bsz_{bsz}{iter}.json'", ".", "format", "(", "\n", "model", "=", "args", ".", "model_name", ",", "\n", "topk", "=", "top_k", ",", "\n", "topp", "=", "top_p", ",", "\n", "split", "=", "args", ".", "eval_split", ",", "\n", "bsz", "=", "args", ".", "batch_size_singletoken", ",", "\n", "iter", "=", "'_%d'", "%", "\n", "train_iter", "if", "train_iter", "is", "not", "None", "else", "''", ",", "\n", ")", ")", "\n", "\n", "json", ".", "dump", "(", "{", "'metrics'", ":", "metrics", ",", "\n", "'config'", ":", "config", "}", ",", "open", "(", "outfile", ",", "'w'", ")", ")", "\n", "print", "(", "\"%s metrics written to %s\"", "%", "(", "args", ".", "mode", ",", "outfile", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_acc_metrics": [[368, 380], ["os.path.join", "json.dump", "print", "os.path.join", "open"], "function", ["None"], ["", "def", "save_acc_metrics", "(", "\n", "metrics", ",", "config", ",", "args", ",", "best", "=", "False", ")", ":", "\n", "    ", "output_dir", "=", "args", ".", "output_dir", "if", "not", "best", "else", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'best'", ")", "\n", "outfile", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\n", "'acc_spl_{split}.json'", ".", "format", "(", "\n", "split", "=", "args", ".", "eval_split", "\n", ")", ")", "\n", "\n", "json", ".", "dump", "(", "{", "'metrics'", ":", "metrics", ",", "\n", "'config'", ":", "config", "}", ",", "open", "(", "outfile", ",", "'w'", ")", ")", "\n", "print", "(", "\"%s metrics written to %s\"", "%", "(", "args", ".", "mode", ",", "outfile", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken_argmax": [[382, 436], ["utils.get_datasets", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "fairseq.custom.baseline_cross_entropy.CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs", "len", "len", "utils.save_singletoken_metrics", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "set", "set", "config.to_dict", "enumerate", "batch[].to", "model", "torch.log_softmax", "torch.nll_loss", "F.log_softmax.argmax().view().tolist", "predicted_tokens.extend", "inp.numel", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "F.nll_loss.item", "logging_outputs.append", "target_tokens.extend", "len", "F.log_softmax.size", "torch.nll_loss", "logits[].float", "target.view().tolist", "F.log_softmax.argmax().view", "target.view", "F.log_softmax.argmax"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_singletoken_metrics"], ["", "def", "eval_singletoken_argmax", "(", "model", ",", "args", ",", "dataset_paths", ",", "config", ",", "\n", "train_iter", "=", "None", ",", "batch_size", "=", "None", ")", ":", "\n", "    ", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "args", ".", "batch_size_singletoken", "\n", "datasets", "=", "get_datasets", "(", "dataset_paths", ",", "max_len", "=", "batch_size", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "datasets", "[", "args", ".", "eval_split", "]", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "datasets", "[", "args", ".", "eval_split", "]", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "1", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "logging_outputs", "=", "[", "]", "\n", "predicted_tokens", "=", "[", "]", "\n", "target_tokens", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "eval_dataloader", ")", ",", "\n", "desc", "=", "\"Evaluating\"", ",", "total", "=", "len", "(", "eval_dataloader", ")", ")", ":", "\n", "            ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "batch_size_singletoken", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "assert", "lprobs", ".", "size", "(", "0", ")", "==", "1", ",", "'We work on flat sequences'", "\n", "loss", "=", "F", ".", "nll_loss", "(", "lprobs", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'sum'", ")", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "\n", "pred", "=", "lprobs", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "predicted_tokens", ".", "extend", "(", "pred", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "\n", "# for human uniq", "\n", "target_tokens", ".", "extend", "(", "target", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "logging_average", "=", "CrossEntropyCriterionWCustomMetrics", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ")", "\n", "logging_average", "[", "'ppl'", "]", "=", "2", "**", "logging_average", "[", "'loss'", "]", "\n", "logging_average", "[", "'uniq'", "]", "=", "len", "(", "set", "(", "predicted_tokens", ")", ")", "\n", "logging_average", "[", "'human_uniq'", "]", "=", "len", "(", "set", "(", "target_tokens", ")", ")", "\n", "\n", "save_singletoken_metrics", "(", "\n", "logging_average", ",", "\n", "config", ".", "to_dict", "(", ")", ",", "\n", "args", ",", "\n", "train_iter", "=", "train_iter", ")", "\n", "return", "logging_average", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_acc": [[438, 486], ["utils.get_datasets", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "fairseq.custom.baseline_cross_entropy.CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs", "utils.save_acc_metrics", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "config.to_dict", "enumerate", "batch[].to", "model", "torch.log_softmax", "torch.nll_loss", "F.log_softmax.argmax().view().tolist", "predicted_tokens.extend", "inp.numel", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "F.nll_loss.item", "logging_outputs.append", "target_tokens.extend", "len", "F.log_softmax.size", "torch.nll_loss", "logits[].float", "target.view().tolist", "F.log_softmax.argmax().view", "target.view", "F.log_softmax.argmax"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_acc_metrics"], ["", "def", "eval_acc", "(", "model", ",", "args", ",", "dataset_paths", ",", "config", ",", "batch_size", "=", "None", ")", ":", "\n", "    ", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "args", ".", "batch_size_singletoken", "\n", "datasets", "=", "get_datasets", "(", "dataset_paths", ",", "max_len", "=", "batch_size", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "datasets", "[", "args", ".", "eval_split", "]", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "datasets", "[", "args", ".", "eval_split", "]", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "1", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "logging_outputs", "=", "[", "]", "\n", "predicted_tokens", "=", "[", "]", "\n", "target_tokens", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "eval_dataloader", ")", ",", "\n", "desc", "=", "\"Evaluating\"", ",", "total", "=", "len", "(", "eval_dataloader", ")", ")", ":", "\n", "            ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "batch_size_singletoken", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "assert", "lprobs", ".", "size", "(", "0", ")", "==", "1", ",", "'We work on flat sequences'", "\n", "loss", "=", "F", ".", "nll_loss", "(", "lprobs", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'sum'", ")", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "\n", "pred", "=", "lprobs", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "predicted_tokens", ".", "extend", "(", "pred", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "loss", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "\n", "# for human uniq", "\n", "target_tokens", ".", "extend", "(", "target", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "logging_average", "=", "CrossEntropyCriterionWCustomMetrics", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ")", "\n", "\n", "save_acc_metrics", "(", "\n", "logging_average", ",", "\n", "config", ".", "to_dict", "(", ")", ",", "\n", "args", ")", "\n", "return", "logging_average", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken": [[488, 593], ["utils.get_datasets", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "fairseq.custom.baseline_cross_entropy.CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs", "numpy.exp", "len", "len", "numpy.mean", "numpy.mean", "numpy.mean", "utils.save_singletoken_sampling_metrics", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "numpy.mean", "set", "set", "numpy.mean", "config.to_dict", "enumerate", "batch[].to", "model", "torch.log_softmax", "torch.nll_loss", "numpy.arange", "entmax.entmax_bisect.size", "entmax.entmax_bisect.view().multinomial().view", "predicted_tokens.extend", "inp.numel", "torch.zeros_like", "torch.zeros_like", "fairseq.custom.metrics.TrainingMetrics.ranking_metrics", "F.nll_loss.item", "smoothed_nll.item", "alpha_entmax_training.jensen_shannon_divergence().mean().item", "logging_outputs.append", "target_tokens.extend", "len", "torch.nll_loss", "top_k_top_p_filtering().unsqueeze", "torch.softmax().multinomial().unsqueeze().squeeze", "torch.softmax", "entmax.entmax_bisect", "logits.size", "torch.mean", "torch.mean", "probs.view().multinomial().view.view().tolist", "rep_logits[].float", "alpha_entmax_training.alpha_entropy", "loss.mean().item", "target.view().tolist", "CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs.items", "k.startswith", "CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs.items", "k.startswith", "torch.tensor().float", "torch.tensor().float", "torch.log", "torch.log", "entmax.entmax_bisect.view().multinomial", "alpha_entmax_training.jensen_shannon_divergence().mean", "utils.top_k_top_p_filtering", "torch.softmax().multinomial().unsqueeze", "target.squeeze().tolist", "probs.view().multinomial().view.view", "probs.view().multinomial().view.squeeze().tolist", "loss.mean", "target.view", "logits.squeeze", "torch.tensor", "torch.tensor", "entmax.entmax_bisect.view", "alpha_entmax_training.jensen_shannon_divergence", "torch.softmax().multinomial", "target.squeeze", "entmax.entmax_bisect.size", "probs.view().multinomial().view.squeeze", "torch.one_hot", "torch.device", "torch.device", "torch.softmax", "entmax.entmax_bisect.size", "top_k_top_p_filtering().unsqueeze.view"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_singletoken_sampling_metrics", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.alpha_entropy", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.alpha_entmax_training.jensen_shannon_divergence"], ["", "def", "eval_singletoken", "(", "model", ",", "\n", "args", ",", "\n", "dataset_paths", ",", "\n", "config", ",", "\n", "top_k", "=", "1", ",", "\n", "top_p", "=", "0.0", ",", "\n", "t", "=", "1.0", ",", "\n", "train_iter", "=", "None", ",", "\n", "batch_size", "=", "None", ")", ":", "\n", "    ", "alpha_entmax", "=", "args", ".", "alpha_entmax", "\n", "\n", "batch_size", "=", "batch_size", "if", "batch_size", "is", "not", "None", "else", "args", ".", "batch_size_singletoken", "\n", "datasets", "=", "get_datasets", "(", "dataset_paths", ",", "max_len", "=", "batch_size", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "datasets", "[", "args", ".", "eval_split", "]", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "datasets", "[", "args", ".", "eval_split", "]", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "1", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "logging_outputs", "=", "[", "]", "\n", "predicted_tokens", "=", "[", "]", "\n", "target_tokens", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "eval_dataloader", ")", ",", "\n", "desc", "=", "\"Evaluating\"", ",", "total", "=", "len", "(", "eval_dataloader", ")", ")", ":", "\n", "            ", "longer_sample", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "inp", "=", "longer_sample", "[", ":", ",", ":", "args", ".", "batch_size_singletoken", "]", "\n", "model_output", "=", "model", "(", "input_ids", "=", "inp", ")", "\n", "target", "=", "longer_sample", "[", ":", ",", "1", ":", "]", "\n", "logits", "=", "model_output", "[", "0", "]", "\n", "log_softmax_probs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "nll", "=", "F", ".", "nll_loss", "(", "log_softmax_probs", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'sum'", ")", "\n", "true_token_logits", "=", "-", "F", ".", "nll_loss", "(", "logits", "[", "0", "]", ",", "target", "[", "0", "]", ",", "reduction", "=", "'none'", ")", "\n", "\n", "if", "alpha_entmax", "is", "False", ":", "\n", "                ", "filtered_logits", "=", "top_k_top_p_filtering", "(", "\n", "logits", ".", "squeeze", "(", "0", ")", ",", "top_k", "=", "args", ".", "top_k", ",", "top_p", "=", "args", ".", "top_p", ")", ".", "unsqueeze", "(", "0", ")", "\n", "prev", "=", "F", ".", "softmax", "(", "\n", "filtered_logits", ".", "view", "(", "filtered_logits", ".", "shape", "[", "1", ":", "]", ")", ",", "\n", "dim", "=", "-", "1", ")", ".", "multinomial", "(", "num_samples", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "probs", "=", "F", ".", "softmax", "(", "filtered_logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "probs", "=", "entmax_bisect", "(", "logits", ",", "torch", ".", "tensor", "(", "\n", "[", "args", ".", "alpha", "]", ",", "requires_grad", "=", "True", ",", "device", "=", "torch", ".", "device", "(", "args", ".", "gpu", ")", ")", ".", "float", "(", ")", ")", "\n", "", "arange", "=", "np", ".", "arange", "(", "logits", ".", "size", "(", "1", ")", ")", "\n", "\n", "next_token_probs", "=", "probs", "[", ":", ",", "arange", ",", "target", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", "\n", "voc_sizes", "=", "probs", ".", "size", "(", "-", "1", ")", "\n", "smoothed_nll", "=", "-", "torch", ".", "mean", "(", "torch", ".", "log", "(", "\n", "(", "next_token_probs", "+", "args", ".", "laplas_eps", ")", "/", "(", "1", "+", "args", ".", "laplas_eps", "*", "voc_sizes", ")", "\n", ")", ")", "\n", "\n", "pred", "=", "probs", ".", "view", "(", "-", "1", ",", "probs", ".", "size", "(", "-", "1", ")", "\n", ")", ".", "multinomial", "(", "num_samples", "=", "1", ")", ".", "view", "(", "probs", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "predicted_tokens", ".", "extend", "(", "pred", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "ntokens", "=", "inp", ".", "numel", "(", ")", "\n", "\n", "rep_logits", "=", "torch", ".", "zeros_like", "(", "logits", ")", "\n", "rep_logits", "[", ":", ",", "arange", ",", "pred", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", "=", "1", "\n", "logging_output", "=", "TrainingMetrics", ".", "ranking_metrics", "(", "\n", "rep_logits", "[", "0", "]", ".", "float", "(", ")", ",", "true_token_logits", ",", "None", ",", "ntokens", ",", "target", "[", "0", "]", ")", "\n", "logging_output", "[", "'loss'", "]", "=", "nll", ".", "item", "(", ")", "\n", "logging_output", "[", "'smoothed_nll_loss'", "]", "=", "smoothed_nll", ".", "item", "(", ")", "\n", "logging_output", "[", "'normalizer'", "]", "=", "ntokens", "\n", "logging_output", "[", "'sample_size'", "]", "=", "ntokens", "\n", "logging_output", "[", "'ntokens'", "]", "=", "ntokens", "\n", "logging_output", "[", "'js_div'", "]", "=", "jensen_shannon_divergence", "(", "\n", "probs", ",", "target", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "if", "args", ".", "token_loss", "==", "'alpha_entmax'", ":", "\n", "                ", "loss", "=", "(", "(", "probs", "-", "F", ".", "one_hot", "(", "target", ",", "\n", "num_classes", "=", "probs", ".", "size", "(", "-", "1", ")", ")", ")", "*", "logits", ")", ".", "sum", "(", "-", "1", ")", "\n", "loss", "+=", "alpha_entropy", "(", "probs", ",", "args", ".", "alpha", ")", "\n", "logging_output", "[", "'alpha_entmax_loss'", "]", "=", "loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "logging_outputs", ".", "append", "(", "logging_output", ")", "\n", "\n", "# for human uniq", "\n", "target_tokens", ".", "extend", "(", "target", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "logging_average", "=", "CrossEntropyCriterionWCustomMetrics", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ")", "\n", "logging_average", "[", "'e_ppl'", "]", "=", "np", ".", "exp", "(", "\n", "np", ".", "mean", "(", "[", "x", "[", "'smoothed_nll_loss'", "]", "for", "x", "in", "logging_outputs", "]", ")", ")", "\n", "# aggregate_logging_outputs does division by log(2) of loss", "\n", "logging_average", "[", "'ppl'", "]", "=", "2", "**", "logging_average", "[", "'loss'", "]", "\n", "logging_average", "[", "'human_uniq'", "]", "=", "len", "(", "set", "(", "target_tokens", ")", ")", "\n", "logging_average", "[", "'uniq'", "]", "=", "len", "(", "set", "(", "predicted_tokens", ")", ")", "\n", "logging_average", "[", "'wrep'", "]", "=", "np", ".", "mean", "(", "\n", "[", "v", "for", "k", ",", "v", "in", "logging_average", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "'wrong_repeat'", ")", "]", ")", "\n", "logging_average", "[", "'rep'", "]", "=", "np", ".", "mean", "(", "\n", "[", "v", "for", "k", ",", "v", "in", "logging_average", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "'repeat'", ")", "]", ")", "\n", "logging_average", "[", "'js_div'", "]", "=", "np", ".", "mean", "(", "[", "x", "[", "'js_div'", "]", "for", "x", "in", "logging_outputs", "]", ")", "\n", "if", "args", ".", "token_loss", "==", "'alpha_entmax'", ":", "\n", "        ", "logging_average", "[", "'alpha_entmax_loss'", "]", "=", "np", ".", "mean", "(", "\n", "[", "x", "[", "'alpha_entmax_loss'", "]", "for", "x", "in", "logging_outputs", "]", ")", "\n", "\n", "", "save_singletoken_sampling_metrics", "(", "\n", "logging_average", ",", "\n", "config", ".", "to_dict", "(", ")", ",", "\n", "args", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "train_iter", "=", "train_iter", ")", "\n", "\n", "return", "logging_average", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_completion": [[595, 686], ["utils.get_datasets", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "model.eval", "torch.no_grad", "torch.no_grad", "fairseq.custom.metrics.Metrics", "fairseq.custom.metrics.Metrics", "tqdm.tqdm", "enumerate", "batch[].cuda", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length", "fairseq.custom.metrics.Metrics.update", "fairseq.custom.metrics.Metrics.update", "str", "utils.save_completion_metrics", "len", "batch[].cuda.size", "utils.sample_sequence", "output[].tolist", "model.generate().tolist", "bpe_continuations.append", "text_continuations.append", "all_text_completions.append", "utils.get_text_continuation", "tokenizer.decode", "fairseq.custom.metrics.Metrics.report", "fairseq.custom.metrics.Metrics.report", "config.to_dict", "model.generate", "len"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_completion_metrics", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.sample_sequence", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_text_continuation"], ["", "def", "eval_completion", "(", "model", ",", "tokenizer", ",", "args", ",", "dataset_paths", ",", "config", ",", "\n", "train_iter", "=", "None", ")", ":", "\n", "    ", "eval_datasets", "=", "get_datasets", "(", "\n", "dataset_paths", ",", "max_len", "=", "args", ".", "batch_size_completion", ")", "\n", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_datasets", "[", "args", ".", "eval_split", "]", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_datasets", "[", "args", ".", "eval_split", "]", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "1", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "logging_outputs", "=", "[", "]", "\n", "predicted_tokens", "=", "[", "]", "\n", "target_tokens", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "all_text_completions", "=", "[", "]", "\n", "\n", "bpe_ngram_metrics", "=", "Metrics", "(", "pad", "=", "-", "1", ")", "\n", "word_ngram_metrics", "=", "Metrics", "(", "pad", "=", "-", "1", ")", "\n", "\n", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "eval_dataloader", ")", ",", "\n", "desc", "=", "\"Evaluating\"", ",", "total", "=", "len", "(", "eval_dataloader", ")", ")", ":", "\n", "            ", "if", "i", ">", "args", ".", "compl_steps", ":", "\n", "                ", "break", "\n", "\n", "", "input_sequence", "=", "batch", "[", "0", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "if", "input_sequence", ".", "size", "(", "1", ")", "<", "args", ".", "prefix_length", ":", "\n", "                ", "continue", "\n", "\n", "# Predict the completions.", "\n", "", "batch", "=", "batch_input_sequence_by_prefix_length", "(", "\n", "input_sequence", ",", "args", ".", "prefix_length", ")", "\n", "if", "args", ".", "num_beams", "==", "1", ":", "\n", "                ", "output", "=", "sample_sequence", "(", "\n", "model", ",", "\n", "batch", ",", "\n", "args", ".", "prefix_length", ",", "\n", "args", ".", "continuation_length", ",", "\n", "num_samples", "=", "1", ",", "\n", "top_k", "=", "args", ".", "top_k", ",", "\n", "top_p", "=", "args", ".", "top_p", ",", "\n", "alpha_entmax", "=", "args", ".", "alpha_entmax", ",", "\n", "alpha", "=", "args", ".", "alpha", ")", "\n", "bpe_completions", "=", "output", "[", "0", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "bpe_completions", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "batch", ",", "\n", "num_beams", "=", "args", ".", "num_beams", ",", "\n", "eos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "max_length", "=", "args", ".", "prefix_length", "+", "\n", "args", ".", "continuation_length", ")", ".", "tolist", "(", ")", "\n", "\n", "# Extract continuations from the predicted", "\n", "# completions.", "\n", "", "bpe_continuations", "=", "[", "]", "\n", "text_continuations", "=", "[", "]", "\n", "for", "bpe_completion", "in", "bpe_completions", ":", "\n", "                ", "bpe_continuations", ".", "append", "(", "\n", "bpe_completion", "[", "args", ".", "prefix_length", ":", "]", ")", "\n", "text_continuations", ".", "append", "(", "\n", "get_text_continuation", "(", "\n", "bpe_completion", ",", "tokenizer", ",", "args", ")", ")", "\n", "all_text_completions", ".", "append", "(", "\n", "tokenizer", ".", "decode", "(", "bpe_completion", ")", ")", "\n", "\n", "# Only keep continuations with at least one 4-gram", "\n", "# (A short continuation may occur due to predicted whitespace, then tokenizing, despite being", "\n", "#  normal length in BPE tokens).", "\n", "", "text_continuations", "=", "[", "\n", "c", "for", "c", "in", "text_continuations", "if", "len", "(", "c", ")", ">", "3", "]", "\n", "\n", "# Update metrics with this batch of", "\n", "# continuations.", "\n", "bpe_ngram_metrics", ".", "update", "(", "bpe_continuations", ")", "\n", "word_ngram_metrics", ".", "update", "(", "text_continuations", ")", "\n", "\n", "# Save the (possibly intermediate) metrics.", "\n", "", "train_iter", "=", "str", "(", "train_iter", ")", "if", "train_iter", "is", "not", "None", "else", "None", "\n", "if", "args", ".", "rank", "==", "args", ".", "start_rank", ":", "\n", "            ", "save_completion_metrics", "(", "\n", "bpe_metrics", "=", "bpe_ngram_metrics", ".", "report", "(", "\n", "'bpe_%s'", "%", "\n", "args", ".", "eval_split", ")", ",", "\n", "word_metrics", "=", "word_ngram_metrics", ".", "report", "(", "\n", "'word_%s'", "%", "\n", "args", ".", "eval_split", ")", ",", "\n", "text_completions", "=", "all_text_completions", ",", "\n", "config", "=", "config", ".", "to_dict", "(", ")", ",", "\n", "args", "=", "args", ",", "\n", "add", "=", "train_iter", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.random_seed": [[62, 67], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "random_seed", "(", "value", ")", ":", "\n", "    ", "random", ".", "seed", "(", "value", ")", "\n", "np", ".", "random", ".", "seed", "(", "value", ")", "\n", "torch", ".", "manual_seed", "(", "value", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.cleanup": [[69, 71], ["torch.destroy_process_group"], "function", ["None"], ["", "def", "cleanup", "(", ")", ":", "\n", "    ", "dist", ".", "destroy_process_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.parse_args": [[73, 213], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "float"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda:0'", ")", "\n", "parser", ".", "add_argument", "(", "'--world-size'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--opt-level'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'O0'", ",", "\n", "choices", "=", "[", "\n", "'O0'", ",", "\n", "'O1'", ",", "\n", "'O2'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--start_rank'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--adress'", ",", "type", "=", "str", ",", "default", "=", "'tcp://127.0.0.1:80'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mode'", ",", "\n", "choices", "=", "[", "\n", "'train'", ",", "\n", "'eval-singletoken'", ",", "\n", "'eval-completion'", ",", "\n", "'eval-singletoken-sampling'", ",", "\n", "'eval-acc'", ",", "\n", "'eval-both'", ",", "\n", "'eval-singletoken-argmax'", "]", ",", "\n", "default", "=", "'eval-singletoken'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-split'", ",", "choices", "=", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--model-name'", ",", "\n", "choices", "=", "[", "\n", "'gpt2'", ",", "\n", "'gpt2-medium'", ",", "\n", "'gpt2-large'", "]", ",", "\n", "default", "=", "'gpt2'", ")", "\n", "parser", ".", "add_argument", "(", "'--model-load-dir'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data-base'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'../fairseq/data-bin/wikitext-103-bpe_v0'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-train-epochs'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-singletoken'", ",", "type", "=", "int", ",", "default", "=", "1024", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size-completion'", ",", "type", "=", "int", ",", "default", "=", "1024", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output-dir'", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "# eval-completion", "\n", "parser", ".", "add_argument", "(", "'--prefix-length'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--continuation-length'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--top-k'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--top-p'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "\n", "# custom training", "\n", "parser", ".", "add_argument", "(", "'--pg-tune-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--ul-tune-rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--train-batch-size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--report-metrics-every'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--save-every'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--sequence-ngram-n'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--train-n-steps'", ",", "type", "=", "int", ",", "default", "=", "5000", ")", "\n", "parser", ".", "add_argument", "(", "'--validate-every'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--ul-accum-steps'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--pg-accum-steps'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-compl-every'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--compl-steps'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "'inf'", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--seq-max-grad-norm'", ",", "type", "=", "int", ",", "default", "=", "10.0", ")", "\n", "parser", ".", "add_argument", "(", "'--n-samples'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--mini-batch-size'", ",", "type", "=", "int", ",", "default", "=", "6", ")", "\n", "parser", ".", "add_argument", "(", "'--report-value-loss-every'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--load-start-iter'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# policy gradient training", "\n", "parser", ".", "add_argument", "(", "'--policy-top-k'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--policy-top-p'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--policy-temperature'", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--reward-ngram-n'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--add_ul_loss_to_pg'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--add_kl_loss_to_pg'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--add_mle_loss_to_pg'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--algorithm'", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\n", "'once_reward_pg'", ",", "\n", "'time_reward_pg'", "]", ",", "\n", "default", "=", "'once_reward_pg'", ",", "\n", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.95", ")", "\n", "parser", ".", "add_argument", "(", "'--lamda'", ",", "type", "=", "float", ",", "default", "=", "0.85", ")", "\n", "parser", ".", "add_argument", "(", "'--ppo-epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--reward-type'", ",", "type", "=", "str", ",", "default", "=", "'reward_for_past'", ",", "\n", "choices", "=", "[", "'reward_for_past'", ",", "'reward_for_future'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--psy-type'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'reward'", ",", "\n", "choices", "=", "[", "\n", "'reward'", ",", "\n", "'advantage'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--ratio-clip-range'", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "'--pg-coef'", ",", "type", "=", "float", ",", "default", "=", "3.0", ")", "\n", "\n", "# training loop", "\n", "parser", ".", "add_argument", "(", "\"--adam-epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max-grad-norm'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training \\\n                            steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient-accumulation-steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before\\\n                            performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--learning-rate'", ",", "type", "=", "float", ",", "default", "=", "6.25e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup-steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-schedule'", ",", "type", "=", "str", ",", "default", "=", "'warmup_linear'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--laplas-eps'", ",", "type", "=", "float", ",", "default", "=", "1e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "1.2", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--token-loss'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'mle'", ",", "\n", "choices", "=", "[", "\n", "'mle'", ",", "\n", "'alpha_entmax_loss'", ",", "\n", "'tldr'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha-entmax'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num-beams'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.main": [[215, 574], ["run_gpt2.random_seed", "print", "print", "torch.init_process_group", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logger.info", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2Config.from_pretrained", "transformers.GPT2LMHeadModel().from_pretrained", "apex.parallel.DistributedDataParallel.cuda", "run_gpt2.cleanup", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "policy_value.PolicyValueModel", "print", "apex.parallel.DistributedDataParallel.load_state_dict", "utils.eval_singletoken_argmax", "utils.eval_acc", "utils.eval_singletoken", "utils.eval_singletoken", "print", "utils.eval_completion", "utils.get_datasets", "torch.utils.data.DataLoader", "list", "transformers.AdamW", "apex.amp.initialize", "apex.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup", "tqdm.trange", "transformers.GPT2LMHeadModel", "torch.load", "torch.load", "torch.load", "torch.load", "list", "max", "os.path.exists", "os.makedirs", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.RandomSampler", "apex.parallel.DistributedDataParallel.named_parameters", "time_reward_pg.TimeRewardTrainer", "once_reward_pg.OnceRewardTrainer", "tqdm.tqdm", "enumerate", "os.path.exists", "ValueError", "os.path.isdir", "ValueError", "filter", "list", "os.path.join", "os.path.join", "gc.collect", "torch.device", "torch.device", "torch.device", "torch.device", "os.listdir", "map", "ValueError", "utils.top_k_top_p_filtering", "int", "apex.parallel.DistributedDataParallel.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "len", "x.startswith", "any", "utils.top_k_top_p_filtering", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "batch[].size", "once_reward_pg.OnceRewardTrainer.sample", "logging_outputs.append", "max", "once_reward_pg.OnceRewardTrainer.train", "vf_loss.append", "avg_value.append", "loss.item.item", "once_reward_pg.OnceRewardTrainer.sample", "logging_outputs.append", "once_reward_pg.OnceRewardTrainer.ppo_step", "vf_loss.append", "avg_value.append", "loss.item.item", "unlikelihood.ul_seq", "logging_outputs.append", "loss.item.backward", "loss.item.item", "token_loss", "loss.item.backward", "loss.item.item", "logging_outputs.append", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "numpy.mean", "numpy.mean", "fairseq.custom.baseline_cross_entropy.CrossEntropyCriterionWCustomMetrics.aggregate_logging_outputs", "fairseq.custom.sequence_penalty_loss.SequencePenaltyCriterion.aggregate_logging_outputs", "SequencePenaltyCriterion.aggregate_logging_outputs.items", "print", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "model_to_save.config.to_json_file", "GPT2Tokenizer.from_pretrained.save_vocabulary", "print", "utils.eval_singletoken", "print", "utils.eval_completion", "int", "any", "train_info[].item", "train_info[].item", "train_info[].item", "train_info[].item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.get_lr", "open", "json.dump", "hasattr", "model_to_save.state_dict", "open", "json.dump", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "model_to_save.config.to_json_file", "GPT2Tokenizer.from_pretrained.save_vocabulary", "utils.save_singletoken_metrics", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "os.path.join", "numpy.exp", "numpy.mean", "os.path.join", "vars", "hasattr", "model_to_save.state_dict", "open", "json.dump", "os.path.join", "GPT2Config.from_pretrained.to_dict", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "numpy.mean", "os.path.join", "vars", "x.split", "len"], "function", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.random_seed", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.run_gpt2.cleanup", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken_argmax", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_acc", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_completion", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.get_datasets", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.sample", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.train", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.sample", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.once_reward_pg.OnceRewardTrainer.ppo_step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.unlikelihood.ul_seq", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_singletoken", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.eval_completion", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.save_singletoken_metrics"], ["", "def", "main", "(", "gpu", ",", "nprocs", ",", "args", ")", ":", "\n", "    ", "random_seed", "(", "args", ".", "seed", ")", "\n", "print", "(", "f'GPU: {gpu}'", ")", "\n", "args", ".", "gpu", "=", "gpu", "\n", "args", ".", "rank", "=", "args", ".", "start_rank", "+", "args", ".", "gpu", "\n", "print", "(", "f'Rank: {args.rank}'", ")", "\n", "dist", ".", "init_process_group", "(", "\"nccl\"", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", "init_method", "=", "args", ".", "adress", ",", "\n", "world_size", "=", "args", ".", "world_size", ")", "\n", "group", "=", "dist", ".", "group", ".", "WORLD", "\n", "args", ".", "device", "=", "gpu", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "\"gpu {}, n_gpu {}\"", ".", "format", "(", "gpu", ",", "n_gpu", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "gpu", ")", "\n", "\n", "start_iter", "=", "0", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "tokenizer", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "model_name", ")", "\n", "config", "=", "GPT2Config", ".", "from_pretrained", "(", "args", ".", "model_name", ")", "\n", "\n", "dataset_paths", "=", "{", "\n", "'train'", ":", "os", ".", "path", ".", "join", "(", "args", ".", "data_base", ",", "'train_tokens_bpe_gpt2.pt'", ")", ",", "\n", "'valid'", ":", "os", ".", "path", ".", "join", "(", "args", ".", "data_base", ",", "'valid_tokens_bpe_gpt2.pt'", ")", ",", "\n", "'test'", ":", "os", ".", "path", ".", "join", "(", "args", ".", "data_base", ",", "'test_tokens_bpe_gpt2.pt'", ")", ",", "\n", "}", "\n", "\n", "gpt2", "=", "GPT2LMHeadModel", "(", "config", ")", ".", "from_pretrained", "(", "\n", "args", ".", "model_name", ",", "output_hidden_states", "=", "True", ")", "\n", "gpt2", ".", "config", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "gpt2", ".", "config", ".", "eos_token_id", "=", "None", "\n", "\n", "if", "args", ".", "psy_type", "==", "'reward'", ":", "\n", "        ", "model", "=", "gpt2", "\n", "", "else", ":", "\n", "        ", "model", "=", "PolicyValueModel", "(", "config", ",", "gpt2", ")", "\n", "\n", "", "if", "args", ".", "model_load_dir", ":", "\n", "        ", "print", "(", "'Load checkpoint'", ")", "\n", "model", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "\n", "args", ".", "model_load_dir", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "gpu", ")", ")", ",", "\n", "strict", "=", "False", ")", "\n", "if", "args", ".", "load_start_iter", ":", "\n", "            ", "dir_path", "=", "args", ".", "model_load_dir", "[", ":", "-", "len", "(", "'pytorch_model.bin'", ")", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_path", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f'Path \\'{dir_path}\\' doesn\\'t exists'", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_path", ")", ":", "\n", "                ", "raise", "ValueError", "(", "f'Path \\'{dir_path}\\' is not a directory'", ")", "\n", "\n", "", "names", "=", "list", "(", "\n", "filter", "(", "\n", "lambda", "x", ":", "x", ".", "startswith", "(", "'singletoken'", ")", ",", "\n", "os", ".", "listdir", "(", "dir_path", ")", ")", ")", "\n", "start_iter", "=", "max", "(", "\n", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "len", "(", "'.json'", ")", "]", ")", ",", "names", ")", ")", ")", "\n", "", "", "model", ".", "cuda", "(", "gpu", ")", "\n", "\n", "if", "args", ".", "mode", "==", "'eval-singletoken-argmax'", ":", "\n", "        ", "eval_singletoken_argmax", "(", "model", ",", "args", ",", "dataset_paths", ",", "config", ")", "\n", "\n", "", "if", "args", ".", "mode", "==", "'eval-acc'", ":", "\n", "        ", "eval_acc", "(", "model", ",", "args", ",", "dataset_paths", ",", "config", ")", "\n", "\n", "", "if", "args", ".", "mode", "==", "'eval-singletoken'", "or", "args", ".", "mode", "==", "'eval-both'", ":", "\n", "        ", "eval_singletoken", "(", "\n", "model", ",", "\n", "args", ",", "\n", "dataset_paths", ",", "\n", "config", ",", "\n", "top_k", "=", "args", ".", "top_k", ",", "\n", "top_p", "=", "args", ".", "top_p", ")", "\n", "\n", "", "if", "args", ".", "mode", "==", "'eval-singletoken-sampling'", "or", "args", ".", "mode", "==", "'eval-both'", ":", "\n", "        ", "eval_singletoken", "(", "model", ",", "args", ",", "dataset_paths", ",", "config", ")", "\n", "\n", "", "if", "args", ".", "mode", "==", "'eval-completion'", "or", "args", ".", "mode", "==", "'eval-both'", ":", "\n", "        ", "print", "(", "'Eval-completion'", ")", "\n", "eval_completion", "(", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "args", ",", "\n", "dataset_paths", ",", "\n", "config", ",", "\n", "train_iter", "=", "None", ")", "\n", "\n", "", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best'", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best'", ")", ")", "\n", "\n", "", "if", "args", ".", "token_loss", "==", "'mle'", ":", "\n", "            ", "token_loss", "=", "mle_loss", "\n", "", "elif", "args", ".", "token_loss", "==", "'alpha_entmax_loss'", ":", "\n", "            ", "token_loss", "=", "alpha_entmax_loss", "\n", "", "elif", "args", ".", "token_loss", "==", "'tldr'", ":", "\n", "            ", "token_loss", "=", "tldr_loss", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'token loss is not defined'", ")", "\n", "\n", "", "datasets", "=", "get_datasets", "(", "dataset_paths", ",", "max_len", "=", "args", ".", "train_batch_size", ")", "\n", "if", "args", ".", "world_size", ">", "1", ":", "\n", "            ", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "datasets", "[", "'train'", "]", ",", "\n", "num_replicas", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", "\n", ")", "\n", "", "else", ":", "\n", "            ", "train_sampler", "=", "RandomSampler", "(", "datasets", "[", "'train'", "]", ")", "\n", "", "train_seq_dataloader", "=", "DataLoader", "(", "\n", "datasets", "[", "'train'", "]", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "1", ")", "\n", "\n", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "opt_level", ")", "\n", "model", "=", "DDP", "(", "model", ")", "\n", "model", ".", "config", "=", "config", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", "num_training_steps", "=", "args", ".", "train_n_steps", ")", "\n", "if", "args", ".", "algorithm", "==", "'time_reward_pg'", ":", "\n", "            ", "if", "args", ".", "policy_top_k", "!=", "0", ":", "\n", "                ", "def", "filter_method", "(", "x", ")", ":", "return", "top_k_top_p_filtering", "(", "\n", "x", ",", "n", "=", "1", ",", "top_k", "=", "args", ".", "policy_top_k", ",", "top_p", "=", "0.0", ")", "\n", "", "elif", "args", ".", "policy_top_p", "!=", "0.", ":", "\n", "                ", "def", "filter_method", "(", "x", ")", ":", "return", "top_k_top_p_filtering", "(", "\n", "x", ",", "n", "=", "1", ",", "top_k", "=", "0", ",", "top_p", "=", "args", ".", "policy_top_p", ")", "\n", "", "elif", "args", ".", "policy_temperature", "!=", "0.", ":", "\n", "                ", "def", "filter_method", "(", "x", ")", ":", "return", "x", "/", "args", ".", "policy_temperature", "\n", "\n", "", "agent_policy", "=", "TimeRewardTrainer", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "prefix_length", "=", "args", ".", "prefix_length", ",", "\n", "continuation_length", "=", "args", ".", "continuation_length", ",", "\n", "device", "=", "gpu", ",", "\n", "mini_batch_size", "=", "args", ".", "mini_batch_size", ",", "\n", "reward_type", "=", "args", ".", "reward_type", ",", "\n", "psy_type", "=", "args", ".", "psy_type", ",", "\n", "n_samples", "=", "args", ".", "n_samples", ",", "\n", "max_grad_norm", "=", "args", ".", "seq_max_grad_norm", ")", "\n", "\n", "", "if", "args", ".", "algorithm", "==", "'once_reward_pg'", ":", "\n", "            ", "agent_policy", "=", "OnceRewardTrainer", "(", "\n", "model", ",", "\n", "config", ",", "\n", "tokenizer", ",", "\n", "optimizer", ",", "\n", "prefix_length", "=", "args", ".", "prefix_length", ",", "\n", "continuation_length", "=", "args", ".", "continuation_length", ",", "\n", "n_samples", "=", "args", ".", "n_samples", ",", "\n", "device", "=", "gpu", ",", "\n", "top_k", "=", "args", ".", "policy_top_k", ",", "\n", "top_p", "=", "args", ".", "policy_top_p", ",", "\n", "temperature", "=", "args", ".", "policy_temperature", ",", "\n", "max_grad_norm", "=", "args", ".", "seq_max_grad_norm", ",", "\n", "ngram_reward", "=", "args", ".", "reward_ngram_n", ",", "\n", "mini_batch_size", "=", "args", ".", "mini_batch_size", ",", "\n", "psy_type", "=", "args", ".", "psy_type", ",", "\n", "clip_range", "=", "args", ".", "ratio_clip_range", ")", "\n", "\n", "", "total_steps", "=", "start_iter", "\n", "best_ppl", "=", "1e20", "\n", "vf_loss", "=", "[", "]", "\n", "avg_value", "=", "[", "]", "\n", "for", "_", "in", "trange", "(", "args", ".", "num_train_epochs", ",", "desc", "=", "\"Epoch\"", ",", "\n", "initial", "=", "start_iter", ")", ":", "\n", "            ", "logging_outputs", "=", "[", "]", "\n", "epoch_loss", "=", "0", "\n", "epoch_steps", "=", "0", "\n", "tqdm_bar", "=", "tqdm", "(", "\n", "train_seq_dataloader", ",", "\n", "desc", "=", "\"Training\"", ",", "\n", "total", "=", "int", "(", "\n", "args", ".", "train_n_steps", "*", "\n", "(", "\n", "(", "1", "-", "\n", "args", ".", "ul_tune_rate", "-", "\n", "args", ".", "pg_tune_rate", ")", "+", "\n", "args", ".", "ul_tune_rate", "*", "\n", "args", ".", "ul_accum_steps", "+", "\n", "args", ".", "pg_tune_rate", "*", "\n", "args", ".", "pg_accum_steps", ")", ")", ")", "\n", "\n", "ul_cnt", "=", "0", "\n", "pg_cnt", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "tqdm_bar", ")", ":", "\n", "                ", "if", "ul_cnt", "%", "args", ".", "ul_accum_steps", "==", "0", "and", "pg_cnt", "%", "args", ".", "pg_accum_steps", "==", "0", ":", "\n", "                    ", "model", ".", "zero_grad", "(", ")", "\n", "", "gc", ".", "collect", "(", ")", "\n", "\n", "# pg", "\n", "if", "torch", ".", "rand", "(", "1", ")", ".", "item", "(", "\n", ")", "<", "args", ".", "pg_tune_rate", "or", "pg_cnt", "%", "args", ".", "pg_accum_steps", "!=", "0", ":", "\n", "                    ", "if", "pg_cnt", "==", "1", ":", "\n", "                        ", "rewards", "=", "[", "]", "\n", "", "if", "batch", "[", "0", "]", ".", "size", "(", "1", ")", "<", "args", ".", "prefix_length", ":", "\n", "                        ", "continue", "\n", "", "pg_cnt", "=", "(", "pg_cnt", "+", "1", ")", "%", "args", ".", "pg_accum_steps", "\n", "\n", "if", "args", ".", "algorithm", "==", "'time_reward_pg'", ":", "\n", "                        ", "samples", ",", "n_sent", ",", "batch_metrics", "=", "agent_policy", ".", "sample", "(", "\n", "batch", ",", "filter_method", ",", "args", ")", "\n", "logging_outputs", ".", "append", "(", "batch_metrics", ")", "\n", "progress", "=", "max", "(", "0", ",", "(", "total_steps", "-", "0", ")", "/", "\n", "(", "args", ".", "train_n_steps", "-", "0", ")", ")", "\n", "clip_range", "=", "args", ".", "clip_range", "*", "(", "1", "-", "progress", ")", "\n", "train_info", "=", "agent_policy", ".", "train", "(", "\n", "samples", ",", "filter_method", ",", "progress", ",", "args", ",", "make_step", "=", "(", "\n", "pg_cnt", "%", "\n", "args", ".", "pg_accum_steps", "==", "0", ")", ")", "\n", "del", "samples", "\n", "vf_loss", ".", "append", "(", "train_info", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "avg_value", ".", "append", "(", "train_info", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "loss", "=", "train_info", "[", "0", "]", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "", "if", "args", ".", "algorithm", "==", "'once_reward_pg'", ":", "\n", "                        ", "samples", ",", "batch_metrics", ",", "batch_size", "=", "agent_policy", ".", "sample", "(", "\n", "batch", ",", "args", ")", "\n", "logging_outputs", ".", "append", "(", "batch_metrics", ")", "\n", "train_info", "=", "agent_policy", ".", "ppo_step", "(", "\n", "samples", ",", "args", ",", "make_step", "=", "(", "\n", "pg_cnt", "%", "\n", "args", ".", "pg_accum_steps", "==", "0", ")", ")", "\n", "del", "samples", "\n", "vf_loss", ".", "append", "(", "train_info", "[", "2", "]", ".", "item", "(", ")", ")", "\n", "avg_value", ".", "append", "(", "train_info", "[", "3", "]", ".", "item", "(", ")", ")", "\n", "loss", "=", "train_info", "[", "0", "]", "\n", "loss", "=", "loss", "/", "args", ".", "pg_accum_steps", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "\n", "# ul", "\n", "", "", "elif", "torch", ".", "rand", "(", "\n", "1", ")", ".", "item", "(", ")", "<", "args", ".", "ul_tune_rate", "or", "ul_cnt", "%", "args", ".", "ul_accum_steps", "!=", "0", ":", "\n", "                    ", "ul_cnt", "=", "(", "ul_cnt", "+", "1", ")", "%", "args", ".", "ul_accum_steps", "\n", "loss", ",", "batch_metrics", "=", "ul_seq", "(", "model", ",", "batch", ",", "args", ")", "\n", "logging_outputs", ".", "append", "(", "batch_metrics", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "if", "ul_cnt", "%", "args", ".", "ul_accum_steps", "==", "0", ":", "\n", "                        ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Token loss", "\n", "", "", "else", ":", "\n", "                    ", "loss", "=", "0", "\n", "loss", ",", "batch_metrics", "=", "token_loss", "(", "model", ",", "batch", ",", "args", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "logging_outputs", ".", "append", "(", "batch_metrics", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "ul_cnt", "%", "args", ".", "ul_accum_steps", "==", "0", "and", "pg_cnt", "%", "args", ".", "pg_accum_steps", "==", "0", ":", "\n", "                    ", "scheduler", ".", "step", "(", ")", "\n", "epoch_loss", "+=", "loss", "\n", "epoch_steps", "+=", "1", "\n", "total_steps", "+=", "1", "\n", "tqdm_bar", ".", "desc", "=", "\"Training loss: {:.2e} lr: {:.2e}\"", ".", "format", "(", "\n", "epoch_loss", "/", "epoch_steps", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ")", "\n", "\n", "if", "epoch_steps", "%", "args", ".", "report_value_loss_every", "==", "0", ":", "\n", "                        ", "vf_loss_rep", "=", "np", ".", "mean", "(", "vf_loss", ")", "\n", "avg_value_rep", "=", "np", ".", "mean", "(", "avg_value", ")", "\n", "vf_loss", "=", "[", "]", "\n", "avg_value", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "f'vf_loss_{total_steps}.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "json", ".", "dump", "(", "{", "'vf_loss'", ":", "vf_loss_rep", ",", "\n", "'avg_value'", ":", "avg_value_rep", "}", ",", "f", ")", "\n", "\n", "", "", "if", "epoch_steps", "%", "args", ".", "report_metrics_every", "==", "0", ":", "\n", "                        ", "logging_average", "=", "CrossEntropyCriterionWCustomMetrics", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ")", "\n", "temp", "=", "SequencePenaltyCriterion", ".", "aggregate_logging_outputs", "(", "\n", "logging_outputs", ")", "\n", "for", "k", ",", "v", "in", "temp", ".", "items", "(", ")", ":", "\n", "                            ", "logging_average", "[", "k", "]", "=", "v", "\n", "", "if", "args", ".", "token_loss", "==", "'mle'", ":", "\n", "                            ", "logging_average", "[", "'ppl'", "]", "=", "2", "**", "logging_average", "[", "'loss'", "]", "\n", "", "elif", "args", ".", "token_loss", "==", "'alpha_entmax_loss'", ":", "\n", "                            ", "logging_average", "[", "'e_ppl'", "]", "=", "np", ".", "exp", "(", "\n", "np", ".", "mean", "(", "[", "x", "[", "'smoothed_nll_loss'", "]", "for", "x", "in", "logging_outputs", "]", ")", ")", "\n", "logging_average", "[", "'js_div'", "]", "=", "np", ".", "mean", "(", "\n", "[", "x", "[", "'js_div'", "]", "for", "x", "in", "logging_outputs", "]", ")", "\n", "", "print", "(", "logging_average", ")", "\n", "logging_outputs", "=", "[", "]", "\n", "\n", "", "if", "total_steps", "==", "args", ".", "train_n_steps", ":", "\n", "                        ", "break", "\n", "\n", "", "if", "epoch_steps", "%", "args", ".", "save_every", "==", "0", "and", "args", ".", "rank", "==", "args", ".", "start_rank", ":", "\n", "                        ", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "\n", "model", ",", "'module'", ")", "else", "model", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "CONFIG_NAME", ")", "\n", "torch", ".", "save", "(", "\n", "model_to_save", ".", "state_dict", "(", ")", ",", "\n", "output_model_file", ")", "\n", "model_to_save", ".", "config", ".", "to_json_file", "(", "output_config_file", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'args.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "f", ")", "\n", "", "tokenizer", ".", "save_vocabulary", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "if", "total_steps", "%", "args", ".", "validate_every", "==", "0", ":", "\n", "                        ", "print", "(", "\"Validating...\"", ")", "\n", "validation_outputs", "=", "eval_singletoken", "(", "\n", "model", ",", "args", ",", "dataset_paths", ",", "config", ",", "train_iter", "=", "total_steps", ")", "\n", "if", "args", ".", "token_loss", "==", "'mle'", ":", "\n", "                            ", "metric", "=", "'ppl'", "\n", "", "elif", "args", ".", "token_loss", "==", "'alpha_entmax_loss'", ":", "\n", "                            ", "metric", "=", "'js_div'", "\n", "", "elif", "args", ".", "token_loss", "==", "'tldr'", ":", "\n", "                            ", "metric", "=", "'ppl'", "\n", "", "if", "validation_outputs", "[", "metric", "]", "<", "best_ppl", "and", "args", ".", "rank", "==", "args", ".", "start_rank", ":", "\n", "                            ", "best_ppl", "=", "validation_outputs", "[", "metric", "]", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "\n", "model", ",", "'module'", ")", "else", "model", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'best'", ",", "WEIGHTS_NAME", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'best'", ",", "CONFIG_NAME", ")", "\n", "torch", ".", "save", "(", "\n", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "model_to_save", ".", "config", ".", "to_json_file", "(", "\n", "output_config_file", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'args.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                                ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "f", ")", "\n", "", "tokenizer", ".", "save_vocabulary", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best'", ")", ")", "\n", "save_singletoken_metrics", "(", "\n", "validation_outputs", ",", "config", ".", "to_dict", "(", ")", ",", "args", ",", "train_iter", "=", "total_steps", ",", "best", "=", "True", ")", "\n", "\n", "", "", "if", "total_steps", "%", "args", ".", "eval_compl_every", "==", "0", ":", "\n", "                        ", "print", "(", "\"Eval completion...\"", ")", "\n", "eval_completion", "(", "model", ",", "\n", "tokenizer", ",", "\n", "args", ",", "\n", "dataset_paths", ",", "\n", "config", ",", "\n", "train_iter", "=", "total_steps", ")", "\n", "", "", "", "", "", "cleanup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.__init__": [[19, 48], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "torch.nn.SmoothL1Loss", "torch.nn.MSELoss", "torch.nn.MSELoss"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "optimizer", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "gamma", "=", "kwargs", ".", "get", "(", "'gamma'", ",", "0.99", ")", "\n", "self", ".", "lamda", "=", "kwargs", ".", "get", "(", "'lamda'", ",", "0.85", ")", "\n", "\n", "self", ".", "psy_type", "=", "kwargs", ".", "get", "(", "'psy_type'", ",", "'advantage'", ")", "\n", "\n", "self", ".", "n_gather", "=", "kwargs", ".", "get", "(", "'n_gather'", ",", "1", ")", "\n", "self", ".", "epochs", "=", "kwargs", ".", "get", "(", "'epochs'", ",", "1", ")", "\n", "self", ".", "n_samples", "=", "kwargs", ".", "get", "(", "'n_samples'", ",", "1", ")", "\n", "self", ".", "n_of_gram", "=", "kwargs", ".", "get", "(", "'n_of_gram'", ",", "4", ")", "\n", "self", ".", "reward_type", "=", "kwargs", ".", "get", "(", "'reward_type'", ",", "'reward_for_past'", ")", "\n", "self", ".", "prefix_length", "=", "kwargs", ".", "get", "(", "'prefix_length'", ",", "50", ")", "\n", "self", ".", "continuation_length", "=", "kwargs", ".", "get", "(", "'continuation_length'", ",", "100", ")", "\n", "\n", "self", ".", "device", "=", "kwargs", ".", "get", "(", "'device'", ",", "'cpu'", ")", "\n", "self", ".", "max_grad_norm", "=", "kwargs", ".", "get", "(", "'max_grad_norm'", ",", "1.", ")", "\n", "\n", "self", ".", "mini_batch_size", "=", "kwargs", ".", "get", "(", "'mini_batch_size'", ",", "1", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "value_loss", "=", "kwargs", ".", "get", "(", "'value_err_f'", ",", "'smooth_l1'", ")", "\n", "if", "self", ".", "value_loss", "==", "'smooth_l1'", ":", "\n", "            ", "self", ".", "value_loss", "=", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "", "elif", "self", ".", "value_loss", "==", "'l2'", ":", "\n", "            ", "self", ".", "value_loss", "=", "lambda", "x", ":", "0.5", "*", "nn", ".", "MSELoss", "(", ")", "(", "x", ")", "\n", "\n", "", "self", ".", "value_loss", "=", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.sample": [[49, 178], ["batch_[].to", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length", "fairseq.custom.evaluate_utils.batch_input_sequence_by_prefix_length.size", "time_reward_pg.TimeRewardTrainer.model", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "values.mean.mean.view", "hidden.view.view.view", "time_reward_pg.TimeRewardTrainer._calc_rewards", "values.mean.mean.resize", "values.mean.mean.mean", "contin.contiguous().numel", "collections.defaultdict", "collections.defaultdict.items", "time_reward_pg.TimeRewardTrainer.model.value", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "filter_method", "torch.softmax().multinomial", "torch.softmax().multinomial", "torch.stack.append", "torch.stack.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.arange", "[].squeeze", "output[].view", "torch.zeros.view", "torch.zeros.view", "time_reward_pg.TimeRewardTrainer.size", "time_reward_pg.TimeRewardTrainer._calc_advantages", "time_reward_pg.TimeRewardTrainer._calc_total_rewards", "torch.cat.view", "torch.cat.view", "torch.zeros().float.view", "torch.zeros().float.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.size", "torch.cat.size", "time_reward_pg.TimeRewardTrainer.model", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "time_reward_pg.TimeRewardTrainer.model", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "contin.contiguous", "y.contiguous().cpu().tolist", "utils.ngram_metrics", "utils.ngram_metrics.items", "torch.softmax", "torch.softmax", "time_reward_pg.TimeRewardTrainer.model.value", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "time_reward_pg.TimeRewardTrainer.model.value", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.log_softmax", "torch.log_softmax", "torch.zeros.size", "torch.zeros.size", "torch.zeros.size", "torch.zeros.size", "y.contiguous().cpu", "torch.softmax().multinomial.squeeze().tolist", "y.contiguous", "torch.softmax().multinomial.squeeze"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_rewards", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_advantages", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_total_rewards", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.utils.ngram_metrics", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value"], ["", "def", "sample", "(", "self", ",", "batch_", ",", "filter_method", ",", "args", ")", ":", "\n", "        ", "input_sequence", "=", "batch_", "[", "0", "]", ".", "to", "(", "args", ".", "gpu", ")", "\n", "batch", "=", "batch_input_sequence_by_prefix_length", "(", "\n", "input_sequence", ",", "args", ".", "prefix_length", ")", "\n", "batch", "=", "batch", "[", ":", "self", ".", "mini_batch_size", "]", "\n", "n_sent", "=", "batch", ".", "size", "(", "0", ")", "\n", "\n", "continuation_logits", "=", "[", "]", "\n", "log_pis", "=", "[", "]", "\n", "context", "=", "batch", "\n", "\n", "out", "=", "self", ".", "model", "(", "input_ids", "=", "batch", ",", "past", "=", "None", ")", "\n", "logits", ",", "past", ",", "hid", "=", "out", "[", ":", "3", "]", "\n", "hid", "=", "torch", ".", "stack", "(", "hid", "[", "1", ":", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "            ", "value", "=", "self", ".", "model", ".", "value", "(", "hid", "[", ":", ",", "-", "1", ",", "...", "]", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "torch", ".", "zeros", "(", "(", "self", ".", "mini_batch_size", ")", ",", "device", "=", "logits", ".", "device", ")", "\n", "", "target", "=", "context", "[", ":", ",", "1", ":", "]", "\n", "lprobs", "=", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "cur_hid", "=", "torch", ".", "cat", "(", "[", "hid", "[", ":", ",", "-", "1", ",", "...", "]", "]", "*", "self", ".", "n_samples", ",", "0", ")", "\n", "past", "=", "[", "torch", ".", "cat", "(", "[", "x", "]", "*", "self", ".", "n_samples", ",", "1", ")", "for", "x", "in", "past", "]", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "logits", "]", "*", "self", ".", "n_samples", ",", "0", ")", "\n", "value", "=", "torch", ".", "cat", "(", "[", "value", "]", "*", "self", ".", "n_samples", ",", "0", ")", "\n", "prev", "=", "torch", ".", "cat", "(", "[", "context", "]", "*", "self", ".", "n_samples", ",", "0", ")", "\n", "output", "=", "torch", ".", "cat", "(", "[", "context", "]", "*", "self", ".", "n_samples", ",", "0", ")", "\n", "\n", "log_probs", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "n_samples", "*", "n_sent", ",", "\n", "self", ".", "continuation_length", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "values", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "n_samples", "*", "n_sent", ",", "\n", "self", ".", "continuation_length", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "hidden", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "n_samples", "*", "\n", "n_sent", ",", "\n", "self", ".", "continuation_length", ",", "\n", "self", ".", "model", ".", "config", ".", "n_embd", ",", "\n", "self", ".", "model", ".", "config", ".", "n_layer", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "continuation_length", ")", ":", "\n", "            ", "values", "[", ":", ",", "i", "]", "=", "value", "\n", "hidden", "[", ":", ",", "i", ",", "...", "]", "=", "cur_hid", "\n", "logits", "=", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "filtered_logits", "=", "filter_method", "(", "logits", ")", "\n", "prev", "=", "F", ".", "softmax", "(", "\n", "filtered_logits", ",", "\n", "dim", "=", "-", "1", ")", ".", "multinomial", "(", "\n", "num_samples", "=", "1", ")", "\n", "continuation_logits", ".", "append", "(", "logits", ")", "\n", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "prev", ")", ",", "dim", "=", "1", ")", "\n", "\n", "arange", "=", "np", ".", "arange", "(", "logits", ".", "size", "(", "0", ")", ")", "\n", "#             next_token_log_prob = F.log_softmax(", "\n", "# filtered_logits, dim=-1)[arange, prev.squeeze().tolist()].squeeze()", "\n", "next_token_log_prob", "=", "F", ".", "log_softmax", "(", "\n", "logits", ",", "dim", "=", "-", "1", ")", "[", "arange", ",", "prev", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "]", ".", "squeeze", "(", ")", "\n", "log_probs", "[", ":", ",", "i", "]", "=", "next_token_log_prob", "\n", "\n", "if", "i", "!=", "self", ".", "continuation_length", "-", "1", ":", "\n", "                ", "out", "=", "self", ".", "model", "(", "prev", ",", "past", "=", "past", ")", "\n", "logits", ",", "past", ",", "cur_hid", "=", "out", "[", ":", "3", "]", "\n", "cur_hid", "=", "torch", ".", "stack", "(", "cur_hid", "[", "1", ":", "]", ",", "-", "1", ")", "\n", "cur_hid", "=", "cur_hid", "[", ":", ",", "-", "1", ",", "...", "]", "\n", "if", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "                    ", "value", "=", "self", ".", "model", ".", "value", "(", "cur_hid", ")", "\n", "", "else", ":", "\n", "                    ", "value", "=", "torch", ".", "zeros", "(", "value", ".", "size", "(", ")", ",", "device", "=", "value", ".", "device", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "model", "(", "prev", ",", "past", "=", "past", ")", "\n", "_", ",", "past", ",", "cur_hid", "=", "out", "[", ":", "3", "]", "\n", "cur_hid", "=", "torch", ".", "stack", "(", "cur_hid", "[", "1", ":", "]", ",", "-", "1", ")", "\n", "cur_hid", "=", "cur_hid", "[", ":", ",", "-", "1", ",", "...", "]", "\n", "if", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "                    ", "last_value", "=", "self", ".", "model", ".", "value", "(", "cur_hid", ")", "\n", "", "else", ":", "\n", "                    ", "last_value", "=", "torch", ".", "zeros", "(", "value", ".", "size", "(", ")", ",", "device", "=", "value", ".", "device", ")", "\n", "\n", "", "", "", "continuation_logits", "=", "torch", ".", "stack", "(", "continuation_logits", ",", "1", ")", "\n", "\n", "contin", "=", "output", "[", ":", ",", "self", ".", "prefix_length", ":", "]", ".", "view", "(", "\n", "n_sent", ",", "self", ".", "n_samples", ",", "self", ".", "continuation_length", ")", ".", "data", "\n", "values", "=", "values", ".", "view", "(", "n_sent", ",", "self", ".", "n_samples", ",", "self", ".", "continuation_length", ")", "\n", "hidden", "=", "hidden", ".", "view", "(", "n_sent", ",", "self", ".", "n_samples", ",", "\n", "self", ".", "continuation_length", ",", "-", "1", ",", "12", ")", "\n", "last_value", "=", "last_value", ".", "view", "(", "n_sent", ",", "self", ".", "n_samples", ")", ".", "data", "\n", "\n", "rewards", "=", "self", ".", "_calc_rewards", "(", "context", ",", "contin", ")", "\n", "values", "=", "values", ".", "resize", "(", "n_sent", ",", "self", ".", "n_samples", ",", "\n", "self", ".", "n_gather", ",", "rewards", ".", "size", "(", "-", "1", ")", ")", "\n", "values", "=", "values", ".", "mean", "(", "-", "2", ")", "\n", "\n", "advantages", "=", "self", ".", "_calc_advantages", "(", "rewards", ",", "values", ",", "last_value", ")", ".", "data", "\n", "total_rewards", "=", "self", ".", "_calc_total_rewards", "(", "rewards", ")", ".", "data", "\n", "\n", "samples", "=", "{", "\n", "'obs'", ":", "output", ".", "view", "(", "n_sent", ",", "self", ".", "n_samples", ",", "-", "1", ")", ",", "\n", "'hidden'", ":", "hidden", ",", "\n", "'actions'", ":", "contin", ",", "\n", "'log_pis'", ":", "log_probs", ".", "view", "(", "n_sent", ",", "self", ".", "n_samples", ",", "self", ".", "continuation_length", ")", ",", "\n", "'values'", ":", "values", ",", "\n", "'last_value'", ":", "last_value", ",", "\n", "'total_rewards'", ":", "total_rewards", ",", "\n", "'advantages'", ":", "advantages", "\n", "}", "\n", "\n", "ntokens", "=", "contin", ".", "contiguous", "(", ")", ".", "numel", "(", ")", "\n", "\n", "logging_output", "=", "{", "\n", "'seq_sample_size'", ":", "ntokens", ",", "\n", "'seq_ntokens'", ":", "ntokens", ",", "\n", "'seq_nsentences'", ":", "n_sent", "*", "self", ".", "n_samples", "\n", "}", "\n", "stats", "=", "defaultdict", "(", "float", ")", "\n", "for", "x", "in", "contin", ":", "\n", "            ", "for", "y", "in", "x", ":", "\n", "                ", "tok_list", "=", "y", ".", "contiguous", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "ms", "=", "ngram_metrics", "(", "tok_list", ",", "pad", "=", "-", "1", ")", "\n", "for", "k", ",", "v", "in", "ms", ".", "items", "(", ")", ":", "\n", "                    ", "stats", "[", "k", "]", "+=", "v", "\n", "", "", "", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", ":", "\n", "            ", "logging_output", "[", "k", "]", "=", "v", "\n", "\n", "", "return", "samples", ",", "n_sent", ",", "logging_output", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_rewards": [[179, 244], ["context.size", "range", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "contin[].tolist", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "time_reward_pg.TimeRewardTrainer._calc_rewards.split_on_ngrams"], "methods", ["None"], ["", "def", "_calc_rewards", "(", "self", ",", "context", ":", "torch", ".", "LongTensor", ",", "\n", "contin", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "continuation_length", "=", "self", ".", "continuation_length", "\n", "n_sent", "=", "context", ".", "size", "(", "0", ")", "\n", "\n", "if", "self", ".", "n_gather", ">", "1", ":", "\n", "            ", "rewards", "=", "torch", ".", "zeros", "(", "\n", "n_sent", ",", "\n", "self", ".", "n_samples", ",", "\n", "continuation_length", "//", "\n", "self", ".", "n_gather", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "rewards", "=", "torch", ".", "zeros", "(", "\n", "n_sent", ",", "\n", "self", ".", "n_samples", ",", "\n", "continuation_length", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "if", "self", ".", "reward_type", "==", "'seq_rep'", ":", "\n", "                ", "rewards_to_go", "=", "torch", ".", "zeros", "(", "\n", "n_sent", ",", "\n", "self", ".", "n_samples", ",", "\n", "continuation_length", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "n_sent", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "n_samples", ")", ":", "\n", "#                 if self.n_gather > 1:", "\n", "#                     split = [(context[i].tolist() + contin[i, j, t : t + self.n_gather].tolist())", "\n", "#                              for t in range(continuation_length // self.n_gather)]", "\n", "#                     for t in range(len(split)):", "\n", "#                         rewards[i, j, t] = 1 - ngram_metrics(split[t], pad=-1)['pct_repeat_3grams']", "\n", "#                 else:", "\n", "                ", "for", "t", "in", "range", "(", "continuation_length", ")", ":", "\n", "                    ", "seq", "=", "contin", "[", "i", ",", "j", ",", "t", ":", "]", ".", "tolist", "(", ")", "\n", "\n", "def", "split_on_ngrams", "(", "l", ",", "n", ")", ":", "return", "[", "\n", "l", "[", "m", ":", "m", "+", "n", "]", "for", "m", "in", "range", "(", "len", "(", "l", ")", "-", "n", ")", "]", "\n", "\n", "if", "self", ".", "reward_type", "==", "'reward_for_past'", ":", "\n", "                        ", "hist", "=", "(", "context", "[", "i", ",", ":", "]", ".", "tolist", "(", ")", "+", "\n", "contin", "[", "i", ",", "j", ",", ":", "t", "]", ".", "tolist", "(", ")", ")", "\n", "cur_ngram", "=", "(", "context", "[", "i", ",", ":", "]", ".", "tolist", "(", "\n", ")", "+", "contin", "[", "i", ",", "j", ",", ":", "t", "+", "1", "]", ".", "tolist", "(", ")", ")", "[", "-", "self", ".", "n_of_gram", ":", "]", "\n", "hist_ngrams", "=", "split_on_ngrams", "(", "hist", ",", "self", ".", "n_of_gram", ")", "\n", "rewards", "[", "i", ",", "j", ",", "t", "]", "=", "1", "if", "cur_ngram", "not", "in", "hist_ngrams", "else", "0", "\n", "\n", "", "elif", "self", ".", "reward_type", "==", "'reward_for_future'", ":", "\n", "                        ", "cur_ngram", "=", "(", "context", "[", "i", ",", ":", "]", ".", "tolist", "(", "\n", ")", "+", "contin", "[", "i", ",", "j", ",", ":", "t", "+", "1", "]", ".", "tolist", "(", ")", ")", "[", "-", "self", ".", "n_of_gram", ":", "]", "\n", "future", "=", "contin", "[", "i", ",", "j", ",", "t", "+", "1", ":", "]", ".", "tolist", "(", ")", "\n", "future_ngrams", "=", "split_on_ngrams", "(", "future", ",", "self", ".", "n_of_gram", ")", "\n", "rewards", "[", "i", ",", "j", ",", "t", "]", "=", "1", "if", "cur_ngram", "not", "in", "future_ngrams", "else", "0", "\n", "#                         elif self.reward_type == 'window':", "\n", "#                             seq = (context[i].tolist() + contin[i, j, :t].tolist())", "\n", "#                             rewards[i, j, t] = 1 - ngram_metrics(seq[-32:], pad=-1)['pct_repeat_1grams']", "\n", "#                         elif self.reward_type == 'seq_rep':", "\n", "#                             rewards_to_go[i, j, t] = 1. - ngram_metrics(seq, pad=-1)['pct_repeat_3grams']", "\n", "#                             if t > 0 and continuation_length - t >= 4:", "\n", "#                                 rewards[i, j, t-1] = rewards_to_go[i, j, t-1] - rewards_to_go[i, j, t]", "\n", "#                             elif continuation_length - t < 4:", "\n", "#                                 rewards[i, j, t-1] = rewards[i, j, t-2]", "\n", "#                         elif self.reward_type == 'pure_seq_rep':", "\n", "#                             rewards[i, j, t] = 1. - ngram_metrics(contin[i, j].tolist(), pad=-1)['pct_repeat_4grams']", "\n", "", "", "", "", "return", "rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_advantages": [[245, 265], ["rewards.size", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "reversed", "range", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "_calc_advantages", "(", "self", ",", "rewards", ":", "torch", ".", "FloatTensor", ",", "\n", "values", ":", "torch", ".", "FloatTensor", ",", "\n", "last_value", ":", "torch", ".", "FloatTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "continuation_length", "=", "rewards", ".", "size", "(", "-", "1", ")", "\n", "advantages", "=", "torch", ".", "zeros_like", "(", "rewards", ",", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "last_advantage", "=", "0", "\n", "renorm_coef", "=", "1", "\n", "\n", "for", "t", "in", "reversed", "(", "range", "(", "continuation_length", ")", ")", ":", "\n", "            ", "delta", "=", "rewards", "[", ":", ",", ":", ",", "t", "]", "+", "self", ".", "gamma", "*", "last_value", "-", "values", "[", ":", ",", ":", ",", "t", "]", "*", "renorm_coef", "\n", "\n", "last_advantage", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "lamda", "*", "last_advantage", "\n", "advantages", "[", ":", ",", ":", ",", "t", "]", "=", "last_advantage", "\n", "last_value", "=", "values", "[", ":", ",", ":", ",", "t", "]", "*", "renorm_coef", "\n", "\n", "if", "self", ".", "psy_type", "==", "'advantage'", "and", "self", ".", "reward_type", "!=", "'seq_rep'", ":", "\n", "                ", "renorm_coef", "=", "1", "+", "self", ".", "gamma", "*", "renorm_coef", "\n", "\n", "", "", "return", "advantages", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._calc_total_rewards": [[266, 282], ["rewards.size", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "torch.zeros_like().float", "reversed", "range", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "_calc_total_rewards", "(", "self", ",", "rewards", ":", "torch", ".", "FloatTensor", "\n", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "continuation_length", "=", "rewards", ".", "size", "(", "-", "1", ")", "\n", "prev_step", "=", "0", "\n", "total_rewards", "=", "torch", ".", "zeros_like", "(", "rewards", ",", "device", "=", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "norm_coef", "=", "1", "\n", "for", "t", "in", "reversed", "(", "range", "(", "continuation_length", ")", ")", ":", "\n", "            ", "total_rewards", "[", ":", ",", ":", ",", "t", "]", "=", "1.", "/", "norm_coef", "*", "(", "rewards", "[", ":", ",", ":", ",", "t", "]", "+", "self", ".", "gamma", "*", "prev_step", ")", "\n", "prev_step", "=", "rewards", "[", ":", ",", ":", ",", "t", "]", "+", "self", ".", "gamma", "*", "prev_step", "\n", "\n", "if", "self", ".", "psy_type", "==", "'advantage'", "and", "self", ".", "reward_type", "!=", "'seq_rep'", ":", "\n", "                ", "norm_coef", "=", "1", "+", "self", ".", "gamma", "*", "norm_coef", "\n", "\n", "", "", "return", "total_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.train": [[283, 324], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "samples.items", "time_reward_pg.TimeRewardTrainer.step", "torch.stack.append", "torch.stack.append", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "range", "samples.items", "time_reward_pg.TimeRewardTrainer.step", "torch.stack.append", "torch.stack.append"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step"], ["", "def", "train", "(", "\n", "self", ",", "\n", "samples", ",", "\n", "filter_method", ":", "callable", ",", "\n", "progress", ":", "float", ",", "\n", "args", ",", "\n", "make_step", ":", "bool", "=", "True", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "train_info", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "if", "self", ".", "n_samples", ">", "1", ":", "\n", "                ", "for", "episode_id", "in", "range", "(", "self", ".", "mini_batch_size", ")", ":", "\n", "                    ", "indexes", "=", "torch", ".", "randperm", "(", "self", ".", "n_samples", ")", "\n", "for", "start", "in", "range", "(", "\n", "0", ",", "self", ".", "n_samples", ",", "self", ".", "mini_batch_size", ")", ":", "\n", "                        ", "end", "=", "start", "+", "self", ".", "mini_batch_size", "\n", "mini_batch_indexes", "=", "indexes", "[", "start", ":", "end", "]", "\n", "mini_batch", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "samples", ".", "items", "(", ")", ":", "\n", "                            ", "mini_batch", "[", "k", "]", "=", "v", "[", "episode_id", ",", "\n", "mini_batch_indexes", ",", "...", "]", "\n", "", "res", "=", "self", ".", "step", "(", "mini_batch", ",", "\n", "args", ".", "ratio_clip_range", ",", "\n", "filter_method", ",", "\n", "progress", ",", "\n", "make_step", ")", "\n", "train_info", ".", "append", "(", "res", ")", "\n", "", "", "", "else", ":", "\n", "                ", "mini_batch", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "samples", ".", "items", "(", ")", ":", "\n", "                    ", "mini_batch", "[", "k", "]", "=", "v", "[", ":", ",", "0", ",", "...", "]", "\n", "", "res", "=", "self", ".", "step", "(", "mini_batch", ",", "\n", "args", ".", "ratio_clip_range", ",", "\n", "filter_method", ",", "\n", "progress", ",", "\n", "make_step", ")", "\n", "train_info", ".", "append", "(", "res", ")", "\n", "\n", "", "", "train_info", "=", "torch", ".", "stack", "(", "train_info", ",", "dim", "=", "0", ")", "\n", "\n", "return", "torch", ".", "mean", "(", "train_info", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step": [[325, 420], ["torch.min.mean", "torch.min.mean", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "time_reward_pg.TimeRewardTrainer._normalize", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "value.mean.mean.resize", "value.mean.mean.mean", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.log_prob", "torch.distributions.categorical.Categorical.log_prob", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "ratio.mean.mean.resize", "ratio.mean.mean.mean", "ratio.mean.mean.clamp", "torch.min", "torch.min", "torch.min", "torch.min", "log_pi.sum.sum.resize", "log_pi.sum.sum.sum", "time_reward_pg.TimeRewardTrainer.optimizer.zero_grad", "time_reward_pg.TimeRewardTrainer.value_loss", "vf_loss.item.item.backward", "vf_loss.item.item.item", "loss.backward", "loss.backward", "time_reward_pg.TimeRewardTrainer.optimizer.step", "time_reward_pg.TimeRewardTrainer.model.gpt2_model.lm_head", "torch.distributions.categorical.Categorical.append", "torch.distributions.categorical.Categorical.append", "value.mean.mean.append", "value.mean.mean.size", "total_rewards.size", "ratio.mean.mean.size", "total_rewards.size", "log_pi.sum.sum.size", "psy.size", "loss.item", "torch.min.item", "torch.min.item", "value.mean.mean.mean().item", "total_rewards.mean", "total_rewards.std", "filter_method", "time_reward_pg.TimeRewardTrainer.model.value().squeeze().view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "time_reward_pg.TimeRewardTrainer.model.parameters", "value.mean.mean.mean", "time_reward_pg.TimeRewardTrainer.model.value().squeeze", "time_reward_pg.TimeRewardTrainer.model.value"], "methods", ["home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._normalize", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer.step", "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.policy_value.PolicyValueModel.value"], ["", "def", "step", "(", "self", ",", "\n", "samples", ":", "dict", ",", "\n", "clip_range", ":", "float", ",", "\n", "filter_method", ":", "callable", ",", "\n", "progress", ":", "float", ",", "\n", "make_step", ":", "bool", "=", "True", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "\n", "        ", "input_ids", "=", "samples", "[", "'obs'", "]", "\n", "hidden", "=", "samples", "[", "'hidden'", "]", "\n", "sampled_action", "=", "samples", "[", "'actions'", "]", "\n", "sampled_return", "=", "samples", "[", "'values'", "]", "+", "samples", "[", "'advantages'", "]", "\n", "sampled_advantage", "=", "self", ".", "_normalize", "(", "\n", "samples", "[", "'advantages'", "]", ")", "if", "self", ".", "n_samples", ">", "1", "else", "samples", "[", "'advantages'", "]", "\n", "sampled_neg_log_pi", "=", "-", "samples", "[", "'log_pis'", "]", "\n", "sampled_value", "=", "samples", "[", "'values'", "]", "\n", "total_rewards", "=", "samples", "[", "'total_rewards'", "]", "\n", "\n", "if", "self", ".", "psy_type", "==", "'reward'", ":", "\n", "            ", "psy", "=", "(", "total_rewards", "-", "total_rewards", ".", "mean", "(", "0", ")", ")", "/", "(", "total_rewards", ".", "std", "(", "0", ")", "+", "1e-8", ")", "\n", "", "elif", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "            ", "psy", "=", "sampled_advantage", "\n", "\n", "", "if", "self", ".", "epochs", ">", "1", ":", "\n", "            ", "sampled_value", "=", "sampled_value", ".", "data", "\n", "sampled_neg_log_pi", "=", "sampled_neg_log_pi", ".", "data", "\n", "pi", "=", "[", "]", "\n", "cl_pi", "=", "[", "]", "\n", "value", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "continuation_length", ")", ":", "\n", "                ", "hid", "=", "hidden", "[", ":", ",", "t", ",", "...", "]", "\n", "logits", "=", "self", ".", "model", ".", "gpt2_model", ".", "lm_head", "(", "hid", "[", "...", ",", "-", "1", "]", ")", "\n", "pi", ".", "append", "(", "filter_method", "(", "logits", ")", ")", "\n", "value", ".", "append", "(", "self", ".", "model", ".", "value", "(", "hid", ")", ".", "squeeze", "(", "-", "1", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "value", "=", "torch", ".", "stack", "(", "value", ",", "1", ")", "\n", "value", "=", "value", ".", "resize", "(", "value", ".", "size", "(", "\n", "0", ")", ",", "self", ".", "n_gather", ",", "total_rewards", ".", "size", "(", "-", "1", ")", ")", "\n", "value", "=", "value", ".", "mean", "(", "-", "2", ")", "\n", "\n", "pi", "=", "torch", ".", "stack", "(", "pi", ",", "1", ")", ".", "squeeze", "(", "2", ")", "\n", "pi", "=", "Categorical", "(", "logits", "=", "pi", ")", "\n", "\n", "log_pi", "=", "pi", ".", "log_prob", "(", "sampled_action", ")", "\n", "\n", "ratio", ":", "torch", ".", "Tensor", "=", "torch", ".", "exp", "(", "sampled_neg_log_pi", "+", "log_pi", ")", "\n", "\n", "ratio", "=", "ratio", ".", "resize", "(", "ratio", ".", "size", "(", "\n", "0", ")", ",", "self", ".", "n_gather", ",", "total_rewards", ".", "size", "(", "-", "1", ")", ")", "\n", "ratio", "=", "ratio", ".", "mean", "(", "-", "2", ")", "\n", "\n", "clipped_ratio", "=", "ratio", ".", "clamp", "(", "min", "=", "1.0", "-", "clip_range", ",", "\n", "max", "=", "1.0", "+", "clip_range", ")", "\n", "policy_reward", "=", "torch", ".", "min", "(", "ratio", "*", "psy", ",", "\n", "clipped_ratio", "*", "psy", ")", "\n", "", "else", ":", "\n", "            ", "log_pi", "=", "-", "sampled_neg_log_pi", "\n", "log_pi", "=", "log_pi", ".", "resize", "(", "log_pi", ".", "size", "(", "0", ")", ",", "self", ".", "n_gather", ",", "psy", ".", "size", "(", "-", "1", ")", ")", "\n", "log_pi", "=", "log_pi", ".", "sum", "(", "-", "2", ")", "\n", "policy_reward", "=", "log_pi", "*", "psy", "\n", "value", "=", "sampled_value", "\n", "\n", "", "policy_reward", "=", "policy_reward", ".", "mean", "(", ")", "\n", "\n", "clipped_value", "=", "sampled_value", "+", "(", "value", "-", "sampled_value", ")", ".", "clamp", "(", "min", "=", "-", "clip_range", ",", "max", "=", "clip_range", ")", "\n", "\n", "if", "make_step", "is", "True", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "self", ".", "psy_type", "==", "'advantage'", ":", "\n", "            ", "vf_loss", "=", "self", ".", "value_loss", "(", "value", ",", "total_rewards", ")", "\n", "vf_loss", ".", "backward", "(", ")", "\n", "vf_loss", "=", "vf_loss", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "vf_loss", "=", "0", "\n", "\n", "", "loss", ":", "torch", ".", "Tensor", "=", "-", "(", "policy_reward", "*", "progress", "**", "2", ")", "/", "self", ".", "epochs", "\n", "\n", "if", "self", ".", "epochs", ">", "1", ":", "\n", "            ", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", "\n", ")", "if", "p", ".", "name", "!=", "'value_head'", "]", ",", "max_norm", "=", "self", ".", "max_grad_norm", ")", "\n", "\n", "if", "make_step", ":", "\n", "            ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "[", "loss", ".", "item", "(", ")", ",", "\n", "policy_reward", ".", "item", "(", ")", ",", "\n", "vf_loss", ",", "\n", "value", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.vklabmipt_implicit-unlikelihood-training.src.time_reward_pg.TimeRewardTrainer._normalize": [[422, 426], ["adv.mean().mean", "adv.std().std", "adv.mean", "adv.std"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_normalize", "(", "adv", ":", "torch", ".", "FloatTensor", ")", ":", "\n", "        ", "return", "(", "adv", "-", "adv", ".", "mean", "(", "dim", "=", "-", "1", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", ")", "/", "(", "adv", ".", "std", "(", "dim", "=", "-", "1", ")", ".", "std", "(", "dim", "=", "-", "1", ")", "+", "1e-8", ")", "\n", "", "", ""]]}