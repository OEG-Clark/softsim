{"home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.ReplayBuffer.__init__": [[11, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "extra_content", ")", ":", "\n", "        ", "\"\"\"Create Replay buffer.\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "size", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n", "# determines the # of first N samples to be preserved forever - set after adding samples", "\n", "self", ".", "n_preserved", "=", "0", "\n", "\n", "self", ".", "extra_content", "=", "extra_content", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.ReplayBuffer.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.ReplayBuffer.add": [[31, 60], ["tuple", "tuple.append", "len", "universal_replay_buffer.ReplayBuffer._storage.append", "int", "int"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "transition", ")", ":", "# obs_t, action, reward, obs_tp1, done, *args, **kwargs)", "\n", "        ", "old_data", "=", "None", "\n", "\n", "data", "=", "[", "\n", "transition", "[", "'obs'", "]", ",", "\n", "transition", "[", "'action'", "]", ",", "\n", "transition", "[", "'reward'", "]", ",", "\n", "transition", "[", "'obs_next'", "]", ",", "\n", "transition", "[", "'done'", "]", "\n", "]", "\n", "\n", "for", "content", "in", "self", ".", "extra_content", ":", "\n", "            ", "data", ".", "append", "(", "transition", "[", "content", "]", ")", "\n", "\n", "", "data", "=", "tuple", "(", "data", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "old_data", "=", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "\n", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "\n", "", "if", "self", ".", "n_preserved", ">", "0", ":", "\n", "            ", "self", ".", "_next_idx", "=", "self", ".", "n_preserved", "+", "int", "(", "(", "self", ".", "_next_idx", "+", "1", "-", "self", ".", "n_preserved", ")", "%", "(", "self", ".", "_maxsize", "-", "self", ".", "n_preserved", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_next_idx", "=", "int", "(", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", ")", "\n", "\n", "", "return", "old_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.ReplayBuffer._encode_sample": [[61, 98], ["sample[].append", "sample[].append", "sample[].append", "sample[].append", "sample[].append", "enumerate", "numpy.array", "numpy.array", "numpy.array", "sample[].append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ",", "in_numpy_form", ")", ":", "\n", "        ", "sample", "=", "{", "\n", "'obs_t'", ":", "[", "]", ",", "\n", "'action'", ":", "[", "]", ",", "\n", "'reward'", ":", "[", "]", ",", "\n", "'obs_tp1'", ":", "[", "]", ",", "\n", "'done'", ":", "[", "]", "\n", "}", "\n", "\n", "for", "content", "in", "self", ".", "extra_content", ":", "\n", "            ", "sample", "[", "content", "]", "=", "[", "]", "\n", "\n", "", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "\n", "sample", "[", "'obs_t'", "]", ".", "append", "(", "np", ".", "array", "(", "data", "[", "0", "]", ",", "copy", "=", "False", ")", ")", "\n", "sample", "[", "'action'", "]", ".", "append", "(", "np", ".", "array", "(", "data", "[", "1", "]", ",", "copy", "=", "False", ")", ")", "\n", "sample", "[", "'reward'", "]", ".", "append", "(", "data", "[", "2", "]", ")", "\n", "sample", "[", "'obs_tp1'", "]", ".", "append", "(", "np", ".", "array", "(", "data", "[", "3", "]", ",", "copy", "=", "False", ")", ")", "\n", "sample", "[", "'done'", "]", ".", "append", "(", "data", "[", "4", "]", ")", "\n", "\n", "for", "j", ",", "content", "in", "enumerate", "(", "self", ".", "extra_content", ")", ":", "\n", "                ", "sample", "[", "content", "]", ".", "append", "(", "data", "[", "5", "+", "j", "]", ")", "\n", "\n", "", "", "extra_content", "=", "{", "}", "\n", "for", "content", "in", "self", ".", "extra_content", ":", "\n", "            ", "if", "in_numpy_form", ":", "\n", "                ", "extra_content", "[", "content", "]", "=", "np", ".", "array", "(", "sample", "[", "content", "]", ")", "\n", "", "else", ":", "\n", "                ", "extra_content", "[", "content", "]", "=", "sample", "[", "content", "]", "\n", "\n", "", "", "if", "in_numpy_form", ":", "\n", "            ", "return", "np", ".", "array", "(", "sample", "[", "'obs_t'", "]", ")", ",", "np", ".", "array", "(", "sample", "[", "'action'", "]", ")", ",", "np", ".", "array", "(", "sample", "[", "'reward'", "]", ")", ",", "np", ".", "array", "(", "sample", "[", "'obs_tp1'", "]", ")", ",", "np", ".", "array", "(", "sample", "[", "'done'", "]", ")", ",", "extra_content", "\n", "", "else", ":", "\n", "            ", "return", "sample", "[", "'obs_t'", "]", ",", "sample", "[", "'action'", "]", ",", "sample", "[", "'reward'", "]", ",", "sample", "[", "'obs_tp1'", "]", ",", "sample", "[", "'done'", "]", ",", "extra_content", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.ReplayBuffer.sample": [[100, 122], ["universal_replay_buffer.ReplayBuffer._encode_sample", "random.randint", "range", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ",", "in_numpy_form", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "idxes", "=", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "return", "self", ".", "_encode_sample", "(", "idxes", ",", "in_numpy_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.PrioritizedReplayBuffer.__init__": [[124, 149], ["universal_replay_buffer.ReplayBuffer.__init__", "segment_tree.SumSegmentTree", "segment_tree.MinSegmentTree"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "extra_content", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        alpha: float\n            how much prioritization is used\n            (0 - no prioritization, 1 - full prioritization)\n        See Also\n        --------\n        ReplayBuffer.__init__\n        \"\"\"", "\n", "super", "(", "PrioritizedReplayBuffer", ",", "self", ")", ".", "__init__", "(", "size", ",", "extra_content", ")", "\n", "assert", "alpha", ">=", "0", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "\n", "it_capacity", "=", "1", "\n", "while", "it_capacity", "<", "size", ":", "\n", "            ", "it_capacity", "*=", "2", "\n", "\n", "", "self", ".", "_it_sum", "=", "SumSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_it_min", "=", "MinSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_max_priority", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.PrioritizedReplayBuffer.add": [[150, 160], ["universal_replay_buffer.ReplayBuffer.add"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.add"], ["", "def", "add", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"See ReplayBuffer.store_effect\"\"\"", "\n", "\n", "idx", "=", "self", ".", "_next_idx", "\n", "old_data", "=", "super", "(", ")", ".", "add", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_it_sum", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha", "\n", "self", ".", "_it_min", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha", "\n", "\n", "return", "old_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.PrioritizedReplayBuffer._sample_proportional": [[163, 178], ["universal_replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "range", "random.random", "numpy.float32", "universal_replay_buffer.PrioritizedReplayBuffer._it_sum.find_prefixsum_idx", "res.append", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.find_prefixsum_idx"], ["", "def", "_sample_proportional", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "p_total", "=", "self", ".", "_it_sum", ".", "sum", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "\n", "#if i == 0:", "\n", "#print(len(self._storage) - 1, p_total)", "\n", "every_range_len", "=", "p_total", "/", "batch_size", "\n", "#print('sampling...', len(self._storage))", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "r", "=", "random", ".", "random", "(", ")", "\n", "mass", "=", "np", ".", "float32", "(", "r", "*", "every_range_len", "+", "i", "*", "every_range_len", ")", "\n", "#if i == 0:", "\n", "#    print(r, every_range_len, p_total, len(self._storage)) # p_total is different", "\n", "idx", "=", "self", ".", "_it_sum", ".", "find_prefixsum_idx", "(", "mass", ")", "\n", "res", ".", "append", "(", "idx", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.PrioritizedReplayBuffer.sample": [[179, 226], ["universal_replay_buffer.PrioritizedReplayBuffer._sample_proportional", "numpy.array", "universal_replay_buffer.PrioritizedReplayBuffer._encode_sample", "tuple", "universal_replay_buffer.PrioritizedReplayBuffer._it_min.min", "universal_replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "numpy.array.append", "len", "universal_replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "list", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer._sample_proportional", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "beta", ",", "in_numpy_form", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n        compared to ReplayBuffer.sample\n        it also returns importance weights and idxes\n        of sampled experiences.\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n        beta: float\n            To what degree to use importance weights\n            (0 - no corrections, 1 - full correction)\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        weights: np.array\n            Array of shape (batch_size,) and dtype np.float32\n            denoting importance weight of each sampled transition\n        idxes: np.array\n            Array of shape (batch_size,) and dtype np.int32\n            idexes in buffer of sampled experiences\n        \"\"\"", "\n", "assert", "beta", ">", "0", "\n", "\n", "idxes", "=", "self", ".", "_sample_proportional", "(", "batch_size", ")", "\n", "\n", "weights", "=", "[", "]", "\n", "p_min", "=", "self", ".", "_it_min", ".", "min", "(", ")", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "max_weight", "=", "(", "p_min", "*", "len", "(", "self", ".", "_storage", ")", ")", "**", "(", "-", "beta", ")", "\n", "\n", "for", "idx", "in", "idxes", ":", "\n", "            ", "p_sample", "=", "self", ".", "_it_sum", "[", "idx", "]", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "weight", "=", "(", "p_sample", "*", "len", "(", "self", ".", "_storage", ")", ")", "**", "(", "-", "beta", ")", "\n", "weights", ".", "append", "(", "weight", "/", "max_weight", ")", "\n", "", "weights", "=", "np", ".", "array", "(", "weights", ")", "\n", "encoded_sample", "=", "self", ".", "_encode_sample", "(", "idxes", ",", "in_numpy_form", ")", "\n", "return", "tuple", "(", "list", "(", "encoded_sample", ")", "+", "[", "weights", ",", "idxes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.universal_replay_buffer.PrioritizedReplayBuffer.update_priorities": [[227, 248], ["zip", "len", "len", "max", "len"], "methods", ["None"], ["", "def", "update_priorities", "(", "self", ",", "idxes", ",", "priorities", ")", ":", "\n", "        ", "\"\"\"Update priorities of sampled transitions.\n        sets priority of transition at index idxes[i] in buffer\n        to priorities[i].\n        Parameters\n        ----------\n        idxes: [int]\n            List of idxes of sampled transitions\n        priorities: [float]\n            List of updated priorities corresponding to\n            transitions at the sampled idxes denoted by\n            variable `idxes`.\n        \"\"\"", "\n", "assert", "len", "(", "idxes", ")", "==", "len", "(", "priorities", ")", "\n", "for", "idx", ",", "priority", "in", "zip", "(", "idxes", ",", "priorities", ")", ":", "\n", "            ", "assert", "priority", ">", "0", "\n", "assert", "0", "<=", "idx", "<", "len", "(", "self", ".", "_storage", ")", "\n", "self", ".", "_it_sum", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "\n", "self", ".", "_it_min", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "\n", "\n", "self", ".", "_max_priority", "=", "max", "(", "self", ".", "_max_priority", ",", "priority", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.__init__": [[5, 189], ["tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "tensorflow.compat.v1.Variable", "run_statistics.Statistics.setup_summary_steps", "run_statistics.Statistics.setup_summary_episode", "run_statistics.Statistics.setup_summary_evaluation", "run_statistics.Statistics.setup_summary_rm_evaluation", "run_statistics.Statistics.loss_var.assign", "run_statistics.Statistics.epsilon_var.assign", "run_statistics.Statistics.exploration_steps_taken_var.assign", "run_statistics.Statistics.exploration_steps_taken_cum_var.assign", "run_statistics.Statistics.advices_taken_var.assign", "run_statistics.Statistics.advices_taken_cum_var.assign", "run_statistics.Statistics.advices_used_var.assign", "run_statistics.Statistics.advices_used_cum_var.assign", "run_statistics.Statistics.advices_reused_var.assign", "run_statistics.Statistics.advices_reused_cum_var.assign", "run_statistics.Statistics.advices_reused_correct_var.assign", "run_statistics.Statistics.advices_reused_correct_cum_var.assign", "run_statistics.Statistics.steps_reward_var.assign", "run_statistics.Statistics.steps_reward_auc_var.assign", "run_statistics.Statistics.steps_error_in_var.assign", "run_statistics.Statistics.steps_error_out_var.assign", "run_statistics.Statistics.episode_reward_var.assign", "run_statistics.Statistics.episode_reward_auc_var.assign", "run_statistics.Statistics.episode_duration_var.assign", "run_statistics.Statistics.episode_error_in_var.assign", "run_statistics.Statistics.episode_error_out_var.assign", "run_statistics.Statistics.evaluation_reward_var.assign", "run_statistics.Statistics.evaluation_duration_var.assign", "run_statistics.Statistics.evaluation_reward_auc_var.assign", "run_statistics.Statistics.rm_uncertainty_self_var.assign", "run_statistics.Statistics.rm_uncertainty_12_var.assign", "run_statistics.Statistics.rm_uncertainty_22_var.assign"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_steps", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_episode", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_evaluation", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_rm_evaluation"], ["    ", "def", "__init__", "(", "self", ",", "summary_writer", ",", "session", ")", ":", "\n", "\n", "        ", "self", ".", "n_steps_per_update", "=", "100", "\n", "\n", "self", ".", "summary_writer", "=", "summary_writer", "\n", "self", ".", "session", "=", "session", "\n", "\n", "self", ".", "n_evaluations", "=", "0", "\n", "\n", "# Number of environment interactions", "\n", "self", ".", "n_env_steps", "=", "0", "\n", "self", ".", "n_env_steps_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0", ")", "\n", "\n", "# Number of episodes", "\n", "self", ".", "n_episodes", "=", "0", "\n", "self", ".", "n_episodes_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0", ")", "\n", "\n", "self", ".", "loss", "=", "0.0", "\n", "self", ".", "loss_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "loss_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "epsilon", "=", "0.0", "\n", "self", ".", "epsilon_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "epsilon_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "exploration_steps_taken", "=", "0.0", "\n", "self", ".", "exploration_steps_taken_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "exploration_steps_taken_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "exploration_steps_taken_cum", "=", "0.0", "\n", "self", ".", "exploration_steps_taken_cum_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "exploration_steps_taken_cum_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Advice Exchange", "\n", "\n", "self", ".", "advices_taken", "=", "0", "\n", "self", ".", "advices_taken_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_taken_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "advices_taken_cum", "=", "0", "\n", "self", ".", "advices_taken_cum_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_taken_cum_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Advice use (Collect || Reuse)", "\n", "\n", "self", ".", "advices_used", "=", "0", "\n", "self", ".", "advices_used_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_used_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "advices_used_cum", "=", "0", "\n", "self", ".", "advices_used_cum_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_used_cum_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Advice Reuse", "\n", "\n", "self", ".", "advices_reused", "=", "0", "\n", "self", ".", "advices_reused_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_reused_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "advices_reused_cum", "=", "0", "\n", "self", ".", "advices_reused_cum_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_reused_cum_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "advices_reused_correct", "=", "0", "\n", "self", ".", "advices_reused_correct_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_reused_correct_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "advices_reused_correct_cum", "=", "0", "\n", "self", ".", "advices_reused_correct_cum_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.0", ")", "\n", "self", ".", "advices_reused_correct_cum_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "# Steps", "\n", "self", ".", "steps_reward_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "steps_reward_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "steps_error_in_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "steps_error_in_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "steps_error_out_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "steps_error_out_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "steps_reward_last", "=", "0.0", "\n", "self", ".", "steps_reward_auc", "=", "0.0", "\n", "self", ".", "steps_reward_auc_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "steps_reward_auc_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# Episodes", "\n", "self", ".", "episode_reward_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "episode_reward_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "episode_error_in_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "episode_error_in_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "episode_error_out_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "episode_error_out_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "episode_duration", "=", "0", "\n", "self", ".", "episode_duration_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "episode_duration_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "episode_reward_last", "=", "0.0", "\n", "self", ".", "episode_reward_auc", "=", "0.0", "\n", "self", ".", "episode_reward_auc_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "episode_reward_auc_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# Evaluation", "\n", "self", ".", "evaluation_reward_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "evaluation_reward_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "evaluation_duration", "=", "0", "\n", "self", ".", "evaluation_duration_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "evaluation_duration_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "self", ".", "evaluation_reward_last", "=", "0.0", "\n", "\n", "self", ".", "evaluation_reward_auc", "=", "0.0", "\n", "self", ".", "evaluation_reward_auc_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "evaluation_reward_auc_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ")", "\n", "\n", "# RM Evaluation", "\n", "self", ".", "rm_uncertainty_self", "=", "0.0", "\n", "self", ".", "rm_uncertainty_self_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "rm_uncertainty_self_ph", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "\n", "self", ".", "rm_uncertainty_12", "=", "0.0", "\n", "self", ".", "rm_uncertainty_12_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "rm_uncertainty_12_ph", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "\n", "self", ".", "rm_uncertainty_22", "=", "0.0", "\n", "self", ".", "rm_uncertainty_22_var", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "self", ".", "rm_uncertainty_22_ph", "=", "tf", ".", "compat", ".", "v1", ".", "Variable", "(", "0.", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "self", ".", "summary_op_steps", "=", "self", ".", "setup_summary_steps", "(", ")", "\n", "self", ".", "summary_op_episode", "=", "self", ".", "setup_summary_episode", "(", ")", "\n", "self", ".", "summary_op_evaluation", "=", "self", ".", "setup_summary_evaluation", "(", ")", "\n", "self", ".", "summary_op_rm_evaluation", "=", "self", ".", "setup_summary_rm_evaluation", "(", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "self", ".", "assignments_steps", "=", "[", "\n", "self", ".", "loss_var", ".", "assign", "(", "self", ".", "loss_ph", ")", ",", "\n", "self", ".", "epsilon_var", ".", "assign", "(", "self", ".", "epsilon_ph", ")", ",", "\n", "self", ".", "exploration_steps_taken_var", ".", "assign", "(", "self", ".", "exploration_steps_taken_ph", ")", ",", "\n", "self", ".", "exploration_steps_taken_cum_var", ".", "assign", "(", "self", ".", "exploration_steps_taken_cum_ph", ")", ",", "\n", "self", ".", "advices_taken_var", ".", "assign", "(", "self", ".", "advices_taken_ph", ")", ",", "\n", "self", ".", "advices_taken_cum_var", ".", "assign", "(", "self", ".", "advices_taken_cum_ph", ")", ",", "\n", "self", ".", "advices_used_var", ".", "assign", "(", "self", ".", "advices_used_ph", ")", ",", "\n", "self", ".", "advices_used_cum_var", ".", "assign", "(", "self", ".", "advices_used_cum_ph", ")", ",", "\n", "self", ".", "advices_reused_var", ".", "assign", "(", "self", ".", "advices_reused_ph", ")", ",", "\n", "self", ".", "advices_reused_cum_var", ".", "assign", "(", "self", ".", "advices_reused_cum_ph", ")", ",", "\n", "self", ".", "advices_reused_correct_var", ".", "assign", "(", "self", ".", "advices_reused_correct_ph", ")", ",", "\n", "self", ".", "advices_reused_correct_cum_var", ".", "assign", "(", "self", ".", "advices_reused_correct_cum_ph", ")", ",", "\n", "\n", "self", ".", "steps_reward_var", ".", "assign", "(", "self", ".", "steps_reward_ph", ")", ",", "\n", "self", ".", "steps_reward_auc_var", ".", "assign", "(", "self", ".", "steps_reward_auc_ph", ")", ",", "\n", "self", ".", "steps_error_in_var", ".", "assign", "(", "self", ".", "steps_error_in_ph", ")", ",", "\n", "self", ".", "steps_error_out_var", ".", "assign", "(", "self", ".", "steps_error_out_ph", ")", ",", "\n", "]", "\n", "\n", "self", ".", "assignments_episode", "=", "[", "\n", "self", ".", "episode_reward_var", ".", "assign", "(", "self", ".", "episode_reward_ph", ")", ",", "\n", "self", ".", "episode_reward_auc_var", ".", "assign", "(", "self", ".", "episode_reward_auc_ph", ")", ",", "\n", "self", ".", "episode_duration_var", ".", "assign", "(", "self", ".", "episode_duration_ph", ")", ",", "\n", "self", ".", "episode_error_in_var", ".", "assign", "(", "self", ".", "episode_error_in_ph", ")", ",", "\n", "self", ".", "episode_error_out_var", ".", "assign", "(", "self", ".", "episode_error_out_ph", ")", ",", "\n", "]", "\n", "\n", "self", ".", "assignments_evaluation", "=", "[", "\n", "self", ".", "evaluation_reward_var", ".", "assign", "(", "self", ".", "evaluation_reward_ph", ")", ",", "\n", "self", ".", "evaluation_duration_var", ".", "assign", "(", "self", ".", "evaluation_duration_ph", ")", ",", "\n", "self", ".", "evaluation_reward_auc_var", ".", "assign", "(", "self", ".", "evaluation_reward_auc_ph", ")", "\n", "]", "\n", "\n", "self", ".", "assignments_rm_evaluation", "=", "[", "\n", "self", ".", "rm_uncertainty_self_var", ".", "assign", "(", "self", ".", "rm_uncertainty_self_ph", ")", ",", "\n", "self", ".", "rm_uncertainty_12_var", ".", "assign", "(", "self", ".", "rm_uncertainty_12_ph", ")", ",", "\n", "self", ".", "rm_uncertainty_22_var", ".", "assign", "(", "self", ".", "rm_uncertainty_22_ph", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_steps": [[193, 225], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge"], "methods", ["None"], ["", "def", "setup_summary_steps", "(", "self", ")", ":", "\n", "        ", "loss_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Loss'", ",", "self", ".", "loss_var", ")", "\n", "epsilon_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Epsilon'", ",", "self", ".", "epsilon_var", ")", "\n", "\n", "exploration_steps_taken_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Exploration Steps Taken'", ",", "self", ".", "exploration_steps_taken_var", ")", "\n", "exploration_steps_taken_cum_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Exploration Steps Taken Cumulative'", ",", "self", ".", "exploration_steps_taken_cum_var", ")", "\n", "\n", "advices_taken_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Taken'", ",", "self", ".", "advices_taken_var", ")", "\n", "advices_taken_cumulative_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Taken Cumulative'", ",", "self", ".", "advices_taken_cum_var", ")", "\n", "\n", "advices_used_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Used'", ",", "self", ".", "advices_used_var", ")", "\n", "advices_used_cum_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Used Cumulative'", ",", "self", ".", "advices_used_cum_var", ")", "\n", "\n", "advices_reused_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Reused'", ",", "self", ".", "advices_reused_var", ")", "\n", "advices_reused_cum_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Reused Cumulative'", ",", "self", ".", "advices_reused_cum_var", ")", "\n", "\n", "advices_reused_correct_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Reused Correct'", ",", "self", ".", "advices_reused_correct_var", ")", "\n", "advices_reused_correct_cum_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Advices Reused Correct Cumulative'", ",", "self", ".", "advices_reused_correct_cum_var", ")", "\n", "\n", "steps_reward_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Reward/Steps'", ",", "self", ".", "steps_reward_var", ")", "\n", "steps_reward_auc_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Reward AUC/Steps'", ",", "self", ".", "steps_reward_auc_var", ")", "\n", "steps_error_in_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Error In/Steps'", ",", "self", ".", "steps_error_in_var", ")", "\n", "steps_error_out_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Error Out/Steps'", ",", "self", ".", "steps_error_out_var", ")", "\n", "\n", "to_be_merged", "=", "[", "loss_sc", ",", "epsilon_sc", ",", "advices_taken_sc", ",", "advices_taken_cumulative_sc", ",", "steps_reward_sc", ",", "\n", "steps_reward_auc_sc", ",", "exploration_steps_taken_sc", ",", "exploration_steps_taken_cum_sc", ",", "\n", "advices_used_sc", ",", "advices_used_cum_sc", ",", "\n", "advices_reused_sc", ",", "advices_reused_cum_sc", ",", "\n", "advices_reused_correct_sc", ",", "advices_reused_correct_cum_sc", ",", "\n", "steps_error_in_sc", ",", "steps_error_out_sc", "]", "\n", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "merge", "(", "to_be_merged", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_episode": [[228, 240], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge"], "methods", ["None"], ["", "def", "setup_summary_episode", "(", "self", ")", ":", "\n", "        ", "episode_reward_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Reward/Episode'", ",", "self", ".", "episode_reward_var", ")", "\n", "episode_reward_auc_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Reward AUC/Episode'", ",", "self", ".", "episode_reward_auc_var", ")", "\n", "episode_duration_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Episode Duration'", ",", "self", ".", "episode_duration_var", ")", "\n", "\n", "episode_error_in_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Error In/Episode'", ",", "self", ".", "episode_error_in_var", ")", "\n", "episode_error_out_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Error Out/Episode'", ",", "self", ".", "episode_error_out_var", ")", "\n", "\n", "to_be_merged", "=", "[", "episode_reward_sc", ",", "episode_reward_auc_sc", ",", "episode_duration_sc", ",", "\n", "episode_error_in_sc", ",", "episode_error_out_sc", "]", "\n", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "merge", "(", "to_be_merged", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_evaluation": [[243, 248], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge"], "methods", ["None"], ["", "def", "setup_summary_evaluation", "(", "self", ")", ":", "\n", "        ", "evaluation_reward_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Evaluation Reward'", ",", "self", ".", "evaluation_reward_var", ")", "\n", "evaluation_duration_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Evaluation Duration'", ",", "self", ".", "evaluation_duration_var", ")", "\n", "evaluation_reward_auc_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'Evaluation Reward AUC'", ",", "self", ".", "evaluation_reward_auc_var", ")", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "merge", "(", "[", "evaluation_reward_sc", ",", "evaluation_duration_sc", ",", "evaluation_reward_auc_sc", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.setup_summary_rm_evaluation": [[251, 256], ["tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.scalar", "tensorflow.compat.v1.summary.merge"], "methods", ["None"], ["", "def", "setup_summary_rm_evaluation", "(", "self", ")", ":", "\n", "        ", "rm_uncertainty_self_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'RM Uncertainty Self'", ",", "self", ".", "rm_uncertainty_self_var", ")", "\n", "rm_uncertainty_12_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'RM Uncertainty 12'", ",", "self", ".", "rm_uncertainty_12_var", ")", "\n", "rm_uncertainty_22_sc", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "scalar", "(", "'RM Uncertainty 22'", ",", "self", ".", "rm_uncertainty_22_var", ")", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "merge", "(", "[", "rm_uncertainty_self_sc", ",", "rm_uncertainty_12_sc", ",", "rm_uncertainty_22_sc", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_steps": [[259, 287], ["run_statistics.Statistics.session.run", "run_statistics.Statistics.session.run", "run_statistics.Statistics.summary_writer.add_summary"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "update_summary_steps", "(", "self", ",", "steps_reward", ",", "steps_reward_auc", ",", "steps_error_in", ",", "steps_error_out", ")", ":", "\n", "        ", "self", ".", "loss", "/=", "self", ".", "n_steps_per_update", "\n", "\n", "requested_ops", "=", "[", "assignment", "for", "assignment", "in", "self", ".", "assignments_steps", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "loss_ph", ":", "self", ".", "loss", ",", "\n", "self", ".", "epsilon_ph", ":", "self", ".", "epsilon", ",", "\n", "self", ".", "exploration_steps_taken_ph", ":", "self", ".", "exploration_steps_taken", ",", "\n", "self", ".", "exploration_steps_taken_cum_ph", ":", "self", ".", "exploration_steps_taken_cum", ",", "\n", "self", ".", "advices_taken_ph", ":", "self", ".", "advices_taken", ",", "\n", "self", ".", "advices_taken_cum_ph", ":", "self", ".", "advices_taken_cum", ",", "\n", "self", ".", "advices_used_ph", ":", "self", ".", "advices_used", ",", "\n", "self", ".", "advices_used_cum_ph", ":", "self", ".", "advices_used_cum", ",", "\n", "self", ".", "advices_reused_ph", ":", "self", ".", "advices_reused", ",", "\n", "self", ".", "advices_reused_cum_ph", ":", "self", ".", "advices_reused_cum", ",", "\n", "self", ".", "advices_reused_correct_ph", ":", "self", ".", "advices_reused_correct", ",", "\n", "self", ".", "advices_reused_correct_cum_ph", ":", "self", ".", "advices_reused_correct_cum", ",", "\n", "self", ".", "steps_reward_ph", ":", "steps_reward", ",", "\n", "self", ".", "steps_reward_auc_ph", ":", "steps_reward_auc", ",", "\n", "self", ".", "steps_error_in_ph", ":", "steps_error_in", ",", "\n", "self", ".", "steps_error_out_ph", ":", "steps_error_out", "}", "\n", "\n", "self", ".", "session", ".", "run", "(", "requested_ops", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary", "=", "self", ".", "session", ".", "run", "(", "self", ".", "summary_op_steps", ")", "\n", "self", ".", "summary_writer", ".", "add_summary", "(", "summary", ",", "self", ".", "n_env_steps", ")", "\n", "\n", "self", ".", "loss", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_episode": [[290, 304], ["run_statistics.Statistics.session.run", "run_statistics.Statistics.session.run", "run_statistics.Statistics.summary_writer.add_summary"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "update_summary_episode", "(", "self", ",", "episode_reward", ",", "episode_reward_auc", ",", "episode_duration", ",", "\n", "episode_error_in", ",", "episode_error_out", ")", ":", "\n", "        ", "requested_ops", "=", "[", "assignment", "for", "assignment", "in", "self", ".", "assignments_episode", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "episode_reward_ph", ":", "episode_reward", ",", "\n", "self", ".", "episode_reward_auc_ph", ":", "episode_reward_auc", ",", "\n", "self", ".", "episode_duration_ph", ":", "episode_duration", ",", "\n", "self", ".", "episode_error_in_ph", ":", "episode_error_in", ",", "\n", "self", ".", "episode_error_out_ph", ":", "episode_error_out", "}", "\n", "\n", "self", ".", "session", ".", "run", "(", "requested_ops", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary", "=", "self", ".", "session", ".", "run", "(", "self", ".", "summary_op_episode", ")", "\n", "self", ".", "summary_writer", ".", "add_summary", "(", "summary", ",", "self", ".", "n_episodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_evaluation": [[307, 318], ["run_statistics.Statistics.session.run", "run_statistics.Statistics.session.run", "run_statistics.Statistics.summary_writer.add_summary"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "update_summary_evaluation", "(", "self", ",", "evaluation_reward", ",", "evaluation_duration", ",", "evaluation_reward_auc", ")", ":", "\n", "        ", "requested_ops", "=", "[", "assignment", "for", "assignment", "in", "self", ".", "assignments_evaluation", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "evaluation_reward_ph", ":", "evaluation_reward", ",", "\n", "self", ".", "evaluation_duration_ph", ":", "evaluation_duration", ",", "\n", "self", ".", "evaluation_reward_auc_ph", ":", "evaluation_reward_auc", "}", "\n", "\n", "self", ".", "session", ".", "run", "(", "requested_ops", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary", "=", "self", ".", "session", ".", "run", "(", "self", ".", "summary_op_evaluation", ")", "\n", "self", ".", "summary_writer", ".", "add_summary", "(", "summary", ",", "self", ".", "n_env_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_rm_evaluation": [[321, 332], ["run_statistics.Statistics.session.run", "run_statistics.Statistics.session.run", "run_statistics.Statistics.summary_writer.add_summary"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "update_summary_rm_evaluation", "(", "self", ",", "rm_uncertainty_self", ",", "rm_uncertainty_12", ",", "rm_uncertainty_22", ")", ":", "\n", "        ", "requested_ops", "=", "[", "assignment", "for", "assignment", "in", "self", ".", "assignments_rm_evaluation", "]", "\n", "\n", "feed_dict", "=", "{", "\n", "self", ".", "rm_uncertainty_self_ph", ":", "rm_uncertainty_self", ",", "\n", "self", ".", "rm_uncertainty_12_ph", ":", "rm_uncertainty_12", ",", "\n", "self", ".", "rm_uncertainty_22_ph", ":", "rm_uncertainty_22", "}", "\n", "\n", "self", ".", "session", ".", "run", "(", "requested_ops", ",", "feed_dict", "=", "feed_dict", ")", "\n", "summary", "=", "self", ".", "session", ".", "run", "(", "self", ".", "summary_op_rm_evaluation", ")", "\n", "self", ".", "summary_writer", ".", "add_summary", "(", "summary", ",", "self", ".", "n_env_steps", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.__init__": [[8, 70], ["dqn.DQN.build_input_obs", "dqn.DQN.build_input_obs", "print", "max", "print"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_input_obs", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_input_obs"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "config", ",", "session", ",", "stats", ")", ":", "\n", "\n", "# Extract relevant configuration:", "\n", "        ", "self", ".", "config", "=", "{", "}", "\n", "self", ".", "config", "[", "'env_name'", "]", "=", "config", "[", "'env_name'", "]", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", "=", "config", "[", "'env_n_actions'", "]", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "=", "config", "[", "'env_obs_dims'", "]", "\n", "self", ".", "config", "[", "'env_obs_form'", "]", "=", "config", "[", "'env_obs_form'", "]", "\n", "\n", "self", ".", "config", "[", "'n_training_frames'", "]", "=", "config", "[", "'n_training_frames'", "]", "\n", "self", ".", "config", "[", "'rm_extra_content'", "]", "=", "config", "[", "'rm_extra_content'", "]", "\n", "\n", "dqn_config_params", "=", "[", "\n", "'dqn_gamma'", ",", "\n", "'dqn_rm_type'", ",", "\n", "'dqn_rm_init'", ",", "\n", "'dqn_rm_max'", ",", "\n", "'dqn_per_ims'", ",", "\n", "'dqn_per_alpha'", ",", "\n", "'dqn_per_beta'", ",", "\n", "'dqn_target_update'", ",", "\n", "'dqn_batch_size'", ",", "\n", "'dqn_learning_rate'", ",", "\n", "'dqn_train_period'", ",", "\n", "'dqn_adam_eps'", ",", "\n", "'dqn_huber_loss_delta'", ",", "\n", "'dqn_hidden_size'", "\n", "]", "\n", "for", "param", "in", "dqn_config_params", ":", "\n", "            ", "self", ".", "config", "[", "param", "]", "=", "config", "[", "param", "]", "\n", "\n", "", "self", ".", "id", "=", "id", "\n", "self", ".", "session", "=", "session", "\n", "self", ".", "stats", "=", "stats", "\n", "\n", "# Scoped names", "\n", "self", ".", "name_online", "=", "self", ".", "id", "+", "'/'", "+", "'ONLINE'", "\n", "self", ".", "name_target", "=", "self", ".", "id", "+", "'/'", "+", "'TARGET'", "\n", "\n", "self", ".", "tf_vars", "=", "{", "}", "\n", "\n", "self", ".", "tf_vars", "[", "'obs'", "]", "=", "self", ".", "build_input_obs", "(", "self", ".", "name_online", ")", "\n", "self", ".", "tf_vars", "[", "'obs_tar'", "]", "=", "self", ".", "build_input_obs", "(", "self", ".", "name_target", ")", "\n", "\n", "self", ".", "replay_memory", "=", "None", "\n", "self", ".", "minibatch_keys", "=", "None", "\n", "\n", "self", ".", "post_init_steps", "=", "0", "\n", "self", ".", "training_steps", "=", "0", "\n", "self", ".", "training_steps_since_target_update", "=", "0", "\n", "self", ".", "n_episode", "=", "0", "\n", "\n", "print", "(", "'# of training frames:'", ",", "self", ".", "config", "[", "'n_training_frames'", "]", ")", "\n", "\n", "self", ".", "total_optimiser_steps", "=", "max", "(", "0", ",", "(", "self", ".", "config", "[", "'n_training_frames'", "]", "-", "self", ".", "config", "[", "'dqn_rm_init'", "]", ")", "/", "self", ".", "config", "[", "'dqn_train_period'", "]", ")", "\n", "\n", "print", "(", "'# of optimiser steps:'", ",", "self", ".", "total_optimiser_steps", ")", "\n", "\n", "self", ".", "replay_memory", "=", "None", "\n", "self", ".", "per_beta", "=", "None", "\n", "self", ".", "per_beta_inc", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.create_replay_memory": [[73, 84], ["universal_replay_buffer.ReplayBuffer", "universal_replay_buffer.PrioritizedReplayBuffer", "float"], "methods", ["None"], ["", "def", "create_replay_memory", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'uniform'", ":", "\n", "            ", "self", ".", "replay_memory", "=", "ReplayBuffer", "(", "self", ".", "config", "[", "'dqn_rm_max'", "]", ",", "\n", "extra_content", "=", "self", ".", "config", "[", "'rm_extra_content'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", ":", "\n", "            ", "self", ".", "replay_memory", "=", "PrioritizedReplayBuffer", "(", "self", ".", "config", "[", "'dqn_rm_max'", "]", ",", "\n", "extra_content", "=", "self", ".", "config", "[", "'rm_extra_content'", "]", ",", "\n", "alpha", "=", "self", ".", "config", "[", "'dqn_per_alpha'", "]", ")", "\n", "\n", "self", ".", "per_beta", "=", "self", ".", "config", "[", "'dqn_per_beta'", "]", "\n", "self", ".", "per_beta_inc", "=", "(", "1.0", "-", "self", ".", "per_beta", ")", "/", "float", "(", "self", ".", "total_optimiser_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.build_input_obs": [[87, 91], ["tensorflow.compat.v1.placeholder"], "methods", ["None"], ["", "", "def", "build_input_obs", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ",", "[", "None", ",", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "0", "]", ",", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "1", "]", ",", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "2", "]", "]", ",", "name", "=", "name", "+", "'_OBS'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.conv_layers": [[94, 125], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.flatten", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling"], "methods", ["None"], ["", "def", "conv_layers", "(", "self", ",", "scope", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "layer_1", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "inputs", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "(", "8", ",", "8", ")", ",", "\n", "strides", "=", "(", "4", ",", "4", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_1'", ")", "\n", "\n", "layer_2", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "layer_1", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "(", "4", ",", "4", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_2'", ")", "\n", "\n", "layer_3", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "layer_2", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_3'", ")", "\n", "\n", "output", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "flatten", "(", "layer_3", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.dense_layers": [[128, 152], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.layers.dense", "tensorflow.compat.v1.layers.dense", "tensorflow.compat.v1.layers.dense", "tensorflow.compat.v1.tile", "tensorflow.compat.v1.layers.dense", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.compat.v1.reduce_mean", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling", "str", "str", "str", "str"], "methods", ["None"], ["", "", "def", "dense_layers", "(", "self", ",", "scope", ",", "inputs", ",", "is_dueling", ",", "hidden_size", ",", "output_size", ",", "head_id", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "layer_1", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "inputs", ",", "hidden_size", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "'DENSE_LAYER_'", "+", "str", "(", "head_id", ")", "+", "'_1'", ")", "\n", "\n", "if", "is_dueling", ":", "\n", "                ", "layer_2_adv", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "layer_1", ",", "output_size", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "None", ",", "name", "=", "'DENSE_LAYER_'", "+", "str", "(", "head_id", ")", "+", "'_2_ADV'", ")", "\n", "\n", "layer_2_val", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "layer_1", ",", "1", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "None", ",", "name", "=", "'DENSE_LAYER_'", "+", "str", "(", "head_id", ")", "+", "'_2_VAL'", ")", "\n", "\n", "advantage", "=", "(", "layer_2_adv", "-", "tf", ".", "compat", ".", "v1", ".", "reduce_mean", "(", "layer_2_adv", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "value", "=", "tf", ".", "compat", ".", "v1", ".", "tile", "(", "layer_2_val", ",", "[", "1", ",", "output_size", "]", ")", "\n", "return", "advantage", "+", "value", ",", "layer_1", "\n", "\n", "", "else", ":", "\n", "                ", "layer_2", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "layer_1", ",", "output_size", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "None", ",", "name", "=", "'DENSE_LAYER_'", "+", "str", "(", "head_id", ")", "+", "'_2'", ")", "\n", "return", "layer_2", ",", "layer_1", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.build_copy_ops": [[155, 167], ["tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.group", "target_var.assign", "trainable_vars_by_name_t.items", "len", "len"], "methods", ["None"], ["", "", "", "def", "build_copy_ops", "(", "self", ")", ":", "\n", "        ", "trainable_vars", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "name_online", ")", "\n", "trainable_vars_by_name", "=", "{", "var", ".", "name", "[", "len", "(", "self", ".", "name_online", ")", ":", "]", ":", "var", "for", "var", "in", "trainable_vars", "}", "\n", "\n", "trainable_vars_t", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "\n", "scope", "=", "self", ".", "name_target", ")", "\n", "trainable_vars_by_name_t", "=", "{", "var", ".", "name", "[", "len", "(", "self", ".", "name_target", ")", ":", "]", ":", "var", "for", "var", "in", "trainable_vars_t", "}", "\n", "\n", "copy_ops", "=", "[", "target_var", ".", "assign", "(", "trainable_vars_by_name", "[", "var_name", "]", ")", "\n", "for", "var_name", ",", "target_var", "in", "trainable_vars_by_name_t", ".", "items", "(", ")", "]", "\n", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "group", "(", "*", "copy_ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.fix_batch_form": [[170, 172], ["None"], "methods", ["None"], ["", "def", "fix_batch_form", "(", "self", ",", "var", ",", "is_batch", ")", ":", "\n", "        ", "return", "var", "if", "is_batch", "else", "[", "var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.random_action": [[175, 177], ["random.randrange"], "methods", ["None"], ["", "def", "random_action", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "randrange", "(", "self", ".", "config", "[", "'env_n_actions'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.save_model": [[180, 184], ["os.path.join().format", "print", "saver.save", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "saver", ",", "models_dir", ",", "session_name", ",", "checkpoint", ")", ":", "\n", "        ", "model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "models_dir", ",", "session_name", ")", ",", "'model-{}.ckpt'", ")", ".", "format", "(", "checkpoint", ")", "\n", "print", "(", "'[{}] Saving model... {}'", ".", "format", "(", "checkpoint", ",", "model_path", ")", ")", "\n", "saver", ".", "save", "(", "self", ".", "session", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.restore": [[187, 196], ["print", "print", "print", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "os.path.join", "len", "tensorflow.compat.v1.get_collection", "os.path.join", "tensorflow.compat.v1.get_collection", "str", "int"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.restore"], ["", "def", "restore", "(", "self", ",", "models_dir", ",", "session_name", ",", "checkpoint", ")", ":", "\n", "        ", "print", "(", "'Restoring...'", ")", "\n", "print", "(", "'Scope: {}'", ".", "format", "(", "self", ".", "id", ")", ")", "\n", "print", "(", "'# of variables: {}'", ".", "format", "(", "\n", "len", "(", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "id", ")", ")", ")", ")", "\n", "loader", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "\n", "var_list", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "id", ")", ")", "\n", "loader", ".", "restore", "(", "self", ".", "session", ",", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "models_dir", ",", "session_name", ")", ",", "'model-'", "+", "str", "(", "int", "(", "checkpoint", ")", ")", "+", "'.ckpt'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer.__init__": [[13, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Create Replay buffer.\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "size", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer.__len__": [[25, 27], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer.add": [[28, 37], ["int", "len", "replay_buffer_bc.ReplayBuffer._storage.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "obs", ",", "action", ")", ":", "\n", "        ", "data", "=", "(", "obs", ",", "action", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "\n", "", "self", ".", "_next_idx", "=", "int", "(", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample": [[38, 53], ["sample[].append", "sample[].append", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ",", "in_numpy_form", ")", ":", "\n", "        ", "sample", "=", "{", "\n", "'obs'", ":", "[", "]", ",", "\n", "'action'", ":", "[", "]", "\n", "}", "\n", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "sample", "[", "'obs'", "]", ".", "append", "(", "np", ".", "array", "(", "data", "[", "0", "]", ",", "copy", "=", "False", ")", ")", "\n", "sample", "[", "'action'", "]", ".", "append", "(", "np", ".", "array", "(", "data", "[", "1", "]", ",", "copy", "=", "False", ")", ")", "\n", "\n", "", "if", "in_numpy_form", ":", "\n", "            ", "return", "np", ".", "array", "(", "sample", "[", "'obs'", "]", ")", ",", "np", ".", "array", "(", "sample", "[", "'action'", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "sample", "[", "'obs'", "]", ",", "sample", "[", "'action'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer.sample": [[54, 76], ["replay_buffer_bc.ReplayBuffer._encode_sample", "random.randint", "range", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ",", "in_numpy_form", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "idxes", "=", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "return", "self", ".", "_encode_sample", "(", "idxes", ",", "in_numpy_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.__init__": [[79, 104], ["replay_buffer_bc.ReplayBuffer.__init__", "segment_tree.SumSegmentTree", "segment_tree.MinSegmentTree"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        alpha: float\n            how much prioritization is used\n            (0 - no prioritization, 1 - full prioritization)\n        See Also\n        --------\n        ReplayBuffer.__init__\n        \"\"\"", "\n", "super", "(", "PrioritizedReplayBuffer", ",", "self", ")", ".", "__init__", "(", "size", ")", "\n", "assert", "alpha", ">=", "0", "\n", "self", ".", "_alpha", "=", "alpha", "\n", "\n", "it_capacity", "=", "1", "\n", "while", "it_capacity", "<", "size", ":", "\n", "            ", "it_capacity", "*=", "2", "\n", "\n", "", "self", ".", "_it_sum", "=", "SumSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_it_min", "=", "MinSegmentTree", "(", "it_capacity", ")", "\n", "self", ".", "_max_priority", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.add": [[105, 115], ["replay_buffer_bc.ReplayBuffer.add"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.add"], ["", "def", "add", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"See ReplayBuffer.store_effect\"\"\"", "\n", "\n", "idx", "=", "self", ".", "_next_idx", "\n", "old_data", "=", "super", "(", ")", ".", "add", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_it_sum", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha", "\n", "self", ".", "_it_min", "[", "idx", "]", "=", "self", ".", "_max_priority", "**", "self", ".", "_alpha", "\n", "\n", "return", "old_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer._sample_proportional": [[116, 126], ["replay_buffer_bc.PrioritizedReplayBuffer._it_sum.sum", "range", "random.random", "numpy.float32", "replay_buffer_bc.PrioritizedReplayBuffer._it_sum.find_prefixsum_idx", "res.append", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.find_prefixsum_idx"], ["", "def", "_sample_proportional", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "p_total", "=", "self", ".", "_it_sum", ".", "sum", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "\n", "every_range_len", "=", "p_total", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "r", "=", "random", ".", "random", "(", ")", "\n", "mass", "=", "np", ".", "float32", "(", "r", "*", "every_range_len", "+", "i", "*", "every_range_len", ")", "\n", "idx", "=", "self", ".", "_it_sum", ".", "find_prefixsum_idx", "(", "mass", ")", "\n", "res", ".", "append", "(", "idx", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.sample": [[127, 174], ["replay_buffer_bc.PrioritizedReplayBuffer._sample_proportional", "numpy.array", "replay_buffer_bc.PrioritizedReplayBuffer._encode_sample", "tuple", "replay_buffer_bc.PrioritizedReplayBuffer._it_min.min", "replay_buffer_bc.PrioritizedReplayBuffer._it_sum.sum", "numpy.array.append", "len", "replay_buffer_bc.PrioritizedReplayBuffer._it_sum.sum", "list", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer._sample_proportional", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum"], ["", "def", "sample", "(", "self", ",", "batch_size", ",", "beta", ",", "in_numpy_form", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n        compared to ReplayBuffer.sample\n        it also returns importance weights and idxes\n        of sampled experiences.\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n        beta: float\n            To what degree to use importance weights\n            (0 - no corrections, 1 - full correction)\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        weights: np.array\n            Array of shape (batch_size,) and dtype np.float32\n            denoting importance weight of each sampled transition\n        idxes: np.array\n            Array of shape (batch_size,) and dtype np.int32\n            idxes in buffer of sampled experiences\n        \"\"\"", "\n", "assert", "beta", ">", "0", "\n", "\n", "idxes", "=", "self", ".", "_sample_proportional", "(", "batch_size", ")", "\n", "\n", "weights", "=", "[", "]", "\n", "p_min", "=", "self", ".", "_it_min", ".", "min", "(", ")", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "max_weight", "=", "(", "p_min", "*", "len", "(", "self", ".", "_storage", ")", ")", "**", "(", "-", "beta", ")", "\n", "\n", "for", "idx", "in", "idxes", ":", "\n", "            ", "p_sample", "=", "self", ".", "_it_sum", "[", "idx", "]", "/", "self", ".", "_it_sum", ".", "sum", "(", ")", "\n", "weight", "=", "(", "p_sample", "*", "len", "(", "self", ".", "_storage", ")", ")", "**", "(", "-", "beta", ")", "\n", "weights", ".", "append", "(", "weight", "/", "max_weight", ")", "\n", "", "weights", "=", "np", ".", "array", "(", "weights", ")", "\n", "encoded_sample", "=", "self", ".", "_encode_sample", "(", "idxes", ",", "in_numpy_form", ")", "\n", "return", "tuple", "(", "list", "(", "encoded_sample", ")", "+", "[", "weights", ",", "idxes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.sample_uniformly": [[175, 197], ["replay_buffer_bc.PrioritizedReplayBuffer._encode_sample", "random.randint", "range", "len"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.ReplayBuffer._encode_sample"], ["", "def", "sample_uniformly", "(", "self", ",", "batch_size", ",", "in_numpy_form", "=", "True", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "idxes", "=", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "return", "self", ".", "_encode_sample", "(", "idxes", ",", "in_numpy_form", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.update_priorities": [[198, 219], ["zip", "len", "len", "max", "len"], "methods", ["None"], ["", "def", "update_priorities", "(", "self", ",", "idxes", ",", "priorities", ")", ":", "\n", "        ", "\"\"\"Update priorities of sampled transitions.\n        sets priority of transition at index idxes[i] in buffer\n        to priorities[i].\n        Parameters\n        ----------\n        idxes: [int]\n            List of idxes of sampled transitions\n        priorities: [float]\n            List of updated priorities corresponding to\n            transitions at the sampled idxes denoted by\n            variable `idxes`.\n        \"\"\"", "\n", "assert", "len", "(", "idxes", ")", "==", "len", "(", "priorities", ")", "\n", "for", "idx", ",", "priority", "in", "zip", "(", "idxes", ",", "priorities", ")", ":", "\n", "            ", "assert", "priority", ">", "0", "\n", "assert", "0", "<=", "idx", "<", "len", "(", "self", ".", "_storage", ")", "\n", "self", ".", "_it_sum", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "\n", "self", ".", "_it_min", "[", "idx", "]", "=", "priority", "**", "self", ".", "_alpha", "\n", "\n", "self", ".", "_max_priority", "=", "max", "(", "self", ".", "_max_priority", ",", "priority", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.__init__": [[32, 96], ["env.metadata.get", "env.metadata.get", "os.path.splitext", "os.path.splitext", "os.path.splitext", "os.path.splitext", "video_recorder.touch", "env.metadata.get", "env.metadata.get", "video_recorder.VideoRecorder.write_metadata", "gym.logger.info", "gym.error.Error", "gym.error.Error", "gym.logger.info", "tempfile.NamedTemporaryFile"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.touch", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.write_metadata"], ["def", "__init__", "(", "self", ",", "env", ",", "\n", "path", "=", "None", ",", "\n", "metadata", "=", "None", ",", "\n", "enabled", "=", "True", ",", "\n", "base_path", "=", "None", ")", ":", "\n", "\n", "        ", "modes", "=", "env", ".", "metadata", ".", "get", "(", "'render.modes'", ",", "[", "]", ")", "\n", "self", ".", "_async", "=", "env", ".", "metadata", ".", "get", "(", "'semantics.async'", ")", "\n", "self", ".", "enabled", "=", "enabled", "\n", "\n", "# Don't bother setting anything else if not enabled", "\n", "if", "not", "self", ".", "enabled", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "ansi_mode", "=", "False", "\n", "if", "'rgb_array'", "not", "in", "modes", ":", "\n", "            ", "if", "'ansi'", "in", "modes", ":", "\n", "                ", "self", ".", "ansi_mode", "=", "True", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "'Disabling video recorder because {} neither supports video mode \"rgb_array\" nor \"ansi\".'", ".", "format", "(", "env", ")", ")", "\n", "# Whoops, turns out we shouldn't be enabled after all", "\n", "self", ".", "enabled", "=", "False", "\n", "return", "\n", "\n", "", "", "if", "path", "is", "not", "None", "and", "base_path", "is", "not", "None", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "\"You can pass at most one of `path` or `base_path`.\"", ")", "\n", "\n", "", "self", ".", "last_frame", "=", "None", "\n", "self", ".", "env", "=", "env", "\n", "\n", "required_ext", "=", "'.json'", "if", "self", ".", "ansi_mode", "else", "'.mp4'", "\n", "if", "path", "is", "None", ":", "\n", "            ", "if", "base_path", "is", "not", "None", ":", "\n", "# Base path given, append ext", "\n", "                ", "path", "=", "base_path", "+", "required_ext", "\n", "", "else", ":", "\n", "# Otherwise, just generate a unique filename", "\n", "                ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "suffix", "=", "required_ext", ",", "delete", "=", "False", ")", "as", "f", ":", "\n", "                    ", "path", "=", "f", ".", "name", "\n", "", "", "", "self", ".", "path", "=", "path", "\n", "\n", "path_base", ",", "actual_ext", "=", "os", ".", "path", ".", "splitext", "(", "self", ".", "path", ")", "\n", "\n", "if", "actual_ext", "!=", "required_ext", ":", "\n", "            ", "hint", "=", "\" HINT: The environment is text-only, therefore we're recording its text output in a structured JSON format.\"", "if", "self", ".", "ansi_mode", "else", "''", "\n", "raise", "error", ".", "Error", "(", "\"Invalid path given: {} -- must have file extension {}.{}\"", ".", "format", "(", "self", ".", "path", ",", "required_ext", ",", "hint", ")", ")", "\n", "# Touch the file in any case, so we know it's present. (This", "\n", "# corrects for platform platform differences. Using ffmpeg on", "\n", "# OS X, the file is precreated, but not on Linux.", "\n", "", "touch", "(", "path", ")", "\n", "\n", "self", ".", "frames_per_sec", "=", "env", ".", "metadata", ".", "get", "(", "'video.frames_per_second'", ",", "30", ")", "\n", "self", ".", "output_frames_per_sec", "=", "env", ".", "metadata", ".", "get", "(", "'video.output_frames_per_second'", ",", "self", ".", "frames_per_sec", ")", "\n", "self", ".", "encoder", "=", "None", "# lazily start the process", "\n", "self", ".", "broken", "=", "False", "\n", "\n", "# Dump metadata", "\n", "self", ".", "metadata", "=", "metadata", "or", "{", "}", "\n", "self", ".", "metadata", "[", "'content_type'", "]", "=", "'video/vnd.openai.ansivid'", "if", "self", ".", "ansi_mode", "else", "'video/mp4'", "\n", "self", ".", "metadata_path", "=", "'{}.meta.json'", ".", "format", "(", "path_base", ")", "\n", "self", ".", "write_metadata", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'Starting new video recorder writing to %s'", ",", "self", ".", "path", ")", "\n", "self", ".", "empty", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.functional": [[97, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "functional", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "enabled", "and", "not", "self", ".", "broken", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.capture_frame": [[101, 123], ["gym.logger.debug", "video_recorder.VideoRecorder.env.render", "gym.logger.warn", "video_recorder.VideoRecorder._encode_ansi_frame", "video_recorder.VideoRecorder._encode_image_frame"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder._encode_ansi_frame", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder._encode_image_frame"], ["", "def", "capture_frame", "(", "self", ")", ":", "\n", "        ", "\"\"\"Render the given `env` and add the resulting frame to the video.\"\"\"", "\n", "if", "not", "self", ".", "functional", ":", "return", "\n", "logger", ".", "debug", "(", "'Capturing video frame: path=%s'", ",", "self", ".", "path", ")", "\n", "\n", "render_mode", "=", "'ansi'", "if", "self", ".", "ansi_mode", "else", "'rgb_array'", "\n", "frame", "=", "self", ".", "env", ".", "render", "(", "mode", "=", "render_mode", ")", "\n", "\n", "if", "frame", "is", "None", ":", "\n", "            ", "if", "self", ".", "_async", ":", "\n", "                ", "return", "\n", "", "else", ":", "\n", "# Indicates a bug in the environment: don't want to raise", "\n", "# an error here.", "\n", "                ", "logger", ".", "warn", "(", "'Env returned None on render(). Disabling further rendering for video recorder by marking as disabled: path=%s metadata_path=%s'", ",", "self", ".", "path", ",", "self", ".", "metadata_path", ")", "\n", "self", ".", "broken", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "last_frame", "=", "frame", "\n", "if", "self", ".", "ansi_mode", ":", "\n", "                ", "self", ".", "_encode_ansi_frame", "(", "frame", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_encode_image_frame", "(", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.close": [[124, 154], ["video_recorder.VideoRecorder.write_metadata", "gym.logger.debug", "video_recorder.VideoRecorder.encoder.close", "os.remove", "os.remove", "os.remove", "os.remove", "gym.logger.info", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.remove", "os.remove", "os.remove", "os.remove"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.write_metadata", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close"], ["", "", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make sure to manually close, or else you'll leak the encoder process\"\"\"", "\n", "if", "not", "self", ".", "enabled", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "encoder", ":", "\n", "            ", "logger", ".", "debug", "(", "'Closing video encoder: path=%s'", ",", "self", ".", "path", ")", "\n", "self", ".", "encoder", ".", "close", "(", ")", "\n", "self", ".", "encoder", "=", "None", "\n", "", "else", ":", "\n", "# No frames captured. Set metadata, and remove the empty output file.", "\n", "            ", "os", ".", "remove", "(", "self", ".", "path", ")", "\n", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "{", "}", "\n", "", "self", ".", "metadata", "[", "'empty'", "]", "=", "True", "\n", "\n", "# If broken, get rid of the output file, otherwise we'd leak it.", "\n", "", "if", "self", ".", "broken", ":", "\n", "            ", "logger", ".", "info", "(", "'Cleaning up paths for broken video recorder: path=%s metadata_path=%s'", ",", "self", ".", "path", ",", "self", ".", "metadata_path", ")", "\n", "\n", "# Might have crashed before even starting the output file, don't try to remove in that case.", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "path", ")", ":", "\n", "                ", "os", ".", "remove", "(", "self", ".", "path", ")", "\n", "\n", "", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "{", "}", "\n", "", "self", ".", "metadata", "[", "'broken'", "]", "=", "True", "\n", "\n", "", "self", ".", "write_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder.write_metadata": [[155, 158], ["open", "json.dump"], "methods", ["None"], ["", "def", "write_metadata", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "metadata_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "metadata", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder._encode_ansi_frame": [[159, 165], ["video_recorder.VideoRecorder.encoder.capture_frame", "video_recorder.TextEncoder"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame"], ["", "", "def", "_encode_ansi_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ":", "\n", "            ", "self", ".", "encoder", "=", "TextEncoder", "(", "self", ".", "path", ",", "self", ".", "frames_per_sec", ")", "\n", "self", ".", "metadata", "[", "'encoder_version'", "]", "=", "self", ".", "encoder", ".", "version_info", "\n", "", "self", ".", "encoder", ".", "capture_frame", "(", "frame", ")", "\n", "self", ".", "empty", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.VideoRecorder._encode_image_frame": [[166, 178], ["video_recorder.ImageEncoder", "video_recorder.VideoRecorder.encoder.capture_frame", "gym.logger.warn"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame"], ["", "def", "_encode_image_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ":", "\n", "            ", "self", ".", "encoder", "=", "ImageEncoder", "(", "self", ".", "path", ",", "frame", ".", "shape", ",", "self", ".", "frames_per_sec", ",", "self", ".", "output_frames_per_sec", ")", "\n", "self", ".", "metadata", "[", "'encoder_version'", "]", "=", "self", ".", "encoder", ".", "version_info", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "encoder", ".", "capture_frame", "(", "frame", ")", "\n", "", "except", "error", ".", "InvalidFrame", "as", "e", ":", "\n", "            ", "logger", ".", "warn", "(", "'Tried to pass invalid video frame, marking as broken: %s'", ",", "e", ")", "\n", "self", ".", "broken", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "empty", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.TextEncoder.__init__": [[184, 188], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "output_path", ",", "frames_per_sec", ")", ":", "\n", "        ", "self", ".", "output_path", "=", "output_path", "\n", "self", ".", "frames_per_sec", "=", "frames_per_sec", "\n", "self", ".", "frames", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.TextEncoder.capture_frame": [[189, 207], ["isinstance", "frame.getvalue.encode", "video_recorder.TextEncoder.frames.append", "isinstance", "gym.error.InvalidFrame", "gym.error.InvalidFrame", "frame.getvalue", "gym.error.InvalidFrame", "type"], "methods", ["None"], ["", "def", "capture_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "string", "=", "None", "\n", "if", "isinstance", "(", "frame", ",", "str", ")", ":", "\n", "            ", "string", "=", "frame", "\n", "", "elif", "isinstance", "(", "frame", ",", "StringIO", ")", ":", "\n", "            ", "string", "=", "frame", ".", "getvalue", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Wrong type {} for {}: text frame must be a string or StringIO'", ".", "format", "(", "type", "(", "frame", ")", ",", "frame", ")", ")", "\n", "\n", "", "frame_bytes", "=", "string", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "if", "frame_bytes", "[", "-", "1", ":", "]", "!=", "b'\\n'", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Frame must end with a newline: \"\"\"{}\"\"\"'", ".", "format", "(", "string", ")", ")", "\n", "\n", "", "if", "b'\\r'", "in", "frame_bytes", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Frame contains carriage returns (only newlines are allowed: \"\"\"{}\"\"\"'", ".", "format", "(", "string", ")", ")", "\n", "\n", "", "self", ".", "frames", ".", "append", "(", "frame_bytes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.TextEncoder.close": [[208, 237], ["max", "max", "open", "json.dump", "len", "frame.count", "max", "frame.replace", "len", "frame.split"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "#frame_duration = float(1) / self.frames_per_sec", "\n", "        ", "frame_duration", "=", ".5", "\n", "\n", "# Turn frames into events: clear screen beforehand", "\n", "# https://rosettacode.org/wiki/Terminal_control/Clear_the_screen#Python", "\n", "# https://rosettacode.org/wiki/Terminal_control/Cursor_positioning#Python", "\n", "clear_code", "=", "b\"%c[2J\\033[1;1H\"", "%", "(", "27", ")", "\n", "# Decode the bytes as UTF-8 since JSON may only contain UTF-8", "\n", "events", "=", "[", "(", "frame_duration", ",", "(", "clear_code", "+", "frame", ".", "replace", "(", "b'\\n'", ",", "b'\\r\\n'", ")", ")", ".", "decode", "(", "'utf-8'", ")", ")", "for", "frame", "in", "self", ".", "frames", "]", "\n", "\n", "# Calculate frame size from the largest frames.", "\n", "# Add some padding since we'll get cut off otherwise.", "\n", "height", "=", "max", "(", "[", "frame", ".", "count", "(", "b'\\n'", ")", "for", "frame", "in", "self", ".", "frames", "]", ")", "+", "1", "\n", "width", "=", "max", "(", "[", "max", "(", "[", "len", "(", "line", ")", "for", "line", "in", "frame", ".", "split", "(", "b'\\n'", ")", "]", ")", "for", "frame", "in", "self", ".", "frames", "]", ")", "+", "2", "\n", "\n", "data", "=", "{", "\n", "\"version\"", ":", "1", ",", "\n", "\"width\"", ":", "width", ",", "\n", "\"height\"", ":", "height", ",", "\n", "\"duration\"", ":", "len", "(", "self", ".", "frames", ")", "*", "frame_duration", ",", "\n", "\"command\"", ":", "\"-\"", ",", "\n", "\"title\"", ":", "\"gym VideoRecorder episode\"", ",", "\n", "\"env\"", ":", "{", "}", ",", "# could add some env metadata here", "\n", "\"stdout\"", ":", "events", ",", "\n", "}", "\n", "\n", "with", "open", "(", "self", ".", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.TextEncoder.version_info": [[238, 241], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "version_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "'backend'", ":", "'TextEncoder'", ",", "'version'", ":", "1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.__init__": [[243, 264], ["video_recorder.ImageEncoder.start", "gym.error.InvalidFrame", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "gym.error.DependencyNotInstalled"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.start"], ["    ", "def", "__init__", "(", "self", ",", "output_path", ",", "frame_shape", ",", "frames_per_sec", ",", "output_frames_per_sec", ")", ":", "\n", "        ", "self", ".", "proc", "=", "None", "\n", "self", ".", "output_path", "=", "output_path", "\n", "# Frame shape should be lines-first, so w and h are swapped", "\n", "h", ",", "w", ",", "pixfmt", "=", "frame_shape", "\n", "if", "pixfmt", "!=", "3", "and", "pixfmt", "!=", "4", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has shape {}, but we require (w,h,3) or (w,h,4), i.e., RGB values for a w-by-h image, with an optional alpha channel.\"", ".", "format", "(", "frame_shape", ")", ")", "\n", "", "self", ".", "wh", "=", "(", "w", ",", "h", ")", "\n", "self", ".", "includes_alpha", "=", "(", "pixfmt", "==", "4", ")", "\n", "self", ".", "frame_shape", "=", "frame_shape", "\n", "self", ".", "frames_per_sec", "=", "frames_per_sec", "\n", "self", ".", "output_frames_per_sec", "=", "output_frames_per_sec", "\n", "\n", "if", "distutils", ".", "spawn", ".", "find_executable", "(", "'avconv'", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "backend", "=", "'avconv'", "\n", "", "elif", "distutils", ".", "spawn", ".", "find_executable", "(", "'ffmpeg'", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "backend", "=", "'ffmpeg'", "\n", "", "else", ":", "\n", "            ", "raise", "error", ".", "DependencyNotInstalled", "(", "\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"", ")", "\n", "\n", "", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.version_info": [[265, 272], ["str", "subprocess.check_output"], "methods", ["None"], ["", "@", "property", "\n", "def", "version_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'backend'", ":", "self", ".", "backend", ",", "\n", "'version'", ":", "str", "(", "subprocess", ".", "check_output", "(", "[", "self", ".", "backend", ",", "'-version'", "]", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ")", ")", ",", "\n", "'cmdline'", ":", "self", ".", "cmdline", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.start": [[274, 300], ["gym.logger.debug", "hasattr", "subprocess.Popen", "subprocess.Popen"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "cmdline", "=", "(", "self", ".", "backend", ",", "\n", "'-nostats'", ",", "\n", "'-loglevel'", ",", "'error'", ",", "# suppress warnings", "\n", "'-y'", ",", "\n", "\n", "# input", "\n", "'-f'", ",", "'rawvideo'", ",", "\n", "'-s:v'", ",", "'{}x{}'", ".", "format", "(", "*", "self", ".", "wh", ")", ",", "\n", "'-pix_fmt'", ",", "(", "'rgb32'", "if", "self", ".", "includes_alpha", "else", "'rgb24'", ")", ",", "\n", "'-framerate'", ",", "'%d'", "%", "self", ".", "frames_per_sec", ",", "\n", "'-i'", ",", "'-'", ",", "# this used to be /dev/stdin, which is not Windows-friendly", "\n", "\n", "# output", "\n", "'-vf'", ",", "'scale=trunc(iw/2)*2:trunc(ih/2)*2'", ",", "\n", "'-vcodec'", ",", "'libx264'", ",", "\n", "'-pix_fmt'", ",", "'yuv420p'", ",", "\n", "'-r'", ",", "'%d'", "%", "self", ".", "output_frames_per_sec", ",", "\n", "self", ".", "output_path", "\n", ")", "\n", "\n", "logger", ".", "debug", "(", "'Starting ffmpeg with \"%s\"'", ",", "' '", ".", "join", "(", "self", ".", "cmdline", ")", ")", "\n", "if", "hasattr", "(", "os", ",", "'setsid'", ")", ":", "#setsid not present on Windows", "\n", "            ", "self", ".", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "cmdline", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "preexec_fn", "=", "os", ".", "setsid", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "cmdline", ",", "stdin", "=", "subprocess", ".", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame": [[301, 313], ["isinstance", "gym.error.InvalidFrame", "gym.error.InvalidFrame", "gym.error.InvalidFrame", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "video_recorder.ImageEncoder.proc.stdin.write", "video_recorder.ImageEncoder.proc.stdin.write", "frame.tobytes", "frame.tostring", "type"], "methods", ["None"], ["", "", "def", "capture_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "frame", ",", "(", "np", ".", "ndarray", ",", "np", ".", "generic", ")", ")", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Wrong type {} for {} (must be np.ndarray or np.generic)'", ".", "format", "(", "type", "(", "frame", ")", ",", "frame", ")", ")", "\n", "", "if", "frame", ".", "shape", "!=", "self", ".", "frame_shape", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has shape {}, but the VideoRecorder is configured for shape {}.\"", ".", "format", "(", "frame", ".", "shape", ",", "self", ".", "frame_shape", ")", ")", "\n", "", "if", "frame", ".", "dtype", "!=", "np", ".", "uint8", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has data type {}, but we require uint8 (i.e. RGB values from 0-255).\"", ".", "format", "(", "frame", ".", "dtype", ")", ")", "\n", "\n", "", "if", "distutils", ".", "version", ".", "LooseVersion", "(", "np", ".", "__version__", ")", ">=", "distutils", ".", "version", ".", "LooseVersion", "(", "'1.9.0'", ")", ":", "\n", "            ", "self", ".", "proc", ".", "stdin", ".", "write", "(", "frame", ".", "tobytes", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proc", ".", "stdin", ".", "write", "(", "frame", ".", "tostring", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close": [[314, 319], ["video_recorder.ImageEncoder.proc.stdin.close", "video_recorder.ImageEncoder.proc.wait", "gym.logger.error"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "proc", ".", "stdin", ".", "close", "(", ")", "\n", "ret", "=", "self", ".", "proc", ".", "wait", "(", ")", "\n", "if", "ret", "!=", "0", ":", "\n", "            ", "logger", ".", "error", "(", "\"VideoRecorder encoder exited with status {}\"", ".", "format", "(", "ret", ")", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.touch": [[14, 16], ["open().close", "open"], "function", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close"], ["def", "touch", "(", "path", ")", ":", "\n", "    ", "open", "(", "path", ",", "'a'", ")", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__init__": [[27, 43], ["tuple", "len", "compress"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "frames", ",", "lz4_compress", "=", "False", ")", ":", "\n", "        ", "self", ".", "frame_shape", "=", "tuple", "(", "frames", "[", "0", "]", ".", "shape", ")", "\n", "# OLD:", "\n", "self", ".", "shape", "=", "(", "len", "(", "frames", ")", ",", ")", "+", "self", ".", "frame_shape", "\n", "#self.shape = self.frame_shape + (len(frames),)", "\n", "\n", "self", ".", "dtype", "=", "frames", "[", "0", "]", ".", "dtype", "\n", "if", "lz4_compress", ":", "\n", "            ", "from", "lz4", ".", "block", "import", "compress", "\n", "frames", "=", "[", "compress", "(", "frame", ")", "for", "frame", "in", "frames", "]", "\n", "\n", "# OLD:", "\n", "", "self", ".", "_frames", "=", "frames", "\n", "# self._frames = np.moveaxis(frames, 0, -1)", "\n", "\n", "self", ".", "lz4_compress", "=", "lz4_compress", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__array__": [[44, 49], ["arr.astype"], "methods", ["None"], ["", "def", "__array__", "(", "self", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "arr", "=", "self", "[", ":", "]", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "            ", "return", "arr", ".", "astype", "(", "dtype", ")", "\n", "", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__len__": [[50, 52], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__getitem__": [[53, 57], ["isinstance", "numpy.stack", "frame_stack.LazyFrames._check_decompress", "frame_stack.LazyFrames._check_decompress"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames._check_decompress", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames._check_decompress"], ["", "def", "__getitem__", "(", "self", ",", "int_or_slice", ")", ":", "\n", "        ", "if", "isinstance", "(", "int_or_slice", ",", "int", ")", ":", "\n", "            ", "return", "self", ".", "_check_decompress", "(", "self", ".", "_frames", "[", "int_or_slice", "]", ")", "# single frame", "\n", "", "return", "np", ".", "stack", "(", "[", "self", ".", "_check_decompress", "(", "f", ")", "for", "f", "in", "self", ".", "_frames", "[", "int_or_slice", "]", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__eq__": [[58, 60], ["frame_stack.LazyFrames.__array__"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__array__"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__array__", "(", ")", "==", "other", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames._check_decompress": [[61, 66], ["numpy.frombuffer().reshape", "numpy.frombuffer", "decompress"], "methods", ["None"], ["", "def", "_check_decompress", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "self", ".", "lz4_compress", ":", "\n", "            ", "from", "lz4", ".", "block", "import", "decompress", "\n", "return", "np", ".", "frombuffer", "(", "decompress", "(", "frame", ")", ",", "dtype", "=", "self", ".", "dtype", ")", ".", "reshape", "(", "self", ".", "frame_shape", ")", "\n", "", "return", "frame", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack.__init__": [[99, 116], ["gym.Wrapper.__init__", "collections.deque", "numpy.repeat", "numpy.repeat", "gym.spaces.Box", "print"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "num_stack", ",", "lz4_compress", "=", "False", ")", ":", "\n", "        ", "super", "(", "FrameStack", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "num_stack", "=", "num_stack", "\n", "self", ".", "lz4_compress", "=", "lz4_compress", "\n", "\n", "self", ".", "frames", "=", "deque", "(", "maxlen", "=", "num_stack", ")", "\n", "\n", "low", "=", "np", ".", "repeat", "(", "self", ".", "observation_space", ".", "low", "[", "np", ".", "newaxis", ",", "...", "]", ",", "num_stack", ",", "axis", "=", "0", ")", "\n", "high", "=", "np", ".", "repeat", "(", "self", ".", "observation_space", ".", "high", "[", "np", ".", "newaxis", ",", "...", "]", ",", "num_stack", ",", "axis", "=", "0", ")", "\n", "\n", "# New:", "\n", "#low = np.moveaxis(low, 0, -1)", "\n", "#high = np.moveaxis(high, 0, -1)", "\n", "\n", "self", ".", "observation_space", "=", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "self", ".", "observation_space", ".", "dtype", ")", "\n", "\n", "print", "(", "self", ".", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack._get_observation": [[117, 123], ["frame_stack.LazyFrames", "len", "len", "list"], "methods", ["None"], ["", "def", "_get_observation", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "frames", ")", "==", "self", ".", "num_stack", ",", "(", "len", "(", "self", ".", "frames", ")", ",", "self", ".", "num_stack", ")", "\n", "#frames = np.asarray(list(self.frames))", "\n", "#frames = np.moveaxis(frames, 0, -1)", "\n", "#return frames", "\n", "return", "LazyFrames", "(", "list", "(", "self", ".", "frames", ")", ",", "self", ".", "lz4_compress", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack.step": [[124, 128], ["frame_stack.FrameStack.env.step", "frame_stack.FrameStack.frames.append", "frame_stack.FrameStack._get_observation"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack._get_observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "observation", ",", "reward", ",", "done", ",", "info", ",", "reward_actual", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "frames", ".", "append", "(", "observation", ")", "\n", "return", "self", ".", "_get_observation", "(", ")", ",", "reward", ",", "done", ",", "info", ",", "reward_actual", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack.reset": [[129, 133], ["frame_stack.FrameStack.env.reset", "frame_stack.FrameStack._get_observation", "frame_stack.FrameStack.frames.append", "range"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.FrameStack._get_observation"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "observation", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "[", "self", ".", "frames", ".", "append", "(", "observation", ")", "for", "_", "in", "range", "(", "self", ".", "num_stack", ")", "]", "\n", "return", "self", ".", "_get_observation", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.__init__": [[9, 35], ["numpy.float64", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ",", "operation", ",", "neutral_element", ")", ":", "\n", "        ", "\"\"\"Build a Segment Tree data structure.\n        https://en.wikipedia.org/wiki/Segment_tree\n        Can be used as regular array, but with two\n        important differences:\n            a) setting item's value is slightly slower.\n               It is O(lg capacity) instead of O(1).\n            b) user has access to an efficient ( O(log segment size) )\n               `reduce` operation which reduces `operation` over\n               a contiguous subsequence of items in the array.\n        Parameters\n        ---------\n        capacity: int\n            Total size of the array - must be a power of two.\n        operation: lambda obj, obj -> obj\n            and operation for combining elements (eg. sum, max)\n            must form a mathematical group together with the set of\n            possible values for array elements (i.e. be associative)\n        neutral_element: obj\n            neutral element for the operation above. eg. float('-inf')\n            for max and 0 for sum.\n        \"\"\"", "\n", "assert", "capacity", ">", "0", "and", "capacity", "&", "(", "capacity", "-", "1", ")", "==", "0", ",", "\"capacity must be positive and a power of 2.\"", "\n", "self", ".", "_capacity", "=", "capacity", "\n", "self", ".", "_value", "=", "[", "np", ".", "float64", "(", "neutral_element", ")", "for", "_", "in", "range", "(", "2", "*", "capacity", ")", "]", "\n", "self", ".", "_operation", "=", "operation", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper": [[38, 56], ["segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._operation", "segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._reduce_helper"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper"], ["", "def", "_reduce_helper", "(", "self", ",", "start", ",", "end", ",", "node", ",", "node_start", ",", "node_end", ")", ":", "\n", "#print(start, end, node, node_start, node_end)", "\n", "        ", "if", "start", "==", "node_start", "and", "end", "==", "node_end", ":", "\n", "#print(self._value[node])", "\n", "            ", "return", "self", ".", "_value", "[", "node", "]", "\n", "", "mid", "=", "(", "node_start", "+", "node_end", ")", "//", "2", "\n", "if", "end", "<=", "mid", ":", "\n", "#print(1)", "\n", "            ", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "2", "*", "node", ",", "node_start", ",", "mid", ")", "\n", "", "else", ":", "\n", "            ", "if", "mid", "+", "1", "<=", "start", ":", "\n", "#print(2)", "\n", "                ", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "2", "*", "node", "+", "1", ",", "mid", "+", "1", ",", "node_end", ")", "\n", "", "else", ":", "\n", "#print(3)", "\n", "                ", "return", "self", ".", "_operation", "(", "\n", "self", ".", "_reduce_helper", "(", "start", ",", "mid", ",", "2", "*", "node", ",", "node_start", ",", "mid", ")", ",", "\n", "self", ".", "_reduce_helper", "(", "mid", "+", "1", ",", "end", ",", "2", "*", "node", "+", "1", ",", "mid", "+", "1", ",", "node_end", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.reduce": [[58, 81], ["segment_tree.SegmentTree._reduce_helper"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree._reduce_helper"], ["", "", "", "def", "reduce", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns result of applying `self.operation`\n        to a contiguous subsequence of the array.\n            self.operation(arr[start], operation(arr[start+1], operation(... arr[end])))\n        Parameters\n        ----------\n        start: int\n            beginning of the subsequence\n        end: int\n            end of the subsequences\n        Returns\n        -------\n        reduced: obj\n            result of reducing self.operation over the specified range of array elements.\n        \"\"\"", "\n", "#print('reduce 0 - ', start, end, self._capacity)", "\n", "if", "end", "is", "None", ":", "\n", "            ", "end", "=", "self", ".", "_capacity", "\n", "", "if", "end", "<", "0", ":", "\n", "            ", "end", "+=", "self", ".", "_capacity", "\n", "", "end", "-=", "1", "\n", "#print('reduce 1 - ', start, end)", "\n", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "1", ",", "0", ",", "self", ".", "_capacity", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.__setitem__": [[82, 96], ["int", "numpy.float64", "segment_tree.SegmentTree._operation"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "idx", ",", "val", ")", ":", "\n", "# index of the leaf", "\n", "#print(idx, self._capacity)", "\n", "# idx += self._capacity", "\n", "        ", "idx", "=", "int", "(", "idx", "+", "self", ".", "_capacity", ")", "\n", "#print(idx)", "\n", "self", ".", "_value", "[", "idx", "]", "=", "np", ".", "float64", "(", "val", ")", "\n", "idx", "//=", "2", "\n", "while", "idx", ">=", "1", ":", "\n", "            ", "self", ".", "_value", "[", "idx", "]", "=", "self", ".", "_operation", "(", "\n", "self", ".", "_value", "[", "2", "*", "idx", "]", ",", "\n", "self", ".", "_value", "[", "2", "*", "idx", "+", "1", "]", "\n", ")", "\n", "idx", "//=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.__getitem__": [[97, 100], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "assert", "0", "<=", "idx", "<", "self", ".", "_capacity", "\n", "return", "self", ".", "_value", "[", "self", ".", "_capacity", "+", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.__init__": [[103, 108], ["segment_tree.SegmentTree.__init__", "numpy.float64"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "super", "(", "SumSegmentTree", ",", "self", ")", ".", "__init__", "(", "\n", "capacity", "=", "capacity", ",", "\n", "operation", "=", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "\n", "neutral_element", "=", "np", ".", "float64", "(", "0.0", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum": [[110, 115], ["segment_tree.SegmentTree.reduce"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.reduce"], ["", "def", "sum", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns arr[start] + ... + arr[end]\"\"\"", "\n", "ret", "=", "super", "(", "SumSegmentTree", ",", "self", ")", ".", "reduce", "(", "start", ",", "end", ")", "\n", "#print(\"sum\", start, end, ret)", "\n", "return", "ret", "\n", "#return super(SumSegmentTree, self).reduce(start, end)", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.find_prefixsum_idx": [[117, 141], ["segment_tree.SumSegmentTree.sum"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SumSegmentTree.sum"], ["", "def", "find_prefixsum_idx", "(", "self", ",", "prefixsum", ")", ":", "\n", "        ", "\"\"\"Find the highest index `i` in the array such that\n            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n        if array values are probabilities, this function\n        allows to sample indexes according to the discrete\n        probability efficiently.\n        Parameters\n        ----------\n        perfixsum: float\n            upperbound on the sum of array prefix\n        Returns\n        -------\n        idx: int\n            highest index satisfying the prefixsum constraint\n        \"\"\"", "\n", "assert", "0", "<=", "prefixsum", "<=", "self", ".", "sum", "(", ")", "+", "1e-5", "\n", "idx", "=", "1", "\n", "while", "idx", "<", "self", ".", "_capacity", ":", "# while non-leaf", "\n", "            ", "if", "self", ".", "_value", "[", "2", "*", "idx", "]", ">", "prefixsum", ":", "\n", "                ", "idx", "=", "2", "*", "idx", "\n", "", "else", ":", "\n", "                ", "prefixsum", "-=", "self", ".", "_value", "[", "2", "*", "idx", "]", "\n", "idx", "=", "2", "*", "idx", "+", "1", "\n", "", "", "return", "idx", "-", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.MinSegmentTree.__init__": [[144, 150], ["segment_tree.SegmentTree.__init__", "numpy.float64"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "#print('minseg')", "\n", "        ", "super", "(", "MinSegmentTree", ",", "self", ")", ".", "__init__", "(", "\n", "capacity", "=", "capacity", ",", "\n", "operation", "=", "min", ",", "\n", "neutral_element", "=", "np", ".", "float64", "(", "np", ".", "inf", ")", "#float('inf')", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.MinSegmentTree.min": [[153, 157], ["segment_tree.SegmentTree.reduce"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.SegmentTree.reduce"], ["", "def", "min", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"", "\n", "\n", "return", "super", "(", "MinSegmentTree", ",", "self", ")", ".", "reduce", "(", "start", ",", "end", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.__init__": [[9, 55], ["behavioural_cloning.BehaviouralCloning.build_input_obs", "behavioural_cloning.BehaviouralCloning.create_replay_memory", "tensorflow.compat.v1.placeholder", "behavioural_cloning.BehaviouralCloning.build_network", "behavioural_cloning.BehaviouralCloning.build_training_ops"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_input_obs", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.create_replay_memory", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_network", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_training_ops"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "config", ",", "session", ",", "stats", ")", ":", "\n", "\n", "# Extract relevant configuration:", "\n", "        ", "self", ".", "config", "=", "{", "}", "\n", "self", ".", "config", "[", "'env_type'", "]", "=", "config", "[", "'env_type'", "]", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", "=", "config", "[", "'env_n_actions'", "]", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "=", "config", "[", "'env_obs_dims'", "]", "\n", "self", ".", "config", "[", "'env_obs_form'", "]", "=", "config", "[", "'env_obs_form'", "]", "\n", "\n", "bc_config_params", "=", "[", "\n", "'bc_hidden_size'", ",", "\n", "'bc_batch_size'", ",", "\n", "'bc_learning_rate'", ",", "\n", "'bc_adam_eps'", ",", "\n", "'bc_dropout_rate'", "\n", "]", "\n", "for", "param", "in", "bc_config_params", ":", "\n", "            ", "self", ".", "config", "[", "param", "]", "=", "config", "[", "param", "]", "\n", "\n", "", "self", ".", "id", "=", "id", "\n", "self", ".", "session", "=", "session", "\n", "self", ".", "stats", "=", "stats", "\n", "\n", "# Scoped names", "\n", "self", ".", "name", "=", "self", ".", "id", "+", "'/'", "+", "'BC_ONLINE'", "\n", "\n", "self", ".", "tf_vars", "=", "{", "}", "\n", "self", ".", "tf_vars", "[", "'obs'", "]", "=", "self", ".", "build_input_obs", "(", "self", ".", "name", ")", "\n", "\n", "self", ".", "replay_memory", "=", "None", "\n", "\n", "self", ".", "post_init_steps", "=", "0", "\n", "self", ".", "training_steps", "=", "0", "\n", "\n", "self", ".", "create_replay_memory", "(", ")", "\n", "\n", "self", ".", "minibatch_keys", "=", "(", "'obs'", ",", "'action'", ")", "\n", "\n", "self", ".", "dropout_rate_ph", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", ")", ",", "name", "=", "'DROPOUT_RATE'", ")", "\n", "\n", "self", ".", "tf_vars", "[", "'pre_fc_features'", "]", ",", "self", ".", "tf_vars", "[", "'mid_fc_features'", "]", ",", "self", ".", "tf_vars", "[", "'action_logits'", "]", ",", "self", ".", "tf_vars", "[", "'action_probs'", "]", "=", "self", ".", "build_network", "(", "self", ".", "name", ",", "self", ".", "tf_vars", "[", "'obs'", "]", ",", "self", ".", "config", "[", "'bc_hidden_size'", "]", ",", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", ")", "\n", "\n", "self", ".", "build_training_ops", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.create_replay_memory": [[58, 60], ["replay_buffer_bc.ReplayBuffer"], "methods", ["None"], ["", "def", "create_replay_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_memory", "=", "replay_memory", ".", "ReplayBuffer", "(", "1e6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_input_obs": [[63, 67], ["tensorflow.compat.v1.placeholder"], "methods", ["None"], ["", "def", "build_input_obs", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ",", "[", "None", ",", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "0", "]", ",", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "1", "]", ",", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "[", "2", "]", "]", ",", "name", "=", "name", "+", "'_OBS'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.conv_layers": [[70, 101], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.conv2d", "tensorflow.compat.v1.layers.flatten", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling"], "methods", ["None"], ["", "def", "conv_layers", "(", "self", ",", "scope", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "layer_1", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "inputs", ",", "\n", "filters", "=", "32", ",", "\n", "kernel_size", "=", "(", "8", ",", "8", ")", ",", "\n", "strides", "=", "(", "4", ",", "4", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_1'", ")", "\n", "\n", "layer_2", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "layer_1", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "(", "4", ",", "4", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_2'", ")", "\n", "\n", "layer_3", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "conv2d", "(", "inputs", "=", "layer_2", ",", "\n", "filters", "=", "64", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "name", "=", "'CONV_LAYER_3'", ")", "\n", "\n", "output", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "flatten", "(", "layer_3", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.dense_layers": [[104, 116], ["tensorflow.compat.v1.variable_scope", "tensorflow.compat.v1.nn.dropout", "tensorflow.compat.v1.layers.dense", "tensorflow.compat.v1.nn.dropout", "tensorflow.compat.v1.layers.dense", "tensorflow.keras.initializers.VarianceScaling", "tensorflow.keras.initializers.VarianceScaling"], "methods", ["None"], ["", "", "def", "dense_layers", "(", "self", ",", "scope", ",", "inputs", ",", "hidden_size", ",", "output_size", ")", ":", "\n", "        ", "with", "tf", ".", "compat", ".", "v1", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "compat", ".", "v1", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "layer_1_in", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "dropout", "(", "inputs", ",", "name", "=", "'DROPOUT_LAYER_1'", ",", "rate", "=", "self", ".", "dropout_rate_ph", ")", "\n", "layer_1_out", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "layer_1_in", ",", "hidden_size", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "'DENSE_LAYER_1'", ")", "\n", "\n", "layer_2_in", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "dropout", "(", "layer_1_out", ",", "name", "=", "'DROPOUT_LAYER_2'", ",", "rate", "=", "self", ".", "dropout_rate_ph", ")", "\n", "layer_2_out", "=", "tf", ".", "compat", ".", "v1", ".", "layers", ".", "dense", "(", "layer_2_in", ",", "output_size", ",", "use_bias", "=", "True", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "VarianceScaling", "(", ")", ",", "\n", "activation", "=", "None", ",", "name", "=", "'DENSE_LAYER_2'", ")", "\n", "return", "layer_2_out", ",", "layer_1_out", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form": [[119, 121], ["None"], "methods", ["None"], ["", "", "def", "fix_batch_form", "(", "self", ",", "var", ",", "is_batch", ")", ":", "\n", "        ", "return", "var", "if", "is_batch", "else", "[", "var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_network": [[124, 130], ["behavioural_cloning.BehaviouralCloning.conv_layers", "behavioural_cloning.BehaviouralCloning.dense_layers", "tensorflow.compat.v1.nn.softmax"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.conv_layers", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.dense_layers"], ["", "def", "build_network", "(", "self", ",", "name", ",", "input", ",", "hidden_size", ",", "output_size", ")", ":", "\n", "        ", "pre_fc_features", "=", "self", ".", "conv_layers", "(", "name", ",", "input", ")", "\n", "action_logits", ",", "mid_fc_features", "=", "self", ".", "dense_layers", "(", "name", ",", "inputs", "=", "pre_fc_features", ",", "hidden_size", "=", "hidden_size", ",", "\n", "output_size", "=", "output_size", ")", "\n", "action_probs", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "softmax", "(", "action_logits", ")", "\n", "return", "pre_fc_features", ",", "mid_fc_features", ",", "action_logits", ",", "action_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.build_training_ops": [[133, 145], ["tensorflow.compat.v1.placeholder", "tensorflow.compat.v1.one_hot", "tensorflow.compat.v1.nn.sigmoid_cross_entropy_with_logits", "tensorflow.compat.v1.reduce_mean", "tensorflow.compat.v1.reduce_mean", "tensorflow.compat.v1.train.AdamOptimizer", "tensorflow.compat.v1.train.AdamOptimizer.minimize", "str"], "methods", ["None"], ["", "def", "build_training_ops", "(", "self", ")", ":", "\n", "        ", "self", ".", "tf_vars", "[", "'action'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "'ACTIONS_'", "+", "str", "(", "self", ".", "id", ")", ")", "\n", "action_one_hot", "=", "tf", ".", "compat", ".", "v1", ".", "one_hot", "(", "self", ".", "tf_vars", "[", "'action'", "]", ",", "self", ".", "config", "[", "'env_n_actions'", "]", ",", "1.0", ",", "0.0", ")", "\n", "\n", "loss_all", "=", "tf", ".", "compat", ".", "v1", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "tf_vars", "[", "'action_logits'", "]", ",", "\n", "labels", "=", "action_one_hot", ")", "\n", "\n", "self", ".", "tf_vars", "[", "'loss_batch'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "reduce_mean", "(", "loss_all", ",", "reduction_indices", "=", "1", ")", "\n", "self", ".", "tf_vars", "[", "'loss'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "reduce_mean", "(", "loss_all", ")", "\n", "\n", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "config", "[", "'bc_learning_rate'", "]", ",", "epsilon", "=", "self", ".", "config", "[", "'bc_adam_eps'", "]", ")", "\n", "self", ".", "tf_vars", "[", "'grads_update'", "]", "=", "optimizer", ".", "minimize", "(", "self", ".", "tf_vars", "[", "'loss'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.feedback_observe": [[148, 150], ["behavioural_cloning.BehaviouralCloning.replay_memory.add"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.add"], ["", "def", "feedback_observe", "(", "self", ",", "obs", ",", "action", ")", ":", "\n", "        ", "self", ".", "replay_memory", ".", "add", "(", "obs", ",", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.feedback_learn": [[153, 157], ["behavioural_cloning.BehaviouralCloning.train_model"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.train_model"], ["", "def", "feedback_learn", "(", "self", ")", ":", "\n", "        ", "self", ".", "post_init_steps", "+=", "1", "\n", "loss", "=", "self", ".", "train_model", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.train_model": [[160, 176], ["min", "behavioural_cloning.BehaviouralCloning.replay_memory.sample", "enumerate", "behavioural_cloning.BehaviouralCloning.get_grads_update", "behavioural_cloning.BehaviouralCloning.replay_memory.__len__", "numpy.moveaxis", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.sample", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_grads_update", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__len__"], ["", "def", "train_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "training_steps", "+=", "1", "\n", "\n", "batch_size", "=", "min", "(", "self", ".", "config", "[", "'bc_batch_size'", "]", ",", "self", ".", "replay_memory", ".", "__len__", "(", ")", ")", "\n", "\n", "minibatch_", "=", "self", ".", "replay_memory", ".", "sample", "(", "batch_size", ",", "in_numpy_form", "=", "True", ")", "\n", "minibatch", "=", "{", "}", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "minibatch_keys", ")", ":", "\n", "            ", "if", "key", "==", "'obs'", ":", "# Float Correction", "\n", "#minibatch[key] = np.asarray(minibatch_[i], dtype=np.float32) / 255.0", "\n", "                ", "minibatch", "[", "key", "]", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "minibatch_", "[", "i", "]", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "minibatch", "[", "key", "]", "=", "minibatch_", "[", "i", "]", "\n", "\n", "", "", "loss", ",", "loss_batch", "=", "self", ".", "get_grads_update", "(", "minibatch", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_action_logits": [[179, 183], ["numpy.moveaxis", "behavioural_cloning.BehaviouralCloning.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_action_logits", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", "}", "\n", "return", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'action_logits'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_action_probs": [[186, 191], ["numpy.moveaxis", "behavioural_cloning.BehaviouralCloning.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_action_probs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "#obs = np.asarray(obs, dtype=np.float32) / 255.0", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", ",", "self", ".", "dropout_rate_ph", ":", "0.0", "}", "\n", "return", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'action_probs'", "]", ",", "feed_dict", "=", "feed_dict", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_latent_features": [[194, 198], ["numpy.moveaxis", "behavioural_cloning.BehaviouralCloning.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_latent_features", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", "}", "\n", "return", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'latent_features'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_loss": [[201, 205], ["behavioural_cloning.BehaviouralCloning.arrange_feed_dict", "behavioural_cloning.BehaviouralCloning.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_loss", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "feed_dict", ",", "is_batch", "=", "self", ".", "arrange_feed_dict", "(", "minibatch", ")", "\n", "loss_batch", "=", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'loss'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "return", "loss_batch", "if", "is_batch", "else", "loss_batch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_grads_update": [[208, 215], ["behavioural_cloning.BehaviouralCloning.arrange_feed_dict", "behavioural_cloning.BehaviouralCloning.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_grads_update", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "feed_dict", ",", "is_batch", "=", "self", ".", "arrange_feed_dict", "(", "minibatch", ")", "\n", "loss_batch", ",", "_", ",", "action_logits", ",", "loss_batch_all", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "tf_vars", "[", "'loss'", "]", ",", "self", ".", "tf_vars", "[", "'grads_update'", "]", ",", "self", ".", "tf_vars", "[", "'action_logits'", "]", ",", "\n", "self", ".", "tf_vars", "[", "'loss_batch'", "]", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "return", "loss_batch", "if", "is_batch", "else", "loss_batch", "[", "0", "]", ",", "loss_batch_all", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.arrange_feed_dict": [[218, 232], ["behavioural_cloning.BehaviouralCloning.fix_batch_form", "behavioural_cloning.BehaviouralCloning.fix_batch_form", "isinstance", "isinstance", "isinstance", "minibatch[].astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form"], ["", "def", "arrange_feed_dict", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "is_batch", "=", "isinstance", "(", "minibatch", "[", "'action'", "]", ",", "list", ")", "or", "isinstance", "(", "minibatch", "[", "'action'", "]", ",", "np", ".", "ndarray", ")", "\n", "\n", "obs_batch", "=", "minibatch", "[", "'obs'", "]", "if", "isinstance", "(", "minibatch", "[", "'obs'", "]", ",", "list", ")", "else", "minibatch", "[", "'obs'", "]", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "obs_batch", "=", "self", ".", "fix_batch_form", "(", "obs_batch", ",", "is_batch", ")", "\n", "action_batch", "=", "self", ".", "fix_batch_form", "(", "minibatch", "[", "'action'", "]", ",", "is_batch", ")", "\n", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "obs_batch", ",", "\n", "self", ".", "tf_vars", "[", "'action'", "]", ":", "action_batch", ",", "\n", "self", ".", "dropout_rate_ph", ":", "self", ".", "config", "[", "'bc_dropout_rate'", "]", "}", "\n", "\n", "return", "feed_dict", ",", "is_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_action": [[235, 239], ["behavioural_cloning.BehaviouralCloning.get_action_probs", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_action_probs"], ["", "def", "get_action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "action_probs", "=", "self", ".", "get_action_probs", "(", "obs", ")", "\n", "return", "np", ".", "argmax", "(", "action_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.restore": [[242, 250], ["print", "print", "print", "tensorflow.compat.v1.train.Saver", "tensorflow.compat.v1.train.Saver.restore", "len", "tensorflow.compat.v1.get_collection", "tensorflow.compat.v1.get_collection"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.restore"], ["", "def", "restore", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "print", "(", "'Restoring...'", ")", "\n", "print", "(", "'Scope: {}'", ".", "format", "(", "self", ".", "id", ")", ")", "\n", "print", "(", "'# of variables: {}'", ".", "format", "(", "len", "(", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "scope", "=", "self", ".", "id", ")", ")", ")", ")", "\n", "loader", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "var_list", "=", "tf", ".", "compat", ".", "v1", ".", "get_collection", "(", "tf", ".", "compat", ".", "v1", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "scope", "=", "self", ".", "id", ")", ")", "\n", "loader", ".", "restore", "(", "self", ".", "session", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_uncertainty": [[253, 270], ["numpy.moveaxis", "numpy.asarray", "numpy.var", "numpy.mean", "behavioural_cloning.BehaviouralCloning.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_uncertainty", "(", "self", ",", "obs", ",", "n_ensembles", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "#obs = np.asarray(obs, dtype=np.float32) / 255.0", "\n", "\n", "obs_batch", "=", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", "*", "n_ensembles", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "obs_batch", ",", "self", ".", "dropout_rate_ph", ":", "self", ".", "config", "[", "'bc_dropout_rate'", "]", "}", "\n", "\n", "probs", "=", "np", ".", "asarray", "(", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'action_probs'", "]", ",", "feed_dict", "=", "feed_dict", ")", ")", "\n", "\n", "#print(probs)", "\n", "#print(np.shape(probs))", "\n", "\n", "probs_vars", "=", "np", ".", "var", "(", "probs", ",", "axis", "=", "0", ")", "\n", "\n", "#print(probs_vars)", "\n", "\n", "return", "np", ".", "mean", "(", "probs_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.__init__": [[44, 91], ["gym.Wrapper.__init__", "gym.spaces.Box", "env.unwrapped.get_action_meanings", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "\n", "noop_max", "=", "30", ",", "\n", "frame_skip", "=", "4", ",", "\n", "screen_size", "=", "84", ",", "\n", "terminal_on_life_loss", "=", "False", ",", "\n", "grayscale_obs", "=", "True", ",", "\n", "grayscale_newaxis", "=", "False", ",", "\n", "scale_obs", "=", "False", ",", "\n", "clip_rewards", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "cv2", "is", "not", "None", ",", "\"opencv-python package not installed! Try running pip install gym[atari] to get dependencies  for atari\"", "\n", "assert", "frame_skip", ">", "0", "\n", "assert", "screen_size", ">", "0", "\n", "assert", "noop_max", ">=", "0", "\n", "if", "frame_skip", ">", "1", ":", "\n", "            ", "assert", "'NoFrameskip'", "in", "env", ".", "spec", ".", "id", ",", "'disable frame-skipping in the original env. for more than one'", "' frame-skip as it will be done by the wrapper'", "\n", "", "self", ".", "noop_max", "=", "noop_max", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "0", "]", "==", "'NOOP'", "\n", "\n", "self", ".", "frame_skip", "=", "frame_skip", "\n", "self", ".", "screen_size", "=", "screen_size", "\n", "self", ".", "terminal_on_life_loss", "=", "terminal_on_life_loss", "\n", "self", ".", "grayscale_obs", "=", "grayscale_obs", "\n", "self", ".", "grayscale_newaxis", "=", "grayscale_newaxis", "\n", "self", ".", "scale_obs", "=", "scale_obs", "\n", "self", ".", "clip_rewards", "=", "clip_rewards", "\n", "\n", "# buffer of most recent two observations for max pooling", "\n", "if", "grayscale_obs", ":", "\n", "            ", "self", ".", "obs_buffer", "=", "[", "np", ".", "empty", "(", "env", ".", "observation_space", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "np", ".", "empty", "(", "env", ".", "observation_space", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "obs_buffer", "=", "[", "np", ".", "empty", "(", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "np", ".", "empty", "(", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "]", "\n", "\n", "", "self", ".", "ale", "=", "env", ".", "unwrapped", ".", "ale", "\n", "self", ".", "lives", "=", "0", "\n", "self", ".", "game_over", "=", "False", "\n", "\n", "_low", ",", "_high", ",", "_obs_dtype", "=", "(", "0", ",", "255", ",", "np", ".", "uint8", ")", "if", "not", "scale_obs", "else", "(", "0", ",", "1", ",", "np", ".", "float32", ")", "\n", "_shape", "=", "(", "screen_size", ",", "screen_size", ",", "1", "if", "grayscale_obs", "else", "3", ")", "\n", "if", "grayscale_obs", "and", "not", "grayscale_newaxis", ":", "\n", "            ", "_shape", "=", "_shape", "[", ":", "-", "1", "]", "# Remove channel axis", "\n", "", "self", ".", "observation_space", "=", "Box", "(", "low", "=", "_low", ",", "high", "=", "_high", ",", "shape", "=", "_shape", ",", "dtype", "=", "_obs_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step": [[92, 125], ["range", "atari_preprocessing.AtariPreprocessing.env.step", "numpy.clip", "atari_preprocessing.AtariPreprocessing._get_obs", "atari_preprocessing.AtariPreprocessing.ale.lives", "atari_preprocessing.AtariPreprocessing.ale.getScreenGrayscale", "atari_preprocessing.AtariPreprocessing.ale.getScreenRGB2", "atari_preprocessing.AtariPreprocessing.ale.getScreenGrayscale", "atari_preprocessing.AtariPreprocessing.ale.getScreenRGB2"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing._get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "R_actual", "=", "0.0", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "frame_skip", ")", ":", "\n", "            ", "_", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "R_actual", "+=", "reward", "\n", "self", ".", "game_over", "=", "done", "\n", "\n", "if", "self", ".", "terminal_on_life_loss", ":", "\n", "                ", "new_lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "done", "=", "done", "or", "new_lives", "<", "self", ".", "lives", "\n", "self", ".", "lives", "=", "new_lives", "\n", "\n", "", "if", "done", ":", "\n", "                ", "break", "\n", "", "if", "t", "==", "self", ".", "frame_skip", "-", "2", ":", "\n", "                ", "if", "self", ".", "grayscale_obs", ":", "\n", "                    ", "self", ".", "ale", ".", "getScreenGrayscale", "(", "self", ".", "obs_buffer", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "ale", ".", "getScreenRGB2", "(", "self", ".", "obs_buffer", "[", "1", "]", ")", "\n", "", "", "elif", "t", "==", "self", ".", "frame_skip", "-", "1", ":", "\n", "                ", "if", "self", ".", "grayscale_obs", ":", "\n", "                    ", "self", ".", "ale", ".", "getScreenGrayscale", "(", "self", ".", "obs_buffer", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "ale", ".", "getScreenRGB2", "(", "self", ".", "obs_buffer", "[", "0", "]", ")", "\n", "\n", "\n", "", "", "", "if", "self", ".", "clip_rewards", ":", "\n", "            ", "R", "=", "np", ".", "clip", "(", "R_actual", ",", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "R", "=", "R_actual", "\n", "\n", "", "return", "self", ".", "_get_obs", "(", ")", ",", "R", ",", "done", ",", "info", ",", "R_actual", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset": [[126, 142], ["atari_preprocessing.AtariPreprocessing.env.reset", "range", "atari_preprocessing.AtariPreprocessing.ale.lives", "atari_preprocessing.AtariPreprocessing.obs_buffer[].fill", "atari_preprocessing.AtariPreprocessing._get_obs", "atari_preprocessing.AtariPreprocessing.env.unwrapped.np_random.randint", "atari_preprocessing.AtariPreprocessing.env.step", "atari_preprocessing.AtariPreprocessing.ale.getScreenGrayscale", "atari_preprocessing.AtariPreprocessing.ale.getScreenRGB2", "atari_preprocessing.AtariPreprocessing.env.reset"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing._get_obs", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# NoopReset", "\n", "        ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "noops", "=", "self", ".", "env", ".", "unwrapped", ".", "np_random", ".", "randint", "(", "1", ",", "self", ".", "noop_max", "+", "1", ")", "if", "self", ".", "noop_max", ">", "0", "else", "0", "\n", "for", "_", "in", "range", "(", "noops", ")", ":", "\n", "            ", "_", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "0", ")", "\n", "if", "done", ":", "\n", "                ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n", "", "", "self", ".", "lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "if", "self", ".", "grayscale_obs", ":", "\n", "            ", "self", ".", "ale", ".", "getScreenGrayscale", "(", "self", ".", "obs_buffer", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ale", ".", "getScreenRGB2", "(", "self", ".", "obs_buffer", "[", "0", "]", ")", "\n", "", "self", ".", "obs_buffer", "[", "1", "]", ".", "fill", "(", "0", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing._get_obs": [[143, 156], ["cv2.resize", "numpy.maximum", "numpy.asarray", "numpy.expand_dims", "numpy.asarray"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "frame_skip", ">", "1", ":", "# more efficient in-place pooling", "\n", "            ", "np", ".", "maximum", "(", "self", ".", "obs_buffer", "[", "0", "]", ",", "self", ".", "obs_buffer", "[", "1", "]", ",", "out", "=", "self", ".", "obs_buffer", "[", "0", "]", ")", "\n", "", "obs", "=", "cv2", ".", "resize", "(", "self", ".", "obs_buffer", "[", "0", "]", ",", "(", "self", ".", "screen_size", ",", "self", ".", "screen_size", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "\n", "if", "self", ".", "scale_obs", ":", "\n", "            ", "obs", "=", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", "\n", "", "else", ":", "\n", "            ", "obs", "=", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "", "if", "self", ".", "grayscale_obs", "and", "self", ".", "grayscale_newaxis", ":", "\n", "            ", "obs", "=", "np", ".", "expand_dims", "(", "obs", ",", "axis", "=", "-", "1", ")", "# Add a channel axis", "\n", "", "return", "obs", "", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.__init__": [[5, 29], ["dqn.DQN.__init__", "dqn_egreedy.EpsilonGreedyDQN.create_replay_memory", "dqn_egreedy.EpsilonGreedyDQN.build_network", "dqn_egreedy.EpsilonGreedyDQN.build_network", "super().build_copy_ops", "dqn_egreedy.EpsilonGreedyDQN.build_training_ops"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.create_replay_memory", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_network", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_network", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.build_copy_ops", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_training_ops"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "config", ",", "session", ",", "eps_start", ",", "eps_final", ",", "eps_steps", ",", "stats", ")", ":", "\n", "        ", "super", "(", "EpsilonGreedyDQN", ",", "self", ")", ".", "__init__", "(", "id", ",", "config", ",", "session", ",", "stats", ")", "\n", "\n", "self", ".", "create_replay_memory", "(", ")", "\n", "\n", "self", ".", "minibatch_keys", "=", "(", "'obs'", ",", "'action'", ",", "'reward'", ",", "'obs_next'", ",", "'done'", ")", "\n", "\n", "self", ".", "eps_start", "=", "eps_start", "\n", "self", ".", "eps_final", "=", "eps_final", "\n", "self", ".", "eps_steps", "=", "eps_steps", "\n", "\n", "self", ".", "eps", "=", "self", ".", "eps_start", "\n", "self", ".", "eps_step", "=", "(", "self", ".", "eps_start", "-", "self", ".", "eps_final", ")", "/", "self", ".", "eps_steps", "\n", "\n", "self", ".", "tf_vars", "[", "'pre_fc_features'", "]", ",", "self", ".", "tf_vars", "[", "'mid_fc_features'", "]", ",", "self", ".", "tf_vars", "[", "'q_values'", "]", "=", "self", ".", "build_network", "(", "self", ".", "name_online", ",", "self", ".", "tf_vars", "[", "'obs'", "]", ",", "True", ",", "self", ".", "config", "[", "'dqn_hidden_size'", "]", ",", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", ")", "\n", "\n", "self", ".", "tf_vars", "[", "'pre_fc_features_tar'", "]", ",", "self", ".", "tf_vars", "[", "'mid_fc_features_tar'", "]", ",", "self", ".", "tf_vars", "[", "'q_values_tar'", "]", "=", "self", ".", "build_network", "(", "self", ".", "name_target", ",", "self", ".", "tf_vars", "[", "'obs_tar'", "]", ",", "True", ",", "self", ".", "config", "[", "'dqn_hidden_size'", "]", ",", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", ")", "\n", "\n", "self", ".", "update_target_weights", "=", "super", "(", ")", ".", "build_copy_ops", "(", ")", "\n", "self", ".", "build_training_ops", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_network": [[32, 42], ["super().conv_layers", "super().dense_layers"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.conv_layers", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.dense_layers"], ["", "def", "build_network", "(", "self", ",", "name", ",", "input", ",", "is_dueling", ",", "dense_hidden_size", ",", "output_size", ")", ":", "\n", "        ", "pre_fc_features", "=", "super", "(", ")", ".", "conv_layers", "(", "name", ",", "input", ")", "\n", "q_values", ",", "mid_fc_features", "=", "super", "(", ")", ".", "dense_layers", "(", "name", ",", "\n", "inputs", "=", "pre_fc_features", ",", "\n", "is_dueling", "=", "is_dueling", ",", "\n", "hidden_size", "=", "dense_hidden_size", ",", "\n", "output_size", "=", "output_size", ",", "\n", "head_id", "=", "1", ")", "\n", "\n", "return", "pre_fc_features", ",", "mid_fc_features", ",", "q_values", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.build_training_ops": [[45, 77], ["tf.compat.v1.placeholder", "tf.compat.v1.placeholder", "tf.compat.v1.placeholder", "tf.compat.v1.placeholder", "tf.compat.v1.one_hot", "tf.compat.v1.reduce_sum", "tf.compat.v1.abs", "tf.compat.v1.math.multiply", "tf.compat.v1.train.AdamOptimizer", "tf.compat.v1.train.AdamOptimizer.minimize", "tf.compat.v1.math.multiply", "tf.compat.v1.losses.huber_loss", "tf.compat.v1.losses.huber_loss", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "build_training_ops", "(", "self", ")", ":", "\n", "        ", "self", ".", "tf_vars", "[", "'action'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "'ACTIONS_'", "+", "str", "(", "self", ".", "id", ")", ")", "\n", "self", ".", "tf_vars", "[", "'td_target'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ",", "[", "None", "]", ",", "\n", "name", "=", "'LABELS_'", "+", "str", "(", "self", ".", "id", ")", ")", "\n", "\n", "self", ".", "tf_vars", "[", "'source'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "'SOURCES_'", "+", "str", "(", "self", ".", "id", ")", ")", "\n", "self", ".", "tf_vars", "[", "'ims_weights'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "placeholder", "(", "tf", ".", "compat", ".", "v1", ".", "float32", ",", "[", "None", "]", ",", "\n", "name", "=", "'IMS_WEIGHTS_'", "+", "str", "(", "self", ".", "id", ")", ")", "\n", "\n", "action_one_hot", "=", "tf", ".", "compat", ".", "v1", ".", "one_hot", "(", "self", ".", "tf_vars", "[", "'action'", "]", ",", "self", ".", "config", "[", "'env_n_actions'", "]", ",", "1.0", ",", "0.0", ")", "\n", "q_values_reduced", "=", "tf", ".", "compat", ".", "v1", ".", "reduce_sum", "(", "tf", ".", "compat", ".", "v1", ".", "math", ".", "multiply", "(", "self", ".", "tf_vars", "[", "'q_values'", "]", ",", "action_one_hot", ")", ",", "\n", "reduction_indices", "=", "1", ")", "\n", "\n", "self", ".", "tf_vars", "[", "'td_error'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "abs", "(", "self", ".", "tf_vars", "[", "'td_target'", "]", "-", "q_values_reduced", ")", "\n", "\n", "# Q-Learning Loss (1-step)", "\n", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", "and", "self", ".", "config", "[", "'dqn_per_ims'", "]", ":", "\n", "            ", "loss_ql", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "huber_loss", "(", "labels", "=", "self", ".", "tf_vars", "[", "'td_target'", "]", ",", "\n", "predictions", "=", "q_values_reduced", ",", "\n", "delta", "=", "self", ".", "config", "[", "'dqn_huber_loss_delta'", "]", ",", "\n", "weights", "=", "self", ".", "tf_vars", "[", "'ims_weights'", "]", ")", "\n", "", "else", ":", "\n", "            ", "loss_ql", "=", "tf", ".", "compat", ".", "v1", ".", "losses", ".", "huber_loss", "(", "labels", "=", "self", ".", "tf_vars", "[", "'td_target'", "]", ",", "\n", "predictions", "=", "q_values_reduced", ",", "\n", "delta", "=", "self", ".", "config", "[", "'dqn_huber_loss_delta'", "]", ")", "\n", "\n", "", "self", ".", "tf_vars", "[", "'loss_ql'", "]", "=", "loss_ql", "\n", "self", ".", "tf_vars", "[", "'loss_ql_weighted'", "]", "=", "tf", ".", "compat", ".", "v1", ".", "math", ".", "multiply", "(", "self", ".", "tf_vars", "[", "'loss_ql'", "]", ",", "1.0", ")", "\n", "self", ".", "tf_vars", "[", "'loss'", "]", "=", "self", ".", "tf_vars", "[", "'loss_ql_weighted'", "]", "\n", "\n", "optimizer", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "config", "[", "'dqn_learning_rate'", "]", ",", "epsilon", "=", "self", ".", "config", "[", "'dqn_adam_eps'", "]", ")", "\n", "self", ".", "tf_vars", "[", "'grads_update'", "]", "=", "optimizer", ".", "minimize", "(", "self", ".", "tf_vars", "[", "'loss'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_observe": [[80, 86], ["dqn_egreedy.EpsilonGreedyDQN.replay_memory.add"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.add"], ["", "def", "feedback_observe", "(", "self", ",", "transition", ")", ":", "\n", "        ", "if", "transition", "[", "'done'", "]", ":", "\n", "            ", "self", ".", "n_episode", "+=", "1", "\n", "\n", "", "old_transition", "=", "self", ".", "replay_memory", ".", "add", "(", "transition", ")", "\n", "return", "old_transition", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_learn": [[89, 112], ["dqn_egreedy.EpsilonGreedyDQN.replay_memory.__len__", "dqn_egreedy.EpsilonGreedyDQN.train_model", "dqn_egreedy.EpsilonGreedyDQN.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__len__", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.train_model", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "feedback_learn", "(", "self", ")", ":", "\n", "        ", "loss", "=", "0.0", "\n", "td_error_batch", "=", "[", "0.0", "]", "\n", "\n", "perform_learning", "=", "self", ".", "replay_memory", ".", "__len__", "(", ")", ">=", "self", ".", "config", "[", "'dqn_rm_init'", "]", "\n", "\n", "if", "perform_learning", ":", "\n", "            ", "if", "self", ".", "eps", ">", "self", ".", "eps_final", ":", "\n", "                ", "self", ".", "eps", "-=", "self", ".", "eps_step", "\n", "\n", "", "self", ".", "post_init_steps", "+=", "1", "\n", "if", "self", ".", "post_init_steps", "%", "self", ".", "config", "[", "'dqn_train_period'", "]", "==", "0", ":", "\n", "\n", "                ", "td_error_batch", ",", "loss", "=", "self", ".", "train_model", "(", ")", "\n", "\n", "if", "self", ".", "training_steps_since_target_update", ">=", "self", ".", "config", "[", "'dqn_target_update'", "]", ":", "\n", "                    ", "self", ".", "training_steps_since_target_update", "=", "0", "\n", "self", ".", "session", ".", "run", "(", "self", ".", "update_target_weights", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", ":", "\n", "                    ", "self", ".", "per_beta", "+=", "self", ".", "per_beta_inc", "\n", "\n", "", "", "", "return", "td_error_batch", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.train_model": [[115, 150], ["enumerate", "dqn_egreedy.EpsilonGreedyDQN.get_grads_update", "dqn_egreedy.EpsilonGreedyDQN.replay_memory.sample", "numpy.abs", "float", "dqn_egreedy.EpsilonGreedyDQN.replay_memory.update_priorities", "dqn_egreedy.EpsilonGreedyDQN.replay_memory.sample", "numpy.moveaxis", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_grads_update", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.sample", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.update_priorities", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.replay_buffer_bc.PrioritizedReplayBuffer.sample"], ["", "def", "train_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "training_steps", "+=", "1", "\n", "self", ".", "training_steps_since_target_update", "+=", "1", "\n", "\n", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'uniform'", ":", "\n", "            ", "minibatch_", "=", "self", ".", "replay_memory", ".", "sample", "(", "self", ".", "config", "[", "'dqn_batch_size'", "]", ",", "\n", "in_numpy_form", "=", "True", ")", "\n", "", "elif", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", ":", "\n", "            ", "minibatch_", "=", "self", ".", "replay_memory", ".", "sample", "(", "self", ".", "config", "[", "'dqn_batch_size'", "]", ",", "\n", "beta", "=", "self", ".", "per_beta", ",", "\n", "in_numpy_form", "=", "True", ")", "\n", "\n", "", "minibatch", "=", "{", "}", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "minibatch_keys", ")", ":", "\n", "            ", "if", "key", "==", "'obs'", "or", "key", "==", "'obs_next'", ":", "# LazyFrames Correction", "\n", "                ", "minibatch", "[", "key", "]", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "minibatch_", "[", "i", "]", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "minibatch", "[", "key", "]", "=", "minibatch_", "[", "i", "]", "\n", "", "if", "i", "==", "4", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'uniform'", ":", "\n", "            ", "minibatch", "[", "'source'", "]", "=", "minibatch_", "[", "-", "1", "]", "[", "'source'", "]", "\n", "", "elif", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", ":", "\n", "            ", "minibatch", "[", "'source'", "]", "=", "minibatch_", "[", "-", "3", "]", "[", "'source'", "]", "\n", "minibatch", "[", "'weights'", "]", "=", "minibatch_", "[", "-", "2", "]", "\n", "minibatch", "[", "'idxes'", "]", "=", "minibatch_", "[", "-", "1", "]", "\n", "\n", "", "td_error", ",", "loss", "=", "self", ".", "get_grads_update", "(", "minibatch", ")", "\n", "prios", "=", "np", ".", "abs", "(", "td_error", "[", ":", "self", ".", "config", "[", "'dqn_batch_size'", "]", "]", ")", "+", "float", "(", "1e-6", ")", "\n", "\n", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", ":", "\n", "            ", "self", ".", "replay_memory", ".", "update_priorities", "(", "minibatch", "[", "'idxes'", "]", ",", "prios", ")", "\n", "\n", "", "return", "td_error", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_q_values": [[153, 157], ["numpy.moveaxis", "dqn_egreedy.EpsilonGreedyDQN.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_q_values", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", "}", "\n", "return", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'q_values'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_latent_features": [[158, 162], ["numpy.moveaxis", "dqn_egreedy.EpsilonGreedyDQN.session.run", "numpy.asarray", "numpy.moveaxis.astype"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_latent_features", "(", "self", ",", "obs", ")", ":", "\n", "        ", "obs", "=", "np", ".", "moveaxis", "(", "np", ".", "asarray", "(", "obs", ",", "dtype", "=", "np", ".", "float32", ")", "/", "255.0", ",", "0", ",", "-", "1", ")", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "[", "obs", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "]", "}", "\n", "return", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'latent_features'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_td_error": [[163, 167], ["dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "dqn_egreedy.EpsilonGreedyDQN.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_td_error", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "feed_dict", ",", "is_batch", "=", "self", ".", "arrange_feed_dict", "(", "minibatch", ")", "\n", "td_error_batch", "=", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'td_error'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "return", "td_error_batch", "if", "is_batch", "else", "td_error_batch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_loss": [[168, 172], ["dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "dqn_egreedy.EpsilonGreedyDQN.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_loss", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "feed_dict", ",", "is_batch", "=", "self", ".", "arrange_feed_dict", "(", "minibatch", ")", "\n", "loss_batch", "=", "self", ".", "session", ".", "run", "(", "self", ".", "tf_vars", "[", "'loss'", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "return", "loss_batch", "if", "is_batch", "else", "loss_batch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_grads_update": [[173, 181], ["dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "dqn_egreedy.EpsilonGreedyDQN.session.run"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_grads_update", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "feed_dict", ",", "is_batch", "=", "self", ".", "arrange_feed_dict", "(", "minibatch", ")", "\n", "td_error_batch", ",", "loss_batch", ",", "_", ",", "q_vals", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "tf_vars", "[", "'td_error'", "]", ",", "self", ".", "tf_vars", "[", "'loss'", "]", ",", "self", ".", "tf_vars", "[", "'grads_update'", "]", ",", "\n", "self", ".", "tf_vars", "[", "'q_values'", "]", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "return", "td_error_batch", "if", "is_batch", "else", "td_error_batch", "[", "0", "]", ",", "loss_batch", "if", "is_batch", "else", "loss_batch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_td_target": [[184, 210], ["super().fix_batch_form", "super().fix_batch_form", "super().fix_batch_form", "dqn_egreedy.EpsilonGreedyDQN.session.run", "numpy.argmax", "range", "isinstance", "isinstance", "isinstance", "obs_next_batch_in.astype", "len", "td_target_batch.append"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run"], ["", "def", "get_td_target", "(", "self", ",", "reward_batch_in", ",", "obs_next_batch_in", ",", "done_batch_in", ")", ":", "\n", "\n", "        ", "is_batch", "=", "isinstance", "(", "reward_batch_in", ",", "list", ")", "or", "isinstance", "(", "reward_batch_in", ",", "np", ".", "ndarray", ")", "\n", "\n", "obs_next_batch", "=", "obs_next_batch_in", "if", "isinstance", "(", "obs_next_batch_in", ",", "list", ")", "else", "obs_next_batch_in", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "reward_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "reward_batch_in", ",", "is_batch", ")", "\n", "obs_next_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "obs_next_batch", ",", "is_batch", ")", "\n", "done_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "done_batch_in", ",", "is_batch", ")", "\n", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "obs_next_batch", ",", "\n", "self", ".", "tf_vars", "[", "'obs_tar'", "]", ":", "obs_next_batch", "}", "\n", "\n", "q_values_next_batch", ",", "q_values_next_target_batch", "=", "self", ".", "session", ".", "run", "(", "[", "self", ".", "tf_vars", "[", "'q_values'", "]", ",", "self", ".", "tf_vars", "[", "'q_values_tar'", "]", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "action_next_batch", "=", "np", ".", "argmax", "(", "q_values_next_batch", ",", "axis", "=", "1", ")", "\n", "\n", "td_target_batch", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "reward_batch", ")", ")", ":", "\n", "            ", "td_target", "=", "reward_batch", "[", "j", "]", "+", "(", "1.0", "-", "done_batch", "[", "j", "]", ")", "*", "self", ".", "config", "[", "'dqn_gamma'", "]", "*", "q_values_next_target_batch", "[", "j", "]", "[", "action_next_batch", "[", "j", "]", "]", "\n", "td_target_batch", ".", "append", "(", "td_target", ")", "\n", "\n", "", "return", "td_target_batch", "if", "is_batch", "else", "td_target_batch", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.arrange_feed_dict": [[213, 241], ["super().fix_batch_form", "super().fix_batch_form", "super().fix_batch_form", "super().fix_batch_form", "super().fix_batch_form", "dqn_egreedy.EpsilonGreedyDQN.get_td_target", "super().fix_batch_form", "isinstance", "isinstance", "isinstance", "minibatch[].astype", "isinstance", "minibatch[].astype", "super().fix_batch_form"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_td_target", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.fix_batch_form"], ["", "def", "arrange_feed_dict", "(", "self", ",", "minibatch", ")", ":", "\n", "        ", "is_batch", "=", "isinstance", "(", "minibatch", "[", "'reward'", "]", ",", "list", ")", "or", "isinstance", "(", "minibatch", "[", "'reward'", "]", ",", "np", ".", "ndarray", ")", "\n", "\n", "obs_batch", "=", "minibatch", "[", "'obs'", "]", "if", "isinstance", "(", "minibatch", "[", "'obs'", "]", ",", "list", ")", "else", "minibatch", "[", "'obs'", "]", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "obs_next_batch", "=", "minibatch", "[", "'obs_next'", "]", "if", "isinstance", "(", "minibatch", "[", "'obs_next'", "]", ",", "list", ")", "else", "minibatch", "[", "'obs_next'", "]", ".", "astype", "(", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "obs_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "obs_batch", ",", "is_batch", ")", "\n", "action_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "minibatch", "[", "'action'", "]", ",", "is_batch", ")", "\n", "reward_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "minibatch", "[", "'reward'", "]", ",", "is_batch", ")", "\n", "obs_next_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "obs_next_batch", ",", "is_batch", ")", "\n", "done_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "minibatch", "[", "'done'", "]", ",", "is_batch", ")", "\n", "td_target_batch", "=", "self", ".", "get_td_target", "(", "reward_batch", ",", "obs_next_batch", ",", "done_batch", ")", "\n", "\n", "feed_dict", "=", "{", "self", ".", "tf_vars", "[", "'obs'", "]", ":", "obs_batch", ",", "\n", "self", ".", "tf_vars", "[", "'action'", "]", ":", "action_batch", ",", "\n", "self", ".", "tf_vars", "[", "'td_target'", "]", ":", "td_target_batch", "}", "\n", "\n", "source_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "minibatch", "[", "'source'", "]", ",", "is_batch", ")", "\n", "feed_dict", "[", "self", ".", "tf_vars", "[", "'source'", "]", "]", "=", "source_batch", "\n", "\n", "if", "self", ".", "config", "[", "'dqn_rm_type'", "]", "==", "'per'", "and", "self", ".", "config", "[", "'dqn_per_ims'", "]", ":", "\n", "            ", "ims_weights_batch", "=", "super", "(", ")", ".", "fix_batch_form", "(", "minibatch", "[", "'weights'", "]", ",", "is_batch", ")", "\n", "feed_dict", "[", "self", ".", "tf_vars", "[", "'ims_weights'", "]", "]", "=", "ims_weights_batch", "\n", "\n", "", "return", "feed_dict", ",", "is_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_action": [[244, 249], ["random.random", "super().random_action", "dqn_egreedy.EpsilonGreedyDQN.get_greedy_action"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.random_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action"], ["", "def", "get_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "eps", ":", "\n", "            ", "return", "super", "(", ")", ".", "random_action", "(", ")", ",", "True", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "get_greedy_action", "(", "obs", ")", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action": [[252, 255], ["dqn_egreedy.EpsilonGreedyDQN.get_q_values", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_q_values"], ["", "", "def", "get_greedy_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "q_values", "=", "self", ".", "get_q_values", "(", "obs", ")", "\n", "return", "np", ".", "argmax", "(", "q_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_random_action": [[256, 258], ["super().random_action"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn.DQN.random_action"], ["", "def", "get_random_action", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "random_action", "(", ")", ",", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.__init__": [[21, 49], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "env", ",", "eval_env", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "eval_env", "=", "eval_env", "\n", "\n", "self", ".", "stats", "=", "None", "\n", "self", ".", "student_agent", "=", "None", "\n", "\n", "self", ".", "episode_duration", "=", "0", "\n", "self", ".", "episode_reward", "=", "0.0", "\n", "self", ".", "steps_reward", "=", "0.0", "\n", "\n", "self", ".", "run_id", "=", "None", "\n", "\n", "self", ".", "session", "=", "None", "\n", "self", ".", "summary_writer", "=", "None", "\n", "self", ".", "saver", "=", "None", "\n", "\n", "self", ".", "teacher_agent", "=", "None", "\n", "\n", "self", ".", "action_advising_budget", "=", "None", "\n", "\n", "self", ".", "video_recorder", "=", "None", "\n", "self", ".", "save_videos_path", "=", "None", "\n", "\n", "self", ".", "bc_net", "=", "None", "\n", "self", ".", "bc_reuse_allowed", "=", "False", "\n", "self", ".", "bc_net_is_trained", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run": [[52, 347], ["str", "random.seed", "numpy.random.seed", "tensorflow.compat.v1.set_random_seed", "tensorflow.random.set_seed", "str", "print", "os.path.dirname", "os.path.join", "print", "print", "os.path.join", "os.makedirs", "os.path.join", "os.makedirs", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "tensorflow.compat.v1.InteractiveSession", "tensorflow.compat.v1.summary.FileWriter", "run_statistics.Statistics", "dqn_egreedy.EpsilonGreedyDQN", "print", "tensorflow.compat.v1.trainable_variables", "print", "tensorflow.compat.v1.train.Saver", "executor.Executor.session.run", "executor.Executor.evaluate_student_agent", "executor.Executor.reset_env", "print", "executor.Executor.session.close", "os.path.abspath", "str", "os.makedirs", "print", "tensorflow.compat.v1.ConfigProto", "print", "tensorflow.compat.v1.ConfigProto", "dqn_egreedy.EpsilonGreedyDQN", "behavioural_cloning.BehaviouralCloning", "variable.get_shape", "tensorflow.compat.v1.global_variables_initializer", "print", "executor.Executor.teacher_agent.restore", "print", "tensorflow.compat.v1.get_default_graph().finalize", "executor.Executor.student_agent.get_action", "executor.Executor.env.step", "executor.Executor.student_agent.feedback_observe", "executor.Executor.student_agent.feedback_learn", "tensorflow.compat.v1.get_default_graph", "executor.Executor.video_recorder.capture_frame", "numpy.trapz", "executor.Executor.stats.update_summary_episode", "print", "print", "print", "print", "print", "executor.Executor.reset_env", "numpy.trapz", "executor.Executor.stats.update_summary_steps", "executor.Executor.evaluate_student_agent", "executor.Executor.save_model", "pathlib.Path", "tensorflow.compat.v1.get_default_graph", "print", "print", "range", "executor.Executor.video_recorder.close", "executor.Executor.bc_net.replay_memory.__len__", "executor.Executor.bc_net.replay_memory.__len__", "executor.Executor.bc_net.feedback_learn", "executor.Executor.teacher_agent.get_greedy_action", "executor.Executor.bc_net.feedback_observe", "executor.Executor.bc_net.get_uncertainty", "numpy.argmax", "executor.Executor.teacher_agent.get_greedy_action", "executor.Executor.teacher_agent.get_greedy_action", "executor.Executor.bc_net.get_action_probs"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.run", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.evaluate_student_agent", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.reset_env", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.restore", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_observe", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_learn", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_episode", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.reset_env", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_steps", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.evaluate_student_agent", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.save_model", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__len__", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.frame_stack.LazyFrames.__len__", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_learn", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.feedback_observe", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_uncertainty", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.behavioural_cloning.BehaviouralCloning.get_action_probs"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "random", ".", "seed", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "tf", ".", "compat", ".", "v1", ".", "set_random_seed", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "tf", ".", "random", ".", "set_seed", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "\n", "self", ".", "run_id", "=", "self", ".", "config", "[", "'run_id'", "]", "\n", "self", ".", "seed_id", "=", "str", "(", "self", ".", "config", "[", "'seed'", "]", ")", "\n", "\n", "print", "(", "'Run ID: {}'", ".", "format", "(", "self", ".", "run_id", ")", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "scripts_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "workspace_dir", "=", "os", ".", "path", ".", "join", "(", "str", "(", "pathlib", ".", "Path", "(", "scripts_dir", ")", ".", "parent", ")", ")", "\n", "\n", "print", "(", "'{} (Code directory)'", ".", "format", "(", "scripts_dir", ")", ")", "\n", "print", "(", "'{} (Workspace directory)'", ".", "format", "(", "workspace_dir", ")", ")", "\n", "\n", "summaries_dir", "=", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'summaries'", ")", "\n", "os", ".", "makedirs", "(", "summaries_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "checkpoints_dir", "=", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'checkpoints'", ")", "\n", "os", ".", "makedirs", "(", "checkpoints_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "videos_dir", "=", "os", ".", "path", ".", "join", "(", "workspace_dir", ",", "'videos'", ")", "\n", "os", ".", "makedirs", "(", "videos_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "save_summary_path", "=", "os", ".", "path", ".", "join", "(", "summaries_dir", ",", "self", ".", "run_id", ",", "self", ".", "seed_id", ")", "\n", "save_model_path", "=", "os", ".", "path", ".", "join", "(", "checkpoints_dir", ",", "self", ".", "run_id", ",", "self", ".", "seed_id", ")", "\n", "self", ".", "save_videos_path", "=", "os", ".", "path", ".", "join", "(", "videos_dir", ",", "self", ".", "run_id", ",", "self", ".", "seed_id", ")", "\n", "\n", "if", "self", ".", "config", "[", "'save_models'", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_model_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "self", ".", "save_videos_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "if", "self", ".", "config", "[", "'use_gpu'", "]", ":", "\n", "            ", "print", "(", "'Using GPU.'", ")", "\n", "session_config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "\n", "#intra_op_parallelism_threads=1,", "\n", "#inter_op_parallelism_threads=1", "\n", ")", "\n", "session_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Using CPU.'", ")", "\n", "session_config", "=", "tf", ".", "compat", ".", "v1", ".", "ConfigProto", "(", "\n", "intra_op_parallelism_threads", "=", "1", ",", "\n", "inter_op_parallelism_threads", "=", "1", ",", "\n", "allow_soft_placement", "=", "True", ",", "\n", "device_count", "=", "{", "'CPU'", ":", "1", ",", "'GPU'", ":", "0", "}", ")", "\n", "\n", "", "self", ".", "session", "=", "tf", ".", "compat", ".", "v1", ".", "InteractiveSession", "(", "graph", "=", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ",", "config", "=", "session_config", ")", "\n", "\n", "self", ".", "summary_writer", "=", "tf", ".", "compat", ".", "v1", ".", "summary", ".", "FileWriter", "(", "save_summary_path", ",", "self", ".", "session", ".", "graph", ")", "\n", "\n", "self", ".", "stats", "=", "Statistics", "(", "self", ".", "summary_writer", ",", "self", ".", "session", ")", "\n", "#self.teacher_stats = Statistics(self.summary_writer, self.session)", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "self", ".", "env_info", "=", "{", "}", "\n", "\n", "env_info", "=", "ENV_INFO", "[", "self", ".", "config", "[", "'env_name'", "]", "]", "\n", "self", ".", "env_info", "[", "'max_timesteps'", "]", "=", "env_info", "[", "8", "]", "\n", "\n", "self", ".", "config", "[", "'env_type'", "]", "=", "env_info", "[", "1", "]", "\n", "self", ".", "config", "[", "'env_obs_form'", "]", "=", "env_info", "[", "2", "]", "\n", "self", ".", "config", "[", "'env_states_are_countable'", "]", "=", "env_info", "[", "3", "]", "\n", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "=", "self", ".", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "config", "[", "'env_n_actions'", "]", "=", "self", ".", "env", ".", "action_space", ".", "n", "\n", "self", ".", "config", "[", "'env_obs_dims'", "]", "=", "(", "84", ",", "84", ",", "4", ")", "# Lazy frames are enabled", "\n", "\n", "self", ".", "config", "[", "'rm_extra_content'", "]", "=", "[", "'source'", ",", "'expert_action'", "]", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Setup student agent", "\n", "self", ".", "config", "[", "'actor_id'", "]", "=", "self", ".", "run_id", "\n", "self", ".", "student_agent", "=", "EpsilonGreedyDQN", "(", "self", ".", "config", "[", "'actor_id'", "]", ",", "self", ".", "config", ",", "self", ".", "session", ",", "\n", "self", ".", "config", "[", "'dqn_eps_start'", "]", ",", "\n", "self", ".", "config", "[", "'dqn_eps_final'", "]", ",", "\n", "self", ".", "config", "[", "'dqn_eps_steps'", "]", ",", "self", ".", "stats", ")", "\n", "\n", "self", ".", "config", "[", "'actor_id'", "]", "=", "self", ".", "student_agent", ".", "id", "\n", "\n", "print", "(", "'Student ID: {}'", ".", "format", "(", "self", ".", "student_agent", ".", "id", ")", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Initialise the teacher agent", "\n", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "!=", "'none'", ":", "\n", "            ", "teacher_info", "=", "TEACHER", "[", "self", ".", "config", "[", "'env_name'", "]", "]", "\n", "self", ".", "config", "[", "'teacher_id'", "]", "=", "teacher_info", "[", "0", "]", "\n", "self", ".", "teacher_agent", "=", "EpsilonGreedyDQN", "(", "self", ".", "config", "[", "'teacher_id'", "]", ",", "self", ".", "config", ",", "self", ".", "session", ",", "0.0", ",", "0.0", ",", "1", ",", "\n", "self", ".", "stats", ")", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "==", "'ai'", ":", "\n", "            ", "self", ".", "bc_net", "=", "BehaviouralCloning", "(", "'BHC'", ",", "self", ".", "config", ",", "self", ".", "session", ",", "None", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "", "total_parameters", "=", "0", "\n", "for", "variable", "in", "tf", ".", "compat", ".", "v1", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "shape", "=", "variable", ".", "get_shape", "(", ")", "\n", "variable_parameters", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "                ", "variable_parameters", "*=", "dim", ".", "value", "\n", "", "total_parameters", "+=", "variable_parameters", "\n", "", "print", "(", "'Number of parameters: {}'", ".", "format", "(", "total_parameters", ")", ")", "\n", "\n", "self", ".", "saver", "=", "tf", ".", "compat", ".", "v1", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "None", ")", "\n", "self", ".", "session", ".", "run", "(", "tf", ".", "compat", ".", "v1", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "# Restore the teacher agent", "\n", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "!=", "'none'", ":", "\n", "            ", "print", "(", "'Restoring the teacher...'", ")", "\n", "teacher_info", "=", "TEACHER", "[", "self", ".", "config", "[", "'env_name'", "]", "]", "\n", "self", ".", "teacher_agent", ".", "restore", "(", "checkpoints_dir", ",", "teacher_info", "[", "0", "]", "+", "'/'", "+", "teacher_info", "[", "1", "]", ",", "teacher_info", "[", "2", "]", ")", "\n", "print", "(", "'done.'", ")", "\n", "\n", "", "self", ".", "action_advising_budget", "=", "self", ".", "config", "[", "'action_advising_budget'", "]", "\n", "\n", "# --------------------------------------------------------------------------------------------------------------", "\n", "\n", "if", "not", "self", ".", "config", "[", "'save_models'", "]", ":", "\n", "            ", "tf", ".", "compat", ".", "v1", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "\n", "", "self", ".", "evaluate_student_agent", "(", ")", "\n", "obs", ",", "render", "=", "self", ".", "reset_env", "(", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "==", "'ai'", ":", "\n", "                ", "if", "(", "not", "self", ".", "bc_net_is_trained", ")", "and", "self", ".", "bc_net", ".", "replay_memory", ".", "__len__", "(", ")", "==", "self", ".", "config", "[", "'action_advising_budget'", "]", ":", "\n", "\n", "                    ", "print", "(", "'Initial BC training.'", ")", "\n", "print", "(", "self", ".", "stats", ".", "n_env_steps", ",", "self", ".", "bc_net", ".", "replay_memory", ".", "__len__", "(", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "config", "[", "'bc_training_iters'", "]", ")", ":", "\n", "                        ", "self", ".", "bc_net", ".", "feedback_learn", "(", ")", "\n", "\n", "", "self", ".", "bc_net_is_trained", "=", "True", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "", "", "action", "=", "None", "\n", "\n", "self_action", ",", "action_is_explorative", "=", "self", ".", "student_agent", ".", "get_action", "(", "obs", ")", "\n", "#self_action, action_is_explorative = self.actor_agent.get_random_action()", "\n", "\n", "if", "action_is_explorative", ":", "\n", "                ", "self", ".", "stats", ".", "exploration_steps_taken", "+=", "1", "\n", "self", ".", "stats", ".", "exploration_steps_taken_cum", "+=", "1", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "\n", "", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "!=", "'none'", ":", "\n", "                ", "if", "self", ".", "config", "[", "'action_advising_method'", "]", "==", "'ai'", ":", "\n", "\n", "                    ", "bc_collection_occurred", "=", "False", "\n", "\n", "# Collection", "\n", "if", "self", ".", "action_advising_budget", ">", "0", "and", "action_is_explorative", ":", "\n", "                        ", "teacher_action", "=", "self", ".", "teacher_agent", ".", "get_greedy_action", "(", "obs", ")", "\n", "self", ".", "bc_net", ".", "feedback_observe", "(", "obs", ",", "teacher_action", ")", "\n", "bc_collection_occurred", "=", "True", "\n", "action", "=", "teacher_action", "\n", "self", ".", "action_advising_budget", "-=", "1", "\n", "self", ".", "stats", ".", "advices_taken", "+=", "1", "\n", "self", ".", "stats", ".", "advices_taken_cum", "+=", "1", "\n", "\n", "# Reuse", "\n", "", "if", "self", ".", "bc_net_is_trained", "and", "self", ".", "bc_reuse_allowed", "and", "(", "not", "bc_collection_occurred", ")", ":", "\n", "                        ", "if", "action_is_explorative", ":", "\n", "                            ", "bc_uncertainty", "=", "self", ".", "bc_net", ".", "get_uncertainty", "(", "obs", ",", "self", ".", "config", "[", "'bc_uc_ensembles'", "]", ")", "\n", "bc_action", "=", "np", ".", "argmax", "(", "self", ".", "bc_net", ".", "get_action_probs", "(", "obs", ")", ")", "\n", "teacher_action", "=", "self", ".", "teacher_agent", ".", "get_greedy_action", "(", "obs", ")", "# Oracle, for measuring accuracy", "\n", "\n", "if", "bc_uncertainty", "<", "self", ".", "config", "[", "'bc_uc_threshold'", "]", ":", "\n", "                                ", "action", "=", "bc_action", "\n", "self", ".", "stats", ".", "advices_reused", "+=", "1", "\n", "self", ".", "stats", ".", "advices_reused_cum", "+=", "1", "\n", "\n", "if", "bc_action", "==", "teacher_action", ":", "\n", "                                    ", "self", ".", "stats", ".", "advices_reused_correct", "+=", "1", "\n", "self", ".", "stats", ".", "advices_reused_correct_cum", "+=", "1", "\n", "\n", "", "", "", "", "", "elif", "self", ".", "config", "[", "'action_advising_method'", "]", "==", "'early'", ":", "\n", "                    ", "if", "self", ".", "action_advising_budget", ">", "0", "and", "action_is_explorative", ":", "\n", "                        ", "action", "=", "self", ".", "teacher_agent", ".", "get_greedy_action", "(", "obs", ")", "\n", "self", ".", "action_advising_budget", "-=", "1", "\n", "self", ".", "stats", ".", "advices_taken", "+=", "1", "\n", "self", ".", "stats", ".", "advices_taken_cum", "+=", "1", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "\n", "", "", "", "if", "action", "is", "not", "None", ":", "\n", "                ", "source", "=", "1", "\n", "self", ".", "stats", ".", "advices_used", "+=", "1", "\n", "self", ".", "stats", ".", "advices_used_cum", "+=", "1", "\n", "", "else", ":", "\n", "                ", "source", "=", "0", "\n", "action", "=", "self_action", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "# Execute action", "\n", "", "obs_next", ",", "reward", ",", "done", ",", "info", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "transition", "=", "{", "\n", "'obs'", ":", "obs", ",", "\n", "'action'", ":", "action", ",", "\n", "'reward'", ":", "reward", ",", "\n", "'obs_next'", ":", "obs_next", ",", "\n", "'done'", ":", "done", ",", "\n", "'source'", ":", "source", ",", "\n", "'expert_action'", ":", "None", "# self.teacher_agent.get_greedy_action(obs)", "\n", "}", "\n", "\n", "if", "render", ":", "\n", "                ", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "\n", "", "self", ".", "episode_reward", "+=", "reward", "\n", "self", ".", "episode_duration", "+=", "1", "\n", "\n", "self", ".", "steps_reward", "+=", "reward", "\n", "self", ".", "stats", ".", "n_env_steps", "+=", "1", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "# Feedback", "\n", "self", ".", "student_agent", ".", "feedback_observe", "(", "transition", ")", "\n", "\n", "# ----------------------------------------------------------------------------------------------------------", "\n", "\n", "td_error_batch", ",", "loss", "=", "self", ".", "student_agent", ".", "feedback_learn", "(", ")", "\n", "\n", "self", ".", "stats", ".", "loss", "+=", "loss", "\n", "obs", "=", "obs_next", "\n", "\n", "done", "=", "done", "or", "self", ".", "episode_duration", ">=", "self", ".", "env_info", "[", "'max_timesteps'", "]", "\n", "\n", "if", "done", ":", "\n", "                ", "self", ".", "stats", ".", "n_episodes", "+=", "1", "\n", "self", ".", "stats", ".", "episode_reward_auc", "+=", "np", ".", "trapz", "(", "[", "self", ".", "stats", ".", "episode_reward_last", ",", "self", ".", "episode_reward", "]", ")", "\n", "self", ".", "stats", ".", "episode_reward_last", "=", "self", ".", "episode_reward", "\n", "\n", "self", ".", "stats", ".", "update_summary_episode", "(", "self", ".", "episode_reward", ",", "self", ".", "stats", ".", "episode_reward_auc", ",", "\n", "self", ".", "episode_duration", ",", "0.0", ",", "0.0", ")", "\n", "\n", "print", "(", "'{}'", ".", "format", "(", "self", ".", "stats", ".", "n_episodes", ")", ",", "end", "=", "' | '", ")", "\n", "print", "(", "'{:.1f}'", ".", "format", "(", "self", ".", "episode_reward", ")", ",", "end", "=", "' | '", ")", "\n", "print", "(", "'{}'", ".", "format", "(", "self", ".", "episode_duration", ")", ",", "end", "=", "' | '", ")", "\n", "print", "(", "'{}'", ".", "format", "(", "self", ".", "stats", ".", "n_env_steps", ")", ",", "end", "=", "' | '", ")", "\n", "print", "(", "self", ".", "bc_reuse_allowed", ")", "\n", "\n", "if", "render", ":", "\n", "                    ", "self", ".", "video_recorder", ".", "close", "(", ")", "\n", "self", ".", "video_recorder", ".", "enabled", "=", "False", "\n", "\n", "", "obs", ",", "render", "=", "self", ".", "reset_env", "(", ")", "\n", "\n", "# Per N steps summary update", "\n", "", "if", "self", ".", "stats", ".", "n_env_steps", "%", "self", ".", "stats", ".", "n_steps_per_update", "==", "0", ":", "\n", "                ", "self", ".", "stats", ".", "steps_reward_auc", "+=", "np", ".", "trapz", "(", "[", "self", ".", "stats", ".", "steps_reward_last", ",", "self", ".", "steps_reward", "]", ")", "\n", "self", ".", "stats", ".", "steps_reward_last", "=", "self", ".", "steps_reward", "\n", "self", ".", "stats", ".", "epsilon", "=", "self", ".", "student_agent", ".", "eps", "\n", "\n", "self", ".", "stats", ".", "update_summary_steps", "(", "self", ".", "steps_reward", ",", "self", ".", "stats", ".", "steps_reward_auc", ",", "0.0", ",", "0.0", ")", "\n", "\n", "self", ".", "stats", ".", "exploration_steps_taken", "=", "0", "\n", "\n", "self", ".", "stats", ".", "advices_taken", "=", "0", "\n", "self", ".", "stats", ".", "advices_used", "=", "0", "\n", "self", ".", "stats", ".", "advices_reused", "=", "0", "\n", "self", ".", "stats", ".", "advices_reused_correct", "=", "0", "\n", "\n", "self", ".", "steps_reward", "=", "0.0", "\n", "\n", "", "if", "self", ".", "stats", ".", "n_env_steps", "%", "self", ".", "config", "[", "'evaluation_period'", "]", "==", "0", ":", "\n", "                ", "self", ".", "evaluate_student_agent", "(", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "'save_models'", "]", "and", "(", "self", ".", "stats", ".", "n_env_steps", "%", "self", ".", "config", "[", "'model_save_period'", "]", "==", "0", "or", "\n", "self", ".", "stats", ".", "n_env_steps", ">=", "self", ".", "config", "[", "'n_training_frames'", "]", ")", ":", "\n", "                ", "self", ".", "save_model", "(", "save_model_path", ")", "\n", "\n", "", "if", "self", ".", "stats", ".", "n_env_steps", ">=", "self", ".", "config", "[", "'n_training_frames'", "]", ":", "\n", "                ", "break", "\n", "\n", "", "", "print", "(", "'Env steps: {}'", ".", "format", "(", "self", ".", "stats", ".", "n_env_steps", ")", ")", "\n", "\n", "self", ".", "session", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.reset_env": [[350, 369], ["executor.Executor.env.reset", "video_recorder.VideoRecorder", "executor.Executor.video_recorder.capture_frame", "random.random", "os.path.join", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame"], ["", "def", "reset_env", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "episode_duration", "=", "0", "\n", "self", ".", "episode_reward", "=", "0.0", "\n", "\n", "render", "=", "self", ".", "stats", ".", "n_episodes", "%", "self", ".", "config", "[", "'visualization_period'", "]", "==", "0", "\n", "if", "render", ":", "\n", "            ", "self", ".", "video_recorder", "=", "video_recorder", ".", "VideoRecorder", "(", "self", ".", "env", ",", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_videos_path", ",", "'{}_{}'", ".", "format", "(", "str", "(", "self", ".", "stats", ".", "n_episodes", ")", ",", "\n", "str", "(", "self", ".", "stats", ".", "n_env_steps", ")", ")", ")", ")", "\n", "\n", "", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "if", "render", ":", "\n", "            ", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "\n", "", "self", ".", "bc_reuse_allowed", "=", "(", "self", ".", "bc_net_is_trained", "and", "random", ".", "random", "(", ")", "<", "0.5", ")", "\n", "\n", "return", "obs", ",", "render", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.evaluate_student_agent": [[372, 429], ["executor.Executor.eval_env.seed", "range", "numpy.trapz", "executor.Executor.stats.update_summary_evaluation", "print", "video_recorder.VideoRecorder", "executor.Executor.eval_env.reset", "float", "executor.Executor.student_agent.get_greedy_action", "executor.Executor.eval_env.step", "os.path.join", "video_recorder.VideoRecorder.capture_frame", "video_recorder.VideoRecorder.capture_frame", "video_recorder.VideoRecorder.close", "str", "str"], "methods", ["home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.run_statistics.Statistics.update_summary_evaluation", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.reset", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.dqn_egreedy.EpsilonGreedyDQN.get_greedy_action", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.atari_preprocessing.AtariPreprocessing.step", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.video_recorder.ImageEncoder.close"], ["", "def", "evaluate_student_agent", "(", "self", ")", ":", "\n", "        ", "eval_render", "=", "self", ".", "stats", ".", "n_evaluations", "%", "self", ".", "config", "[", "'evaluation_visualization_period'", "]", "==", "0", "\n", "\n", "eval_total_reward", "=", "0.0", "\n", "eval_duration", "=", "0", "\n", "\n", "self", ".", "eval_env", ".", "seed", "(", "self", ".", "config", "[", "'env_evaluation_seed'", "]", ")", "\n", "\n", "if", "eval_render", ":", "\n", "            ", "video_capture_eval", "=", "video_recorder", ".", "VideoRecorder", "(", "self", ".", "eval_env", ",", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_videos_path", ",", "'E_{}_{}'", ".", "format", "(", "str", "(", "self", ".", "stats", ".", "n_episodes", ")", ",", "\n", "str", "(", "self", ".", "stats", ".", "n_env_steps", ")", ")", ")", ")", "\n", "\n", "", "for", "i_eval_trial", "in", "range", "(", "self", ".", "config", "[", "'n_evaluation_trials'", "]", ")", ":", "\n", "            ", "eval_obs", "=", "self", ".", "eval_env", ".", "reset", "(", ")", "\n", "\n", "eval_episode_reward", "=", "0.0", "\n", "eval_episode_duration", "=", "0", "\n", "\n", "while", "True", ":", "\n", "                ", "if", "eval_render", ":", "\n", "                    ", "video_capture_eval", ".", "capture_frame", "(", ")", "\n", "\n", "", "eval_action", "=", "self", ".", "student_agent", ".", "get_greedy_action", "(", "eval_obs", ")", "\n", "eval_obs_next", ",", "eval_reward", ",", "eval_done", ",", "eval_info", ",", "eval_actual_reward", "=", "self", ".", "eval_env", ".", "step", "(", "eval_action", ")", "\n", "\n", "eval_episode_reward", "+=", "eval_actual_reward", "\n", "eval_duration", "+=", "1", "\n", "eval_episode_duration", "+=", "1", "\n", "eval_obs", "=", "eval_obs_next", "\n", "\n", "eval_done", "=", "eval_done", "or", "eval_episode_duration", ">=", "self", ".", "env_info", "[", "'max_timesteps'", "]", "\n", "\n", "if", "eval_done", ":", "\n", "                    ", "if", "eval_render", ":", "\n", "                        ", "video_capture_eval", ".", "capture_frame", "(", ")", "\n", "video_capture_eval", ".", "close", "(", ")", "\n", "video_capture_eval", ".", "enabled", "=", "False", "\n", "\n", "eval_render", "=", "False", "\n", "", "eval_total_reward", "+=", "eval_episode_reward", "\n", "break", "\n", "\n", "", "", "", "eval_mean_reward", "=", "eval_total_reward", "/", "float", "(", "self", ".", "config", "[", "'n_evaluation_trials'", "]", ")", "\n", "\n", "self", ".", "stats", ".", "evaluation_reward_auc", "+=", "np", ".", "trapz", "(", "[", "self", ".", "stats", ".", "evaluation_reward_last", ",", "eval_mean_reward", "]", ")", "\n", "self", ".", "stats", ".", "evaluation_reward_last", "=", "eval_mean_reward", "\n", "\n", "self", ".", "stats", ".", "n_evaluations", "+=", "1", "\n", "\n", "self", ".", "stats", ".", "update_summary_evaluation", "(", "eval_mean_reward", ",", "eval_duration", ",", "self", ".", "stats", ".", "evaluation_reward_auc", ")", "\n", "\n", "print", "(", "'Evaluation @ {} | {}'", ".", "format", "(", "self", ".", "stats", ".", "n_env_steps", ",", "eval_mean_reward", ")", ")", "\n", "\n", "return", "eval_mean_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.ercumentilhan_naive-advice-imitation.code.executor.Executor.save_model": [[432, 437], ["os.path.join().format", "print", "executor.Executor.saver.save", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "save_model_path", ")", ":", "\n", "        ", "model_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "save_model_path", ")", ",", "'model-{}.ckpt'", ")", ".", "format", "(", "\n", "self", ".", "stats", ".", "n_env_steps", ")", "\n", "print", "(", "'[{}] Saving model... {}'", ".", "format", "(", "self", ".", "stats", ".", "n_env_steps", ",", "model_path", ")", ")", "\n", "self", ".", "saver", ".", "save", "(", "self", ".", "session", ",", "model_path", ")", "\n", "", "", ""]]}