{"home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_eval.eval_once": [[64, 115], ["tensorflow.Session", "tensorflow.train.get_checkpoint_state", "tensorflow.train.Coordinator", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "saver.restore", "print", "tensorflow.get_collection", "int", "print", "tensorflow.Summary", "tf.Summary.ParseFromString", "tf.Summary.value.add", "summary_writer.add_summary", "[].split", "threads.extend", "math.ceil", "sess.run", "numpy.sum", "sess.run", "tf.train.Coordinator.request_stop", "qr.create_threads", "tf.train.Coordinator.should_stop", "datetime.datetime.now", "tf.train.get_checkpoint_state.model_checkpoint_path.split"], "function", ["None"], ["def", "eval_once", "(", "saver", ",", "summary_writer", ",", "top_k_op", ",", "summary_op", ")", ":", "\n", "  ", "\"\"\"Run Eval once.\n\n  Args:\n    saver: Saver.\n    summary_writer: Summary writer.\n    top_k_op: Top K op.\n    summary_op: Summary op.\n  \"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "FLAGS", ".", "checkpoint_dir", ")", "\n", "if", "ckpt", "and", "ckpt", ".", "model_checkpoint_path", ":", "\n", "      ", "saver", ".", "restore", "(", "sess", ",", "ckpt", ".", "model_checkpoint_path", ")", "\n", "# Assuming model_checkpoint_path looks something like:", "\n", "#   /my-favorite-path/cifar10_train/model.ckpt-0,", "\n", "# extract global_step from it.", "\n", "global_step", "=", "ckpt", ".", "model_checkpoint_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "print", "(", "'No checkpoint file found'", ")", "\n", "return", "\n", "\n", "# Start the queue runners.", "\n", "", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "try", ":", "\n", "      ", "threads", "=", "[", "]", "\n", "for", "qr", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "QUEUE_RUNNERS", ")", ":", "\n", "        ", "threads", ".", "extend", "(", "qr", ".", "create_threads", "(", "sess", ",", "coord", "=", "coord", ",", "daemon", "=", "True", ",", "\n", "start", "=", "True", ")", ")", "\n", "\n", "", "num_iter", "=", "int", "(", "math", ".", "ceil", "(", "FLAGS", ".", "num_examples", "/", "FLAGS", ".", "batch_size", ")", ")", "\n", "true_count", "=", "0", "# Counts the number of correct predictions.", "\n", "total_sample_count", "=", "num_iter", "*", "FLAGS", ".", "batch_size", "\n", "step", "=", "0", "\n", "while", "step", "<", "num_iter", "and", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "        ", "predictions", "=", "sess", ".", "run", "(", "[", "top_k_op", "]", ")", "\n", "true_count", "+=", "np", ".", "sum", "(", "predictions", ")", "\n", "step", "+=", "1", "\n", "\n", "# Compute precision @ 1.", "\n", "", "precision", "=", "true_count", "/", "total_sample_count", "\n", "print", "(", "'%s: precision @ 1 = %.3f'", "%", "(", "datetime", ".", "now", "(", ")", ",", "precision", ")", ")", "\n", "\n", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "summary", ".", "ParseFromString", "(", "sess", ".", "run", "(", "summary_op", ")", ")", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "'Precision @ 1'", ",", "simple_value", "=", "precision", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "global_step", ")", "\n", "", "except", "Exception", "as", "e", ":", "# pylint: disable=broad-except", "\n", "      ", "coord", ".", "request_stop", "(", "e", ")", "\n", "\n", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ",", "stop_grace_period_secs", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_eval.evaluate": [[117, 147], ["tensorflow.Graph().as_default", "cifar10.inputs", "cifar10.inference", "tensorflow.nn.in_top_k", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.variables_to_restore", "tensorflow.train.Saver", "tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "cifar10_eval.eval_once", "time.sleep", "tensorflow.Graph"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.inputs", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.inference", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_eval.eval_once"], ["", "", "def", "evaluate", "(", ")", ":", "\n", "  ", "\"\"\"Eval CIFAR-10 for a number of steps.\"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "g", ":", "\n", "# Get images and labels for CIFAR-10.", "\n", "    ", "eval_data", "=", "FLAGS", ".", "eval_data", "==", "'test'", "\n", "images", ",", "labels", "=", "cifar10", ".", "inputs", "(", "eval_data", "=", "eval_data", ")", "\n", "\n", "# Build a Graph that computes the logits predictions from the", "\n", "# inference model.", "\n", "logits", "=", "cifar10", ".", "inference", "(", "images", ")", "\n", "\n", "# Calculate predictions.", "\n", "top_k_op", "=", "tf", ".", "nn", ".", "in_top_k", "(", "logits", ",", "labels", ",", "1", ")", "\n", "\n", "# Restore the moving average version of the learned variables for eval.", "\n", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "cifar10", ".", "MOVING_AVERAGE_DECAY", ")", "\n", "variables_to_restore", "=", "variable_averages", ".", "variables_to_restore", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables_to_restore", ")", "\n", "\n", "# Build the summary operation based on the TF collection of Summaries.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "FLAGS", ".", "eval_dir", ",", "g", ")", "\n", "\n", "while", "True", ":", "\n", "      ", "eval_once", "(", "saver", ",", "summary_writer", ",", "top_k_op", ",", "summary_op", ")", "\n", "if", "FLAGS", ".", "run_once", ":", "\n", "        ", "break", "\n", "", "time", ".", "sleep", "(", "FLAGS", ".", "eval_interval_secs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_eval.main": [[149, 155], ["cifar10.maybe_download_and_extract", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "cifar10_eval.evaluate", "tensorflow.gfile.DeleteRecursively"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.maybe_download_and_extract", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_eval.evaluate"], ["", "", "", "def", "main", "(", "argv", "=", "None", ")", ":", "# pylint: disable=unused-argument", "\n", "  ", "cifar10", ".", "maybe_download_and_extract", "(", ")", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "FLAGS", ".", "eval_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "FLAGS", ".", "eval_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "eval_dir", ")", "\n", "evaluate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.gen_noise_tridiagonal": [[7, 23], ["numpy.zeros"], "function", ["None"], ["def", "gen_noise_tridiagonal", "(", ")", ":", "\n", "# Three diagonals", "\n", "  ", "NOISY_PROPORTION", "=", "0.6", "\n", "T", "=", "np", ".", "zeros", "(", "(", "10", ",", "10", ")", ")", "\n", "T", "[", "0", "]", "[", "0", "]", ",", "T", "[", "0", "]", "[", "1", "]", "=", "1.0", "-", "NOISY_PROPORTION", "+", "0.2", ",", "NOISY_PROPORTION", "-", "0.2", "\n", "T", "[", "1", "]", "[", "0", "]", ",", "T", "[", "1", "]", "[", "1", "]", ",", "T", "[", "1", "]", "[", "2", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "2", "]", "[", "1", "]", ",", "T", "[", "2", "]", "[", "2", "]", ",", "T", "[", "2", "]", "[", "3", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "3", "]", "[", "2", "]", ",", "T", "[", "3", "]", "[", "3", "]", ",", "T", "[", "3", "]", "[", "4", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "4", "]", "[", "3", "]", ",", "T", "[", "4", "]", "[", "4", "]", ",", "T", "[", "4", "]", "[", "5", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "5", "]", "[", "4", "]", ",", "T", "[", "5", "]", "[", "5", "]", ",", "T", "[", "5", "]", "[", "6", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "6", "]", "[", "5", "]", ",", "T", "[", "6", "]", "[", "6", "]", ",", "T", "[", "6", "]", "[", "7", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "7", "]", "[", "6", "]", ",", "T", "[", "7", "]", "[", "7", "]", ",", "T", "[", "7", "]", "[", "8", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "8", "]", "[", "7", "]", ",", "T", "[", "8", "]", "[", "8", "]", ",", "T", "[", "8", "]", "[", "9", "]", "=", "NOISY_PROPORTION", "/", "2.0", ",", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "9", "]", "[", "8", "]", ",", "T", "[", "9", "]", "[", "9", "]", "=", "NOISY_PROPORTION", "-", "0.2", ",", "1.0", "-", "NOISY_PROPORTION", "+", "0.2", "\n", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.gen_noise_column": [[24, 40], ["numpy.zeros"], "function", ["None"], ["", "def", "gen_noise_column", "(", ")", ":", "\n", "# Column disturbs", "\n", "  ", "NOISY_PROPORTION", "=", "0.6", "\n", "T", "=", "np", ".", "zeros", "(", "(", "10", ",", "10", ")", ")", "\n", "T", "[", "0", "]", "[", "0", "]", ",", "T", "[", "0", "]", "[", "3", "]", ",", "T", "[", "0", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "1", "]", "[", "1", "]", ",", "T", "[", "1", "]", "[", "3", "]", ",", "T", "[", "1", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "2", "]", "[", "2", "]", ",", "T", "[", "2", "]", "[", "3", "]", ",", "T", "[", "2", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "3", "]", "[", "3", "]", ",", "T", "[", "3", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", "+", "0.2", ",", "NOISY_PROPORTION", "-", "0.2", "\n", "T", "[", "4", "]", "[", "4", "]", ",", "T", "[", "4", "]", "[", "3", "]", ",", "T", "[", "4", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "5", "]", "[", "5", "]", ",", "T", "[", "5", "]", "[", "3", "]", "=", "1.0", "-", "NOISY_PROPORTION", "+", "0.2", ",", "NOISY_PROPORTION", "-", "0.2", "\n", "T", "[", "6", "]", "[", "6", "]", ",", "T", "[", "6", "]", "[", "3", "]", ",", "T", "[", "6", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "7", "]", "[", "7", "]", ",", "T", "[", "7", "]", "[", "3", "]", ",", "T", "[", "7", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "8", "]", "[", "8", "]", ",", "T", "[", "8", "]", "[", "3", "]", ",", "T", "[", "8", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "T", "[", "9", "]", "[", "9", "]", ",", "T", "[", "9", "]", "[", "3", "]", ",", "T", "[", "9", "]", "[", "5", "]", "=", "1.0", "-", "NOISY_PROPORTION", ",", "NOISY_PROPORTION", "/", "2.0", ",", "NOISY_PROPORTION", "/", "2.0", "\n", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.dis_noise": [[41, 43], ["xrange", "numpy.argmax", "numpy.random.multinomial"], "function", ["None"], ["", "def", "dis_noise", "(", "label", ",", "T", ")", ":", "\n", "   ", "return", "xrange", "(", "10", ")", "[", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "size", "=", "1", ",", "n", "=", "1", ",", "pvals", "=", "T", "[", "label", "]", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.inject_data": [[44, 55], ["open", "open", "f.read", "ord", "noise.dis_noise", "w.write", "f.read", "chr"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.noise.dis_noise"], ["", "def", "inject_data", "(", "noise", ",", "filename", ",", "noise_name", ")", ":", "\n", "   ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "      ", "with", "open", "(", "filename", "[", ":", "-", "4", "]", "+", "'_'", "+", "noise_name", "+", "filename", "[", "-", "4", ":", "]", ",", "'wb'", ")", "as", "w", ":", "\n", "        ", "e", "=", "f", ".", "read", "(", "3073", ")", "\n", "while", "e", ":", "\n", "          ", "label", "=", "ord", "(", "e", "[", "0", "]", ")", "\n", "#print(label)", "\n", "dis_label", "=", "dis_noise", "(", "label", ",", "noise", ")", "\n", "dis_e", "=", "chr", "(", "dis_label", ")", "+", "e", "[", "1", ":", "]", "\n", "w", ".", "write", "(", "dis_e", ")", "\n", "e", "=", "f", ".", "read", "(", "3073", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_train_GANT.train": [[72, 264], ["tensorflow.Graph().as_default", "tensorflow.train.get_or_create_global_step", "tensorflow.constant", "tensorflow.tile", "tensorflow.tile", "tensorflow.tile", "tensorflow.nn.softmax", "tensorflow.sigmoid", "cifar10_train_GANT.train.discriminator"], "function", ["None"], ["def", "train", "(", "T_est", ")", ":", "\n", "  ", "\"\"\"Train CIFAR-10 for a number of steps.\"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "# Get images and labels for CIFAR-10.", "\n", "# Force input pipeline to CPU:0 to avoid operations sometimes ending up on", "\n", "# GPU and resulting in a slow down.", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "#images, labels = cifar10.distorted_inputs()", "\n", "#images, labels = cifar10.noisy_distorted_inputs()", "\n", "      ", "images", ",", "labels", ",", "T_tru", ",", "T_mask", "=", "cifar10", ".", "noisy_distorted_inputs", "(", "return_T_flag", "=", "True", ")", "\n", "\n", "", "T_est", "=", "tf", ".", "constant", "(", "T_est", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "#### Prior and groudtruth", "\n", "T_est", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "T_est", ",", "0", ")", ",", "[", "FLAGS", ".", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "T_tru", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "T_tru", ",", "0", ")", ",", "[", "FLAGS", ".", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "T_mask", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "T_mask", ",", "0", ")", ",", "[", "FLAGS", ".", "batch_size", ",", "1", ",", "1", "]", ")", "\n", "\n", "#### generator", "\n", "with", "tf", ".", "variable_scope", "(", "'generator'", ")", "as", "scope", ":", "\n", "       ", "normal", "=", "Normal", "(", "tf", ".", "zeros", "(", "[", "1", ",", "10", "]", ")", ",", "tf", ".", "ones", "(", "[", "1", ",", "10", "]", ")", ")", "\n", "epsilon", "=", "tf", ".", "to_float", "(", "normal", ".", "sample", "(", "FLAGS", ".", "batch_size", ")", ")", "\n", "net", "=", "slim", ".", "stack", "(", "epsilon", ",", "slim", ".", "fully_connected", ",", "[", "50", ",", "50", "]", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "cifar10", ".", "NUM_CLASSES", "*", "cifar10", ".", "NUM_CLASSES", ",", "activation_fn", "=", "None", ")", "\n", "net", "=", "tf", ".", "reshape", "(", "net", ",", "[", "-", "1", ",", "cifar10", ".", "NUM_CLASSES", ",", "cifar10", ".", "NUM_CLASSES", "]", ")", "\n", "", "S", "=", "tf", ".", "nn", ".", "softmax", "(", "net", ")", "\n", "\n", "# input to discriminator", "\n", "S_mask", "=", "tf", ".", "sigmoid", "(", "(", "S", "-", "0.05", ")", "/", "0.005", ")", "\n", "\n", "#### discriminator", "\n", "def", "discriminator", "(", "input", ")", ":", "\n", "       ", "with", "tf", ".", "variable_scope", "(", "'discriminator'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "as", "scope", ":", "\n", "          ", "input", "=", "slim", ".", "flatten", "(", "input", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "input", ",", "20", ",", "activation_fn", "=", "tf", ".", "nn", ".", "sigmoid", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "1", ",", "activation_fn", "=", "None", ")", "\n", "", "return", "net", "\n", "", "D_t", "=", "discriminator", "(", "T_mask", ")", "\n", "D_s", "=", "discriminator", "(", "S_mask", ")", "\n", "\n", "#### reconstructor", "\n", "dropout", "=", "tf", ".", "constant", "(", "0.75", ")", "\n", "logits", "=", "cifar10", ".", "inference", "(", "images", ",", "dropout", ",", "dropout_flag", "=", "True", ")", "\n", "preds", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "preds_aug", "=", "tf", ".", "reshape", "(", "tf", ".", "matmul", "(", "tf", ".", "reshape", "(", "preds", ",", "[", "FLAGS", ".", "batch_size", ",", "1", ",", "-", "1", "]", ")", ",", "S", ")", ",", "[", "FLAGS", ".", "batch_size", ",", "-", "1", "]", ")", "\n", "logits_aug", "=", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "preds_aug", ",", "1e-8", ",", "1.0", "-", "1e-8", ")", ")", "\n", "\n", "#### loss ", "\n", "# R loss   ", "\n", "R_loss", "=", "cifar10", ".", "loss", "(", "logits_aug", ",", "labels", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'reconstructor loss'", ",", "R_loss", ")", "\n", "\n", "# D loss", "\n", "D_loss", "=", "-", "tf", ".", "reduce_mean", "(", "D_t", ")", "+", "tf", ".", "reduce_mean", "(", "D_s", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'discriminator loss'", ",", "D_loss", ")", "\n", "\n", "# G loss", "\n", "G_loss", "=", "R_loss", "-", "tf", ".", "reduce_mean", "(", "D_s", ")", "\n", "#G_loss = - tf.reduce_mean(D_s)", "\n", "tf", ".", "summary", ".", "scalar", "(", "'generator loss'", ",", "G_loss", ")", "\n", "\n", "# initialization of G ", "\n", "S_logits", "=", "tf", ".", "log", "(", "tf", ".", "clip_by_value", "(", "S", ",", "1e-8", ",", "1.0", "-", "1e-8", ")", ")", "\n", "Initial_G_loss", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "reduce_sum", "(", "T_est", "*", "S_logits", ",", "axis", "=", "2", ")", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# variable list", "\n", "var_C", "=", "[", "]", "\n", "var_D", "=", "[", "]", "\n", "var_G", "=", "[", "]", "\n", "for", "item", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "       ", "if", "\"generator\"", "in", "item", ".", "name", ":", "\n", "          ", "var_G", ".", "append", "(", "item", ")", "\n", "", "elif", "\"discriminator\"", "in", "item", ".", "name", ":", "\n", "          ", "var_D", ".", "append", "(", "item", ")", "\n", "", "else", ":", "\n", "          ", "var_C", ".", "append", "(", "item", ")", "\n", "\n", "#### optimizer", "\n", "# Build a Graph that trains the model with one batch of examples and", "\n", "# updates the model parameters.", "\n", "", "", "R_train_op", ",", "variable_averages", ",", "lr", "=", "cifar10", ".", "train", "(", "R_loss", ",", "global_step", ",", "var_C", ",", "return_variable_averages", "=", "True", ",", "return_lr", "=", "True", ")", "\n", "lr_DG", "=", "tf", ".", "constant", "(", "1e-5", ")", "\n", "D_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "lr_DG", ")", ".", "minimize", "(", "D_loss", ",", "var_list", "=", "var_D", ")", "\n", "G_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "lr_DG", ")", ".", "minimize", "(", "G_loss", ",", "var_list", "=", "var_G", "+", "var_C", ")", "\n", "\n", "#### optimizer for the initialization of the generator and the discriminator", "\n", "Initial_G_train_op", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "1e-4", ")", ".", "minimize", "(", "Initial_G_loss", ",", "var_list", "=", "var_G", ")", "\n", "\n", "#### weight clamping for WGAN", "\n", "clip_D", "=", "[", "var", ".", "assign", "(", "tf", ".", "clip_by_value", "(", "var", ",", "-", "0.01", ",", "0.005", ")", ")", "for", "var", "in", "var_D", "]", "\n", "\n", "class", "_LoggerHook", "(", "tf", ".", "train", ".", "SessionRunHook", ")", ":", "\n", "      ", "\"\"\"Logs loss and runtime.\"\"\"", "\n", "\n", "def", "begin", "(", "self", ")", ":", "\n", "        ", "self", ".", "_my_print_flag", "=", "False", "\n", "self", ".", "_step", "=", "-", "1", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "self", ".", "_step", "+=", "1", "\n", "return", "tf", ".", "train", ".", "SessionRunArgs", "(", "R_loss", ")", "# Asks for loss value.", "\n", "\n", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "_step", "%", "FLAGS", ".", "log_frequency", "==", "0", ":", "\n", "          ", "current_time", "=", "time", ".", "time", "(", ")", "\n", "duration", "=", "current_time", "-", "self", ".", "_start_time", "\n", "self", ".", "_start_time", "=", "current_time", "\n", "\n", "loss_value", "=", "run_values", ".", "results", "\n", "examples_per_sec", "=", "FLAGS", ".", "log_frequency", "*", "FLAGS", ".", "batch_size", "/", "duration", "\n", "sec_per_batch", "=", "float", "(", "duration", "/", "FLAGS", ".", "log_frequency", ")", "\n", "\n", "if", "self", ".", "_my_print_flag", ":", "\n", "             ", "format_str", "=", "(", "'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '", "\n", "'sec/batch)'", ")", "\n", "print", "(", "format_str", "%", "(", "datetime", ".", "now", "(", ")", ",", "self", ".", "_step", ",", "loss_value", ",", "\n", "examples_per_sec", ",", "sec_per_batch", ")", ")", "\n", "\n", "#### build scalffold for MonitoredTrainingSession to restore the variables you wish", "\n", "", "", "", "", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "FLAGS", ".", "init_dir", ")", "\n", "variables_to_restore", "=", "variable_averages", ".", "variables_to_restore", "(", ")", "\n", "#print(variables_to_restore)", "\n", "for", "var_name", "in", "variables_to_restore", ".", "keys", "(", ")", ":", "\n", "       ", "if", "(", "'generator'", "in", "var_name", ")", "or", "(", "'discriminator'", "in", "var_name", ")", "or", "(", "'RMSProp'", "in", "var_name", ")", "or", "(", "'global_step'", "in", "var_name", ")", ":", "\n", "          ", "del", "variables_to_restore", "[", "var_name", "]", "\n", "", "", "print", "(", "variables_to_restore", ")", "\n", "\n", "init_assign_op", ",", "init_feed_dict", "=", "tf", ".", "contrib", ".", "framework", ".", "assign_from_checkpoint", "(", "\n", "ckpt", ".", "model_checkpoint_path", ",", "variables_to_restore", ")", "\n", "def", "InitAssignFn", "(", "scaffold", ",", "sess", ")", ":", "\n", "       ", "sess", ".", "run", "(", "init_assign_op", ",", "init_feed_dict", ")", "\n", "\n", "", "scaffold", "=", "tf", ".", "train", ".", "Scaffold", "(", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", ",", "init_fn", "=", "InitAssignFn", ")", "\n", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "0.45", ")", "\n", "loggerHook", "=", "_LoggerHook", "(", ")", "\n", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "checkpoint_dir", "=", "FLAGS", ".", "train_dir", ",", "\n", "scaffold", "=", "scaffold", ",", "\n", "hooks", "=", "[", "tf", ".", "train", ".", "StopAtStepHook", "(", "last_step", "=", "FLAGS", ".", "max_steps", ")", ",", "\n", "tf", ".", "train", ".", "NanTensorHook", "(", "R_loss", ")", ",", "\n", "loggerHook", "]", ",", "\n", "save_checkpoint_secs", "=", "60", ",", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "log_device_placement", "=", "FLAGS", ".", "log_device_placement", ",", "gpu_options", "=", "gpu_options", ")", ")", "as", "mon_sess", ":", "\n", "\n", "#### pretrain the generator", "\n", "      ", "loggerHook", ".", "_my_print_flag", "=", "False", "\n", "res", "=", "None", "\n", "for", "i", "in", "xrange", "(", "10000", ")", ":", "\n", "         ", "res", "=", "mon_sess", ".", "run", "(", "[", "Initial_G_train_op", ",", "Initial_G_loss", ",", "T_est", ",", "S", ",", "lr", ",", "lr_DG", "]", ")", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'Step: %d\\tGenerator loss: %.3f'", "%", "(", "i", ",", "res", "[", "1", "]", ")", ")", "\n", "print", "(", "'Pre-estimation'", ",", "res", "[", "2", "]", "[", "0", "]", ")", "\n", "print", "(", "'Initialization'", ",", "res", "[", "3", "]", "[", "0", "]", ")", "\n", "\n", "#### iteratively train G and <D,R>", "\n", "", "", "loggerHook", ".", "_my_print_flag", "=", "False", "\n", "step", "=", "0", "\n", "step_control", "=", "0", "\n", "lr_", ",", "lr_DG_", "=", "res", "[", "-", "2", "]", ",", "res", "[", "-", "1", "]", "\n", "while", "not", "mon_sess", ".", "should_stop", "(", ")", ":", "\n", "# update the learning_rate of generator and discriminator to sync with the classifier", "\n", "        ", "if", "lr_DG_", ">=", "lr_", ":", "# to avoid over-tuning the transition matrix due to the learning_rate decay", "\n", "           ", "lr_DG_", "=", "lr_DG_", "/", "10.0", "\n", "# do the adversarial game", "\n", "", "if", "step", ">=", "step_control", ":", "\n", "           ", "res", "=", "mon_sess", ".", "run", "(", "[", "G_train_op", ",", "G_loss", ",", "T_est", ",", "S", ",", "T_tru", ",", "S_mask", ",", "T_mask", "]", ",", "feed_dict", "=", "{", "lr_DG", ":", "lr_DG_", "}", ")", "\n", "g_loss", "=", "res", "[", "1", "]", "\n", "\n", "for", "i", "in", "xrange", "(", "5", ")", ":", "\n", "              ", "_", ",", "d_loss", "=", "mon_sess", ".", "run", "(", "[", "D_train_op", ",", "D_loss", "]", ",", "feed_dict", "=", "{", "lr_DG", ":", "lr_DG_", "}", ")", "\n", "\n", "# train the classifier", "\n", "", "", "_", ",", "r_loss", ",", "g_step", ",", "lr_", ",", "lr_DG_", "=", "mon_sess", ".", "run", "(", "[", "R_train_op", ",", "R_loss", ",", "global_step", ",", "lr", ",", "lr_DG", "]", ",", "feed_dict", "=", "{", "lr_DG", ":", "lr_DG_", "}", ")", "\n", "\n", "if", "step", ">=", "step_control", ":", "\n", "           ", "print", "(", "'Step: %d\\tR_loss: %.3f\\tD_loss: %.3f\\tG_loss: %.3f'", "%", "(", "g_step", ",", "r_loss", ",", "d_loss", ",", "g_loss", ")", ")", "\n", "\n", "if", "(", "g_step", "%", "2000", "==", "0", ")", "or", "(", "g_step", "==", "FLAGS", ".", "max_steps", "-", "1", ")", ":", "\n", "             ", "print", "(", "'Pre-estimation'", ",", "res", "[", "2", "]", "[", "0", "]", ")", "\n", "print", "(", "'Generated sample'", ",", "res", "[", "3", "]", "[", "0", "]", ")", "\n", "print", "(", "'True transition'", ",", "res", "[", "4", "]", "[", "0", "]", ")", "\n", "print", "(", "'Generated structure'", ",", "res", "[", "5", "]", "[", "0", "]", ")", "\n", "print", "(", "'True structure'", ",", "res", "[", "6", "]", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "           ", "print", "(", "'Step: %d\\tR_loss: %.3f'", "%", "(", "g_step", ",", "r_loss", ")", ")", "\n", "\n", "", "step", "=", "g_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_train_GANT.main": [[265, 274], ["cifar10.maybe_download_and_extract", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "cifar10_train_GANT.train", "tensorflow.gfile.DeleteRecursively", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.maybe_download_and_extract", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.train"], ["", "", "", "", "def", "main", "(", "argv", "=", "None", ")", ":", "# pylint: disable=unused-argument", "\n", "  ", "cifar10", ".", "maybe_download_and_extract", "(", ")", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "FLAGS", ".", "train_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "train_dir", ")", "\n", "with", "open", "(", "'T.pkl'", ")", "as", "f", ":", "\n", "     ", "T", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "print", "(", "'estimated confusion matrix\\n'", ",", "T", ")", "\n", "train", "(", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_train.train": [[61, 126], ["tensorflow.Graph().as_default", "tensorflow.train.get_or_create_global_step", "tensorflow.placeholder", "cifar10.inference", "cifar10.loss", "cifar10.train", "tensorflow.GPUOptions", "tensorflow.device", "cifar10.noisy_distorted_inputs", "tensorflow.train.MonitoredTrainingSession", "tensorflow.Graph", "time.time", "tensorflow.train.SessionRunArgs", "mon_sess.should_stop", "mon_sess.run", "time.time", "float", "print", "tensorflow.ConfigProto", "print", "print", "tensorflow.train.StopAtStepHook", "tensorflow.train.NanTensorHook", "_LoggerHook", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.inference", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.loss", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.train", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.noisy_distorted_inputs"], ["def", "train", "(", ")", ":", "\n", "  ", "\"\"\"Train CIFAR-10 for a number of steps.\"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "# Get images and labels for CIFAR-10.", "\n", "# Force input pipeline to CPU:0 to avoid operations sometimes ending up on", "\n", "# GPU and resulting in a slow down.", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "#images, labels = cifar10.distorted_inputs()", "\n", "      ", "images", ",", "labels", ",", "T", ",", "T_mask", "=", "cifar10", ".", "noisy_distorted_inputs", "(", "return_T_flag", "=", "True", ")", "\n", "\n", "# Build a Graph that computes the logits predictions from the", "\n", "# inference model.", "\n", "", "dropout", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'dropout_rate'", ")", "\n", "logits", "=", "cifar10", ".", "inference", "(", "images", ",", "dropout", ",", "dropout_flag", "=", "True", ")", "\n", "\n", "# Calculate loss.", "\n", "loss", "=", "cifar10", ".", "loss", "(", "logits", ",", "labels", ")", "\n", "\n", "# Build a Graph that trains the model with one batch of examples and", "\n", "# updates the model parameters.", "\n", "train_op", "=", "cifar10", ".", "train", "(", "loss", ",", "global_step", ")", "\n", "\n", "class", "_LoggerHook", "(", "tf", ".", "train", ".", "SessionRunHook", ")", ":", "\n", "      ", "\"\"\"Logs loss and runtime.\"\"\"", "\n", "\n", "def", "begin", "(", "self", ")", ":", "\n", "        ", "self", ".", "_step", "=", "-", "1", "\n", "self", ".", "_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "def", "before_run", "(", "self", ",", "run_context", ")", ":", "\n", "        ", "self", ".", "_step", "+=", "1", "\n", "return", "tf", ".", "train", ".", "SessionRunArgs", "(", "loss", ")", "# Asks for loss value.", "\n", "\n", "", "def", "after_run", "(", "self", ",", "run_context", ",", "run_values", ")", ":", "\n", "        ", "if", "self", ".", "_step", "%", "FLAGS", ".", "log_frequency", "==", "0", ":", "\n", "          ", "current_time", "=", "time", ".", "time", "(", ")", "\n", "duration", "=", "current_time", "-", "self", ".", "_start_time", "\n", "self", ".", "_start_time", "=", "current_time", "\n", "\n", "loss_value", "=", "run_values", ".", "results", "\n", "examples_per_sec", "=", "FLAGS", ".", "log_frequency", "*", "FLAGS", ".", "batch_size", "/", "duration", "\n", "sec_per_batch", "=", "float", "(", "duration", "/", "FLAGS", ".", "log_frequency", ")", "\n", "\n", "format_str", "=", "(", "'%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '", "\n", "'sec/batch)'", ")", "\n", "print", "(", "format_str", "%", "(", "datetime", ".", "now", "(", ")", ",", "self", ".", "_step", ",", "loss_value", ",", "\n", "examples_per_sec", ",", "sec_per_batch", ")", ")", "\n", "\n", "", "", "", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "per_process_gpu_memory_fraction", "=", "0.45", ")", "\n", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "checkpoint_dir", "=", "FLAGS", ".", "train_dir", ",", "\n", "hooks", "=", "[", "tf", ".", "train", ".", "StopAtStepHook", "(", "last_step", "=", "FLAGS", ".", "max_steps", ")", ",", "\n", "tf", ".", "train", ".", "NanTensorHook", "(", "loss", ")", ",", "\n", "_LoggerHook", "(", ")", "]", ",", "\n", "save_checkpoint_secs", "=", "60", ",", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "log_device_placement", "=", "FLAGS", ".", "log_device_placement", ",", "gpu_options", "=", "gpu_options", ")", ")", "as", "mon_sess", ":", "\n", "      ", "while", "not", "mon_sess", ".", "should_stop", "(", ")", ":", "\n", "#mon_sess.run(train_op,feed_dict={dropout:0.75})", "\n", "        ", "res", "=", "mon_sess", ".", "run", "(", "[", "train_op", ",", "global_step", ",", "T", ",", "T_mask", "]", ",", "feed_dict", "=", "{", "dropout", ":", "0.75", "}", ")", "\n", "if", "res", "[", "1", "]", "%", "1000", "==", "0", ":", "\n", "           ", "print", "(", "'Disturbing matrix\\n'", ",", "res", "[", "2", "]", ")", "\n", "print", "(", "'Masked structure\\n'", ",", "res", "[", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_train.main": [[127, 133], ["cifar10.maybe_download_and_extract", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "cifar10_train.train", "tensorflow.gfile.DeleteRecursively"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.maybe_download_and_extract", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.train"], ["", "", "", "", "", "def", "main", "(", "argv", "=", "None", ")", ":", "# pylint: disable=unused-argument", "\n", "  ", "cifar10", ".", "maybe_download_and_extract", "(", ")", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "FLAGS", ".", "train_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "FLAGS", ".", "train_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "FLAGS", ".", "train_dir", ")", "\n", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary": [[80, 97], ["re.sub", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.nn.zero_fraction"], "function", ["None"], ["def", "_activation_summary", "(", "x", ")", ":", "\n", "  ", "\"\"\"Helper to create summaries for activations.\n\n  Creates a summary that provides a histogram of activations.\n  Creates a summary that measures the sparsity of activations.\n\n  Args:\n    x: Tensor\n  Returns:\n    nothing\n  \"\"\"", "\n", "# Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training", "\n", "# session. This helps the clarity of presentation on tensorboard.", "\n", "tensor_name", "=", "re", ".", "sub", "(", "'%s_[0-9]*/'", "%", "TOWER_NAME", ",", "''", ",", "x", ".", "op", ".", "name", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "tensor_name", "+", "'/activations'", ",", "x", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "tensor_name", "+", "'/sparsity'", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu": [[99, 114], ["tensorflow.device", "tensorflow.get_variable"], "function", ["None"], ["", "def", "_variable_on_cpu", "(", "name", ",", "shape", ",", "initializer", ")", ":", "\n", "  ", "\"\"\"Helper to create a Variable stored on CPU memory.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n\n  Returns:\n    Variable Tensor\n  \"\"\"", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "    ", "dtype", "=", "tf", ".", "float16", "if", "FLAGS", ".", "use_fp16", "else", "tf", ".", "float32", "\n", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", ",", "initializer", "=", "initializer", ",", "dtype", "=", "dtype", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay": [[116, 141], ["cifar10._variable_on_cpu", "tensorflow.truncated_normal_initializer", "tensorflow.multiply", "tensorflow.add_to_collection", "tensorflow.nn.l2_loss"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu"], ["", "def", "_variable_with_weight_decay", "(", "name", ",", "shape", ",", "stddev", ",", "wd", ")", ":", "\n", "  ", "\"\"\"Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    stddev: standard deviation of a truncated Gaussian\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n\n  Returns:\n    Variable Tensor\n  \"\"\"", "\n", "dtype", "=", "tf", ".", "float16", "if", "FLAGS", ".", "use_fp16", "else", "tf", ".", "float32", "\n", "var", "=", "_variable_on_cpu", "(", "\n", "name", ",", "\n", "shape", ",", "\n", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ",", "dtype", "=", "dtype", ")", ")", "\n", "if", "wd", "is", "not", "None", ":", "\n", "    ", "weight_decay", "=", "tf", ".", "multiply", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ",", "wd", ",", "name", "=", "'weight_loss'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "weight_decay", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.distorted_inputs": [[143, 162], ["os.path.join", "cifar10_input.distorted_inputs", "ValueError", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.distorted_inputs"], ["", "def", "distorted_inputs", "(", ")", ":", "\n", "  ", "\"\"\"Construct distorted input for CIFAR training using the Reader ops.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n\n  Raises:\n    ValueError: If no data_dir\n  \"\"\"", "\n", "if", "not", "FLAGS", ".", "data_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'Please supply a data_dir'", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'cifar-10-batches-bin'", ")", "\n", "images", ",", "labels", "=", "cifar10_input", ".", "distorted_inputs", "(", "data_dir", "=", "data_dir", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ")", "\n", "if", "FLAGS", ".", "use_fp16", ":", "\n", "    ", "images", "=", "tf", ".", "cast", "(", "images", ",", "tf", ".", "float16", ")", "\n", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float16", ")", "\n", "", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.noisy_distorted_inputs": [[163, 190], ["os.path.join", "ValueError", "cifar10_input.noisy_distorted_inputs", "cifar10_input.noisy_distorted_inputs", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.noisy_distorted_inputs", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.noisy_distorted_inputs"], ["", "def", "noisy_distorted_inputs", "(", "return_T_flag", "=", "False", ")", ":", "\n", "  ", "\"\"\"Construct distorted input for CIFAR training using the Reader ops.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n\n  Raises:\n    ValueError: If no data_dir\n  \"\"\"", "\n", "if", "not", "FLAGS", ".", "data_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'Please supply a data_dir'", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'cifar-10-batches-bin'", ")", "\n", "if", "return_T_flag", ":", "\n", "    ", "images", ",", "labels", ",", "T", ",", "T_mask", "=", "cifar10_input", ".", "noisy_distorted_inputs", "(", "data_dir", "=", "data_dir", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "return_T_flag", "=", "return_T_flag", ")", "\n", "", "else", ":", "\n", "    ", "images", ",", "labels", "=", "cifar10_input", ".", "noisy_distorted_inputs", "(", "data_dir", "=", "data_dir", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "return_T_flag", "=", "return_T_flag", ")", "\n", "", "if", "FLAGS", ".", "use_fp16", ":", "\n", "    ", "images", "=", "tf", ".", "cast", "(", "images", ",", "tf", ".", "float16", ")", "\n", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float16", ")", "\n", "\n", "", "if", "return_T_flag", ":", "\n", "    ", "return", "images", ",", "labels", ",", "T", ",", "T_mask", "\n", "", "else", ":", "\n", "    ", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.inputs": [[191, 214], ["os.path.join", "cifar10_input.inputs", "ValueError", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.inputs"], ["", "", "def", "inputs", "(", "eval_data", ",", "batch_size", "=", "FLAGS", ".", "batch_size", ")", ":", "\n", "  ", "\"\"\"Construct input for CIFAR evaluation using the Reader ops.\n\n  Args:\n    eval_data: bool, indicating if one should use the train or eval data set.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n\n  Raises:\n    ValueError: If no data_dir\n  \"\"\"", "\n", "if", "not", "FLAGS", ".", "data_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'Please supply a data_dir'", ")", "\n", "", "data_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'cifar-10-batches-bin'", ")", "\n", "images", ",", "labels", "=", "cifar10_input", ".", "inputs", "(", "eval_data", "=", "eval_data", ",", "\n", "data_dir", "=", "data_dir", ",", "\n", "batch_size", "=", "batch_size", ")", "\n", "if", "FLAGS", ".", "use_fp16", ":", "\n", "    ", "images", "=", "tf", ".", "cast", "(", "images", ",", "tf", ".", "float16", ")", "\n", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float16", ")", "\n", "", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.inference": [[216, 304], ["tensorflow.nn.max_pool", "tensorflow.nn.lrn", "tensorflow.nn.lrn", "tensorflow.nn.max_pool", "tensorflow.variable_scope", "cifar10._variable_with_weight_decay", "tensorflow.nn.conv2d", "cifar10._variable_on_cpu", "tensorflow.nn.bias_add", "tensorflow.nn.relu", "cifar10._activation_summary", "tensorflow.variable_scope", "cifar10._variable_with_weight_decay", "tensorflow.nn.conv2d", "cifar10._variable_on_cpu", "tensorflow.nn.bias_add", "tensorflow.nn.relu", "cifar10._activation_summary", "tensorflow.variable_scope", "tensorflow.reshape", "cifar10._variable_with_weight_decay", "cifar10._variable_on_cpu", "tensorflow.nn.relu", "cifar10._activation_summary", "tensorflow.variable_scope", "cifar10._variable_with_weight_decay", "cifar10._variable_on_cpu", "tensorflow.nn.relu", "cifar10._activation_summary", "tensorflow.variable_scope", "cifar10._variable_with_weight_decay", "cifar10._variable_on_cpu", "tensorflow.add", "cifar10._activation_summary", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.nn.dropout", "tensorflow.constant_initializer", "tensorflow.nn.dropout", "tensorflow.constant_initializer", "tensorflow.matmul", "tf.reshape.get_shape", "tensorflow.matmul", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_with_weight_decay", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._variable_on_cpu", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._activation_summary"], ["", "def", "inference", "(", "images", ",", "dropout", "=", "None", ",", "dropout_flag", "=", "None", ")", ":", "\n", "  ", "\"\"\"Build the CIFAR-10 model.\n\n  Args:\n    images: Images returned from distorted_inputs() or inputs().\n\n  Returns:\n    Logits.\n  \"\"\"", "\n", "# We instantiate all variables using tf.get_variable() instead of", "\n", "# tf.Variable() in order to share variables across multiple GPU training runs.", "\n", "# If we only ran this model on a single GPU, we could simplify this function", "\n", "# by replacing all instances of tf.get_variable() with tf.Variable().", "\n", "#", "\n", "# conv1", "\n", "with", "tf", ".", "variable_scope", "(", "'conv1'", ")", "as", "scope", ":", "\n", "    ", "kernel", "=", "_variable_with_weight_decay", "(", "'weights'", ",", "\n", "shape", "=", "[", "5", ",", "5", ",", "3", ",", "64", "]", ",", "\n", "stddev", "=", "5e-2", ",", "\n", "wd", "=", "None", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "images", ",", "kernel", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "biases", "=", "_variable_on_cpu", "(", "'biases'", ",", "[", "64", "]", ",", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "pre_activation", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ")", "\n", "conv1", "=", "tf", ".", "nn", ".", "relu", "(", "pre_activation", ",", "name", "=", "scope", ".", "name", ")", "\n", "_activation_summary", "(", "conv1", ")", "\n", "\n", "# pool1", "\n", "", "pool1", "=", "tf", ".", "nn", ".", "max_pool", "(", "conv1", ",", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ",", "name", "=", "'pool1'", ")", "\n", "# norm1", "\n", "norm1", "=", "tf", ".", "nn", ".", "lrn", "(", "pool1", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "\n", "name", "=", "'norm1'", ")", "\n", "\n", "# conv2", "\n", "with", "tf", ".", "variable_scope", "(", "'conv2'", ")", "as", "scope", ":", "\n", "    ", "kernel", "=", "_variable_with_weight_decay", "(", "'weights'", ",", "\n", "shape", "=", "[", "5", ",", "5", ",", "64", ",", "64", "]", ",", "\n", "stddev", "=", "5e-2", ",", "\n", "wd", "=", "None", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "norm1", ",", "kernel", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "biases", "=", "_variable_on_cpu", "(", "'biases'", ",", "[", "64", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "pre_activation", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ")", "\n", "conv2", "=", "tf", ".", "nn", ".", "relu", "(", "pre_activation", ",", "name", "=", "scope", ".", "name", ")", "\n", "_activation_summary", "(", "conv2", ")", "\n", "\n", "# norm2", "\n", "", "norm2", "=", "tf", ".", "nn", ".", "lrn", "(", "conv2", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "\n", "name", "=", "'norm2'", ")", "\n", "# pool2", "\n", "pool2", "=", "tf", ".", "nn", ".", "max_pool", "(", "norm2", ",", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "padding", "=", "'SAME'", ",", "name", "=", "'pool2'", ")", "\n", "\n", "# local3", "\n", "with", "tf", ".", "variable_scope", "(", "'local3'", ")", "as", "scope", ":", "\n", "# Move everything into depth so we can perform a single matrix multiply.", "\n", "    ", "reshape", "=", "tf", ".", "reshape", "(", "pool2", ",", "[", "FLAGS", ".", "batch_size", ",", "-", "1", "]", ")", "\n", "dim", "=", "reshape", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "weights", "=", "_variable_with_weight_decay", "(", "'weights'", ",", "shape", "=", "[", "dim", ",", "384", "]", ",", "\n", "stddev", "=", "0.04", ",", "wd", "=", "0.004", ")", "\n", "biases", "=", "_variable_on_cpu", "(", "'biases'", ",", "[", "384", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "local3", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "reshape", ",", "weights", ")", "+", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "if", "dropout_flag", ":", "\n", "       ", "local3", "=", "tf", ".", "nn", ".", "dropout", "(", "local3", ",", "dropout", ")", "\n", "", "_activation_summary", "(", "local3", ")", "\n", "\n", "# local4", "\n", "", "with", "tf", ".", "variable_scope", "(", "'local4'", ")", "as", "scope", ":", "\n", "    ", "weights", "=", "_variable_with_weight_decay", "(", "'weights'", ",", "shape", "=", "[", "384", ",", "192", "]", ",", "\n", "stddev", "=", "0.04", ",", "wd", "=", "0.004", ")", "\n", "biases", "=", "_variable_on_cpu", "(", "'biases'", ",", "[", "192", "]", ",", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "local4", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "matmul", "(", "local3", ",", "weights", ")", "+", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "if", "dropout_flag", ":", "\n", "       ", "local4", "=", "tf", ".", "nn", ".", "dropout", "(", "local4", ",", "dropout", ")", "\n", "", "_activation_summary", "(", "local4", ")", "\n", "\n", "# linear layer(WX + b),", "\n", "# We don't apply softmax here because", "\n", "# tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits", "\n", "# and performs the softmax internally for efficiency.", "\n", "", "with", "tf", ".", "variable_scope", "(", "'softmax_linear'", ")", "as", "scope", ":", "\n", "    ", "weights", "=", "_variable_with_weight_decay", "(", "'weights'", ",", "[", "192", ",", "NUM_CLASSES", "]", ",", "\n", "stddev", "=", "1", "/", "192.0", ",", "wd", "=", "None", ")", "\n", "biases", "=", "_variable_on_cpu", "(", "'biases'", ",", "[", "NUM_CLASSES", "]", ",", "\n", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "softmax_linear", "=", "tf", ".", "add", "(", "tf", ".", "matmul", "(", "local4", ",", "weights", ")", ",", "biases", ",", "name", "=", "scope", ".", "name", ")", "\n", "_activation_summary", "(", "softmax_linear", ")", "\n", "\n", "", "return", "softmax_linear", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.loss": [[306, 328], ["tensorflow.cast", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.add_to_collection", "tensorflow.add_n", "tensorflow.get_collection"], "function", ["None"], ["", "def", "loss", "(", "logits", ",", "labels", ")", ":", "\n", "  ", "\"\"\"Add L2Loss to all the trainable variables.\n\n  Add summary for \"Loss\" and \"Loss/avg\".\n  Args:\n    logits: Logits from inference().\n    labels: Labels from distorted_inputs or inputs(). 1-D tensor\n            of shape [batch_size]\n\n  Returns:\n    Loss tensor of type float.\n  \"\"\"", "\n", "# Calculate the average cross entropy loss across the batch.", "\n", "labels", "=", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "int64", ")", "\n", "cross_entropy", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", ",", "logits", "=", "logits", ",", "name", "=", "'cross_entropy_per_example'", ")", "\n", "cross_entropy_mean", "=", "tf", ".", "reduce_mean", "(", "cross_entropy", ",", "name", "=", "'cross_entropy'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "cross_entropy_mean", ")", "\n", "\n", "# The total loss is defined as the cross entropy loss plus all of the weight", "\n", "# decay terms (L2 loss).", "\n", "return", "tf", ".", "add_n", "(", "tf", ".", "get_collection", "(", "'losses'", ")", ",", "name", "=", "'total_loss'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._add_loss_summaries": [[330, 355], ["tensorflow.train.ExponentialMovingAverage", "tensorflow.get_collection", "tf.train.ExponentialMovingAverage.apply", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tf.train.ExponentialMovingAverage.average"], "function", ["None"], ["", "def", "_add_loss_summaries", "(", "total_loss", ")", ":", "\n", "  ", "\"\"\"Add summaries for losses in CIFAR-10 model.\n\n  Generates moving average for all losses and associated summaries for\n  visualizing the performance of the network.\n\n  Args:\n    total_loss: Total loss from loss().\n  Returns:\n    loss_averages_op: op for generating moving averages of losses.\n  \"\"\"", "\n", "# Compute the moving average of all individual losses and the total loss.", "\n", "loss_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "0.9", ",", "name", "=", "'avg'", ")", "\n", "losses", "=", "tf", ".", "get_collection", "(", "'losses'", ")", "\n", "loss_averages_op", "=", "loss_averages", ".", "apply", "(", "losses", "+", "[", "total_loss", "]", ")", "\n", "\n", "# Attach a scalar summary to all individual losses and the total loss; do the", "\n", "# same for the averaged version of the losses.", "\n", "for", "l", "in", "losses", "+", "[", "total_loss", "]", ":", "\n", "# Name each loss as '(raw)' and name the moving average version of the loss", "\n", "# as the original loss name.", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "l", ".", "op", ".", "name", "+", "' (raw)'", ",", "l", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "l", ".", "op", ".", "name", ",", "loss_averages", ".", "average", "(", "l", ")", ")", "\n", "\n", "", "return", "loss_averages_op", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.train": [[357, 430], ["int", "tensorflow.train.exponential_decay", "tensorflow.maximum", "tensorflow.summary.scalar", "cifar10._add_loss_summaries", "tf.train.GradientDescentOptimizer.apply_gradients", "tensorflow.trainable_variables", "tensorflow.train.ExponentialMovingAverage", "tensorflow.control_dependencies", "tensorflow.train.GradientDescentOptimizer", "tf.train.GradientDescentOptimizer.compute_gradients", "tensorflow.summary.histogram", "tf.train.ExponentialMovingAverage.apply", "tf.train.ExponentialMovingAverage.apply", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.summary.histogram", "tensorflow.trainable_variables", "capped_grads.append"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10._add_loss_summaries"], ["", "def", "train", "(", "total_loss", ",", "global_step", ",", "variable_list", "=", "None", ",", "return_variable_averages", "=", "False", ",", "return_lr", "=", "False", ")", ":", "\n", "  ", "\"\"\"Train CIFAR-10 model.\n\n  Create an optimizer and apply to all trainable variables. Add moving\n  average for all trainable variables.\n\n  Args:\n    total_loss: Total loss from loss().\n    global_step: Integer Variable counting the number of training steps\n      processed.\n  Returns:\n    train_op: op for training.\n  \"\"\"", "\n", "# Variables that affect learning rate.", "\n", "num_batches_per_epoch", "=", "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN", "/", "FLAGS", ".", "batch_size", "\n", "decay_steps", "=", "int", "(", "num_batches_per_epoch", "*", "NUM_EPOCHS_PER_DECAY", ")", "\n", "\n", "#Decay the learning rate exponentially based on the number of steps.", "\n", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "INITIAL_LEARNING_RATE", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "LEARNING_RATE_DECAY_FACTOR", ",", "\n", "staircase", "=", "True", ")", "\n", "lr", "=", "tf", ".", "maximum", "(", "lr", ",", "1e-4", ")", "# this is to balance its effect compared with other learning rates of other optimizers", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "lr", ")", "\n", "\n", "# Generate moving averages of all losses and associated summaries.", "\n", "loss_averages_op", "=", "_add_loss_summaries", "(", "total_loss", ")", "\n", "\n", "# Compute gradients.", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "loss_averages_op", "]", ")", ":", "\n", "    ", "opt", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "lr", ")", "\n", "grads", "=", "opt", ".", "compute_gradients", "(", "total_loss", ")", "\n", "\n", "", "capped_grads", "=", "[", "]", "\n", "if", "variable_list", ":", "\n", "     ", "for", "item", "in", "grads", ":", "\n", "        ", "if", "item", "[", "1", "]", "in", "variable_list", ":", "\n", "           ", "capped_grads", ".", "append", "(", "item", ")", "\n", "", "else", ":", "\n", "           ", "pass", "\n", "", "", "", "else", ":", "\n", "     ", "capped_grads", "=", "grads", "\n", "\n", "# Apply gradients.", "\n", "", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "capped_grads", ",", "global_step", "=", "global_step", ")", "\n", "\n", "# Add histograms for trainable variables.", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "    ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", ",", "var", ")", "\n", "\n", "# Add histograms for gradients.", "\n", "", "for", "grad", ",", "var", "in", "grads", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "'/gradients'", ",", "grad", ")", "\n", "\n", "# Track the moving averages of all trainable variables.", "\n", "", "", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "MOVING_AVERAGE_DECAY", ",", "global_step", ")", "\n", "if", "variable_list", ":", "\n", "     ", "variables_averages_op", "=", "variable_averages", ".", "apply", "(", "variable_list", ")", "\n", "", "else", ":", "\n", "     ", "variables_averages_op", "=", "variable_averages", ".", "apply", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "[", "apply_gradient_op", ",", "variables_averages_op", "]", ")", ":", "\n", "    ", "train_op", "=", "tf", ".", "no_op", "(", "name", "=", "'train'", ")", "\n", "\n", "", "if", "return_variable_averages", "and", "return_lr", ":", "\n", "    ", "return", "train_op", ",", "variable_averages", ",", "lr", "\n", "", "elif", "return_variable_averages", ":", "\n", "    ", "return", "train_op", ",", "variable_averages", "\n", "", "else", ":", "\n", "    ", "return", "train_op", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10.maybe_download_and_extract": [[431, 450], ["os.path.join", "os.path.join", "os.path.exists", "os.makedirs", "DATA_URL.split", "os.path.exists", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "os.path.exists", "tarfile.open().extractall", "sys.stdout.write", "sys.stdout.flush", "tarfile.open", "float", "float"], "function", ["None"], ["", "", "def", "maybe_download_and_extract", "(", ")", ":", "\n", "  ", "\"\"\"Download and extract the tarball from Alex's website.\"\"\"", "\n", "dest_directory", "=", "FLAGS", ".", "data_dir", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dest_directory", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "dest_directory", ")", "\n", "", "filename", "=", "DATA_URL", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dest_directory", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "    ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "filename", ",", "\n", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "DATA_URL", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "", "extracted_dir_path", "=", "os", ".", "path", ".", "join", "(", "dest_directory", ",", "'cifar-10-batches-bin'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "extracted_dir_path", ")", ":", "\n", "    ", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "dest_directory", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.read_cifar10": [[42, 103], ["CIFAR10Record", "tensorflow.FixedLengthRecordReader", "tf.FixedLengthRecordReader.read", "tensorflow.decode_raw", "tensorflow.cast", "tensorflow.reshape", "tensorflow.transpose", "tensorflow.strided_slice", "tensorflow.strided_slice"], "function", ["None"], ["def", "read_cifar10", "(", "filename_queue", ")", ":", "\n", "  ", "\"\"\"Reads and parses examples from CIFAR10 data files.\n\n  Recommendation: if you want N-way read parallelism, call this function\n  N times.  This will give you N independent Readers reading different\n  files & positions within those files, which will give better mixing of\n  examples.\n\n  Args:\n    filename_queue: A queue of strings with the filenames to read from.\n\n  Returns:\n    An object representing a single example, with the following fields:\n      height: number of rows in the result (32)\n      width: number of columns in the result (32)\n      depth: number of color channels in the result (3)\n      key: a scalar string Tensor describing the filename & record number\n        for this example.\n      label: an int32 Tensor with the label in the range 0..9.\n      uint8image: a [height, width, depth] uint8 Tensor with the image data\n  \"\"\"", "\n", "\n", "class", "CIFAR10Record", "(", "object", ")", ":", "\n", "    ", "pass", "\n", "", "result", "=", "CIFAR10Record", "(", ")", "\n", "\n", "# Dimensions of the images in the CIFAR-10 dataset.", "\n", "# See http://www.cs.toronto.edu/~kriz/cifar.html for a description of the", "\n", "# input format.", "\n", "label_bytes", "=", "1", "# 2 for CIFAR-100", "\n", "result", ".", "height", "=", "32", "\n", "result", ".", "width", "=", "32", "\n", "result", ".", "depth", "=", "3", "\n", "image_bytes", "=", "result", ".", "height", "*", "result", ".", "width", "*", "result", ".", "depth", "\n", "# Every record consists of a label followed by the image, with a", "\n", "# fixed number of bytes for each.", "\n", "record_bytes", "=", "label_bytes", "+", "image_bytes", "\n", "\n", "# Read a record, getting filenames from the filename_queue.  No", "\n", "# header or footer in the CIFAR-10 format, so we leave header_bytes", "\n", "# and footer_bytes at their default of 0.", "\n", "reader", "=", "tf", ".", "FixedLengthRecordReader", "(", "record_bytes", "=", "record_bytes", ")", "\n", "result", ".", "key", ",", "value", "=", "reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "# Convert from a string to a vector of uint8 that is record_bytes long.", "\n", "record_bytes", "=", "tf", ".", "decode_raw", "(", "value", ",", "tf", ".", "uint8", ")", "\n", "\n", "# The first bytes represent the label, which we convert from uint8->int32.", "\n", "result", ".", "label", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "strided_slice", "(", "record_bytes", ",", "[", "0", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "\n", "# The remaining bytes after the label represent the image, which we reshape", "\n", "# from [depth * height * width] to [depth, height, width].", "\n", "depth_major", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "strided_slice", "(", "record_bytes", ",", "[", "label_bytes", "]", ",", "\n", "[", "label_bytes", "+", "image_bytes", "]", ")", ",", "\n", "[", "result", ".", "depth", ",", "result", ".", "height", ",", "result", ".", "width", "]", ")", "\n", "# Convert from [depth, height, width] to [height, width, depth].", "\n", "result", ".", "uint8image", "=", "tf", ".", "transpose", "(", "depth_major", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input._generate_image_and_label_batch": [[105, 142], ["tensorflow.summary.image", "tensorflow.train.shuffle_batch", "tensorflow.train.batch", "tensorflow.reshape"], "function", ["None"], ["", "def", "_generate_image_and_label_batch", "(", "image", ",", "label", ",", "min_queue_examples", ",", "\n", "batch_size", ",", "shuffle", ")", ":", "\n", "  ", "\"\"\"Construct a queued batch of images and labels.\n\n  Args:\n    image: 3-D Tensor of [height, width, 3] of type.float32.\n    label: 1-D Tensor of type.int32\n    min_queue_examples: int32, minimum number of samples to retain\n      in the queue that provides of batches of examples.\n    batch_size: Number of images per batch.\n    shuffle: boolean indicating whether to use a shuffling queue.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, height, width, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"", "\n", "# Create a queue that shuffles the examples, and then", "\n", "# read 'batch_size' images + labels from the example queue.", "\n", "num_preprocess_threads", "=", "16", "\n", "if", "shuffle", ":", "\n", "    ", "images", ",", "label_batch", "=", "tf", ".", "train", ".", "shuffle_batch", "(", "\n", "[", "image", ",", "label", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "num_preprocess_threads", ",", "\n", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ",", "\n", "min_after_dequeue", "=", "min_queue_examples", ")", "\n", "", "else", ":", "\n", "    ", "images", ",", "label_batch", "=", "tf", ".", "train", ".", "batch", "(", "\n", "[", "image", ",", "label", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "num_preprocess_threads", ",", "\n", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_size", ")", "\n", "\n", "# Display the training images in the visualizer.", "\n", "", "tf", ".", "summary", ".", "image", "(", "'images'", ",", "images", ")", "\n", "\n", "return", "images", ",", "tf", ".", "reshape", "(", "label_batch", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.distorted_inputs": [[144, 212], ["tensorflow.train.string_input_producer", "cifar10_input._generate_image_and_label_batch", "tensorflow.name_scope", "cifar10_input.read_cifar10", "tensorflow.cast", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.per_image_standardization", "tf.image.per_image_standardization.set_shape", "read_cifar10.label.set_shape", "int", "print", "os.path.join", "os.path.join", "tensorflow.gfile.Exists", "ValueError", "six.moves.xrange", "six.moves.xrange"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input._generate_image_and_label_batch", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.read_cifar10"], ["", "def", "distorted_inputs", "(", "data_dir", ",", "batch_size", ",", "noise_type", "=", "None", ")", ":", "\n", "  ", "\"\"\"Construct distorted input for CIFAR training using the Reader ops.\n\n  Args:\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"", "\n", "if", "noise_type", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'data_batch_%d_%s.bin'", "%", "(", "i", ",", "noise_type", ")", ")", "\n", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "", "else", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'data_batch_%d.bin'", "%", "i", ")", "\n", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "", "for", "f", "in", "filenames", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "f", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Failed to find file: '", "+", "f", ")", "\n", "\n", "# Create a queue that produces the filenames to read.", "\n", "", "", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "'data_augmentation'", ")", ":", "\n", "# Read examples from files in the filename queue.", "\n", "    ", "read_input", "=", "read_cifar10", "(", "filename_queue", ")", "\n", "reshaped_image", "=", "tf", ".", "cast", "(", "read_input", ".", "uint8image", ",", "tf", ".", "float32", ")", "\n", "\n", "height", "=", "IMAGE_SIZE", "\n", "width", "=", "IMAGE_SIZE", "\n", "\n", "# Image processing for training the network. Note the many random", "\n", "# distortions applied to the image.", "\n", "\n", "# Randomly crop a [height, width] section of the image.", "\n", "distorted_image", "=", "tf", ".", "random_crop", "(", "reshaped_image", ",", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "\n", "# Randomly flip the image horizontally.", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "distorted_image", ")", "\n", "\n", "# Because these operations are not commutative, consider randomizing", "\n", "# the order their operation.", "\n", "# NOTE: since per_image_standardization zeros the mean and makes", "\n", "# the stddev unit, this likely has no effect see tensorflow#1458.", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_brightness", "(", "distorted_image", ",", "\n", "max_delta", "=", "63", ")", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_contrast", "(", "distorted_image", ",", "\n", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "\n", "# Subtract off the mean and divide by the variance of the pixels.", "\n", "float_image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "distorted_image", ")", "\n", "\n", "# Set the shapes of tensors.", "\n", "float_image", ".", "set_shape", "(", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "read_input", ".", "label", ".", "set_shape", "(", "[", "1", "]", ")", "\n", "\n", "# Ensure that the random shuffling has good mixing properties.", "\n", "min_fraction_of_examples_in_queue", "=", "0.4", "\n", "min_queue_examples", "=", "int", "(", "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN", "*", "\n", "min_fraction_of_examples_in_queue", ")", "\n", "print", "(", "'Filling queue with %d CIFAR images before starting to train. '", "\n", "'This will take a few minutes.'", "%", "min_queue_examples", ")", "\n", "\n", "# Generate a batch of images and labels by building up a queue of examples.", "\n", "", "return", "_generate_image_and_label_batch", "(", "float_image", ",", "read_input", ".", "label", ",", "\n", "min_queue_examples", ",", "batch_size", ",", "\n", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.noisy_distorted_inputs": [[213, 241], ["numpy.ones", "cifar10_input.distorted_inputs", "noise.gen_noise_tridiagonal", "noise.gen_noise_column", "ValueError", "numpy.equal", "tensorflow.constant", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.distorted_inputs", "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.gen_noise_tridiagonal", "home.repos.pwc.inspect_result.bhanML_Masking.None.noise.gen_noise_column"], ["", "def", "noisy_distorted_inputs", "(", "data_dir", ",", "batch_size", ",", "return_T_flag", ")", ":", "\n", "  ", "\"\"\"Construct noisy distorted input for CIFAR training using the Reader ops.\n\n  Args:\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"", "\n", "import", "noise", "\n", "if", "NOISE_TYPE", "==", "'tridiagonal'", ":", "\n", "    ", "T", "=", "noise", ".", "gen_noise_tridiagonal", "(", ")", "\n", "", "elif", "NOISE_TYPE", "==", "'column'", ":", "\n", "    ", "T", "=", "noise", ".", "gen_noise_column", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"NOISE TYPE is not properly set\"", ")", "\n", "\n", "", "T_zero_mask", "=", "np", ".", "ones", "(", "(", "10", ",", "10", ")", ")", "\n", "T_zero_mask", "[", "np", ".", "equal", "(", "T", ",", "0", ")", "]", "=", "0.0", "\n", "\n", "images", ",", "labels", "=", "distorted_inputs", "(", "data_dir", ",", "batch_size", ",", "NOISE_TYPE", ")", "\n", "\n", "if", "return_T_flag", ":", "\n", "    ", "return", "images", ",", "labels", ",", "tf", ".", "constant", "(", "T", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "tf", ".", "constant", "(", "T_zero_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "    ", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.inputs": [[242, 298], ["cifar10_input._generate_image_and_label_batch", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "cifar10_input.read_cifar10", "tensorflow.cast", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.image.per_image_standardization", "tf.image.per_image_standardization.set_shape", "read_cifar10.label.set_shape", "int", "os.path.join", "os.path.join", "tensorflow.gfile.Exists", "ValueError", "six.moves.xrange"], "function", ["home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input._generate_image_and_label_batch", "home.repos.pwc.inspect_result.bhanML_Masking.None.cifar10_input.read_cifar10"], ["", "", "def", "inputs", "(", "eval_data", ",", "data_dir", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"Construct input for CIFAR evaluation using the Reader ops.\n\n  Args:\n    eval_data: bool, indicating if one should use the train or eval data set.\n    data_dir: Path to the CIFAR-10 data directory.\n    batch_size: Number of images per batch.\n\n  Returns:\n    images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.\n    labels: Labels. 1D tensor of [batch_size] size.\n  \"\"\"", "\n", "if", "not", "eval_data", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'data_batch_%d_%s.bin'", "%", "(", "i", ",", "NOISE_TYPE", ")", ")", "\n", "for", "i", "in", "xrange", "(", "1", ",", "6", ")", "]", "\n", "num_examples_per_epoch", "=", "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN", "\n", "", "else", ":", "\n", "    ", "filenames", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test_batch.bin'", ")", "]", "\n", "num_examples_per_epoch", "=", "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL", "\n", "\n", "", "for", "f", "in", "filenames", ":", "\n", "    ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "f", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Failed to find file: '", "+", "f", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'input'", ")", ":", "\n", "# Create a queue that produces the filenames to read.", "\n", "    ", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "filenames", ")", "\n", "\n", "# Read examples from files in the filename queue.", "\n", "read_input", "=", "read_cifar10", "(", "filename_queue", ")", "\n", "reshaped_image", "=", "tf", ".", "cast", "(", "read_input", ".", "uint8image", ",", "tf", ".", "float32", ")", "\n", "\n", "height", "=", "IMAGE_SIZE", "\n", "width", "=", "IMAGE_SIZE", "\n", "\n", "# Image processing for evaluation.", "\n", "# Crop the central [height, width] of the image.", "\n", "resized_image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "reshaped_image", ",", "\n", "height", ",", "width", ")", "\n", "\n", "# Subtract off the mean and divide by the variance of the pixels.", "\n", "float_image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "resized_image", ")", "\n", "\n", "# Set the shapes of tensors.", "\n", "float_image", ".", "set_shape", "(", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "read_input", ".", "label", ".", "set_shape", "(", "[", "1", "]", ")", "\n", "\n", "# Ensure that the random shuffling has good mixing properties.", "\n", "min_fraction_of_examples_in_queue", "=", "0.4", "\n", "min_queue_examples", "=", "int", "(", "num_examples_per_epoch", "*", "\n", "min_fraction_of_examples_in_queue", ")", "\n", "\n", "# Generate a batch of images and labels by building up a queue of examples.", "\n", "", "return", "_generate_image_and_label_batch", "(", "float_image", ",", "read_input", ".", "label", ",", "\n", "min_queue_examples", ",", "batch_size", ",", "\n", "shuffle", "=", "False", ")", "\n", "", ""]]}