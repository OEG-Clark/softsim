{"home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.opts.parse_opts": [[4, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_opts", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--video_path'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Directory path of Videos'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_file'", ",", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "help", "=", "'dataset file path'", ")", "\n", "parser", ".", "add_argument", "(", "'--result_path'", ",", "default", "=", "'results'", ",", "\n", "type", "=", "str", ",", "help", "=", "'Result directory path'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'ins'", ",", "\n", "type", "=", "str", ",", "help", "=", "'Used dataset (ins | ucf101 | hmdb51)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_subset'", ",", "default", "=", "'val'", ",", "\n", "type", "=", "str", ",", "help", "=", "'validation set or test set for testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_classes'", ",", "default", "=", "256", ",", "\n", "type", "=", "int", ",", "help", "=", "'Number of classes (ucf101: 101, hmdb51: 51)'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_finetune_classes'", ",", "default", "=", "101", ",", "\n", "type", "=", "int", ",", "help", "=", "'Number of classes for fine-tuning. n_classes is set to the number when pretraining.'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_size'", ",", "default", "=", "224", ",", "\n", "type", "=", "int", ",", "help", "=", "'Height and width of inputs'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_duration'", ",", "default", "=", "16", ",", "\n", "type", "=", "int", ",", "help", "=", "'Temporal duration of inputs'", ")", "\n", "parser", ".", "add_argument", "(", "'--stride_size'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Temporal stride of inputs'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "default", "=", "None", ",", "type", "=", "int", ",", "help", "=", "'GPU id to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist-url'", ",", "default", "=", "'tcp://224.66.41.62:23456'", ",", "type", "=", "str", ",", "\n", "help", "=", "'url used to set up distributed training'", ")", "\n", "parser", ".", "add_argument", "(", "'--world-size'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of nodes for distributed training'", ")", "\n", "parser", ".", "add_argument", "(", "'--rank'", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'node rank for distributed training'", ")", "\n", "parser", ".", "add_argument", "(", "'--multiprocessing-distributed'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Use multi-processing distributed training to launch '", "\n", "'N processes per node, which has N GPUs. This is the '", "\n", "'fastest way to use PyTorch for either single node or '", "\n", "'multi node data parallel training'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist-backend'", ",", "default", "=", "'nccl'", ",", "type", "=", "str", ",", "\n", "help", "=", "'distributed backend'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_bert'", ",", "default", "=", "3e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "'Initial learning rate for BERT'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "help", "=", "'Momentum'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "default", "=", "1e-3", ",", "\n", "type", "=", "float", ",", "help", "=", "'Weight Decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_patience'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'Patience of LR scheduler. See documentation of ReduceLROnPlateau.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_factor'", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_gradient'", ",", "default", "=", "20", ",", "type", "=", "float", ",", "\n", "help", "=", "'Clip the gradient when gradient is larger than threshold'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "help", "=", "'Batch Size'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_epochs'", ",", "default", "=", "200", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--ft_bert_ep'", ",", "default", "=", "150", ",", "type", "=", "int", ",", "\n", "help", "=", "'Epoch start to finetune bert model.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--resume_path'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'Save data (.pth) of previous training'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_path'", ",", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "help", "=", "'Pretrained model (.pth)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ft_begin_index'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "'Begin block index of fine-tuning'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_train'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, training is not performed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_val'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, validation is not performed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, test is performed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_cuda'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, cuda is not used.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_cuda", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--n_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of threads for multi-thread loading'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "\n", "help", "=", "'Trained model is saved at every this epochs.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'resnet'", ",", "type", "=", "str", ",", "\n", "help", "=", "'(resnet | preresnet | wideresnet | resnext | densenet | '", ")", "\n", "parser", ".", "add_argument", "(", "'--model_depth'", ",", "default", "=", "50", ",", "type", "=", "int", ",", "\n", "help", "=", "'Depth of resnet (10 | 18 | 34 | 50 | 101)'", ")", "\n", "parser", ".", "add_argument", "(", "'--resnet_shortcut'", ",", "default", "=", "'A'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Shortcut type of resnet (A | B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dp'", ",", "default", "=", "0.", ",", "type", "=", "float", ",", "\n", "help", "=", "'possibility to set to zero.'", ")", "\n", "parser", ".", "add_argument", "(", "'--manual_seed'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Manually set random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "default", "=", "\"finetuning\"", ",", "type", "=", "str", ",", "\n", "help", "=", "'pretraining or finetuning phase'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_dim'", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "'feature dimmension in embedding space'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_frq'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "'frequency of print training log'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_k'", ",", "default", "=", "16392", ",", "type", "=", "int", ",", "\n", "help", "=", "'number of negative samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_t'", ",", "default", "=", "0.07", ",", "type", "=", "float", ",", "\n", "help", "=", "'temperature that modulates the possible distribution'", ")", "\n", "parser", ".", "add_argument", "(", "'--nce_m'", ",", "default", "=", "0.5", ",", "type", "=", "float", ",", "\n", "help", "=", "'the momentum for dynamically updating the memory'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.main": [[26, 59], ["opts.parse_opts", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "warnings.warn", "int", "main.main_worker", "torch.spawn", "torch.get_context", "mp.get_context.Queue", "torch.spawn"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.opts.parse_opts", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.main_worker"], ["def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parse_opts", "(", ")", "\n", "assert", "opt", ".", "phase", "in", "[", "\n", "'pretraining'", ",", "'finetuning'", "]", ",", "\"Only support pretraining and finetuning.\"", "\n", "\n", "if", "opt", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "warnings", ".", "warn", "(", "'You have chosen a specific GPU. This will completely '", "\n", "'disable data parallelism.'", ")", "\n", "\n", "", "if", "opt", ".", "dist_url", "==", "\"env://\"", "and", "opt", ".", "world_size", "==", "-", "1", ":", "\n", "        ", "opt", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "\n", "", "opt", ".", "distributed", "=", "opt", ".", "world_size", ">", "1", "or", "opt", ".", "multiprocessing_distributed", "\n", "\n", "ngpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "opt", ".", "multiprocessing_distributed", ":", "\n", "# Since we have ngpus_per_node processes per node, the total world_size", "\n", "# needs to be adjusted accordingly", "\n", "        ", "opt", ".", "world_size", "=", "ngpus_per_node", "*", "opt", ".", "world_size", "\n", "# Use torch.multiprocessing.spawn to launch distributed processes: the", "\n", "# main_worker process function", "\n", "if", "not", "opt", ".", "test", ":", "\n", "            ", "mp", ".", "spawn", "(", "main_worker", ",", "nprocs", "=", "ngpus_per_node", ",", "\n", "args", "=", "(", "ngpus_per_node", ",", "opt", ")", ")", "\n", "", "else", ":", "\n", "            ", "ctx", "=", "mp", ".", "get_context", "(", "'spawn'", ")", "\n", "test_results", "=", "ctx", ".", "Queue", "(", ")", "\n", "mp", ".", "spawn", "(", "main_worker", ",", "nprocs", "=", "ngpus_per_node", ",", "\n", "args", "=", "(", "ngpus_per_node", ",", "opt", ",", "test_results", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "# Simply call main_worker function", "\n", "        ", "main_worker", "(", "opt", ".", "gpu", ",", "ngpus_per_node", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.main_worker": [[61, 234], ["range", "print", "torch.init_process_group", "int", "int", "dataset.get_training_set", "len", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.generate_model", "utils.Logger", "utils.Logger", "torch.optim.SGD", "dataset.get_validation_set", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils.Logger", "model.generate_model", "dataset.get_test_set", "dataset.get_test_set.get_idx_to_label", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "model.load_state_dict", "tensorboardX.SummaryWriter", "test.test", "int", "os.path.exists", "os.makedirs", "open", "json.dump", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.CrossEntropyLoss().cuda", "os.path.join", "os.path.join", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.join", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "optim.SGD.load_state_dict", "main.train_epoch", "os.path.join", "vars", "loss.NCECriterion.NCECriterion().cuda", "NotImplementedError", "torch.utils.data.distributed.DistributedSampler.set_epoch", "main.val_finetune_epoch", "lr_scheduler.ReduceLROnPlateau.step", "test_results.get", "open", "json.dump", "torch.nn.CrossEntropyLoss", "main.val_pretrain_epoch", "main.adjuest_learning_rate", "os.path.join", "loss.NCECriterion.NCECriterion", "len"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_training_set", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.model.generate_model", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_validation_set", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.model.generate_model", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_test_set", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.get_idx_to_label", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.test.test", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.train_epoch", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.val_finetune_epoch", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.val_pretrain_epoch", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.adjuest_learning_rate"], ["", "", "def", "main_worker", "(", "gpu", ",", "ngpus_per_node", ",", "opt", ",", "test_results", "=", "None", ")", ":", "\n", "    ", "opt", ".", "gpu", "=", "gpu", "\n", "\n", "# suppress printing if not master", "\n", "\n", "if", "opt", ".", "multiprocessing_distributed", "and", "opt", ".", "gpu", "!=", "0", ":", "\n", "        ", "def", "print_pass", "(", "*", "args", ")", ":", "\n", "            ", "pass", "\n", "", "builtins", ".", "print", "=", "print_pass", "\n", "\n", "", "if", "opt", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "opt", ".", "gpu", ")", ")", "\n", "\n", "", "if", "opt", ".", "distributed", ":", "\n", "        ", "if", "opt", ".", "dist_url", "==", "\"env://\"", "and", "opt", ".", "rank", "==", "-", "1", ":", "\n", "            ", "opt", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "", "if", "opt", ".", "multiprocessing_distributed", ":", "\n", "# For multiprocessing distributed training, rank needs to be the", "\n", "# global rank among all the processes", "\n", "            ", "opt", ".", "rank", "=", "opt", ".", "rank", "*", "ngpus_per_node", "+", "gpu", "\n", "", "dist", ".", "init_process_group", "(", "backend", "=", "opt", ".", "dist_backend", ",", "init_method", "=", "opt", ".", "dist_url", ",", "\n", "world_size", "=", "opt", ".", "world_size", ",", "rank", "=", "opt", ".", "rank", ")", "\n", "opt", ".", "batch_size", "=", "int", "(", "opt", ".", "batch_size", "/", "ngpus_per_node", ")", "\n", "opt", ".", "n_threads", "=", "int", "(", "\n", "(", "opt", ".", "n_threads", "+", "ngpus_per_node", "-", "1", ")", "/", "ngpus_per_node", ")", "\n", "\n", "", "if", "opt", ".", "rank", "%", "ngpus_per_node", "==", "0", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "opt", ".", "result_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "opt", ".", "result_path", ")", "\n", "", "opt", ".", "arch", "=", "'{}-{}'", ".", "format", "(", "opt", ".", "model", ",", "opt", ".", "model_depth", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'opts.json'", ")", ",", "'w'", ")", "as", "opt_file", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "opt", ")", ",", "opt_file", ")", "\n", "\n", "", "", "if", "not", "opt", ".", "no_train", ":", "\n", "        ", "training_data", "=", "get_training_set", "(", "opt", ")", "\n", "opt", ".", "N_data", "=", "len", "(", "training_data", ")", "\n", "\n", "if", "opt", ".", "distributed", ":", "\n", "            ", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "training_data", ")", "\n", "", "else", ":", "\n", "            ", "train_sampler", "=", "None", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", "sampler", "=", "train_sampler", ")", "\n", "\n", "model", ",", "parameters", "=", "generate_model", "(", "opt", ")", "\n", "\n", "if", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "            ", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "opt", ".", "gpu", ")", "\n", "", "elif", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "            ", "criterion", "=", "NCECriterion", "(", "len", "(", "training_data", ")", ")", ".", "cuda", "(", "opt", ".", "gpu", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'not implement {} phase'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "\n", "", "train_logger", "=", "Logger", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'train.log.rank{}'", ".", "format", "(", "opt", ".", "rank", ")", ")", ",", "\n", "[", "'epoch'", ",", "'loss'", ",", "'acc'", ",", "'lr'", "]", ")", "\n", "train_batch_logger", "=", "Logger", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "\n", "'train_batch.log.{}'", ".", "format", "(", "opt", ".", "rank", ")", ")", ",", "\n", "[", "'epoch'", ",", "'batch'", ",", "'iter'", ",", "'loss'", ",", "'acc'", ",", "'lr'", "]", ")", "\n", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "parameters", ",", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "momentum", "=", "opt", ".", "momentum", ",", "\n", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "\n", "if", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "            ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "\n", "optimizer", ",", "'max'", ",", "patience", "=", "opt", ".", "lr_patience", ",", "\n", "min_lr", "=", "1e-6", ",", "factor", "=", "opt", ".", "lr_factor", ")", "\n", "\n", "", "", "if", "not", "opt", ".", "no_val", ":", "\n", "        ", "validation_data", "=", "get_validation_set", "(", "opt", ")", "\n", "if", "opt", ".", "distributed", ":", "\n", "            ", "val_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "validation_data", ")", "\n", "", "else", ":", "\n", "            ", "val_sampler", "=", "None", "\n", "", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "validation_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "(", "val_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ",", "\n", "sampler", "=", "val_sampler", ")", "\n", "val_logger", "=", "Logger", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'val.log.rank{}'", ".", "format", "(", "opt", ".", "rank", ")", ")", ",", "\n", "[", "'epoch'", ",", "'acc1'", ",", "'acc5'", "]", "if", "opt", ".", "phase", "==", "'finetuning'", "else", "[", "'epoch'", ",", "'recall@1'", ",", "'recall@10'", "]", ")", "\n", "\n", "", "if", "opt", ".", "test", ":", "\n", "        ", "model", ",", "parameters", "=", "generate_model", "(", "opt", ")", "\n", "\n", "test_data", "=", "get_test_set", "(", "opt", ")", "\n", "idx_to_labels", "=", "test_data", ".", "get_idx_to_label", "(", ")", "\n", "if", "opt", ".", "distributed", ":", "\n", "            ", "test_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "test_data", ",", "shuffle", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "test_sampler", "=", "None", "\n", "", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "(", "test_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "False", ",", "\n", "sampler", "=", "test_sampler", ")", "\n", "\n", "", "if", "opt", ".", "resume_path", ":", "\n", "        ", "print", "(", "'==>loading checkpoint {}'", ".", "format", "(", "opt", ".", "resume_path", ")", ")", "\n", "if", "opt", ".", "gpu", "is", "None", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "resume_path", ")", "\n", "", "else", ":", "\n", "# Map model to be loaded to specified single gpu.", "\n", "            ", "loc", "=", "'cuda:{}'", ".", "format", "(", "opt", ".", "gpu", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "resume_path", ",", "map_location", "=", "loc", ")", "\n", "\n", "", "opt", ".", "begin_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "if", "not", "opt", ".", "no_train", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "opt", ".", "begin_epoch", "=", "1", "\n", "\n", "", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "if", "opt", ".", "rank", "%", "ngpus_per_node", "==", "0", ":", "\n", "        ", "summary_writer", "=", "SummaryWriter", "(", "log_dir", "=", "opt", ".", "result_path", ")", "\n", "", "else", ":", "\n", "        ", "summary_writer", "=", "None", "\n", "", "for", "i", "in", "range", "(", "opt", ".", "begin_epoch", ",", "opt", ".", "n_epochs", "+", "1", ")", ":", "\n", "        ", "if", "not", "opt", ".", "no_train", ":", "\n", "            ", "if", "opt", ".", "distributed", ":", "\n", "                ", "train_sampler", ".", "set_epoch", "(", "i", ")", "\n", "\n", "", "train_epoch", "(", "i", ",", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "opt", ",", "\n", "train_logger", ",", "train_batch_logger", ",", "summary_writer", ")", "\n", "\n", "", "if", "not", "opt", ".", "no_val", ":", "\n", "            ", "if", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "                ", "val_acc", "=", "val_finetune_epoch", "(", "i", ",", "val_loader", ",", "model", ",", "opt", ",", "\n", "val_logger", ",", "summary_writer", ")", "\n", "", "elif", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "                ", "val_acc", "=", "val_pretrain_epoch", "(", "i", ",", "val_loader", ",", "model", ",", "opt", ",", "\n", "val_logger", ",", "summary_writer", ")", "\n", "", "", "if", "not", "opt", ".", "no_train", "and", "not", "opt", ".", "no_val", ":", "\n", "            ", "if", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "                ", "scheduler", ".", "step", "(", "val_acc", ")", "\n", "", "elif", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "                ", "adjuest_learning_rate", "(", "optimizer", ",", "i", ",", "opt", ")", "\n", "\n", "", "", "", "if", "opt", ".", "test", ":", "\n", "        ", "test", ".", "test", "(", "test_loader", ",", "model", ",", "opt", ",", "idx_to_labels", ",", "test_results", ")", "\n", "if", "opt", ".", "multiprocessing_distributed", "and", "opt", ".", "gpu", "==", "0", ":", "\n", "            ", "result_json", "=", "{", "}", "\n", "finish_procs", "=", "0", "\n", "while", "(", "finish_procs", "<", "ngpus_per_node", ")", ":", "\n", "                ", "rst", "=", "test_results", ".", "get", "(", ")", "\n", "if", "rst", "==", "-", "1", ":", "\n", "                    ", "finish_procs", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "result_json", "[", "rst", "[", "0", "]", "]", "=", "rst", "[", "1", "]", "\n", "", "", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'{}.json'", ".", "format", "(", "opt", ".", "test_subset", ")", ")", ",", "\n", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "{", "'results'", ":", "result_json", "}", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.train_epoch": [[237, 345], ["print", "model.train", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "time.time", "enumerate", "epoch_logger.log", "print", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "utils.AverageMeter.update", "time.time", "writer.add_scalar", "writer.add_scalar", "writer.flush", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "model", "criterion", "criterion.item", "inputs.cuda.size", "inputs.cuda.size", "torch.nn.utils.clip_grad_norm_", "batch_logger.log", "print", "model.state_dict", "optimizer.state_dict", "time.time", "inputs.cuda.cuda", "targets.cuda.cuda", "utils.accuracy", "model", "criterion", "criterion", "NotImplementedError", "model.parameters", "print", "time.time", "inputs.cuda.cuda", "targets.cuda.cuda", "index.cuda.cuda", "utils.accuracy", "len", "vis_out.squeeze", "torch.zeros().cuda().long", "torch.zeros().cuda().long", "torch.zeros().cuda().long", "torch.zeros().cuda().long", "len", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet.train", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.log", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.log", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.accuracy", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.accuracy", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["", "", "", "", "def", "train_epoch", "(", "epoch", ",", "data_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "opt", ",", "\n", "epoch_logger", ",", "batch_logger", ",", "writer", "=", "None", ")", ":", "\n", "    ", "print", "(", "'train at epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "accuracies", "=", "AverageMeter", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "inputs", ",", "targets", ",", "index", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "\n", "if", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "            ", "if", "not", "opt", ".", "no_cuda", ":", "\n", "                ", "inputs", "=", "inputs", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "targets", "=", "targets", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "outputs", "=", "model", "(", "inputs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "acc", "=", "accuracy", "(", "outputs", ",", "targets", ")", "[", "0", "]", "\n", "", "elif", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "            ", "if", "not", "opt", ".", "no_cuda", ":", "\n", "                ", "vis_inputs", "=", "inputs", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "text_inputs", "=", "targets", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "index", "=", "index", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "vis_out", ",", "text_out", "=", "model", "(", "\n", "vis_inputs", ",", "text_inputs", ",", "index", ",", "epoch", ">", "opt", ".", "ft_bert_ep", ")", "\n", "l_vp", ",", "l_vn", "=", "criterion", "(", "vis_out", ")", "\n", "l_tp", ",", "l_tn", "=", "criterion", "(", "text_out", ")", "\n", "loss", "=", "l_vp", "+", "l_vn", "+", "l_tp", "+", "l_tn", "\n", "bsz", "=", "vis_out", ".", "shape", "[", "0", "]", "\n", "acc", "=", "accuracy", "(", "vis_out", ".", "squeeze", "(", ")", ",", "\n", "torch", ".", "zeros", "(", "[", "bsz", "]", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'not implement {} phase'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "\n", "", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "accuracies", ".", "update", "(", "acc", "[", "0", "]", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "opt", ".", "clip_gradient", "is", "not", "None", ":", "\n", "            ", "total_norm", "=", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "opt", ".", "clip_gradient", ")", "\n", "if", "total_norm", ">", "opt", ".", "clip_gradient", ":", "\n", "                ", "print", "(", "\"clipping gradient: {} with coef {}\"", ".", "format", "(", "\n", "total_norm", ",", "opt", ".", "clip_gradient", "/", "total_norm", ")", ")", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "if", "i", "%", "opt", ".", "print_frq", "==", "0", ":", "\n", "            ", "batch_logger", ".", "log", "(", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'batch'", ":", "i", "+", "1", ",", "\n", "'iter'", ":", "(", "epoch", "-", "1", ")", "*", "len", "(", "data_loader", ")", "+", "(", "i", "+", "1", ")", ",", "\n", "'loss'", ":", "losses", ".", "val", ",", "\n", "'acc'", ":", "accuracies", ".", "val", ",", "\n", "'lr'", ":", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "}", ")", "\n", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Lr {3}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'", "\n", "'Loss {losses.val:.4f} ({losses.avg:.4f})\\t'", "\n", "'Acc {accuracies.val:.7f} ({accuracies.avg:.7f})'", ".", "format", "(", "\n", "epoch", ",", "\n", "i", "+", "1", ",", "\n", "len", "(", "data_loader", ")", ",", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ",", "\n", "losses", "=", "losses", ",", "\n", "accuracies", "=", "accuracies", ")", ")", "\n", "\n", "", "", "epoch_logger", ".", "log", "(", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'loss'", ":", "losses", ".", "avg", ",", "\n", "'acc'", ":", "accuracies", ".", "avg", ",", "\n", "'lr'", ":", "optimizer", ".", "param_groups", "[", "-", "1", "]", "[", "'lr'", "]", "\n", "}", ")", "\n", "print", "(", "'Epoch: [{0}]\\t'", "\n", "'Lr {1}\\t'", "\n", "'Loss {loss.avg:.4f}\\t'", "\n", "'Acc {acc.avg:.7f}'", ".", "format", "(", "\n", "epoch", ",", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "loss", "=", "losses", ",", "\n", "acc", "=", "accuracies", ")", ")", "\n", "if", "writer", "is", "not", "None", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "'scalar/train_loss'", ",", "losses", ".", "avg", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'scalar/train_acc'", ",", "accuracies", ".", "avg", ",", "epoch", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n", "", "if", "epoch", "%", "opt", ".", "checkpoint", "==", "0", "and", "opt", ".", "rank", "==", "0", ":", "\n", "        ", "save_file_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "\n", "'save_{}.pth'", ".", "format", "(", "epoch", ")", ")", "\n", "states", "=", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "opt", ".", "arch", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "torch", ".", "save", "(", "states", ",", "save_file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.val_pretrain_epoch": [[347, 386], ["print", "model.eval", "tqdm.tqdm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "main.concat_all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "main.concat_all_gather", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.tensor().cuda().long", "torch.tensor().cuda().long", "torch.tensor().cuda().long", "torch.tensor().cuda().long", "utils.accuracy", "print", "print", "logger.log", "concat_all_gather.t", "writer.add_scalar", "writer.add_scalar", "writer.flush", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "concat_all_gather.append", "concat_all_gather.append", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "text_inputs.cuda.cuda", "vis_inputs.cuda.cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "list", "range", "concat_all_gather.size"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.accuracy", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.log", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["", "", "def", "val_pretrain_epoch", "(", "epoch", ",", "data_loader", ",", "model", ",", "opt", ",", "logger", ",", "writer", "=", "None", ")", ":", "\n", "    ", "print", "(", "'validation at epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "video_feats", "=", "[", "]", "\n", "text_feats", "=", "[", "]", "\n", "\n", "for", "vis_inputs", ",", "text_inputs", ",", "_", "in", "tqdm", "(", "data_loader", ",", "disable", "=", "opt", ".", "rank", "!=", "0", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "not", "opt", ".", "no_cuda", ":", "\n", "                ", "text_inputs", "=", "text_inputs", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "vis_inputs", "=", "vis_inputs", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "vis_out", ",", "text_out", "=", "model", "(", "vis_inputs", ",", "text_inputs", ")", "\n", "video_feats", ".", "append", "(", "vis_out", ")", "\n", "text_feats", ".", "append", "(", "text_out", ")", "\n", "\n", "", "", "video_feats", "=", "torch", ".", "cat", "(", "video_feats", ",", "dim", "=", "0", ")", "\n", "video_feats", "=", "concat_all_gather", "(", "video_feats", ")", "\n", "\n", "text_feats", "=", "torch", ".", "cat", "(", "text_feats", ",", "dim", "=", "0", ")", "\n", "text_feats", "=", "concat_all_gather", "(", "text_feats", ")", "\n", "\n", "rank_mat", "=", "torch", ".", "mm", "(", "text_feats", ",", "video_feats", ".", "t", "(", ")", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "list", "(", "range", "(", "video_feats", ".", "size", "(", "0", ")", ")", ")", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "top1", ",", "top10", "=", "accuracy", "(", "rank_mat", ",", "target", ",", "topk", "=", "(", "1", ",", "10", ")", ")", "\n", "top1", ",", "top10", "=", "top1", "[", "0", "]", ",", "top10", "[", "0", "]", "\n", "\n", "print", "(", "\"recall@1: {}\"", ".", "format", "(", "top1", ")", ")", "\n", "print", "(", "\"recall@10: {}\"", ".", "format", "(", "top10", ")", ")", "\n", "\n", "logger", ".", "log", "(", "{", "'epoch'", ":", "epoch", ",", "'recall@1'", ":", "top1", ",", "'recall@10'", ":", "top10", "}", ")", "\n", "if", "writer", "is", "not", "None", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "'scalar/recall@1'", ",", "top1", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'scalar/recall@5'", ",", "top10", ",", "epoch", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n", "", "return", "top1", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.val_finetune_epoch": [[388, 421], ["print", "model.eval", "utils.AverageMeter", "utils.AverageMeter", "tqdm.tqdm", "logger.log", "print", "writer.add_scalar", "writer.add_scalar", "writer.flush", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "main.concat_all_gather", "main.concat_all_gather", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "targets.cuda.cuda", "inputs.cuda.cuda", "inputs.cuda.size", "inputs.cuda.size"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.log", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.accuracy", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["", "def", "val_finetune_epoch", "(", "epoch", ",", "data_loader", ",", "model", ",", "opt", ",", "logger", ",", "writer", "=", "None", ")", ":", "\n", "    ", "print", "(", "'validation at epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "acc1_avg", "=", "AverageMeter", "(", ")", "\n", "acc5_avg", "=", "AverageMeter", "(", ")", "\n", "\n", "for", "inputs", ",", "targets", ",", "_", "in", "tqdm", "(", "data_loader", ",", "disable", "=", "opt", ".", "rank", "!=", "0", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "not", "opt", ".", "no_cuda", ":", "\n", "                ", "targets", "=", "targets", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "cuda", "(", "opt", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "outputs", "=", "model", "(", "inputs", ")", "\n", "outputs", "=", "concat_all_gather", "(", "outputs", ")", "\n", "targets", "=", "concat_all_gather", "(", "targets", ")", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "outputs", ",", "targets", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "acc1_avg", ".", "update", "(", "acc1", "[", "0", "]", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "acc5_avg", ".", "update", "(", "acc5", "[", "0", "]", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "logger", ".", "log", "(", "{", "'epoch'", ":", "epoch", ",", "'acc1'", ":", "acc1_avg", ".", "avg", ",", "'acc5'", ":", "acc5_avg", ".", "avg", "}", ")", "\n", "print", "(", "'Epoch: [{0}]\\t'", "\n", "'Acc@1 {acc1_avg.avg:.3f}\\t'", "\n", "'Acc@5 {acc5_avg.avg:.3f}'", ".", "format", "(", "\n", "epoch", ",", "\n", "acc1_avg", "=", "acc1_avg", ",", "\n", "acc5_avg", "=", "acc5_avg", ")", ")", "\n", "if", "writer", "is", "not", "None", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "'scalar/val_acc1'", ",", "acc1_avg", ".", "avg", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'scalar/val_acc5'", ",", "acc5_avg", ".", "avg", ",", "epoch", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "", "return", "acc1_avg", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.adjuest_learning_rate": [[423, 438], ["print"], "function", ["None"], ["", "def", "adjuest_learning_rate", "(", "optimizer", ",", "epoch", ",", "opt", ")", ":", "\n", "    ", "if", "(", "epoch", "+", "1", ")", "==", "opt", ".", "ft_bert_ep", ":", "\n", "        ", "print", "(", "'start updating bert parameters.'", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "opt", ".", "lr_bert", "*", "0.1", "if", "param_group", "[", "'lr'", "]", "==", "0", "else", "param_group", "[", "'lr'", "]", "\n", "", "", "gamma", "=", "1", "\n", "if", "epoch", "==", "100", ":", "\n", "        ", "gamma", "=", "0.1", "\n", "", "elif", "epoch", "==", "201", ":", "\n", "        ", "gamma", "=", "0.1", "\n", "", "elif", "epoch", "==", "250", ":", "\n", "        ", "gamma", "=", "0.1", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "*=", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.main.concat_all_gather": [[440, 452], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "range", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "concat_all_gather", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: torch.distributed.all_gather has no gradient.\n    \"\"\"", "\n", "tensors_gather", "=", "[", "torch", ".", "ones_like", "(", "tensor", ")", "\n", "for", "_", "in", "range", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "tensors_gather", ",", "tensor", ",", "async_op", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "tensors_gather", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_training_set": [[5, 42], ["datasets.ucf101.UcfHmdb", "datasets.ucf101.UcfHmdb", "datasets.instagram.Instagram"], "function", ["None"], ["def", "get_training_set", "(", "opt", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'ucf101'", ",", "'hmdb51'", ",", "'ins'", "]", "\n", "\n", "if", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "training_data", "=", "UcfHmdb", "(", "\n", "'UCF101'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'training'", ",", "\n", "testing", "=", "False", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "n_samples_for_each_frame", "=", "1", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "training_data", "=", "UcfHmdb", "(", "\n", "'HMDB51'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'training'", ",", "\n", "testing", "=", "False", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "n_samples_for_each_frame", "=", "1", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'ins'", ":", "\n", "        ", "training_data", "=", "Instagram", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'training'", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "\n", "", "return", "training_data", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_validation_set": [[44, 81], ["datasets.ucf101.UcfHmdb", "datasets.ucf101.UcfHmdb", "datasets.instagram.Instagram"], "function", ["None"], ["", "def", "get_validation_set", "(", "opt", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'ucf101'", ",", "'hmdb51'", ",", "'ins'", "]", "\n", "\n", "if", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "validation_data", "=", "UcfHmdb", "(", "\n", "'UCF101'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'validation'", ",", "\n", "testing", "=", "False", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "n_samples_for_each_frame", "=", "1", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "validation_data", "=", "UcfHmdb", "(", "\n", "'HMDB51'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'validation'", ",", "\n", "testing", "=", "False", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "n_samples_for_each_frame", "=", "1", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'ins'", ":", "\n", "        ", "validation_data", "=", "Instagram", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "'validation'", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "\n", "", "return", "validation_data", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.dataset.get_test_set": [[83, 118], ["datasets.ucf101.UcfHmdb", "datasets.ucf101.UcfHmdb"], "function", ["None"], ["", "def", "get_test_set", "(", "opt", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'ucf101'", ",", "'hmdb51'", "]", "\n", "assert", "opt", ".", "test_subset", "in", "[", "'val'", ",", "'test'", "]", "\n", "\n", "if", "opt", ".", "test_subset", "==", "'val'", ":", "\n", "        ", "subset", "=", "'validation'", "\n", "", "elif", "opt", ".", "test_subset", "==", "'test'", ":", "\n", "        ", "subset", "=", "'testing'", "\n", "\n", "", "if", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "test_data", "=", "UcfHmdb", "(", "\n", "'UCF101'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "subset", ",", "\n", "testing", "=", "True", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "10", ",", "\n", "n_samples_for_each_frame", "=", "3", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "test_data", "=", "UcfHmdb", "(", "\n", "'HMDB51'", ",", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "dataset_file", ",", "\n", "subset", ",", "\n", "testing", "=", "True", ",", "\n", "num_frames", "=", "opt", ".", "sample_duration", "//", "opt", ".", "stride_size", ",", "\n", "sample_stride", "=", "opt", ".", "stride_size", ",", "\n", "n_samples_for_each_video", "=", "10", ",", "\n", "n_samples_for_each_frame", "=", "3", ",", "\n", "crop_size", "=", "opt", ".", "sample_size", ")", "\n", "\n", "", "return", "test_data", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.test.calculate_video_results": [[5, 18], ["torch.stack", "torch.mean", "torch.topk", "range", "test_results.put", "sorted_scores.size", "video_results.append", "sorted_scores[].item", "locs[].item"], "function", ["None"], ["def", "calculate_video_results", "(", "output_buffer", ",", "video_id", ",", "test_results", ",", "class_names", ")", ":", "\n", "    ", "video_outputs", "=", "torch", ".", "stack", "(", "output_buffer", ")", "\n", "average_scores", "=", "torch", ".", "mean", "(", "video_outputs", ",", "dim", "=", "0", ")", "\n", "sorted_scores", ",", "locs", "=", "torch", ".", "topk", "(", "average_scores", ",", "k", "=", "1", ")", "\n", "\n", "video_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "sorted_scores", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "video_results", ".", "append", "(", "{", "\n", "'label'", ":", "class_names", "[", "locs", "[", "i", "]", ".", "item", "(", ")", "]", ",", "\n", "'score'", ":", "sorted_scores", "[", "i", "]", ".", "item", "(", ")", "\n", "}", ")", "\n", "\n", "", "test_results", ".", "put", "(", "[", "video_id", ",", "video_results", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.test.test": [[20, 42], ["print", "model.eval", "tqdm.tqdm", "test_results.put", "range", "torch.no_grad", "model", "model.size", "output_buffer.append", "inputs.cuda", "test.calculate_video_results", "outputs[].data.cpu"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.test.calculate_video_results"], ["", "def", "test", "(", "data_loader", ",", "model", ",", "opt", ",", "class_names", ",", "test_results", ")", ":", "\n", "    ", "print", "(", "'test'", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "output_buffer", "=", "[", "]", "\n", "previous_video_id", "=", "''", "\n", "i", "=", "0", "\n", "for", "(", "inputs", ",", "targets", ",", "_", ")", "in", "tqdm", "(", "data_loader", ",", "disable", "=", "opt", ".", "rank", "!=", "0", ")", ":", "\n", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ".", "cuda", "(", ")", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "outputs", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "not", "(", "i", "==", "0", "and", "j", "==", "0", ")", "and", "targets", "[", "j", "]", "!=", "previous_video_id", ":", "\n", "                ", "calculate_video_results", "(", "output_buffer", ",", "previous_video_id", ",", "\n", "test_results", ",", "class_names", ")", "\n", "output_buffer", "=", "[", "]", "\n", "", "output_buffer", ".", "append", "(", "outputs", "[", "j", "]", ".", "data", ".", "cpu", "(", ")", ")", "\n", "previous_video_id", "=", "targets", "[", "j", "]", "\n", "", "i", "+=", "1", "\n", "", "test_results", ".", "put", "(", "-", "1", ")", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.model.generate_model": [[9, 119], ["models.cpd.CPD", "NotImplementedError", "resnet.resnet50.parameters", "models.resnet.resnet10", "NotImplementedError", "get_fine_tuning_parameters", "models.resnet.resnet18", "torch.cuda.set_device", "resnet.resnet50.cuda", "torch.nn.parallel.DistributedDataParallel", "resnet.resnet50.cuda", "torch.nn.parallel.DistributedDataParallel", "torch.nn.Linear().cuda", "get_fine_tuning_parameters", "NotImplementedError", "int", "models.resnet.resnet34", "print", "torch.load", "collections.OrderedDict", "pretrain[].items", "resnet.resnet50.state_dict", "model.state_dict.keys", "model.state_dict.update", "resnet.resnet50.load_state_dict", "int", "models.resnet.resnet50", "torch.nn.Linear", "int", "collections.OrderedDict.keys", "print", "int", "name.replace"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet10", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.get_fine_tuning_parameters", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet18", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.get_fine_tuning_parameters", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet34", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet50"], ["def", "generate_model", "(", "opt", ")", ":", "\n", "    ", "assert", "opt", ".", "model", "in", "[", "'resnet'", "]", "\n", "\n", "if", "opt", ".", "model", "==", "'resnet'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "10", ",", "18", ",", "34", ",", "50", "]", "\n", "\n", "from", "models", ".", "resnet", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "10", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet10", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "int", "(", "opt", ".", "sample_duration", "/", "opt", ".", "stride_size", ")", ",", "\n", "dp", "=", "opt", ".", "dp", "\n", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "18", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet18", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "int", "(", "opt", ".", "sample_duration", "/", "opt", ".", "stride_size", ")", ",", "\n", "dp", "=", "opt", ".", "dp", "\n", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "34", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet34", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "int", "(", "opt", ".", "sample_duration", "/", "opt", ".", "stride_size", ")", ",", "\n", "dp", "=", "opt", ".", "dp", "\n", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "50", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet50", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "int", "(", "opt", ".", "sample_duration", "/", "opt", ".", "stride_size", ")", ",", "\n", "dp", "=", "opt", ".", "dp", ",", "\n", "freeze_bn", "=", "False", "\n", ")", "\n", "\n", "", "", "if", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "        ", "from", "models", ".", "cpd", "import", "get_fine_tuning_parameters", "\n", "model", "=", "cpd", ".", "CPD", "(", "visual_encoder", "=", "model", ",", "\n", "N_data", "=", "opt", ".", "N_data", ",", "\n", "emb_dim", "=", "opt", ".", "emb_dim", ",", "\n", "dropout", "=", "opt", ".", "dp", ",", "\n", "K", "=", "opt", ".", "nce_k", ",", "\n", "T", "=", "opt", ".", "nce_t", ",", "\n", "m", "=", "opt", ".", "nce_m", ",", "\n", "gpu", "=", "opt", ".", "gpu", ")", "\n", "\n", "", "if", "not", "opt", ".", "no_cuda", ":", "\n", "        ", "if", "opt", ".", "distributed", ":", "\n", "# For multiprocessing distributed, DistributedDataParallel constructor", "\n", "# should always set the single device scope, otherwise,", "\n", "# DistributedDataParallel will use all available devices.", "\n", "            ", "if", "opt", ".", "gpu", "is", "not", "None", ":", "\n", "                ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "model", ".", "cuda", "(", "opt", ".", "gpu", ")", "\n", "# When using a single GPU per process and per", "\n", "# DistributedDataParallel, we need to divide the batch size", "\n", "# ourselves based on the total number of GPUs we have", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "opt", ".", "gpu", "]", ",", "find_unused_parameters", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "cuda", "(", ")", "\n", "# DistributedDataParallel will divide and allocate batch_size to all", "\n", "# available GPUs if device_ids are not set", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "find_unused_parameters", "=", "True", ")", "\n", "", "", "else", ":", "\n", "# AllGather implementation (batch shuffle, queue update, etc.) in", "\n", "# this code only supports DistributedDataParallel.", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Only DistributedDataParallel is supported.\"", ")", "\n", "\n", "", "if", "opt", ".", "phase", "==", "'pretraining'", ":", "\n", "            ", "parameters", "=", "get_fine_tuning_parameters", "(", "\n", "model", ",", "opt", ".", "learning_rate", ")", "\n", "return", "model", ",", "parameters", "\n", "", "elif", "opt", ".", "phase", "==", "'finetuning'", ":", "\n", "            ", "if", "opt", ".", "pretrain_path", "is", "not", "None", ":", "\n", "                ", "print", "(", "'loading pretrained model {}'", ".", "format", "(", "opt", ".", "pretrain_path", ")", ")", "\n", "pretrain", "=", "torch", ".", "load", "(", "opt", ".", "pretrain_path", ",", "map_location", "=", "'cuda:{}'", ".", "format", "(", "opt", ".", "gpu", ")", ")", "\n", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "name", ",", "weights", "in", "pretrain", "[", "'state_dict'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "'visual_encoder'", "in", "name", ":", "\n", "                        ", "new_state_dict", "[", "name", ".", "replace", "(", "\n", "'visual_encoder.'", ",", "''", ")", "]", "=", "weights", "\n", "\n", "", "", "x", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "k", "in", "x", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "k", "not", "in", "new_state_dict", ".", "keys", "(", ")", ":", "\n", "                        ", "print", "(", "'Missing Keys: '", ",", "k", ")", "\n", "", "", "x", ".", "update", "(", "new_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "x", ")", "\n", "", "model", ".", "module", ".", "fc", "=", "nn", ".", "Linear", "(", "\n", "model", ".", "module", ".", "fc", ".", "in_features", ",", "opt", ".", "n_finetune_classes", ")", ".", "cuda", "(", ")", "\n", "parameters", "=", "get_fine_tuning_parameters", "(", "\n", "model", ",", "opt", ".", "ft_begin_index", ",", "opt", ".", "learning_rate", ")", "\n", "return", "model", ",", "parameters", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "'not implement {} phase'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"CPU version: not implemented!\"", ")", "\n", "", "return", "model", ",", "model", ".", "parameters", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.__init__": [[8, 10], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.reset": [[11, 16], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.AverageMeter.update": [[17, 22], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.__init__": [[26, 32], ["open", "csv.writer", "utils.Logger.logger.writerow"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "header", ")", ":", "\n", "        ", "self", ".", "log_file", "=", "open", "(", "path", ",", "'w'", ")", "\n", "self", ".", "logger", "=", "csv", ".", "writer", "(", "self", ".", "log_file", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "self", ".", "logger", ".", "writerow", "(", "header", ")", "\n", "self", ".", "header", "=", "header", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.__del": [[33, 35], ["utils.Logger.log_file.close"], "methods", ["None"], ["", "def", "__del", "(", "self", ")", ":", "\n", "        ", "self", ".", "log_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.Logger.log": [[36, 44], ["utils.Logger.logger.writerow", "utils.Logger.log_file.flush", "write_values.append"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "values", ")", ":", "\n", "        ", "write_values", "=", "[", "]", "\n", "for", "col", "in", "self", ".", "header", ":", "\n", "            ", "assert", "col", "in", "values", "\n", "write_values", ".", "append", "(", "values", "[", "col", "]", ")", "\n", "\n", "", "self", ".", "logger", ".", "writerow", "(", "write_values", ")", "\n", "self", ".", "log_file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.load_value_file": [[46, 51], ["open", "float", "input_file.read().rstrip", "input_file.read"], "function", ["None"], ["", "", "def", "load_value_file", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "input_file", ":", "\n", "        ", "value", "=", "float", "(", "input_file", ".", "read", "(", ")", ".", "rstrip", "(", "'\\n\\r'", ")", ")", "\n", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.calculate_accuracy": [[53, 62], ["targets.size", "outputs.topk", "pred.t.t", "pred.t.eq", "pred.eq.float().sum().item", "targets.view", "pred.eq.float().sum", "pred.eq.float"], "function", ["None"], ["", "def", "calculate_accuracy", "(", "outputs", ",", "targets", ")", ":", "\n", "    ", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "outputs", ".", "topk", "(", "1", ",", "1", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "n_correct_elems", "=", "correct", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "return", "n_correct_elems", "/", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.None.utils.accuracy": [[64, 80], ["torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions\n       for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.video_container.get_video_container": [[7, 23], ["av.logging.set_level", "av.open"], "function", ["None"], ["def", "get_video_container", "(", "path_to_vid", ",", "multi_thread_decode", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Given the path to the video, return the pyav video container.\n    Args:\n        path_to_vid (str): path to the video.\n        multi_thread_decode (bool): if True, perform multi-thread decoding.\n    Returns:\n        container (container): pyav video container.\n    \"\"\"", "\n", "# av.logging.restore_default_callback()", "\n", "av", ".", "logging", ".", "set_level", "(", "5", ")", "\n", "container", "=", "av", ".", "open", "(", "path_to_vid", ")", "\n", "if", "multi_thread_decode", ":", "\n", "# Enable multiple threads for decoding.", "\n", "        ", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "thread_type", "=", "'AUTO'", "\n", "", "return", "container", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.__init__": [[51, 87], ["print", "ucf101.UcfHmdb.make_dataset"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "dataset_name", ",", "\n", "root_path", ",", "\n", "annotation_path", ",", "\n", "subset", ",", "\n", "video_tmpl", "=", "'{}.avi'", ",", "\n", "testing", "=", "False", ",", "\n", "num_frames", "=", "16", ",", "\n", "sample_stride", "=", "4", ",", "\n", "n_samples_for_each_video", "=", "10", ",", "\n", "n_samples_for_each_frame", "=", "3", ",", "\n", "crop_size", "=", "112", ",", "\n", "num_retries", "=", "10", "\n", ")", ":", "\n", "        ", "assert", "subset", "in", "[", "'training'", ",", "'validation'", "]", ",", "'Split {} not supported for {}'", ".", "format", "(", "\n", "subset", ",", "dataset_name", ")", "\n", "self", ".", "_dataset_name", "=", "dataset_name", "\n", "self", ".", "_subset", "=", "subset", "\n", "\n", "self", ".", "_testing", "=", "testing", "\n", "if", "not", "self", ".", "_testing", ":", "\n", "            ", "self", ".", "_num_clip", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "_num_clip", "=", "n_samples_for_each_video", "*", "n_samples_for_each_frame", "\n", "", "self", ".", "_num_spatial_crops", "=", "n_samples_for_each_frame", "\n", "self", ".", "_num_temporal_crops", "=", "n_samples_for_each_video", "\n", "\n", "self", ".", "_num_frames", "=", "num_frames", "\n", "self", ".", "_sample_stride", "=", "sample_stride", "\n", "\n", "self", ".", "_crop_size", "=", "crop_size", "\n", "self", ".", "_num_retries", "=", "num_retries", "\n", "\n", "print", "(", "'Making {} dataset...'", ".", "format", "(", "dataset_name", ")", ")", "\n", "self", ".", "make_dataset", "(", "root_path", ",", "annotation_path", ",", "\n", "subset", ",", "video_tmpl", ",", "self", ".", "_num_clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.make_dataset": [[88, 117], ["ucf101.load_annotation_data", "ucf101.get_video_names_and_annotations", "ucf101.get_class_labels", "zip", "print", "os.path.join", "range", "video_tmpl.format", "os.path.exists", "print", "datasets.video_container.get_video_container", "copy.deepcopy", "ucf101.UcfHmdb._data.append", "len", "vid.split"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.load_annotation_data", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.get_video_names_and_annotations", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.get_class_labels", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.video_container.get_video_container"], ["", "def", "make_dataset", "(", "self", ",", "root_path", ",", "annotation_path", ",", "subset", ",", "video_tmpl", ",", "clip_num", ")", ":", "\n", "        ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "annotations", "=", "get_video_names_and_annotations", "(", "\n", "data", ",", "subset", ")", "\n", "self", ".", "class_to_idx", ",", "self", ".", "idx_to_class", "=", "get_class_labels", "(", "data", ")", "\n", "\n", "self", ".", "_data", "=", "[", "]", "\n", "for", "vid", ",", "annotation", "in", "zip", "(", "video_names", ",", "annotations", ")", ":", "\n", "            ", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_tmpl", ".", "format", "(", "vid", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "                ", "print", "(", "\"{} not exists\"", ".", "format", "(", "video_path", ")", ")", "\n", "", "try", ":", "\n", "                ", "_", "=", "get_video_container", "(", "video_path", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "continue", "\n", "\n", "", "sample", "=", "{", "\n", "'video_path'", ":", "video_path", ",", "\n", "'video_id'", ":", "vid", ".", "split", "(", "'/'", ")", "[", "1", "]", ",", "\n", "'label'", ":", "self", ".", "class_to_idx", "[", "annotation", "[", "'label'", "]", "]", "\n", "}", "\n", "\n", "for", "k", "in", "range", "(", "clip_num", ")", ":", "\n", "                ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "sample_j", "[", "'crop_index'", "]", "=", "k", "\n", "sample_j", "[", "'video_mata'", "]", "=", "{", "}", "\n", "self", ".", "_data", ".", "append", "(", "sample_j", ")", "\n", "", "", "print", "(", "'Make {} dataset ({} clips)'", ".", "format", "(", "\n", "self", ".", "_dataset_name", ",", "len", "(", "self", ".", "_data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.__getitem__": [[118, 186], ["range", "datasets.decoder.decode", "ucf101.UcfHmdb.float", "ucf101.UcfHmdb.permute", "ucf101.UcfHmdb.spatial_sampling", "datasets.video_container.get_video_container", "random.randint", "random.randint", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.decode", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.spatial_sampling", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.video_container.get_video_container"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", "=", "self", ".", "_data", "[", "index", "]", "[", "'video_path'", "]", "\n", "\n", "if", "not", "self", ".", "_testing", ":", "\n", "            ", "temporal_sample_index", "=", "-", "1", "\n", "spatial_sample_index", "=", "-", "1", "\n", "if", "self", ".", "_crop_size", "==", "112", ":", "\n", "                ", "min_size", ",", "max_size", "=", "128", ",", "170", "\n", "", "elif", "self", ".", "_crop_size", "==", "224", ":", "\n", "                ", "min_size", ",", "max_size", "=", "256", ",", "340", "\n", "", "", "elif", "self", ".", "_testing", ":", "\n", "            ", "temporal_sample_index", "=", "(", "self", ".", "_data", "[", "index", "]", "[", "'crop_index'", "]", "\n", "//", "self", ".", "_num_spatial_crops", ")", "\n", "spatial_sample_index", "=", "(", "self", ".", "_data", "[", "index", "]", "[", "'crop_index'", "]", "\n", "%", "self", ".", "_num_spatial_crops", ")", "\n", "min_size", ",", "max_size", "=", "self", ".", "_crop_size", ",", "self", ".", "_crop_size", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_num_retries", ")", ":", "\n", "            ", "video_container", "=", "None", "\n", "try", ":", "\n", "                ", "video_container", "=", "get_video_container", "(", "\n", "path", ",", "multi_thread_decode", "=", "True", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"Failed to load video from {} with error {}\"", ".", "format", "(", "path", ",", "e", ")", ")", "\n", "\n", "", "if", "video_container", "is", "None", ":", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_data", ")", "-", "1", ")", "\n", "continue", "\n", "\n", "", "frames", "=", "decode", "(", "video_container", ",", "\n", "self", ".", "_sample_stride", ",", "\n", "self", ".", "_num_frames", ",", "\n", "temporal_sample_index", ",", "\n", "self", ".", "_num_temporal_crops", ",", "\n", "video_meta", "=", "self", ".", "_data", "[", "index", "]", "[", "'video_mata'", "]", ",", "\n", "target_fps", "=", "30", "\n", ")", "\n", "\n", "if", "frames", "is", "None", ":", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_data", ")", "-", "1", ")", "\n", "continue", "\n", "\n", "", "frames", "=", "frames", ".", "float", "(", ")", "\n", "# Normalization", "\n", "frames", "=", "frames", "/", "255.0", "\n", "frames", "=", "frames", "-", "torch", ".", "tensor", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "frames", "=", "frames", "/", "torch", ".", "tensor", "(", "[", "0.225", ",", "0.225", ",", "0.225", "]", ")", "\n", "\n", "frames", "=", "frames", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "\n", "frames", "=", "self", ".", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "spatial_sample_index", ",", "\n", "min_scale", "=", "min_size", ",", "\n", "max_scale", "=", "max_size", ",", "\n", "crop_size", "=", "self", ".", "_crop_size", "\n", ")", "\n", "if", "self", ".", "_testing", ":", "\n", "                ", "target", "=", "self", ".", "_data", "[", "index", "]", "[", "'video_id'", "]", "\n", "", "else", ":", "\n", "                ", "target", "=", "self", ".", "_data", "[", "index", "]", "[", "'label'", "]", "\n", "", "return", "frames", ",", "target", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.spatial_sampling": [[187, 236], ["datasets.transform.random_short_side_scale_jitter", "datasets.transform.uniform_crop", "datasets.transform.random_short_side_scale_jitter", "datasets.transform.random_crop", "datasets.transform.horizontal_flip", "datasets.transform.random_short_side_scale_jitter", "datasets.transform.random_crop", "len"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.uniform_crop", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_crop", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.horizontal_flip", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_crop"], ["", "", "def", "spatial_sampling", "(", "\n", "self", ",", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Perform spatial sampling on the given video frames. If spatial_idx is\n        -1, perform random scale, random crop, and random flip on the given\n        frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n        with the given spatial_idx.\n        Args:\n            frames (tensor): frames of images sampled from the video. The\n                dimension is `num frames` x `height` x `width` x `channel`.\n            spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n                or 2, perform left, center, right crop if width is larger than\n                height, and perform top, center, buttom crop if height is larger\n                than width.\n            min_scale (int): the minimal size of scaling.\n            max_scale (int): the maximal size of scaling.\n            crop_size (int): the size of height and width used to crop the\n                frames.\n        Returns:\n            frames (tensor): spatially sampled frames.\n        \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "-", "1", ",", "0", ",", "1", ",", "2", "]", "\n", "if", "spatial_idx", "==", "-", "1", ":", "\n", "            ", "if", "self", ".", "_subset", "==", "'training'", ":", "\n", "                ", "frames", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", "=", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "frames", "=", "horizontal_flip", "(", "0.5", ",", "frames", ")", "\n", "", "else", ":", "\n", "                ", "frames", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", "=", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "", "", "else", ":", "\n", "# The testing is deterministic and no jitter should be performed.", "\n", "# min_scale, max_scale, and crop_size are expect to be the same.", "\n", "            ", "assert", "len", "(", "{", "min_scale", ",", "max_scale", ",", "crop_size", "}", ")", "==", "1", "\n", "frames", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", "=", "uniform_crop", "(", "frames", ",", "crop_size", ",", "spatial_idx", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.get_idx_to_label": [[237, 239], ["None"], "methods", ["None"], ["", "def", "get_idx_to_label", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.UcfHmdb.__len__": [[240, 242], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.load_annotation_data": [[15, 18], ["open", "json.load"], "function", ["None"], ["def", "load_annotation_data", "(", "data_file_path", ")", ":", "\n", "    ", "with", "open", "(", "data_file_path", ",", "'r'", ")", "as", "data_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.get_class_labels": [[20, 31], ["torch.data"], "function", ["None"], ["", "", "def", "get_class_labels", "(", "data", ")", ":", "\n", "    ", "class_labels_map", "=", "{", "}", "\n", "labels_class_map", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "class_label", "in", "data", "[", "'labels'", "]", ":", "\n", "        ", "if", "class_label", "==", "''", ":", "\n", "            ", "continue", "\n", "", "class_labels_map", "[", "class_label", "]", "=", "index", "\n", "labels_class_map", "[", "index", "]", "=", "class_label", "\n", "index", "+=", "1", "\n", "", "return", "class_labels_map", ",", "labels_class_map", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.ucf101.get_video_names_and_annotations": [[33, 44], ["data[].items", "video_names.append", "annotations.append", "torch.data"], "function", ["None"], ["", "def", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", ":", "\n", "    ", "video_names", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "for", "key", ",", "value", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "        ", "this_subset", "=", "value", "[", "'subset'", "]", "\n", "if", "this_subset", "==", "subset", ":", "\n", "            ", "label", "=", "value", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "video_names", ".", "append", "(", "'{}/{}'", ".", "format", "(", "label", ",", "key", ")", ")", "\n", "annotations", ".", "append", "(", "value", "[", "'annotations'", "]", ")", "\n", "", "", "return", "video_names", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.temporal_sampling": [[10, 34], ["torch.linspace", "torch.clamp().long", "torch.index_select", "torch.linspace", "torch.clamp().long().tolist", "torch.clamp", "torch.clamp().long", "torch.clamp", "len"], "function", ["None"], ["def", "temporal_sampling", "(", "frames", ",", "start_idx", ",", "end_idx", ",", "num_samples", ",", "get_tensor", ")", ":", "\n", "    ", "\"\"\"\n    Given the start and end frame index, sample num_samples frames between\n    the start and end with equal interval.\n    Args:\n        frames (tensor): a tensor of video frames, dimension is\n            `num video frames` x `channel` x `height` x `width`.\n        start_idx (int): the index of the start frame.\n        end_idx (int): the index of the end frame.\n        num_samples (int): number of frames to sample.\n    Returns:\n        frames (tersor): a tensor of temporal sampled video frames, dimension is\n            `num clip frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "if", "get_tensor", ":", "\n", "        ", "index", "=", "torch", ".", "linspace", "(", "start_idx", ",", "end_idx", ",", "num_samples", ")", "\n", "index", "=", "torch", ".", "clamp", "(", "index", ",", "0", ",", "frames", ".", "shape", "[", "0", "]", "-", "1", ")", ".", "long", "(", ")", "\n", "frames", "=", "torch", ".", "index_select", "(", "frames", ",", "0", ",", "index", ")", "\n", "return", "frames", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "linspace", "(", "start_idx", ",", "end_idx", ",", "num_samples", ")", "\n", "index", "=", "torch", ".", "clamp", "(", "index", ",", "0", ",", "len", "(", "frames", ")", "-", "1", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "frames", "=", "[", "frames", "[", "i", "]", "for", "i", "in", "index", "]", "\n", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.get_start_end_idx": [[36, 65], ["max", "random.uniform"], "function", ["None"], ["", "", "def", "get_start_end_idx", "(", "video_size", ",", "clip_size", ",", "clip_idx", ",", "num_clips", ")", ":", "\n", "    ", "\"\"\"\n    Sample a clip of size clip_size from a video of size video_size and\n    return the indices of the first and last frame of the clip. If clip_idx is\n    -1, the clip is randomly sampled, otherwise uniformly split the video to\n    num_clips clips, and select the start and end index of clip_idx-th video\n    clip.\n    Args:\n        video_size (int): number of overall frames.\n        clip_size (int): size of the clip to sample from the frames.\n        clip_idx (int): if clip_idx is -1, perform random jitter sampling. If\n            clip_idx is larger than -1, uniformly split the video to num_clips\n            clips, and select the start and end index of the clip_idx-th video\n            clip.\n        num_clips (int): overall number of clips to uniformly sample from the\n            given video for testing.\n    Returns:\n        start_idx (int): the start frame index.\n        end_idx (int): the end frame index.\n    \"\"\"", "\n", "delta", "=", "max", "(", "video_size", "-", "clip_size", ",", "0", ")", "\n", "if", "clip_idx", "==", "-", "1", ":", "\n", "# Random temporal sampling.", "\n", "        ", "start_idx", "=", "random", ".", "uniform", "(", "0", ",", "delta", ")", "\n", "", "else", ":", "\n", "# Uniformly sample the clip with the given index.", "\n", "        ", "start_idx", "=", "delta", "*", "clip_idx", "/", "num_clips", "\n", "", "end_idx", "=", "start_idx", "+", "clip_size", "-", "1", "\n", "return", "start_idx", ",", "end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.pyav_decode_stream": [[67, 107], ["max", "container.seek", "container.decode", "max", "sorted"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.decode"], ["", "def", "pyav_decode_stream", "(", "\n", "container", ",", "start_pts", ",", "end_pts", ",", "stream", ",", "stream_name", ",", "buffer_size", "=", "0", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Decode the video with PyAV decoder.\n    Args:\n        container (container): PyAV container.\n        start_pts (int): the starting Presentation TimeStamp to fetch the\n            video frames.\n        end_pts (int): the ending Presentation TimeStamp of the decoded frames.\n        stream (stream): PyAV stream.\n        stream_name (dict): a dictionary of streams. For example, {\"video\": 0}\n            means video stream at stream index 0.\n        buffer_size (int): number of additional frames to decode beyond end_pts.\n    Returns:\n        result (list): list of frames decoded.\n        max_pts (int): max Presentation TimeStamp of the video sequence.\n    \"\"\"", "\n", "# Seeking in the stream is imprecise. Thus, seek to an ealier PTS by a", "\n", "# margin pts.", "\n", "margin", "=", "1024", "\n", "seek_offset", "=", "max", "(", "start_pts", "-", "margin", ",", "0", ")", "\n", "\n", "container", ".", "seek", "(", "seek_offset", ",", "any_frame", "=", "False", ",", "backward", "=", "True", ",", "stream", "=", "stream", ")", "\n", "frames", "=", "{", "}", "\n", "buffer_count", "=", "0", "\n", "max_pts", "=", "0", "\n", "for", "frame", "in", "container", ".", "decode", "(", "**", "stream_name", ")", ":", "\n", "        ", "max_pts", "=", "max", "(", "max_pts", ",", "frame", ".", "pts", ")", "\n", "if", "frame", ".", "pts", "<", "start_pts", ":", "\n", "            ", "continue", "\n", "", "if", "frame", ".", "pts", "<=", "end_pts", ":", "\n", "            ", "frames", "[", "frame", ".", "pts", "]", "=", "frame", "\n", "", "else", ":", "\n", "            ", "buffer_count", "+=", "1", "\n", "frames", "[", "frame", ".", "pts", "]", "=", "frame", "\n", "if", "buffer_count", ">=", "buffer_size", ":", "\n", "                ", "break", "\n", "", "", "", "result", "=", "[", "frames", "[", "pts", "]", "for", "pts", "in", "sorted", "(", "frames", ")", "]", "\n", "return", "result", ",", "max_pts", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.pyav_decode": [[109, 180], ["float", "decoder.get_start_end_idx", "int", "int", "decoder.pyav_decode_stream", "container.close", "torch.as_tensor", "frame.to_rgb().to_ndarray", "numpy.stack", "frame.to_image", "frame.to_rgb"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.get_start_end_idx", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.pyav_decode_stream"], ["", "def", "pyav_decode", "(", "\n", "container", ",", "sampling_rate", ",", "num_frames", ",", "clip_idx", ",", "\n", "num_clips", "=", "10", ",", "target_fps", "=", "30", ",", "get_tensor", "=", "True", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Convert the video from its original fps to the target_fps. If the video\n    support selective decoding (contain decoding information in the video head),\n    the perform temporal selective decoding and sample a clip from the video\n    with the PyAV decoder. If the video does not support selective decoding,\n    decode the entire video.\n\n    Args:\n        container (container): pyav container.\n        sampling_rate (int): frame sampling rate (interval between two sampled\n            frames.\n        num_frames (int): number of frames to sample.\n        clip_idx (int): if clip_idx is -1, perform random temporal sampling. If\n            clip_idx is larger than -1, uniformly split the video to num_clips\n            clips, and select the clip_idx-th video clip.\n        num_clips (int): overall number of clips to uniformly sample from the\n            given video.\n        target_fps (int): the input video may has different fps, convert it to\n            the target video fps before frame sampling.\n    Returns:\n        frames (tensor): decoded frames from the video. Return None if the no\n            video stream was found.\n        fps (float): the number of frames per second of the video.\n        decode_all_video (bool): If True, the entire video was decoded.\n    \"\"\"", "\n", "# Try to fetch the decoding information from the video head. Some of the", "\n", "# videos does not support fetching the decoding information, for that case", "\n", "# it will get None duration.", "\n", "fps", "=", "float", "(", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "average_rate", ")", "\n", "frames_length", "=", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "frames", "\n", "duration", "=", "container", ".", "streams", ".", "video", "[", "0", "]", ".", "duration", "\n", "\n", "if", "duration", "is", "None", ":", "\n", "# If failed to fetch the decoding information, decode the entire video.", "\n", "        ", "decode_all_video", "=", "True", "\n", "video_start_pts", ",", "video_end_pts", "=", "0", ",", "math", ".", "inf", "\n", "", "else", ":", "\n", "# Perform selective decoding.", "\n", "        ", "decode_all_video", "=", "False", "\n", "start_idx", ",", "end_idx", "=", "get_start_end_idx", "(", "\n", "frames_length", ",", "\n", "sampling_rate", "*", "num_frames", "/", "target_fps", "*", "fps", ",", "\n", "clip_idx", ",", "\n", "num_clips", ",", "\n", ")", "\n", "timebase", "=", "duration", "/", "frames_length", "\n", "video_start_pts", "=", "int", "(", "start_idx", "*", "timebase", ")", "\n", "video_end_pts", "=", "int", "(", "end_idx", "*", "timebase", ")", "\n", "\n", "", "frames", "=", "None", "\n", "# If video stream was found, fetch video frames from the video.", "\n", "if", "container", ".", "streams", ".", "video", ":", "\n", "        ", "video_frames", ",", "max_pts", "=", "pyav_decode_stream", "(", "\n", "container", ",", "\n", "video_start_pts", ",", "\n", "video_end_pts", ",", "\n", "container", ".", "streams", ".", "video", "[", "0", "]", ",", "\n", "{", "\"video\"", ":", "0", "}", ",", "\n", ")", "\n", "container", ".", "close", "(", ")", "\n", "\n", "if", "get_tensor", ":", "\n", "            ", "frames", "=", "[", "frame", ".", "to_rgb", "(", ")", ".", "to_ndarray", "(", ")", "for", "frame", "in", "video_frames", "]", "\n", "frames", "=", "torch", ".", "as_tensor", "(", "np", ".", "stack", "(", "frames", ")", ")", "\n", "", "else", ":", "\n", "            ", "frames", "=", "[", "frame", ".", "to_image", "(", ")", "for", "frame", "in", "video_frames", "]", "\n", "", "", "return", "frames", ",", "fps", ",", "decode_all_video", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.decode": [[182, 245], ["decoder.get_start_end_idx", "decoder.temporal_sampling", "decoder.pyav_decode", "print", "len"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.get_start_end_idx", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.temporal_sampling", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.pyav_decode"], ["", "def", "decode", "(", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", "=", "-", "1", ",", "\n", "num_clips", "=", "10", ",", "\n", "video_meta", "=", "None", ",", "\n", "target_fps", "=", "30", ",", "\n", "get_tensor", "=", "True", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Decode the video and perform temporal sampling.\n    Args:\n        container (container): pyav container.\n        sampling_rate (int): frame sampling rate (interval between two sampled\n            frames).\n        num_frames (int): number of frames to sample.\n        clip_idx (int): if clip_idx is -1, perform random temporal\n            sampling. If clip_idx is larger than -1, uniformly split the\n            video to num_clips clips, and select the\n            clip_idx-th video clip.\n        num_clips (int): overall number of clips to uniformly\n            sample from the given video.\n        video_meta (dict): a dict contains \"fps\", \"timebase\", and\n            \"max_pts\":\n            `fps` is the frames per second of the given video.\n            `timebase` is the video timebase.\n            `max_pts` is the largest pts from the video.\n        target_fps (int): the input video may have different fps, convert it to\n            the target video fps before frame sampling.\n    Returns:\n        frames (tensor): decoded frames from the video.\n    \"\"\"", "\n", "# Currently support two decoders: 1) PyAV, and 2) TorchVision.", "\n", "assert", "clip_idx", ">=", "-", "1", ",", "\"Not valied clip_idx {}\"", ".", "format", "(", "clip_idx", ")", "\n", "try", ":", "\n", "        ", "frames", ",", "fps", ",", "decode_all_video", "=", "pyav_decode", "(", "\n", "container", ",", "\n", "sampling_rate", ",", "\n", "num_frames", ",", "\n", "clip_idx", ",", "\n", "num_clips", ",", "\n", "target_fps", ",", "\n", "get_tensor", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Failed to decode with pyav with exception: {}\"", ".", "format", "(", "e", ")", ")", "\n", "return", "None", "\n", "\n", "# Return None if the frames was not decoded successfully.", "\n", "", "if", "frames", "is", "None", ":", "\n", "        ", "return", "frames", "\n", "\n", "", "start_idx", ",", "end_idx", "=", "get_start_end_idx", "(", "\n", "frames", ".", "shape", "[", "0", "]", "if", "get_tensor", "else", "len", "(", "frames", ")", ",", "\n", "num_frames", "*", "sampling_rate", "*", "fps", "/", "target_fps", ",", "\n", "clip_idx", "if", "decode_all_video", "else", "0", ",", "\n", "num_clips", "if", "decode_all_video", "else", "1", ",", "\n", ")", "\n", "# Perform temporal sampling from the decoded video.", "\n", "frames", "=", "temporal_sampling", "(", "\n", "frames", ",", "start_idx", ",", "end_idx", ",", "num_frames", ",", "get_tensor", ")", "\n", "return", "frames", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter": [[9, 41], ["int", "torch.nn.functional.interpolate", "round", "int", "int", "numpy.random.uniform", "math.floor", "math.floor", "float", "float"], "function", ["None"], ["def", "random_short_side_scale_jitter", "(", "images", ",", "min_size", ",", "max_size", ")", ":", "\n", "    ", "\"\"\"\n    Perform a spatial short scale jittering on the given images.\n    Args:\n        images (tensor): images to perform scale jitter. Dimension is\n            `num frames` x `channel` x `height` x `width`.\n        min_size (int): the minimal size to scale the frames.\n        max_size (int): the maximal size to scale the frames.\n    Returns:\n        (tensor): the scaled images with dimension of\n            `num frames` x `channel` x `new height` x `new width`.\n    \"\"\"", "\n", "size", "=", "int", "(", "round", "(", "np", ".", "random", ".", "uniform", "(", "min_size", ",", "max_size", ")", ")", ")", "\n", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "if", "(", "width", "<=", "height", "and", "width", "==", "size", ")", "or", "(", "\n", "height", "<=", "width", "and", "height", "==", "size", "\n", ")", ":", "\n", "        ", "return", "images", "\n", "", "new_width", "=", "size", "\n", "new_height", "=", "size", "\n", "if", "width", "<", "height", ":", "\n", "        ", "new_height", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "height", ")", "/", "width", ")", "*", "size", ")", ")", "\n", "", "else", ":", "\n", "        ", "new_width", "=", "int", "(", "math", ".", "floor", "(", "(", "float", "(", "width", ")", "/", "height", ")", "*", "size", ")", ")", "\n", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "\n", "images", ",", "\n", "size", "=", "(", "new_height", ",", "new_width", ")", ",", "\n", "mode", "=", "\"bilinear\"", ",", "\n", "align_corners", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_crop": [[44, 69], ["int", "int", "numpy.random.randint", "numpy.random.randint"], "function", ["None"], ["", "def", "random_crop", "(", "images", ",", "size", ")", ":", "\n", "    ", "\"\"\"\n    Perform random spatial crop on the given images.\n    Args:\n        images (tensor): images to perform random crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): the size of height and width to crop on the image.\n    Returns:\n        (tensor): cropped images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n    \"\"\"", "\n", "if", "images", ".", "shape", "[", "2", "]", "==", "size", "and", "images", ".", "shape", "[", "3", "]", "==", "size", ":", "\n", "        ", "return", "images", "\n", "", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "y_offset", "=", "0", "\n", "if", "height", ">", "size", ":", "\n", "        ", "y_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "height", "-", "size", ")", ")", "\n", "", "x_offset", "=", "0", "\n", "if", "width", ">", "size", ":", "\n", "        ", "x_offset", "=", "int", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "width", "-", "size", ")", ")", "\n", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.horizontal_flip": [[71, 85], ["numpy.random.uniform", "images.flip.flip"], "function", ["None"], ["", "def", "horizontal_flip", "(", "prob", ",", "images", ")", ":", "\n", "    ", "\"\"\"\n    Perform horizontal flip on the given images.\n    Args:\n        prob (float): probility to flip the images.\n        images (tensor): images to perform horizontal flip, the dimension is\n            `num frames` x `channel` x `height` x `width`.\n    Returns:\n        (tensor): images with dimension of\n            `num frames` x `channel` x `height` x `width`.\n    \"\"\"", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "prob", ":", "\n", "        ", "images", "=", "images", ".", "flip", "(", "(", "-", "1", ")", ")", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.uniform_crop": [[87, 122], ["int", "int", "math.ceil", "math.ceil"], "function", ["None"], ["", "def", "uniform_crop", "(", "images", ",", "size", ",", "spatial_idx", ")", ":", "\n", "    ", "\"\"\"\n    Perform uniform spatial sampling on the images.\n    Args:\n        images (tensor): images to perform uniform crop. The dimension is\n            `num frames` x `channel` x `height` x `width`.\n        size (int): size of height and weight to crop the images.\n        spatial_idx (int): 0, 1, or 2 for left, center, and right crop if width\n            is larger than height. Or 0, 1, or 2 for top, center, and bottom\n            crop if height is larger than width.\n    Returns:\n        cropped (tensor): images with dimension of\n            `num frames` x `channel` x `size` x `size`.\n    \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "0", ",", "1", ",", "2", "]", "\n", "height", "=", "images", ".", "shape", "[", "2", "]", "\n", "width", "=", "images", ".", "shape", "[", "3", "]", "\n", "\n", "y_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "height", "-", "size", ")", "/", "2", ")", ")", "\n", "x_offset", "=", "int", "(", "math", ".", "ceil", "(", "(", "width", "-", "size", ")", "/", "2", ")", ")", "\n", "\n", "if", "height", ">", "width", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "y_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "y_offset", "=", "height", "-", "size", "\n", "", "", "else", ":", "\n", "        ", "if", "spatial_idx", "==", "0", ":", "\n", "            ", "x_offset", "=", "0", "\n", "", "elif", "spatial_idx", "==", "2", ":", "\n", "            ", "x_offset", "=", "width", "-", "size", "\n", "", "", "cropped", "=", "images", "[", "\n", ":", ",", ":", ",", "y_offset", ":", "y_offset", "+", "size", ",", "x_offset", ":", "x_offset", "+", "size", "\n", "]", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.color_drop": [[124, 136], ["numpy.random.uniform", "numpy.random.choice", "torch.stack"], "function", ["None"], ["", "def", "color_drop", "(", "prob", ",", "images", ")", ":", "\n", "    ", "'''\n    images (tensor): images to perform uniform crop. The dimension is\n            `channel` x `num frames` x `height` x `width`.\n    '''", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "prob", ":", "\n", "        ", "channel", "=", "np", ".", "random", ".", "choice", "(", "3", ")", "\n", "images", "=", "images", "[", "channel", ",", ":", ",", ":", ",", ":", "]", "\n", "images", "=", "torch", ".", "stack", "(", "(", "images", ",", "images", ",", "images", ")", ",", "0", ")", "\n", "return", "images", "\n", "", "else", ":", "\n", "        ", "return", "images", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.__init__": [[21, 49], ["print", "transformers.DistilBertTokenizer.from_pretrained", "print", "instagram.Instagram.make_dataset"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root_path", ",", "\n", "list_file", ",", "\n", "subset", ",", "\n", "video_tmpl", "=", "'trimmed_resize_{}.mp4'", ",", "\n", "num_frames", "=", "16", ",", "\n", "sample_stride", "=", "4", ",", "\n", "crop_size", "=", "112", ",", "\n", "num_retries", "=", "10", ",", "\n", "max_sentence_length", "=", "64", "\n", ")", ":", "\n", "        ", "assert", "subset", "in", "[", "\n", "'training'", ",", "'validation'", "]", ",", "'Split {} not supported for Instagram'", ".", "format", "(", "subset", ")", "\n", "self", ".", "_subset", "=", "subset", "\n", "\n", "self", ".", "_num_frames", "=", "num_frames", "\n", "self", ".", "_sample_stride", "=", "sample_stride", "\n", "\n", "self", ".", "_crop_size", "=", "crop_size", "\n", "self", ".", "_num_retries", "=", "num_retries", "\n", "\n", "print", "(", "'Init tokenizer...'", ")", "\n", "self", ".", "_tokenizer", "=", "DistilBertTokenizer", ".", "from_pretrained", "(", "\n", "'distilbert-base-uncased'", ")", "\n", "self", ".", "_max_sentence_length", "=", "max_sentence_length", "\n", "\n", "print", "(", "'Making dataset...'", ")", "\n", "self", ".", "make_dataset", "(", "root_path", ",", "list_file", ",", "video_tmpl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.make_dataset": [[50, 74], ["json.load.items", "print", "open", "json.load", "os.path.join", "instagram.Instagram._data.append", "len", "video_tmpl.format", "os.path.exists", "print"], "methods", ["None"], ["", "def", "make_dataset", "(", "self", ",", "video_prefix_path", ",", "list_file", ",", "video_tmpl", ")", ":", "\n", "        ", "self", ".", "_data", "=", "[", "]", "\n", "\n", "with", "open", "(", "list_file", ",", "'r'", ")", "as", "load_f", ":", "\n", "            ", "database", "=", "json", ".", "load", "(", "load_f", ")", "\n", "\n", "", "for", "vid", ",", "info", "in", "database", ".", "items", "(", ")", ":", "\n", "            ", "if", "info", "[", "'subset'", "]", "==", "self", ".", "_subset", ":", "\n", "                ", "video_path", "=", "os", ".", "path", ".", "join", "(", "\n", "video_prefix_path", ",", "video_tmpl", ".", "format", "(", "vid", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "                    ", "print", "(", "\"{} not exists\"", ".", "format", "(", "video_path", ")", ")", "\n", "continue", "\n", "\n", "", "sample", "=", "{", "\n", "'video_path'", ":", "video_path", ",", "\n", "'video_id'", ":", "vid", ",", "\n", "'text'", ":", "info", "[", "'caption'", "]", ",", "\n", "'video_mata'", ":", "{", "}", "\n", "}", "\n", "\n", "self", ".", "_data", ".", "append", "(", "sample", ")", "\n", "", "", "print", "(", "'Make {} dataset ({} clips)'", ".", "format", "(", "list_file", ",", "len", "(", "self", ".", "_data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.__getitem__": [[75, 147], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "text_embedding.long.long.long", "datasets.decoder.decode", "instagram.Instagram.float", "instagram.Instagram.permute", "instagram.Instagram.spatial_sampling", "instagram.Instagram._tokenizer.encode", "random.randint", "datasets.video_container.get_video_container", "random.randint", "random.randint", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.decoder.decode", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.spatial_sampling", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.video_container.get_video_container"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, text_embedding, index).\n        \"\"\"", "\n", "temporal_sample_index", "=", "-", "1", "\n", "spatial_sample_index", "=", "-", "1", "\n", "if", "self", ".", "_crop_size", "==", "112", ":", "\n", "            ", "min_size", ",", "max_size", "=", "128", ",", "170", "\n", "", "elif", "self", ".", "_crop_size", "==", "224", ":", "\n", "            ", "min_size", ",", "max_size", "=", "256", ",", "340", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_num_retries", ")", ":", "\n", "            ", "path", "=", "self", ".", "_data", "[", "index", "]", "[", "'video_path'", "]", "\n", "\n", "text", "=", "self", ".", "_data", "[", "index", "]", "[", "'text'", "]", "\n", "text_ids", "=", "torch", ".", "tensor", "(", "self", ".", "_tokenizer", ".", "encode", "(", "text", ")", ")", "\n", "if", "text_ids", ".", "shape", "[", "0", "]", ">", "512", ":", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_data", ")", "-", "1", ")", "\n", "continue", "\n", "# padding to fixed length", "\n", "", "text_embedding", "=", "torch", ".", "zeros", "(", "self", ".", "_max_sentence_length", ")", "\n", "if", "self", ".", "_max_sentence_length", ">", "text_ids", ".", "shape", "[", "0", "]", ":", "\n", "                ", "text_embedding", "[", "0", ":", "text_ids", ".", "shape", "[", "0", "]", "]", "=", "text_ids", "\n", "", "else", ":", "\n", "                ", "text_embedding", "=", "text_ids", "[", "0", ":", "self", ".", "_max_sentence_length", "]", "\n", "", "text_embedding", "=", "text_embedding", ".", "long", "(", ")", "\n", "\n", "video_container", "=", "None", "\n", "try", ":", "\n", "                ", "video_container", "=", "get_video_container", "(", "\n", "path", ",", "multi_thread_decode", "=", "True", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"Failed to load video from {} with error {}\"", ".", "format", "(", "path", ",", "e", ")", ")", "\n", "\n", "", "if", "video_container", "is", "None", ":", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_data", ")", "-", "1", ")", "\n", "continue", "\n", "\n", "# print('decode video')", "\n", "", "frames", "=", "decode", "(", "video_container", ",", "\n", "self", ".", "_sample_stride", ",", "\n", "self", ".", "_num_frames", ",", "\n", "temporal_sample_index", ",", "\n", "1", ",", "\n", "video_meta", "=", "self", ".", "_data", "[", "index", "]", "[", "'video_mata'", "]", ",", "\n", "target_fps", "=", "30", "\n", ")", "\n", "\n", "if", "frames", "is", "None", ":", "\n", "                ", "index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_data", ")", "-", "1", ")", "\n", "continue", "\n", "\n", "", "frames", "=", "frames", ".", "float", "(", ")", "\n", "frames", "=", "frames", "/", "255.0", "\n", "frames", "=", "frames", "-", "torch", ".", "tensor", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "frames", "=", "frames", "/", "torch", ".", "tensor", "(", "[", "0.225", ",", "0.225", ",", "0.225", "]", ")", "\n", "\n", "frames", "=", "frames", ".", "permute", "(", "3", ",", "0", ",", "1", ",", "2", ")", "\n", "\n", "frames", "=", "self", ".", "spatial_sampling", "(", "\n", "frames", ",", "\n", "spatial_idx", "=", "spatial_sample_index", ",", "\n", "min_scale", "=", "min_size", ",", "\n", "max_scale", "=", "max_size", ",", "\n", "crop_size", "=", "self", ".", "_crop_size", "\n", ")", "\n", "\n", "return", "frames", ",", "text_embedding", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.spatial_sampling": [[148, 194], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "datasets.transform.random_short_side_scale_jitter", "datasets.transform.random_crop", "datasets.transform.horizontal_flip", "datasets.transform.random_short_side_scale_jitter", "datasets.transform.uniform_crop", "len"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_crop", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.horizontal_flip", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.random_short_side_scale_jitter", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.transform.uniform_crop"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "spatial_sampling", "(", "\n", "self", ",", "\n", "frames", ",", "\n", "spatial_idx", "=", "-", "1", ",", "\n", "min_scale", "=", "256", ",", "\n", "max_scale", "=", "320", ",", "\n", "crop_size", "=", "224", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Modify from pySlowFast('https://github.com/facebookresearch/SlowFast')\n\n        Perform spatial sampling on the given video frames. If spatial_idx is\n        -1, perform random scale, random crop, and random flip on the given\n        frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n        with the given spatial_idx.\n        Args:\n            frames (tensor): frames of images sampled from the video. The\n                dimension is `num frames` x `height` x `width` x `channel`.\n            spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n                or 2, perform left, center, right crop if width is larger than\n                height, and perform top, center, buttom crop if height is larger\n                than width.\n            min_scale (int): the minimal size of scaling.\n            max_scale (int): the maximal size of scaling.\n            crop_size (int): the size of height and width used to crop the\n                frames.\n        Returns:\n            frames (tensor): spatially sampled frames.\n        \"\"\"", "\n", "assert", "spatial_idx", "in", "[", "-", "1", ",", "0", ",", "1", ",", "2", "]", "\n", "if", "spatial_idx", "==", "-", "1", ":", "\n", "            ", "frames", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", "=", "random_crop", "(", "frames", ",", "crop_size", ")", "\n", "frames", "=", "horizontal_flip", "(", "0.5", ",", "frames", ")", "\n", "", "else", ":", "\n", "# The testing is deterministic and no jitter should be performed.", "\n", "# min_scale, max_scale, and crop_size are expect to be the same.", "\n", "            ", "assert", "len", "(", "{", "min_scale", ",", "max_scale", ",", "crop_size", "}", ")", "==", "1", "\n", "frames", "=", "random_short_side_scale_jitter", "(", "\n", "frames", ",", "min_scale", ",", "max_scale", "\n", ")", "\n", "frames", "=", "uniform_crop", "(", "frames", ",", "crop_size", ",", "spatial_idx", ")", "\n", "", "return", "frames", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.datasets.instagram.Instagram.__len__": [[195, 197], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.__init__": [[14, 44], ["torch.Module.__init__", "transformers.DistilBertModel.from_pretrained", "cpd.CPD._prepare_base_model", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "alias_multinomial.AliasMethod", "cpd.CPD.multinomial.cuda", "cpd.CPD.register_buffer", "cpd.CPD.register_buffer", "cpd.CPD.register_buffer", "cpd.CPD.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "math.sqrt", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_().add_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand().mul_", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD._prepare_base_model", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["def", "__init__", "(", "self", ",", "visual_encoder", ",", "N_data", ",", "\n", "emb_dim", "=", "256", ",", "dropout", "=", "0", ",", "K", "=", "4096", ",", "T", "=", "0.07", ",", "m", "=", "0.5", ",", "gpu", "=", "None", ")", ":", "\n", "        ", "super", "(", "CPD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "visual_encoder", "=", "visual_encoder", "\n", "self", ".", "textual_encoder", "=", "DistilBertModel", ".", "from_pretrained", "(", "\n", "'distilbert-base-uncased'", ")", "\n", "\n", "self", ".", "emb_dim", "=", "emb_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "_prepare_base_model", "(", ")", "\n", "\n", "self", ".", "vis_emb", "=", "nn", ".", "Linear", "(", "self", ".", "feature_dim", ",", "emb_dim", ")", "\n", "self", ".", "text_emb", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "\n", "768", ",", "emb_dim", "*", "2", ")", ",", "nn", ".", "BatchNorm1d", "(", "emb_dim", "*", "2", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "emb_dim", "*", "2", ",", "emb_dim", ")", ")", "\n", "\n", "self", ".", "N_data", "=", "N_data", "\n", "self", ".", "K", "=", "K", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "unigrams", "=", "torch", ".", "ones", "(", "N_data", ")", "\n", "self", ".", "multinomial", "=", "AliasMethod", "(", "self", ".", "unigrams", ")", "\n", "self", ".", "multinomial", ".", "cuda", "(", "gpu", ")", "\n", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "emb_dim", "/", "3", ")", "\n", "self", ".", "register_buffer", "(", "'Z_v'", ",", "torch", ".", "tensor", "(", "[", "-", "1.0", "]", ")", ")", "\n", "self", ".", "register_buffer", "(", "'Z_t'", ",", "torch", ".", "tensor", "(", "[", "-", "1.0", "]", ")", ")", "\n", "self", ".", "register_buffer", "(", "'vis_memory'", ",", "torch", ".", "rand", "(", "\n", "N_data", ",", "emb_dim", ")", ".", "mul_", "(", "2", "*", "stdv", ")", ".", "add_", "(", "-", "stdv", ")", ")", "\n", "self", ".", "register_buffer", "(", "'text_memory'", ",", "torch", ".", "rand", "(", "\n", "N_data", ",", "emb_dim", ")", ".", "mul_", "(", "2", "*", "stdv", ")", ".", "add_", "(", "-", "stdv", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD._prepare_base_model": [[45, 51], ["getattr", "setattr", "setattr", "cpd.Identity", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["None"], ["", "def", "_prepare_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "feature_dim", "=", "getattr", "(", "self", ".", "visual_encoder", ",", "'fc'", ")", ".", "in_features", "\n", "if", "self", ".", "dropout", "==", "0", ":", "\n", "            ", "setattr", "(", "self", ".", "visual_encoder", ",", "'fc'", ",", "Identity", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "self", ".", "visual_encoder", ",", "'fc'", ",", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.forward": [[52, 105], ["v.size", "cpd.CPD.visual_encoder", "cpd.CPD.vis_emb", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "cpd.CPD.forward_text_encoder", "cpd.CPD.text_emb", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "cpd.CPD.multinomial.draw().view", "cpd.CPD.select().copy_", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "text_feats.view.view.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "torch.index_select().detach", "vis_feats.view.view.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "cpd.CPD.update_memory", "v.squeeze", "mask.sum", "torch.functional.normalize.view", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.functional.normalize.view", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cpd.CPD.Z_v.detach", "cpd.CPD.Z_t.detach", "cpd.CPD.multinomial.draw", "cpd.CPD.select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "cpd.CPD.Z_v[].item", "cpd.reduce_tensor", "print", "cpd.CPD.Z_t[].item", "cpd.reduce_tensor", "print", "cpd.CPD.view", "cpd.CPD.view", "torch.div.mean", "torch.div.mean", "torch.div.mean", "torch.div.mean", "torch.div.mean", "torch.div.mean", "cpd.CPD.Z_v[].item", "cpd.CPD.Z_t[].item"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.forward_text_encoder", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.update_memory", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.draw", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.reduce_tensor", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.reduce_tensor"], ["", "", "def", "forward", "(", "self", ",", "v", ",", "t", ",", "idx", "=", "None", ",", "updbert", "=", "False", ")", ":", "\n", "\n", "# Extract visual embedding", "\n", "        ", "bs", "=", "v", ".", "size", "(", "0", ")", "\n", "vis_base_out", "=", "self", ".", "visual_encoder", "(", "v", ".", "squeeze", "(", ")", ")", "\n", "vis_base_out", "=", "self", ".", "vis_emb", "(", "vis_base_out", ")", "\n", "vis_base_out", "=", "nn", ".", "functional", ".", "normalize", "(", "vis_base_out", ",", "dim", "=", "1", ")", "\n", "\n", "# Extract textual embedding", "\n", "mask", "=", "(", "t", "!=", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "text_base_out", "=", "self", ".", "forward_text_encoder", "(", "t", ",", "updbert", ")", "\n", "# average pooling", "\n", "text_base_out", "=", "(", "text_base_out", "*", "mask", ")", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "\n", "text_base_out", "=", "self", ".", "text_emb", "(", "text_base_out", ")", "\n", "text_base_out", "=", "nn", ".", "functional", ".", "normalize", "(", "text_base_out", ",", "dim", "=", "1", ")", "\n", "\n", "if", "idx", "is", "None", ":", "\n", "# validation forward", "\n", "            ", "return", "vis_base_out", ",", "text_base_out", "\n", "\n", "# Video and text pair discrimination", "\n", "", "slct_idx", "=", "self", ".", "multinomial", ".", "draw", "(", "bs", "*", "(", "self", ".", "K", "+", "1", ")", ")", ".", "view", "(", "bs", ",", "-", "1", ")", "\n", "slct_idx", ".", "select", "(", "1", ",", "0", ")", ".", "copy_", "(", "idx", ".", "data", ")", "\n", "\n", "text_feats", "=", "torch", ".", "index_select", "(", "\n", "self", ".", "text_memory", ",", "0", ",", "slct_idx", ".", "view", "(", "-", "1", ")", ")", ".", "detach", "(", ")", "\n", "text_feats", "=", "text_feats", ".", "view", "(", "bs", ",", "self", ".", "K", "+", "1", ",", "self", ".", "emb_dim", ")", "\n", "vis_out", "=", "torch", ".", "bmm", "(", "text_feats", ",", "vis_base_out", ".", "view", "(", "bs", ",", "self", ".", "emb_dim", ",", "1", ")", ")", "\n", "vis_out", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "vis_out", ",", "self", ".", "T", ")", ")", "\n", "\n", "vis_feats", "=", "torch", ".", "index_select", "(", "\n", "self", ".", "vis_memory", ",", "0", ",", "slct_idx", ".", "view", "(", "-", "1", ")", ")", ".", "detach", "(", ")", "\n", "vis_feats", "=", "vis_feats", ".", "view", "(", "bs", ",", "self", ".", "K", "+", "1", ",", "self", ".", "emb_dim", ")", "\n", "text_out", "=", "torch", ".", "bmm", "(", "\n", "vis_feats", ",", "text_base_out", ".", "view", "(", "bs", ",", "self", ".", "emb_dim", ",", "1", ")", ")", "\n", "text_out", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "text_out", ",", "self", ".", "T", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "Z_v", "[", "0", "]", ".", "item", "(", ")", "<", "0", ":", "\n", "                ", "self", ".", "Z_v", "[", "0", "]", "=", "vis_out", ".", "mean", "(", ")", "*", "self", ".", "N_data", "\n", "self", ".", "Z_v", "[", "0", "]", "=", "reduce_tensor", "(", "self", ".", "Z_v", "[", "0", "]", ")", "\n", "print", "(", "'normalization constant Z_v is set to {:.1f}'", ".", "format", "(", "\n", "self", ".", "Z_v", "[", "0", "]", ".", "item", "(", ")", ")", ")", "\n", "", "if", "self", ".", "Z_t", "[", "0", "]", ".", "item", "(", ")", "<", "0", ":", "\n", "                ", "self", ".", "Z_t", "[", "0", "]", "=", "text_out", ".", "mean", "(", ")", "*", "self", ".", "N_data", "\n", "self", ".", "Z_t", "[", "0", "]", "=", "reduce_tensor", "(", "self", ".", "Z_t", "[", "0", "]", ")", "\n", "print", "(", "'normalization constant Z_t is set to {:.1f}'", ".", "format", "(", "\n", "self", ".", "Z_t", "[", "0", "]", ".", "item", "(", ")", ")", ")", "\n", "", "", "vis_out", "=", "torch", ".", "div", "(", "vis_out", ",", "self", ".", "Z_v", ".", "detach", "(", ")", ")", "\n", "text_out", "=", "torch", ".", "div", "(", "text_out", ",", "self", ".", "Z_t", ".", "detach", "(", ")", ")", "\n", "\n", "self", ".", "update_memory", "(", "vis_base_out", ",", "text_base_out", ",", "idx", ")", "\n", "return", "vis_out", ",", "text_out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.update_memory": [[106, 120], ["cpd.concat_all_gather", "cpd.concat_all_gather", "cpd.concat_all_gather", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select.mul_().add_", "torch.index_select.mul_().add_", "torch.index_select.mul_().add_", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "cpd.CPD.vis_memory.index_copy_", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select.mul_().add_", "torch.index_select.mul_().add_", "torch.index_select.mul_().add_", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "cpd.CPD.text_memory.index_copy_", "concat_all_gather.view", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "concat_all_gather.view", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.index_select.mul_", "torch.index_select.mul_", "torch.index_select.mul_", "torch.index_select.mul_", "torch.index_select.mul_", "torch.index_select.mul_"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather"], ["", "def", "update_memory", "(", "self", ",", "vis_feat", ",", "text_feat", ",", "idx", ")", ":", "\n", "        ", "vis_feat", "=", "concat_all_gather", "(", "vis_feat", ")", "\n", "text_feat", "=", "concat_all_gather", "(", "text_feat", ")", "\n", "idx", "=", "concat_all_gather", "(", "idx", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "vis_pos", "=", "torch", ".", "index_select", "(", "self", ".", "vis_memory", ",", "0", ",", "idx", ".", "view", "(", "-", "1", ")", ")", "\n", "vis_pos", ".", "mul_", "(", "self", ".", "m", ")", ".", "add_", "(", "torch", ".", "mul", "(", "vis_feat", ",", "1", "-", "self", ".", "m", ")", ")", "\n", "vis_update", "=", "nn", ".", "functional", ".", "normalize", "(", "vis_pos", ",", "dim", "=", "1", ")", "\n", "self", ".", "vis_memory", ".", "index_copy_", "(", "0", ",", "idx", ",", "vis_update", ")", "\n", "\n", "text_pos", "=", "torch", ".", "index_select", "(", "self", ".", "text_memory", ",", "0", ",", "idx", ".", "view", "(", "-", "1", ")", ")", "\n", "text_pos", ".", "mul_", "(", "self", ".", "m", ")", ".", "add_", "(", "torch", ".", "mul", "(", "text_feat", ",", "1", "-", "self", ".", "m", ")", ")", "\n", "text_update", "=", "nn", ".", "functional", ".", "normalize", "(", "text_pos", ",", "dim", "=", "1", ")", "\n", "self", ".", "text_memory", ".", "index_copy_", "(", "0", ",", "idx", ",", "text_update", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.CPD.forward_text_encoder": [[121, 132], ["cpd.CPD.textual_encoder", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "cpd.CPD.textual_encoder"], "methods", ["None"], ["", "", "def", "forward_text_encoder", "(", "self", ",", "t", ",", "updbert", ")", ":", "\n", "        ", "\"\"\" \n            Curriculum learning for CPD training stage.\n            Freezing textual encoder in stage I. \n        \"\"\"", "\n", "if", "updbert", ":", "\n", "            ", "text_out", "=", "self", ".", "textual_encoder", "(", "t", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "text_out", "=", "self", ".", "textual_encoder", "(", "t", ")", "[", "0", "]", "\n", "", "", "return", "text_out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.Identity.forward": [[135, 137], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.get_fine_tuning_parameters": [[139, 149], ["model.named_parameters", "parameters.append", "parameters.append"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "lr", ")", ":", "\n", "    ", "\"\"\"Set small learning rate on bert\"\"\"", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'textual_encoder'", "in", "k", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0", "}", ")", "\n", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "lr", "}", ")", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.concat_all_gather": [[151, 163], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like", "torch.ones_like", "torch.ones_like", "range", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "concat_all_gather", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: dist.all_gather has no gradient.\n    \"\"\"", "\n", "tensors_gather", "=", "[", "torch", ".", "ones_like", "(", "tensor", ")", "\n", "for", "_", "in", "range", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "tensors_gather", ",", "tensor", ",", "async_op", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "tensors_gather", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.cpd.reduce_tensor": [[165, 171], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "tensor.clone", "torch.all_reduce", "torch.get_world_size"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reduce_tensor", "(", "tensor", ")", ":", "\n", "    ", "output", "=", "tensor", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "output", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "output", "/=", "dist", ".", "get_world_size", "(", ")", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.BasicBlock.__init__": [[46, 58], ["torch.Module.__init__", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "resnet.conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "resnet.conv3d", "resnet.conv3d"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.conv3d", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.conv3d", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.conv3d"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "temporal_interact", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "temporal_interact", ":", "\n", "            ", "self", ".", "conv1", "=", "conv3d", "(", "inplanes", ",", "planes", ",", "(", "3", ",", "3", ",", "3", ")", ",", "stride", ",", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "conv3d", "(", "inplanes", ",", "planes", ",", "(", "1", ",", "3", ",", "3", ")", ",", "stride", ",", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3d", "(", "planes", ",", "planes", ",", "(", "1", ",", "3", ",", "3", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.BasicBlock.forward": [[59, 76], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.Bottleneck.__init__": [[81, 96], ["torch.Module.__init__", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "temporal_interact", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "temporal_interact", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "(", "3", ",", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "stride", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "(", "1", ",", "1", ",", "1", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.Bottleneck.forward": [[97, 118], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet.__init__": [[122, 176], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "int", "int", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "torch.Dropout", "torch.Dropout", "torch.Dropout", "print", "math.ceil", "math.ceil", "isinstance", "print", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "layers", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "dp", ",", "\n", "shortcut_type", "=", "'B'", ",", "\n", "num_classes", "=", "400", ",", "\n", "extract_feature", "=", "False", ",", "\n", "freeze_bn", "=", "False", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "64", ",", "\n", "kernel_size", "=", "(", "1", ",", "7", ",", "7", ")", ",", "\n", "# kernel_size=7,", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "0", ",", "3", ",", "3", ")", ",", "\n", "# padding=(3, 3, 3),", "\n", "bias", "=", "False", "\n", "# bias=True", "\n", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ",", "shortcut_type", ",", "temporal_interact", "=", "False", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "shortcut_type", ",", "stride", "=", "2", ",", "temporal_interact", "=", "False", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "shortcut_type", ",", "stride", "=", "2", ",", "temporal_interact", "=", "True", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "shortcut_type", ",", "stride", "=", "2", ",", "temporal_interact", "=", "True", ")", "\n", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "sample_duration", "/", "1", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "ceil", "(", "sample_size", "/", "32", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "avgpool_exf", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "1", ",", "1", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "self", ".", "dp", "=", "nn", ".", "Dropout", "(", "p", "=", "dp", ")", "\n", "self", ".", "extract_feature", "=", "extract_feature", "\n", "self", ".", "freeze_bn", "=", "freeze_bn", "\n", "print", "(", "'this resnet has DROPOUT={}!'", ".", "format", "(", "dp", ")", ")", "\n", "if", "self", ".", "extract_feature", ":", "\n", "            ", "print", "(", "\"resnet: EXTRACT FEATURE MODE\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet._make_layer": [[177, 201], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "shortcut_type", ",", "stride", "=", "1", ",", "temporal_interact", "=", "False", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "shortcut_type", "==", "'A'", ":", "\n", "                ", "downsample", "=", "partial", "(", "\n", "downsample_basic_block", ",", "\n", "planes", "=", "planes", "*", "block", ".", "expansion", ",", "\n", "stride", "=", "(", "1", ",", "stride", ",", "stride", ")", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm3d", "(", "planes", "*", "block", ".", "expansion", ")", ")", "\n", "\n", "", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "(", "1", ",", "stride", ",", "stride", ")", ",", "downsample", ",", "temporal_interact", "=", "temporal_interact", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "temporal_interact", "=", "temporal_interact", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet.train": [[202, 209], ["super().train", "print", "resnet.ResNet.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet.train"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "if", "self", ".", "freeze_bn", ":", "\n", "            ", "print", "(", "\"Freezing BatchNorm\"", ")", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.ResNet.forward": [[210, 231], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.dp", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "# print(x.shape)", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "# print(x.shape)", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "# print(x.shape)", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "# print(x.shape)", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "dp", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.conv3d": [[19, 28], ["torch.Conv3d"], "function", ["None"], ["def", "conv3d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ":", "\n", "# 3x3x3 convolution with padding", "\n", "    ", "return", "nn", ".", "Conv3d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.downsample_basic_block": [[30, 41], ["torch.avg_pool3d", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "isinstance", "torch.autograd.Variable", "zero_pads.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["", "def", "downsample_basic_block", "(", "x", ",", "planes", ",", "stride", ")", ":", "\n", "    ", "out", "=", "F", ".", "avg_pool3d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ")", "\n", "zero_pads", "=", "torch", ".", "Tensor", "(", "\n", "out", ".", "size", "(", "0", ")", ",", "planes", "-", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ",", "\n", "out", ".", "size", "(", "4", ")", ")", ".", "zero_", "(", ")", "\n", "if", "isinstance", "(", "out", ".", "data", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "        ", "zero_pads", "=", "zero_pads", ".", "cuda", "(", ")", "\n", "\n", "", "out", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "out", ".", "data", ",", "zero_pads", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.get_fine_tuning_parameters": [[233, 252], ["range", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "parameters.append", "print"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ",", "lr", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'layer{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'fc'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "name", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "param", "}", ")", "\n", "print", "(", "'update:'", ",", "name", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet10": [[254, 259], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet10", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet18": [[261, 266], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet34": [[268, 273], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet34", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet50": [[275, 280], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet50", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet101": [[282, 287], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet101", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet152": [[289, 294], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet152", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.resnet.resnet200": [[296, 301], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet200", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.__init__": [[5, 35], ["len", "torch.zeros", "torch.LongTensor", "enumerate", "probs.sum", "probs.div_", "smaller.pop", "larger.pop", "probs.sum", "smaller.append", "larger.append", "len", "len", "smaller.append", "larger.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "probs", ")", ":", "\n", "        ", "if", "probs", ".", "sum", "(", ")", ">", "1", ":", "\n", "            ", "probs", ".", "div_", "(", "probs", ".", "sum", "(", ")", ")", "\n", "", "K", "=", "len", "(", "probs", ")", "\n", "self", ".", "prob", "=", "torch", ".", "zeros", "(", "K", ")", "\n", "self", ".", "alias", "=", "torch", ".", "LongTensor", "(", "[", "0", "]", "*", "K", ")", "\n", "\n", "smaller", "=", "[", "]", "\n", "larger", "=", "[", "]", "\n", "for", "kk", ",", "prob", "in", "enumerate", "(", "probs", ")", ":", "\n", "            ", "self", ".", "prob", "[", "kk", "]", "=", "K", "*", "prob", "\n", "if", "self", ".", "prob", "[", "kk", "]", "<", "1.0", ":", "\n", "                ", "smaller", ".", "append", "(", "kk", ")", "\n", "", "else", ":", "\n", "                ", "larger", ".", "append", "(", "kk", ")", "\n", "\n", "", "", "while", "len", "(", "smaller", ")", ">", "0", "and", "len", "(", "larger", ")", ">", "0", ":", "\n", "            ", "small", "=", "smaller", ".", "pop", "(", ")", "\n", "large", "=", "larger", ".", "pop", "(", ")", "\n", "\n", "self", ".", "alias", "[", "small", "]", "=", "large", "\n", "self", ".", "prob", "[", "large", "]", "=", "(", "self", ".", "prob", "[", "large", "]", "-", "1.0", ")", "+", "self", ".", "prob", "[", "small", "]", "\n", "\n", "if", "self", ".", "prob", "[", "large", "]", "<", "1.0", ":", "\n", "                ", "smaller", ".", "append", "(", "large", ")", "\n", "", "else", ":", "\n", "                ", "larger", ".", "append", "(", "large", ")", "\n", "\n", "", "", "for", "last_one", "in", "smaller", "+", "larger", ":", "\n", "            ", "self", ".", "prob", "[", "last_one", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda": [[36, 39], ["alias_multinomial.AliasMethod.prob.cuda", "alias_multinomial.AliasMethod.alias.cuda"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.cuda"], ["", "", "def", "cuda", "(", "self", ",", "gpu", ")", ":", "\n", "        ", "self", ".", "prob", "=", "self", ".", "prob", ".", "cuda", "(", "gpu", ")", "\n", "self", ".", "alias", "=", "self", ".", "alias", ".", "cuda", "(", "gpu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.models.alias_multinomial.AliasMethod.draw": [[41, 53], ["alias_multinomial.AliasMethod.alias.size", "torch.zeros().random_", "alias_multinomial.AliasMethod.prob.index_select", "alias_multinomial.AliasMethod.alias.index_select", "torch.bernoulli", "torch.zeros().random_.mul", "alias_multinomial.AliasMethod.mul", "torch.bernoulli.long", "torch.zeros"], "methods", ["None"], ["", "def", "draw", "(", "self", ",", "N", ")", ":", "\n", "        ", "K", "=", "self", ".", "alias", ".", "size", "(", "0", ")", "\n", "\n", "kk", "=", "torch", ".", "zeros", "(", "N", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "prob", ".", "device", ")", ".", "random_", "(", "0", ",", "K", ")", "\n", "prob", "=", "self", ".", "prob", ".", "index_select", "(", "0", ",", "kk", ")", "\n", "alias", "=", "self", ".", "alias", ".", "index_select", "(", "0", ",", "kk", ")", "\n", "\n", "b", "=", "torch", ".", "bernoulli", "(", "prob", ")", "\n", "oq", "=", "kk", ".", "mul", "(", "b", ".", "long", "(", ")", ")", "\n", "oj", "=", "alias", ".", "mul", "(", "(", "1", "-", "b", ")", ".", "long", "(", ")", ")", "\n", "\n", "return", "oq", "+", "oj", "\n", "", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_ucf101.UCFclassification.__init__": [[8, 30], ["eval_ucf101.UCFclassification._import_ground_truth", "eval_ucf101.UCFclassification._import_prediction", "IOError", "IOError", "print", "len", "print", "len", "print"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_ground_truth", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_prediction"], ["    ", "def", "__init__", "(", "self", ",", "ground_truth_filename", "=", "None", ",", "prediction_filename", "=", "None", ",", "\n", "subset", "=", "'validation'", ",", "verbose", "=", "False", ",", "top_k", "=", "1", ")", ":", "\n", "        ", "if", "not", "ground_truth_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid ground truth file.'", ")", "\n", "", "if", "not", "prediction_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid prediction file.'", ")", "\n", "", "self", ".", "subset", "=", "subset", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "ap", "=", "None", "\n", "self", ".", "hit_at_k", "=", "None", "\n", "# Import ground truth and predictions.", "\n", "self", ".", "ground_truth", ",", "self", ".", "activity_index", "=", "self", ".", "_import_ground_truth", "(", "\n", "ground_truth_filename", ")", "\n", "self", ".", "prediction", "=", "self", ".", "_import_prediction", "(", "prediction_filename", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[INIT] Loaded annotations from {} subset.'", ".", "format", "(", "subset", ")", ")", "\n", "nr_gt", "=", "len", "(", "self", ".", "ground_truth", ")", "\n", "print", "(", "'\\tNumber of ground truth instances: {}'", ".", "format", "(", "nr_gt", ")", ")", "\n", "nr_pred", "=", "len", "(", "self", ".", "prediction", ")", "\n", "print", "(", "'\\tNumber of predictions: {}'", ".", "format", "(", "nr_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_ucf101.UCFclassification._import_ground_truth": [[31, 69], ["data[].items", "pandas.DataFrame", "ground_truth.drop_duplicates().reset_index.drop_duplicates().reset_index.drop_duplicates().reset_index", "open", "json.load", "video_lst.append", "label_lst.append", "ground_truth.drop_duplicates().reset_index.drop_duplicates().reset_index.drop_duplicates"], "methods", ["None"], ["", "", "def", "_import_ground_truth", "(", "self", ",", "ground_truth_filename", ")", ":", "\n", "        ", "\"\"\"Reads ground truth file, checks if it is well formatted, and returns\n           the ground truth instances and the activity classes.\n\n        Parameters\n        ----------\n        ground_truth_filename : str\n            Full path to the ground truth json file.\n\n        Outputs\n        -------\n        ground_truth : df\n            Data frame containing the ground truth instances.\n        activity_index : dict\n            Dictionary containing class index.\n        \"\"\"", "\n", "with", "open", "(", "ground_truth_filename", ",", "'r'", ")", "as", "fobj", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fobj", ")", "\n", "# Checking format", "\n", "# if not all([field in data.keys() for field in self.gt_fields]):", "\n", "# raise IOError('Please input a valid ground truth file.')", "\n", "\n", "# Initialize data frame", "\n", "", "activity_index", ",", "cidx", "=", "{", "}", ",", "0", "\n", "video_lst", ",", "label_lst", "=", "[", "]", ",", "[", "]", "\n", "for", "videoid", ",", "v", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "subset", "!=", "v", "[", "'subset'", "]", ":", "\n", "                ", "continue", "\n", "", "this_label", "=", "v", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "if", "this_label", "not", "in", "activity_index", ":", "\n", "                ", "activity_index", "[", "this_label", "]", "=", "cidx", "\n", "cidx", "+=", "1", "\n", "", "video_lst", ".", "append", "(", "videoid", ")", "\n", "label_lst", ".", "append", "(", "activity_index", "[", "this_label", "]", ")", "\n", "", "ground_truth", "=", "pd", ".", "DataFrame", "(", "{", "'video-id'", ":", "video_lst", ",", "\n", "'label'", ":", "label_lst", "}", ")", "\n", "ground_truth", "=", "ground_truth", ".", "drop_duplicates", "(", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "return", "ground_truth", ",", "activity_index", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_ucf101.UCFclassification._import_prediction": [[70, 102], ["data[].items", "pandas.DataFrame", "open", "json.load", "video_lst.append", "label_lst.append", "score_lst.append"], "methods", ["None"], ["", "def", "_import_prediction", "(", "self", ",", "prediction_filename", ")", ":", "\n", "        ", "\"\"\"Reads prediction file, checks if it is well formatted, and returns\n           the prediction instances.\n\n        Parameters\n        ----------\n        prediction_filename : str\n            Full path to the prediction json file.\n\n        Outputs\n        -------\n        prediction : df\n            Data frame containing the prediction instances.\n        \"\"\"", "\n", "with", "open", "(", "prediction_filename", ",", "'r'", ")", "as", "fobj", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fobj", ")", "\n", "# Checking format...", "\n", "# if not all([field in data.keys() for field in self.pred_fields]):", "\n", "# raise IOError('Please input a valid prediction file.')", "\n", "\n", "# Initialize data frame", "\n", "", "video_lst", ",", "label_lst", ",", "score_lst", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "videoid", ",", "v", "in", "data", "[", "'results'", "]", ".", "items", "(", ")", ":", "\n", "            ", "for", "result", "in", "v", ":", "\n", "                ", "label", "=", "self", ".", "activity_index", "[", "result", "[", "'label'", "]", "]", "\n", "video_lst", ".", "append", "(", "videoid", ")", "\n", "label_lst", ".", "append", "(", "label", ")", "\n", "score_lst", ".", "append", "(", "result", "[", "'score'", "]", ")", "\n", "", "", "prediction", "=", "pd", ".", "DataFrame", "(", "{", "'video-id'", ":", "video_lst", ",", "\n", "'label'", ":", "label_lst", ",", "\n", "'score'", ":", "score_lst", "}", ")", "\n", "return", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_ucf101.UCFclassification.evaluate": [[103, 116], ["eval_ucf101.compute_video_hit_at_k", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.compute_video_hit_at_k"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Evaluates a prediction file. For the detection task we measure the\n        interpolated mean average precision to measure the performance of a\n        method.\n        \"\"\"", "\n", "hit_at_k", "=", "compute_video_hit_at_k", "(", "self", ".", "ground_truth", ",", "\n", "self", ".", "prediction", ",", "top_k", "=", "self", ".", "top_k", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[RESULTS] Performance on UCF101 trimmed video '", "\n", "'classification task.'", ")", "\n", "print", "(", "'\\tAccuracy@{}: {}'", ".", "format", "(", "self", ".", "top_k", ",", "hit_at_k", ")", ")", "\n", "#print '\\tAvg Hit@{}: {}'.format(self.top_k, avg_hit_at_k)", "\n", "", "self", ".", "hit_at_k", "=", "hit_at_k", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_ucf101.compute_video_hit_at_k": [[120, 156], ["numpy.unique", "numpy.zeros", "enumerate", "float", "prediction.loc[].reset_index", "this_pred.loc[].reset_index.loc[].reset_index", "this_pred[].tolist", "[].tolist", "numpy.mean", "np.zeros.mean", "pred_idx.any", "this_pred[].values.argsort"], "function", ["None"], ["", "", "def", "compute_video_hit_at_k", "(", "ground_truth", ",", "prediction", ",", "top_k", "=", "3", ")", ":", "\n", "    ", "\"\"\"Compute accuracy at k prediction between ground truth and\n    predictions data frames. This code is greatly inspired by evaluation\n    performed in Karpathy et al. CVPR14.\n\n    Parameters\n    ----------\n    ground_truth : df\n        Data frame containing the ground truth instances.\n        Required fields: ['video-id', 'label']\n    prediction : df\n        Data frame containing the prediction instances.\n        Required fields: ['video-id, 'label', 'score']\n\n    Outputs\n    -------\n    acc : float\n        Top k accuracy score.\n    \"\"\"", "\n", "video_ids", "=", "np", ".", "unique", "(", "ground_truth", "[", "'video-id'", "]", ".", "values", ")", "\n", "avg_hits_per_vid", "=", "np", ".", "zeros", "(", "video_ids", ".", "size", ")", "\n", "for", "i", ",", "vid", "in", "enumerate", "(", "video_ids", ")", ":", "\n", "        ", "pred_idx", "=", "prediction", "[", "'video-id'", "]", "==", "vid", "\n", "if", "not", "pred_idx", ".", "any", "(", ")", ":", "\n", "            ", "continue", "\n", "", "this_pred", "=", "prediction", ".", "loc", "[", "pred_idx", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Get top K predictions sorted by decreasing score.", "\n", "sort_idx", "=", "this_pred", "[", "'score'", "]", ".", "values", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_k", "]", "\n", "this_pred", "=", "this_pred", ".", "loc", "[", "sort_idx", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Get labels and compare against ground truth.", "\n", "pred_label", "=", "this_pred", "[", "'label'", "]", ".", "tolist", "(", ")", "\n", "gt_idx", "=", "ground_truth", "[", "'video-id'", "]", "==", "vid", "\n", "gt_label", "=", "ground_truth", ".", "loc", "[", "gt_idx", "]", "[", "'label'", "]", ".", "tolist", "(", ")", "\n", "avg_hits_per_vid", "[", "i", "]", "=", "np", ".", "mean", "(", "[", "1", "if", "this_label", "in", "pred_label", "else", "0", "\n", "for", "this_label", "in", "gt_label", "]", ")", "\n", "", "return", "float", "(", "avg_hits_per_vid", ".", "mean", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification.__init__": [[8, 30], ["eval_hmdb51.HMDBclassification._import_ground_truth", "eval_hmdb51.HMDBclassification._import_prediction", "IOError", "IOError", "print", "len", "print", "len", "print"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_ground_truth", "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_prediction"], ["    ", "def", "__init__", "(", "self", ",", "ground_truth_filename", "=", "None", ",", "prediction_filename", "=", "None", ",", "\n", "subset", "=", "'validation'", ",", "verbose", "=", "False", ",", "top_k", "=", "1", ")", ":", "\n", "        ", "if", "not", "ground_truth_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid ground truth file.'", ")", "\n", "", "if", "not", "prediction_filename", ":", "\n", "            ", "raise", "IOError", "(", "'Please input a valid prediction file.'", ")", "\n", "", "self", ".", "subset", "=", "subset", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "ap", "=", "None", "\n", "self", ".", "hit_at_k", "=", "None", "\n", "# Import ground truth and predictions.", "\n", "self", ".", "ground_truth", ",", "self", ".", "activity_index", "=", "self", ".", "_import_ground_truth", "(", "\n", "ground_truth_filename", ")", "\n", "self", ".", "prediction", "=", "self", ".", "_import_prediction", "(", "prediction_filename", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[INIT] Loaded annotations from {} subset.'", ".", "format", "(", "subset", ")", ")", "\n", "nr_gt", "=", "len", "(", "self", ".", "ground_truth", ")", "\n", "print", "(", "'\\tNumber of ground truth instances: {}'", ".", "format", "(", "nr_gt", ")", ")", "\n", "nr_pred", "=", "len", "(", "self", ".", "prediction", ")", "\n", "print", "(", "'\\tNumber of predictions: {}'", ".", "format", "(", "nr_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_ground_truth": [[31, 69], ["data[].iteritems", "pandas.DataFrame", "ground_truth.drop_duplicates().reset_index.drop_duplicates().reset_index.drop_duplicates().reset_index", "open", "json.load", "video_lst.append", "label_lst.append", "ground_truth.drop_duplicates().reset_index.drop_duplicates().reset_index.drop_duplicates"], "methods", ["None"], ["", "", "def", "_import_ground_truth", "(", "self", ",", "ground_truth_filename", ")", ":", "\n", "        ", "\"\"\"Reads ground truth file, checks if it is well formatted, and returns\n           the ground truth instances and the activity classes.\n\n        Parameters\n        ----------\n        ground_truth_filename : str\n            Full path to the ground truth json file.\n\n        Outputs\n        -------\n        ground_truth : df\n            Data frame containing the ground truth instances.\n        activity_index : dict\n            Dictionary containing class index.\n        \"\"\"", "\n", "with", "open", "(", "ground_truth_filename", ",", "'r'", ")", "as", "fobj", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fobj", ")", "\n", "# Checking format", "\n", "# if not all([field in data.keys() for field in self.gt_fields]):", "\n", "# raise IOError('Please input a valid ground truth file.')", "\n", "\n", "# Initialize data frame", "\n", "", "activity_index", ",", "cidx", "=", "{", "}", ",", "0", "\n", "video_lst", ",", "label_lst", "=", "[", "]", ",", "[", "]", "\n", "for", "videoid", ",", "v", "in", "data", "[", "'database'", "]", ".", "iteritems", "(", ")", ":", "\n", "            ", "if", "self", ".", "subset", "!=", "v", "[", "'subset'", "]", ":", "\n", "                ", "continue", "\n", "", "this_label", "=", "v", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "if", "this_label", "not", "in", "activity_index", ":", "\n", "                ", "activity_index", "[", "this_label", "]", "=", "cidx", "\n", "cidx", "+=", "1", "\n", "", "video_lst", ".", "append", "(", "videoid", ")", "\n", "label_lst", ".", "append", "(", "activity_index", "[", "this_label", "]", ")", "\n", "", "ground_truth", "=", "pd", ".", "DataFrame", "(", "{", "'video-id'", ":", "video_lst", ",", "\n", "'label'", ":", "label_lst", "}", ")", "\n", "ground_truth", "=", "ground_truth", ".", "drop_duplicates", "(", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "return", "ground_truth", ",", "activity_index", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification._import_prediction": [[70, 102], ["data[].iteritems", "pandas.DataFrame", "open", "json.load", "video_lst.append", "label_lst.append", "score_lst.append"], "methods", ["None"], ["", "def", "_import_prediction", "(", "self", ",", "prediction_filename", ")", ":", "\n", "        ", "\"\"\"Reads prediction file, checks if it is well formatted, and returns\n           the prediction instances.\n\n        Parameters\n        ----------\n        prediction_filename : str\n            Full path to the prediction json file.\n\n        Outputs\n        -------\n        prediction : df\n            Data frame containing the prediction instances.\n        \"\"\"", "\n", "with", "open", "(", "prediction_filename", ",", "'r'", ")", "as", "fobj", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "fobj", ")", "\n", "# Checking format...", "\n", "# if not all([field in data.keys() for field in self.pred_fields]):", "\n", "# raise IOError('Please input a valid prediction file.')", "\n", "\n", "# Initialize data frame", "\n", "", "video_lst", ",", "label_lst", ",", "score_lst", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "videoid", ",", "v", "in", "data", "[", "'results'", "]", ".", "iteritems", "(", ")", ":", "\n", "            ", "for", "result", "in", "v", ":", "\n", "                ", "label", "=", "self", ".", "activity_index", "[", "result", "[", "'label'", "]", "]", "\n", "video_lst", ".", "append", "(", "videoid", ")", "\n", "label_lst", ".", "append", "(", "label", ")", "\n", "score_lst", ".", "append", "(", "result", "[", "'score'", "]", ")", "\n", "", "", "prediction", "=", "pd", ".", "DataFrame", "(", "{", "'video-id'", ":", "video_lst", ",", "\n", "'label'", ":", "label_lst", ",", "\n", "'score'", ":", "score_lst", "}", ")", "\n", "return", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.HMDBclassification.evaluate": [[103, 116], ["eval_hmdb51.compute_video_hit_at_k", "print", "print"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.compute_video_hit_at_k"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Evaluates a prediction file. For the detection task we measure the\n        interpolated mean average precision to measure the performance of a\n        method.\n        \"\"\"", "\n", "hit_at_k", "=", "compute_video_hit_at_k", "(", "self", ".", "ground_truth", ",", "\n", "self", ".", "prediction", ",", "top_k", "=", "self", ".", "top_k", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "'[RESULTS] Performance on ActivityNet untrimmed video '", "\n", "'classification task.'", ")", "\n", "print", "(", "'\\tError@{}: {}'", ".", "format", "(", "self", ".", "top_k", ",", "1.0", "-", "hit_at_k", ")", ")", "\n", "#print '\\tAvg Hit@{}: {}'.format(self.top_k, avg_hit_at_k)", "\n", "", "self", ".", "hit_at_k", "=", "hit_at_k", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.evaluation.eval_hmdb51.compute_video_hit_at_k": [[120, 156], ["numpy.unique", "numpy.zeros", "enumerate", "float", "prediction.loc[].reset_index", "this_pred.loc[].reset_index.loc[].reset_index", "this_pred[].tolist", "[].tolist", "numpy.mean", "np.zeros.mean", "pred_idx.any", "this_pred[].values.argsort"], "function", ["None"], ["", "", "def", "compute_video_hit_at_k", "(", "ground_truth", ",", "prediction", ",", "top_k", "=", "3", ")", ":", "\n", "    ", "\"\"\"Compute accuracy at k prediction between ground truth and\n    predictions data frames. This code is greatly inspired by evaluation\n    performed in Karpathy et al. CVPR14.\n\n    Parameters\n    ----------\n    ground_truth : df\n        Data frame containing the ground truth instances.\n        Required fields: ['video-id', 'label']\n    prediction : df\n        Data frame containing the prediction instances.\n        Required fields: ['video-id, 'label', 'score']\n\n    Outputs\n    -------\n    acc : float\n        Top k accuracy score.\n    \"\"\"", "\n", "video_ids", "=", "np", ".", "unique", "(", "ground_truth", "[", "'video-id'", "]", ".", "values", ")", "\n", "avg_hits_per_vid", "=", "np", ".", "zeros", "(", "video_ids", ".", "size", ")", "\n", "for", "i", ",", "vid", "in", "enumerate", "(", "video_ids", ")", ":", "\n", "        ", "pred_idx", "=", "prediction", "[", "'video-id'", "]", "==", "vid", "\n", "if", "not", "pred_idx", ".", "any", "(", ")", ":", "\n", "            ", "continue", "\n", "", "this_pred", "=", "prediction", ".", "loc", "[", "pred_idx", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Get top K predictions sorted by decreasing score.", "\n", "sort_idx", "=", "this_pred", "[", "'score'", "]", ".", "values", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_k", "]", "\n", "this_pred", "=", "this_pred", ".", "loc", "[", "sort_idx", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Get labels and compare against ground truth.", "\n", "pred_label", "=", "this_pred", "[", "'label'", "]", ".", "tolist", "(", ")", "\n", "gt_idx", "=", "ground_truth", "[", "'video-id'", "]", "==", "vid", "\n", "gt_label", "=", "ground_truth", ".", "loc", "[", "gt_idx", "]", "[", "'label'", "]", ".", "tolist", "(", ")", "\n", "avg_hits_per_vid", "[", "i", "]", "=", "np", ".", "mean", "(", "[", "1", "if", "this_label", "in", "pred_label", "else", "0", "\n", "for", "this_label", "in", "gt_label", "]", ")", "\n", "", "return", "float", "(", "avg_hits_per_vid", ".", "mean", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__": [[8, 11], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_data", ")", ":", "\n", "        ", "super", "(", "NCECriterion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_data", "=", "n_data", "\n", "\n"]], "home.repos.pwc.inspect_result.MCG-NJU_CPD-Video.loss.NCECriterion.NCECriterion.forward": [[12, 27], ["x.select", "torch.div().log_", "x.narrow", "torch.div().log_", "float", "torch.div", "torch.div", "torch.div().log_.sum", "torch.div().log_.view().sum", "x.select.add", "x.narrow.clone().fill_", "x.narrow.add", "torch.div().log_.view", "x.narrow.clone"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batchsize", "=", "x", ".", "shape", "[", "0", "]", "\n", "m", "=", "x", ".", "shape", "[", "1", "]", "-", "1", "\n", "\n", "Pn", "=", "1", "/", "float", "(", "self", ".", "n_data", ")", "\n", "\n", "P_pos", "=", "x", ".", "select", "(", "1", ",", "0", ")", "\n", "log_D1", "=", "torch", ".", "div", "(", "P_pos", ",", "P_pos", ".", "add", "(", "m", "*", "Pn", "+", "eps", ")", ")", ".", "log_", "(", ")", "\n", "\n", "P_neg", "=", "x", ".", "narrow", "(", "1", ",", "1", ",", "m", ")", "\n", "log_D0", "=", "torch", ".", "div", "(", "P_neg", ".", "clone", "(", ")", ".", "fill_", "(", "m", "*", "Pn", ")", ",", "P_neg", ".", "add", "(", "m", "*", "Pn", "+", "eps", ")", ")", ".", "log_", "(", ")", "\n", "\n", "loss_pos", "=", "-", "log_D1", ".", "sum", "(", "0", ")", "/", "batchsize", "\n", "loss_neg", "=", "-", "log_D0", ".", "view", "(", "-", "1", ",", "1", ")", ".", "sum", "(", "0", ")", "/", "batchsize", "\n", "return", "loss_pos", ",", "loss_neg", "\n", "", "", ""]]}