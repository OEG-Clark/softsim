{"home.repos.pwc.inspect_result.cswluo_SEF.None.modellearning.train": [[17, 248], ["isinstance", "copy.deepcopy", "time.time", "range", "print", "print", "print", "print", "dict", "best_acc.item", "model.load_state_dict", "print", "len", "isinstance", "model.state_dict", "utils.modelserial.loadCheckpoint", "model.load_state_dict", "print", "print", "print", "print", "scheduler.step", "print", "time.time", "len", "print", "print", "dataloader.keys", "model.train", "model.eval", "inputs.cuda.cuda", "labels.cuda.cuda", "optimizer.zero_grad", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "running_corrects.double", "range", "print", "print", "print", "copy.deepcopy", "utils.modelserial.saveCheckpoint", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.max", "torch.max", "torch.max", "torch.max", "cls_loss.item", "inputs.cuda.size", "torch.tensor.item", "inputs.cuda.size", "range", "writer.add_scalar", "writer.add_scalar", "model.named_parameters", "writer.add_scalar", "writer.add_scalar", "model.named_parameters", "model.state_dict", "model", "softmax", "range", "logsoftmax", "range", "model", "softmax", "all_loss.backward", "optimizer.step", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "cls_loss.item", "torch.tensor.item", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_histogram", "running_corrects_parts[].double", "range", "writer.add_histogram", "writer.add_scalar", "writer.add_scalar", "model.state_dict", "probl.append", "predl.append", "logprobl.append", "torch.mul().sum().div", "torch.mul().sum().div", "torch.mul().sum().div", "torch.mul().sum().div", "soft_loss_list.append", "sum().div", "logsoftmax", "torch.mul().sum().neg().div", "torch.mul().sum().neg().div", "torch.mul().sum().neg().div", "torch.mul().sum().neg().div", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "writer.add_scalar", "param.data.clone().cpu().numpy", "writer.add_scalar", "param.data.clone().cpu().numpy", "range", "softmax", "logsoftmax", "inputs.cuda.size", "torch.mul().sum().div", "torch.mul().sum().div", "torch.mul().sum().div", "torch.mul().sum().div", "inputs.cuda.size", "writer.add_scalar", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "inputs.cuda.size", "sum", "torch.mul().sum().neg", "torch.mul().sum().neg", "torch.mul().sum().neg", "torch.mul().sum().neg", "param.data.clone().cpu", "param.data.clone().cpu", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "param.data.clone", "param.data.clone", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.neg", "torch.neg", "torch.neg", "torch.neg", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.modelserial.loadCheckpoint", "home.repos.pwc.inspect_result.cswluo_SEF.None.modellearning.train", "home.repos.pwc.inspect_result.cswluo_SEF.None.modellearning.eval", "home.repos.pwc.inspect_result.cswluo_SEF.utils.modelserial.saveCheckpoint"], ["def", "train", "(", "model", ",", "dataloader", ",", "criterion", ",", "optimizer", ",", "scheduler", ",", "datasetname", "=", "None", ",", "isckpt", "=", "False", ",", "epochs", "=", "50", ",", "networkname", "=", "None", ",", "writer", "=", "None", ",", "maxent_flag", "=", "False", ",", "device", "=", "'cpu'", ",", "**", "penalty", ")", ":", "\n", "\n", "    ", "output_log_file", "=", "penalty", "[", "'logfile'", "]", "\n", "nparts", "=", "model", ".", "nparts", "\n", "attention_flag", "=", "model", ".", "attention", "\n", "\n", "if", "isinstance", "(", "dataloader", ",", "dict", ")", ":", "\n", "        ", "dataset_sizes", "=", "{", "x", ":", "len", "(", "dataloader", "[", "x", "]", ".", "dataset", ")", "for", "x", "in", "dataloader", ".", "keys", "(", ")", "}", "\n", "print", "(", "dataset_sizes", ")", "\n", "", "else", ":", "\n", "        ", "dataset_size", "=", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "criterion", ",", "list", ")", ":", "\n", "        ", "criterion", "=", "[", "criterion", "]", "\n", "\n", "", "best_model_params", "=", "copy", ".", "deepcopy", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "best_acc", "=", "0.0", "\n", "global_step", "=", "0", "\n", "global_step_resume", "=", "0", "\n", "best_epoch", "=", "0", "\n", "best_step", "=", "0", "\n", "start_epoch", "=", "-", "1", "\n", "\n", "\n", "if", "isckpt", ":", "\n", "        ", "checkpoint", "=", "modelserial", ".", "loadCheckpoint", "(", "datasetname", "+", "'-'", "+", "networkname", ")", "\n", "\n", "# records for the stopping epoch", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "global_step_resume", "=", "checkpoint", "[", "'global_step'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "\n", "# records for the epoch with the best performance", "\n", "best_model_params", "=", "checkpoint", "[", "'best_state_dict'", "]", "\n", "best_acc", "=", "checkpoint", "[", "'best_acc'", "]", "\n", "best_epoch", "=", "checkpoint", "[", "'best_epoch'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "checkpoint", "[", "'current_lr'", "]", "\n", "\n", "", "since", "=", "time", ".", "time", "(", ")", "\n", "for", "epoch", "in", "range", "(", "start_epoch", "+", "1", ",", "epochs", ")", ":", "\n", "\n", "# print to file", "\n", "        ", "print", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "epochs", ")", ",", "file", "=", "output_log_file", ")", "\n", "print", "(", "'-'", "*", "10", ",", "file", "=", "output_log_file", ")", "\n", "\n", "# print to terminal", "\n", "print", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "epochs", ")", ")", "\n", "print", "(", "'-'", "*", "10", ")", "\n", "\n", "\n", "for", "phase", "in", "[", "'trainval'", ",", "'test'", "]", ":", "\n", "            ", "if", "phase", "==", "'trainval'", ":", "\n", "# scheduler.step()", "\n", "                ", "model", ".", "train", "(", ")", "# Set model to training mode", "\n", "global_step", "=", "global_step_resume", "\n", "", "else", ":", "\n", "                ", "model", ".", "eval", "(", ")", "# Set model to evaluate mode", "\n", "global_step_resume", "=", "global_step", "\n", "\n", "", "running_cls_loss", "=", "0.0", "\n", "running_reg_loss", "=", "0.0", "\n", "running_corrects", "=", "0.0", "\n", "running_corrects_parts", "=", "[", "0.0", "]", "*", "nparts", "\n", "epoch_acc_parts", "=", "[", "0.0", "]", "*", "nparts", "\n", "\n", "\n", "for", "inputs", ",", "labels", "in", "dataloader", "[", "phase", "]", ":", "\n", "                ", "inputs", "=", "inputs", ".", "cuda", "(", "device", ")", "\n", "labels", "=", "labels", ".", "cuda", "(", "device", ")", "\n", "\n", "# zero the parameter gradients", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# forward", "\n", "with", "torch", ".", "set_grad_enabled", "(", "phase", "==", "'trainval'", ")", ":", "\n", "\n", "                    ", "if", "attention_flag", ":", "\n", "# outputs are logits from linear models", "\n", "                        ", "xglobal", ",", "xlocal", ",", "xcosin", ",", "_", "=", "model", "(", "inputs", ")", "\n", "probs", "=", "softmax", "(", "xglobal", ")", "\n", "cls_loss", "=", "criterion", "[", "0", "]", "(", "xglobal", ",", "labels", ")", "\n", "\n", "############################################################## prediction", "\n", "\n", "# prediction of every  branch", "\n", "probl", ",", "predl", ",", "logprobl", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                            ", "probl", ".", "append", "(", "softmax", "(", "torch", ".", "squeeze", "(", "xlocal", "[", "i", "]", ")", ")", ")", "\n", "predl", ".", "append", "(", "torch", ".", "max", "(", "probl", "[", "i", "]", ",", "1", ")", "[", "-", "1", "]", ")", "\n", "logprobl", ".", "append", "(", "logsoftmax", "(", "torch", ".", "squeeze", "(", "xlocal", "[", "i", "]", ")", ")", ")", "\n", "\n", "\n", "############################################################### regularization", "\n", "\n", "", "logprobs", "=", "logsoftmax", "(", "xglobal", ")", "\n", "entropy_loss", "=", "penalty", "[", "'entropy_weights'", "]", "*", "torch", ".", "mul", "(", "probs", ",", "logprobs", ")", ".", "sum", "(", ")", ".", "div", "(", "inputs", ".", "size", "(", "0", ")", ")", "\n", "soft_loss_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                            ", "soft_loss_list", ".", "append", "(", "torch", ".", "mul", "(", "torch", ".", "neg", "(", "probs", ")", ",", "logprobl", "[", "i", "]", ")", ".", "sum", "(", ")", ".", "div", "(", "inputs", ".", "size", "(", "0", ")", ")", ")", "\n", "", "soft_loss", "=", "penalty", "[", "'soft_weights'", "]", "*", "sum", "(", "soft_loss_list", ")", ".", "div", "(", "nparts", ")", "\n", "\n", "# regularization loss", "\n", "lmgm_reg_loss", "=", "criterion", "[", "1", "]", "(", "xcosin", ")", "\n", "reg_loss", "=", "lmgm_reg_loss", "+", "entropy_loss", "+", "soft_loss", "\n", "\n", "\n", "", "else", ":", "\n", "                        ", "outputs", "=", "model", "(", "inputs", ")", "\n", "probs", "=", "softmax", "(", "outputs", ")", "\n", "cls_loss", "=", "criterion", "[", "0", "]", "(", "outputs", ",", "labels", ")", "\n", "if", "maxent_flag", ":", "\n", "                            ", "logprobs", "=", "logsoftmax", "(", "outputs", ")", "\n", "reg_loss", "=", "torch", ".", "mul", "(", "probs", ",", "logprobs", ")", ".", "sum", "(", ")", ".", "neg", "(", ")", ".", "div", "(", "inputs", ".", "size", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "                            ", "reg_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", "\n", "\n", "\n", "", "", "_", ",", "preds", "=", "torch", ".", "max", "(", "probs", ",", "1", ")", "# the indeices of the largeset value in each row   ", "\n", "\n", "all_loss", "=", "cls_loss", "+", "reg_loss", "\n", "\n", "if", "phase", "==", "'trainval'", ":", "\n", "                        ", "all_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# statistics", "\n", "", "", "running_cls_loss", "+=", "(", "cls_loss", ".", "item", "(", ")", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "running_reg_loss", "+=", "(", "reg_loss", ".", "item", "(", ")", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "running_corrects", "+=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "if", "attention_flag", ":", "\n", "                    ", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                        ", "running_corrects_parts", "[", "i", "]", "+=", "torch", ".", "sum", "(", "predl", "[", "i", "]", "==", "labels", ".", "data", ")", "\n", "\n", "# log variables", "\n", "", "", "global_step", "+=", "1", "\n", "if", "global_step", "%", "100", "==", "1", "and", "writer", "is", "not", "None", "and", "phase", "is", "'trainval'", ":", "\n", "                    ", "batch_loss", "=", "cls_loss", ".", "item", "(", ")", "+", "reg_loss", ".", "item", "(", ")", "\n", "writer", ".", "add_scalar", "(", "'running loss/running_train_loss'", ",", "batch_loss", ",", "global_step", ")", "\n", "writer", ".", "add_scalar", "(", "'running loss/running_cls_loss'", ",", "cls_loss", ",", "global_step", ")", "\n", "if", "attention_flag", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "'running loss/running_lmgm_reg_loss'", ",", "lmgm_reg_loss", ",", "global_step", ")", "\n", "writer", ".", "add_scalar", "(", "'running loss/running_entropy_reg_loss'", ",", "entropy_loss", ",", "global_step", ")", "\n", "writer", ".", "add_scalar", "(", "'running loss/running_soft_reg_loss'", ",", "soft_loss", ",", "global_step", ")", "\n", "", "elif", "maxent_flag", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "'running loss/running_maxent_reg_loss'", ",", "reg_loss", ",", "global_step", ")", "\n", "", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "writer", ".", "add_histogram", "(", "'params_in_running/'", "+", "name", ",", "param", ".", "data", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "global_step", ")", "# global_step", "\n", "\n", "\n", "\n", "############################################### for each epoch", "\n", "\n", "# epoch loss and accuracy", "\n", "", "", "", "epoch_loss", "=", "running_cls_loss", "/", "dataset_sizes", "[", "phase", "]", "\n", "epoch_acc", "=", "running_corrects", ".", "double", "(", ")", "/", "dataset_sizes", "[", "phase", "]", "\n", "if", "attention_flag", ":", "\n", "                ", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                    ", "epoch_acc_parts", "[", "i", "]", "=", "running_corrects_parts", "[", "i", "]", ".", "double", "(", ")", "/", "dataset_sizes", "[", "phase", "]", "\n", "\n", "\n", "# log variables for each epoch", "\n", "", "", "if", "writer", "is", "not", "None", ":", "\n", "                ", "if", "phase", "is", "'trainval'", ":", "\n", "                    ", "writer", ".", "add_scalar", "(", "'epoch loss/train_epoch_loss'", ",", "epoch_loss", ",", "epoch", ")", "# global_step", "\n", "writer", ".", "add_scalar", "(", "'accuracy/train_epoch_acc'", ",", "epoch_acc", ",", "epoch", ")", "# global_step", "\n", "if", "attention_flag", ":", "\n", "                        ", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                            ", "writer", ".", "add_scalar", "(", "'accuracy/train_acc_part{}_acc'", ".", "format", "(", "i", ")", ",", "epoch_acc_parts", "[", "i", "]", ",", "epoch", ")", "\n", "", "", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "writer", ".", "add_histogram", "(", "'params_in_epoch/'", "+", "name", ",", "param", ".", "data", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "epoch", ")", "# global_step", "\n", "", "", "elif", "phase", "is", "'test'", ":", "\n", "                    ", "writer", ".", "add_scalar", "(", "'epoch loss/eval_epoch_loss'", ",", "epoch_loss", ",", "epoch", ")", "# global_step_resume", "\n", "writer", ".", "add_scalar", "(", "'accuracy/eval_epoch_acc'", ",", "epoch_acc", ",", "epoch", ")", "# global_step_resume", "\n", "if", "attention_flag", ":", "\n", "                        ", "for", "i", "in", "range", "(", "nparts", ")", ":", "\n", "                            ", "writer", ".", "add_scalar", "(", "'accuracy/eval_acc_part{}_acc'", ".", "format", "(", "i", ")", ",", "epoch_acc_parts", "[", "i", "]", ",", "epoch", ")", "\n", "\n", "# print to log file", "\n", "", "", "", "", "print", "(", "'{} Loss: {:.4f} Acc: {:.4f}'", ".", "format", "(", "phase", ",", "epoch_loss", ",", "epoch_acc", ")", ",", "file", "=", "output_log_file", ")", "\n", "if", "phase", "==", "'trainval'", ":", "print", "(", "'current lr: {}'", ".", "format", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ",", "file", "=", "output_log_file", ")", "\n", "if", "phase", "==", "'test'", ":", "print", "(", "'\\n'", ",", "file", "=", "output_log_file", ")", "\n", "\n", "# print to terminal", "\n", "print", "(", "'{} Loss: {:.4f} Acc: {:.4f}'", ".", "format", "(", "phase", ",", "epoch_loss", ",", "epoch_acc", ")", ")", "\n", "if", "phase", "==", "'trainval'", ":", "print", "(", "'current lr: {}'", ".", "format", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "# deep copy the model", "\n", "if", "phase", "==", "'test'", "and", "epoch_acc", ">", "best_acc", ":", "\n", "                ", "best_acc", "=", "epoch_acc", "\n", "best_epoch", "=", "epoch", "\n", "best_step", "=", "global_step_resume", "\n", "best_model_params", "=", "copy", ".", "deepcopy", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "if", "phase", "==", "'test'", "and", "epoch", "%", "5", "==", "1", ":", "\n", "                ", "modelserial", ".", "saveCheckpoint", "(", "{", "'epoch'", ":", "epoch", ",", "\n", "'global_step'", ":", "global_step", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_epoch'", ":", "best_epoch", ",", "\n", "'best_state_dict'", ":", "best_model_params", ",", "\n", "'best_acc'", ":", "best_acc", ",", "\n", "'current_lr'", ":", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "}", ",", "datasetname", "+", "'-'", "+", "networkname", ")", "\n", "\n", "# adjust learning rate after each epoch", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "\n", "print", "(", ")", "\n", "\n", "\n", "", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "since", "\n", "print", "(", "'Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ",", "file", "=", "output_log_file", ")", "\n", "print", "(", "'Best test Acc: {:4f}'", ".", "format", "(", "best_acc", ")", ",", "file", "=", "output_log_file", ")", "\n", "print", "(", "'Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ")", "\n", "print", "(", "'Best test Acc: {:4f}'", ".", "format", "(", "best_acc", ")", ")", "\n", "\n", "\n", "# recording training params", "\n", "rsltparams", "=", "dict", "(", ")", "\n", "rsltparams", "[", "'datasetname'", "]", "=", "datasetname", "\n", "rsltparams", "[", "'nparts'", "]", "=", "model", ".", "nparts", "\n", "rsltparams", "[", "'val_acc'", "]", "=", "best_acc", ".", "item", "(", ")", "\n", "rsltparams", "[", "'lmgm'", "]", "=", "criterion", "[", "1", "]", ".", "rho", "\n", "rsltparams", "[", "'lr'", "]", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "rsltparams", "[", "'best_epoch'", "]", "=", "best_epoch", "\n", "rsltparams", "[", "'best_step'", "]", "=", "best_step", "\n", "rsltparams", "[", "'soft_weights'", "]", "=", "penalty", "[", "'soft_weights'", "]", "\n", "rsltparams", "[", "'entropy_weights'", "]", "=", "penalty", "[", "'entropy_weights'", "]", "\n", "\n", "# load best model weights", "\n", "model", ".", "load_state_dict", "(", "best_model_params", ")", "\n", "return", "model", ",", "rsltparams", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.modellearning.eval": [[250, 321], ["model.eval", "len", "dict", "dict", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "print", "dict", "print", "inputs.to.to", "labels.to.to", "softmax", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "good_mask.nonzero", "torch.logical_not.nonzero", "dict.keys", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "good_data.append", "bad_data.append", "torch.div", "torch.div", "torch.div", "torch.div", "len", "dict.setdefault", "model", "model", "running_corrects.double", "label.item", "dict.setdefault", "labels[].item", "labels[].item", "label.item", "label.item", "label.item"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.modellearning.eval"], ["", "def", "eval", "(", "model", ",", "dataloader", "=", "None", ",", "device", "=", "'cpu'", ",", "datasetname", "=", "None", ")", ":", "\n", "\n", "    ", "if", "not", "datasetname", "or", "datasetname", "not", "in", "[", "'cubbirds'", ",", "'stcars'", ",", "'stdogs'", ",", "'vggaircraft'", ",", "'nabirds'", "]", ":", "\n", "        ", "print", "(", "\"illegal dataset\"", ")", "\n", "return", "\n", "\n", "", "attention_flag", "=", "model", ".", "attention", "\n", "model", ".", "eval", "(", ")", "\n", "datasize", "=", "len", "(", "dataloader", ".", "dataset", ")", "\n", "running_corrects", "=", "0", "\n", "good_data", "=", "[", "]", "\n", "bad_data", "=", "[", "]", "\n", "num_label_counts", "=", "dict", "(", ")", "\n", "pred_label_counts", "=", "dict", "(", ")", "\n", "\n", "for", "paths", ",", "inputs", ",", "labels", "in", "dataloader", ":", "\n", "\n", "        ", "if", "datasetname", "==", "'vggaircraft'", ":", "\n", "            ", "for", "label", "in", "labels", ".", "data", ":", "\n", "                ", "num_label_counts", ".", "setdefault", "(", "label", ".", "item", "(", ")", ",", "0", ")", "\n", "num_label_counts", "[", "label", ".", "item", "(", ")", "]", "+=", "1", "\n", "\n", "", "", "inputs", "=", "inputs", ".", "to", "(", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "attention_flag", ":", "\n", "                ", "outputs", ",", "_", ",", "_", ",", "_", "=", "model", "(", "inputs", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs", ")", "\n", "\n", "", "", "probs", "=", "softmax", "(", "outputs", ")", "\n", "_", ",", "preds", "=", "torch", ".", "max", "(", "probs", ",", "1", ")", "\n", "\n", "if", "datasetname", "==", "'vggaircraft'", ":", "\n", "            ", "for", "i", ",", "label", "in", "enumerate", "(", "preds", ".", "data", ")", ":", "\n", "                ", "if", "label", "==", "labels", "[", "i", "]", ":", "\n", "                    ", "pred_label_counts", ".", "setdefault", "(", "label", ".", "item", "(", ")", ",", "0", ")", "\n", "pred_label_counts", "[", "label", ".", "item", "(", ")", "]", "+=", "1", "\n", "\n", "", "", "", "running_corrects", "+=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "\n", "# record paths and labels", "\n", "good_mask", "=", "preds", "==", "labels", ".", "data", "\n", "bad_mask", "=", "torch", ".", "logical_not", "(", "good_mask", ")", "\n", "good_index", "=", "good_mask", ".", "nonzero", "(", ")", "\n", "bad_index", "=", "bad_mask", ".", "nonzero", "(", ")", "\n", "for", "idx", "in", "good_index", ":", "\n", "            ", "good_data", ".", "append", "(", "(", "paths", "[", "idx", "]", ",", "labels", "[", "idx", "]", ".", "item", "(", ")", ")", ")", "\n", "", "for", "idx", "in", "bad_index", ":", "\n", "            ", "bad_data", ".", "append", "(", "(", "paths", "[", "idx", "]", ",", "labels", "[", "idx", "]", ".", "item", "(", ")", ")", ")", "\n", "\n", "\n", "", "", "acc", "=", "torch", ".", "div", "(", "running_corrects", ".", "double", "(", ")", ",", "datasize", ")", ".", "item", "(", ")", "\n", "avg_acc", "=", "0.0", "\n", "print", "(", "\"General Accuracy: {}\"", ".", "format", "(", "acc", ")", ")", "\n", "\n", "if", "datasetname", "==", "'vggaircraft'", ":", "\n", "        ", "running_corrects", "=", "0", "\n", "for", "key", "in", "pred_label_counts", ".", "keys", "(", ")", ":", "\n", "            ", "running_corrects", "+=", "pred_label_counts", "[", "key", "]", "/", "num_label_counts", "[", "key", "]", "\n", "", "avg_acc", "=", "running_corrects", "/", "len", "(", "num_label_counts", ")", "\n", "print", "(", "\"{}: Class Average Accuracy: {}\"", ".", "format", "(", "datasetname", ",", "avg_acc", ")", ")", "\n", "\n", "", "rsltparams", "=", "dict", "(", ")", "\n", "rsltparams", "[", "'acc'", "]", "=", "acc", "\n", "rsltparams", "[", "'avg_acc'", "]", "=", "avg_acc", "\n", "rsltparams", "[", "'good_data'", "]", "=", "good_data", "\n", "rsltparams", "[", "'bad_data'", "]", "=", "bad_data", "\n", "\n", "return", "rsltparams", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.LocalMaxGlobalMin.__init__": [[44, 69], ["torch.Module.__init__", "range", "seps.append"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rho", ",", "nchannels", ",", "nparts", "=", "1", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", "LocalMaxGlobalMin", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nparts", "=", "nparts", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "nchannels", "=", "nchannels", "\n", "self", ".", "rho", "=", "rho", "\n", "\n", "\n", "nlocal_channels_norm", "=", "nchannels", "//", "self", ".", "nparts", "\n", "reminder", "=", "nchannels", "%", "self", ".", "nparts", "\n", "nlocal_channels_last", "=", "nlocal_channels_norm", "\n", "if", "reminder", "!=", "0", ":", "\n", "            ", "nlocal_channels_last", "=", "nlocal_channels_norm", "+", "reminder", "\n", "\n", "# seps records the indices partitioning feature channels into separate parts", "\n", "", "seps", "=", "[", "]", "\n", "sep_node", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "nparts", ")", ":", "\n", "            ", "if", "i", "!=", "self", ".", "nparts", "-", "1", ":", "\n", "                ", "sep_node", "+=", "nlocal_channels_norm", "\n", "#seps.append(sep_node)", "\n", "", "else", ":", "\n", "                ", "sep_node", "+=", "nlocal_channels_last", "\n", "", "seps", ".", "append", "(", "sep_node", ")", "\n", "", "self", ".", "seps", "=", "seps", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.LocalMaxGlobalMin.forward": [[72, 87], ["x.pow.pow.pow", "range", "intra_x.append", "intra_x.append", "inter_x.append", "x[].mean", "sum", "sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "pow", "(", "2", ")", "\n", "intra_x", "=", "[", "]", "\n", "inter_x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nparts", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "intra_x", ".", "append", "(", "(", "1", "-", "x", "[", ":", ",", ":", "self", ".", "seps", "[", "i", "]", ",", ":", "self", ".", "seps", "[", "i", "]", "]", ")", ".", "mean", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "intra_x", ".", "append", "(", "(", "1", "-", "x", "[", ":", ",", "self", ".", "seps", "[", "i", "-", "1", "]", ":", "self", ".", "seps", "[", "i", "]", ",", "self", ".", "seps", "[", "i", "-", "1", "]", ":", "self", ".", "seps", "[", "i", "]", "]", ")", ".", "mean", "(", ")", ")", "\n", "inter_x", ".", "append", "(", "x", "[", ":", ",", "self", ".", "seps", "[", "i", "-", "1", "]", ":", "self", ".", "seps", "[", "i", "]", ",", ":", "self", ".", "seps", "[", "i", "-", "1", "]", "]", ".", "mean", "(", ")", ")", "\n", "\n", "", "", "loss", "=", "self", ".", "rho", "*", "0.5", "*", "(", "sum", "(", "intra_x", ")", "/", "self", ".", "nparts", "+", "sum", "(", "inter_x", ")", "/", "(", "self", ".", "nparts", "*", "(", "self", ".", "nparts", "-", "1", ")", "/", "2", ")", ")", "\n", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.BasicBlock.__init__": [[94, 111], ["torch.Module.__init__", "sef.conv3x3", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "sef.conv3x3", "norm_layer", "ValueError", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv3x3", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", "or", "base_width", "!=", "64", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1 and base_width=64'", ")", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dilation > 1 not supported in BasicBlock\"", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.BasicBlock.forward": [[112, 130], ["sef.BasicBlock.conv1", "sef.BasicBlock.bn1", "sef.BasicBlock.relu", "sef.BasicBlock.conv2", "sef.BasicBlock.bn2", "sef.BasicBlock.relu", "sef.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.Bottleneck.__init__": [[135, 151], ["torch.Module.__init__", "sef.conv1x1", "norm_layer", "sef.conv3x3", "norm_layer", "sef.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv1x1", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv3x3", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "groups", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.Bottleneck.forward": [[152, 173], ["sef.Bottleneck.conv1", "sef.Bottleneck.bn1", "sef.Bottleneck.relu", "sef.Bottleneck.conv2", "sef.Bottleneck.bn2", "sef.Bottleneck.relu", "sef.Bottleneck.conv3", "sef.Bottleneck.bn3", "sef.Bottleneck.relu", "sef.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet.__init__": [[177, 253], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "sef.ResNet._make_layer", "sef.ResNet._make_layer", "sef.ResNet._make_layer", "sef.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "sef.ResNet.modules", "len", "ValueError", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "isinstance", "sef.ResNet.modules", "separations.append", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "fc_list.append", "fc_list.append", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet._make_layer", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet._make_layer", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet._make_layer", "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "nparts", "=", "0", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ",", "attention", "=", "False", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attention", "=", "attention", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "nparts", "=", "nparts", "\n", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "attention", ":", "\n", "            ", "nfeatures", "=", "512", "*", "block", ".", "expansion", "\n", "nlocal_channels_norm", "=", "nfeatures", "//", "self", ".", "nparts", "\n", "reminder", "=", "nfeatures", "%", "self", ".", "nparts", "\n", "nlocal_channels_last", "=", "nlocal_channels_norm", "\n", "if", "reminder", "!=", "0", ":", "\n", "                ", "nlocal_channels_last", "=", "nlocal_channels_norm", "+", "reminder", "\n", "", "fc_list", "=", "[", "]", "\n", "separations", "=", "[", "]", "\n", "sep_node", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "nparts", ")", ":", "\n", "                ", "if", "i", "!=", "self", ".", "nparts", "-", "1", ":", "\n", "                    ", "sep_node", "+=", "nlocal_channels_norm", "\n", "fc_list", ".", "append", "(", "nn", ".", "Linear", "(", "nlocal_channels_norm", ",", "num_classes", ")", ")", "\n", "#separations.append(sep_node)", "\n", "", "else", ":", "\n", "                    ", "sep_node", "+=", "nlocal_channels_last", "\n", "fc_list", ".", "append", "(", "nn", ".", "Linear", "(", "nlocal_channels_last", ",", "num_classes", ")", ")", "\n", "", "separations", ".", "append", "(", "sep_node", ")", "\n", "", "self", ".", "fclocal", "=", "nn", ".", "Sequential", "(", "*", "fc_list", ")", "\n", "self", ".", "separations", "=", "separations", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet._make_layer": [[254, 277], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "sef.conv1x1", "norm_layer", "block"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv1x1"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilate", "=", "False", ")", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.ResNet.forward": [[278, 324], ["sef.ResNet.conv1", "sef.ResNet.bn1", "sef.ResNet.relu", "sef.ResNet.maxpool", "sef.ResNet.layer1", "sef.ResNet.layer2", "sef.ResNet.layer3", "sef.ResNet.layer4", "sef.ResNet.view", "sef.ResNet.view.div", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "sef.ResNet.clone().detach", "sef.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "sef.ResNet.fc", "sef.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "sef.ResNet.fc", "x.view.div.transpose", "sef.ResNet.avgpool().flatten", "attention_scores.append", "sef.ResNet.view.norm", "sef.ResNet.clone", "sef.ResNet.avgpool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "if", "self", ".", "attention", ":", "\n", "\n", "            ", "nsamples", ",", "nchannels", ",", "height", ",", "width", "=", "x", ".", "shape", "\n", "\n", "xview", "=", "x", ".", "view", "(", "nsamples", ",", "nchannels", ",", "-", "1", ")", "\n", "xnorm", "=", "xview", ".", "div", "(", "xview", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "+", "eps", ")", "\n", "xcosin", "=", "torch", ".", "bmm", "(", "xnorm", ",", "xnorm", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "\n", "attention_scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nparts", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "xx", "=", "x", "[", ":", ",", ":", "self", ".", "separations", "[", "i", "]", "]", "\n", "", "else", ":", "\n", "                    ", "xx", "=", "x", "[", ":", ",", "self", ".", "separations", "[", "i", "-", "1", "]", ":", "self", ".", "separations", "[", "i", "]", "]", "\n", "", "xx_pool", "=", "self", ".", "avgpool", "(", "xx", ")", ".", "flatten", "(", "1", ")", "\n", "attention_scores", ".", "append", "(", "self", ".", "fclocal", "[", "i", "]", "(", "xx_pool", ")", ")", "\n", "", "xlocal", "=", "torch", ".", "stack", "(", "attention_scores", ",", "dim", "=", "0", ")", "\n", "\n", "xmaps", "=", "x", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# for global", "\n", "xpool", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "xpool", "=", "torch", ".", "flatten", "(", "xpool", ",", "1", ")", "\n", "xglobal", "=", "self", ".", "fc", "(", "xpool", ")", "\n", "\n", "\n", "return", "xglobal", ",", "xlocal", ",", "xcosin", ",", "xmaps", "\n", "", "else", ":", "\n", "# for original resnet outputs", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv3x3": [[30, 34], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.conv1x1": [[36, 39], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet": [[327, 335], ["sef.ResNet", "ResNet.load_state_dict", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "", "def", "_resnet", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "model_dir", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "ResNet", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "arch", "]", ",", "model_dir", "=", "model_dir", ")", ")", "\n", "# state_dict = load_state_dict_from_url(model_urls[arch],", "\n", "#                                       progress=progress)", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnet18": [[337, 347], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnet18", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "model_dir", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet18'", ",", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pretrained", ",", "progress", ",", "model_dir", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnet34": [[349, 359], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet34'", ",", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnet50": [[361, 371], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "model_dir", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet50'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "model_dir", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnet101": [[373, 383], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet101'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnet152": [[385, 395], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnext50_32x4d": [[397, 409], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnext50_32x4d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "4", "\n", "return", "_resnet", "(", "'resnext50_32x4d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.resnext101_32x8d": [[411, 423], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "resnext101_32x8d", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.wide_resnet50_2": [[425, 441], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "wide_resnet50_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet50_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.None.sef.wide_resnet101_2": [[443, 459], ["sef._resnet"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.None.sef._resnet"], ["", "def", "wide_resnet101_2", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet101_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Dataset.__getitem__": [[24, 26], ["None"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Dataset.__len__": [[8, 9], ["None"], "methods", ["None"], ["class", "Dataset", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Dataset.__add__": [[27, 29], ["dataset.ConcatDataset"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "ConcatDataset", "(", "[", "self", ",", "other", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.IterableDataset.__iter__": [[138, 140], ["None"], "methods", ["None"], ["def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.TensorDataset.__init__": [[157, 160], ["all", "tensors[].size", "tensor.size"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "tensors", ")", ":", "\n", "        ", "assert", "all", "(", "tensors", "[", "0", "]", ".", "size", "(", "0", ")", "==", "tensor", ".", "size", "(", "0", ")", "for", "tensor", "in", "tensors", ")", "\n", "self", ".", "tensors", "=", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.__init__": [[186, 193], ["object.__init__", "list", "dataset.ConcatDataset.cumsum", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.cumsum"], ["", "def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "super", "(", "ConcatDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "datasets", ")", ">", "0", ",", "'datasets should not be an empty iterable'", "\n", "self", ".", "datasets", "=", "list", "(", "datasets", ")", "\n", "for", "d", "in", "self", ".", "datasets", ":", "\n", "            ", "assert", "not", "isinstance", "(", "d", ",", "IterableDataset", ")", ",", "\"ConcatDataset does not support IterableDataset\"", "\n", "", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Subset.__init__": [[252, 255], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "indices", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.random_split": [[263, 276], ["torch.randperm().tolist", "sum", "len", "ValueError", "dataset.Subset", "torch.randperm", "zip", "sum", "torch._utils._accumulate"], "function", ["None"], ["", "", "def", "random_split", "(", "dataset", ",", "lengths", ")", ":", "\n", "    ", "r\"\"\"\n    Randomly split a dataset into non-overlapping new datasets of given lengths.\n\n    Arguments:\n        dataset (Dataset): Dataset to be split\n        lengths (sequence): lengths of splits to be produced\n    \"\"\"", "\n", "if", "sum", "(", "lengths", ")", "!=", "len", "(", "dataset", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Sum of input lengths does not equal the length of the input dataset!\"", ")", "\n", "\n", "", "indices", "=", "randperm", "(", "sum", "(", "lengths", ")", ")", ".", "tolist", "(", ")", "\n", "return", "[", "Subset", "(", "dataset", ",", "indices", "[", "offset", "-", "length", ":", "offset", "]", ")", "for", "offset", ",", "length", "in", "zip", "(", "_accumulate", "(", "lengths", ")", ",", "lengths", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.Sampler.__init__": [[17, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.Sampler.__iter__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.Sampler.__len__": [[8, 9], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.RandomSampler.__init__": [[79, 95], ["isinstance", "ValueError", "ValueError", "ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "replacement", "=", "False", ",", "num_samples", "=", "None", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "replacement", "=", "replacement", "\n", "self", ".", "_num_samples", "=", "num_samples", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "replacement", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"replacement should be a boolean value, but got \"", "\n", "\"replacement={}\"", ".", "format", "(", "self", ".", "replacement", ")", ")", "\n", "\n", "", "if", "self", ".", "_num_samples", "is", "not", "None", "and", "not", "replacement", ":", "\n", "            ", "raise", "ValueError", "(", "\"With replacement=False, num_samples should not be specified, \"", "\n", "\"since a random permute will be performed.\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "num_samples", ",", "int", ")", "or", "self", ".", "num_samples", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integer \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "self", ".", "num_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SubsetRandomSampler.__init__": [[120, 122], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.WeightedRandomSampler.__init__": [[147, 158], ["torch.as_tensor", "isinstance", "ValueError", "isinstance", "ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "weights", ",", "num_samples", ",", "replacement", "=", "True", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "num_samples", ",", "_int_classes", ")", "or", "isinstance", "(", "num_samples", ",", "bool", ")", "or", "num_samples", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integer \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "num_samples", ")", ")", "\n", "", "if", "not", "isinstance", "(", "replacement", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"replacement should be a boolean value, but got \"", "\n", "\"replacement={}\"", ".", "format", "(", "replacement", ")", ")", "\n", "", "self", ".", "weights", "=", "torch", ".", "as_tensor", "(", "weights", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "self", ".", "replacement", "=", "replacement", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.BatchSampler.__init__": [[182, 197], ["isinstance", "ValueError", "isinstance", "ValueError", "isinstance", "ValueError", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ",", "batch_size", ",", "drop_last", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "sampler", ",", "Sampler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"sampler should be an instance of \"", "\n", "\"torch.utils.data.Sampler, but got sampler={}\"", "\n", ".", "format", "(", "sampler", ")", ")", "\n", "", "if", "not", "isinstance", "(", "batch_size", ",", "_int_classes", ")", "or", "isinstance", "(", "batch_size", ",", "bool", ")", "or", "batch_size", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size should be a positive integer value, \"", "\n", "\"but got batch_size={}\"", ".", "format", "(", "batch_size", ")", ")", "\n", "", "if", "not", "isinstance", "(", "drop_last", ",", "bool", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"drop_last should be a boolean value, but got \"", "\n", "\"drop_last={}\"", ".", "format", "(", "drop_last", ")", ")", "\n", "", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.distributed.DistributedSampler.__init__": [[6, 7], ["None"], "methods", ["None"], ["\n", "class", "DistributedSampler", "(", "Sampler", ")", ":", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.distributed.DistributedSampler.__iter__": [[7, 8], ["None"], "methods", ["None"], ["class", "DistributedSampler", "(", "Sampler", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.distributed.DistributedSampler.__len__": [[8, 9], ["None"], "methods", ["None"], ["    "]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.distributed.DistributedSampler.set_epoch": [[9, 10], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.cswluo_SEF.utils.modelserial.saveCheckpoint": [[4, 12], ["print", "torch.save", "filename.format"], "function", ["None"], ["def", "saveCheckpoint", "(", "state", ",", "datasetname", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save checkpoint if a new best is achieved\"\"\"", "\n", "\n", "filename", "=", "'./ckpt/{}-checkpoint.pth.tar'", "\n", "\n", "# if is_best:", "\n", "print", "(", "\"=> Saving a new best\"", ")", "\n", "torch", ".", "save", "(", "state", ",", "filename", ".", "format", "(", "datasetname", ")", ")", "# save checkpoint", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.modelserial.loadCheckpoint": [[15, 19], ["torch.load", "filename.format"], "function", ["None"], ["", "def", "loadCheckpoint", "(", "datasetname", ")", ":", "\n", "    ", "filename", "=", "'./ckpt/{}-checkpoint.pth.tar'", "\n", "checkpoint", "=", "torch", ".", "load", "(", "filename", ".", "format", "(", "datasetname", ")", ",", "map_location", "=", "device", ")", "\n", "return", "checkpoint", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._DatasetKind.create_fetcher": [[36, 42], ["_utils.fetch._MapDatasetFetcher", "_utils.fetch._IterableDatasetFetcher"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "create_fetcher", "(", "kind", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", ":", "\n", "        ", "if", "kind", "==", "_DatasetKind", ".", "Map", ":", "\n", "            ", "return", "_utils", ".", "fetch", ".", "_MapDatasetFetcher", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "", "else", ":", "\n", "            ", "return", "_utils", ".", "fetch", ".", "_IterableDatasetFetcher", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._InfiniteConstantSampler.__init__": [[52, 54], ["Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "_InfiniteConstantSampler", ",", "self", ")", ".", "__init__", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._InfiniteConstantSampler.__iter__": [[55, 58], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader.__init__": [[120, 235], ["torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "isinstance", "ValueError", "ValueError", "ValueError", "BatchSampler", "ValueError", "ValueError", "mydataloader._InfiniteConstantSampler", "ValueError", "ValueError", "RandomSampler", "SequentialSampler", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "sampler", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "num_workers", "=", "0", ",", "collate_fn", "=", "None", ",", "\n", "pin_memory", "=", "False", ",", "drop_last", "=", "False", ",", "timeout", "=", "0", ",", "\n", "worker_init_fn", "=", "None", ",", "multiprocessing_context", "=", "None", ")", ":", "\n", "        ", "torch", ".", "_C", ".", "_log_api_usage_once", "(", "\"python.data_loader\"", ")", "\n", "\n", "if", "num_workers", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'num_workers option should be non-negative; '", "\n", "'use num_workers=0 to disable multiprocessing.'", ")", "\n", "\n", "", "if", "timeout", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'timeout option should be non-negative'", ")", "\n", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "pin_memory", "=", "pin_memory", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "worker_init_fn", "=", "worker_init_fn", "\n", "self", ".", "multiprocessing_context", "=", "multiprocessing_context", "\n", "\n", "# Arg-check dataset related before checking samplers because we want to", "\n", "# tell users that iterable-style datasets are incompatible with custom", "\n", "# samplers first, so that they don't learn that this combo doesn't work", "\n", "# after spending time fixing the custom sampler errors.", "\n", "if", "isinstance", "(", "dataset", ",", "IterableDataset", ")", ":", "\n", "            ", "self", ".", "_dataset_kind", "=", "_DatasetKind", ".", "Iterable", "\n", "# NOTE [ Custom Samplers and `IterableDataset` ]", "\n", "#", "\n", "# `IterableDataset` does not support custom `batch_sampler` or", "\n", "# `sampler` since the key is irrelevant (unless we support", "\n", "# generator-style dataset one day...).", "\n", "#", "\n", "# For `sampler`, we always create a dummy sampler. This is an", "\n", "# infinite sampler even when the dataset may have an implemented", "\n", "# finite `__len__` because in multi-process data loading, naive", "\n", "# settings will return duplicated data (which may be desired), and", "\n", "# thus using a sampler with length matching that of dataset will", "\n", "# cause data lost (you may have duplicates of the first couple", "\n", "# batches, but never see anything afterwards). Therefore,", "\n", "# `Iterabledataset` always uses an infinite sampler, an instance of", "\n", "# `_InfiniteConstantSampler` defined above.", "\n", "#", "\n", "# A custom `batch_sampler` essentially only controls the batch size.", "\n", "# However, it is unclear how useful it would be since an iterable-style", "\n", "# dataset can handle that within itself. Moreover, it is pointless", "\n", "# in multi-process data loading as the assignment order of batches", "\n", "# to workers is an implementation detail so users can not control", "\n", "# how to batchify each worker's iterable. Thus, we disable this", "\n", "# option. If this turns out to be useful in future, we can re-enable", "\n", "# this, and support custom samplers that specify the assignments to", "\n", "# specific workers.", "\n", "if", "shuffle", "is", "not", "False", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"shuffle option, but got shuffle={}\"", ".", "format", "(", "shuffle", ")", ")", "\n", "", "elif", "sampler", "is", "not", "None", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"sampler option, but got sampler={}\"", ".", "format", "(", "sampler", ")", ")", "\n", "", "elif", "batch_sampler", "is", "not", "None", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"batch_sampler option, but got batch_sampler={}\"", ".", "format", "(", "batch_sampler", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_dataset_kind", "=", "_DatasetKind", ".", "Map", "\n", "\n", "", "if", "sampler", "is", "not", "None", "and", "shuffle", ":", "\n", "            ", "raise", "ValueError", "(", "'sampler option is mutually exclusive with '", "\n", "'shuffle'", ")", "\n", "\n", "", "if", "batch_sampler", "is", "not", "None", ":", "\n", "# auto_collation with custom batch_sampler", "\n", "            ", "if", "batch_size", "!=", "1", "or", "shuffle", "or", "sampler", "is", "not", "None", "or", "drop_last", ":", "\n", "                ", "raise", "ValueError", "(", "'batch_sampler option is mutually exclusive '", "\n", "'with batch_size, shuffle, sampler, and '", "\n", "'drop_last'", ")", "\n", "", "batch_size", "=", "None", "\n", "drop_last", "=", "False", "\n", "", "elif", "batch_size", "is", "None", ":", "\n", "# no auto_collation", "\n", "            ", "if", "shuffle", "or", "drop_last", ":", "\n", "                ", "raise", "ValueError", "(", "'batch_size=None option disables auto-batching '", "\n", "'and is mutually exclusive with '", "\n", "'shuffle, and drop_last'", ")", "\n", "\n", "", "", "if", "sampler", "is", "None", ":", "# give default samplers", "\n", "            ", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "sampler", "=", "_InfiniteConstantSampler", "(", ")", "\n", "", "else", ":", "# map-style", "\n", "                ", "if", "shuffle", ":", "\n", "                    ", "sampler", "=", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "                    ", "sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "\n", "", "", "", "if", "batch_size", "is", "not", "None", "and", "batch_sampler", "is", "None", ":", "\n", "# auto_collation without custom batch_sampler", "\n", "            ", "batch_sampler", "=", "BatchSampler", "(", "sampler", ",", "batch_size", ",", "drop_last", ")", "\n", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "\n", "if", "collate_fn", "is", "None", ":", "\n", "            ", "if", "self", ".", "_auto_collation", ":", "\n", "                ", "collate_fn", "=", "_utils", ".", "collate", ".", "default_collate", "\n", "", "else", ":", "\n", "                ", "collate_fn", "=", "_utils", ".", "collate", ".", "default_convert", "\n", "\n", "", "", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "__initialized", "=", "True", "\n", "self", ".", "_IterableDataset_len_called", "=", "None", "# See NOTE [ IterableDataset and __len__ ]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader.multiprocessing_context": [[240, 267], ["isinstance", "ValueError", "ValueError", "multiprocessing.get_all_start_methods", "torch.get_all_start_methods", "torch.get_all_start_methods", "torch.get_all_start_methods", "multiprocessing.get_context", "torch.get_context", "torch.get_context", "torch.get_context", "isinstance", "ValueError", "ValueError"], "methods", ["None"], ["", "@", "multiprocessing_context", ".", "setter", "\n", "def", "multiprocessing_context", "(", "self", ",", "multiprocessing_context", ")", ":", "\n", "        ", "if", "multiprocessing_context", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "                ", "if", "not", "multiprocessing", ".", "_supports_context", ":", "\n", "                    ", "raise", "ValueError", "(", "'multiprocessing_context relies on Python >= 3.4, with '", "\n", "'support for different start methods'", ")", "\n", "\n", "", "if", "isinstance", "(", "multiprocessing_context", ",", "string_classes", ")", ":", "\n", "                    ", "valid_start_methods", "=", "multiprocessing", ".", "get_all_start_methods", "(", ")", "\n", "if", "multiprocessing_context", "not", "in", "valid_start_methods", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "(", "'multiprocessing_context option '", "\n", "'should specify a valid start method in {}, but got '", "\n", "'multiprocessing_context={}'", ")", ".", "format", "(", "valid_start_methods", ",", "multiprocessing_context", ")", ")", "\n", "", "multiprocessing_context", "=", "multiprocessing", ".", "get_context", "(", "multiprocessing_context", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "multiprocessing_context", ",", "python_multiprocessing", ".", "context", ".", "BaseContext", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "(", "'multiprocessing_context option should be a valid context '", "\n", "'object or a string specifying the start method, but got '", "\n", "'multiprocessing_context={}'", ")", ".", "format", "(", "multiprocessing_context", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "(", "'multiprocessing_context can only be used with '", "\n", "'multi-process loading (num_workers > 0), but got '", "\n", "'num_workers={}'", ")", ".", "format", "(", "self", ".", "num_workers", ")", ")", "\n", "\n", "", "", "self", ".", "__multiprocessing_context", "=", "multiprocessing_context", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader.__setattr__": [[268, 274], ["object.__setattr__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.WorkerInfo.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "attr", ",", "val", ")", ":", "\n", "        ", "if", "self", ".", "__initialized", "and", "attr", "in", "(", "'batch_size'", ",", "'batch_sampler'", ",", "'sampler'", ",", "'drop_last'", ",", "'dataset'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'{} attribute should not be set after {} is '", "\n", "'initialized'", ".", "format", "(", "attr", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "\n", "", "super", "(", "DataLoader", ",", "self", ")", ".", "__setattr__", "(", "attr", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader.__iter__": [[275, 280], ["mydataloader._SingleProcessDataLoaderIter", "mydataloader._MultiProcessingDataLoaderIter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_workers", "==", "0", ":", "\n", "            ", "return", "_SingleProcessDataLoaderIter", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "_MultiProcessingDataLoaderIter", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader._auto_collation": [[281, 284], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "_auto_collation", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_sampler", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader._index_sampler": [[285, 296], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_index_sampler", "(", "self", ")", ":", "\n", "# The actual sampler used for generating indices for `_DatasetFetcher`", "\n", "# (see _utils/fetch.py) to read data at each time. This would be", "\n", "# `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise.", "\n", "# We can't change `.sampler` and `.batch_sampler` attributes for BC", "\n", "# reasons.", "\n", "        ", "if", "self", ".", "_auto_collation", ":", "\n", "            ", "return", "self", ".", "batch_sampler", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader.DataLoader.__len__": [[297, 317], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# NOTE [ IterableDataset and __len__ ]", "\n", "#", "\n", "# For `IterableDataset`, `__len__` could be inaccurate when one naively", "\n", "# does multi-processing data loading, since the samples will be duplicated.", "\n", "# However, no real use case should be actually using that behavior, so", "\n", "# it should count as a user error. We should generally trust user", "\n", "# code to do the proper thing (e.g., configure each replica differently", "\n", "# in `__iter__`), and give us the correct `__len__` if they choose to", "\n", "# implement it (this will still throw if the dataset does not implement", "\n", "# a `__len__`).", "\n", "#", "\n", "# To provide a further warning, we track if `__len__` was called on the", "\n", "# `DataLoader`, save the returned value in `self._len_called`, and warn", "\n", "# if the iterator ends up yielding more than this number of samples.", "\n", "            ", "length", "=", "self", ".", "_IterableDataset_len_called", "=", "len", "(", "self", ".", "dataset", ")", "\n", "return", "length", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_index_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter.__init__": [[320, 334], ["iter", "torch.empty().random_().item", "torch.empty().random_().item", "torch.empty().random_().item", "torch.empty().random_().item", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.empty().random_", "torch.empty().random_", "torch.empty().random_", "torch.empty().random_", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "loader", ".", "dataset", "\n", "self", ".", "_dataset_kind", "=", "loader", ".", "_dataset_kind", "\n", "self", ".", "_IterableDataset_len_called", "=", "loader", ".", "_IterableDataset_len_called", "\n", "self", ".", "_auto_collation", "=", "loader", ".", "_auto_collation", "\n", "self", ".", "_drop_last", "=", "loader", ".", "drop_last", "\n", "self", ".", "_index_sampler", "=", "loader", ".", "_index_sampler", "\n", "self", ".", "_num_workers", "=", "loader", ".", "num_workers", "\n", "self", ".", "_pin_memory", "=", "loader", ".", "pin_memory", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "self", ".", "_timeout", "=", "loader", ".", "timeout", "\n", "self", ".", "_collate_fn", "=", "loader", ".", "collate_fn", "\n", "self", ".", "_sampler_iter", "=", "iter", "(", "self", ".", "_index_sampler", ")", "\n", "self", ".", "_base_seed", "=", "torch", ".", "empty", "(", "(", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "random_", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_num_yielded", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter.__iter__": [[335, 337], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter._next_index": [[338, 340], ["next"], "methods", ["None"], ["", "def", "_next_index", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "_sampler_iter", ")", "# may raise StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter._next_data": [[341, 343], ["None"], "methods", ["None"], ["", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter.__next__": [[344, 359], ["mydataloader._BaseDataLoaderIter._next_data", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._next_data"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "_next_data", "(", ")", "\n", "self", ".", "_num_yielded", "+=", "1", "\n", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", "and", "self", ".", "_IterableDataset_len_called", "is", "not", "None", "and", "self", ".", "_num_yielded", ">", "self", ".", "_IterableDataset_len_called", ":", "\n", "            ", "warn_msg", "=", "(", "\"Length of IterableDataset {} was reported to be {} (when accessing len(dataloader)), but {} \"", "\n", "\"samples have been fetched. \"", ")", ".", "format", "(", "self", ".", "_dataset", ",", "self", ".", "_IterableDataset_len_called", ",", "\n", "self", ".", "_num_yielded", ")", "\n", "if", "self", ".", "_num_workers", ">", "0", ":", "\n", "                ", "warn_msg", "+=", "(", "\"For multiprocessing data-loading, this could be caused by not properly configuring the \"", "\n", "\"IterableDataset replica at each worker. Please see \"", "\n", "\"https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\"", ")", "\n", "", "warnings", ".", "warn", "(", "warn_msg", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter.__len__": [[362, 364], ["len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_index_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._BaseDataLoaderIter.__getstate__": [[365, 372], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "# TODO: add limited pickling support for sharing an iterator", "\n", "# across multiple threads for HOGWILD.", "\n", "# Probably the best way to do this is by moving the sample pushing", "\n", "# to a separate thread and then just sharing the data queue", "\n", "# but signalling the end is tricky without a non-blocking API", "\n", "        ", "raise", "NotImplementedError", "(", "\"{} cannot be pickled\"", ",", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._SingleProcessDataLoaderIter.__init__": [[375, 382], ["mydataloader._BaseDataLoaderIter.__init__", "mydataloader._DatasetKind.create_fetcher"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._DatasetKind.create_fetcher"], ["    ", "def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "super", "(", "_SingleProcessDataLoaderIter", ",", "self", ")", ".", "__init__", "(", "loader", ")", "\n", "assert", "self", ".", "_timeout", "==", "0", "\n", "assert", "self", ".", "_num_workers", "==", "0", "\n", "\n", "self", ".", "_dataset_fetcher", "=", "_DatasetKind", ".", "create_fetcher", "(", "\n", "self", ".", "_dataset_kind", ",", "self", ".", "_dataset", ",", "self", ".", "_auto_collation", ",", "self", ".", "_collate_fn", ",", "self", ".", "_drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._SingleProcessDataLoaderIter._next_data": [[383, 389], ["mydataloader._SingleProcessDataLoaderIter._next_index", "mydataloader._SingleProcessDataLoaderIter._dataset_fetcher.fetch", "_utils.pin_memory.pin_memory"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_index", "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.fetch", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory"], ["", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "index", "=", "self", ".", "_next_index", "(", ")", "# may raise StopIteration", "\n", "data", "=", "self", ".", "_dataset_fetcher", ".", "fetch", "(", "index", ")", "# may raise StopIteration", "\n", "if", "self", ".", "_pin_memory", ":", "\n", "            ", "data", "=", "_utils", ".", "pin_memory", ".", "pin_memory", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter.__init__": [[672, 747], ["mydataloader._BaseDataLoaderIter.__init__", "itertools.cycle", "multiprocessing_context.Queue", "multiprocessing_context.Event", "range", "_utils.signal_handling._set_worker_pids", "_utils.signal_handling._set_SIGCHLD_handler", "range", "range", "multiprocessing_context.Queue", "multiprocessing_context.Process", "multiprocessing_context.Process.start", "mydataloader._MultiProcessingDataLoaderIter._index_queues.append", "mydataloader._MultiProcessingDataLoaderIter._workers.append", "mydataloader._MultiProcessingDataLoaderIter._workers_status.append", "threading.Event", "torch._six.queue.Queue", "torch._six.queue.Queue", "threading.Thread", "threading.Thread.start", "id", "tuple", "mydataloader._MultiProcessingDataLoaderIter._try_put_index", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF._utils.signal_handling._set_SIGCHLD_handler", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "super", "(", "_MultiProcessingDataLoaderIter", ",", "self", ")", ".", "__init__", "(", "loader", ")", "\n", "\n", "assert", "self", ".", "_num_workers", ">", "0", "\n", "\n", "if", "loader", ".", "multiprocessing_context", "is", "None", ":", "\n", "            ", "multiprocessing_context", "=", "multiprocessing", "\n", "", "else", ":", "\n", "            ", "multiprocessing_context", "=", "loader", ".", "multiprocessing_context", "\n", "\n", "", "self", ".", "_worker_init_fn", "=", "loader", ".", "worker_init_fn", "\n", "self", ".", "_worker_queue_idx_cycle", "=", "itertools", ".", "cycle", "(", "range", "(", "self", ".", "_num_workers", ")", ")", "\n", "self", ".", "_worker_result_queue", "=", "multiprocessing_context", ".", "Queue", "(", ")", "\n", "self", ".", "_worker_pids_set", "=", "False", "\n", "self", ".", "_shutdown", "=", "False", "\n", "self", ".", "_send_idx", "=", "0", "# idx of the next task to be sent to workers", "\n", "self", ".", "_rcvd_idx", "=", "0", "# idx of the next task to be returned in __next__", "\n", "# information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).", "\n", "# map: task idx => - (worker_id,)        if data isn't fetched (outstanding)", "\n", "#                  \\ (worker_id, data)   if data is already fetched (out-of-order)", "\n", "self", ".", "_task_info", "=", "{", "}", "\n", "self", ".", "_tasks_outstanding", "=", "0", "# always equal to count(v for v in task_info.values() if len(v) == 1)", "\n", "self", ".", "_workers_done_event", "=", "multiprocessing_context", ".", "Event", "(", ")", "\n", "\n", "self", ".", "_index_queues", "=", "[", "]", "\n", "self", ".", "_workers", "=", "[", "]", "\n", "# A list of booleans representing whether each worker still has work to", "\n", "# do, i.e., not having exhausted its iterable dataset object. It always", "\n", "# contains all `True`s if not using an iterable-style dataset", "\n", "# (i.e., if kind != Iterable).", "\n", "self", ".", "_workers_status", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_workers", ")", ":", "\n", "            ", "index_queue", "=", "multiprocessing_context", ".", "Queue", "(", ")", "\n", "# index_queue.cancel_join_thread()", "\n", "w", "=", "multiprocessing_context", ".", "Process", "(", "\n", "target", "=", "_utils", ".", "worker", ".", "_worker_loop", ",", "\n", "args", "=", "(", "self", ".", "_dataset_kind", ",", "self", ".", "_dataset", ",", "index_queue", ",", "\n", "self", ".", "_worker_result_queue", ",", "self", ".", "_workers_done_event", ",", "\n", "self", ".", "_auto_collation", ",", "self", ".", "_collate_fn", ",", "self", ".", "_drop_last", ",", "\n", "self", ".", "_base_seed", "+", "i", ",", "self", ".", "_worker_init_fn", ",", "i", ",", "self", ".", "_num_workers", ")", ")", "\n", "w", ".", "daemon", "=", "True", "\n", "# NB: Process.start() actually take some time as it needs to", "\n", "#     start a process and pass the arguments over via a pipe.", "\n", "#     Therefore, we only add a worker to self._workers list after", "\n", "#     it started, so that we do not call .join() if program dies", "\n", "#     before it starts, and __del__ tries to join but will get:", "\n", "#     AssertionError: can only join a started process.", "\n", "w", ".", "start", "(", ")", "\n", "self", ".", "_index_queues", ".", "append", "(", "index_queue", ")", "\n", "self", ".", "_workers", ".", "append", "(", "w", ")", "\n", "self", ".", "_workers_status", ".", "append", "(", "True", ")", "\n", "\n", "", "if", "self", ".", "_pin_memory", ":", "\n", "            ", "self", ".", "_pin_memory_thread_done_event", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "_data_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "pin_memory_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "_utils", ".", "pin_memory", ".", "_pin_memory_loop", ",", "\n", "args", "=", "(", "self", ".", "_worker_result_queue", ",", "self", ".", "_data_queue", ",", "\n", "torch", ".", "cuda", ".", "current_device", "(", ")", ",", "\n", "self", ".", "_pin_memory_thread_done_event", ")", ")", "\n", "pin_memory_thread", ".", "daemon", "=", "True", "\n", "pin_memory_thread", ".", "start", "(", ")", "\n", "# Similar to workers (see comment above), we only register", "\n", "# pin_memory_thread once it is started.", "\n", "self", ".", "_pin_memory_thread", "=", "pin_memory_thread", "\n", "", "else", ":", "\n", "            ", "self", ".", "_data_queue", "=", "self", ".", "_worker_result_queue", "\n", "\n", "", "_utils", ".", "signal_handling", ".", "_set_worker_pids", "(", "id", "(", "self", ")", ",", "tuple", "(", "w", ".", "pid", "for", "w", "in", "self", ".", "_workers", ")", ")", "\n", "_utils", ".", "signal_handling", ".", "_set_SIGCHLD_handler", "(", ")", "\n", "self", ".", "_worker_pids_set", "=", "True", "\n", "\n", "# prime the prefetch loop", "\n", "for", "_", "in", "range", "(", "2", "*", "self", ".", "_num_workers", ")", ":", "\n", "            ", "self", ".", "_try_put_index", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._try_get_data": [[748, 778], ["mydataloader._MultiProcessingDataLoaderIter._data_queue.get", "enumerate", "isinstance", "len", "RuntimeError", "failed_workers.append", "mydataloader._MultiProcessingDataLoaderIter._shutdown_worker", "w.is_alive", "str"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker"], ["", "", "def", "_try_get_data", "(", "self", ",", "timeout", "=", "_utils", ".", "MP_STATUS_CHECK_INTERVAL", ")", ":", "\n", "# Tries to fetch data from `self._data_queue` once for a given timeout.", "\n", "# This can also be used as inner loop of fetching without timeout, with", "\n", "# the sender status as the loop condition.", "\n", "#", "\n", "# This raises a `RuntimeError` if any worker died expectedly. This error", "\n", "# can come from either the SIGCHLD handler in `_utils/signal_handling.py`", "\n", "# (only for non-Windows platforms), or the manual check below on errors", "\n", "# and timeouts.", "\n", "#", "\n", "# Returns a 2-tuple:", "\n", "#   (bool: whether successfully get data, any: data if successful else None)", "\n", "        ", "try", ":", "\n", "            ", "data", "=", "self", ".", "_data_queue", ".", "get", "(", "timeout", "=", "timeout", ")", "\n", "return", "(", "True", ",", "data", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# At timeout and error, we manually check whether any worker has", "\n", "# failed. Note that this is the only mechanism for Windows to detect", "\n", "# worker failures.", "\n", "            ", "failed_workers", "=", "[", "]", "\n", "for", "worker_id", ",", "w", "in", "enumerate", "(", "self", ".", "_workers", ")", ":", "\n", "                ", "if", "self", ".", "_workers_status", "[", "worker_id", "]", "and", "not", "w", ".", "is_alive", "(", ")", ":", "\n", "                    ", "failed_workers", ".", "append", "(", "w", ")", "\n", "self", ".", "_shutdown_worker", "(", "worker_id", ")", "\n", "", "", "if", "len", "(", "failed_workers", ")", ">", "0", ":", "\n", "                ", "pids_str", "=", "', '", ".", "join", "(", "str", "(", "w", ".", "pid", ")", "for", "w", "in", "failed_workers", ")", "\n", "raise", "RuntimeError", "(", "'DataLoader worker (pid(s) {}) exited unexpectedly'", ".", "format", "(", "pids_str", ")", ")", "\n", "", "if", "isinstance", "(", "e", ",", "queue", ".", "Empty", ")", ":", "\n", "                ", "return", "(", "False", ",", "None", ")", "\n", "", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._get_data": [[779, 811], ["mydataloader._MultiProcessingDataLoaderIter._try_get_data", "RuntimeError", "mydataloader._MultiProcessingDataLoaderIter._pin_memory_thread.is_alive", "mydataloader._MultiProcessingDataLoaderIter._try_get_data", "RuntimeError", "mydataloader._MultiProcessingDataLoaderIter._try_get_data"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data"], ["", "", "def", "_get_data", "(", "self", ")", ":", "\n", "# Fetches data from `self._data_queue`.", "\n", "#", "\n", "# We check workers' status every `MP_STATUS_CHECK_INTERVAL` seconds,", "\n", "# which we achieve by running `self._try_get_data(timeout=MP_STATUS_CHECK_INTERVAL)`", "\n", "# in a loop. This is the only mechanism to detect worker failures for", "\n", "# Windows. For other platforms, a SIGCHLD handler is also used for", "\n", "# worker failure detection.", "\n", "#", "\n", "# If `pin_memory=True`, we also need check if `pin_memory_thread` had", "\n", "# died at timeouts.", "\n", "        ", "if", "self", ".", "_timeout", ">", "0", ":", "\n", "            ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", "self", ".", "_timeout", ")", "\n", "if", "success", ":", "\n", "                ", "return", "data", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "'DataLoader timed out after {} seconds'", ".", "format", "(", "self", ".", "_timeout", ")", ")", "\n", "", "", "elif", "self", ".", "_pin_memory", ":", "\n", "            ", "while", "self", ".", "_pin_memory_thread", ".", "is_alive", "(", ")", ":", "\n", "                ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", ")", "\n", "if", "success", ":", "\n", "                    ", "return", "data", "\n", "", "", "else", ":", "\n", "# while condition is false, i.e., pin_memory_thread died.", "\n", "                ", "raise", "RuntimeError", "(", "'Pin memory thread exited unexpectedly'", ")", "\n", "# In this case, `self._data_queue` is a `queue.Queue`,. But we don't", "\n", "# need to call `.task_done()` because we don't use `.join()`.", "\n", "", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", ")", "\n", "if", "success", ":", "\n", "                    ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._next_data": [[812, 857], ["mydataloader._MultiProcessingDataLoaderIter._get_data", "mydataloader._MultiProcessingDataLoaderIter._shutdown_workers", "len", "mydataloader._MultiProcessingDataLoaderIter._process_data", "isinstance", "mydataloader._MultiProcessingDataLoaderIter._process_data", "mydataloader._MultiProcessingDataLoaderIter._task_info.pop", "mydataloader._MultiProcessingDataLoaderIter._shutdown_worker", "mydataloader._MultiProcessingDataLoaderIter._try_put_index", "len"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_workers", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._process_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._process_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["", "", "", "", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "# If the worker responsible for `self._rcvd_idx` has already ended", "\n", "# and was unable to fulfill this task (due to exhausting an `IterableDataset`),", "\n", "# we try to advance `self._rcvd_idx` to find the next valid index.", "\n", "#", "\n", "# This part needs to run in the loop because both the `self._get_data()`", "\n", "# call and `_IterableDatasetStopIteration` check below can mark", "\n", "# extra worker(s) as dead.", "\n", "            ", "while", "self", ".", "_rcvd_idx", "<", "self", ".", "_send_idx", ":", "\n", "                ", "info", "=", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", "\n", "worker_id", "=", "info", "[", "0", "]", "\n", "if", "len", "(", "info", ")", "==", "2", "or", "self", ".", "_workers_status", "[", "worker_id", "]", ":", "# has data or is still active", "\n", "                    ", "break", "\n", "", "del", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", "\n", "self", ".", "_rcvd_idx", "+=", "1", "\n", "", "else", ":", "\n", "# no valid `self._rcvd_idx` is found (i.e., didn't break)", "\n", "                ", "self", ".", "_shutdown_workers", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Now `self._rcvd_idx` is the batch index we want to fetch", "\n", "\n", "# Check if the next sample has already been generated", "\n", "", "if", "len", "(", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", ")", "==", "2", ":", "\n", "                ", "data", "=", "self", ".", "_task_info", ".", "pop", "(", "self", ".", "_rcvd_idx", ")", "[", "1", "]", "\n", "return", "self", ".", "_process_data", "(", "data", ")", "\n", "\n", "", "assert", "not", "self", ".", "_shutdown", "and", "self", ".", "_tasks_outstanding", ">", "0", "\n", "idx", ",", "data", "=", "self", ".", "_get_data", "(", ")", "\n", "self", ".", "_tasks_outstanding", "-=", "1", "\n", "\n", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# Check for _IterableDatasetStopIteration", "\n", "                ", "if", "isinstance", "(", "data", ",", "_utils", ".", "worker", ".", "_IterableDatasetStopIteration", ")", ":", "\n", "                    ", "self", ".", "_shutdown_worker", "(", "data", ".", "worker_id", ")", "\n", "self", ".", "_try_put_index", "(", ")", "\n", "continue", "\n", "\n", "", "", "if", "idx", "!=", "self", ".", "_rcvd_idx", ":", "\n", "# store out-of-order samples", "\n", "                ", "self", ".", "_task_info", "[", "idx", "]", "+=", "(", "data", ",", ")", "\n", "", "else", ":", "\n", "                ", "del", "self", ".", "_task_info", "[", "idx", "]", "\n", "return", "self", ".", "_process_data", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._try_put_index": [[858, 876], ["range", "mydataloader._MultiProcessingDataLoaderIter._index_queues[].put", "mydataloader._MultiProcessingDataLoaderIter._next_index", "next"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_index"], ["", "", "", "def", "_try_put_index", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "_tasks_outstanding", "<", "2", "*", "self", ".", "_num_workers", "\n", "try", ":", "\n", "            ", "index", "=", "self", ".", "_next_index", "(", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_num_workers", ")", ":", "# find the next active worker, if any", "\n", "            ", "worker_queue_idx", "=", "next", "(", "self", ".", "_worker_queue_idx_cycle", ")", "\n", "if", "self", ".", "_workers_status", "[", "worker_queue_idx", "]", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "# not found (i.e., didn't break)", "\n", "            ", "return", "\n", "\n", "", "self", ".", "_index_queues", "[", "worker_queue_idx", "]", ".", "put", "(", "(", "self", ".", "_send_idx", ",", "index", ")", ")", "\n", "self", ".", "_task_info", "[", "self", ".", "_send_idx", "]", "=", "(", "worker_queue_idx", ",", ")", "\n", "self", ".", "_tasks_outstanding", "+=", "1", "\n", "self", ".", "_send_idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._process_data": [[877, 883], ["mydataloader._MultiProcessingDataLoaderIter._try_put_index", "isinstance", "data.reraise"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["", "def", "_process_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "_rcvd_idx", "+=", "1", "\n", "self", ".", "_try_put_index", "(", ")", "\n", "if", "isinstance", "(", "data", ",", "ExceptionWrapper", ")", ":", "\n", "            ", "data", ".", "reraise", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._shutdown_worker": [[884, 906], ["q.put"], "methods", ["None"], ["", "def", "_shutdown_worker", "(", "self", ",", "worker_id", ")", ":", "\n", "# Mark a worker as having finished its work and dead, e.g., due to", "\n", "# exhausting an `IterableDataset`. This should be used only when this", "\n", "# `_MultiProcessingDataLoaderIter` is going to continue running.", "\n", "\n", "        ", "assert", "self", ".", "_workers_status", "[", "worker_id", "]", "\n", "\n", "# Signal termination to that specific worker.", "\n", "q", "=", "self", ".", "_index_queues", "[", "worker_id", "]", "\n", "# Indicate that no more data will be put on this queue by the current", "\n", "# process.", "\n", "q", ".", "put", "(", "None", ")", "\n", "\n", "# Note that we don't actually join the worker here, nor do we remove the", "\n", "# worker's pid from C side struct because (1) joining may be slow, and", "\n", "# (2) since we don't join, the worker may still raise error, and we", "\n", "# prefer capturing those, rather than ignoring them, even though they", "\n", "# are raised after the worker has finished its job.", "\n", "# Joinning is deferred to `_shutdown_workers`, which it is called when", "\n", "# all workers finish their jobs (e.g., `IterableDataset` replicas) or", "\n", "# when this iterator is garbage collected.", "\n", "self", ".", "_workers_status", "[", "worker_id", "]", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter._shutdown_workers": [[907, 960], ["hasattr", "mydataloader._MultiProcessingDataLoaderIter._workers_done_event.set", "range", "mydataloader._MultiProcessingDataLoaderIter._pin_memory_thread_done_event.set", "mydataloader._MultiProcessingDataLoaderIter._worker_result_queue.put", "mydataloader._MultiProcessingDataLoaderIter._pin_memory_thread.join", "mydataloader._MultiProcessingDataLoaderIter._worker_result_queue.cancel_join_thread", "mydataloader._MultiProcessingDataLoaderIter._worker_result_queue.close", "len", "w.join", "q.cancel_join_thread", "q.close", "_utils.signal_handling._remove_worker_pids", "mydataloader._MultiProcessingDataLoaderIter._shutdown_worker", "id"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker"], ["", "def", "_shutdown_workers", "(", "self", ")", ":", "\n", "# Called when shutting down this `_MultiProcessingDataLoaderIter`.", "\n", "# See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on", "\n", "# the logic of this function.", "\n", "        ", "python_exit_status", "=", "_utils", ".", "python_exit_status", "\n", "if", "python_exit_status", "is", "True", "or", "python_exit_status", "is", "None", ":", "\n", "# See (2) of the note. If Python is shutting down, do no-op.", "\n", "            ", "return", "\n", "# Normal exit when last reference is gone / iterator is depleted.", "\n", "# See (1) and the second half of the note.", "\n", "", "if", "not", "self", ".", "_shutdown", ":", "\n", "            ", "self", ".", "_shutdown", "=", "True", "\n", "try", ":", "\n", "# Exit `pin_memory_thread` first because exiting workers may leave", "\n", "# corrupted data in `worker_result_queue` which `pin_memory_thread`", "\n", "# reads from.", "\n", "                ", "if", "hasattr", "(", "self", ",", "'_pin_memory_thread'", ")", ":", "\n", "# Use hasattr in case error happens before we set the attribute.", "\n", "                    ", "self", ".", "_pin_memory_thread_done_event", ".", "set", "(", ")", "\n", "# Send something to pin_memory_thread in case it is waiting", "\n", "# so that it can wake up and check `pin_memory_thread_done_event`", "\n", "self", ".", "_worker_result_queue", ".", "put", "(", "(", "None", ",", "None", ")", ")", "\n", "self", ".", "_pin_memory_thread", ".", "join", "(", ")", "\n", "self", ".", "_worker_result_queue", ".", "cancel_join_thread", "(", ")", "\n", "self", ".", "_worker_result_queue", ".", "close", "(", ")", "\n", "\n", "# Exit workers now.", "\n", "", "self", ".", "_workers_done_event", ".", "set", "(", ")", "\n", "for", "worker_id", "in", "range", "(", "len", "(", "self", ".", "_workers", ")", ")", ":", "\n", "# Get number of workers from `len(self._workers)` instead of", "\n", "# `self._num_workers` in case we error before starting all", "\n", "# workers.", "\n", "                    ", "if", "self", ".", "_workers_status", "[", "worker_id", "]", ":", "\n", "                        ", "self", ".", "_shutdown_worker", "(", "worker_id", ")", "\n", "", "", "for", "w", "in", "self", ".", "_workers", ":", "\n", "                    ", "w", ".", "join", "(", ")", "\n", "", "for", "q", "in", "self", ".", "_index_queues", ":", "\n", "                    ", "q", ".", "cancel_join_thread", "(", ")", "\n", "q", ".", "close", "(", ")", "\n", "", "", "finally", ":", "\n", "# Even though all this function does is putting into queues that", "\n", "# we have called `cancel_join_thread` on, weird things can", "\n", "# happen when a worker is killed by a signal, e.g., hanging in", "\n", "# `Event.set()`. So we need to guard this with SIGCHLD handler,", "\n", "# and remove pids from the C side data structure only at the", "\n", "# end.", "\n", "#", "\n", "# FIXME: Unfortunately, for Windows, we are missing a worker", "\n", "#        error detection mechanism here in this function, as it", "\n", "#        doesn't provide a SIGCHLD handler.", "\n", "                ", "if", "self", ".", "_worker_pids_set", ":", "\n", "                    ", "_utils", ".", "signal_handling", ".", "_remove_worker_pids", "(", "id", "(", "self", ")", ")", "\n", "self", ".", "_worker_pids_set", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.mydataloader._MultiProcessingDataLoaderIter.__del__": [[961, 963], ["mydataloader._MultiProcessingDataLoaderIter._shutdown_workers"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_workers"], ["", "", "", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_shutdown_workers", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.CubBirds.__init__": [[13, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "self", ".", "file_dict", "=", "{", "'Cid'", ":", "'classes.txt'", ",", "\n", "'imageCid'", ":", "'image_class_labels.txt'", ",", "\n", "'imageId'", ":", "'images.txt'", ",", "\n", "'imageTVT'", ":", "'train_test_split.txt'", "\n", "}", "\n", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.CubBirds._className": [[21, 27], ["open", "f.readlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "x.split"], "methods", ["None"], ["", "def", "_className", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "file_dict", "[", "'Cid'", "]", ")", ")", "as", "f", ":", "\n", "            ", "coxt", "=", "f", ".", "readlines", "(", ")", "\n", "class_names", "=", "[", "x", ".", "split", "(", ")", "[", "-", "1", "]", "for", "x", "in", "coxt", "]", "\n", "", "self", ".", "class_names", "=", "class_names", "\n", "return", "self", ".", "class_names", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.CubBirds._imdb": [[28, 44], ["pandas.DataFrame", "open", "f.readlines", "open", "f.readlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "int", "x.split", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "int", "x.split", "x.split", "x.split"], "methods", ["None"], ["", "def", "_imdb", "(", "self", ")", ":", "\n", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "file_dict", "[", "'imageId'", "]", ")", ")", "as", "f", ":", "\n", "            ", "coxt", "=", "f", ".", "readlines", "(", ")", "\n", "imageId", "=", "[", "int", "(", "x", ".", "split", "(", ")", "[", "0", "]", ")", "for", "x", "in", "coxt", "]", "\n", "imagePath", "=", "[", "x", ".", "split", "(", ")", "[", "-", "1", "]", "for", "x", "in", "coxt", "]", "\n", "", "df", "=", "{", "'imageId'", ":", "imageId", ",", "'imagePath'", ":", "imagePath", "}", "\n", "imdb", "=", "pd", ".", "DataFrame", "(", "data", "=", "df", ")", "\n", "imageCid", "=", "[", "x", ".", "split", "(", "'/'", ")", "[", "0", "]", "for", "x", "in", "imdb", "[", "'imagePath'", "]", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "file_dict", "[", "'imageTVT'", "]", ")", ")", "as", "f", ":", "\n", "            ", "coxt", "=", "f", ".", "readlines", "(", ")", "\n", "imageTVT", "=", "[", "int", "(", "x", ".", "split", "(", ")", "[", "-", "1", "]", ")", "for", "x", "in", "coxt", "]", "\n", "", "imdb", "[", "'imageCid'", "]", "=", "imageCid", "\n", "imdb", "[", "'imageTVT'", "]", "=", "imageTVT", "\n", "\n", "return", "imdb", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.StCars.__init__": [[48, 56], ["open", "pickle.load", "os.join", "os.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "with", "open", "(", "osp", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "annos", "=", "pk", ".", "load", "(", "handle", ")", "\n", "", "self", ".", "classnames", "=", "annos", "[", "'classnames'", "]", "\n", "self", ".", "classdict", "=", "annos", "[", "'classdict'", "]", "\n", "self", ".", "testdata", "=", "annos", "[", "'annos_test'", "]", "\n", "self", ".", "traindata", "=", "annos", "[", "'annos_train'", "]", "\n", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.StCars._createTVTFolders": [[57, 64], ["os.exists", "os.exists", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join"], "methods", ["None"], ["", "def", "_createTVTFolders", "(", "self", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "self", ".", "classnames", "[", "0", "]", ")", ")", ":", "\n", "            ", "for", "classname", "in", "self", ".", "classnames", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'trainval'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'test'", ",", "classname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.StDogs.__init__": [[68, 79], ["open", "pickle.load", "os.join", "os.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "with", "open", "(", "osp", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "annos", "=", "pk", ".", "load", "(", "handle", ")", "\n", "\n", "", "self", ".", "classdict", "=", "annos", "[", "'classdict'", "]", "\n", "self", ".", "classnames", "=", "annos", "[", "'classnames'", "]", "\n", "self", ".", "traindata", "=", "annos", "[", "'traindata'", "]", "\n", "self", ".", "trainlabels", "=", "annos", "[", "'trainlabels'", "]", "\n", "self", ".", "testdata", "=", "annos", "[", "'testdata'", "]", "\n", "self", ".", "testlabels", "=", "annos", "[", "'testlabels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.StDogs._createTVTFolders": [[80, 87], ["os.exists", "os.exists", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join"], "methods", ["None"], ["", "def", "_createTVTFolders", "(", "self", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "self", ".", "classnames", "[", "0", "]", ")", ")", ":", "\n", "            ", "for", "classname", "in", "self", ".", "classnames", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'trainval'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'test'", ",", "classname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.VggAircraft.__init__": [[91, 106], ["open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "annos", "=", "pk", ".", "load", "(", "handle", ")", "\n", "\n", "", "self", ".", "classdict_variant", "=", "annos", "[", "'classdict_variant'", "]", "\n", "self", ".", "classdict_family", "=", "annos", "[", "'classdict_variant'", "]", "\n", "self", ".", "classdict_manufacturer", "=", "annos", "[", "'classdict_variant'", "]", "\n", "self", ".", "classnames_variant", "=", "annos", "[", "'classnames_variant'", "]", "\n", "self", ".", "classnames_family", "=", "annos", "[", "'classnames_family'", "]", "\n", "self", ".", "classnames_manufacturer", "=", "annos", "[", "'classnames_manufacturer'", "]", "\n", "self", ".", "traindata", "=", "annos", "[", "'traindata'", "]", "\n", "self", ".", "trainvaldata", "=", "annos", "[", "'trainvaldata'", "]", "\n", "self", ".", "testdata", "=", "annos", "[", "'testdata'", "]", "\n", "self", ".", "valdata", "=", "annos", "[", "'valdata'", "]", "\n", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.VggAircraft._createTVTFolders": [[107, 114], ["os.exists", "os.exists", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join"], "methods", ["None"], ["", "def", "_createTVTFolders", "(", "self", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "self", ".", "classnames_variant", "[", "0", "]", ")", ")", ":", "\n", "            ", "for", "classname", "in", "self", ".", "classnames_variant", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'trainval'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'test'", ",", "classname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.NaBirds.__init__": [[117, 127], ["open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "annos", "=", "pk", ".", "load", "(", "handle", ")", "\n", "\n", "", "self", ".", "prntclassid", "=", "annos", "[", "'prntclassid'", "]", "\n", "self", ".", "classnames", "=", "annos", "[", "'classnames'", "]", "\n", "self", ".", "subclassid", "=", "annos", "[", "'subclassid'", "]", "\n", "self", ".", "testdata", "=", "annos", "[", "'testdata'", "]", "\n", "self", ".", "traindata", "=", "annos", "[", "'traindata'", "]", "\n", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.NaBirds._createTVTFolders": [[128, 136], ["list", "set", "os.exists", "os.exists", "imdb.NaBirds.subclassid.values", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join"], "methods", ["None"], ["", "def", "_createTVTFolders", "(", "self", ")", ":", "\n", "        ", "subclassid", "=", "list", "(", "set", "(", "self", ".", "subclassid", ".", "values", "(", ")", ")", ")", "\n", "if", "not", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "subclassid", "[", "0", "]", ")", ")", ":", "\n", "            ", "for", "classname", "in", "subclassid", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'trainval'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'test'", ",", "classname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs.__init__": [[140, 151], ["open", "pickle.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "handle", ":", "\n", "            ", "annos", "=", "pk", ".", "load", "(", "handle", ")", "\n", "\n", "", "self", ".", "classdict", "=", "annos", "[", "'classdict'", "]", "\n", "self", ".", "classnames", "=", "annos", "[", "'classnames'", "]", "\n", "self", ".", "traindata", "=", "annos", "[", "'traindata'", "]", "\n", "self", ".", "trainvaldata", "=", "annos", "[", "'trainvaldata'", "]", "\n", "self", ".", "testdata", "=", "annos", "[", "'testdata'", "]", "\n", "self", ".", "valdata", "=", "annos", "[", "'valdata'", "]", "\n", "self", ".", "root", "=", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders": [[152, 159], ["os.exists", "os.exists", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join"], "methods", ["None"], ["", "def", "_createTVTFolders", "(", "self", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "self", ".", "classnames", "[", "0", "]", ")", ")", ":", "\n", "            ", "for", "classname", "in", "self", ".", "classnames", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'train'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'trainval'", ",", "classname", ")", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "join", "(", "self", ".", "root", ",", "'test'", ",", "classname", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.creatDataset": [[160, 474], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "sum", "sum", "sum", "sum", "print", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "len", "len", "len", "imdb.CubBirds", "imdb.CubBirds._className", "os.path.exists", "os.path.exists", "print", "len", "len", "len", "len", "print", "os.path.join", "os.path.join", "CubBirds._imdb", "pandas.DataFrame", "pandas.DataFrame", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "imdb.StCars", "imdb.StCars._createTVTFolders", "os.listdir", "os.listdir", "print", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "open", "pickle.load", "numpy.random.permutation", "train_pd.append.append", "val_pd.append.append", "open", "pickle.dump", "os.path.exists", "os.path.exists", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.path.join", "os.path.join", "shutil.copy", "shutil.copy", "os.path.join", "os.path.join", "shutil.copy", "shutil.copy", "print", "os.path.join", "os.path.join", "shutil.copy", "print", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.listdir", "os.listdir", "len", "numpy.random.permutation", "int", "os.join", "os.join", "imdb.StDogs", "imdb.StDogs._createTVTFolders", "os.listdir", "os.listdir", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.join", "numpy.floor", "shutil.copy", "shutil.copy", "print", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.listdir", "os.listdir", "len", "numpy.random.permutation", "int", "os.join", "os.join", "imdb.VggAircraft", "imdb.VggAircraft._createTVTFolders", "print", "os.join", "os.join", "imgpath.split", "imgpath.split", "os.join", "numpy.floor", "shutil.copy", "shutil.copy", "print", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "imdb.NaBirds", "imdb.NaBirds._createTVTFolders", "os.listdir", "os.listdir", "print", "os.join", "os.join", "print", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.listdir", "os.listdir", "len", "numpy.random.permutation", "int", "os.join", "os.join", "imdb.WdDogs", "imdb.WdDogs._createTVTFolders", "print", "print", "os.join", "numpy.floor", "shutil.copy", "shutil.copy", "print", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.join", "os.join", "shutil.copy", "os.join", "os.join"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.CubBirds._className", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.CubBirds._imdb", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders", "home.repos.pwc.inspect_result.cswluo_SEF.utils.imdb.WdDogs._createTVTFolders"], ["", "", "", "", "def", "creatDataset", "(", "root", ",", "datasetname", "=", "None", ")", ":", "\n", "\n", "    ", "if", "datasetname", "is", "not", "None", ":", "\n", "        ", "trainpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'train'", ")", "\n", "valpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'val'", ")", "\n", "testpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'test'", ")", "\n", "trainvalpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'trainval'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "trainpath", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "trainpath", ")", "\n", "os", ".", "makedirs", "(", "valpath", ")", "\n", "os", ".", "makedirs", "(", "testpath", ")", "\n", "os", ".", "makedirs", "(", "trainvalpath", ")", "\n", "\n", "# checking the train/val/test integrity", "\n", "", "train_folders", "=", "os", ".", "listdir", "(", "trainpath", ")", "\n", "val_folders", "=", "os", ".", "listdir", "(", "valpath", ")", "\n", "test_folders", "=", "os", ".", "listdir", "(", "testpath", ")", "\n", "trainval_folders", "=", "os", ".", "listdir", "(", "trainvalpath", ")", "\n", "\n", "assert", "len", "(", "train_folders", ")", "==", "len", "(", "val_folders", ")", "==", "len", "(", "\n", "test_folders", ")", ",", "\"The train/val/test datasets are not complete\"", "\n", "\n", "num_train_data", "=", "sum", "(", "[", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "trainpath", ",", "subfolder", ")", ")", ")", "for", "subfolder", "in", "train_folders", "]", ")", "\n", "num_val_data", "=", "sum", "(", "[", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "valpath", ",", "subfolder", ")", ")", ")", "for", "subfolder", "in", "val_folders", "]", ")", "\n", "num_test_data", "=", "sum", "(", "[", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "testpath", ",", "subfolder", ")", ")", ")", "for", "subfolder", "in", "test_folders", "]", ")", "\n", "num_trainval_data", "=", "sum", "(", "\n", "[", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "trainvalpath", ",", "subfolder", ")", ")", ")", "for", "subfolder", "in", "trainval_folders", "]", ")", "\n", "\n", "\n", "\n", "if", "datasetname", "==", "\"cubbirds\"", ":", "\n", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "11788", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "\n", "# if the train/val/test datasets are not exist", "\n", "", "birds", "=", "CubBirds", "(", "root", ")", "\n", "class_names", "=", "birds", ".", "_className", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ")", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "pdata", "=", "pk", ".", "load", "(", "f", ")", "\n", "train_pd", ",", "val_pd", ",", "test_pd", ",", "=", "pdata", "[", "'train'", "]", ",", "pdata", "[", "'val'", "]", ",", "pdata", "[", "'test'", "]", "\n", "", "", "else", ":", "\n", "                ", "imdb", "=", "birds", ".", "_imdb", "(", ")", "\n", "\n", "test_pd", "=", "imdb", ".", "loc", "[", "imdb", "[", "'imageTVT'", "]", "==", "0", "]", "\n", "train_tpd", "=", "imdb", ".", "loc", "[", "imdb", "[", "'imageTVT'", "]", "==", "1", "]", "\n", "\n", "train_pd", "=", "pd", ".", "DataFrame", "(", ")", "\n", "val_pd", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "for", "class_name", "in", "class_names", ":", "\n", "                    ", "trainval", "=", "train_tpd", ".", "loc", "[", "train_tpd", "[", "'imageCid'", "]", "==", "class_name", "]", "\n", "permuind", "=", "np", ".", "random", ".", "permutation", "(", "trainval", ".", "index", ")", "\n", "# print(permuind)", "\n", "train_pd", "=", "train_pd", ".", "append", "(", "trainval", ".", "loc", "[", "permuind", "[", ":", "-", "3", "]", "]", ",", "ignore_index", "=", "True", ")", "\n", "val_pd", "=", "val_pd", ".", "append", "(", "trainval", ".", "loc", "[", "permuind", "[", "-", "3", ":", "]", "]", ",", "ignore_index", "=", "True", ")", "\n", "# print(trainval.index)", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'imdb.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pk", ".", "dump", "(", "{", "'train'", ":", "train_pd", ",", "'val'", ":", "val_pd", ",", "'test'", ":", "test_pd", "}", ",", "f", ")", "\n", "\n", "", "", "for", "class_name", "in", "class_names", ":", "\n", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "trainvalpath", ",", "class_name", ")", ")", ":", "\n", "                    ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "trainpath", ",", "class_name", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "valpath", ",", "class_name", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "testpath", ",", "class_name", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "trainvalpath", ",", "class_name", ")", ")", "\n", "\n", "\n", "", "train_dst_path", "=", "os", ".", "path", ".", "join", "(", "trainpath", ",", "class_name", ")", "\n", "val_dst_path", "=", "os", ".", "path", ".", "join", "(", "valpath", ",", "class_name", ")", "\n", "test_dst_path", "=", "os", ".", "path", ".", "join", "(", "testpath", ",", "class_name", ")", "\n", "trainval_dst_path", "=", "os", ".", "path", ".", "join", "(", "trainvalpath", ",", "class_name", ")", "\n", "\n", "newtrainpd", "=", "train_pd", ".", "loc", "[", "train_pd", "[", "'imageCid'", "]", "==", "class_name", "]", "\n", "newtrainpd_index", "=", "newtrainpd", ".", "index", "\n", "for", "i_", "in", "newtrainpd_index", ":", "\n", "                    ", "src_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "newtrainpd", ".", "loc", "[", "i_", ",", "'imagePath'", "]", ")", "\n", "shutil", ".", "copy", "(", "src_path", ",", "train_dst_path", ")", "\n", "shutil", ".", "copy", "(", "src_path", ",", "trainval_dst_path", ")", "\n", "\n", "", "newvalpd", "=", "val_pd", ".", "loc", "[", "val_pd", "[", "'imageCid'", "]", "==", "class_name", "]", "\n", "newvalpd_index", "=", "newvalpd", ".", "index", "\n", "for", "i_", "in", "newvalpd_index", ":", "\n", "                    ", "src_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "newvalpd", ".", "loc", "[", "i_", ",", "'imagePath'", "]", ")", "\n", "shutil", ".", "copy", "(", "src_path", ",", "val_dst_path", ")", "\n", "shutil", ".", "copy", "(", "src_path", ",", "trainval_dst_path", ")", "\n", "\n", "", "newtestpd", "=", "test_pd", ".", "loc", "[", "test_pd", "[", "'imageCid'", "]", "==", "class_name", "]", "\n", "newtestpd_index", "=", "newtestpd", ".", "index", "\n", "for", "i_", "in", "newtestpd", ".", "index", ":", "\n", "                    ", "print", "(", "i_", ")", "\n", "src_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "newtestpd", ".", "loc", "[", "i_", ",", "'imagePath'", "]", ")", "\n", "shutil", ".", "copy", "(", "src_path", ",", "test_dst_path", ")", "\n", "", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "\n", "\n", "", "elif", "datasetname", "==", "\"stcars\"", ":", "\n", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "16185", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "\n", "# if the train/val/test datasets are not exist", "\n", "", "cars", "=", "StCars", "(", "root", ")", "\n", "class_names", "=", "cars", ".", "classnames", "\n", "class_dict", "=", "cars", ".", "classdict", "\n", "traindata", "=", "cars", ".", "traindata", "\n", "testdata", "=", "cars", ".", "testdata", "\n", "\n", "cars", ".", "_createTVTFolders", "(", ")", "\n", "\n", "for", "line", "in", "traindata", ":", "\n", "                ", "train_src_path", "=", "osp", ".", "join", "(", "cars", ".", "root", ",", "line", "[", "'relative_im_path'", "]", ")", "\n", "class_name", "=", "class_dict", "[", "line", "[", "'class'", "]", "]", "\n", "trainval_dst_path", "=", "osp", ".", "join", "(", "trainvalpath", ",", "class_name", ")", "\n", "shutil", ".", "copy", "(", "train_src_path", ",", "trainval_dst_path", ")", "\n", "", "for", "line", "in", "testdata", ":", "\n", "                ", "test_src_path", "=", "osp", ".", "join", "(", "cars", ".", "root", ",", "line", "[", "'relative_im_path'", "]", ")", "\n", "class_name", "=", "class_dict", "[", "line", "[", "'class'", "]", "]", "\n", "test_dst_path", "=", "osp", ".", "join", "(", "testpath", ",", "class_name", ")", "\n", "shutil", ".", "copy", "(", "test_src_path", ",", "test_dst_path", ")", "\n", "\n", "# build train and validation sets from the trainval set", "\n", "", "subfolders", "=", "os", ".", "listdir", "(", "trainvalpath", ")", "\n", "for", "subfolder", "in", "subfolders", ":", "\n", "                ", "imgs", "=", "os", ".", "listdir", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ")", ")", "\n", "num_imgs", "=", "len", "(", "imgs", ")", "\n", "rndidx", "=", "np", ".", "random", ".", "permutation", "(", "num_imgs", ")", "\n", "num_val", "=", "int", "(", "np", ".", "floor", "(", "0.1", "*", "num_imgs", ")", ")", "\n", "num_train", "=", "num_imgs", "-", "num_val", "\n", "train_dst_path", "=", "osp", ".", "join", "(", "trainpath", ",", "subfolder", ")", "\n", "val_dst_path", "=", "osp", ".", "join", "(", "valpath", ",", "subfolder", ")", "\n", "for", "idx", "in", "rndidx", "[", ":", "num_train", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "train_dst_path", ")", "\n", "", "for", "idx", "in", "rndidx", "[", "num_train", ":", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "val_dst_path", ")", "\n", "\n", "", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "\n", "\n", "", "elif", "datasetname", "==", "'stdogs'", ":", "\n", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "20580", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "\n", "# if the train/val/test datasets are not exist", "\n", "", "dogs", "=", "StDogs", "(", "root", ")", "\n", "class_names", "=", "dogs", ".", "classnames", "\n", "class_dict", "=", "dogs", ".", "classdict", "\n", "train_data", "=", "dogs", ".", "traindata", "\n", "train_labels", "=", "dogs", ".", "trainlabels", "\n", "test_data", "=", "dogs", ".", "testdata", "\n", "test_labels", "=", "dogs", ".", "testlabels", "\n", "\n", "dogs", ".", "_createTVTFolders", "(", ")", "\n", "\n", "for", "imgpath", "in", "train_data", ":", "\n", "                ", "class_name", "=", "imgpath", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "train_src_path", "=", "osp", ".", "join", "(", "dogs", ".", "root", ",", "'Images'", ",", "imgpath", ")", "\n", "trainval_dst_path", "=", "osp", ".", "join", "(", "trainvalpath", ",", "class_name", ")", "\n", "shutil", ".", "copy", "(", "train_src_path", ",", "trainval_dst_path", ")", "\n", "", "for", "imgpath", "in", "test_data", ":", "\n", "                ", "class_name", "=", "imgpath", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "test_src_path", "=", "osp", ".", "join", "(", "dogs", ".", "root", ",", "'Images'", ",", "imgpath", ")", "\n", "test_dst_path", "=", "osp", ".", "join", "(", "testpath", ",", "class_name", ")", "\n", "shutil", ".", "copy", "(", "test_src_path", ",", "test_dst_path", ")", "\n", "\n", "# build train and validation sets from the trainval set", "\n", "", "subfolders", "=", "os", ".", "listdir", "(", "trainvalpath", ")", "\n", "for", "subfolder", "in", "subfolders", ":", "\n", "                ", "imgs", "=", "os", ".", "listdir", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ")", ")", "\n", "num_imgs", "=", "len", "(", "imgs", ")", "\n", "rndidx", "=", "np", ".", "random", ".", "permutation", "(", "num_imgs", ")", "\n", "num_val", "=", "int", "(", "np", ".", "floor", "(", "0.1", "*", "num_imgs", ")", ")", "\n", "num_train", "=", "num_imgs", "-", "num_val", "\n", "train_dst_path", "=", "osp", ".", "join", "(", "trainpath", ",", "subfolder", ")", "\n", "val_dst_path", "=", "osp", ".", "join", "(", "valpath", ",", "subfolder", ")", "\n", "for", "idx", "in", "rndidx", "[", ":", "num_train", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "train_dst_path", ")", "\n", "", "for", "idx", "in", "rndidx", "[", "num_train", ":", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "val_dst_path", ")", "\n", "\n", "", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "\n", "\n", "", "elif", "datasetname", "==", "\"vggaircraft\"", ":", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "10000", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "\n", "", "aircrafts", "=", "VggAircraft", "(", "root", ")", "\n", "traindata", "=", "aircrafts", ".", "traindata", "\n", "trainvaldata", "=", "aircrafts", ".", "trainvaldata", "\n", "valdata", "=", "aircrafts", ".", "valdata", "\n", "testdata", "=", "aircrafts", ".", "testdata", "\n", "classnames", "=", "aircrafts", ".", "classnames_variant", "\n", "classdict", "=", "aircrafts", ".", "classdict_variant", "\n", "aircrafts", ".", "_createTVTFolders", "(", ")", "\n", "\n", "for", "row", "in", "traindata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "'images'", ",", "row", "[", "0", "]", "+", "'.jpg'", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'train'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "row", "in", "trainvaldata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "'images'", ",", "row", "[", "0", "]", "+", "'.jpg'", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'trainval'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "row", "in", "valdata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "'images'", ",", "row", "[", "0", "]", "+", "'.jpg'", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'val'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "row", "in", "testdata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "'images'", ",", "row", "[", "0", "]", "+", "'.jpg'", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'test'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "\n", "", "elif", "datasetname", "==", "\"nabirds\"", ":", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "48562", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "", "nabirds", "=", "NaBirds", "(", "root", ")", "\n", "traindata", "=", "nabirds", ".", "traindata", "\n", "testdata", "=", "nabirds", ".", "testdata", "\n", "classnames", "=", "nabirds", ".", "classnames", "\n", "prntclassid", "=", "nabirds", ".", "prntclassid", "\n", "subclassid", "=", "nabirds", ".", "subclassid", "\n", "nabirds", ".", "_createTVTFolders", "(", ")", "\n", "\n", "# trainval data", "\n", "for", "row", "in", "traindata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "row", "[", "0", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'trainval'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "# testing data", "\n", "", "for", "row", "in", "testdata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "row", "[", "0", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "root", ",", "'test'", ",", "row", "[", "1", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "# build train and validation sets from the trainval set", "\n", "", "subfolders", "=", "os", ".", "listdir", "(", "trainvalpath", ")", "\n", "for", "subfolder", "in", "subfolders", ":", "\n", "                ", "imgs", "=", "os", ".", "listdir", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ")", ")", "\n", "num_imgs", "=", "len", "(", "imgs", ")", "\n", "rndidx", "=", "np", ".", "random", ".", "permutation", "(", "num_imgs", ")", "\n", "num_val", "=", "int", "(", "np", ".", "floor", "(", "0.1", "*", "num_imgs", ")", ")", "\n", "num_train", "=", "num_imgs", "-", "num_val", "\n", "train_dst_path", "=", "osp", ".", "join", "(", "trainpath", ",", "subfolder", ")", "\n", "val_dst_path", "=", "osp", ".", "join", "(", "valpath", ",", "subfolder", ")", "\n", "for", "idx", "in", "rndidx", "[", ":", "num_train", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "train_dst_path", ")", "\n", "", "for", "idx", "in", "rndidx", "[", "num_train", ":", "]", ":", "\n", "                    ", "shutil", ".", "copy", "(", "osp", ".", "join", "(", "trainvalpath", ",", "subfolder", ",", "imgs", "[", "idx", "]", ")", ",", "val_dst_path", ")", "\n", "\n", "", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "", "elif", "datasetname", "==", "\"wddogs\"", ":", "\n", "            ", "if", "num_test_data", "+", "num_train_data", "+", "num_val_data", "==", "299458", "and", "num_train_data", "+", "num_val_data", "==", "num_trainval_data", ":", "\n", "                ", "print", "(", "\"train/val/test sets are already exist.\"", ")", "\n", "return", "True", "\n", "", "wddogs", "=", "WdDogs", "(", "root", ")", "\n", "traindata", "=", "wddogs", ".", "traindata", "\n", "testdata", "=", "wddogs", ".", "testdata", "\n", "valdata", "=", "wddogs", ".", "valdata", "\n", "trainvaldata", "=", "wddogs", ".", "trainvaldata", "\n", "classnames", "=", "wddogs", ".", "classnames", "\n", "classdict", "=", "wddogs", ".", "classdict", "\n", "wddogs", ".", "_createTVTFolders", "(", ")", "\n", "\n", "for", "elmt", "in", "traindata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "elmt", "[", "'imgname'", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "trainpath", ",", "elmt", "[", "'imgCname'", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "elmt", "in", "valdata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "elmt", "[", "'imgname'", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "valpath", ",", "elmt", "[", "'imgCname'", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "elmt", "in", "trainvaldata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "elmt", "[", "'imgname'", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "trainvalpath", ",", "elmt", "[", "'imgCname'", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "for", "elmt", "in", "testdata", ":", "\n", "                ", "img_src_path", "=", "osp", ".", "join", "(", "root", ",", "elmt", "[", "'imgname'", "]", ")", "\n", "img_dst_path", "=", "osp", ".", "join", "(", "testpath", ",", "elmt", "[", "'imgCname'", "]", ")", "\n", "shutil", ".", "copy", "(", "img_src_path", ",", "img_dst_path", ")", "\n", "\n", "", "print", "(", "\"Successfully creating train/val/test sets.\"", ")", "\n", "return", "True", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"This dataset has not been implemented.\"", ")", "\n", "return", "False", "\n", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"You should provide the dataset name for proceeding.\\n\"", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.__init__": [[9, 27], ["isinstance", "os.path.expanduser", "ValueError", "vision.StandardTransform"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "transforms", "=", "None", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "root", ",", "torch", ".", "_six", ".", "string_classes", ")", ":", "\n", "            ", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "", "self", ".", "root", "=", "root", "\n", "\n", "has_transforms", "=", "transforms", "is", "not", "None", "\n", "has_separate_transform", "=", "transform", "is", "not", "None", "or", "target_transform", "is", "not", "None", "\n", "if", "has_transforms", "and", "has_separate_transform", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only transforms or transform/target_transform can \"", "\n", "\"be passed as argument\"", ")", "\n", "\n", "# for backwards-compatibility", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "if", "has_separate_transform", ":", "\n", "            ", "transforms", "=", "StandardTransform", "(", "transform", ",", "target_transform", ")", "\n", "", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.__getitem__": [[28, 30], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.__len__": [[31, 33], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.__repr__": [[34, 44], ["vision.VisionDataset.extra_repr().splitlines", "body.append", "hasattr", "vision.VisionDataset.__len__", "vision.VisionDataset.extra_repr", "repr"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.BatchSampler.__len__", "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.extra_repr"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "head", "=", "\"Dataset \"", "+", "self", ".", "__class__", ".", "__name__", "\n", "body", "=", "[", "\"Number of datapoints: {}\"", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "]", "\n", "if", "self", ".", "root", "is", "not", "None", ":", "\n", "            ", "body", ".", "append", "(", "\"Root location: {}\"", ".", "format", "(", "self", ".", "root", ")", ")", "\n", "", "body", "+=", "self", ".", "extra_repr", "(", ")", ".", "splitlines", "(", ")", "\n", "if", "hasattr", "(", "self", ",", "\"transforms\"", ")", "and", "self", ".", "transforms", "is", "not", "None", ":", "\n", "            ", "body", "+=", "[", "repr", "(", "self", ".", "transforms", ")", "]", "\n", "", "lines", "=", "[", "head", "]", "+", "[", "\" \"", "*", "self", ".", "_repr_indent", "+", "line", "for", "line", "in", "body", "]", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset._format_transform_repr": [[45, 49], ["transform.__repr__().splitlines", "transform.__repr__", "len"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform.__repr__"], ["", "def", "_format_transform_repr", "(", "self", ",", "transform", ",", "head", ")", ":", "\n", "        ", "lines", "=", "transform", ".", "__repr__", "(", ")", ".", "splitlines", "(", ")", "\n", "return", "(", "[", "\"{}{}\"", ".", "format", "(", "head", ",", "lines", "[", "0", "]", ")", "]", "+", "\n", "[", "\"{}{}\"", ".", "format", "(", "\" \"", "*", "len", "(", "head", ")", ",", "line", ")", "for", "line", "in", "lines", "[", "1", ":", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.VisionDataset.extra_repr": [[50, 52], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform.__init__": [[55, 58], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform.__call__": [[59, 65], ["vision.StandardTransform.transform", "vision.StandardTransform.target_transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "input", "=", "self", ".", "transform", "(", "input", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "", "return", "input", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform._format_transform_repr": [[66, 70], ["transform.__repr__().splitlines", "transform.__repr__", "len"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform.__repr__"], ["", "def", "_format_transform_repr", "(", "self", ",", "transform", ",", "head", ")", ":", "\n", "        ", "lines", "=", "transform", ".", "__repr__", "(", ")", ".", "splitlines", "(", ")", "\n", "return", "(", "[", "\"{}{}\"", ".", "format", "(", "head", ",", "lines", "[", "0", "]", ")", "]", "+", "\n", "[", "\"{}{}\"", ".", "format", "(", "\" \"", "*", "len", "(", "head", ")", ",", "line", ")", "for", "line", "in", "lines", "[", "1", ":", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform.__repr__": [[71, 81], ["vision.StandardTransform._format_transform_repr", "vision.StandardTransform._format_transform_repr"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform._format_transform_repr", "home.repos.pwc.inspect_result.cswluo_SEF.utils.vision.StandardTransform._format_transform_repr"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "body", "=", "[", "self", ".", "__class__", ".", "__name__", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "body", "+=", "self", ".", "_format_transform_repr", "(", "self", ".", "transform", ",", "\n", "\"Transform: \"", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "body", "+=", "self", ".", "_format_transform_repr", "(", "self", ".", "target_transform", ",", "\n", "\"Target transform: \"", ")", "\n", "\n", "", "return", "'\\n'", ".", "join", "(", "body", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.DatasetFolder.__init__": [[90, 107], ["vision.VisionDataset.__init__", "myimagefolder.DatasetFolder._find_classes", "myimagefolder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.DatasetFolder._find_classes", "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.make_dataset"], ["def", "__init__", "(", "self", ",", "root", ",", "loader", ",", "extensions", "=", "None", ",", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "is_valid_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "DatasetFolder", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "classes", ",", "class_to_idx", "=", "self", ".", "_find_classes", "(", "self", ".", "root", ")", "\n", "samples", "=", "make_dataset", "(", "self", ".", "root", ",", "class_to_idx", ",", "extensions", ",", "is_valid_file", ")", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 files in subfolders of: \"", "+", "self", ".", "root", "+", "\"\\n\"", "\n", "\"Supported extensions are: \"", "+", "\",\"", ".", "join", "(", "extensions", ")", ")", ")", "\n", "\n", "", "self", ".", "loader", "=", "loader", "\n", "self", ".", "extensions", "=", "extensions", "\n", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "class_to_idx", "=", "class_to_idx", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "targets", "=", "[", "s", "[", "1", "]", "for", "s", "in", "samples", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.DatasetFolder._find_classes": [[108, 125], ["classes.sort", "os.scandir", "os.scandir", "os.scandir", "os.scandir", "d.is_dir", "range", "len"], "methods", ["None"], ["", "def", "_find_classes", "(", "self", ",", "dir", ")", ":", "\n", "        ", "\"\"\"\n        Finds the class folders in a dataset.\n\n        Args:\n            dir (string): Root directory path.\n\n        Returns:\n            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n\n        Ensures:\n            No class is a subdirectory of another.\n        \"\"\"", "\n", "classes", "=", "[", "d", ".", "name", "for", "d", "in", "os", ".", "scandir", "(", "dir", ")", "if", "d", ".", "is_dir", "(", ")", "]", "\n", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.DatasetFolder.__getitem__": [[126, 142], ["myimagefolder.DatasetFolder.loader", "myimagefolder.DatasetFolder.transform", "myimagefolder.DatasetFolder.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "path", ",", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.DatasetFolder.__len__": [[143, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.ImageFolder.__init__": [[201, 208], ["myimagefolder.DatasetFolder.__init__"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "is_valid_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "ImageFolder", ",", "self", ")", ".", "__init__", "(", "root", ",", "loader", ",", "IMG_EXTENSIONS", "if", "is_valid_file", "is", "None", "else", "None", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "is_valid_file", "=", "is_valid_file", ")", "\n", "self", ".", "imgs", "=", "self", ".", "samples", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.has_file_allowed_extension": [[9, 20], ["filename.lower().endswith", "filename.lower"], "function", ["None"], ["def", "has_file_allowed_extension", "(", "filename", ",", "extensions", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an allowed extension.\n\n    Args:\n        filename (string): path to a file\n        extensions (tuple of strings): extensions to consider (lowercase)\n\n    Returns:\n        bool: True if the filename ends with one of given extensions\n    \"\"\"", "\n", "return", "filename", ".", "lower", "(", ")", ".", "endswith", "(", "extensions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.is_image_file": [[22, 32], ["myimagefolder.has_file_allowed_extension"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.has_file_allowed_extension"], ["", "def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an allowed image extension.\n\n    Args:\n        filename (string): path to a file\n\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"", "\n", "return", "has_file_allowed_extension", "(", "filename", ",", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.make_dataset": [[34, 56], ["os.path.expanduser", "os.path.expanduser", "sorted", "ValueError", "class_to_idx.keys", "os.path.join", "os.path.join", "sorted", "myimagefolder.has_file_allowed_extension", "os.path.isdir", "os.path.isdir", "os.walk", "os.walk", "sorted", "os.path.join", "os.path.join", "myimagefolder.make_dataset.is_valid_file"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.has_file_allowed_extension"], ["", "def", "make_dataset", "(", "directory", ",", "class_to_idx", ",", "extensions", "=", "None", ",", "is_valid_file", "=", "None", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "directory", "=", "os", ".", "path", ".", "expanduser", "(", "directory", ")", "\n", "both_none", "=", "extensions", "is", "None", "and", "is_valid_file", "is", "None", "\n", "both_something", "=", "extensions", "is", "not", "None", "and", "is_valid_file", "is", "not", "None", "\n", "if", "both_none", "or", "both_something", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both extensions and is_valid_file cannot be None or not None at the same time\"", ")", "\n", "", "if", "extensions", "is", "not", "None", ":", "\n", "        ", "def", "is_valid_file", "(", "x", ")", ":", "\n", "            ", "return", "has_file_allowed_extension", "(", "x", ",", "extensions", ")", "\n", "", "", "for", "target_class", "in", "sorted", "(", "class_to_idx", ".", "keys", "(", ")", ")", ":", "\n", "        ", "class_index", "=", "class_to_idx", "[", "target_class", "]", "\n", "target_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "target_class", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "target_dir", ")", ":", "\n", "            ", "continue", "\n", "", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "target_dir", ",", "followlinks", "=", "True", ")", ")", ":", "\n", "            ", "for", "fname", "in", "sorted", "(", "fnames", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "if", "is_valid_file", "(", "path", ")", ":", "\n", "                    ", "item", "=", "path", ",", "class_index", "\n", "instances", ".", "append", "(", "item", ")", "\n", "", "", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.pil_loader": [[150, 155], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.accimage_loader": [[157, 164], ["accimage.Image", "myimagefolder.pil_loader"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.pil_loader"], ["", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "import", "accimage", "\n", "try", ":", "\n", "        ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.default_loader": [[166, 172], ["get_image_backend", "myimagefolder.accimage_loader", "myimagefolder.pil_loader"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.accimage_loader", "home.repos.pwc.inspect_result.cswluo_SEF.utils.myimagefolder.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader.__init__": [[120, 235], ["torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "torch._C._log_api_usage_once", "isinstance", "ValueError", "ValueError", "ValueError", "BatchSampler", "ValueError", "ValueError", "dataloader._InfiniteConstantSampler", "ValueError", "ValueError", "RandomSampler", "SequentialSampler", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "sampler", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "num_workers", "=", "0", ",", "collate_fn", "=", "None", ",", "\n", "pin_memory", "=", "False", ",", "drop_last", "=", "False", ",", "timeout", "=", "0", ",", "\n", "worker_init_fn", "=", "None", ",", "multiprocessing_context", "=", "None", ")", ":", "\n", "        ", "torch", ".", "_C", ".", "_log_api_usage_once", "(", "\"python.data_loader\"", ")", "\n", "\n", "if", "num_workers", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'num_workers option should be non-negative; '", "\n", "'use num_workers=0 to disable multiprocessing.'", ")", "\n", "\n", "", "if", "timeout", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'timeout option should be non-negative'", ")", "\n", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "pin_memory", "=", "pin_memory", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "worker_init_fn", "=", "worker_init_fn", "\n", "self", ".", "multiprocessing_context", "=", "multiprocessing_context", "\n", "\n", "# Arg-check dataset related before checking samplers because we want to", "\n", "# tell users that iterable-style datasets are incompatible with custom", "\n", "# samplers first, so that they don't learn that this combo doesn't work", "\n", "# after spending time fixing the custom sampler errors.", "\n", "if", "isinstance", "(", "dataset", ",", "IterableDataset", ")", ":", "\n", "            ", "self", ".", "_dataset_kind", "=", "_DatasetKind", ".", "Iterable", "\n", "# NOTE [ Custom Samplers and `IterableDataset` ]", "\n", "#", "\n", "# `IterableDataset` does not support custom `batch_sampler` or", "\n", "# `sampler` since the key is irrelevant (unless we support", "\n", "# generator-style dataset one day...).", "\n", "#", "\n", "# For `sampler`, we always create a dummy sampler. This is an", "\n", "# infinite sampler even when the dataset may have an implemented", "\n", "# finite `__len__` because in multi-process data loading, naive", "\n", "# settings will return duplicated data (which may be desired), and", "\n", "# thus using a sampler with length matching that of dataset will", "\n", "# cause data lost (you may have duplicates of the first couple", "\n", "# batches, but never see anything afterwards). Therefore,", "\n", "# `Iterabledataset` always uses an infinite sampler, an instance of", "\n", "# `_InfiniteConstantSampler` defined above.", "\n", "#", "\n", "# A custom `batch_sampler` essentially only controls the batch size.", "\n", "# However, it is unclear how useful it would be since an iterable-style", "\n", "# dataset can handle that within itself. Moreover, it is pointless", "\n", "# in multi-process data loading as the assignment order of batches", "\n", "# to workers is an implementation detail so users can not control", "\n", "# how to batchify each worker's iterable. Thus, we disable this", "\n", "# option. If this turns out to be useful in future, we can re-enable", "\n", "# this, and support custom samplers that specify the assignments to", "\n", "# specific workers.", "\n", "if", "shuffle", "is", "not", "False", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"shuffle option, but got shuffle={}\"", ".", "format", "(", "shuffle", ")", ")", "\n", "", "elif", "sampler", "is", "not", "None", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"sampler option, but got sampler={}\"", ".", "format", "(", "sampler", ")", ")", "\n", "", "elif", "batch_sampler", "is", "not", "None", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "raise", "ValueError", "(", "\n", "\"DataLoader with IterableDataset: expected unspecified \"", "\n", "\"batch_sampler option, but got batch_sampler={}\"", ".", "format", "(", "batch_sampler", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_dataset_kind", "=", "_DatasetKind", ".", "Map", "\n", "\n", "", "if", "sampler", "is", "not", "None", "and", "shuffle", ":", "\n", "            ", "raise", "ValueError", "(", "'sampler option is mutually exclusive with '", "\n", "'shuffle'", ")", "\n", "\n", "", "if", "batch_sampler", "is", "not", "None", ":", "\n", "# auto_collation with custom batch_sampler", "\n", "            ", "if", "batch_size", "!=", "1", "or", "shuffle", "or", "sampler", "is", "not", "None", "or", "drop_last", ":", "\n", "                ", "raise", "ValueError", "(", "'batch_sampler option is mutually exclusive '", "\n", "'with batch_size, shuffle, sampler, and '", "\n", "'drop_last'", ")", "\n", "", "batch_size", "=", "None", "\n", "drop_last", "=", "False", "\n", "", "elif", "batch_size", "is", "None", ":", "\n", "# no auto_collation", "\n", "            ", "if", "shuffle", "or", "drop_last", ":", "\n", "                ", "raise", "ValueError", "(", "'batch_size=None option disables auto-batching '", "\n", "'and is mutually exclusive with '", "\n", "'shuffle, and drop_last'", ")", "\n", "\n", "", "", "if", "sampler", "is", "None", ":", "# give default samplers", "\n", "            ", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# See NOTE [ Custom Samplers and IterableDataset ]", "\n", "                ", "sampler", "=", "_InfiniteConstantSampler", "(", ")", "\n", "", "else", ":", "# map-style", "\n", "                ", "if", "shuffle", ":", "\n", "                    ", "sampler", "=", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "                    ", "sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "\n", "", "", "", "if", "batch_size", "is", "not", "None", "and", "batch_sampler", "is", "None", ":", "\n", "# auto_collation without custom batch_sampler", "\n", "            ", "batch_sampler", "=", "BatchSampler", "(", "sampler", ",", "batch_size", ",", "drop_last", ")", "\n", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "batch_sampler", "=", "batch_sampler", "\n", "\n", "if", "collate_fn", "is", "None", ":", "\n", "            ", "if", "self", ".", "_auto_collation", ":", "\n", "                ", "collate_fn", "=", "_utils", ".", "collate", ".", "default_collate", "\n", "", "else", ":", "\n", "                ", "collate_fn", "=", "_utils", ".", "collate", ".", "default_convert", "\n", "\n", "", "", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "__initialized", "=", "True", "\n", "self", ".", "_IterableDataset_len_called", "=", "None", "# See NOTE [ IterableDataset and __len__ ]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader.__len__": [[297, 317], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# NOTE [ IterableDataset and __len__ ]", "\n", "#", "\n", "# For `IterableDataset`, `__len__` could be inaccurate when one naively", "\n", "# does multi-processing data loading, since the samples will be duplicated.", "\n", "# However, no real use case should be actually using that behavior, so", "\n", "# it should count as a user error. We should generally trust user", "\n", "# code to do the proper thing (e.g., configure each replica differently", "\n", "# in `__iter__`), and give us the correct `__len__` if they choose to", "\n", "# implement it (this will still throw if the dataset does not implement", "\n", "# a `__len__`).", "\n", "#", "\n", "# To provide a further warning, we track if `__len__` was called on the", "\n", "# `DataLoader`, save the returned value in `self._len_called`, and warn", "\n", "# if the iterator ends up yielding more than this number of samples.", "\n", "            ", "length", "=", "self", ".", "_IterableDataset_len_called", "=", "len", "(", "self", ".", "dataset", ")", "\n", "return", "length", "\n", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "_index_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader.__iter__": [[275, 280], ["dataloader._SingleProcessDataLoaderIter", "dataloader._MultiProcessingDataLoaderIter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_workers", "==", "0", ":", "\n", "            ", "return", "_SingleProcessDataLoaderIter", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "_MultiProcessingDataLoaderIter", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter.__init__": [[320, 334], ["iter", "torch.empty().random_().item", "torch.empty().random_().item", "torch.empty().random_().item", "torch.empty().random_().item", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.empty().random_", "torch.empty().random_", "torch.empty().random_", "torch.empty().random_", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "self", ".", "_dataset", "=", "loader", ".", "dataset", "\n", "self", ".", "_dataset_kind", "=", "loader", ".", "_dataset_kind", "\n", "self", ".", "_IterableDataset_len_called", "=", "loader", ".", "_IterableDataset_len_called", "\n", "self", ".", "_auto_collation", "=", "loader", ".", "_auto_collation", "\n", "self", ".", "_drop_last", "=", "loader", ".", "drop_last", "\n", "self", ".", "_index_sampler", "=", "loader", ".", "_index_sampler", "\n", "self", ".", "_num_workers", "=", "loader", ".", "num_workers", "\n", "self", ".", "_pin_memory", "=", "loader", ".", "pin_memory", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "self", ".", "_timeout", "=", "loader", ".", "timeout", "\n", "self", ".", "_collate_fn", "=", "loader", ".", "collate_fn", "\n", "self", ".", "_sampler_iter", "=", "iter", "(", "self", ".", "_index_sampler", ")", "\n", "self", ".", "_base_seed", "=", "torch", ".", "empty", "(", "(", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "random_", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_num_yielded", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter.__len__": [[362, 364], ["len"], "methods", ["None"], ["def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_index_sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter.__iter__": [[335, 337], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter.__next__": [[344, 359], ["dataloader._BaseDataLoaderIter._next_data", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._next_data"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "_next_data", "(", ")", "\n", "self", ".", "_num_yielded", "+=", "1", "\n", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", "and", "self", ".", "_IterableDataset_len_called", "is", "not", "None", "and", "self", ".", "_num_yielded", ">", "self", ".", "_IterableDataset_len_called", ":", "\n", "            ", "warn_msg", "=", "(", "\"Length of IterableDataset {} was reported to be {} (when accessing len(dataloader)), but {} \"", "\n", "\"samples have been fetched. \"", ")", ".", "format", "(", "self", ".", "_dataset", ",", "self", ".", "_IterableDataset_len_called", ",", "\n", "self", ".", "_num_yielded", ")", "\n", "if", "self", ".", "_num_workers", ">", "0", ":", "\n", "                ", "warn_msg", "+=", "(", "\"For multiprocessing data-loading, this could be caused by not properly configuring the \"", "\n", "\"IterableDataset replica at each worker. Please see \"", "\n", "\"https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\"", ")", "\n", "", "warnings", ".", "warn", "(", "warn_msg", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.default_collate": [[13, 14], ["None"], "function", ["None"], ["import", "torch", "\n", "import", "torch", ".", "multiprocessing", "as", "multiprocessing", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.receptivesize.reseq": [[57, 80], ["isinstance", "receptivesize.reseq", "isinstance", "module._get_name", "print", "isinstance", "module.named_children", "isinstance", "str", "print", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.receptivesize.reseq"], ["def", "reseq", "(", "module", ",", "layer_size", ",", "name", "=", "None", ",", "seqnum", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "module", ",", "nn", ".", "Sequential", ")", ":", "\n", "        ", "reseq", "(", "module", ",", "layer_size", ",", "name", ",", "seqnum", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "nn", ".", "Conv2d", ",", "nn", ".", "MaxPool2d", ")", ")", ":", "\n", "        ", "kernel_size", "=", "module", ".", "kernel_size", "\n", "stride_size", "=", "module", ".", "stride", "\n", "padding_size", "=", "module", ".", "padding", "\n", "subname", "=", "module", ".", "_get_name", "(", ")", "\n", "print", "(", "name", "+", "'.'", "+", "str", "(", "seqnum", ")", ",", "kernel_size", ",", "stride_size", ",", "padding_size", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "layer_size", "[", "name", "+", "'.'", "+", "str", "(", "seqnum", ")", "+", "'.'", "+", "subname", "]", "=", "[", "kernel_size", "[", "0", "]", ",", "stride_size", "[", "0", "]", ",", "padding_size", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "layer_size", "[", "name", "+", "'.'", "+", "str", "(", "seqnum", ")", "+", "'.'", "+", "subname", "]", "=", "[", "kernel_size", ",", "stride_size", ",", "padding_size", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "for", "m", "in", "module", ".", "named_children", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", "[", "-", "1", "]", ",", "(", "nn", ".", "Conv2d", ",", "nn", ".", "MaxPool2d", ")", ")", ":", "\n", "                ", "kernel_size", "=", "m", "[", "-", "1", "]", ".", "kernel_size", "[", "0", "]", "\n", "stride_size", "=", "m", "[", "-", "1", "]", ".", "stride", "[", "0", "]", "\n", "padding_size", "=", "m", "[", "-", "1", "]", ".", "padding", "[", "0", "]", "\n", "subname", "=", "m", "[", "0", "]", "\n", "print", "(", "name", "+", "'.'", "+", "str", "(", "seqnum", ")", "+", "'.'", "+", "subname", ",", "kernel_size", ",", "stride_size", ",", "padding_size", ")", "\n", "layer_size", "[", "name", "+", "'.'", "+", "str", "(", "seqnum", ")", "+", "'.'", "+", "subname", "]", "=", "[", "kernel_size", ",", "stride_size", ",", "padding_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.receptivesize.outFromIn": [[105, 123], ["math.ceil", "math.floor", "math.floor"], "function", ["None"], ["def", "outFromIn", "(", "conv", ",", "layerIn", ")", ":", "\n", "    ", "n_in", "=", "layerIn", "[", "0", "]", "# input feature dimension", "\n", "j_in", "=", "layerIn", "[", "1", "]", "# jumps", "\n", "r_in", "=", "layerIn", "[", "2", "]", "# receptive field", "\n", "start_in", "=", "layerIn", "[", "3", "]", "\n", "k", "=", "conv", "[", "0", "]", "# kernel size", "\n", "s", "=", "conv", "[", "1", "]", "# strides", "\n", "p", "=", "conv", "[", "2", "]", "# padding", "\n", "\n", "n_out", "=", "math", ".", "floor", "(", "(", "n_in", "-", "k", "+", "2", "*", "p", ")", "/", "s", ")", "+", "1", "\n", "actualP", "=", "(", "n_out", "-", "1", ")", "*", "s", "-", "n_in", "+", "k", "# the total actual padding size", "\n", "pR", "=", "math", ".", "ceil", "(", "actualP", "/", "2", ")", "\n", "pL", "=", "math", ".", "floor", "(", "actualP", "/", "2", ")", "\n", "\n", "j_out", "=", "j_in", "*", "s", "\n", "r_out", "=", "r_in", "+", "(", "k", "-", "1", ")", "*", "j_in", "\n", "start_out", "=", "start_in", "+", "(", "(", "k", "-", "1", ")", "/", "2", "-", "pL", ")", "*", "j_in", "\n", "return", "n_out", ",", "j_out", ",", "r_out", ",", "start_out", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.receptivesize.printLayer": [[125, 129], ["print", "print"], "function", ["None"], ["", "def", "printLayer", "(", "layer", ",", "layer_name", ")", ":", "\n", "    ", "print", "(", "layer_name", "+", "\":\"", ")", "\n", "print", "(", "\"\\t n features: %s \\n \\t jump: %s \\n \\t receptive size: %s \\t start: %s \"", "%", "(", "\n", "layer", "[", "0", "]", ",", "layer", "[", "1", "]", ",", "layer", "[", "2", "]", ",", "layer", "[", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.IterableDataset.__add__": [[141, 143], ["dataset.ChainDataset"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "ChainDataset", "(", "[", "self", ",", "other", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.TensorDataset.__getitem__": [[161, 163], ["tuple"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "tuple", "(", "tensor", "[", "index", "]", "for", "tensor", "in", "self", ".", "tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.TensorDataset.__len__": [[164, 166], ["dataset.TensorDataset.tensors[].size"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tensors", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.cumsum": [[177, 185], ["len", "r.append"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ")", ":", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "e", "in", "sequence", ":", "\n", "            ", "l", "=", "len", "(", "e", ")", "\n", "r", ".", "append", "(", "l", "+", "s", ")", "\n", "s", "+=", "l", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.__len__": [[194, 196], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cumulative_sizes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.__getitem__": [[197, 208], ["bisect.bisect_right", "len", "ValueError", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "0", ":", "\n", "            ", "if", "-", "idx", ">", "len", "(", "self", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"absolute value of index should not exceed dataset length\"", ")", "\n", "", "idx", "=", "len", "(", "self", ")", "+", "idx", "\n", "", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "idx", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "return", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ConcatDataset.cummulative_sizes": [[209, 214], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "cummulative_sizes", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"cummulative_sizes attribute is renamed to \"", "\n", "\"cumulative_sizes\"", ",", "DeprecationWarning", ",", "stacklevel", "=", "2", ")", "\n", "return", "self", ".", "cumulative_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ChainDataset.__init__": [[226, 229], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "super", "(", "ChainDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "datasets", "=", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ChainDataset.__iter__": [[230, 235], ["isinstance"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "d", "in", "self", ".", "datasets", ":", "\n", "            ", "assert", "isinstance", "(", "d", ",", "IterableDataset", ")", ",", "\"ChainDataset only supports IterableDataset\"", "\n", "for", "x", "in", "d", ":", "\n", "                ", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.ChainDataset.__len__": [[236, 242], ["isinstance", "len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "total", "=", "0", "\n", "for", "d", "in", "self", ".", "datasets", ":", "\n", "            ", "assert", "isinstance", "(", "d", ",", "IterableDataset", ")", ",", "\"ChainDataset only supports IterableDataset\"", "\n", "total", "+=", "len", "(", "d", ")", "\n", "", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Subset.__getitem__": [[256, 258], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "dataset", "[", "self", ".", "indices", "[", "idx", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataset.Subset.__len__": [[259, 261], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SequentialSampler.__init__": [[58, 60], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SequentialSampler.__iter__": [[61, 63], ["iter", "range", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "range", "(", "len", "(", "self", ".", "data_source", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SequentialSampler.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.RandomSampler.num_samples": [[96, 102], ["len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "num_samples", "(", "self", ")", ":", "\n", "# dataset size might change at runtime", "\n", "        ", "if", "self", ".", "_num_samples", "is", "None", ":", "\n", "            ", "return", "len", "(", "self", ".", "data_source", ")", "\n", "", "return", "self", ".", "_num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.RandomSampler.__iter__": [[103, 108], ["len", "iter", "iter", "torch.randperm().tolist", "torch.randint().tolist", "torch.randperm", "torch.randint"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "n", "=", "len", "(", "self", ".", "data_source", ")", "\n", "if", "self", ".", "replacement", ":", "\n", "            ", "return", "iter", "(", "torch", ".", "randint", "(", "high", "=", "n", ",", "size", "=", "(", "self", ".", "num_samples", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "tolist", "(", ")", ")", "\n", "", "return", "iter", "(", "torch", ".", "randperm", "(", "n", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.RandomSampler.__len__": [[109, 111], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SubsetRandomSampler.__iter__": [[123, 125], ["torch.randperm", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "indices", "[", "i", "]", "for", "i", "in", "torch", ".", "randperm", "(", "len", "(", "self", ".", "indices", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.SubsetRandomSampler.__len__": [[126, 128], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.WeightedRandomSampler.__iter__": [[159, 161], ["iter", "torch.multinomial().tolist", "torch.multinomial"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "torch", ".", "multinomial", "(", "self", ".", "weights", ",", "self", ".", "num_samples", ",", "self", ".", "replacement", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.WeightedRandomSampler.__len__": [[162, 164], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.BatchSampler.__iter__": [[198, 207], ["batch.append", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "batch", "=", "[", "]", "\n", "for", "idx", "in", "self", ".", "sampler", ":", "\n", "            ", "batch", ".", "append", "(", "idx", ")", "\n", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "batch", "\n", "batch", "=", "[", "]", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", "and", "not", "self", ".", "drop_last", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.sampler.BatchSampler.__len__": [[208, 213], ["len", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "drop_last", ":", "\n", "            ", "return", "len", "(", "self", ".", "sampler", ")", "//", "self", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "return", "(", "len", "(", "self", ".", "sampler", ")", "+", "self", ".", "batch_size", "-", "1", ")", "//", "self", ".", "batch_size", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.misc.SoftSigmoid.__init__": [[7, 11], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SoftSigmoid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.misc.SoftSigmoid.forward": [[12, 17], ["torch.reciprocal", "torch.reciprocal", "torch.reciprocal", "torch.reciprocal", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.neg", "torch.neg", "torch.neg", "torch.neg", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "sval", "=", "torch", ".", "reciprocal", "(", "1", "+", "torch", ".", "exp", "(", "torch", ".", "neg", "(", "torch", ".", "mul", "(", "x", ",", "self", ".", "weight", ")", "+", "self", ".", "bias", ")", ")", ")", "\n", "\n", "return", "sval", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.misc.SoftCrossEntropy": [[18, 27], ["torch.div", "torch.div", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.neg", "torch.neg", "torch.log", "torch.log"], "function", ["None"], ["", "", "def", "SoftCrossEntropy", "(", "p", ",", "q", ")", ":", "\n", "\n", "    ", "assert", "p", ".", "shape", "==", "q", ".", "shape", ",", "'the size of p and q must be euqal.'", "\n", "\n", "nsamples", "=", "p", ".", "shape", "[", "0", "]", "\n", "\n", "loss", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "p", ",", "torch", ".", "neg", "(", "torch", ".", "log", "(", "q", ")", ")", ")", ")", ",", "nsamples", ")", "\n", "\n", "return", "loss", "\n", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._DatasetKind.create_fetcher": [[36, 42], ["_utils.fetch._MapDatasetFetcher", "_utils.fetch._IterableDatasetFetcher"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "create_fetcher", "(", "kind", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", ":", "\n", "        ", "if", "kind", "==", "_DatasetKind", ".", "Map", ":", "\n", "            ", "return", "_utils", ".", "fetch", ".", "_MapDatasetFetcher", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "", "else", ":", "\n", "            ", "return", "_utils", ".", "fetch", ".", "_IterableDatasetFetcher", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._InfiniteConstantSampler.__init__": [[52, 54], ["Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "_InfiniteConstantSampler", ",", "self", ")", ".", "__init__", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._InfiniteConstantSampler.__iter__": [[55, 58], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader.multiprocessing_context": [[240, 267], ["isinstance", "ValueError", "ValueError", "multiprocessing.get_all_start_methods", "torch.get_all_start_methods", "torch.get_all_start_methods", "torch.get_all_start_methods", "multiprocessing.get_context", "torch.get_context", "torch.get_context", "torch.get_context", "isinstance", "ValueError", "ValueError"], "methods", ["None"], ["", "@", "multiprocessing_context", ".", "setter", "\n", "def", "multiprocessing_context", "(", "self", ",", "multiprocessing_context", ")", ":", "\n", "        ", "if", "multiprocessing_context", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_workers", ">", "0", ":", "\n", "                ", "if", "not", "multiprocessing", ".", "_supports_context", ":", "\n", "                    ", "raise", "ValueError", "(", "'multiprocessing_context relies on Python >= 3.4, with '", "\n", "'support for different start methods'", ")", "\n", "\n", "", "if", "isinstance", "(", "multiprocessing_context", ",", "string_classes", ")", ":", "\n", "                    ", "valid_start_methods", "=", "multiprocessing", ".", "get_all_start_methods", "(", ")", "\n", "if", "multiprocessing_context", "not", "in", "valid_start_methods", ":", "\n", "                        ", "raise", "ValueError", "(", "\n", "(", "'multiprocessing_context option '", "\n", "'should specify a valid start method in {}, but got '", "\n", "'multiprocessing_context={}'", ")", ".", "format", "(", "valid_start_methods", ",", "multiprocessing_context", ")", ")", "\n", "", "multiprocessing_context", "=", "multiprocessing", ".", "get_context", "(", "multiprocessing_context", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "multiprocessing_context", ",", "python_multiprocessing", ".", "context", ".", "BaseContext", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "(", "'multiprocessing_context option should be a valid context '", "\n", "'object or a string specifying the start method, but got '", "\n", "'multiprocessing_context={}'", ")", ".", "format", "(", "multiprocessing_context", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "(", "'multiprocessing_context can only be used with '", "\n", "'multi-process loading (num_workers > 0), but got '", "\n", "'num_workers={}'", ")", ".", "format", "(", "self", ".", "num_workers", ")", ")", "\n", "\n", "", "", "self", ".", "__multiprocessing_context", "=", "multiprocessing_context", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader.__setattr__": [[268, 274], ["object.__setattr__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.WorkerInfo.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "attr", ",", "val", ")", ":", "\n", "        ", "if", "self", ".", "__initialized", "and", "attr", "in", "(", "'batch_size'", ",", "'batch_sampler'", ",", "'sampler'", ",", "'drop_last'", ",", "'dataset'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'{} attribute should not be set after {} is '", "\n", "'initialized'", ".", "format", "(", "attr", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "\n", "", "super", "(", "DataLoader", ",", "self", ")", ".", "__setattr__", "(", "attr", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader._auto_collation": [[281, 284], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "_auto_collation", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "batch_sampler", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader.DataLoader._index_sampler": [[285, 296], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_index_sampler", "(", "self", ")", ":", "\n", "# The actual sampler used for generating indices for `_DatasetFetcher`", "\n", "# (see _utils/fetch.py) to read data at each time. This would be", "\n", "# `.batch_sampler` if in auto-collation mode, and `.sampler` otherwise.", "\n", "# We can't change `.sampler` and `.batch_sampler` attributes for BC", "\n", "# reasons.", "\n", "        ", "if", "self", ".", "_auto_collation", ":", "\n", "            ", "return", "self", ".", "batch_sampler", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_index": [[338, 340], ["next"], "methods", ["None"], ["", "def", "_next_index", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "_sampler_iter", ")", "# may raise StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_data": [[341, 343], ["None"], "methods", ["None"], ["", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter.__getstate__": [[365, 372], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "# TODO: add limited pickling support for sharing an iterator", "\n", "# across multiple threads for HOGWILD.", "\n", "# Probably the best way to do this is by moving the sample pushing", "\n", "# to a separate thread and then just sharing the data queue", "\n", "# but signalling the end is tricky without a non-blocking API", "\n", "        ", "raise", "NotImplementedError", "(", "\"{} cannot be pickled\"", ",", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._SingleProcessDataLoaderIter.__init__": [[375, 382], ["dataloader._BaseDataLoaderIter.__init__", "dataloader._DatasetKind.create_fetcher"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._DatasetKind.create_fetcher"], ["    ", "def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "super", "(", "_SingleProcessDataLoaderIter", ",", "self", ")", ".", "__init__", "(", "loader", ")", "\n", "assert", "self", ".", "_timeout", "==", "0", "\n", "assert", "self", ".", "_num_workers", "==", "0", "\n", "\n", "self", ".", "_dataset_fetcher", "=", "_DatasetKind", ".", "create_fetcher", "(", "\n", "self", ".", "_dataset_kind", ",", "self", ".", "_dataset", ",", "self", ".", "_auto_collation", ",", "self", ".", "_collate_fn", ",", "self", ".", "_drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._SingleProcessDataLoaderIter._next_data": [[383, 389], ["dataloader._SingleProcessDataLoaderIter._next_index", "dataloader._SingleProcessDataLoaderIter._dataset_fetcher.fetch", "_utils.pin_memory.pin_memory"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_index", "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.fetch", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory"], ["", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "index", "=", "self", ".", "_next_index", "(", ")", "# may raise StopIteration", "\n", "data", "=", "self", ".", "_dataset_fetcher", ".", "fetch", "(", "index", ")", "# may raise StopIteration", "\n", "if", "self", ".", "_pin_memory", ":", "\n", "            ", "data", "=", "_utils", ".", "pin_memory", ".", "pin_memory", "(", "data", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter.__init__": [[672, 747], ["dataloader._BaseDataLoaderIter.__init__", "itertools.cycle", "multiprocessing_context.Queue", "multiprocessing_context.Event", "range", "_utils.signal_handling._set_worker_pids", "_utils.signal_handling._set_SIGCHLD_handler", "range", "range", "multiprocessing_context.Queue", "multiprocessing_context.Process", "multiprocessing_context.Process.start", "dataloader._MultiProcessingDataLoaderIter._index_queues.append", "dataloader._MultiProcessingDataLoaderIter._workers.append", "dataloader._MultiProcessingDataLoaderIter._workers_status.append", "threading.Event", "torch._six.queue.Queue", "torch._six.queue.Queue", "threading.Thread", "threading.Thread.start", "id", "tuple", "dataloader._MultiProcessingDataLoaderIter._try_put_index", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__", "home.repos.pwc.inspect_result.cswluo_SEF._utils.signal_handling._set_SIGCHLD_handler", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["def", "__init__", "(", "self", ",", "loader", ")", ":", "\n", "        ", "super", "(", "_MultiProcessingDataLoaderIter", ",", "self", ")", ".", "__init__", "(", "loader", ")", "\n", "\n", "assert", "self", ".", "_num_workers", ">", "0", "\n", "\n", "if", "loader", ".", "multiprocessing_context", "is", "None", ":", "\n", "            ", "multiprocessing_context", "=", "multiprocessing", "\n", "", "else", ":", "\n", "            ", "multiprocessing_context", "=", "loader", ".", "multiprocessing_context", "\n", "\n", "", "self", ".", "_worker_init_fn", "=", "loader", ".", "worker_init_fn", "\n", "self", ".", "_worker_queue_idx_cycle", "=", "itertools", ".", "cycle", "(", "range", "(", "self", ".", "_num_workers", ")", ")", "\n", "self", ".", "_worker_result_queue", "=", "multiprocessing_context", ".", "Queue", "(", ")", "\n", "self", ".", "_worker_pids_set", "=", "False", "\n", "self", ".", "_shutdown", "=", "False", "\n", "self", ".", "_send_idx", "=", "0", "# idx of the next task to be sent to workers", "\n", "self", ".", "_rcvd_idx", "=", "0", "# idx of the next task to be returned in __next__", "\n", "# information about data not yet yielded, i.e., tasks w/ indices in range [rcvd_idx, send_idx).", "\n", "# map: task idx => - (worker_id,)        if data isn't fetched (outstanding)", "\n", "#                  \\ (worker_id, data)   if data is already fetched (out-of-order)", "\n", "self", ".", "_task_info", "=", "{", "}", "\n", "self", ".", "_tasks_outstanding", "=", "0", "# always equal to count(v for v in task_info.values() if len(v) == 1)", "\n", "self", ".", "_workers_done_event", "=", "multiprocessing_context", ".", "Event", "(", ")", "\n", "\n", "self", ".", "_index_queues", "=", "[", "]", "\n", "self", ".", "_workers", "=", "[", "]", "\n", "# A list of booleans representing whether each worker still has work to", "\n", "# do, i.e., not having exhausted its iterable dataset object. It always", "\n", "# contains all `True`s if not using an iterable-style dataset", "\n", "# (i.e., if kind != Iterable).", "\n", "self", ".", "_workers_status", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_workers", ")", ":", "\n", "            ", "index_queue", "=", "multiprocessing_context", ".", "Queue", "(", ")", "\n", "# index_queue.cancel_join_thread()", "\n", "w", "=", "multiprocessing_context", ".", "Process", "(", "\n", "target", "=", "_utils", ".", "worker", ".", "_worker_loop", ",", "\n", "args", "=", "(", "self", ".", "_dataset_kind", ",", "self", ".", "_dataset", ",", "index_queue", ",", "\n", "self", ".", "_worker_result_queue", ",", "self", ".", "_workers_done_event", ",", "\n", "self", ".", "_auto_collation", ",", "self", ".", "_collate_fn", ",", "self", ".", "_drop_last", ",", "\n", "self", ".", "_base_seed", "+", "i", ",", "self", ".", "_worker_init_fn", ",", "i", ",", "self", ".", "_num_workers", ")", ")", "\n", "w", ".", "daemon", "=", "True", "\n", "# NB: Process.start() actually take some time as it needs to", "\n", "#     start a process and pass the arguments over via a pipe.", "\n", "#     Therefore, we only add a worker to self._workers list after", "\n", "#     it started, so that we do not call .join() if program dies", "\n", "#     before it starts, and __del__ tries to join but will get:", "\n", "#     AssertionError: can only join a started process.", "\n", "w", ".", "start", "(", ")", "\n", "self", ".", "_index_queues", ".", "append", "(", "index_queue", ")", "\n", "self", ".", "_workers", ".", "append", "(", "w", ")", "\n", "self", ".", "_workers_status", ".", "append", "(", "True", ")", "\n", "\n", "", "if", "self", ".", "_pin_memory", ":", "\n", "            ", "self", ".", "_pin_memory_thread_done_event", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "_data_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "pin_memory_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "_utils", ".", "pin_memory", ".", "_pin_memory_loop", ",", "\n", "args", "=", "(", "self", ".", "_worker_result_queue", ",", "self", ".", "_data_queue", ",", "\n", "torch", ".", "cuda", ".", "current_device", "(", ")", ",", "\n", "self", ".", "_pin_memory_thread_done_event", ")", ")", "\n", "pin_memory_thread", ".", "daemon", "=", "True", "\n", "pin_memory_thread", ".", "start", "(", ")", "\n", "# Similar to workers (see comment above), we only register", "\n", "# pin_memory_thread once it is started.", "\n", "self", ".", "_pin_memory_thread", "=", "pin_memory_thread", "\n", "", "else", ":", "\n", "            ", "self", ".", "_data_queue", "=", "self", ".", "_worker_result_queue", "\n", "\n", "", "_utils", ".", "signal_handling", ".", "_set_worker_pids", "(", "id", "(", "self", ")", ",", "tuple", "(", "w", ".", "pid", "for", "w", "in", "self", ".", "_workers", ")", ")", "\n", "_utils", ".", "signal_handling", ".", "_set_SIGCHLD_handler", "(", ")", "\n", "self", ".", "_worker_pids_set", "=", "True", "\n", "\n", "# prime the prefetch loop", "\n", "for", "_", "in", "range", "(", "2", "*", "self", ".", "_num_workers", ")", ":", "\n", "            ", "self", ".", "_try_put_index", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data": [[748, 778], ["dataloader._MultiProcessingDataLoaderIter._data_queue.get", "enumerate", "isinstance", "len", "RuntimeError", "failed_workers.append", "dataloader._MultiProcessingDataLoaderIter._shutdown_worker", "w.is_alive", "str"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker"], ["", "", "def", "_try_get_data", "(", "self", ",", "timeout", "=", "_utils", ".", "MP_STATUS_CHECK_INTERVAL", ")", ":", "\n", "# Tries to fetch data from `self._data_queue` once for a given timeout.", "\n", "# This can also be used as inner loop of fetching without timeout, with", "\n", "# the sender status as the loop condition.", "\n", "#", "\n", "# This raises a `RuntimeError` if any worker died expectedly. This error", "\n", "# can come from either the SIGCHLD handler in `_utils/signal_handling.py`", "\n", "# (only for non-Windows platforms), or the manual check below on errors", "\n", "# and timeouts.", "\n", "#", "\n", "# Returns a 2-tuple:", "\n", "#   (bool: whether successfully get data, any: data if successful else None)", "\n", "        ", "try", ":", "\n", "            ", "data", "=", "self", ".", "_data_queue", ".", "get", "(", "timeout", "=", "timeout", ")", "\n", "return", "(", "True", ",", "data", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# At timeout and error, we manually check whether any worker has", "\n", "# failed. Note that this is the only mechanism for Windows to detect", "\n", "# worker failures.", "\n", "            ", "failed_workers", "=", "[", "]", "\n", "for", "worker_id", ",", "w", "in", "enumerate", "(", "self", ".", "_workers", ")", ":", "\n", "                ", "if", "self", ".", "_workers_status", "[", "worker_id", "]", "and", "not", "w", ".", "is_alive", "(", ")", ":", "\n", "                    ", "failed_workers", ".", "append", "(", "w", ")", "\n", "self", ".", "_shutdown_worker", "(", "worker_id", ")", "\n", "", "", "if", "len", "(", "failed_workers", ")", ">", "0", ":", "\n", "                ", "pids_str", "=", "', '", ".", "join", "(", "str", "(", "w", ".", "pid", ")", "for", "w", "in", "failed_workers", ")", "\n", "raise", "RuntimeError", "(", "'DataLoader worker (pid(s) {}) exited unexpectedly'", ".", "format", "(", "pids_str", ")", ")", "\n", "", "if", "isinstance", "(", "e", ",", "queue", ".", "Empty", ")", ":", "\n", "                ", "return", "(", "False", ",", "None", ")", "\n", "", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._get_data": [[779, 811], ["dataloader._MultiProcessingDataLoaderIter._try_get_data", "RuntimeError", "dataloader._MultiProcessingDataLoaderIter._pin_memory_thread.is_alive", "dataloader._MultiProcessingDataLoaderIter._try_get_data", "RuntimeError", "dataloader._MultiProcessingDataLoaderIter._try_get_data"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_get_data"], ["", "", "def", "_get_data", "(", "self", ")", ":", "\n", "# Fetches data from `self._data_queue`.", "\n", "#", "\n", "# We check workers' status every `MP_STATUS_CHECK_INTERVAL` seconds,", "\n", "# which we achieve by running `self._try_get_data(timeout=MP_STATUS_CHECK_INTERVAL)`", "\n", "# in a loop. This is the only mechanism to detect worker failures for", "\n", "# Windows. For other platforms, a SIGCHLD handler is also used for", "\n", "# worker failure detection.", "\n", "#", "\n", "# If `pin_memory=True`, we also need check if `pin_memory_thread` had", "\n", "# died at timeouts.", "\n", "        ", "if", "self", ".", "_timeout", ">", "0", ":", "\n", "            ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", "self", ".", "_timeout", ")", "\n", "if", "success", ":", "\n", "                ", "return", "data", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "'DataLoader timed out after {} seconds'", ".", "format", "(", "self", ".", "_timeout", ")", ")", "\n", "", "", "elif", "self", ".", "_pin_memory", ":", "\n", "            ", "while", "self", ".", "_pin_memory_thread", ".", "is_alive", "(", ")", ":", "\n", "                ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", ")", "\n", "if", "success", ":", "\n", "                    ", "return", "data", "\n", "", "", "else", ":", "\n", "# while condition is false, i.e., pin_memory_thread died.", "\n", "                ", "raise", "RuntimeError", "(", "'Pin memory thread exited unexpectedly'", ")", "\n", "# In this case, `self._data_queue` is a `queue.Queue`,. But we don't", "\n", "# need to call `.task_done()` because we don't use `.join()`.", "\n", "", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "success", ",", "data", "=", "self", ".", "_try_get_data", "(", ")", "\n", "if", "success", ":", "\n", "                    ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._next_data": [[812, 857], ["dataloader._MultiProcessingDataLoaderIter._get_data", "dataloader._MultiProcessingDataLoaderIter._shutdown_workers", "len", "dataloader._MultiProcessingDataLoaderIter._process_data", "isinstance", "dataloader._MultiProcessingDataLoaderIter._process_data", "dataloader._MultiProcessingDataLoaderIter._task_info.pop", "dataloader._MultiProcessingDataLoaderIter._shutdown_worker", "dataloader._MultiProcessingDataLoaderIter._try_put_index", "len"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._get_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_workers", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._process_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._process_data", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker", "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["", "", "", "", "def", "_next_data", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "# If the worker responsible for `self._rcvd_idx` has already ended", "\n", "# and was unable to fulfill this task (due to exhausting an `IterableDataset`),", "\n", "# we try to advance `self._rcvd_idx` to find the next valid index.", "\n", "#", "\n", "# This part needs to run in the loop because both the `self._get_data()`", "\n", "# call and `_IterableDatasetStopIteration` check below can mark", "\n", "# extra worker(s) as dead.", "\n", "            ", "while", "self", ".", "_rcvd_idx", "<", "self", ".", "_send_idx", ":", "\n", "                ", "info", "=", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", "\n", "worker_id", "=", "info", "[", "0", "]", "\n", "if", "len", "(", "info", ")", "==", "2", "or", "self", ".", "_workers_status", "[", "worker_id", "]", ":", "# has data or is still active", "\n", "                    ", "break", "\n", "", "del", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", "\n", "self", ".", "_rcvd_idx", "+=", "1", "\n", "", "else", ":", "\n", "# no valid `self._rcvd_idx` is found (i.e., didn't break)", "\n", "                ", "self", ".", "_shutdown_workers", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Now `self._rcvd_idx` is the batch index we want to fetch", "\n", "\n", "# Check if the next sample has already been generated", "\n", "", "if", "len", "(", "self", ".", "_task_info", "[", "self", ".", "_rcvd_idx", "]", ")", "==", "2", ":", "\n", "                ", "data", "=", "self", ".", "_task_info", ".", "pop", "(", "self", ".", "_rcvd_idx", ")", "[", "1", "]", "\n", "return", "self", ".", "_process_data", "(", "data", ")", "\n", "\n", "", "assert", "not", "self", ".", "_shutdown", "and", "self", ".", "_tasks_outstanding", ">", "0", "\n", "idx", ",", "data", "=", "self", ".", "_get_data", "(", ")", "\n", "self", ".", "_tasks_outstanding", "-=", "1", "\n", "\n", "if", "self", ".", "_dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "# Check for _IterableDatasetStopIteration", "\n", "                ", "if", "isinstance", "(", "data", ",", "_utils", ".", "worker", ".", "_IterableDatasetStopIteration", ")", ":", "\n", "                    ", "self", ".", "_shutdown_worker", "(", "data", ".", "worker_id", ")", "\n", "self", ".", "_try_put_index", "(", ")", "\n", "continue", "\n", "\n", "", "", "if", "idx", "!=", "self", ".", "_rcvd_idx", ":", "\n", "# store out-of-order samples", "\n", "                ", "self", ".", "_task_info", "[", "idx", "]", "+=", "(", "data", ",", ")", "\n", "", "else", ":", "\n", "                ", "del", "self", ".", "_task_info", "[", "idx", "]", "\n", "return", "self", ".", "_process_data", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index": [[858, 876], ["range", "dataloader._MultiProcessingDataLoaderIter._index_queues[].put", "dataloader._MultiProcessingDataLoaderIter._next_index", "next"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._BaseDataLoaderIter._next_index"], ["", "", "", "def", "_try_put_index", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "_tasks_outstanding", "<", "2", "*", "self", ".", "_num_workers", "\n", "try", ":", "\n", "            ", "index", "=", "self", ".", "_next_index", "(", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "\n", "", "for", "_", "in", "range", "(", "self", ".", "_num_workers", ")", ":", "# find the next active worker, if any", "\n", "            ", "worker_queue_idx", "=", "next", "(", "self", ".", "_worker_queue_idx_cycle", ")", "\n", "if", "self", ".", "_workers_status", "[", "worker_queue_idx", "]", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "# not found (i.e., didn't break)", "\n", "            ", "return", "\n", "\n", "", "self", ".", "_index_queues", "[", "worker_queue_idx", "]", ".", "put", "(", "(", "self", ".", "_send_idx", ",", "index", ")", ")", "\n", "self", ".", "_task_info", "[", "self", ".", "_send_idx", "]", "=", "(", "worker_queue_idx", ",", ")", "\n", "self", ".", "_tasks_outstanding", "+=", "1", "\n", "self", ".", "_send_idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._process_data": [[877, 883], ["dataloader._MultiProcessingDataLoaderIter._try_put_index", "isinstance", "data.reraise"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._try_put_index"], ["", "def", "_process_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "_rcvd_idx", "+=", "1", "\n", "self", ".", "_try_put_index", "(", ")", "\n", "if", "isinstance", "(", "data", ",", "ExceptionWrapper", ")", ":", "\n", "            ", "data", ".", "reraise", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker": [[884, 906], ["q.put"], "methods", ["None"], ["", "def", "_shutdown_worker", "(", "self", ",", "worker_id", ")", ":", "\n", "# Mark a worker as having finished its work and dead, e.g., due to", "\n", "# exhausting an `IterableDataset`. This should be used only when this", "\n", "# `_MultiProcessingDataLoaderIter` is going to continue running.", "\n", "\n", "        ", "assert", "self", ".", "_workers_status", "[", "worker_id", "]", "\n", "\n", "# Signal termination to that specific worker.", "\n", "q", "=", "self", ".", "_index_queues", "[", "worker_id", "]", "\n", "# Indicate that no more data will be put on this queue by the current", "\n", "# process.", "\n", "q", ".", "put", "(", "None", ")", "\n", "\n", "# Note that we don't actually join the worker here, nor do we remove the", "\n", "# worker's pid from C side struct because (1) joining may be slow, and", "\n", "# (2) since we don't join, the worker may still raise error, and we", "\n", "# prefer capturing those, rather than ignoring them, even though they", "\n", "# are raised after the worker has finished its job.", "\n", "# Joinning is deferred to `_shutdown_workers`, which it is called when", "\n", "# all workers finish their jobs (e.g., `IterableDataset` replicas) or", "\n", "# when this iterator is garbage collected.", "\n", "self", ".", "_workers_status", "[", "worker_id", "]", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_workers": [[907, 960], ["hasattr", "dataloader._MultiProcessingDataLoaderIter._workers_done_event.set", "range", "dataloader._MultiProcessingDataLoaderIter._pin_memory_thread_done_event.set", "dataloader._MultiProcessingDataLoaderIter._worker_result_queue.put", "dataloader._MultiProcessingDataLoaderIter._pin_memory_thread.join", "dataloader._MultiProcessingDataLoaderIter._worker_result_queue.cancel_join_thread", "dataloader._MultiProcessingDataLoaderIter._worker_result_queue.close", "len", "w.join", "q.cancel_join_thread", "q.close", "_utils.signal_handling._remove_worker_pids", "dataloader._MultiProcessingDataLoaderIter._shutdown_worker", "id"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_worker"], ["", "def", "_shutdown_workers", "(", "self", ")", ":", "\n", "# Called when shutting down this `_MultiProcessingDataLoaderIter`.", "\n", "# See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on", "\n", "# the logic of this function.", "\n", "        ", "python_exit_status", "=", "_utils", ".", "python_exit_status", "\n", "if", "python_exit_status", "is", "True", "or", "python_exit_status", "is", "None", ":", "\n", "# See (2) of the note. If Python is shutting down, do no-op.", "\n", "            ", "return", "\n", "# Normal exit when last reference is gone / iterator is depleted.", "\n", "# See (1) and the second half of the note.", "\n", "", "if", "not", "self", ".", "_shutdown", ":", "\n", "            ", "self", ".", "_shutdown", "=", "True", "\n", "try", ":", "\n", "# Exit `pin_memory_thread` first because exiting workers may leave", "\n", "# corrupted data in `worker_result_queue` which `pin_memory_thread`", "\n", "# reads from.", "\n", "                ", "if", "hasattr", "(", "self", ",", "'_pin_memory_thread'", ")", ":", "\n", "# Use hasattr in case error happens before we set the attribute.", "\n", "                    ", "self", ".", "_pin_memory_thread_done_event", ".", "set", "(", ")", "\n", "# Send something to pin_memory_thread in case it is waiting", "\n", "# so that it can wake up and check `pin_memory_thread_done_event`", "\n", "self", ".", "_worker_result_queue", ".", "put", "(", "(", "None", ",", "None", ")", ")", "\n", "self", ".", "_pin_memory_thread", ".", "join", "(", ")", "\n", "self", ".", "_worker_result_queue", ".", "cancel_join_thread", "(", ")", "\n", "self", ".", "_worker_result_queue", ".", "close", "(", ")", "\n", "\n", "# Exit workers now.", "\n", "", "self", ".", "_workers_done_event", ".", "set", "(", ")", "\n", "for", "worker_id", "in", "range", "(", "len", "(", "self", ".", "_workers", ")", ")", ":", "\n", "# Get number of workers from `len(self._workers)` instead of", "\n", "# `self._num_workers` in case we error before starting all", "\n", "# workers.", "\n", "                    ", "if", "self", ".", "_workers_status", "[", "worker_id", "]", ":", "\n", "                        ", "self", ".", "_shutdown_worker", "(", "worker_id", ")", "\n", "", "", "for", "w", "in", "self", ".", "_workers", ":", "\n", "                    ", "w", ".", "join", "(", ")", "\n", "", "for", "q", "in", "self", ".", "_index_queues", ":", "\n", "                    ", "q", ".", "cancel_join_thread", "(", ")", "\n", "q", ".", "close", "(", ")", "\n", "", "", "finally", ":", "\n", "# Even though all this function does is putting into queues that", "\n", "# we have called `cancel_join_thread` on, weird things can", "\n", "# happen when a worker is killed by a signal, e.g., hanging in", "\n", "# `Event.set()`. So we need to guard this with SIGCHLD handler,", "\n", "# and remove pids from the C side data structure only at the", "\n", "# end.", "\n", "#", "\n", "# FIXME: Unfortunately, for Windows, we are missing a worker", "\n", "#        error detection mechanism here in this function, as it", "\n", "#        doesn't provide a SIGCHLD handler.", "\n", "                ", "if", "self", ".", "_worker_pids_set", ":", "\n", "                    ", "_utils", ".", "signal_handling", ".", "_remove_worker_pids", "(", "id", "(", "self", ")", ")", "\n", "self", ".", "_worker_pids_set", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter.__del__": [[961, 963], ["dataloader._MultiProcessingDataLoaderIter._shutdown_workers"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._MultiProcessingDataLoaderIter._shutdown_workers"], ["", "", "", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_shutdown_workers", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_convert": [[15, 35], ["type", "isinstance", "torch.as_tensor", "isinstance", "np_str_obj_array_pattern.search", "collate.default_convert", "isinstance", "hasattr", "type.", "isinstance", "isinstance", "collate.default_convert", "collate.default_convert"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_convert", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_convert", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_convert"], ["def", "default_convert", "(", "data", ")", ":", "\n", "    ", "r\"\"\"Converts each NumPy array data field into a tensor\"\"\"", "\n", "elem_type", "=", "type", "(", "data", ")", "\n", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "data", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "# array of string classes and object", "\n", "        ", "if", "elem_type", ".", "__name__", "==", "'ndarray'", "and", "np_str_obj_array_pattern", ".", "search", "(", "data", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "            ", "return", "data", "\n", "", "return", "torch", ".", "as_tensor", "(", "data", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "container_abcs", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "key", ":", "default_convert", "(", "data", "[", "key", "]", ")", "for", "key", "in", "data", "}", "\n", "", "elif", "isinstance", "(", "data", ",", "tuple", ")", "and", "hasattr", "(", "data", ",", "'_fields'", ")", ":", "# namedtuple", "\n", "        ", "return", "elem_type", "(", "*", "(", "default_convert", "(", "d", ")", "for", "d", "in", "data", ")", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "container_abcs", ".", "Sequence", ")", "and", "not", "isinstance", "(", "data", ",", "string_classes", ")", ":", "\n", "        ", "return", "[", "default_convert", "(", "d", ")", "for", "d", "in", "data", "]", "\n", "", "else", ":", "\n", "        ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_collate": [[42, 82], ["type", "isinstance", "TypeError", "torch.stack", "default_collate_err_msg_format.format", "torch.utils.data.get_worker_info", "sum", "elem.storage()._new_shared", "elem.new", "isinstance", "collate.default_collate", "torch.tensor", "isinstance", "x.numel", "elem.storage", "np_str_obj_array_pattern.search", "TypeError", "torch.as_tensor", "torch.tensor", "isinstance", "default_collate_err_msg_format.format", "torch.as_tensor", "isinstance", "collate.default_collate", "isinstance", "hasattr", "type.", "isinstance", "zip", "collate.default_collate", "collate.default_collate", "zip"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.get_worker_info", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_collate", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_collate", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_collate", "home.repos.pwc.inspect_result.cswluo_SEF._utils.collate.default_collate"], ["def", "default_collate", "(", "batch", ")", ":", "\n", "    ", "r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"", "\n", "\n", "elem", "=", "batch", "[", "0", "]", "\n", "elem_type", "=", "type", "(", "elem", ")", "\n", "if", "isinstance", "(", "elem", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "out", "=", "None", "\n", "if", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "is", "not", "None", ":", "\n", "# If we're in a background process, concatenate directly into a", "\n", "# shared memory tensor to avoid an extra copy", "\n", "            ", "numel", "=", "sum", "(", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "elem", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out", "=", "elem", ".", "new", "(", "storage", ")", "\n", "", "return", "torch", ".", "stack", "(", "batch", ",", "0", ",", "out", "=", "out", ")", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "        ", "elem", "=", "batch", "[", "0", "]", "\n", "if", "elem_type", ".", "__name__", "==", "'ndarray'", ":", "\n", "# array of string classes and object", "\n", "            ", "if", "np_str_obj_array_pattern", ".", "search", "(", "elem", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "default_collate_err_msg_format", ".", "format", "(", "elem", ".", "dtype", ")", ")", "\n", "\n", "", "return", "default_collate", "(", "[", "torch", ".", "as_tensor", "(", "b", ")", "for", "b", "in", "batch", "]", ")", "\n", "", "elif", "elem", ".", "shape", "==", "(", ")", ":", "# scalars", "\n", "            ", "return", "torch", ".", "as_tensor", "(", "batch", ")", "\n", "", "", "elif", "isinstance", "(", "elem", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "int_classes", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "", "elif", "isinstance", "(", "elem", ",", "container_abcs", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "key", ":", "default_collate", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "elem", "}", "\n", "", "elif", "isinstance", "(", "elem", ",", "tuple", ")", "and", "hasattr", "(", "elem", ",", "'_fields'", ")", ":", "# namedtuple", "\n", "        ", "return", "elem_type", "(", "*", "(", "default_collate", "(", "samples", ")", "for", "samples", "in", "zip", "(", "*", "batch", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "elem", ",", "container_abcs", ".", "Sequence", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "default_collate", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "\n", "", "raise", "TypeError", "(", "default_collate_err_msg_format", ".", "format", "(", "elem_type", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.WorkerInfo.__init__": [[63, 67], ["kwargs.items", "setattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "", "self", ".", "__initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.WorkerInfo.__setattr__": [[68, 72], ["object.__setattr__", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.WorkerInfo.__setattr__"], ["", "def", "__setattr__", "(", "self", ",", "key", ",", "val", ")", ":", "\n", "        ", "if", "self", ".", "__initialized", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Cannot assign attributes to {} objects\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "", "return", "super", "(", "WorkerInfo", ",", "self", ")", ".", "__setattr__", "(", "key", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.worker.get_worker_info": [[74, 101], ["None"], "function", ["None"], ["", "", "def", "get_worker_info", "(", ")", ":", "\n", "    ", "r\"\"\"Returns the information about the current\n    :class:`~torch.utils.data.DataLoader` iterator worker process.\n\n    When called in a worker, this returns an object guaranteed to have the\n    following attributes:\n\n    * :attr:`id`: the current worker id.\n    * :attr:`num_workers`: the total number of workers.\n    * :attr:`seed`: the random seed set for the current worker. This value is\n      determined by main process RNG and the worker id. See\n      :class:`~torch.utils.data.DataLoader`'s documentation for more details.\n    * :attr:`dataset`: the copy of the dataset object in **this** process. Note\n      that this will be a different object in a different process than the one\n      in the main process.\n\n    When called in the main process, this returns ``None``.\n\n    .. note::\n       When used in a :attr:`worker_init_fn` passed over to\n       :class:`~torch.utils.data.DataLoader`, this method can be useful to\n       set up each worker process differently, for instance, using ``worker_id``\n       to configure the ``dataset`` object to only read a specific fraction of a\n       sharded dataset, or use ``seed`` to seed other libraries used in dataset\n       code (e.g., NumPy).\n    \"\"\"", "\n", "return", "_worker_info", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.worker._worker_loop": [[107, 200], ["done_event.is_set", "signal_handling._set_worker_signal_handlers", "torch.set_num_threads", "random.seed", "torch.manual_seed", "worker.WorkerInfo", "ManagerWatchdog", "ManagerWatchdog.is_alive", "data_queue.cancel_join_thread", "data_queue.close", "_DatasetKind.create_fetcher", "data_queue.put", "init_fn", "torch._utils.ExceptionWrapper", "index_queue.get", "done_event.is_set", "done_event.is_set", "_DatasetKind.create_fetcher.fetch", "isinstance", "_IterableDatasetStopIteration", "torch._utils.ExceptionWrapper"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF.utils.dataloader._DatasetKind.create_fetcher", "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.fetch"], ["def", "_worker_loop", "(", "dataset_kind", ",", "dataset", ",", "index_queue", ",", "data_queue", ",", "done_event", ",", "\n", "auto_collation", ",", "collate_fn", ",", "drop_last", ",", "seed", ",", "init_fn", ",", "worker_id", ",", "\n", "num_workers", ")", ":", "\n", "# See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on the", "\n", "# logic of this function.", "\n", "\n", "    ", "try", ":", "\n", "# Initialize C side signal handlers for SIGBUS and SIGSEGV. Python signal", "\n", "# module's handlers are executed after Python returns from C low-level", "\n", "# handlers, likely when the same fatal signal had already happened", "\n", "# again.", "\n", "# https://docs.python.org/3/library/signal.html#execution-of-python-signal-handlers", "\n", "        ", "signal_handling", ".", "_set_worker_signal_handlers", "(", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "global", "_worker_info", "\n", "_worker_info", "=", "WorkerInfo", "(", "id", "=", "worker_id", ",", "num_workers", "=", "num_workers", ",", "\n", "seed", "=", "seed", ",", "dataset", "=", "dataset", ")", "\n", "\n", "from", "torch", ".", "utils", ".", "data", "import", "_DatasetKind", "\n", "\n", "init_exception", "=", "None", "\n", "\n", "try", ":", "\n", "            ", "if", "init_fn", "is", "not", "None", ":", "\n", "                ", "init_fn", "(", "worker_id", ")", "\n", "\n", "", "fetcher", "=", "_DatasetKind", ".", "create_fetcher", "(", "dataset_kind", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "init_exception", "=", "ExceptionWrapper", "(", "\n", "where", "=", "\"in DataLoader worker process {}\"", ".", "format", "(", "worker_id", ")", ")", "\n", "\n", "# When using Iterable mode, some worker can exit earlier than others due", "\n", "# to the IterableDataset behaving differently for different workers.", "\n", "# When such things happen, an `_IterableDatasetStopIteration` object is", "\n", "# sent over to the main process with the ID of this worker, so that the", "\n", "# main process won't send more tasks to this worker, and will send", "\n", "# `None` to this worker to properly exit it.", "\n", "#", "\n", "# Note that we cannot set `done_event` from a worker as it is shared", "\n", "# among all processes. Instead, we set the `iteration_end` flag to", "\n", "# signify that the iterator is exhausted. When either `done_event` or", "\n", "# `iteration_end` is set, we skip all processing step and just wait for", "\n", "# `None`.", "\n", "", "iteration_end", "=", "False", "\n", "\n", "watchdog", "=", "ManagerWatchdog", "(", ")", "\n", "\n", "while", "watchdog", ".", "is_alive", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "r", "=", "index_queue", ".", "get", "(", "timeout", "=", "MP_STATUS_CHECK_INTERVAL", ")", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "                ", "continue", "\n", "", "if", "r", "is", "None", ":", "\n", "# Received the final signal", "\n", "                ", "assert", "done_event", ".", "is_set", "(", ")", "or", "iteration_end", "\n", "break", "\n", "", "elif", "done_event", ".", "is_set", "(", ")", "or", "iteration_end", ":", "\n", "# `done_event` is set. But I haven't received the final signal", "\n", "# (None) yet. I will keep continuing until get it, and skip the", "\n", "# processing steps.", "\n", "                ", "continue", "\n", "", "idx", ",", "index", "=", "r", "\n", "if", "init_exception", "is", "not", "None", ":", "\n", "                ", "data", "=", "init_exception", "\n", "init_exception", "=", "None", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "data", "=", "fetcher", ".", "fetch", "(", "index", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "if", "isinstance", "(", "e", ",", "StopIteration", ")", "and", "dataset_kind", "==", "_DatasetKind", ".", "Iterable", ":", "\n", "                        ", "data", "=", "_IterableDatasetStopIteration", "(", "worker_id", ")", "\n", "# Set `iteration_end`", "\n", "#   (1) to save future `next(...)` calls, and", "\n", "#   (2) to avoid sending multiple `_IterableDatasetStopIteration`s.", "\n", "iteration_end", "=", "True", "\n", "", "else", ":", "\n", "# It is important that we don't store exc_info in a variable.", "\n", "# `ExceptionWrapper` does the correct thing.", "\n", "# See NOTE [ Python Traceback Reference Cycle Problem ]", "\n", "                        ", "data", "=", "ExceptionWrapper", "(", "\n", "where", "=", "\"in DataLoader worker process {}\"", ".", "format", "(", "worker_id", ")", ")", "\n", "", "", "", "data_queue", ".", "put", "(", "(", "idx", ",", "data", ")", ")", "\n", "del", "data", ",", "idx", ",", "index", ",", "r", "# save memory", "\n", "", "", "except", "KeyboardInterrupt", ":", "\n", "# Main process will raise KeyboardInterrupt anyways.", "\n", "        ", "pass", "\n", "", "if", "done_event", ".", "is_set", "(", ")", ":", "\n", "        ", "data_queue", ".", "cancel_join_thread", "(", ")", "\n", "data_queue", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory._pin_memory_loop": [[14, 43], ["torch.set_num_threads", "torch.cuda.set_device", "done_event.is_set", "in_queue.get", "done_event.is_set", "done_event.is_set", "isinstance", "pin_memory.pin_memory", "out_queue.put", "torch._utils.ExceptionWrapper"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory"], ["def", "_pin_memory_loop", "(", "in_queue", ",", "out_queue", ",", "device_id", ",", "done_event", ")", ":", "\n", "# This setting is thread local, and prevents the copy in pin_memory from", "\n", "# consuming all CPU cores.", "\n", "    ", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device_id", ")", "\n", "\n", "# See NOTE [ Data Loader Multiprocessing Shutdown Logic ] for details on the", "\n", "# logic of this function.", "\n", "while", "not", "done_event", ".", "is_set", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "r", "=", "in_queue", ".", "get", "(", "timeout", "=", "MP_STATUS_CHECK_INTERVAL", ")", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "            ", "continue", "\n", "", "idx", ",", "data", "=", "r", "\n", "if", "not", "done_event", ".", "is_set", "(", ")", "and", "not", "isinstance", "(", "data", ",", "ExceptionWrapper", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "data", "=", "pin_memory", "(", "data", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "data", "=", "ExceptionWrapper", "(", "\n", "where", "=", "\"in pin memory thread for device {}\"", ".", "format", "(", "device_id", ")", ")", "\n", "", "r", "=", "(", "idx", ",", "data", ")", "\n", "", "while", "not", "done_event", ".", "is_set", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "out_queue", ".", "put", "(", "r", ",", "timeout", "=", "MP_STATUS_CHECK_INTERVAL", ")", "\n", "break", "\n", "", "except", "queue", ".", "Full", ":", "\n", "                ", "continue", "\n", "", "", "del", "r", "# save memory", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory": [[45, 60], ["isinstance", "data.pin_memory", "isinstance", "isinstance", "pin_memory.pin_memory", "isinstance", "hasattr", "isinstance", "data.items", "type", "hasattr", "pin_memory.pin_memory", "data.pin_memory", "pin_memory.pin_memory"], "function", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory", "home.repos.pwc.inspect_result.cswluo_SEF._utils.pin_memory.pin_memory"], ["", "", "def", "pin_memory", "(", "data", ")", ":", "\n", "    ", "if", "isinstance", "(", "data", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "data", ".", "pin_memory", "(", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "string_classes", ")", ":", "\n", "        ", "return", "data", "\n", "", "elif", "isinstance", "(", "data", ",", "container_abcs", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "k", ":", "pin_memory", "(", "sample", ")", "for", "k", ",", "sample", "in", "data", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "data", ",", "tuple", ")", "and", "hasattr", "(", "data", ",", "'_fields'", ")", ":", "# namedtuple", "\n", "        ", "return", "type", "(", "data", ")", "(", "*", "(", "pin_memory", "(", "sample", ")", "for", "sample", "in", "data", ")", ")", "\n", "", "elif", "isinstance", "(", "data", ",", "container_abcs", ".", "Sequence", ")", ":", "\n", "        ", "return", "[", "pin_memory", "(", "sample", ")", "for", "sample", "in", "data", "]", "\n", "", "elif", "hasattr", "(", "data", ",", "\"pin_memory\"", ")", ":", "\n", "        ", "return", "data", ".", "pin_memory", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.signal_handling._set_SIGCHLD_handler": [[47, 72], ["signal.getsignal", "signal.signal", "isinstance", "callable", "torch._C._error_if_any_worker_fails", "threading.current_thread", "signal.getsignal."], "function", ["None"], ["def", "_set_SIGCHLD_handler", "(", ")", ":", "\n", "# Windows doesn't support SIGCHLD handler", "\n", "    ", "if", "IS_WINDOWS", ":", "\n", "        ", "return", "\n", "# can't set signal in child threads", "\n", "", "if", "not", "isinstance", "(", "threading", ".", "current_thread", "(", ")", ",", "threading", ".", "_MainThread", ")", ":", "\n", "        ", "return", "\n", "", "global", "_SIGCHLD_handler_set", "\n", "if", "_SIGCHLD_handler_set", ":", "\n", "        ", "return", "\n", "", "previous_handler", "=", "signal", ".", "getsignal", "(", "signal", ".", "SIGCHLD", ")", "\n", "if", "not", "callable", "(", "previous_handler", ")", ":", "\n", "# This doesn't catch default handler, but SIGCHLD default handler is a", "\n", "# no-op.", "\n", "        ", "previous_handler", "=", "None", "\n", "\n", "", "def", "handler", "(", "signum", ",", "frame", ")", ":", "\n", "# This following call uses `waitid` with WNOHANG from C side. Therefore,", "\n", "# Python can still get and update the process status successfully.", "\n", "        ", "_error_if_any_worker_fails", "(", ")", "\n", "if", "previous_handler", "is", "not", "None", ":", "\n", "            ", "previous_handler", "(", "signum", ",", "frame", ")", "\n", "\n", "", "", "signal", ".", "signal", "(", "signal", ".", "SIGCHLD", ",", "handler", ")", "\n", "_SIGCHLD_handler_set", "=", "True", "\n", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._BaseDatasetFetcher.__init__": [[8, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "auto_collation", "=", "auto_collation", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._BaseDatasetFetcher.fetch": [[14, 16], ["NotImplementedError"], "methods", ["None"], ["", "def", "fetch", "(", "self", ",", "possibly_batched_index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._IterableDatasetFetcher.__init__": [[19, 22], ["fetch._BaseDatasetFetcher.__init__", "iter"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", ":", "\n", "        ", "super", "(", "_IterableDatasetFetcher", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "self", ".", "dataset_iter", "=", "iter", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._IterableDatasetFetcher.fetch": [[23, 36], ["fetch._IterableDatasetFetcher.collate_fn", "next", "next.append", "len", "next", "len", "len"], "methods", ["None"], ["", "def", "fetch", "(", "self", ",", "possibly_batched_index", ")", ":", "\n", "        ", "if", "self", ".", "auto_collation", ":", "\n", "            ", "data", "=", "[", "]", "\n", "for", "_", "in", "possibly_batched_index", ":", "\n", "                ", "try", ":", "\n", "                    ", "data", ".", "append", "(", "next", "(", "self", ".", "dataset_iter", ")", ")", "\n", "", "except", "StopIteration", ":", "\n", "                    ", "break", "\n", "", "", "if", "len", "(", "data", ")", "==", "0", "or", "(", "self", ".", "drop_last", "and", "len", "(", "data", ")", "<", "len", "(", "possibly_batched_index", ")", ")", ":", "\n", "                ", "raise", "StopIteration", "\n", "", "", "else", ":", "\n", "            ", "data", "=", "next", "(", "self", ".", "dataset_iter", ")", "\n", "", "return", "self", ".", "collate_fn", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__": [[39, 41], ["fetch._BaseDatasetFetcher.__init__"], "methods", ["home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", ":", "\n", "        ", "super", "(", "_MapDatasetFetcher", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "auto_collation", ",", "collate_fn", ",", "drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.fetch._MapDatasetFetcher.fetch": [[42, 48], ["fetch._MapDatasetFetcher.collate_fn"], "methods", ["None"], ["", "def", "fetch", "(", "self", ",", "possibly_batched_index", ")", ":", "\n", "        ", "if", "self", ".", "auto_collation", ":", "\n", "            ", "data", "=", "[", "self", ".", "dataset", "[", "idx", "]", "for", "idx", "in", "possibly_batched_index", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "self", ".", "dataset", "[", "possibly_batched_index", "]", "\n", "", "return", "self", ".", "collate_fn", "(", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cswluo_SEF._utils.__init__._set_python_exit_flag": [[38, 41], ["None"], "function", ["None"], []]}