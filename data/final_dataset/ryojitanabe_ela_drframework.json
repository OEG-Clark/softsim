{"home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.stat_accuracy.avg_accuracy": [[6, 16], ["range", "statistics.mean", "os.path.join", "open", "fh.read", "scores.append", "float"], "function", ["None"], ["def", "avg_accuracy", "(", "class_res_dir_path", ",", "high_level_label", ",", "dim", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "\n", "for", "fun_id", "in", "range", "(", "1", ",", "24", "+", "1", ")", ":", "\n", "        ", "res_class_file_path", "=", "os", ".", "path", ".", "join", "(", "class_res_dir_path", ",", "'accuracy_{}_f{}_DIM{}.csv'", ".", "format", "(", "high_level_label", ",", "fun_id", ",", "dim", ")", ")", "\n", "with", "open", "(", "res_class_file_path", ",", "'r'", ")", "as", "fh", ":", "\n", "            ", "s_score", "=", "fh", ".", "read", "(", ")", "\n", "scores", ".", "append", "(", "float", "(", "s_score", ")", ")", "\n", "\n", "", "", "return", "stat", ".", "mean", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.sample.create_sample": [[12, 40], ["numpy.full", "numpy.full", "pflacco.pflacco.create_initial_sample", "obj_values.append", "numpy.random.random_sample", "fun", "pyDOE.lhs", "Exception"], "function", ["None"], ["def", "create_sample", "(", "fun", ",", "sampling_method", ",", "sample_size", ")", ":", "\n", "    ", "dim", "=", "fun", ".", "dimension", "\n", "\n", "# Each solution is generated in the range [0,1]^dim.    ", "\n", "if", "sampling_method", "==", "'ilhs'", ":", "\n", "        ", "sample", "=", "create_initial_sample", "(", "n_obs", "=", "sample_size", ",", "dim", "=", "dim", ",", "type", "=", "'lhs'", ")", "\n", "", "elif", "sampling_method", "==", "'random'", ":", "\n", "        ", "sample", "=", "np", ".", "random", ".", "random_sample", "(", "(", "sample_size", ",", "dim", ")", ")", "\n", "# sobol_seq is available for <= 80 dimensions", "\n", "# elif sampling_method == 'sobol':     ", "\n", "#     sample = sobol_seq.i4_sobol_generate(dim, sample_size)", "\n", "", "elif", "sampling_method", "==", "'lhs'", ":", "\n", "        ", "sample", "=", "lhs", "(", "dim", ",", "sample_size", ",", "criterion", "=", "'center'", ")", "\n", "", "else", ":", "\n", "        ", "error_msg", "=", "\"Error: %s is not defined.\"", "%", "(", "sampling_method", ")", "\n", "raise", "Exception", "(", "error_msg", ")", "\n", "\n", "# Linearly map each solution from [0,1]^dim to [-5,5]^dim", "\n", "", "lbound", "=", "np", ".", "full", "(", "dim", ",", "-", "5.", ")", "\n", "ubound", "=", "np", ".", "full", "(", "dim", ",", "5.", ")", "\n", "sample", "=", "(", "ubound", "-", "lbound", ")", "*", "sample", "+", "lbound", "\n", "\n", "# Evaluate each solution in the sample", "\n", "obj_values", "=", "[", "]", "\n", "for", "x", "in", "sample", ":", "\n", "        ", "obj_values", ".", "append", "(", "fun", "(", "x", ")", ")", "\n", "\n", "", "return", "sample", ",", "obj_values", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.sample.create_sample_bbob": [[45, 88], ["os.path.join", "os.makedirs", "cocoex.Suite", "cocoex.Observer", "cocoex.utilities.MiniPrint", "problem.observe_with", "sample.create_sample", "int", "os.path.join", "cocoex.utilities.MiniPrint.", "open", "zip", "[].split", "fh.write", "str", "len", "problem.info.split"], "function", ["home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.sample.create_sample"], ["", "def", "create_sample_bbob", "(", "bbob_suite", "=", "'bbob'", ",", "sample_multiplier", "=", "50", ",", "sampling_method", "=", "'lhs'", ",", "sample_dir_path", "=", "'./sample_data'", ",", "sample_id", "=", "0", ")", ":", "\n", "    ", "sample_dir_path", "=", "os", ".", "path", ".", "join", "(", "sample_dir_path", ",", "'{}_multiplier{}_sid{}'", ".", "format", "(", "sampling_method", ",", "sample_multiplier", ",", "sample_id", ")", ")", "\n", "os", ".", "makedirs", "(", "sample_dir_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "### input", "\n", "output_folder", "=", "'tmp'", "\n", "\n", "### prepare", "\n", "suite", "=", "cocoex", ".", "Suite", "(", "bbob_suite", ",", "\"\"", ",", "\"\"", ")", "\n", "observer", "=", "cocoex", ".", "Observer", "(", "bbob_suite", ",", "\"result_folder: \"", "+", "output_folder", ")", "\n", "minimal_print", "=", "cocoex", ".", "utilities", ".", "MiniPrint", "(", ")", "\n", "\n", "count_instance_id", "=", "1", "\n", "\n", "### go", "\n", "for", "problem", "in", "suite", ":", "# this loop will take several minutes or longer", "\n", "        ", "problem", ".", "observe_with", "(", "observer", ")", "# generates the data for cocopp post-processing", "\n", "\n", "# In our experiment, we used the noiseless BBOB function set for 2, 3, 5, and 10 dimensions and the large-scale BBOB function set for 20, 40, 80, 160, 320, and 640 dimensions. So, it is not needed to create samples for the noiseless BBOB function set with 20 and 40 dimensions.", "\n", "if", "bbob_suite", "==", "'bbob'", "and", "problem", ".", "dimension", ">=", "20", ":", "\n", "            ", "break", "\n", "\n", "", "sample_size", "=", "sample_multiplier", "*", "problem", ".", "dimension", "\n", "sample", ",", "obj_values", "=", "create_sample", "(", "problem", ",", "sampling_method", ",", "sample_size", ")", "\n", "\n", "fun_id", "=", "int", "(", "problem", ".", "info", ".", "split", "(", "'_f'", ")", "[", "1", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "# Actual instance ID", "\n", "#instance_id = int(problem.info.split('_i')[1].split('_')[0])", "\n", "instance_id", "=", "count_instance_id", "\n", "\n", "# Recode each pair of x and f(x) in a csv file    ", "\n", "sample_data_file_path", "=", "os", ".", "path", ".", "join", "(", "sample_dir_path", ",", "'x_f_data_{}_f{}_DIM{}_i{}.csv'", ".", "format", "(", "bbob_suite", ",", "fun_id", ",", "problem", ".", "dimension", ",", "instance_id", ")", ")", "\n", "with", "open", "(", "sample_data_file_path", ",", "'w'", ")", "as", "fh", ":", "\n", "            ", "for", "x", ",", "obj_val", "in", "zip", "(", "sample", ",", "obj_values", ")", ":", "\n", "                ", "data_str", "=", "'{},'", ".", "format", "(", "obj_val", ")", "\n", "data_str", "+=", "','", ".", "join", "(", "[", "str", "(", "y", ")", "for", "y", "in", "x", "]", ")", "\n", "fh", ".", "write", "(", "data_str", "+", "'\\n'", ")", "\n", "\n", "", "", "count_instance_id", "+=", "1", "\n", "if", "count_instance_id", ">", "15", ":", "\n", "            ", "count_instance_id", "=", "1", "\n", "\n", "", "minimal_print", "(", "problem", ",", "final", "=", "problem", ".", "index", "==", "len", "(", "suite", ")", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.feature_computation.scale_X": [[13, 22], ["X.mean", "scipy.stats.rankdata", "len", "numpy.sum", "numpy.log", "numpy.log", "w.reshape"], "function", ["None"], ["def", "scale_X", "(", "X", ",", "func_vals", ")", ":", "\n", "    ", "X_mean", "=", "X", ".", "mean", "(", "axis", "=", "0", ")", "\n", "X_", "=", "X", "-", "X_mean", "\n", "\n", "r", "=", "rankdata", "(", "func_vals", ")", "\n", "N", "=", "len", "(", "func_vals", ")", "\n", "w", "=", "np", ".", "log", "(", "N", ")", "-", "np", ".", "log", "(", "r", ")", "\n", "w", "/=", "np", ".", "sum", "(", "w", ")", "\n", "return", "X_", "*", "w", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.feature_computation.compute_features": [[23, 71], ["numpy.loadtxt", "pflacco.pflacco.create_feature_object", "print", "feature_computation.scale_X", "sklearn.decomposition.PCA", "sklearn.decomposition.PCA.fit_transform", "numpy.min", "numpy.max", "pflacco.pflacco.calculate_feature_set", "len", "print", "open", "pflacco.pflacco.calculate_feature_set.items", "open", "pflacco.pflacco.calculate_feature_set.items", "len", "fh.write", "fh.write"], "function", ["home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.feature_computation.scale_X"], ["", "def", "compute_features", "(", "ela_feature_class", ",", "sample_data_file_path", ",", "feature_file_path", ",", "dim_redu", "=", "'none'", ",", "n_pca_components", "=", "None", ")", ":", "\n", "    ", "bbob_lower_bound", "=", "-", "5", "\n", "bbob_upper_bound", "=", "5", "\n", "\n", "n_cell_blocks", "=", "None", "\n", "if", "ela_feature_class", "in", "[", "'cm_angle'", ",", "'cm_conv'", ",", "'cm_grad'", ",", "'gcm'", "]", ":", "\n", "        ", "n_cell_blocks", "=", "3", "\n", "\n", "", "data_set", "=", "np", ".", "loadtxt", "(", "sample_data_file_path", ",", "delimiter", "=", "\",\"", ",", "comments", "=", "\"#\"", ",", "dtype", "=", "np", ".", "float", ")", "\n", "sample_f", "=", "data_set", "[", ":", ",", "0", "]", "\n", "sample_x", "=", "data_set", "[", ":", ",", "1", ":", "]", "\n", "\n", "if", "dim_redu", "==", "'pca'", "and", "len", "(", "sample_x", "[", "0", "]", ")", "<=", "n_pca_components", ":", "\n", "        ", "print", "(", "\"Warning. It is impossible to reduce the original dimension {} to a higher dimension {}, so skipped\"", ".", "format", "(", "len", "(", "sample_x", "[", "0", "]", ")", ",", "n_pca_components", ")", ")", "\n", "return", "0", "\n", "\n", "# Dimensionality reduction by the weighted PCA strategy in PCA-BO", "\n", "# https://github.com/wangronin/Bayesian-Optimization", "\n", "", "if", "dim_redu", "==", "'pca'", ":", "\n", "        ", "sample_x", "=", "scale_X", "(", "sample_x", ",", "sample_f", ")", "\n", "pca", "=", "PCA", "(", "n_components", "=", "n_pca_components", ",", "svd_solver", "=", "'full'", ")", "\n", "sample_x", "=", "pca", ".", "fit_transform", "(", "sample_x", ",", "sample_f", ")", "\n", "\n", "", "if", "dim_redu", "==", "'pca'", "and", "ela_feature_class", "in", "[", "'cm_angle'", ",", "'cm_conv'", ",", "'cm_grad'", ",", "'gcm'", "]", ":", "\n", "# Normalize each point x in the sample X into the range [0,1]^m", "\n", "        ", "min_values", "=", "np", ".", "min", "(", "sample_x", ",", "axis", "=", "0", ")", "\n", "max_values", "=", "np", ".", "max", "(", "sample_x", ",", "axis", "=", "0", ")", "\n", "sample_x", "=", "(", "sample_x", "-", "min_values", ")", "/", "(", "max_values", "-", "min_values", ")", "\n", "bbob_lower_bound", "=", "0", "\n", "bbob_upper_bound", "=", "1", "\n", "\n", "", "feat_object", "=", "create_feature_object", "(", "x", "=", "sample_x", ",", "y", "=", "sample_f", ",", "minimize", "=", "True", ",", "lower", "=", "bbob_lower_bound", ",", "upper", "=", "bbob_upper_bound", ",", "blocks", "=", "n_cell_blocks", ")", "\n", "\n", "try", ":", "\n", "# The calculate_feature_set function returns a dictionary object ", "\n", "        ", "feature_dict", "=", "calculate_feature_set", "(", "feat_object", ",", "ela_feature_class", ")", "\n", "", "except", "rpy2", ".", "rinterface_lib", ".", "embedded", ".", "RRuntimeError", "as", "e", ":", "\n", "        ", "print", "(", "e", ")", "\n", "\n", "\n", "", "if", "dim_redu", "==", "'pca'", ":", "\n", "        ", "with", "open", "(", "feature_file_path", ",", "'w'", ")", "as", "fh", ":", "\n", "            ", "for", "key", ",", "value", "in", "feature_dict", ".", "items", "(", ")", ":", "\n", "                ", "fh", ".", "write", "(", "'tpca{}_{},{}\\n'", ".", "format", "(", "n_pca_components", ",", "key", ",", "value", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "feature_file_path", ",", "'w'", ")", "as", "fh", ":", "\n", "            ", "for", "key", ",", "value", "in", "feature_dict", ".", "items", "(", ")", ":", "\n", "                ", "fh", ".", "write", "(", "'{},{}\\n'", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.feature_aggregation.create_feature_table_data": [[9, 64], ["range", "range", "pandas.read_csv", "column_names.extend", "column_names.extend", "pandas.DataFrame", "table_df.append.to_csv", "os.path.join", "numpy.loadtxt", "feature_data_set[].tolist", "column_names.extend", "table_df.append.append", "os.path.join", "numpy.loadtxt", "pandas.Series"], "function", ["None"], ["def", "create_feature_table_data", "(", "table_file_path", ",", "feature_dir_path", ",", "all_feature_classes", ",", "dims", ")", ":", "\n", "    ", "all_fun_ids", "=", "range", "(", "1", ",", "24", "+", "1", ")", "\n", "all_instance_ids", "=", "range", "(", "1", ",", "15", "+", "1", ")", "\n", "my_high_level_prop_names", "=", "[", "'multimodality'", ",", "'globalstructure'", ",", "'separability'", ",", "'variablescaling'", ",", "'homogeneity'", ",", "'basinsizes'", ",", "'glcontrast'", ",", "'fungroup'", "]", "\n", "label_df", "=", "pd", ".", "read_csv", "(", "'./high_level_fun_prop.csv'", ",", "header", "=", "0", ")", "\n", "\n", "# 1. Set the name of each column", "\n", "column_names", "=", "[", "]", "\n", "my_basic_feature_names", "=", "[", "'dim'", ",", "'fun'", ",", "'instance'", "]", "\n", "column_names", ".", "extend", "(", "my_basic_feature_names", ")", "\n", "column_names", ".", "extend", "(", "my_high_level_prop_names", ")", "\n", "\n", "# Extract the name of all the features", "\n", "dim", "=", "dims", "[", "0", "]", "\n", "instance_id", "=", "all_instance_ids", "[", "0", "]", "\n", "fun_id", "=", "all_fun_ids", "[", "0", "]", "\n", "\n", "bbob_suite", "=", "'bbob'", "\n", "if", "dim", ">=", "20", ":", "\n", "        ", "bbob_suite", "=", "'bbob-largescale'", "\n", "\n", "", "for", "ela_feature_class", "in", "all_feature_classes", ":", "\n", "        ", "feature_file_path", "=", "os", ".", "path", ".", "join", "(", "feature_dir_path", ",", "'{}_{}_f{}_DIM{}_i{}.csv'", ".", "format", "(", "ela_feature_class", ",", "bbob_suite", ",", "fun_id", ",", "dim", ",", "instance_id", ")", ")", "\n", "feature_data_set", "=", "np", ".", "loadtxt", "(", "feature_file_path", ",", "delimiter", "=", "\",\"", ",", "comments", "=", "\"#\"", ",", "dtype", "=", "np", ".", "str", ")", "\n", "feature_names", "=", "feature_data_set", "[", ":", ",", "0", "]", ".", "tolist", "(", ")", "\n", "column_names", ".", "extend", "(", "feature_names", ")", "\n", "\n", "# 2. Make table data", "\n", "", "table_df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "column_names", ")", "\n", "\n", "for", "dim", "in", "dims", ":", "\n", "        ", "bbob_suite", "=", "'bbob'", "\n", "if", "dim", ">=", "20", ":", "\n", "            ", "bbob_suite", "=", "'bbob-largescale'", "\n", "\n", "", "for", "fun_id", "in", "all_fun_ids", ":", "\n", "            ", "data_dict", "=", "{", "}", "\n", "data_dict", "[", "'dim'", "]", "=", "dim", "\n", "data_dict", "[", "'fun'", "]", "=", "fun_id", "\n", "\n", "for", "label", "in", "my_high_level_prop_names", ":", "\n", "                ", "data_dict", "[", "label", "]", "=", "label_df", ".", "loc", "[", "fun_id", "-", "1", ",", "label", "]", "\n", "\n", "# For each instance, recode the feature values", "\n", "", "for", "instance_id", "in", "all_instance_ids", ":", "\n", "                ", "data_dict", "[", "'instance'", "]", "=", "instance_id", "\n", "\n", "for", "ela_feature_class", "in", "all_feature_classes", ":", "\n", "                    ", "feature_file_path", "=", "os", ".", "path", ".", "join", "(", "feature_dir_path", ",", "'{}_{}_f{}_DIM{}_i{}.csv'", ".", "format", "(", "ela_feature_class", ",", "bbob_suite", ",", "fun_id", ",", "dim", ",", "instance_id", ")", ")", "\n", "feature_data_set", "=", "np", ".", "loadtxt", "(", "feature_file_path", ",", "delimiter", "=", "\",\"", ",", "comments", "=", "\"#\"", ",", "dtype", "=", "np", ".", "str", ")", "\n", "for", "key", ",", "value", "in", "feature_data_set", ":", "\n", "                        ", "data_dict", "[", "key", "]", "=", "value", "\n", "", "", "table_df", "=", "table_df", ".", "append", "(", "pd", ".", "Series", "(", "data_dict", ")", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "", "table_df", ".", "to_csv", "(", "table_file_path", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ryojitanabe_ela_drframework.None.property_classification.classification_lopo_cv": [[12, 58], ["pandas.read_csv", "table_df.drop.replace", "table_df.drop.dropna", "table_df.drop.drop", "test_df.drop.drop", "test_df.drop.drop", "train_df.drop.drop", "train_df.drop.drop", "sklearn.ensemble.RandomForestClassifier", "sklearn.ensemble.RandomForestClassifier.fit", "sklearn.ensemble.RandomForestClassifier.predict", "sklearn.metrics.accuracy_score", "len", "len", "table_df[].nunique", "open", "fh.write", "dup_columns.append", "str"], "function", ["None"], ["def", "classification_lopo_cv", "(", "res_class_file_path", ",", "table_data_file_path", ",", "dim", ",", "left_fun_id", ",", "target_label", ")", ":", "\n", "    ", "problem_info_columns", "=", "[", "'dim'", ",", "'fun'", ",", "'instance'", "]", "\n", "high_level_prop_labels", "=", "[", "'multimodality'", ",", "'globalstructure'", ",", "'separability'", ",", "'variablescaling'", ",", "'homogeneity'", ",", "'basinsizes'", ",", "'glcontrast'", ",", "'fungroup'", "]", "\n", "\n", "table_df", "=", "pd", ".", "read_csv", "(", "table_data_file_path", ",", "header", "=", "0", ")", "\n", "table_df", "=", "table_df", "[", "table_df", "[", "'dim'", "]", "==", "dim", "]", "\n", "\n", "# remove columns that include inf or nan", "\n", "table_df", "=", "table_df", ".", "replace", "(", "[", "np", ".", "inf", ",", "-", "np", ".", "inf", "]", ",", "np", ".", "nan", ")", "\n", "table_df", "=", "table_df", ".", "dropna", "(", "how", "=", "'any'", ",", "axis", "=", "1", ")", "\n", "\n", "# remove duplicated columns", "\n", "dup_columns", "=", "[", "]", "\n", "# The first len(problem_info_columns) + len(high_level_prop_labels) should be ignored", "\n", "n_misc", "=", "len", "(", "problem_info_columns", ")", "+", "len", "(", "high_level_prop_labels", ")", "\n", "all_columns", "=", "table_df", ".", "columns", ".", "values", "\n", "for", "column", "in", "all_columns", "[", "n_misc", ":", "]", ":", "\n", "        ", "unum", "=", "table_df", "[", "column", "]", ".", "nunique", "(", ")", "\n", "if", "unum", "==", "1", ":", "\n", "            ", "dup_columns", ".", "append", "(", "column", ")", "\n", "", "", "table_df", "=", "table_df", ".", "drop", "(", "dup_columns", ",", "axis", "=", "1", ")", "\n", "\n", "# Split data sets into train and test datasets", "\n", "# Test data", "\n", "test_df", "=", "table_df", "[", "table_df", "[", "'fun'", "]", "==", "left_fun_id", "]", "\n", "test_df", "=", "test_df", ".", "drop", "(", "columns", "=", "problem_info_columns", ")", "\n", "y_test", "=", "test_df", "[", "target_label", "]", ".", "values", "\n", "test_df", "=", "test_df", ".", "drop", "(", "columns", "=", "high_level_prop_labels", ")", "\n", "X_test", "=", "test_df", ".", "values", "\n", "\n", "# train datasets", "\n", "train_df", "=", "table_df", "[", "table_df", "[", "'fun'", "]", "!=", "left_fun_id", "]", "\n", "train_df", "=", "train_df", ".", "drop", "(", "columns", "=", "problem_info_columns", ")", "\n", "y_train", "=", "train_df", "[", "target_label", "]", ".", "values", "\n", "train_df", "=", "train_df", ".", "drop", "(", "columns", "=", "high_level_prop_labels", ")", "\n", "X_train", "=", "train_df", ".", "values", "\n", "\n", "# train", "\n", "estimator", "=", "RandomForestClassifier", "(", "n_estimators", "=", "1000", ",", "random_state", "=", "0", ")", "\n", "estimator", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "# test", "\n", "pred_labels", "=", "estimator", ".", "predict", "(", "X_test", ")", "\n", "score", "=", "accuracy_score", "(", "y_test", ",", "pred_labels", ")", "\n", "\n", "with", "open", "(", "res_class_file_path", ",", "'w'", ")", "as", "fh", ":", "\n", "        ", "fh", ".", "write", "(", "str", "(", "score", ")", ")", "\n", "\n"]]}