{"home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.__init__": [[16, 46], ["torch.Module.__init__", "len", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "bilstmcrf.BiLSTM_CRF.init_hidden", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.rectifier_net.RectifierNetwork.__init__", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.init_hidden"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "tag_to_ix", ",", "embedding_dim", ",", "hidden_dim", ",", "embed_matrix", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiLSTM_CRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "tag_to_ix", "=", "tag_to_ix", "\n", "self", ".", "tagset_size", "=", "len", "(", "tag_to_ix", ")", "\n", "\n", "if", "embed_matrix", "==", "None", ":", "\n", "            ", "self", ".", "word_embeds", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_embeds", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "tensor", "(", "embed_matrix", ")", ".", "float", "(", ")", ")", "\n", "\n", "", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "embedding_dim", ",", "hidden_dim", "//", "2", ",", "\n", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ")", "\n", "\n", "# Maps the output of the LSTM into tag space.", "\n", "self", ".", "hidden2tag", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "self", ".", "tagset_size", ")", "\n", "\n", "# Matrix of transition parameters.  Entry i,j is the score of", "\n", "# transitioning *to* i *from* j.", "\n", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "self", ".", "tagset_size", ",", "self", ".", "tagset_size", ")", ")", "\n", "\n", "# These two statements enforce the constraint that we never transfer", "\n", "# to the start tag and we never transfer from the stop tag", "\n", "self", ".", "transitions", ".", "data", "[", "tag_to_ix", "[", "START_TAG", "]", ",", ":", "]", "=", "-", "10000", "\n", "self", ".", "transitions", ".", "data", "[", ":", ",", "tag_to_ix", "[", "STOP_TAG", "]", "]", "=", "-", "10000", "\n", "\n", "self", ".", "hidden", "=", "self", ".", "init_hidden", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.init_hidden": [[47, 50], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "        ", "return", "(", "torch", ".", "zeros", "(", "2", ",", "1", ",", "self", ".", "hidden_dim", "//", "2", ")", ",", "\n", "torch", ".", "zeros", "(", "2", ",", "1", ",", "self", ".", "hidden_dim", "//", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._forward_alg": [[51, 86], ["torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "utils.log_sum_exp", "range", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "feat[].view().expand", "bilstmcrf.BiLSTM_CRF.transitions[].view", "alphas_t.append", "utils.log_sum_exp().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "feat[].view", "utils.log_sum_exp"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.log_sum_exp", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.log_sum_exp"], ["", "def", "_forward_alg", "(", "self", ",", "feats", ")", ":", "\n", "# Do the forward algorithm to compute the partition function", "\n", "        ", "init_alphas", "=", "torch", ".", "full", "(", "(", "1", ",", "self", ".", "tagset_size", ")", ",", "-", "10000.", ")", "\n", "# START_TAG has all of the score.", "\n", "init_alphas", "[", "0", "]", "[", "self", ".", "tag_to_ix", "[", "START_TAG", "]", "]", "=", "0.", "\n", "\n", "# Wrap in a variable so that we will get automatic backprop", "\n", "forward_var", "=", "init_alphas", "\n", "\n", "# Iterate through the sentence", "\n", "for", "feat", "in", "feats", ":", "\n", "            ", "alphas_t", "=", "[", "]", "# The forward tensors at this timestep", "\n", "for", "next_tag", "in", "range", "(", "self", ".", "tagset_size", ")", ":", "\n", "# broadcast the emission score: it is the same regardless of", "\n", "# the previous tag", "\n", "                ", "emit_score", "=", "feat", "[", "next_tag", "]", ".", "view", "(", "\n", "1", ",", "-", "1", ")", ".", "expand", "(", "1", ",", "self", ".", "tagset_size", ")", "\n", "# the ith entry of trans_score is the score of transitioning to", "\n", "# next_tag from i", "\n", "trans_score", "=", "self", ".", "transitions", "[", "next_tag", "]", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "# The ith entry of next_tag_var is the value for the", "\n", "# edge (i -> next_tag) before we do log-sum-exp", "\n", "next_tag_var", "=", "forward_var", "+", "trans_score", "+", "emit_score", "\n", "# The forward variable for this tag is log-sum-exp of all the", "\n", "# scores.", "\n", "\n", "alphas_t", ".", "append", "(", "log_sum_exp", "(", "next_tag_var", ")", ".", "view", "(", "1", ")", ")", "\n", "\n", "", "forward_var", "=", "torch", ".", "cat", "(", "alphas_t", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "terminal_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "STOP_TAG", "]", "]", "\n", "alpha", "=", "log_sum_exp", "(", "terminal_var", ")", "\n", "\n", "return", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._get_lstm_features": [[87, 95], ["bilstmcrf.BiLSTM_CRF.init_hidden", "bilstmcrf.BiLSTM_CRF.word_embeds().view", "bilstmcrf.BiLSTM_CRF.lstm", "lstm_out.view.view.view", "bilstmcrf.BiLSTM_CRF.hidden2tag", "len", "len", "bilstmcrf.BiLSTM_CRF.word_embeds"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.init_hidden"], ["", "def", "_get_lstm_features", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "self", ".", "init_hidden", "(", ")", "\n", "embeds", "=", "self", ".", "word_embeds", "(", "sentence", ")", ".", "view", "(", "len", "(", "sentence", ")", ",", "1", ",", "-", "1", ")", "\n", "lstm_out", ",", "self", ".", "hidden", "=", "self", ".", "lstm", "(", "embeds", ",", "self", ".", "hidden", ")", "\n", "lstm_out", "=", "lstm_out", ".", "view", "(", "len", "(", "sentence", ")", ",", "self", ".", "hidden_dim", ")", "\n", "lstm_feats", "=", "self", ".", "hidden2tag", "(", "lstm_out", ")", "\n", "\n", "return", "lstm_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._score_sentence": [[96, 105], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "_score_sentence", "(", "self", ",", "feats", ",", "tags", ")", ":", "\n", "# Gives the score of a provided tag sequence", "\n", "        ", "score", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "tags", "=", "torch", ".", "cat", "(", "[", "torch", ".", "tensor", "(", "[", "self", ".", "tag_to_ix", "[", "START_TAG", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "tags", "]", ")", "\n", "for", "i", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "score", "=", "score", "+", "self", ".", "transitions", "[", "tags", "[", "i", "+", "1", "]", ",", "tags", "[", "i", "]", "]", "+", "feat", "[", "tags", "[", "i", "+", "1", "]", "]", "\n", "", "score", "=", "score", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "STOP_TAG", "]", ",", "tags", "[", "-", "1", "]", "]", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._viterbi_decode": [[106, 154], ["torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "utils.argmax", "reversed", "best_path.pop", "best_path.reverse", "range", "forwards.append", "backpointers.append", "best_path.append", "utils.argmax", "bptrs_t.append", "viterbivars_t.append", "[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.argmax", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.argmax"], ["", "def", "_viterbi_decode", "(", "self", ",", "feats", ")", ":", "\n", "        ", "backpointers", "=", "[", "]", "\n", "forwards", "=", "[", "]", "\n", "\n", "# Initialize the viterbi variables in log space", "\n", "init_vvars", "=", "torch", ".", "full", "(", "(", "1", ",", "self", ".", "tagset_size", ")", ",", "-", "10000.", ")", "\n", "\n", "init_vvars", "[", "0", "]", "[", "self", ".", "tag_to_ix", "[", "START_TAG", "]", "]", "=", "0", "\n", "\n", "# forward_var at step i holds the viterbi variables for step i-1", "\n", "forward_var", "=", "init_vvars", "\n", "for", "feat", "in", "feats", ":", "\n", "            ", "bptrs_t", "=", "[", "]", "# holds the backpointers for this step", "\n", "viterbivars_t", "=", "[", "]", "# holds the viterbi variables for this step", "\n", "\n", "for", "next_tag", "in", "range", "(", "self", ".", "tagset_size", ")", ":", "\n", "# next_tag_var[i] holds the viterbi variable for tag i at the", "\n", "# previous step, plus the score of transitioning", "\n", "# from tag i to next_tag.", "\n", "# We don't include the emission scores here because the max", "\n", "# does not depend on them (we add them in below)", "\n", "                ", "next_tag_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "next_tag", "]", "\n", "best_tag_id", "=", "argmax", "(", "next_tag_var", ")", "\n", "bptrs_t", ".", "append", "(", "best_tag_id", ")", "\n", "viterbivars_t", ".", "append", "(", "next_tag_var", "[", "0", "]", "[", "best_tag_id", "]", ".", "view", "(", "1", ")", ")", "\n", "# Now add in the emission scores, and assign forward_var to the set", "\n", "# of viterbi variables we just computed", "\n", "", "forward_var", "=", "(", "torch", ".", "cat", "(", "viterbivars_t", ")", "+", "feat", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "forwards", ".", "append", "(", "forward_var", ")", "\n", "backpointers", ".", "append", "(", "bptrs_t", ")", "\n", "\n", "# Transition to STOP_TAG", "\n", "", "terminal_var", "=", "forward_var", "+", "self", ".", "transitions", "[", "self", ".", "tag_to_ix", "[", "STOP_TAG", "]", "]", "\n", "best_tag_id", "=", "argmax", "(", "terminal_var", ")", "\n", "path_score", "=", "terminal_var", "[", "0", "]", "[", "best_tag_id", "]", "\n", "\n", "# Follow the back pointers to decode the best path.", "\n", "best_path", "=", "[", "best_tag_id", "]", "\n", "for", "bptrs_t", "in", "reversed", "(", "backpointers", ")", ":", "\n", "            ", "best_tag_id", "=", "bptrs_t", "[", "best_tag_id", "]", "\n", "best_path", ".", "append", "(", "best_tag_id", ")", "\n", "# Pop off the start tag (we dont want to return that to the caller)", "\n", "", "start", "=", "best_path", ".", "pop", "(", ")", "\n", "assert", "start", "==", "self", ".", "tag_to_ix", "[", "START_TAG", "]", "# Sanity check", "\n", "best_path", ".", "reverse", "(", ")", "\n", "#print(best_path)", "\n", "\n", "return", "path_score", ",", "best_path", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.neg_log_likelihood": [[155, 160], ["bilstmcrf.BiLSTM_CRF._get_lstm_features", "bilstmcrf.BiLSTM_CRF._forward_alg", "bilstmcrf.BiLSTM_CRF._score_sentence"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._get_lstm_features", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._forward_alg", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._score_sentence"], ["", "def", "neg_log_likelihood", "(", "self", ",", "sentence", ",", "tags", ")", ":", "\n", "        ", "feats", "=", "self", ".", "_get_lstm_features", "(", "sentence", ")", "\n", "forward_score", "=", "self", ".", "_forward_alg", "(", "feats", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "feats", ",", "tags", ")", "\n", "return", "forward_score", "-", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.forward": [[161, 168], ["bilstmcrf.BiLSTM_CRF._get_lstm_features", "bilstmcrf.BiLSTM_CRF._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._get_lstm_features", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._viterbi_decode"], ["", "def", "forward", "(", "self", ",", "sentence", ")", ":", "# dont confuse this with _forward_alg above.", "\n", "# Get the emission scores from the BiLSTM", "\n", "        ", "lstm_feats", "=", "self", ".", "_get_lstm_features", "(", "sentence", ")", "\n", "\n", "# Find the best path, given the features.", "\n", "score", ",", "tag_seq", "=", "self", ".", "_viterbi_decode", "(", "lstm_feats", ")", "\n", "return", "score", ",", "tag_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.constrained_beam_search": [[169, 256], ["torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "constraints.get_constraint_vector", "rectifier_net.RectifierNetwork", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "rectifier_net.RectifierNetwork.load_state_dict", "rectifier_net.RectifierNetwork.eval", "torch.LogSoftmax.tolist", "temp_beam.sort", "range", "len", "torch.LogSoftmax.tolist", "range", "range", "len", "constraints.get_constraint_vector", "rectifier_net.RectifierNetwork.", "torch.LogSoftmax.", "beam[].copy", "beam[].copy.append", "temp_beam.append", "len", "constraints.get_constraint_vector", "rectifier_net.RectifierNetwork.", "len", "constraints.get_constraint_vector.float", "torch.LogSoftmax.", "constraints.get_constraint_vector.float", "new_beam.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_vector", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_vector", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_vector"], ["", "def", "constrained_beam_search", "(", "self", ",", "sentence", ",", "lstm_feats", ",", "args", ",", "embedding_matrix", ",", "tokens", ",", "pos", ")", ":", "\n", "\n", "        ", "log_softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "0", ")", "\n", "beam_arr", "=", "[", "(", "[", "self", ".", "tag_to_ix", "[", "START_TAG", "]", "]", ",", "0.0", ")", "]", "\n", "\n", "if", "args", "[", "'allow_constraint'", "]", "==", "1", ":", "\n", "# Loading the trained rectifier network for constrained inference", "\n", "# Dummy vector returns a dummy vector of the inout shape of the rectifier", "\n", "            ", "dummy_vec", "=", "get_constraint_vector", "(", "args", "[", "'choice'", "]", ",", "args", "[", "'ngram'", "]", ",", "self", ".", "tag_to_ix", ",", "embedding_matrix", "=", "embedding_matrix", ")", "\n", "net", "=", "RectifierNetwork", "(", "len", "(", "dummy_vec", ")", ",", "args", "[", "'hidden_rect'", "]", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", "[", "'constraint_model_dir'", "]", ")", "\n", "net", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n", "", "itert", "=", "0", "\n", "for", "feat", "in", "lstm_feats", ":", "\n", "            ", "itert", "+=", "1", "\n", "temp_beam", "=", "[", "]", "\n", "emission", "=", "log_softmax", "(", "feat", ")", ".", "tolist", "(", ")", "\n", "\n", "for", "beam", "in", "beam_arr", ":", "\n", "# For every beam compute the label log probabilities ", "\n", "# adding all possible beams for the step", "\n", "                ", "prev_tag", "=", "beam", "[", "0", "]", "[", "-", "1", "]", "\n", "\n", "trans_scores", "=", "log_softmax", "(", "self", ".", "transitions", "[", ":", ",", "prev_tag", "]", ")", ".", "tolist", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "tagset_size", ")", ":", "\n", "                    ", "tag_seq", "=", "beam", "[", "0", "]", ".", "copy", "(", ")", "\n", "temp_score", "=", "beam", "[", "1", "]", "\n", "temp_score", "+=", "emission", "[", "i", "]", "+", "trans_scores", "[", "i", "]", "\n", "tag_seq", ".", "append", "(", "i", ")", "\n", "temp_beam", ".", "append", "(", "(", "tag_seq", ",", "temp_score", ")", ")", "\n", "\n", "", "", "temp_beam", ".", "sort", "(", "key", "=", "lambda", "tup", ":", "tup", "[", "1", "]", ",", "reverse", "=", "True", ")", "# sorts in place", "\n", "\n", "\n", "new_beam", "=", "[", "]", "\n", "\n", "######### LOCAL CONSTRAINT CHECK ####################################################", "\n", "if", "args", "[", "'allow_constraint'", "]", ":", "\n", "                ", "i", "=", "0", "\n", "for", "index", "in", "range", "(", "len", "(", "temp_beam", ")", ")", ":", "\n", "# Gets corresponding constraint feature vector for every beam", "\n", "                    ", "vec", "=", "get_constraint_vector", "(", "args", "[", "'choice'", "]", ",", "args", "[", "'ngram'", "]", ",", "self", ".", "tag_to_ix", ",", "temp_beam", "[", "index", "]", "[", "0", "]", ",", "self", ".", "word_embeds", ",", "sentence", "[", ":", "len", "(", "temp_beam", "[", "index", "]", "[", "0", "]", ")", "-", "1", "]", ",", "tokens", "[", ":", "len", "(", "temp_beam", "[", "index", "]", "[", "0", "]", ")", "-", "1", "]", ",", "pos", ")", "\n", "satisfied", "=", "net", "(", "vec", ".", "float", "(", ")", ")", "# Checks if constraint is satisfied", "\n", "\n", "if", "satisfied", "[", "0", "]", ">", "0.5", ":", "\n", "                        ", "i", "+=", "1", "\n", "new_beam", ".", "append", "(", "temp_beam", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                        ", "temp_beam", "[", "index", "]", "=", "(", "temp_beam", "[", "index", "]", "[", "0", "]", ",", "-", "10000", ")", "\n", "\n", "# Break when you have the required amount of beams", "\n", "", "if", "i", "==", "args", "[", "'beam'", "]", ":", "\n", "                        ", "break", "\n", "\n", "\n", "", "", "if", "len", "(", "new_beam", ")", "==", "0", ":", "\n", "                    ", "beam_arr", "=", "[", "temp_beam", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "beam_arr", "=", "new_beam", "\n", "\n", "\n", "\n", "", "", "else", ":", "\n", "# If constraint not allowed or choice is global ", "\n", "# we should continue with the normal BS decoder", "\n", "                ", "beam_arr", "=", "temp_beam", "[", ":", "args", "[", "'beam'", "]", "]", "\n", "\n", "\n", "######### GLOBAL CONSTRAINT CHECK ####################################################", "\n", "########## Irrelevant to the current constraints however should be adjusted ##########", "\n", "####################### when global constraints are added ############################", "\n", "", "", "if", "args", "[", "'choice'", "]", ">", "2", "and", "args", "[", "'allow_constraint'", "]", ":", "\n", "            ", "for", "index", "in", "range", "(", "len", "(", "beam_arr", ")", ")", ":", "\n", "                    ", "vec", "=", "get_constraint_vector", "(", "args", "[", "'choice'", "]", ",", "args", "[", "'ngram'", "]", ",", "self", ".", "tag_to_ix", ",", "beam_arr", "[", "index", "]", "[", "0", "]", ",", "embedding_matrix", ",", "sentence", ")", "\n", "\n", "satisfied", "=", "net", "(", "vec", ".", "float", "(", ")", ")", "\n", "\n", "if", "satisfied", "[", "0", "]", ">", "0.5", ":", "\n", "                        ", "return", "(", "beam_arr", "[", "index", "]", "[", "1", "]", ",", "beam_arr", "[", "index", "]", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "\n", "", "", "", "return", "(", "beam_arr", "[", "0", "]", "[", "1", "]", ",", "beam_arr", "[", "0", "]", "[", "0", "]", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.predict": [[259, 266], ["bilstmcrf.BiLSTM_CRF._get_lstm_features", "bilstmcrf.BiLSTM_CRF.constrained_beam_search"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF._get_lstm_features", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.constrained_beam_search"], ["", "def", "predict", "(", "self", ",", "args", ",", "sentence", ",", "embedding_matrix", ",", "tokens", ",", "pos", ")", ":", "\n", "# Get the emission scores from the BiLSTM", "\n", "        ", "lstm_feats", "=", "self", ".", "_get_lstm_features", "(", "sentence", ")", "\n", "\n", "out", "=", "self", ".", "constrained_beam_search", "(", "sentence", ",", "lstm_feats", ",", "args", ",", "embedding_matrix", ",", "tokens", ",", "pos", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.run_bilstmcrf_glove.config_parser": [[26, 46], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "range"], "function", ["None"], ["def", "config_parser", "(", "parser", ")", ":", "\n", "\t", "\"\"\" Add all command line arguments here\n\t\"\"\"", "\n", "parser", ".", "add_argument", "(", "'--choice'", ",", "type", "=", "int", ",", "choices", "=", "range", "(", "1", ",", "3", ")", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Your constraint choices- \\n 1) Label N-gram existence \\n2) Part of Speech Tags\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ngram'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--train_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/train_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/test_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/dev_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ")", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../models_glove/0.01/16_0.8589211618257261\"", ")", "\n", "parser", ".", "add_argument", "(", "'--constraint_model_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../constraint_models/choice_1/ngram_3/ratio_0.01/90_0.8839285714285714\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_enable'", ",", "type", "=", "str", ",", "default", "=", "\"n\"", ")", "\n", "parser", ".", "add_argument", "(", "'--task_name'", ",", "type", "=", "str", ",", "default", "=", "\"chunking\"", ")", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_rect'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--allow_constraint'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.run_bilstmcrf_glove.get_vectors": [[48, 79], ["preprocess.preprocess", "preprocess.prepare_word2idx_glove", "training_data.copy", "training_data.copy.extend", "training_data.copy.extend", "utils.prepare_tag2idx", "len", "len", "utils.prepare_word2idx", "utils.prepare_tag2idx.keys", "utils.prepare_tag2idx.keys"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.preprocess", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.prepare_word2idx_glove", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_tag2idx", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_word2idx"], ["", "def", "get_vectors", "(", "args", ")", ":", "\n", "\t", "if", "not", "toy", ":", "\n", "\t    ", "training_data", ",", "dev_data", ",", "test_data", "=", "preprocess", "(", "args", "[", "'ratio'", "]", ",", "\n", "args", "[", "'train_dir'", "]", ",", "\n", "args", "[", "'dev_dir'", "]", ",", "\n", "args", "[", "'test_dir'", "]", ")", "\n", "word_to_ix", ",", "training_data", ",", "dev_data", ",", "test_data", ",", "embedding_matrix", "=", "prepare_word2idx_glove", "(", "training_data", ",", "dev_data", ",", "test_data", ")", "\n", "data", "=", "training_data", ".", "copy", "(", ")", "\n", "data", ".", "extend", "(", "dev_data", ")", "\n", "data", ".", "extend", "(", "test_data", ")", "\n", "tag_to_ix", "=", "prepare_tag2idx", "(", "data", ")", "\n", "tag_to_ix", "[", "START_TAG", "]", "=", "len", "(", "tag_to_ix", ".", "keys", "(", ")", ")", "\n", "tag_to_ix", "[", "STOP_TAG", "]", "=", "len", "(", "tag_to_ix", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "EMBEDDING_DIM", "=", "5", "\n", "HIDDEN_DIM", "=", "4", "\n", "# Make up some training data", "\n", "training_data", "=", "[", "(", "\n", "\"the wall street journal reported today that apple corporation made money\"", ".", "split", "(", ")", ",", "\n", "\"B I I I O O O B I O O\"", ".", "split", "(", ")", "\n", ")", ",", "(", "\n", "\"georgia tech is a university in georgia\"", ".", "split", "(", ")", ",", "\n", "\"B I O O O O B\"", ".", "split", "(", ")", "\n", ")", "]", "\n", "\n", "word_to_ix", "=", "prepare_word2idx", "(", "training_data", ")", "\n", "tag_to_ix", "=", "{", "\"B\"", ":", "0", ",", "\"I\"", ":", "1", ",", "\"O\"", ":", "2", ",", "START_TAG", ":", "3", ",", "STOP_TAG", ":", "4", "}", "\n", "dev_data", "=", "None", "\n", "test_data", "=", "None", "\n", "\n", "", "return", "training_data", ",", "dev_data", ",", "test_data", ",", "embedding_matrix", ",", "word_to_ix", ",", "tag_to_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.run_bilstmcrf_glove.train": [[82, 193], ["bilstmcrf.BiLSTM_CRF", "torch.SGD", "range", "len", "bilstmcrf.BiLSTM_CRF.parameters", "time.time", "print", "tqdm.tqdm", "time.time", "print", "print", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.get_rng_state", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.prepare_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "bilstmcrf.BiLSTM_CRF.zero_grad", "utils.prepare_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "bilstmcrf.BiLSTM_CRF.neg_log_likelihood", "model.neg_log_likelihood.item", "model.neg_log_likelihood.backward", "optim.SGD.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.save", "torch.save", "torch.save", "torch.save", "bilstmcrf.BiLSTM_CRF.", "str", "utils.prepare_sequence", "bilstmcrf.BiLSTM_CRF.", "utils.calc_correct", "utils.prepare_sequence", "bilstmcrf.BiLSTM_CRF.", "utils.calc_correct", "os.path.exists", "os.mkdir", "open", "json.dump", "exit", "len", "bilstmcrf.BiLSTM_CRF.state_dict", "optim.SGD.state_dict", "str", "len", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_sequence", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_sequence", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.bilstmcrf.BiLSTM_CRF.neg_log_likelihood", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_sequence", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.calc_correct", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_sequence", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.calc_correct"], ["", "def", "train", "(", "training_data", ",", "dev_data", ",", "embedding_matrix", ",", "test_data", ",", "word_to_ix", ",", "tag_to_ix", ")", ":", "\n", "\t", "\"\"\" Function to train the chunker\n\t\"\"\"", "\n", "model", "=", "BiLSTM_CRF", "(", "len", "(", "word_to_ix", ")", ",", "tag_to_ix", ",", "EMBEDDING_DIM", ",", "HIDDEN_DIM", ",", "embedding_matrix", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.01", ",", "weight_decay", "=", "1e-4", ")", "\n", "\n", "# checkpoint = torch.load(\"./../models_glove/26_0.9544608399545971\")", "\n", "# model.load_state_dict(checkpoint['model_state_dict'])", "\n", "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])", "\n", "# torch.set_rng_state(checkpoint['tst_rnd_state'])", "\n", "\n", "\n", "if", "toy", ":", "\n", "# Check predictions before training", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t    ", "precheck_sent", "=", "prepare_sequence", "(", "training_data", "[", "0", "]", "[", "0", "]", ",", "word_to_ix", ")", "\n", "precheck_tags", "=", "torch", ".", "tensor", "(", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "training_data", "[", "0", "]", "[", "1", "]", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "print", "(", "model", "(", "precheck_sent", ")", ")", "\n", "", "", "best_dev", "=", "0", "\n", "early_stopping", "=", "0", "\n", "# Make sure prepare_sequence from earlier in the LSTM section is loaded", "\n", "for", "epoch", "in", "range", "(", "300", ")", ":", "# again, normally you would NOT do 300 epochs, it is toy data", "\n", "\t    ", "epoch_loss", "=", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Epoch \"", "+", "str", "(", "epoch", "+", "1", ")", ")", "\n", "for", "sentence", ",", "tags", "in", "tqdm", "(", "training_data", ")", ":", "\n", "# Step 1. Remember that Pytorch accumulates gradients.", "\n", "# We need to clear them out before each instance", "\n", "\t        ", "model", ".", "zero_grad", "(", ")", "\n", "\n", "# Step 2. Get our inputs ready for the network, that is,", "\n", "# turn them into Tensors of word indices.", "\n", "sentence_in", "=", "prepare_sequence", "(", "sentence", ",", "word_to_ix", ")", "\n", "targets", "=", "torch", ".", "tensor", "(", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "tags", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "# Step 3. Run our forward pass.", "\n", "loss", "=", "model", ".", "neg_log_likelihood", "(", "sentence_in", ",", "targets", ")", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "# Step 4. Compute the loss, gradients, and update the parameters by", "\n", "# calling optimizer.step()", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Loss : {}\"", ".", "format", "(", "epoch_loss", "/", "len", "(", "training_data", ")", ")", ")", "\n", "print", "(", "\"Time : {}\"", ".", "format", "(", "end", "-", "start", ")", ")", "\n", "\n", "dev_rnd_state", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "\n", "# Check predictions after training", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t    \t", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "sentence", ",", "tags", "in", "dev_data", ":", "\n", "\t    \t\t", "precheck_sent", "=", "prepare_sequence", "(", "sentence", ",", "word_to_ix", ")", "\n", "targets", "=", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "tags", "]", "\n", "\n", "out", "=", "model", "(", "precheck_sent", ")", "\n", "corr", ",", "tot", "=", "calc_correct", "(", "out", ",", "targets", ")", "\n", "correct", "+=", "corr", "\n", "total", "+=", "tot", "\n", "", "dev_acc", "=", "correct", "/", "total", "\n", "print", "(", "\"Dev accuracy (macro): {} \\n\"", ".", "format", "(", "dev_acc", ")", ")", "\n", "\n", "\n", "", "tst_rnd_state", "=", "torch", ".", "get_rng_state", "(", ")", "\n", "\n", "# Check predictions after training", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t    \t", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "sentence", ",", "tags", "in", "test_data", ":", "\n", "\t    \t\t", "precheck_sent", "=", "prepare_sequence", "(", "sentence", ",", "word_to_ix", ")", "\n", "targets", "=", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "tags", "]", "\n", "\n", "out", "=", "model", "(", "precheck_sent", ")", "\n", "corr", ",", "tot", "=", "calc_correct", "(", "out", ",", "targets", ")", "\n", "\n", "correct", "+=", "corr", "\n", "total", "+=", "tot", "\n", "", "test_acc", "=", "correct", "/", "total", "\n", "\n", "# Save models", "\n", "", "if", "args", "[", "'save_enable'", "]", "==", "\"y\"", ":", "\n", "\t        ", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", "+", "str", "(", "args", "[", "\"ratio\"", "]", ")", "+", "\"/\"", ")", ":", "\n", "\t            ", "os", ".", "mkdir", "(", "model_dir", "+", "str", "(", "args", "[", "\"ratio\"", "]", ")", "+", "\"/\"", ")", "\n", "", "torch", ".", "save", "(", "\n", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model_state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "epoch_loss", "/", "len", "(", "training_data", ")", ",", "\n", "'dev_accuracy'", ":", "dev_acc", ",", "\n", "'test_accuracy'", ":", "test_acc", ",", "\n", "'dev_rnd_state'", ":", "dev_rnd_state", ",", "\n", "'tst_rnd_state'", ":", "tst_rnd_state", "\n", "}", ",", "model_dir", "+", "str", "(", "args", "[", "\"ratio\"", "]", ")", "+", "\"/\"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\"_\"", "+", "str", "(", "dev_acc", ")", ")", "\n", "\n", "res", "=", "{", "'dev_acc'", ":", "dev_acc", ",", "'test_acc'", ":", "test_acc", "}", "\n", "\n", "with", "open", "(", "model_dir", "+", "str", "(", "args", "[", "\"ratio\"", "]", ")", "+", "\"/\"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\"_\"", "+", "str", "(", "dev_acc", ")", "+", "\".json\"", ",", "'w'", ")", "as", "fp", ":", "\n", "\t            ", "json", ".", "dump", "(", "res", ",", "fp", ")", "\n", "\n", "\n", "", "", "if", "dev_acc", ">", "best_dev", ":", "\n", "\t    \t", "best_dev", "=", "dev_acc", "\n", "early_stopping", "=", "0", "\n", "", "else", ":", "\n", "\t    \t", "early_stopping", "+=", "1", "\n", "if", "early_stopping", "==", "10", ":", "\n", "\t    \t\t", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_gram_vector": [[25, 42], ["torch.tensor", "temp_data.extend", "range", "torch.tensor", "len", "len", "len", "len", "len"], "function", ["None"], ["def", "get_gram_vector", "(", "choice", ",", "gram", ",", "tag_to_ix", ",", "data", ",", "embedding_matrix", ",", "sentence", ",", "tokens_sent", ",", "pos_tags", ")", ":", "\n", "\n", "\t", "if", "data", "==", "\"dummy\"", ":", "\n", "\t\t", "return", "torch", ".", "tensor", "(", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "tag_to_ix", ")", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "doi", "=", "data", "[", "-", "gram", ":", "]", "\n", "temp_data", "=", "[", "None", "]", "*", "(", "gram", "-", "len", "(", "doi", ")", ")", "\n", "temp_data", ".", "extend", "(", "doi", ")", "\n", "\n", "temp_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "tag_to_ix", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "temp_data", ")", ")", ":", "\n", "\t\t\t", "if", "temp_data", "[", "i", "]", "==", "None", ":", "\n", "\t\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t", "temp_arr", "[", "i", "*", "len", "(", "tag_to_ix", ")", "+", "temp_data", "[", "i", "]", "]", "=", "1", "\n", "\n", "", "", "return", "torch", ".", "tensor", "(", "[", "temp_arr", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_positive_grams": [[44, 67], ["set", "range", "new_targets.append", "new_targets.extend", "new_targets.append", "new_targets.extend", "range", "set.add", "tuple", "len", "len", "len"], "function", ["None"], ["", "", "def", "get_positive_grams", "(", "targets", ",", "gram", ",", "tag_to_ix", ")", ":", "\n", "\t", "gram_set", "=", "set", "(", ")", "\n", "if", "gram", ">", "1", ":", "\n", "\t\t", "new_targets", "=", "[", "None", "]", "*", "(", "gram", "-", "2", ")", "\n", "new_targets", ".", "append", "(", "tag_to_ix", "[", "\"<START>\"", "]", ")", "\n", "new_targets", ".", "extend", "(", "targets", ")", "\n", "new_targets", ".", "append", "(", "tag_to_ix", "[", "\"<STOP>\"", "]", ")", "\n", "new_targets", ".", "extend", "(", "[", "None", "]", "*", "(", "gram", "-", "2", ")", ")", "\n", "# new_targets = [tag_to_ix[\"<START>\"]]*(gram-1)", "\n", "# new_targets.extend(targets)", "\n", "# new_targets.extend([tag_to_ix[\"<STOP>\"]]*(gram-1))", "\n", "", "else", ":", "\n", "\t\t", "new_targets", "=", "targets", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "new_targets", ")", "-", "gram", "+", "1", ")", ":", "\n", "\t\t", "temp_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "tag_to_ix", ")", ")", "\n", "for", "j", "in", "range", "(", "gram", ")", ":", "\n", "\t\t\t", "if", "new_targets", "[", "i", "+", "j", "]", "==", "None", ":", "\n", "\t\t\t\t", "continue", "\n", "", "temp_arr", "[", "j", "*", "len", "(", "tag_to_ix", ")", "+", "new_targets", "[", "i", "+", "j", "]", "]", "=", "1", "\n", "", "gram_set", ".", "add", "(", "tuple", "(", "temp_arr", ")", ")", "\n", "\n", "", "return", "gram_set", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_negative_grams": [[69, 110], ["set", "list().copy", "len", "random.choice", "set", "list.remove", "list", "list", "range", "len", "random.choice", "set", "list.remove", "list", "list().copy.copy", "range", "len", "tuple", "tuple", "tuple", "len", "set.add", "len", "len", "tuple", "tuple", "tuple", "len", "len"], "function", ["None"], ["", "def", "get_negative_grams", "(", "positive_ex", ",", "nminus1set", ",", "tag_to_ix", ",", "no_of_gram", ",", "train_pos", ")", ":", "\n", "\t", "negative_ex", "=", "set", "(", ")", "\n", "for", "arr", "in", "positive_ex", ":", "\n", "\t\t", "temp_arr", "=", "list", "(", "arr", ")", ".", "copy", "(", ")", "\n", "g_pointer", "=", "[", "*", "range", "(", "no_of_gram", ")", "]", "\n", "flag", "=", "0", "\n", "while", "len", "(", "g_pointer", ")", "!=", "0", ":", "\n", "\t\t\t", "index", "=", "random", ".", "choice", "(", "g_pointer", ")", "\n", "g_pointer", "=", "set", "(", "g_pointer", ")", "\n", "g_pointer", ".", "remove", "(", "index", ")", "\n", "g_pointer", "=", "list", "(", "g_pointer", ")", "\n", "\n", "t_pointer", "=", "[", "*", "range", "(", "len", "(", "tag_to_ix", ")", ")", "]", "\n", "while", "len", "(", "t_pointer", ")", "!=", "0", ":", "\n", "\t\t\t\t", "index_t", "=", "random", ".", "choice", "(", "t_pointer", ")", "\n", "t_pointer", "=", "set", "(", "t_pointer", ")", "\n", "t_pointer", ".", "remove", "(", "index_t", ")", "\n", "t_pointer", "=", "list", "(", "t_pointer", ")", "\n", "\n", "new", "=", "[", "0", "]", "*", "len", "(", "tag_to_ix", ")", "\n", "new", "[", "index_t", "]", "=", "1", "\n", "new_arr", "=", "temp_arr", ".", "copy", "(", ")", "\n", "new_arr", "[", "index", "*", "len", "(", "tag_to_ix", ")", ":", "(", "index", "+", "1", ")", "*", "len", "(", "tag_to_ix", ")", "]", "=", "new", "\n", "\n", "if", "tuple", "(", "new_arr", ")", "in", "negative_ex", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "if", "tuple", "(", "new_arr", ")", "in", "positive_ex", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "if", "tuple", "(", "new_arr", ")", "in", "train_pos", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "if", "(", "tuple", "(", "new_arr", "[", "-", "(", "no_of_gram", "-", "1", ")", "*", "len", "(", "tag_to_ix", ")", ":", "]", ")", "in", "nminus1set", ")", "and", "(", "tuple", "(", "new_arr", "[", ":", "(", "no_of_gram", "-", "1", ")", "*", "len", "(", "tag_to_ix", ")", "]", ")", "in", "nminus1set", ")", ":", "\n", "\t\t\t\t\t\t", "negative_ex", ".", "add", "(", "tuple", "(", "new_arr", ")", ")", "\n", "flag", "=", "1", "\n", "break", "\n", "\n", "", "", "", "if", "flag", "==", "1", ":", "\n", "\t\t\t\t", "break", "\n", "\n", "", "", "", "return", "negative_ex", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.ngram_lab": [[113, 128], ["set", "set", "constraints.get_negative_grams", "constraints.get_positive_grams", "positive_ex.union.union", "nminus1set.union.union", "constraints.get_positive_grams", "nminus1set.union.union"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_negative_grams", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_positive_grams", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_positive_grams"], ["", "def", "ngram_lab", "(", "data", ",", "grams", ",", "word_to_ix", ",", "tag_to_ix", ",", "embedding_matrix", ",", "train_pos", ",", "nminus1", ")", ":", "\n", "\t", "positive_ex", "=", "set", "(", ")", "\n", "nminus1set", "=", "set", "(", ")", "\n", "for", "sentence", ",", "tags", "in", "data", ":", "\n", "\t\t", "targets", "=", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "tags", "]", "\n", "\n", "if", "grams", ">", "1", ":", "\n", "\t\t\t", "nminus1set_temp", "=", "get_positive_grams", "(", "targets", ",", "grams", "-", "1", ",", "tag_to_ix", ")", "\n", "nminus1set", "=", "nminus1set", ".", "union", "(", "nminus1set_temp", ")", "\n", "", "n_set", "=", "get_positive_grams", "(", "targets", ",", "grams", ",", "tag_to_ix", ")", "\n", "positive_ex", "=", "positive_ex", ".", "union", "(", "n_set", ")", "\n", "\n", "", "negative_ex", "=", "get_negative_grams", "(", "positive_ex", ",", "nminus1set", ".", "union", "(", "nminus1", ")", ",", "tag_to_ix", ",", "grams", ",", "train_pos", ")", "\n", "\n", "return", "positive_ex", ",", "negative_ex", ",", "nminus1set", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_postag_vector": [[133, 180], ["len", "len", "torch.tensor", "temp_data.extend", "temp_pos.extend", "range", "temp_arr.extend", "torch.tensor", "pos.append", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_postag_vector", "(", "choice", ",", "gram", ",", "tag_to_ix", ",", "data", ",", "embedding_matrix", ",", "sentence", ",", "tokens_sent", ",", "pos_tags", ")", ":", "\n", "\t", "tagdict", "=", "[", "'ADJ'", ",", "'ADP'", ",", "'ADV'", ",", "'AUX'", ",", "'CCONJ'", ",", "'DET'", ",", "'INTJ'", ",", "\n", "'NOUN'", ",", "'NUM'", ",", "'PART'", ",", "'PRON'", ",", "'PROPN'", ",", "'PUNCT'", ",", "\n", "'SCONJ'", ",", "'SYM'", ",", "'VERB'", ",", "'X'", "]", "\n", "cnt", "=", "0", "\n", "pos_tagdict", "=", "{", "}", "\n", "for", "key", "in", "tagdict", ":", "\n", "\t\t", "pos_tagdict", "[", "key", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "pos_tagdict", "[", "\"start\"", "]", "=", "len", "(", "pos_tagdict", ")", "\n", "pos_tagdict", "[", "\"stop\"", "]", "=", "len", "(", "pos_tagdict", ")", "\n", "\n", "if", "data", "==", "\"dummy\"", ":", "\n", "\t\t", "return", "torch", ".", "tensor", "(", "[", "0", "]", "*", "(", "gram", "*", "(", "len", "(", "pos_tagdict", ")", "+", "len", "(", "tag_to_ix", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "pos_tags", "=", "pos_tags", "[", ":", "len", "(", "tokens_sent", ")", "]", "\n", "pos", "=", "[", "]", "\n", "\n", "for", "t", "in", "pos_tags", ":", "\n", "\t\t\t", "pos", ".", "append", "(", "pos_tagdict", "[", "t", "]", ")", "\n", "\n", "", "doi", "=", "data", "[", "-", "gram", ":", "]", "\n", "poi", "=", "pos", "[", "-", "gram", ":", "]", "\n", "\n", "temp_data", "=", "[", "None", "]", "*", "(", "gram", "-", "len", "(", "doi", ")", ")", "\n", "temp_data", ".", "extend", "(", "doi", ")", "\n", "\n", "temp_pos", "=", "[", "None", "]", "*", "(", "gram", "-", "len", "(", "poi", ")", ")", "\n", "temp_pos", ".", "extend", "(", "poi", ")", "\n", "\n", "if", "len", "(", "poi", ")", "<", "gram", ":", "\n", "\t\t\t", "temp_pos", "[", "gram", "-", "len", "(", "poi", ")", "-", "1", "]", "=", "pos_tagdict", "[", "\"start\"", "]", "\n", "\n", "\n", "", "temp_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "tag_to_ix", ")", ")", "\n", "temp_pos_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "pos_tagdict", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "gram", ")", ":", "\n", "\t\t\t", "if", "temp_data", "[", "j", "]", "==", "None", ":", "\n", "\t\t\t\t", "continue", "\n", "", "temp_arr", "[", "j", "*", "len", "(", "tag_to_ix", ")", "+", "temp_data", "[", "j", "]", "]", "=", "1", "\n", "temp_pos_arr", "[", "j", "*", "len", "(", "pos_tagdict", ")", "+", "temp_pos", "[", "j", "]", "]", "=", "1", "\n", "\n", "", "temp_arr", ".", "extend", "(", "temp_pos_arr", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "[", "temp_arr", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_negative_pos_tag": [[181, 222], ["set", "len", "list().copy", "len", "len", "random.choice", "set", "list.remove", "list", "list", "list", "range", "len", "random.choice", "set", "list.remove", "list", "list().copy.copy", "range", "len", "tuple", "tuple", "tuple", "set.add", "len", "tuple", "len", "len"], "function", ["None"], ["", "", "def", "get_negative_pos_tag", "(", "positive_ex", ",", "tag_to_ix", ",", "no_of_gram", ",", "train_pos", ")", ":", "\n", "\t", "negative_set", "=", "set", "(", ")", "\n", "tag_index", "=", "len", "(", "list", "(", "positive_ex", ")", "[", "0", "]", ")", "-", "no_of_gram", "*", "len", "(", "tag_to_ix", ")", "\n", "\n", "for", "arr", "in", "positive_ex", ":", "\n", "\t\t", "temp_arr", "=", "list", "(", "arr", ")", ".", "copy", "(", ")", "\n", "g_pointer", "=", "[", "*", "range", "(", "no_of_gram", ")", "]", "\n", "flag", "=", "0", "\n", "while", "len", "(", "g_pointer", ")", "!=", "0", ":", "\n", "\t\t\t", "index", "=", "random", ".", "choice", "(", "g_pointer", ")", "\n", "g_pointer", "=", "set", "(", "g_pointer", ")", "\n", "g_pointer", ".", "remove", "(", "index", ")", "\n", "g_pointer", "=", "list", "(", "g_pointer", ")", "\n", "\n", "t_pointer", "=", "[", "*", "range", "(", "len", "(", "tag_to_ix", ")", ")", "]", "\n", "while", "len", "(", "t_pointer", ")", "!=", "0", ":", "\n", "\t\t\t\t", "index_t", "=", "random", ".", "choice", "(", "t_pointer", ")", "\n", "t_pointer", "=", "set", "(", "t_pointer", ")", "\n", "t_pointer", ".", "remove", "(", "index_t", ")", "\n", "t_pointer", "=", "list", "(", "t_pointer", ")", "\n", "\n", "new", "=", "[", "0", "]", "*", "len", "(", "tag_to_ix", ")", "\n", "new", "[", "index_t", "]", "=", "1", "\n", "new_arr", "=", "temp_arr", ".", "copy", "(", ")", "\n", "new_arr", "[", "tag_index", "+", "index", "*", "len", "(", "tag_to_ix", ")", ":", "tag_index", "+", "(", "index", "+", "1", ")", "*", "len", "(", "tag_to_ix", ")", "]", "=", "new", "\n", "\n", "if", "tuple", "(", "new_arr", ")", "in", "negative_set", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "if", "tuple", "(", "new_arr", ")", "in", "positive_ex", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "if", "tuple", "(", "new_arr", ")", "in", "train_pos", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "negative_set", ".", "add", "(", "tuple", "(", "new_arr", ")", ")", "\n", "flag", "=", "1", "\n", "break", "\n", "\n", "", "", "if", "flag", "==", "1", ":", "\n", "\t\t\t\t", "break", "\n", "\n", "", "", "", "return", "negative_set", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_positive_pos": [[224, 256], ["set", "range", "new_targets.append", "new_pos.append", "new_targets.extend", "new_pos.extend", "new_targets.append", "new_pos.append", "new_targets.extend", "new_pos.extend", "range", "temp_arr.extend", "set.add", "tuple", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_positive_pos", "(", "pos", ",", "targets", ",", "gram", ",", "tag_to_ix", ",", "pos_tagdict", ")", ":", "\n", "\t", "gram_set", "=", "set", "(", ")", "\n", "\n", "if", "gram", ">", "1", ":", "\n", "\t\t", "new_targets", "=", "[", "None", "]", "*", "(", "gram", "-", "2", ")", "\n", "new_pos", "=", "[", "None", "]", "*", "(", "gram", "-", "2", ")", "\n", "new_targets", ".", "append", "(", "tag_to_ix", "[", "\"<START>\"", "]", ")", "\n", "new_pos", ".", "append", "(", "pos_tagdict", "[", "\"start\"", "]", ")", "\n", "new_targets", ".", "extend", "(", "targets", ")", "\n", "new_pos", ".", "extend", "(", "pos", ")", "\n", "new_targets", ".", "append", "(", "tag_to_ix", "[", "\"<STOP>\"", "]", ")", "\n", "new_pos", ".", "append", "(", "pos_tagdict", "[", "\"stop\"", "]", ")", "\n", "new_targets", ".", "extend", "(", "[", "None", "]", "*", "(", "gram", "-", "2", ")", ")", "\n", "new_pos", ".", "extend", "(", "[", "None", "]", "*", "(", "gram", "-", "2", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "new_targets", "=", "targets", "\n", "new_pos", "=", "pos", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "new_targets", ")", "-", "gram", "+", "1", ")", ":", "\n", "\t\t", "temp_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "tag_to_ix", ")", ")", "\n", "temp_pos_arr", "=", "[", "0", "]", "*", "(", "gram", "*", "len", "(", "pos_tagdict", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "gram", ")", ":", "\n", "\t\t\t", "if", "new_targets", "[", "i", "+", "j", "]", "==", "None", ":", "\n", "\t\t\t\t", "continue", "\n", "", "temp_arr", "[", "j", "*", "len", "(", "tag_to_ix", ")", "+", "new_targets", "[", "i", "+", "j", "]", "]", "=", "1", "\n", "temp_pos_arr", "[", "j", "*", "len", "(", "pos_tagdict", ")", "+", "new_pos", "[", "i", "+", "j", "]", "]", "=", "1", "\n", "\n", "", "temp_arr", ".", "extend", "(", "temp_pos_arr", ")", "\n", "gram_set", ".", "add", "(", "tuple", "(", "temp_arr", ")", ")", "\n", "\n", "", "return", "gram_set", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.pos_tag": [[258, 288], ["set", "len", "len", "constraints.get_negative_pos_tag", "nlp.tokenizer.tokens_from_list", "nlp.tagger", "constraints.get_positive_pos", "positive_ex.union.union", "pos.append"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_negative_pos_tag", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_positive_pos"], ["", "def", "pos_tag", "(", "data", ",", "grams", ",", "word_to_ix", ",", "tag_to_ix", ",", "embedding_matrix", ",", "train_pos", ",", "nminus1", ")", ":", "\n", "\t", "positive_ex", "=", "set", "(", ")", "\n", "tagdict", "=", "[", "'ADJ'", ",", "'ADP'", ",", "'ADV'", ",", "'AUX'", ",", "'CCONJ'", ",", "'DET'", ",", "'INTJ'", ",", "\n", "'NOUN'", ",", "'NUM'", ",", "'PART'", ",", "'PRON'", ",", "'PROPN'", ",", "'PUNCT'", ",", "\n", "'SCONJ'", ",", "'SYM'", ",", "'VERB'", ",", "'X'", "]", "\n", "cnt", "=", "0", "\n", "pos_tagdict", "=", "{", "}", "\n", "for", "key", "in", "tagdict", ":", "\n", "\t\t", "pos_tagdict", "[", "key", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "pos_tagdict", "[", "\"start\"", "]", "=", "len", "(", "pos_tagdict", ")", "\n", "pos_tagdict", "[", "\"stop\"", "]", "=", "len", "(", "pos_tagdict", ")", "\n", "\n", "for", "sentence", ",", "tags", "in", "data", ":", "\n", "\t\t", "targets", "=", "[", "tag_to_ix", "[", "t", "]", "for", "t", "in", "tags", "]", "\n", "\n", "pos", "=", "[", "]", "\n", "tokens", "=", "nlp", ".", "tokenizer", ".", "tokens_from_list", "(", "sentence", ")", "\n", "nlp", ".", "tagger", "(", "tokens", ")", "\n", "for", "t", "in", "tokens", ":", "\n", "\t\t\t", "pos", ".", "append", "(", "pos_tagdict", "[", "t", ".", "pos_", "]", ")", "\n", "\n", "", "n_set", "=", "get_positive_pos", "(", "pos", ",", "targets", ",", "grams", ",", "tag_to_ix", ",", "pos_tagdict", ")", "\n", "\n", "positive_ex", "=", "positive_ex", ".", "union", "(", "n_set", ")", "\n", "\n", "", "negative_ex", "=", "get_negative_pos_tag", "(", "positive_ex", ",", "tag_to_ix", ",", "grams", ",", "train_pos", ")", "\n", "\n", "return", "positive_ex", ",", "negative_ex", ",", "nminus1", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_features": [[294, 299], ["set", "set", "print"], "function", ["None"], ["def", "get_constraint_features", "(", "data", ",", "opt", ",", "grams", ",", "word_to_ix", ",", "tag_to_ix", ",", "embedding_matrix", ",", "train_pos", "=", "set", "(", ")", ",", "nminus1", "=", "set", "(", ")", ")", ":", "\n", "\t", "print", "(", "\"Preparing constraint features for {} considering {} grams\"", ".", "format", "(", "opt_name", "[", "opt", "-", "1", "]", ",", "grams", ")", ")", "\n", "positive_ex", ",", "negative_ex", ",", "m1", "=", "func_dict", "[", "opt", "-", "1", "]", "(", "data", ",", "grams", ",", "word_to_ix", ",", "tag_to_ix", ",", "embedding_matrix", ",", "train_pos", ",", "nminus1", ")", "\n", "\n", "return", "positive_ex", ",", "negative_ex", ",", "m1", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_vector": [[301, 304], ["None"], "function", ["None"], ["", "def", "get_constraint_vector", "(", "choice", ",", "gram", ",", "tag_to_ix", ",", "data", "=", "\"dummy\"", ",", "embedding_matrix", "=", "None", ",", "sentence", "=", "None", ",", "tokens_sent", "=", "None", ",", "pos", "=", "None", ")", ":", "\n", "\t", "vec", "=", "vec_dict", "[", "choice", "-", "1", "]", "(", "choice", ",", "gram", ",", "tag_to_ix", ",", "data", ",", "embedding_matrix", ",", "sentence", ",", "tokens_sent", ",", "pos", ")", "\n", "return", "vec", "", "", ""]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.preprocess": [[4, 68], ["open().readlines", "open().readlines", "open().readlines", "print", "print", "print", "[].strip", "temp_wrd.append", "temp_lab.append", "[].strip", "temp_wrd.append", "temp_lab.append", "[].strip", "temp_wrd.append", "temp_lab.append", "len", "len", "len", "open", "open", "open", "train_d.append", "line.split", "dev_d.append", "line.split", "int", "int", "test_d.append", "line.split", "line.split", "line.split", "len", "len", "line.split"], "function", ["None"], ["def", "preprocess", "(", "ratio", "=", "1", ",", "\n", "train_file", "=", "\"./../data/train_new.txt\"", ",", "\n", "dev_file", "=", "\"./../data/dev_new.txt\"", ",", "\n", "test_file", "=", "\"./../data/test_new.txt\"", ")", ":", "\n", "\n", "\t", "train_data", "=", "open", "(", "train_file", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "dev_data", "=", "open", "(", "dev_file", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "test_data", "=", "open", "(", "test_file", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "\n", "train_d", "=", "[", "]", "\n", "dev_d", "=", "[", "]", "\n", "test_d", "=", "[", "]", "\n", "\n", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "\n", "for", "line", "in", "train_data", ":", "\n", "\t\t", "if", "line", "==", "\"\\n\"", ":", "\n", "\t\t\t", "train_d", ".", "append", "(", "(", "temp_wrd", ",", "temp_lab", ")", ")", "\n", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "continue", "\n", "", "lab", "=", "line", ".", "split", "(", "\" \"", ")", "[", "1", "]", ".", "strip", "(", "\"\\n\"", ")", "\n", "word", "=", "line", ".", "split", "(", "\" \"", ")", "[", "0", "]", "\n", "temp_wrd", ".", "append", "(", "word", ")", "\n", "temp_lab", ".", "append", "(", "lab", ")", "\n", "\n", "\n", "", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "\n", "for", "line", "in", "dev_data", ":", "\n", "\t\t", "if", "line", "==", "\"\\n\"", ":", "\n", "\t\t\t", "dev_d", ".", "append", "(", "(", "temp_wrd", ",", "temp_lab", ")", ")", "\n", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "continue", "\n", "", "lab", "=", "line", ".", "split", "(", "\" \"", ")", "[", "1", "]", ".", "strip", "(", "\"\\n\"", ")", "\n", "word", "=", "line", ".", "split", "(", "\" \"", ")", "[", "0", "]", "\n", "temp_wrd", ".", "append", "(", "word", ")", "\n", "temp_lab", ".", "append", "(", "lab", ")", "\n", "\n", "", "train_d", "=", "train_d", "[", ":", "int", "(", "len", "(", "train_d", ")", "*", "ratio", ")", "]", "\n", "dev_d", "=", "dev_d", "[", ":", "int", "(", "len", "(", "dev_d", ")", "*", "ratio", ")", "]", "\n", "\n", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "\n", "for", "line", "in", "test_data", ":", "\n", "\t\t", "if", "line", "==", "\"\\n\"", ":", "\n", "\t\t\t", "test_d", ".", "append", "(", "(", "temp_wrd", ",", "temp_lab", ")", ")", "\n", "temp_wrd", "=", "[", "]", "\n", "temp_lab", "=", "[", "]", "\n", "continue", "\n", "", "lab", "=", "line", ".", "split", "(", "\" \"", ")", "[", "1", "]", ".", "strip", "(", "\"\\n\"", ")", "\n", "word", "=", "line", ".", "split", "(", "\" \"", ")", "[", "0", "]", "\n", "temp_wrd", ".", "append", "(", "word", ")", "\n", "temp_lab", ".", "append", "(", "lab", ")", "\n", "\n", "", "print", "(", "len", "(", "train_d", ")", ")", "\n", "print", "(", "len", "(", "dev_d", ")", ")", "\n", "print", "(", "len", "(", "test_d", ")", ")", "\n", "\n", "return", "train_d", ",", "dev_d", ",", "test_d", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.loadGloveModel": [[70, 85], ["print", "open", "print", "line.split", "len", "numpy.array", "float"], "function", ["None"], ["", "def", "loadGloveModel", "(", "gloveFile", ")", ":", "\n", "    ", "print", "(", "\"Loading Glove Vocab\"", ")", "\n", "f", "=", "open", "(", "gloveFile", ",", "'r'", ")", "\n", "#f2 = open(gloveFile,'r').readlines()", "\n", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "        ", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "try", ":", "\n", "        \t", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "except", ":", "\n", "        \t", "continue", "\n", "", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.prepare_word2idx_glove": [[87, 125], ["preprocess.loadGloveModel", "loadGloveModel.keys", "range", "range", "range", "print", "len", "range", "len", "range", "len", "range", "len", "len", "len", "word_to_ix.keys", "word_to_ix.keys", "word_to_ix.keys", "len", "embedding_matrix.append", "len", "embedding_matrix.append", "len", "embedding_matrix.append"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.loadGloveModel"], ["", "def", "prepare_word2idx_glove", "(", "training_data", ",", "dev_data", ",", "test_data", ")", ":", "\n", "\t", "word_to_ix", "=", "{", "'unk'", ":", "0", "}", "\n", "embed", "=", "loadGloveModel", "(", "\"./../data/glove.840B.300d.txt\"", ")", "\n", "glove_vocab", "=", "embed", ".", "keys", "(", ")", "\n", "embedding_matrix", "=", "[", "embed", "[", "'unk'", "]", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "training_data", ")", ")", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "0", ",", "len", "(", "training_data", "[", "i", "]", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t", "if", "training_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "word_to_ix", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "if", "training_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "glove_vocab", ":", "\n", "\t\t\t\t\t", "training_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "=", "'unk'", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "word_to_ix", "[", "training_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", "=", "len", "(", "word_to_ix", ")", "\n", "embedding_matrix", ".", "append", "(", "embed", "[", "training_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dev_data", ")", ")", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "0", ",", "len", "(", "dev_data", "[", "i", "]", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t", "if", "dev_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "word_to_ix", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "if", "dev_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "glove_vocab", ":", "\n", "\t\t\t\t\t", "dev_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "=", "'unk'", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "word_to_ix", "[", "dev_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", "=", "len", "(", "word_to_ix", ")", "\n", "embedding_matrix", ".", "append", "(", "embed", "[", "dev_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "test_data", ")", ")", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "0", ",", "len", "(", "test_data", "[", "i", "]", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t", "if", "test_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "word_to_ix", ".", "keys", "(", ")", ":", "\n", "\t\t\t\t", "if", "test_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "not", "in", "glove_vocab", ":", "\n", "\t\t\t\t\t", "test_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "=", "'unk'", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "word_to_ix", "[", "test_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", "=", "len", "(", "word_to_ix", ")", "\n", "embedding_matrix", ".", "append", "(", "embed", "[", "test_data", "[", "i", "]", "[", "0", "]", "[", "j", "]", "]", ")", "\n", "\n", "\n", "", "", "", "", "print", "(", "\"Loaded GloVe vectors\"", ")", "\n", "del", "embed", "\n", "\n", "return", "word_to_ix", ",", "training_data", ",", "dev_data", ",", "test_data", ",", "embedding_matrix", "", "", ""]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.rectifier_net.RectifierNetwork.__init__": [[12, 21], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.rectifier_net.RectifierNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ")", ":", "\n", "\t\t", "\"\"\" Constructor\n\t\tInput: in_dim\t- Dimension of input vector\n\t\t\t   out_dim\t- Dimension of output vector\n\t\t\"\"\"", "\n", "super", "(", "RectifierNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ")", "\n", "#self.fc2 = nn.Linear(out_dim,1)", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.rectifier_net.RectifierNetwork.forward": [[23, 31], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "rectifier_net.RectifierNetwork.sigmoid", "rectifier_net.RectifierNetwork.fc1", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "\t\t", "\"\"\" Function for forward pass\n\t\tInput:\tinp \t- Input to the network of dimension in_dim\n\t\tOutput: output \t- Output of the network with dimension 1\n\t\t\"\"\"", "\n", "out_intermediate", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inp", ")", ")", "\n", "output", "=", "self", ".", "sigmoid", "(", "1", "-", "torch", ".", "sum", "(", "out_intermediate", ",", "1", ")", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.config_parser": [[16, 33], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "range"], "function", ["None"], ["def", "config_parser", "(", "parser", ")", ":", "\n", "\t", "\"\"\" Add all command line arguments here\n\t\"\"\"", "\n", "parser", ".", "add_argument", "(", "'--choice'", ",", "type", "=", "int", ",", "choices", "=", "range", "(", "1", ",", "3", ")", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Your constraint choices- \\n 1) Label N-gram existence \\n2) Part of Speech Tags\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ngram'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--train_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/train_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/test_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../data/dev_new.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./../constraint_models_2/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_rect'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--task_name'", ",", "type", "=", "str", ",", "default", "=", "\"chunking\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_enable'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.convertSettoList": [[34, 49], ["list", "list", "list", "list", "list.copy", "lab.extend", "pstv.copy.extend", "map", "map", "len", "len"], "function", ["None"], ["", "def", "convertSettoList", "(", "pstv_ex", ",", "neg_ex", ")", ":", "\n", "\t", "pstv_list", "=", "list", "(", "pstv_ex", ")", "\n", "#pstv = [list(elem) for elem in pstv_list]", "\n", "pstv", "=", "list", "(", "map", "(", "list", ",", "pstv_list", ")", ")", "\n", "\n", "neg_list", "=", "list", "(", "neg_ex", ")", "\n", "#neg = [list(elem) for elem in neg_list]", "\n", "neg", "=", "list", "(", "map", "(", "list", ",", "neg_list", ")", ")", "\n", "\n", "data", "=", "pstv", ".", "copy", "(", ")", "\n", "lab", "=", "[", "1", "]", "*", "len", "(", "pstv", ")", "\n", "lab", ".", "extend", "(", "[", "0", "]", "*", "len", "(", "neg", ")", ")", "\n", "data", ".", "extend", "(", "neg", ")", "\n", "\n", "return", "data", ",", "lab", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.getVectors": [[52, 126], ["os.path.exists", "training_data.copy", "training_data.copy.extend", "training_data.copy.extend", "utils.prepare_tag2idx", "len", "len", "constraints.get_constraint_features", "constraints.get_constraint_features", "print", "print", "print", "print", "cons_learn.convertSettoList", "cons_learn.convertSettoList", "print", "print", "preprocess.preprocess", "preprocess.prepare_word2idx_glove", "print", "utils.prepare_tag2idx.keys", "utils.prepare_tag2idx.keys", "len", "len", "len", "open", "pickle.load", "open", "pickle.dump", "str", "str", "str", "str", "pstv_ex.intersection", "pstv_ex.intersection", "pstv_dev_ex.intersection", "str", "len", "len", "len", "len", "str", "str"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_tag2idx", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_features", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.constraints.get_constraint_features", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.convertSettoList", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.convertSettoList", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.preprocess", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.preprocess.prepare_word2idx_glove"], ["", "def", "getVectors", "(", "args", ")", ":", "\n", "\t", "\"\"\" Based on the training, dev and test files, we get the positive and negative\n\tvectors with their respective labels for the rectifier training \n\t\"\"\"", "\n", "START_TAG", "=", "\"<START>\"", "\n", "STOP_TAG", "=", "\"<STOP>\"", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "data_dir", "+", "args", "[", "'task_name'", "]", "+", "\"_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\".pkl\"", ")", ":", "\n", "\t\t", "print", "(", "\"preprocessed dumps found. Loading them.\"", ")", "\n", "with", "open", "(", "data_dir", "+", "args", "[", "'task_name'", "]", "+", "\"_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\".pkl\"", ",", "'rb'", ")", "as", "handle", ":", "\n", "\t\t\t", "b", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "word_to_ix", "=", "b", "[", "'word_to_ix'", "]", "\n", "training_data", "=", "b", "[", "'training_data'", "]", "\n", "dev_data", "=", "b", "[", "'dev_data'", "]", "\n", "test_data", "=", "b", "[", "'test_data'", "]", "\n", "embedding_matrix", "=", "b", "[", "'embedding_matrix'", "]", "\n", "", "else", ":", "\n", "\t\t", "print", "(", "\"Saved preprocessed data files not found .....creating new dump\"", ")", "\n", "training_data", ",", "dev_data", ",", "test_data", "=", "preprocess", "(", "args", "[", "'ratio'", "]", ",", "\n", "args", "[", "'train_dir'", "]", ",", "\n", "args", "[", "'dev_dir'", "]", ",", "\n", "args", "[", "'test_dir'", "]", ")", "\n", "\n", "\n", "word_to_ix", ",", "training_data", ",", "dev_data", ",", "test_data", ",", "embedding_matrix", "=", "prepare_word2idx_glove", "(", "training_data", ",", "dev_data", ",", "test_data", ")", "\n", "\n", "save_dict", "=", "{", "\"word_to_ix\"", ":", "word_to_ix", ",", "\"training_data\"", ":", "training_data", ",", "\"dev_data\"", ":", "dev_data", ",", "\"test_data\"", ":", "test_data", ",", "\"embedding_matrix\"", ":", "embedding_matrix", "}", "\n", "\n", "with", "open", "(", "data_dir", "+", "args", "[", "'task_name'", "]", "+", "\"_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\".pkl\"", ",", "'wb'", ")", "as", "handle", ":", "\n", "\t\t\t", "pickle", ".", "dump", "(", "save_dict", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "print", "(", "\"New preprocessed files dumped.....Things'll get faster next time!\"", ")", "\n", "\n", "\n", "", "data", "=", "training_data", ".", "copy", "(", ")", "\n", "data", ".", "extend", "(", "dev_data", ")", "\n", "data", ".", "extend", "(", "test_data", ")", "\n", "\n", "#word_to_ix = prepare_word2idx(data)", "\n", "\n", "tag_to_ix", "=", "prepare_tag2idx", "(", "data", ")", "\n", "tag_to_ix", "[", "START_TAG", "]", "=", "len", "(", "tag_to_ix", ".", "keys", "(", ")", ")", "\n", "tag_to_ix", "[", "STOP_TAG", "]", "=", "len", "(", "tag_to_ix", ".", "keys", "(", ")", ")", "\n", "\n", "\n", "pstv_ex", ",", "neg_ex", ",", "nminus1", "=", "get_constraint_features", "(", "training_data", ",", "\n", "args", "[", "'choice'", "]", ",", "\n", "args", "[", "'ngram'", "]", ",", "\n", "word_to_ix", ",", "\n", "tag_to_ix", ",", "\n", "embedding_matrix", ")", "\n", "\n", "pstv_dev_ex", ",", "neg_dev_ex", ",", "_", "=", "get_constraint_features", "(", "dev_data", ",", "\n", "args", "[", "'choice'", "]", ",", "\n", "args", "[", "'ngram'", "]", ",", "\n", "word_to_ix", ",", "\n", "tag_to_ix", ",", "\n", "embedding_matrix", ",", "\n", "train_pos", "=", "pstv_ex", ",", "\n", "nminus1", "=", "nminus1", ")", "\n", "print", "(", "\"Positive Examples: \"", "+", "str", "(", "len", "(", "pstv_ex", ")", ")", ")", "\n", "print", "(", "\"Negative Examples: \"", "+", "str", "(", "len", "(", "neg_ex", ")", ")", ")", "\n", "print", "(", "\"Dev Positive Examples: \"", "+", "str", "(", "len", "(", "pstv_dev_ex", ")", ")", ")", "\n", "print", "(", "\"Dev Negative Examples: \"", "+", "str", "(", "len", "(", "neg_dev_ex", ")", ")", ")", "\n", "\n", "assert", "len", "(", "pstv_ex", ".", "intersection", "(", "neg_ex", ")", ")", "==", "0", "\n", "assert", "len", "(", "pstv_ex", ".", "intersection", "(", "neg_dev_ex", ")", ")", "==", "0", "\n", "assert", "len", "(", "pstv_dev_ex", ".", "intersection", "(", "neg_dev_ex", ")", ")", "==", "0", "\n", "\n", "data", ",", "lab", "=", "convertSettoList", "(", "pstv_ex", ",", "neg_ex", ")", "\n", "data_dev", ",", "lab_dev", "=", "convertSettoList", "(", "pstv_dev_ex", ",", "neg_dev_ex", ")", "\n", "\n", "return", "data", ",", "lab", ",", "data_dev", ",", "lab_dev", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.predict": [[129, 146], ["enumerate", "net", "range", "len"], "function", ["None"], ["", "def", "predict", "(", "net", ",", "loader", ")", ":", "\n", "\t", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "index", ",", "(", "inp", ",", "gold", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "\t\t", "pred", "=", "net", "(", "inp", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "pred", ")", ")", ":", "\n", "\t\t\t", "if", "pred", "[", "i", "]", ">=", "0.5", ":", "\n", "\t\t\t\t", "pred_b", "=", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "pred_b", "=", "0", "\n", "\n", "", "if", "pred_b", "==", "gold", "[", "i", "]", ":", "\n", "\t\t\t\t", "correct", "+=", "1", "\n", "", "total", "+=", "1", "\n", "\n", "", "", "return", "correct", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.train": [[149, 216], ["torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "rectifier_net.RectifierNetwork", "torch.Adam", "torch.BCELoss", "range", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "len", "rectifier_net.RectifierNetwork.parameters", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "enumerate", "cons_learn.predict", "cons_learn.predict", "print", "print", "print", "print", "str", "optim.Adam.zero_grad", "rectifier_net.RectifierNetwork.", "nn.BCELoss.", "loss.item", "loss.backward", "optim.Adam.step", "print", "exit", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.save", "torch.save", "torch.save", "str", "str", "str", "str", "str", "str", "str", "open", "json.dump", "len", "rectifier_net.RectifierNetwork.state_dict", "optim.Adam.state_dict", "str", "str", "str", "str", "str", "str", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.predict", "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.cons_learn.predict"], ["", "def", "train", "(", "data", ",", "lab", ",", "data_dev", ",", "lab_dev", ")", ":", "\n", "\t", "\"\"\" Function to train the rectifier network\n\t\"\"\"", "\n", "\n", "# Data Loaders are formed for the data splits", "\n", "dataset", "=", "TensorDataset", "(", "torch", ".", "tensor", "(", "data", ")", ".", "float", "(", ")", ",", "torch", ".", "tensor", "(", "lab", ")", ".", "float", "(", ")", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "8", ",", "shuffle", "=", "True", ")", "\n", "\n", "dataset_dev", "=", "TensorDataset", "(", "torch", ".", "tensor", "(", "data_dev", ")", ".", "float", "(", ")", ",", "torch", ".", "tensor", "(", "lab_dev", ")", ".", "float", "(", ")", ")", "\n", "loader_dev", "=", "DataLoader", "(", "dataset_dev", ",", "batch_size", "=", "8", ",", "shuffle", "=", "True", ")", "\n", "\n", "net", "=", "RectifierNetwork", "(", "len", "(", "data", "[", "0", "]", ")", ",", "args", "[", "'hidden_rect'", "]", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "net", ".", "parameters", "(", ")", ",", "lr", "=", "args", "[", "'lr'", "]", ")", "\n", "loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/\"", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/ngram_\"", "+", "str", "(", "args", "[", "'ngram'", "]", ")", "+", "\"/\"", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/ngram_\"", "+", "str", "(", "args", "[", "'ngram'", "]", ")", "+", "\"/\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/ngram_\"", "+", "str", "(", "args", "[", "'ngram'", "]", ")", "+", "\"/ratio_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\"/\"", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/ngram_\"", "+", "str", "(", "args", "[", "'ngram'", "]", ")", "+", "\"/ratio_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\"/\"", ")", "\n", "\n", "", "save_folder", "=", "save_dir", "+", "\"choice_\"", "+", "str", "(", "args", "[", "'choice'", "]", ")", "+", "\"/ngram_\"", "+", "str", "(", "args", "[", "'ngram'", "]", ")", "+", "\"/ratio_\"", "+", "str", "(", "args", "[", "'ratio'", "]", ")", "+", "\"/\"", "\n", "\n", "prev_best_dev", "=", "0.0", "\n", "for", "ep", "in", "range", "(", "1000", ")", ":", "\n", "# Training Loop", "\n", "\t\t", "train_loss", "=", "0.0", "\n", "for", "index", ",", "(", "inp", ",", "gold", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "\t\t\t", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "net", "(", "inp", ")", "\n", "out_loss", "=", "loss", "(", "output", ",", "gold", ")", "\n", "train_loss", "+=", "out_loss", ".", "item", "(", ")", "\n", "out_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "train_acc", "=", "predict", "(", "net", ",", "loader", ")", "\n", "dev_acc", "=", "predict", "(", "net", ",", "loader_dev", ")", "\n", "\n", "# Models with better dev accuracy are saved\t", "\n", "if", "dev_acc", ">", "prev_best_dev", ":", "\n", "\t\t\t", "prev_best_dev", "=", "dev_acc", "\n", "if", "args", "[", "'save_enable'", "]", ":", "\n", "\t\t\t\t", "torch", ".", "save", "(", "{", "'epoch'", ":", "ep", "+", "1", ",", "\n", "'model_state_dict'", ":", "net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'loss'", ":", "train_loss", "/", "len", "(", "data", ")", ",", "\n", "'dev_accuracy'", ":", "dev_acc", ",", "\n", "'train_accuracy'", ":", "train_acc", "\n", "}", ",", "save_folder", "+", "str", "(", "ep", "+", "1", ")", "+", "\"_\"", "+", "str", "(", "dev_acc", ")", ")", "\n", "\n", "res", "=", "{", "'dev_acc'", ":", "dev_acc", ",", "'train_acc'", ":", "train_acc", "}", "\n", "\n", "with", "open", "(", "save_folder", "+", "str", "(", "ep", "+", "1", ")", "+", "\"_\"", "+", "str", "(", "dev_acc", ")", "+", "\".json\"", ",", "'w'", ")", "as", "fp", ":", "\n", "\t\t\t\t\t", "json", ".", "dump", "(", "res", ",", "fp", ")", "\n", "\n", "\n", "", "", "", "print", "(", "\"Epoch : {}\"", ".", "format", "(", "ep", "+", "1", ")", ")", "\n", "print", "(", "\"Training loss: {:.4f}\"", ".", "format", "(", "train_loss", "/", "len", "(", "data", ")", ")", ")", "\n", "print", "(", "\"Training Accuracy: {:.4f} \"", ".", "format", "(", "train_acc", ")", ")", "\n", "print", "(", "\"Development Accuracy: {:.4f} \\n\"", ".", "format", "(", "dev_acc", ")", ")", "\n", "\n", "if", "train_acc", "==", "1.0", ":", "\n", "\t\t\t", "print", "(", "\"Train Accuracy reached 1. Ending early!!\"", ")", "\n", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.argmax": [[4, 8], ["torch.max", "torch.max", "idx.item"], "function", ["None"], ["def", "argmax", "(", "vec", ")", ":", "\n", "# return the argmax as a python int", "\n", "    ", "_", ",", "idx", "=", "torch", ".", "max", "(", "vec", ",", "1", ")", "\n", "return", "idx", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_sequence": [[10, 13], ["torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "prepare_sequence", "(", "seq", ",", "to_ix", ")", ":", "\n", "    ", "idxs", "=", "[", "to_ix", "[", "w", "]", "for", "w", "in", "seq", "]", "\n", "return", "torch", ".", "tensor", "(", "idxs", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.log_sum_exp": [[16, 21], ["max_score.view().expand", "torch.log", "torch.log", "max_score.view", "vec.size", "torch.sum", "torch.sum", "utils.argmax", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.argmax"], ["", "def", "log_sum_exp", "(", "vec", ")", ":", "\n", "    ", "max_score", "=", "vec", "[", "0", ",", "argmax", "(", "vec", ")", "]", "\n", "max_score_broadcast", "=", "max_score", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "1", ",", "vec", ".", "size", "(", ")", "[", "1", "]", ")", "\n", "return", "max_score", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "vec", "-", "max_score_broadcast", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_word2idx": [[22, 29], ["len"], "function", ["None"], ["", "def", "prepare_word2idx", "(", "training_data", ")", ":", "\n", "\t", "word_to_ix", "=", "{", "}", "\n", "for", "sentence", ",", "tags", "in", "training_data", ":", "\n", "\t\t", "for", "word", "in", "sentence", ":", "\n", "\t\t\t", "if", "word", "not", "in", "word_to_ix", ":", "\n", "\t\t\t\t", "word_to_ix", "[", "word", "]", "=", "len", "(", "word_to_ix", ")", "\n", "", "", "", "return", "word_to_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.prepare_tag2idx": [[30, 37], ["len"], "function", ["None"], ["", "def", "prepare_tag2idx", "(", "training_data", ")", ":", "\n", "\t", "tag_to_ix", "=", "{", "}", "\n", "for", "sentence", ",", "tags", "in", "training_data", ":", "\n", "\t\t", "for", "tag", "in", "tags", ":", "\n", "\t\t\t", "if", "tag", "not", "in", "tag_to_ix", ":", "\n", "\t\t\t\t", "tag_to_ix", "[", "tag", "]", "=", "len", "(", "tag_to_ix", ")", "\n", "", "", "", "return", "tag_to_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.utahnlp_learning-constraints.scripts.utils.calc_correct": [[39, 50], ["range", "len"], "function", ["None"], ["", "def", "calc_correct", "(", "pred", ",", "tag", ")", ":", "\n", "\t", "predictions", "=", "pred", "[", "1", "]", "\n", "\n", "c", "=", "0", "\n", "t", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "tag", ")", ")", ":", "\n", "\t\t", "if", "tag", "[", "i", "]", "==", "predictions", "[", "i", "]", ":", "\n", "\t\t\t", "c", "+=", "1", "\n", "", "t", "+=", "1", "\n", "\n", "", "return", "c", ",", "t", "", "", ""]]}