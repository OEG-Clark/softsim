{"home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.ft_init_l2.accuracy": [[32, 46], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.prepare_imbalanced_list_files.from_list_to_dict": [[21, 38], ["line.strip().split.strip().split", "images_dict.keys", "int", "str", "images_dict.keys", "images_dict[].append", "random.shuffle", "line.strip().split.strip", "str", "str", "str", "str"], "function", ["None"], ["", "def", "from_list_to_dict", "(", "images_list", ",", "shuffle", "=", "False", ")", ":", "\n", "\n", "    ", "images_dict", "=", "{", "}", "\n", "for", "line", "in", "images_list", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", ")", "\n", "image_path", ",", "class_number", "=", "line", "[", "0", "]", ",", "int", "(", "line", "[", "1", "]", ")", "\n", "\n", "if", "str", "(", "class_number", ")", "not", "in", "images_dict", ".", "keys", "(", ")", ":", "\n", "            ", "images_dict", "[", "str", "(", "class_number", ")", "]", "=", "[", "image_path", "+", "' '", "+", "str", "(", "class_number", ")", "]", "\n", "", "else", ":", "\n", "            ", "images_dict", "[", "str", "(", "class_number", ")", "]", ".", "append", "(", "image_path", "+", "' '", "+", "str", "(", "class_number", ")", ")", "\n", "\n", "", "", "if", "shuffle", ":", "\n", "        ", "for", "key", "in", "images_dict", ".", "keys", "(", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "images_dict", "[", "key", "]", ")", "\n", "\n", "", "", "return", "images_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.features_extraction_ft.get_dataset_mean_std": [[14, 28], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "float", "re.findall", "re.findall"], "function", ["None"], ["def", "get_dataset_mean_std", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "dataset_std", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "1", "]", ")", "]", "\n", "return", "dataset_mean", ",", "dataset_std", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.th_calibration": [[42, 48], ["range", "range"], "function", ["None"], ["", "def", "th_calibration", "(", "scores", ",", "N", ",", "n", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "scores", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "n", "[", "j", "]", ">", "0", ":", "\n", "                ", "scores", "[", "i", "]", "[", "j", "]", "*=", "N", "/", "n", "[", "j", "]", "\n", "", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.get_dataset_N_n": [[50, 62], ["range", "sum", "n.keys", "len", "len"], "function", ["None"], ["", "def", "get_dataset_N_n", "(", "dsets", ",", "model_num_classes", ")", ":", "\n", "    ", "n", "=", "{", "}", "\n", "for", "class_name", "in", "range", "(", "model_num_classes", ")", ":", "\n", "        ", "for", "dset", "in", "dsets", ":", "\n", "            ", "if", "class_name", "in", "dset", ".", "targets", ":", "\n", "                ", "n", "[", "class_name", "]", "=", "len", "(", "[", "x", "for", "x", "in", "dset", ".", "targets", "if", "x", "==", "class_name", "]", ")", "\n", "\n", "", "", "if", "class_name", "not", "in", "n", ".", "keys", "(", ")", ":", "# undetected classes", "\n", "            ", "n", "[", "class_name", "]", "=", "0", "\n", "\n", "", "", "N", "=", "sum", "(", "[", "len", "(", "dset", ")", "for", "dset", "in", "dsets", "]", ")", "\n", "return", "N", ",", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.active_learning": [[64, 225], ["os.path.join", "os.path.join", "torch.Sequential", "features_extractor.cuda.eval", "features_extractor.cuda.cuda", "model.cuda.eval", "model.cuda.cuda", "print", "print", "print", "MyImageFolder.ImagesListFolder", "len", "int", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "numpy.array", "enumerate", "os.path.join", "print", "data_utils.min_max", "numpy.arange", "print", "print", "print", "print", "classical_AFs.oracle_annotation", "list", "print", "zip", "print", "open.close", "zip", "torchvision.Compose", "inputs.cuda.cuda", "features_extractor.cuda.", "model.cuda.", "torch.softmax", "numpy.array", "features_extractor.data.cpu().numpy", "np_features.reshape.reshape", "th_calibration.data.cpu().numpy", "open", "cPickle.dump", "data_utils.create_dist_matrix", "classical_AFs.oracle_annotation.run", "set", "new_data_list.append", "open", "open", "open.write", "open.close", "oracle_annotated_paths.append", "str", "str", "torch.autograd.Variable", "torch.autograd.Variable", "main.th_calibration", "numpy.append", "numpy.vstack", "numpy.vstack", "str", "str", "str", "poor", "str", "open", "open", "open.write", "list", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.ToTensor", "range", "features_extractor.data.cpu", "th_calibration.data.cpu", "len", "bcore", "print", "sys.exit", "sorted", "str", "numpy.vstack", "model.cuda.children", "len", "str", "str", "str", "list"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.data_utils.min_max", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.data_utils.create_dist_matrix", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.th_calibration"], ["", "def", "active_learning", "(", "rerun", ",", "sess", ",", "batch_size", ",", "batch_number", ",", "model", ",", "N", ",", "n", ",", "B", ",", "next_new_data_file_path", ",", "\n", "sess_new_data_paths", ",", "run_data_output_dir", ",", "undetected_classes", ")", ":", "\n", "    ", "\"\"\"Annotate a new batch of images\n       Return the oracle (class oracle_annotation)\"\"\"", "\n", "\n", "new_data_file_fpath", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "str", "(", "batch_number", ")", "+", "'_new'", ")", "\n", "new_data_feat_file_fpath", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "str", "(", "batch_number", ")", "+", "'_feat_new'", ")", "\n", "\n", "features_extractor", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "features_extractor", ".", "eval", "(", ")", "\n", "features_extractor", "=", "features_extractor", ".", "cuda", "(", "gpu", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "model", "=", "model", ".", "cuda", "(", "gpu", ")", "\n", "print", "(", "'\\n\\n********* PREPARING NEW DATA FOR THIS BATCH ********* '", ")", "\n", "print", "(", "'------> Features extraction of new data S{}* using model M{}'", ".", "format", "(", "batch_number", ",", "batch_number", "-", "1", ")", ")", "\n", "print", "(", "'data partially loaded from : '", "+", "next_new_data_file_path", ")", "\n", "\n", "dataset", "=", "ImagesListFolder", "(", "\n", "sess_new_data_paths", ",", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", ")", "\n", "\n", "new_data_size", "=", "len", "(", "dataset", ")", "\n", "budget", "=", "int", "(", "(", "new_data_size", "*", "B", ")", "/", "100", ")", "\n", "dataset_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "full_features", "=", "None", "\n", "full_paths", "=", "None", "\n", "full_scores", "=", "None", "\n", "full_classes", "=", "np", ".", "array", "(", "[", "dataset", ".", "samples", "[", "i", "]", "[", "1", "]", "for", "i", "in", "range", "(", "len", "(", "dataset", ".", "samples", ")", ")", "]", ")", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "dataset_loader", ")", ":", "\n", "        ", "(", "inputs", ",", "labels", ")", ",", "paths", "=", "data", "\n", "inputs", "=", "inputs", ".", "cuda", "(", "gpu", ")", "\n", "features", "=", "features_extractor", "(", "Variable", "(", "inputs", ")", ")", "\n", "scores", "=", "model", "(", "Variable", "(", "inputs", ")", ")", "\n", "# scores[:, undetected_classes] = -np.Inf", "\n", "scores", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "1", ")", "\n", "\n", "if", "apply_th_train", "or", "apply_th_val_al", ":", "\n", "            ", "scores", "=", "th_calibration", "(", "scores", ",", "N", ",", "n", ")", "\n", "\n", "", "np_paths", "=", "np", ".", "array", "(", "paths", ")", "\n", "np_features", "=", "features", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np_features", "=", "np_features", ".", "reshape", "(", "np_features", ".", "shape", "[", "0", "]", ",", "np_features", ".", "shape", "[", "1", "]", ")", "\n", "np_scores", "=", "scores", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "            ", "full_paths", "=", "np_paths", "\n", "full_features", "=", "np_features", "\n", "full_scores", "=", "np_scores", "\n", "", "else", ":", "\n", "            ", "full_paths", "=", "np", ".", "append", "(", "full_paths", ",", "np_paths", ")", "\n", "full_features", "=", "np", ".", "vstack", "(", "(", "full_features", ",", "np_features", ")", ")", "\n", "full_scores", "=", "np", ".", "vstack", "(", "(", "full_scores", ",", "np_scores", ")", ")", "\n", "\n", "", "", "probas_path", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "str", "(", "batch_number", ")", "+", "'_proba.pkl'", ")", "\n", "with", "open", "(", "probas_path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "cPickle", ".", "dump", "(", "full_scores", ",", "f", ")", "\n", "\n", "", "print", "(", "\"\"", ")", "\n", "\n", "# Features normalization", "\n", "full_features", "=", "min_max", "(", "full_features", ")", "\n", "\n", "dist_matrix", "=", "None", "\n", "if", "(", "'kcenters'", "in", "classical_AF", "and", "sess", "==", "0", ")", "or", "'kcenters'", "in", "balancing_AF", ":", "dist_matrix", "=", "create_dist_matrix", "(", "full_features", ")", "\n", "\n", "# Available indexes for oracle", "\n", "# todo: modify entropy code to allow working on avail indexes", "\n", "avail_indexes", "=", "np", ".", "arange", "(", "full_features", ".", "shape", "[", "0", "]", ")", "\n", "\n", "print", "(", "'------> Manual annotation'", ")", "\n", "print", "(", "'images number -> '", "+", "str", "(", "len", "(", "full_paths", ")", ")", ")", "\n", "print", "(", "'budget of oracle -> '", "+", "str", "(", "budget", ")", ")", "\n", "print", "(", "''", ")", "\n", "\n", "oracle", "=", "oracle_annotation", "(", "budget", ",", "full_features", ",", "full_paths", ",", "dist_matrix", ",", "avail_indexes", ",", "full_classes", ",", "probas_path", ")", "\n", "\n", "if", "sess", "==", "0", ":", "\n", "# Annotation of budget by oracle + Balancing", "\n", "        ", "oracle", ".", "run", "(", "classical_AF", ")", "\n", "\n", "# Data annotated manually by the oracle", "\n", "# annotated_img_idx = oracle.annotated_img_idx", "\n", "annotated_classes", "=", "oracle", ".", "annotated_classes", "\n", "annotated_paths", "=", "oracle", ".", "annotated_paths", "\n", "annotated_features", "=", "oracle", ".", "annotated_features", "\n", "\n", "", "else", ":", "\n", "\n", "        ", "if", "balancing_AF", "==", "'poor'", ":", "\n", "            ", "annotated_classes", ",", "annotated_paths", ",", "annotated_features", "=", "poor", "(", "\n", "full_features", ",", "full_classes", ",", "\n", "full_paths", ",", "budget", ",", "\n", "new_data_file_fpath", ",", "\n", "new_data_feat_file_fpath", ")", "\n", "\n", "\n", "", "elif", "balancing_AF", "==", "'bcore'", ":", "\n", "            ", "annotated_classes", ",", "annotated_paths", ",", "annotated_features", "=", "bcore", "(", "dist_matrix", ",", "full_features", ",", "full_classes", ",", "\n", "full_paths", ",", "budget", ",", "\n", "new_data_file_fpath", ",", "\n", "new_data_feat_file_fpath", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "'invalid balancing type'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "", "classes", "=", "list", "(", "set", "(", "annotated_classes", ")", ")", "\n", "print", "(", "'Classes detected by the oracle = '", "+", "str", "(", "sorted", "(", "classes", ")", ")", ")", "\n", "\n", "###################", "\n", "\n", "# list of new data after oracle : to be saved in a file", "\n", "new_data_list", "=", "[", "]", "\n", "for", "(", "path", ",", "class_", ")", "in", "zip", "(", "annotated_paths", ",", "annotated_classes", ")", ":", "\n", "        ", "new_data_list", ".", "append", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", ")", "\n", "\n", "\n", "# Writing new data lists file:", "\n", "", "print", "(", "'New data S{}+ saved in {} '", ".", "format", "(", "batch_number", ",", "new_data_file_fpath", ")", ")", "\n", "if", "sess", "==", "0", ":", "\n", "        ", "new_data_file", "=", "open", "(", "new_data_file_fpath", ",", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "new_data_file", "=", "open", "(", "new_data_file_fpath", ",", "'a'", ")", "\n", "\n", "\n", "", "for", "line", "in", "new_data_list", ":", "\n", "        ", "new_data_file", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "new_data_file", ".", "close", "(", ")", "\n", "\n", "############################### SAVING  annotated features", "\n", "if", "balancing_AF", "==", "'poor'", ":", "\n", "        ", "new_data_features", "=", "None", "\n", "for", "feat", "in", "annotated_features", ":", "\n", "            ", "if", "new_data_features", "is", "None", ":", "\n", "                ", "new_data_features", "=", "feat", "\n", "", "else", ":", "\n", "                ", "new_data_features", "=", "np", ".", "vstack", "(", "(", "new_data_features", ",", "feat", ")", ")", "\n", "\n", "", "", "if", "sess", "==", "0", ":", "\n", "            ", "new_data_feat_file", "=", "open", "(", "new_data_feat_file_fpath", ",", "'w'", ")", "\n", "", "else", ":", "\n", "            ", "new_data_feat_file", "=", "open", "(", "new_data_feat_file_fpath", ",", "'a'", ")", "\n", "\n", "", "for", "feat", "in", "new_data_features", ":", "\n", "            ", "new_data_feat_file", ".", "write", "(", "str", "(", "' '", ".", "join", "(", "[", "str", "(", "e", ")", "for", "e", "in", "list", "(", "feat", ")", "]", ")", ")", "+", "'\\n'", ")", "\n", "", "new_data_feat_file", ".", "close", "(", ")", "\n", "##########################################", "\n", "\n", "", "oracle_annotated_paths", "=", "[", "]", "\n", "for", "(", "path", ",", "class_", ")", "in", "zip", "(", "annotated_paths", ",", "annotated_classes", ")", ":", "\n", "        ", "oracle_annotated_paths", ".", "append", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", "+", "'\\n'", ")", "\n", "\n", "", "return", "oracle_annotated_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.main": [[376, 499], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "range", "print", "print", "print", "int", "print", "print", "print", "range", "range", "int", "range", "range", "range", "print", "print", "resnet.resnet_main", "print", "resnet.resnet_main", "math.ceil", "int", "resnet_features_.append", "numpy.asarray", "numpy.mean", "range", "numpy.ceil", "int", "len", "math.ceil", "numpy.where", "numpy.asarray", "numpy.zeros", "selected_feat.append", "selected.append", "x_train_protoset[].append", "y_train_protoset[].append", "math.ceil", "len", "len", "len", "len", "len", "len", "len", "str", "min", "min", "numpy.linalg.norm", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_main", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_main"], ["new_val_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", ")", "\n", "\n", "val_datasets", "=", "torch", ".", "utils", ".", "data", ".", "dataset", ".", "ConcatDataset", "(", "(", "\n", "old_val_dataset", ",", "new_val_dataset", "\n", ")", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "val_datasets", ",", "batch_size", "=", "val_batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "old_classes_number", "=", "len", "(", "old_train_dataset", ".", "classes", ")", "\n", "\n", "# Loading the model", "\n", "if", "b", "==", "2", ":", "\n", "                            ", "model_load_path", "=", "first_model_load_path", "\n", "", "else", ":", "\n", "                            ", "model_load_path", "=", "os", ".", "path", ".", "join", "(", "run_models_save_dir", ",", "algo_name", "+", "'_b'", "+", "str", "(", "b", "-", "1", ")", "+", "'.pt'", ")", "\n", "\n", "", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "base", "+", "P", "*", "(", "b", "-", "2", ")", ")", "\n", "\n", "print", "(", "'\\nLoading saved model from '", "+", "model_load_path", ")", "\n", "state", "=", "torch", ".", "load", "(", "model_load_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "state", "[", "'state_dict'", "]", ")", "\n", "\n", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "base", "+", "P", "*", "(", "b", "-", "1", ")", ")", "\n", "model", "=", "model", ".", "cuda", "(", "gpu", ")", "\n", "\n", "# Define Loss and Optimizer", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "momentum", ",", "weight_decay", "=", "weight_decay", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "patience", "=", "patience", ",", "factor", "=", "lr_decay", ")", "\n", "\n", "print", "(", "\"\\nlr = {:.4f}\"", ".", "format", "(", "lr", ")", ")", "\n", "print", "(", "\"Old classes number = \"", "+", "str", "(", "old_classes_number", ")", ")", "\n", "print", "(", "\"Old Training-set size = \"", "+", "str", "(", "len", "(", "old_train_dataset", ")", ")", ")", "\n", "print", "(", "\"Validation-set size = \"", "+", "str", "(", "len", "(", "val_datasets", ")", ")", "+", "'\\n'", ")", "\n", "##############################", "\n", "# Active learning : update batch_oracle_annotated_paths / Semi-supervised labelisation step", "\n", "batch_oracle_annotated_paths", "[", "b", "]", "=", "[", "]", "\n", "next_new_train_file_path", "=", "os", ".", "path", ".", "join", "(", "train_files_dir", ",", "'batch'", "+", "str", "(", "b", ")", ")", "\n", "\n", "for", "sess", "in", "range", "(", "I", ")", ":", "\n", "\n", "                            ", "if", "sess", "==", "0", ":", "\n", "                                ", "al_model", "=", "previous_model", "\n", "", "else", ":", "\n", "                                ", "al_model", "=", "model", "\n", "\n", "", "sess_epochs", "=", "int", "(", "num_epochs", "/", "I", ")", "#todo modify", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "if", "mode", "==", "\"il\"", "or", "I", "==", "1", ":", "\n", "                                ", "sess_budget", "=", "B", "\n", "", "else", ":", "\n", "                                ", "if", "sess", "==", "0", ":", "# take 40% of budget", "\n", "                                    ", "sess_budget", "=", "math", ".", "ceil", "(", "int", "(", "B", "*", "40", "/", "100", ")", ")", "\n", "", "else", ":", "\n", "                                    ", "sess_budget", "=", "math", ".", "ceil", "(", "int", "(", "B", "*", "20", "/", "100", ")", ")", "\n", "\n", "", "", "next_new_train_paths_list", "=", "open", "(", "next_new_train_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "assert", "(", "sorted", "(", "list", "(", "set", "(", "next_new_train_paths_list", ")", ")", ")", "==", "sorted", "(", "next_new_train_paths_list", ")", ")", "\n", "assert", "(", "sorted", "(", "list", "(", "set", "(", "batch_oracle_annotated_paths", "[", "b", "]", ")", ")", ")", "==", "sorted", "(", "\n", "batch_oracle_annotated_paths", "[", "b", "]", ")", ")", "\n", "\n", "sess_new_train_paths", "=", "list", "(", "\n", "set", "(", "next_new_train_paths_list", ")", "-", "set", "(", "batch_oracle_annotated_paths", "[", "b", "]", ")", ")", "\n", "oracle_annotated_paths", "=", "active_learning", "(", "rerun", ",", "sess", ",", "new_batch_size", ",", "b", ",", "al_model", ",", "N", ",", "n", ",", "\n", "sess_budget", ",", "\n", "next_new_train_file_path", ",", "sess_new_train_paths", ",", "\n", "run_data_output_dir", ",", "\n", "undetected_classes", ")", "\n", "\n", "batch_oracle_annotated_paths", "[", "b", "]", ".", "extend", "(", "oracle_annotated_paths", ")", "\n", "\n", "new_train_file_path", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "str", "(", "b", ")", "+", "'_new'", ")", "\n", "\n", "print", "(", "'New train data loaded from '", "+", "new_train_file_path", ")", "\n", "\n", "new_train_dataset", "=", "ImagesListFileFolder", "(", "\n", "new_train_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", "\n", ")", "\n", "\n", "model_dsets", "=", "[", "old_train_dataset", ",", "new_train_dataset", "]", "\n", "\n", "new_and_old_train_datasets", "=", "torch", ".", "utils", ".", "data", ".", "dataset", ".", "ConcatDataset", "(", "\n", "(", "old_train_dataset", ",", "new_train_dataset", ")", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "new_and_old_train_datasets", ",", "shuffle", "=", "True", ",", "batch_size", "=", "new_batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "new_classes_number", "=", "len", "(", "new_train_dataset", ".", "classes", ")", "\n", "undetected_classes", ".", "extend", "(", "\n", "list", "(", "set", "(", "range", "(", "base", "+", "P", "*", "(", "b", "-", "2", ")", ",", "base", "+", "P", "*", "(", "b", "-", "1", ")", ")", ")", "-", "set", "(", "new_train_dataset", ".", "classes", ")", ")", ")", "\n", "undetected_classes", "=", "sorted", "(", "list", "(", "set", "(", "undetected_classes", ")", ")", ")", "\n", "print", "(", "'undetected_classes = '", "+", "str", "(", "undetected_classes", ")", ")", "\n", "\n", "print", "(", "\"New classes number = \"", "+", "str", "(", "new_classes_number", ")", ")", "\n", "print", "(", "\"New Training-set size = \"", "+", "str", "(", "len", "(", "new_train_dataset", ")", ")", ")", "\n", "print", "(", "\"Training-set size = \"", "+", "str", "(", "len", "(", "new_and_old_train_datasets", ")", ")", ")", "\n", "\n", "N", ",", "n", "=", "get_dataset_N_n", "(", "model_dsets", ",", "model", ".", "fc", ".", "out_features", ")", "\n", "\n", "# Training", "\n", "print", "(", "\"-\"", "*", "20", ")", "\n", "print", "(", "'\\n\\n********* TRAINING ********* '", ")", "\n", "starting_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "sess_epochs", ")", ":", "\n", "                                ", "top1", "=", "AverageMeter", "(", ")", "\n", "topx", "=", "AverageMeter", "(", ")", "\n", "model", ".", "train", "(", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.data_utils.min_max": [[9, 24], ["numpy.zeros", "range", "min_features.append", "max_features.append", "max", "min"], "function", ["None"], ["def", "min_max", "(", "features", ")", ":", "#! OK", "\n", "    ", "\"\"\"Return features (numpy array) after min-max normalization\"\"\"", "\n", "min_features", ",", "max_features", "=", "[", "]", ",", "[", "]", "\n", "new_features", "=", "np", ".", "zeros", "(", "features", ".", "shape", ")", "\n", "i", "=", "0", "\n", "for", "dim", "in", "range", "(", "features", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "max_ft", ",", "min_ft", "=", "max", "(", "features", "[", ":", ",", "dim", "]", ")", ",", "min", "(", "features", "[", ":", ",", "dim", "]", ")", "\n", "min_features", ".", "append", "(", "min_ft", ")", "\n", "max_features", ".", "append", "(", "max_ft", ")", "\n", "\n", "if", "max_ft", "!=", "0", ":", "\n", "            ", "new_features", "[", ":", ",", "i", "]", "=", "(", "features", "[", ":", ",", "dim", "]", "-", "min_ft", ")", "/", "(", "max_ft", "-", "min_ft", ")", "\n", "\n", "", "i", "+=", "1", "\n", "", "return", "new_features", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.data_utils.create_dist_matrix": [[25, 37], ["print", "print", "numpy.zeros", "range", "range", "numpy.linalg.norm"], "function", ["None"], ["", "def", "create_dist_matrix", "(", "features", ")", ":", "#! OK", "\n", "    ", "\"\"\"Compute and return the L2 distance matrix of features array\"\"\"", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"Computing the distances between the pairwise of images in features space\"", ")", "\n", "n", "=", "features", ".", "shape", "[", "0", "]", "\n", "dist_matrix", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ")", "\n", "for", "i", "in", "range", "(", "n", "-", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "n", ")", ":", "\n", "            ", "dist_ij", "=", "np", ".", "linalg", ".", "norm", "(", "features", "[", "i", "]", "-", "features", "[", "j", "]", ")", "\n", "dist_matrix", "[", "i", ",", "j", "]", "=", "dist_ij", "\n", "dist_matrix", "[", "j", ",", "i", "]", "=", "dist_ij", "\n", "", "", "return", "dist_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.features_extraction.get_dataset_mean": [[22, 35], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "re.findall"], "function", ["None"], ["", "if", "not", "os", ".", "path", ".", "exists", "(", "sys", ".", "argv", "[", "1", "]", ")", ":", "\n", "    ", "print", "(", "'No configuration file found in the specified path'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "\n", "# loading configuration file", "\n", "", "cp", "=", "ConfigParser", "(", ")", "\n", "cp", ".", "read", "(", "sys", ".", "argv", "[", "1", "]", ")", "\n", "cp", "=", "cp", "[", "os", ".", "path", ".", "basename", "(", "__file__", ")", "]", "\n", "\n", "# reading parameters", "\n", "num_workers", "=", "int", "(", "cp", "[", "'num_workers'", "]", ")", "\n", "batch_size", "=", "int", "(", "cp", "[", "'batch_size'", "]", ")", "\n", "models_load_path_prefix", "=", "cp", "[", "'models_load_path_prefix'", "]", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.features_extraction.get_exemplars": [[36, 42], ["range", "exemplars.extend"], "function", ["None"], ["gpu", "=", "int", "(", "cp", "[", "'gpu'", "]", ")", "\n", "val_images_list_dir", "=", "cp", "[", "'val_images_list_dir'", "]", "\n", "destination_dir", "=", "cp", "[", "'destination_dir'", "]", "\n", "normalization_dataset_name", "=", "cp", "[", "'normalization_dataset_name'", "]", "\n", "first_batch_number", "=", "int", "(", "cp", "[", "'first_batch_number'", "]", ")", "\n", "last_batch_number", "=", "int", "(", "cp", "[", "'last_batch_number'", "]", ")", "\n", "datasets_mean_std_file_path", "=", "cp", "[", "'datasets_mean_std_file_path'", "]", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu": [[9, 14], ["tensorflow.maximum", "tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["\n", "", "def", "relu", "(", "x", ",", "name", ",", "alpha", ")", ":", "\n", "    ", "if", "alpha", ">", "0", ":", "\n", "        ", "return", "tf", ".", "maximum", "(", "alpha", "*", "x", ",", "x", ",", "name", "=", "name", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "relu", "(", "x", ",", "name", "=", "name", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable": [[16, 22], ["tensorflow.device", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable"], ["\n", "", "", "def", "get_variable", "(", "name", ",", "shape", ",", "dtype", ",", "initializer", ",", "trainable", "=", "True", ",", "regularizer", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "        ", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "regularizer", ",", "trainable", "=", "trainable", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", "]", ")", "\n", "", "return", "var", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.conv": [[24, 50], ["tensorflow.contrib.layers.xavier_initializer_conv2d", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "inp.get_shape().as_list", "tensorflow.variable_scope", "utils_resnet.get_variable", "utils_resnet.get_variable", "tensorflow.add", "relu.set_shape", "tensorflow.add", "utils_resnet.relu", "inp.get_shape", "inp.get_shape", "inp.get_shape", "inp.get_shape", "tensorflow.zeros_initializer", "tensorflow.nn.atrous_conv2d", "tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["\n", "", "def", "conv", "(", "inp", ",", "name", ",", "size", ",", "out_channels", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "dilation", "=", "None", ",", "padding", "=", "'SAME'", ",", "apply_relu", "=", "True", ",", "alpha", "=", "0.0", ",", "bias", "=", "True", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", ")", ")", ":", "\n", "\n", "    ", "batch_size", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "\n", "res1", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "res2", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "in_channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "W", "=", "get_variable", "(", "\"W\"", ",", "shape", "=", "[", "size", ",", "size", ",", "in_channels", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "initializer", ",", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "b", "=", "get_variable", "(", "\"b\"", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "out_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "bias", ")", "\n", "\n", "if", "dilation", ":", "\n", "            ", "assert", "(", "strides", "==", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "atrous_conv2d", "(", "inp", ",", "W", ",", "rate", "=", "dilation", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "out", ".", "set_shape", "(", "[", "batch_size", ",", "res1", ",", "res2", ",", "out_channels", "]", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "add", "(", "tf", ".", "nn", ".", "conv2d", "(", "inp", ",", "W", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ")", ",", "b", ",", "name", "=", "'convolution'", ")", "\n", "\n", "", "if", "apply_relu", ":", "\n", "            ", "out", "=", "relu", "(", "out", ",", "alpha", "=", "alpha", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "out", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.softmax": [[52, 58], ["tensorflow.reduce_max", "tensorflow.exp", "tensorflow.reduce_sum"], "function", ["None"], ["\n", "", "def", "softmax", "(", "target", ",", "axis", ",", "name", "=", "None", ")", ":", "\n", "    ", "max_axis", "=", "tf", ".", "reduce_max", "(", "target", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "target_exp", "=", "tf", ".", "exp", "(", "target", "-", "max_axis", ")", "\n", "normalize", "=", "tf", ".", "reduce_sum", "(", "target_exp", ",", "axis", ",", "keep_dims", "=", "True", ")", "\n", "softmax", "=", "target_exp", "/", "normalize", "\n", "return", "softmax", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.batch_norm": [[60, 82], ["inp.get_shape().as_list", "tensorflow.variable_scope", "utils_resnet.get_variable", "utils_resnet.get_variable", "utils_resnet.get_variable", "utils_resnet.get_variable", "tensorflow.nn.moments", "get_variable.assign", "get_variable.assign", "tensorflow.nn.batch_normalization", "inp.get_shape", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable"], ["\n", "", "def", "batch_norm", "(", "inp", ",", "name", ",", "phase", ",", "decay", "=", "0.9", ")", ":", "\n", "\n", "    ", "channels", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "moving_mean", "=", "get_variable", "(", "\"mean\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "trainable", "=", "False", ")", "\n", "moving_variance", "=", "get_variable", "(", "\"var\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "offset", "=", "get_variable", "(", "\"offset\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "scale", "=", "get_variable", "(", "\"scale\"", ",", "shape", "=", "[", "channels", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ",", "regularizer", "=", "tf", ".", "nn", ".", "l2_loss", ")", "\n", "\n", "mean", ",", "variance", "=", "tf", ".", "nn", ".", "moments", "(", "inp", ",", "axes", "=", "[", "0", ",", "1", ",", "2", "]", ",", "shift", "=", "moving_mean", ")", "\n", "\n", "mean_op", "=", "moving_mean", ".", "assign", "(", "decay", "*", "moving_mean", "+", "(", "1", "-", "decay", ")", "*", "mean", ")", "\n", "var_op", "=", "moving_variance", ".", "assign", "(", "decay", "*", "moving_variance", "+", "(", "1", "-", "decay", ")", "*", "variance", ")", "\n", "\n", "assert", "(", "phase", "in", "[", "'train'", ",", "'test'", "]", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "mean_op", ",", "var_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "mean", ",", "variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "inp", ",", "moving_mean", ",", "moving_variance", ",", "offset", ",", "scale", ",", "0.01", ",", "name", "=", "'norm'", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.pool": [[84, 98], ["tensorflow.variable_scope", "tensorflow.nn.max_pool", "tensorflow.nn.avg_pool"], "function", ["None"], ["\n", "", "", "", "def", "pool", "(", "inp", ",", "name", ",", "kind", ",", "size", ",", "stride", ",", "padding", "=", "'SAME'", ")", ":", "\n", "\n", "    ", "assert", "kind", "in", "[", "'max'", ",", "'avg'", "]", "\n", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "sizes", "=", "[", "1", ",", "size", ",", "size", ",", "1", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "if", "kind", "==", "'max'", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "max_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "tf", ".", "nn", ".", "avg_pool", "(", "inp", ",", "sizes", ",", "strides", "=", "strides", ",", "padding", "=", "padding", ",", "name", "=", "kind", ")", "\n", "\n", "", "", "return", "out", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.ResNet18": [[100, 160], ["utils_resnet.conv", "utils_resnet.batch_norm", "utils_resnet.pool", "utils_resnet.ResNet18.residual_block"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.conv", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.batch_norm", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.pool"], ["\n", "", "def", "ResNet18", "(", "inp", ",", "phase", ",", "num_outputs", "=", "1000", ",", "alpha", "=", "0.0", ")", ":", "\n", "    ", "def", "residual_block", "(", "inp", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'a'", ",", "increase_dim", "=", "False", ",", "last", "=", "False", ")", ":", "\n", "        ", "input_num_filters", "=", "inp", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "if", "increase_dim", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "*", "2", "\n", "", "else", ":", "\n", "            ", "first_stride", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "out_num_filters", "=", "input_num_filters", "\n", "\n", "", "layer", "=", "conv", "(", "inp", ",", "'resconv1'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "first_stride", ",", "out_channels", "=", "out_num_filters", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv1'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "'resconv2'", "+", "nom", ",", "size", "=", "3", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "out_channels", "=", "out_num_filters", ",", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_resconv2'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "\n", "if", "increase_dim", ":", "\n", "                ", "projection", "=", "conv", "(", "inp", ",", "'projconv'", "+", "nom", ",", "size", "=", "1", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "out_channels", "=", "out_num_filters", ",", "alpha", "=", "alpha", ",", "apply_relu", "=", "False", ",", "padding", "=", "'SAME'", ",", "bias", "=", "False", ")", "\n", "projection", "=", "batch_norm", "(", "projection", ",", "'batch_norm_projconv'", "+", "nom", ",", "phase", "=", "phase", ")", "\n", "if", "last", ":", "\n", "                    ", "block", "=", "layer", "+", "projection", "\n", "", "else", ":", "\n", "                    ", "block", "=", "layer", "+", "projection", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "last", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "", "else", ":", "\n", "                ", "block", "=", "layer", "+", "inp", "\n", "block", "=", "tf", ".", "nn", ".", "relu", "(", "block", ",", "name", "=", "'relu'", ")", "\n", "\n", "", "", "return", "block", "\n", "\n", "# First conv", "\n", "#layer = batch_norm(inp, 'batch_norm_0', phase=phase)", "\n", "", "layer", "=", "conv", "(", "inp", ",", "\"conv1\"", ",", "size", "=", "7", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "out_channels", "=", "64", ",", "alpha", "=", "alpha", ",", "padding", "=", "'SAME'", ")", "\n", "layer", "=", "batch_norm", "(", "layer", ",", "'batch_norm_1'", ",", "phase", "=", "phase", ")", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool1'", ",", "'max'", ",", "size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "# First stack of residual blocks", "\n", "for", "letter", "in", "'ab'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Second stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'c'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'d'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Third stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'e'", ",", "increase_dim", "=", "True", ")", "\n", "for", "letter", "in", "'f'", ":", "\n", "        ", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "letter", ")", "\n", "\n", "# Fourth stack of residual blocks", "\n", "", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'g'", ",", "increase_dim", "=", "True", ")", "\n", "layer", "=", "residual_block", "(", "layer", ",", "phase", ",", "alpha", "=", "0.0", ",", "nom", "=", "'h'", ",", "increase_dim", "=", "False", ",", "last", "=", "True", ")", "\n", "\n", "layer", "=", "pool", "(", "layer", ",", "'pool_last'", ",", "'avg'", ",", "size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "'VALID'", ")", "\n", "layer", "=", "conv", "(", "layer", ",", "name", "=", "'fc'", ",", "size", "=", "1", ",", "out_channels", "=", "num_outputs", ",", "padding", "=", "'VALID'", ",", "apply_relu", "=", "False", ",", "alpha", "=", "alpha", ")", "[", ":", ",", "0", ",", "0", ",", ":", "]", "\n", "\n", "return", "layer", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_weight_initializer": [[162, 172], ["tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "params.items", "tensorflow.get_variable().assign", "initializer.append", "tensorflow.get_variable"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable"], ["\n", "", "def", "get_weight_initializer", "(", "params", ")", ":", "\n", "\n", "    ", "initializer", "=", "[", "]", "\n", "\n", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "for", "layer", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "        ", "op", "=", "tf", ".", "get_variable", "(", "'%s'", "%", "layer", ")", ".", "assign", "(", "value", ")", "\n", "initializer", ".", "append", "(", "op", ")", "\n", "", "return", "initializer", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.save_model": [[174, 179], ["tensorflow.get_collection", "cPickle.dump", "open", "sess.run", "v.name.split"], "function", ["None"], ["\n", "", "def", "save_model", "(", "name", ",", "scope", ",", "sess", ")", ":", "\n", "    ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "scope", ")", "\n", "d", "=", "[", "(", "v", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", ",", "sess", ".", "run", "(", "v", ")", ")", "for", "v", "in", "variables", "]", "\n", "\n", "cPickle", ".", "dump", "(", "d", ",", "open", "(", "name", ",", "'wb'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.last_layer_params_extraction.get_dataset_mean": [[22, 35], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "re.findall"], "function", ["None"], ["def", "get_dataset_mean", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "return", "dataset_mean", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_icarl.reading_data_and_preparing_network": [[13, 33], ["utils_data.read_data_test", "tensorflow.train.batch", "tensorflow.one_hot", "tensorflow.constant", "tensorflow.reduce_mean", "dict", "utils_resnet.get_weight_initializer", "tensorflow.variable_scope", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "cPickle.load", "tensorflow.device", "utils_resnet.ResNet18", "tensorflow.get_default_graph", "open", "tf.get_default_graph.get_operation_by_name", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_data.read_data_test", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_weight_initializer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.ResNet18"], ["    ", "import", "_pickle", "as", "cPickle", "\n", "\n", "\n", "", "def", "reading_data_and_preparing_network", "(", "images_mean", ",", "files_from_cl", ",", "device", ",", "itera", ",", "batch_size", ",", "nb_groups", ",", "nb_cl", ",", "save_path", ")", ":", "\n", "    ", "image_train", ",", "label_train", ",", "file_string", "=", "utils_data", ".", "read_data_test", "(", "files_from_cl", "=", "files_from_cl", ")", "\n", "image_batch", ",", "label_batch", ",", "file_string_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "image_train", ",", "label_train", ",", "file_string", "]", ",", "batch_size", "=", "batch_size", ",", "num_threads", "=", "8", ")", "\n", "label_batch_one_hot", "=", "tf", ".", "one_hot", "(", "label_batch", ",", "nb_groups", "*", "nb_cl", ")", "\n", "\n", "### Network and loss function  ", "\n", "mean_img", "=", "tf", ".", "constant", "(", "images_mean", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "3", "]", ",", "name", "=", "'img_mean'", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'ResNet18'", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "scores", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'test'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "op_feature_map", "=", "graph", ".", "get_operation_by_name", "(", "'ResNet18/pool_last/avg'", ")", ".", "outputs", "[", "0", "]", "\n", "\n", "", "", "loss_class", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "label_batch_one_hot", ",", "logits", "=", "scores", ")", ")", "\n", "\n", "### Initilization", "\n", "params", "=", "dict", "(", "cPickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "save_path", ",", "'model-iteration'", "+", "str", "(", "nb_cl", ")", "+", "'-%i.pickle'", ")", "%", "itera", ",", "'rb'", ")", ")", ")", "\n", "inits", "=", "utils_resnet", ".", "get_weight_initializer", "(", "params", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_icarl.load_class_in_feature_space": [[34, 50], ["range", "numpy.concatenate", "numpy.array", "numpy.array", "int", "sess.run", "np.array.extend", "np.array.extend", "np.concatenate.append", "numpy.ceil", "numpy.linalg.norm", "len"], "function", ["None"], ["\n", "return", "inits", ",", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "op_feature_map", "\n", "\n", "", "def", "load_class_in_feature_space", "(", "files_from_cl", ",", "batch_size", ",", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "op_feature_map", ",", "sess", ")", ":", "\n", "    ", "processed_files", "=", "[", "]", "\n", "label_dico", "=", "[", "]", "\n", "Dtot", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "len", "(", "files_from_cl", ")", "/", "batch_size", ")", "+", "1", ")", ")", ":", "\n", "        ", "sc", ",", "l", ",", "loss", ",", "files_tmp", ",", "feat_map_tmp", "=", "sess", ".", "run", "(", "[", "scores", ",", "label_batch", ",", "loss_class", ",", "file_string_batch", ",", "op_feature_map", "]", ")", "\n", "processed_files", ".", "extend", "(", "files_tmp", ")", "\n", "label_dico", ".", "extend", "(", "l", ")", "\n", "mapped_prototypes", "=", "feat_map_tmp", "[", ":", ",", "0", ",", "0", ",", ":", "]", "#plater la couche de sortie", "\n", "Dtot", ".", "append", "(", "(", "mapped_prototypes", ".", "T", ")", "/", "np", ".", "linalg", ".", "norm", "(", "mapped_prototypes", ".", "T", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "Dtot", "=", "np", ".", "concatenate", "(", "Dtot", ",", "axis", "=", "1", ")", "\n", "processed_files", "=", "np", ".", "array", "(", "processed_files", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_icarl.prepare_networks": [[51, 76], ["tensorflow.constant", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "tensorflow.variable_scope", "tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "tensorflow.device", "utils_resnet.ResNet18", "scores.append", "tensorflow.device", "utils_resnet.ResNet18", "scores_stored.append"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.ResNet18", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.ResNet18"], ["label_dico", "=", "np", ".", "array", "(", "label_dico", ")", "\n", "return", "Dtot", ",", "processed_files", ",", "label_dico", "\n", "\n", "", "def", "prepare_networks", "(", "images_mean", ",", "device", ",", "image_batch", ",", "nb_cl", ",", "nb_groups", ")", ":", "\n", "  ", "mean_img", "=", "tf", ".", "constant", "(", "images_mean", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "3", "]", ",", "name", "=", "'img_mean'", ")", "\n", "scores", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'ResNet18'", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "        ", "score", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'train'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "scores", ".", "append", "(", "score", ")", "\n", "\n", "", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "# First score and initialization", "\n", "", "variables_graph", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "'ResNet18'", ")", "\n", "scores_stored", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'store_ResNet18'", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "        ", "score", "=", "utils_resnet", ".", "ResNet18", "(", "image_batch", "-", "mean_img", ",", "phase", "=", "'test'", ",", "num_outputs", "=", "nb_cl", "*", "nb_groups", ")", "\n", "scores_stored", ".", "append", "(", "score", ")", "\n", "\n", "", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", "\n", "scope", ".", "reuse_variables", "(", ")", "\n", "\n", "", "variables_graph2", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "WEIGHTS", ",", "scope", "=", "'store_ResNet18'", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_data.read_data": [[12, 27], ["numpy.array", "numpy.array", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.train.slice_input_producer", "tensorflow.read_file", "tensorflow.image.resize_images", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "len", "len", "tensorflow.image.decode_jpeg", "e.split", "e.split"], "function", ["None"], ["\n", "", "def", "read_data", "(", "files_from_cl", ")", ":", "\n", "    ", "image_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "0", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "labels_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "1", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "\n", "assert", "(", "len", "(", "image_list", ")", "==", "len", "(", "labels_list", ")", ")", "\n", "images", "=", "tf", ".", "convert_to_tensor", "(", "image_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "input_queue", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "images", ",", "labels", "]", ",", "shuffle", "=", "True", ",", "capacity", "=", "2000", ")", "\n", "image_file_content", "=", "tf", ".", "read_file", "(", "input_queue", "[", "0", "]", ")", "\n", "label", "=", "input_queue", "[", "1", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "tf", ".", "image", ".", "decode_jpeg", "(", "image_file_content", ",", "channels", "=", "3", ")", ",", "[", "256", ",", "256", "]", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "224", ",", "224", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "\n", "return", "image", ",", "label", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_data.read_data_test": [[28, 44], ["numpy.array", "numpy.array", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.train.slice_input_producer", "tensorflow.read_file", "tensorflow.image.resize_images", "len", "len", "tensorflow.image.decode_jpeg", "e.split", "e.split"], "function", ["None"], ["\n", "", "def", "read_data_test", "(", "files_from_cl", ")", ":", "\n", "    ", "image_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "0", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "labels_list", "=", "np", ".", "array", "(", "[", "e", ".", "split", "(", ")", "[", "1", "]", "for", "e", "in", "files_from_cl", "]", ")", "\n", "files_list", "=", "files_from_cl", "# or put only the base name?", "\n", "\n", "assert", "(", "len", "(", "image_list", ")", "==", "len", "(", "labels_list", ")", ")", "\n", "images", "=", "tf", ".", "convert_to_tensor", "(", "image_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "files", "=", "tf", ".", "convert_to_tensor", "(", "files_list", ",", "dtype", "=", "tf", ".", "string", ")", "\n", "labels", "=", "tf", ".", "convert_to_tensor", "(", "labels_list", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "input_queue", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "images", ",", "labels", ",", "files", "]", ",", "shuffle", "=", "False", ",", "capacity", "=", "2000", ")", "\n", "image_file_content", "=", "tf", ".", "read_file", "(", "input_queue", "[", "0", "]", ")", "\n", "label", "=", "input_queue", "[", "1", "]", "\n", "file_string", "=", "input_queue", "[", "2", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "tf", ".", "image", ".", "decode_jpeg", "(", "image_file_content", ",", "channels", "=", "3", ")", ",", "[", "224", ",", "224", "]", ")", "\n", "\n", "return", "image", ",", "label", ",", "file_string", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_data.prepare_files": [[45, 105], ["open().readlines", "open().readlines", "len", "len", "range", "range", "line.strip.strip", "line.strip.split", "train_dict.keys", "files_train.append", "len", "len", "line.strip.strip", "line.strip.split", "val_dict.keys", "files_valid.append", "len", "len", "open", "open", "int", "train_dict.keys", "train_dict[].append", "int", "val_dict.keys", "val_dict[].append", "group_images.extend", "group_images.extend", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["\n", "", "def", "prepare_files", "(", "train_images_path", ",", "val_images_path", ",", "nb_groups", ",", "nb_cl", ")", ":", "\n", "    ", "files_train", "=", "[", "]", "\n", "files_valid", "=", "[", "]", "\n", "\n", "train_list", "=", "open", "(", "train_images_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "val_list", "=", "open", "(", "val_images_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "total_train_images_number", "=", "len", "(", "train_list", ")", "\n", "total_val_images_number", "=", "len", "(", "val_list", ")", "\n", "\n", "train_dict", "=", "{", "}", "\n", "for", "line", "in", "train_list", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "img_path_class", "=", "line", ".", "split", "(", ")", "\n", "image_path", ",", "image_class", "=", "img_path_class", "[", "0", "]", ",", "int", "(", "img_path_class", "[", "1", "]", ")", "\n", "if", "image_class", "not", "in", "train_dict", ".", "keys", "(", ")", ":", "\n", "            ", "train_dict", "[", "image_class", "]", "=", "[", "line", "]", "\n", "", "else", ":", "\n", "            ", "train_dict", "[", "image_class", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "num", "in", "range", "(", "nb_groups", ")", ":", "\n", "        ", "group_images", "=", "[", "]", "\n", "for", "key", "in", "train_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "int", "(", "key", ")", ">=", "num", "*", "nb_cl", "and", "int", "(", "key", ")", "<", "(", "num", "+", "1", ")", "*", "nb_cl", ":", "\n", "                ", "group_images", ".", "extend", "(", "train_dict", "[", "int", "(", "key", ")", "]", ")", "\n", "", "", "files_train", ".", "append", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "len", "(", "files_train", ")", "==", "nb_groups", ")", "\n", "train_images_number", "=", "0", "\n", "for", "group_images", "in", "files_train", ":", "\n", "        ", "train_images_number", "+=", "len", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "train_images_number", "==", "total_train_images_number", ")", "\n", "\n", "# Same for validation", "\n", "val_dict", "=", "{", "}", "\n", "for", "line", "in", "val_list", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "img_path_class", "=", "line", ".", "split", "(", ")", "\n", "image_path", ",", "image_class", "=", "img_path_class", "[", "0", "]", ",", "int", "(", "img_path_class", "[", "1", "]", ")", "\n", "if", "image_class", "not", "in", "val_dict", ".", "keys", "(", ")", ":", "\n", "            ", "val_dict", "[", "image_class", "]", "=", "[", "line", "]", "\n", "", "else", ":", "\n", "            ", "val_dict", "[", "image_class", "]", ".", "append", "(", "line", ")", "\n", "\n", "", "", "for", "num", "in", "range", "(", "nb_groups", ")", ":", "\n", "        ", "group_images", "=", "[", "]", "\n", "for", "key", "in", "val_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "int", "(", "key", ")", ">=", "num", "*", "nb_cl", "and", "int", "(", "key", ")", "<", "(", "num", "+", "1", ")", "*", "nb_cl", ":", "\n", "                ", "group_images", ".", "extend", "(", "val_dict", "[", "int", "(", "key", ")", "]", ")", "\n", "", "", "files_valid", ".", "append", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "len", "(", "files_valid", ")", "==", "nb_groups", ")", "\n", "val_images_number", "=", "0", "\n", "for", "group_images", "in", "files_valid", ":", "\n", "        ", "val_images_number", "+=", "len", "(", "group_images", ")", "\n", "\n", "", "assert", "(", "val_images_number", "==", "total_val_images_number", ")", "\n", "\n", "return", "files_train", ",", "files_valid", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.features_extraction.get_dataset_mean_std": [[14, 28], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "float", "re.findall", "re.findall"], "function", ["None"], ["\n", "utils", "=", "DataUtils", "(", ")", "\n", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "!=", "2", ":", "\n", "    ", "print", "(", "'Arguments : general_config'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "sys", ".", "argv", "[", "1", "]", ")", ":", "\n", "    ", "print", "(", "'No configuration file found in the specified path'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "\n", "# loading configuration file", "\n", "", "cp", "=", "ConfigParser", "(", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_dataset.split_images_labels": [[8, 17], ["images.append", "labels.append", "numpy.array", "numpy.array"], "function", ["None"], ["def", "split_images_labels", "(", "imgs", ")", ":", "\n", "\n", "    ", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "item", "in", "imgs", ":", "\n", "        ", "images", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "labels", ".", "append", "(", "item", "[", "1", "]", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "images", ")", ",", "np", ".", "array", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_dataset.split_images_labels_paths": [[19, 29], ["images.append", "labels.append", "paths.append", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "split_images_labels_paths", "(", "imgs", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "paths", "=", "[", "]", "\n", "for", "item", "in", "imgs", ":", "\n", "        ", "images", ".", "append", "(", "item", "[", "0", "]", ")", "\n", "labels", ".", "append", "(", "item", "[", "1", "]", ")", "\n", "paths", ".", "append", "(", "item", "[", "2", "]", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "images", ")", ",", "np", ".", "array", "(", "labels", ")", ",", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_dataset.merge_images_labels": [[31, 41], ["list", "list", "range", "len", "len", "len", "imgs.append"], "function", ["None"], ["", "def", "merge_images_labels", "(", "images", ",", "labels", ")", ":", "\n", "    ", "images", "=", "list", "(", "images", ")", "\n", "labels", "=", "list", "(", "labels", ")", "\n", "assert", "(", "len", "(", "images", ")", "==", "len", "(", "labels", ")", ")", "\n", "imgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "images", ")", ")", ":", "\n", "        ", "item", "=", "(", "images", "[", "i", "]", ",", "labels", "[", "i", "]", ")", "\n", "imgs", ".", "append", "(", "item", ")", "\n", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_dataset.save_protosets": [[43, 50], ["os.path.join", "open", "open.close", "open.write", "int", "str"], "function", ["None"], ["", "def", "save_protosets", "(", "current_eval_set", ",", "b", ",", "output_dir", ")", ":", "\n", "    ", "ckp_name", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'protoset_{}.lst'", ".", "format", "(", "b", ")", ")", "\n", "protoset_file", "=", "open", "(", "ckp_name", ",", "'w'", ")", "\n", "for", "protoset", "in", "current_eval_set", ":", "\n", "        ", "path", ",", "class_", "=", "protoset", "[", "0", "]", ",", "int", "(", "protoset", "[", "1", "]", ")", "\n", "protoset_file", ".", "write", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", "+", "'\\n'", ")", "\n", "", "protoset_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.CosineLinear.__init__": [[9, 19], ["torch.nn.Module.__init__", "torch.nn.parameter.Parameter", "modified_linear.CosineLinear.reset_parameters", "torch.Tensor", "torch.nn.parameter.Parameter", "modified_linear.CosineLinear.register_parameter", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.CosineLinear.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "sigma", "=", "True", ")", ":", "\n", "        ", "super", "(", "CosineLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "if", "sigma", ":", "\n", "            ", "self", ".", "sigma", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'sigma'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.CosineLinear.reset_parameters": [[20, 25], ["modified_linear.CosineLinear.weight.data.uniform_", "math.sqrt", "modified_linear.CosineLinear.sigma.data.fill_", "modified_linear.CosineLinear.weight.size"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "weight", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "self", ".", "sigma", ".", "data", ".", "fill_", "(", "1", ")", "#for initializaiton of sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.CosineLinear.forward": [[26, 38], ["torch.nn.functional.linear", "torch.nn.functional.normalize", "torch.nn.functional.normalize"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "#w_norm = self.weight.data.norm(dim=1, keepdim=True)", "\n", "#w_norm = w_norm.expand_as(self.weight).add_(self.epsilon)", "\n", "#x_norm = input.data.norm(dim=1, keepdim=True)", "\n", "#x_norm = x_norm.expand_as(input).add_(self.epsilon)", "\n", "#w = self.weight.div(w_norm)", "\n", "#x = input.div(x_norm)", "\n", "        ", "out", "=", "F", ".", "linear", "(", "F", ".", "normalize", "(", "input", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ",", "F", ".", "normalize", "(", "self", ".", "weight", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ")", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "sigma", "*", "out", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.SplitCosineLinear.__init__": [[41, 52], ["torch.nn.Module.__init__", "modified_linear.CosineLinear", "modified_linear.CosineLinear", "torch.nn.parameter.Parameter", "modified_linear.SplitCosineLinear.sigma.data.fill_", "modified_linear.SplitCosineLinear.register_parameter", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features1", ",", "out_features2", ",", "sigma", "=", "True", ")", ":", "\n", "        ", "super", "(", "SplitCosineLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features1", "+", "out_features2", "\n", "self", ".", "fc1", "=", "CosineLinear", "(", "in_features", ",", "out_features1", ",", "False", ")", "\n", "self", ".", "fc2", "=", "CosineLinear", "(", "in_features", ",", "out_features2", ",", "False", ")", "\n", "if", "sigma", ":", "\n", "            ", "self", ".", "sigma", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "sigma", ".", "data", ".", "fill_", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'sigma'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_linear.SplitCosineLinear.forward": [[53, 60], ["modified_linear.SplitCosineLinear.fc1", "modified_linear.SplitCosineLinear.fc2", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out1", "=", "self", ".", "fc1", "(", "x", ")", "\n", "out2", "=", "self", ".", "fc2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out1", ",", "out2", ")", ",", "dim", "=", "1", ")", "#concatenate along the channel", "\n", "if", "self", ".", "sigma", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "sigma", "*", "out", "\n", "", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.BasicBlock.__init__": [[28, 37], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.conv3x3", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.BasicBlock.forward": [[38, 55], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.Bottleneck.__init__": [[60, 72], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.Bottleneck.forward": [[73, 94], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.ResNet.__init__": [[97, 118], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.ResNet._make_layer": [[119, 135], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.ResNet.forward": [[136, 152], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv3x3": [[19, 23], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet18": [[153, 163], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet34": [[165, 175], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet50": [[176, 186], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet101": [[188, 198], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet152": [[200, 210], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.BasicBlock.__init__": [[15, 25], ["torch.Module.__init__", "modified_resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "modified_resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.conv3x3", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "last", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "last", "=", "last", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.BasicBlock.forward": [[26, 44], ["modified_resnet.BasicBlock.conv1", "modified_resnet.BasicBlock.bn1", "modified_resnet.BasicBlock.relu", "modified_resnet.BasicBlock.conv2", "modified_resnet.BasicBlock.bn2", "modified_resnet.BasicBlock.downsample", "modified_resnet.BasicBlock.relu"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "if", "not", "self", ".", "last", ":", "#remove ReLU in the last layer", "\n", "            ", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet.__init__": [[47, 68], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "modified_resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "modified_linear.CosineLinear", "modified_resnet.ResNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "last_phase", "=", "True", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "modified_linear", ".", "CosineLinear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet._make_layer": [[69, 90], ["layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "range", "layers.append", "range", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "layers.append", "block", "layers.append", "block", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "last_phase", "=", "False", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "if", "last_phase", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "blocks", "-", "1", ")", ":", "\n", "                ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "last", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "                ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.ResNet.forward": [[91, 107], ["modified_resnet.ResNet.conv1", "modified_resnet.ResNet.bn1", "modified_resnet.ResNet.relu", "modified_resnet.ResNet.maxpool", "modified_resnet.ResNet.layer1", "modified_resnet.ResNet.layer2", "modified_resnet.ResNet.layer3", "modified_resnet.ResNet.layer4", "modified_resnet.ResNet.avgpool", "modified_resnet.ResNet.view", "modified_resnet.ResNet.fc", "modified_resnet.ResNet.size"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.conv3x3": [[6, 10], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.modified_resnet.resnet18": [[108, 116], ["modified_resnet.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.savepickle": [[22, 27], ["utils_pytorch.mkdir_p", "print", "os.dirname", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.mkdir_p"], ["", "def", "savepickle", "(", "data", ",", "file_path", ")", ":", "\n", "    ", "mkdir_p", "(", "osp", ".", "dirname", "(", "file_path", ")", ",", "delete", "=", "False", ")", "\n", "print", "(", "'pickle into'", ",", "file_path", ")", "\n", "with", "open", "(", "file_path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.unpickle": [[28, 32], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "unpickle", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.mkdir_p": [[33, 42], ["subprocess.call", "os.exists", "subprocess.call", "print"], "function", ["None"], ["", "def", "mkdir_p", "(", "path", ",", "delete", "=", "False", ",", "print_info", "=", "True", ")", ":", "\n", "    ", "if", "path", "==", "''", ":", "return", "\n", "\n", "if", "delete", ":", "\n", "        ", "subprocess", ".", "call", "(", "(", "'rm -r '", "+", "path", ")", ".", "split", "(", ")", ")", "\n", "", "if", "not", "osp", ".", "exists", "(", "path", ")", ":", "\n", "        ", "if", "print_info", ":", "\n", "            ", "print", "(", "'mkdir -p  '", "+", "path", ")", "\n", "", "subprocess", ".", "call", "(", "(", "'mkdir -p '", "+", "path", ")", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.get_mean_and_std": [[43, 56], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "print", "torch.zeros.div_", "torch.zeros.div_", "range", "len", "len", "inputs[].mean", "inputs[].std"], "function", ["None"], ["", "", "def", "get_mean_and_std", "(", "dataset", ")", ":", "\n", "    ", "'''Compute the mean and std value of dataset.'''", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ",", "num_workers", "=", "2", ")", "\n", "mean", "=", "torch", ".", "zeros", "(", "3", ")", "\n", "std", "=", "torch", ".", "zeros", "(", "3", ")", "\n", "print", "(", "'==> Computing mean and std..'", ")", "\n", "for", "inputs", ",", "targets", "in", "dataloader", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "mean", "[", "i", "]", "+=", "inputs", "[", ":", ",", "i", ",", ":", ",", ":", "]", ".", "mean", "(", ")", "\n", "std", "[", "i", "]", "+=", "inputs", "[", ":", ",", "i", ",", ":", ",", ":", "]", ".", "std", "(", ")", "\n", "", "", "mean", ".", "div_", "(", "len", "(", "dataset", ")", ")", "\n", "std", ".", "div_", "(", "len", "(", "dataset", ")", ")", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.init_params": [[57, 71], ["net.modules", "isinstance", "torch.kaiming_normal_", "isinstance", "torch.constant_", "torch.constant_", "torch.constant_", "isinstance", "torch.normal_", "torch.constant_"], "function", ["None"], ["", "def", "init_params", "(", "net", ")", ":", "\n", "    ", "'''Init layer parameters.'''", "\n", "for", "m", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "if", "m", ".", "bias", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ",", "std", "=", "1e-3", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_pytorch.format_time": [[73, 104], ["int", "int", "int", "int", "int", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "", "", "def", "format_time", "(", "seconds", ")", ":", "\n", "    ", "days", "=", "int", "(", "seconds", "/", "3600", "/", "24", ")", "\n", "seconds", "=", "seconds", "-", "days", "*", "3600", "*", "24", "\n", "hours", "=", "int", "(", "seconds", "/", "3600", ")", "\n", "seconds", "=", "seconds", "-", "hours", "*", "3600", "\n", "minutes", "=", "int", "(", "seconds", "/", "60", ")", "\n", "seconds", "=", "seconds", "-", "minutes", "*", "60", "\n", "secondsf", "=", "int", "(", "seconds", ")", "\n", "seconds", "=", "seconds", "-", "secondsf", "\n", "millis", "=", "int", "(", "seconds", "*", "1000", ")", "\n", "\n", "f", "=", "''", "\n", "i", "=", "1", "\n", "if", "days", ">", "0", ":", "\n", "        ", "f", "+=", "str", "(", "days", ")", "+", "'D'", "\n", "i", "+=", "1", "\n", "", "if", "hours", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "hours", ")", "+", "'h'", "\n", "i", "+=", "1", "\n", "", "if", "minutes", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "minutes", ")", "+", "'m'", "\n", "i", "+=", "1", "\n", "", "if", "secondsf", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "secondsf", ")", "+", "'s'", "\n", "i", "+=", "1", "\n", "", "if", "millis", ">", "0", "and", "i", "<=", "2", ":", "\n", "        ", "f", "+=", "str", "(", "millis", ")", "+", "'ms'", "\n", "i", "+=", "1", "\n", "", "if", "f", "==", "''", ":", "\n", "        ", "f", "=", "'0ms'", "\n", "", "return", "f", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.ImagenetModel.__init__": [[186, 220], ["resnet.Model.__init__", "main_no_herding._get_block_sizes"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main._get_block_sizes"], ["tg_model", "=", "modified_resnet", ".", "resnet18", "(", "num_classes", "=", "B", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\"out_features:\"", ",", "out_features", ")", "\n", "ref_model", "=", "None", "\n", "", "elif", "b", "==", "first_batch_number", "+", "1", ":", "\n", "############################################################", "\n", "                ", "last_iter", "=", "b", "\n", "############################################################", "\n", "#increment classes", "\n", "ref_model", "=", "copy", ".", "deepcopy", "(", "tg_model", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\"out_features:\"", ",", "out_features", ")", "\n", "new_fc", "=", "modified_linear", ".", "SplitCosineLinear", "(", "in_features", ",", "out_features", ",", "P", ")", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "=", "tg_model", ".", "fc", ".", "weight", ".", "data", "\n", "new_fc", ".", "sigma", ".", "data", "=", "tg_model", ".", "fc", ".", "sigma", ".", "data", "\n", "tg_model", ".", "fc", "=", "new_fc", "\n", "lamda_mult", "=", "out_features", "*", "1.0", "/", "P", "\n", "", "else", ":", "\n", "############################################################", "\n", "                ", "last_iter", "=", "b", "\n", "############################################################", "\n", "ref_model", "=", "copy", ".", "deepcopy", "(", "tg_model", ")", "\n", "in_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "out_features1", "=", "tg_model", ".", "fc", ".", "fc1", ".", "out_features", "\n", "out_features2", "=", "tg_model", ".", "fc", ".", "fc2", ".", "out_features", "\n", "print", "(", "\"in_features:\"", ",", "in_features", ",", "\"out_features1:\"", ",", "out_features1", ",", "\"out_features2:\"", ",", "out_features2", ")", "\n", "new_fc", "=", "modified_linear", ".", "SplitCosineLinear", "(", "in_features", ",", "out_features1", "+", "out_features2", ",", "P", ")", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "[", ":", "out_features1", "]", "=", "tg_model", ".", "fc", ".", "fc1", ".", "weight", ".", "data", "\n", "new_fc", ".", "fc1", ".", "weight", ".", "data", "[", "out_features1", ":", "]", "=", "tg_model", ".", "fc", ".", "fc2", ".", "weight", ".", "data", "\n", "new_fc", ".", "sigma", ".", "data", "=", "tg_model", ".", "fc", ".", "sigma", ".", "data", "\n", "tg_model", ".", "fc", "=", "new_fc", "\n", "lamda_mult", "=", "(", "out_features1", "+", "out_features2", ")", "*", "1.0", "/", "(", "P", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.ImagenetModel.__call__": [[221, 315], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.transpose", "tensorflow.variable_scope", "resnet.conv2d_fixed_padding", "tensorflow.identity", "enumerate", "resnet.batch_norm_relu", "tensorflow.layers.average_pooling2d", "tensorflow.identity", "tensorflow.reshape", "tensorflow.identity", "tensorflow.layers.dense", "tensorflow.identity", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope.reuse_variables", "tensorflow.variable_scope", "resnet.conv2d_fixed_padding", "tensorflow.identity", "enumerate", "resnet.batch_norm_relu", "tensorflow.layers.average_pooling2d", "tensorflow.identity", "tensorflow.reshape", "tensorflow.identity", "tensorflow.layers.dense", "tensorflow.identity", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope.reuse_variables", "tensorflow.layers.max_pooling2d", "tensorflow.identity", "resnet.block_layer", "tensorflow.layers.max_pooling2d", "tensorflow.identity", "resnet.block_layer"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer"], ["\n", "", "if", "b", ">", "first_batch_number", "and", "less_forget", "and", "adapt_lamda", ":", "\n", "                ", "cur_lamda", "=", "lamda", "*", "math", ".", "sqrt", "(", "lamda_mult", ")", "\n", "", "else", ":", "\n", "                ", "cur_lamda", "=", "lamda", "\n", "", "if", "b", ">", "first_batch_number", "and", "less_forget", ":", "\n", "                ", "print", "(", "\"###############################\"", ")", "\n", "print", "(", "\"Lamda for less forget is set to \"", ",", "cur_lamda", ")", "\n", "print", "(", "\"###############################\"", ")", "\n", "\n", "# Prepare the training data for the current batch of classes", "\n", "", "actual_cl", "=", "order", "[", "range", "(", "last_iter", "*", "P", ",", "(", "b", "+", "1", ")", "*", "P", ")", "]", "\n", "indices_train_10", "=", "np", ".", "array", "(", "[", "i", "in", "order", "[", "range", "(", "last_iter", "*", "P", ",", "(", "b", "+", "1", ")", "*", "P", ")", "]", "for", "i", "in", "Y_train_total", "]", ")", "\n", "indices_test_10", "=", "np", ".", "array", "(", "[", "i", "in", "order", "[", "range", "(", "last_iter", "*", "P", ",", "(", "b", "+", "1", ")", "*", "P", ")", "]", "for", "i", "in", "Y_valid_total", "]", ")", "\n", "\n", "X_train", "=", "X_train_total", "[", "indices_train_10", "]", "\n", "X_valid", "=", "X_valid_total", "[", "indices_test_10", "]", "\n", "X_valid_cumuls", ".", "append", "(", "X_valid", ")", "\n", "X_train_cumuls", ".", "append", "(", "X_train", ")", "\n", "X_valid_cumul", "=", "np", ".", "concatenate", "(", "X_valid_cumuls", ")", "\n", "X_train_cumul", "=", "np", ".", "concatenate", "(", "X_train_cumuls", ")", "\n", "\n", "Y_train", "=", "Y_train_total", "[", "indices_train_10", "]", "\n", "Y_valid", "=", "Y_valid_total", "[", "indices_test_10", "]", "\n", "Y_valid_cumuls", ".", "append", "(", "Y_valid", ")", "\n", "Y_train_cumuls", ".", "append", "(", "Y_train", ")", "\n", "Y_valid_cumul", "=", "np", ".", "concatenate", "(", "Y_valid_cumuls", ")", "\n", "Y_train_cumul", "=", "np", ".", "concatenate", "(", "Y_train_cumuls", ")", "\n", "\n", "# Add the stored exemplars to the training data", "\n", "if", "b", "==", "first_batch_number", ":", "\n", "                ", "X_valid_ori", "=", "X_valid", "\n", "Y_valid_ori", "=", "Y_valid", "\n", "", "else", ":", "\n", "                ", "X_protoset", "=", "np", ".", "concatenate", "(", "X_protoset_cumuls", ")", "\n", "Y_protoset", "=", "np", ".", "concatenate", "(", "Y_protoset_cumuls", ")", "\n", "if", "rs_ratio", ">", "0", ":", "\n", "                    ", "scale_factor", "=", "(", "len", "(", "X_train", ")", "*", "rs_ratio", ")", "/", "(", "len", "(", "X_protoset", ")", "*", "(", "1", "-", "rs_ratio", ")", ")", "\n", "rs_sample_weights", "=", "np", ".", "concatenate", "(", "(", "np", ".", "ones", "(", "len", "(", "X_train", ")", ")", ",", "np", ".", "ones", "(", "len", "(", "X_protoset", ")", ")", "*", "scale_factor", ")", ")", "\n", "#number of samples per epoch", "\n", "rs_num_samples", "=", "int", "(", "len", "(", "X_train", ")", "/", "(", "1", "-", "rs_ratio", ")", ")", "\n", "print", "(", "\"X_train:{}, X_protoset:{}, rs_num_samples:{}\"", ".", "format", "(", "len", "(", "X_train", ")", ",", "len", "(", "X_protoset", ")", ",", "rs_num_samples", ")", ")", "\n", "", "X_train", "=", "np", ".", "concatenate", "(", "(", "X_train", ",", "X_protoset", ")", ",", "axis", "=", "0", ")", "\n", "Y_train", "=", "np", ".", "concatenate", "(", "(", "Y_train", ",", "Y_protoset", ")", ")", "\n", "\n", "# Launch the training loop", "\n", "", "print", "(", "'Batch of classes number {0} arrives ...'", ".", "format", "(", "b", "+", "1", ")", ")", "\n", "map_Y_train", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_train", "]", ")", "\n", "map_Y_valid_cumul", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_valid_cumul", "]", ")", "\n", "\n", "#imprint weights", "\n", "if", "b", ">", "first_batch_number", "and", "imprint_weights", ":", "\n", "                ", "print", "(", "\"Imprint weights\"", ")", "\n", "#########################################", "\n", "#compute the average norm of old embdding", "\n", "old_embedding_norm", "=", "tg_model", ".", "fc", ".", "fc1", ".", "weight", ".", "data", ".", "norm", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "average_old_embedding_norm", "=", "torch", ".", "mean", "(", "old_embedding_norm", ",", "dim", "=", "0", ")", ".", "to", "(", "'cpu'", ")", ".", "type", "(", "torch", ".", "DoubleTensor", ")", "\n", "#########################################", "\n", "tg_feature_model", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "tg_model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "num_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "novel_embedding", "=", "torch", ".", "zeros", "(", "(", "P", ",", "num_features", ")", ")", "\n", "for", "cls_idx", "in", "range", "(", "b", "*", "P", ",", "(", "b", "+", "1", ")", "*", "P", ")", ":", "\n", "                    ", "cls_indices", "=", "np", ".", "array", "(", "[", "i", "==", "cls_idx", "for", "i", "in", "map_Y_train", "]", ")", "\n", "assert", "(", "len", "(", "np", ".", "where", "(", "cls_indices", "==", "1", ")", "[", "0", "]", ")", "<=", "max_class_len", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "X_train", "[", "cls_indices", "]", ",", "np", ".", "zeros", "(", "len", "(", "X_train", "[", "cls_indices", "]", ")", ")", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ")", "\n", "num_samples", "=", "len", "(", "X_train", "[", "cls_indices", "]", ")", "\n", "cls_features", "=", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ")", "\n", "norm_features", "=", "F", ".", "normalize", "(", "torch", ".", "from_numpy", "(", "cls_features", ")", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "cls_embedding", "=", "torch", ".", "mean", "(", "norm_features", ",", "dim", "=", "0", ")", "\n", "novel_embedding", "[", "cls_idx", "-", "b", "*", "P", "]", "=", "F", ".", "normalize", "(", "cls_embedding", ",", "p", "=", "2", ",", "dim", "=", "0", ")", "*", "average_old_embedding_norm", "\n", "", "tg_model", ".", "to", "(", "device", ")", "\n", "tg_model", ".", "fc", ".", "fc2", ".", "weight", ".", "data", "=", "novel_embedding", ".", "to", "(", "device", ")", "\n", "\n", "############################################################", "\n", "", "current_train_imgs", "=", "merge_images_labels", "(", "X_train", ",", "map_Y_train", ")", "\n", "trainset", ".", "imgs", "=", "trainset", ".", "samples", "=", "current_train_imgs", "\n", "if", "b", ">", "first_batch_number", "and", "rs_ratio", ">", "0", "and", "scale_factor", ">", "1", ":", "\n", "                ", "print", "(", "\"Weights from sampling:\"", ",", "rs_sample_weights", ")", "\n", "index1", "=", "np", ".", "where", "(", "rs_sample_weights", ">", "1", ")", "[", "0", "]", "\n", "index2", "=", "np", ".", "where", "(", "map_Y_train", "<", "b", "*", "P", ")", "[", "0", "]", "\n", "assert", "(", "(", "index1", "==", "index2", ")", ".", "all", "(", ")", ")", "\n", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "WeightedRandomSampler", "(", "rs_sample_weights", ",", "rs_num_samples", ")", "\n", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "train_batch_size", ",", "shuffle", "=", "False", ",", "sampler", "=", "train_sampler", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "train_batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "print", "(", "'Training-set size = '", "+", "str", "(", "len", "(", "trainset", ")", ")", ")", "\n", "\n", "current_test_imgs", "=", "merge_images_labels", "(", "X_valid_cumul", ",", "map_Y_valid_cumul", ")", "\n", "testset", ".", "imgs", "=", "testset", ".", "samples", "=", "current_test_imgs", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.parse_record": [[117, 152], ["tensorflow.read_file", "tensorflow.image.decode_jpeg", "tensorflow.image.decode_jpeg", "vgg_preprocessing.preprocess_image", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.reduce_join", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing.preprocess_image"], ["\n", "testset", "=", "ImagesListFileFolder", "(", "\n", "test_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "]", ")", ")", "\n", "\n", "\n", "evalset", "=", "ImagesListFileFolder", "(", "\n", "test_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "]", ")", ")", "\n", "\n", "################################", "\n", "\n", "# Initialization", "\n", "# top1_acc_list_cumul = np.zeros((int(num_classes/P),3,nb_runs))", "\n", "# top1_acc_list_ori   = np.zeros((int(num_classes/P),3,nb_runs))", "\n", "\n", "X_train_total", ",", "Y_train_total", "=", "split_images_labels", "(", "trainset", ".", "imgs", ")", "\n", "X_valid_total", ",", "Y_valid_total", "=", "split_images_labels", "(", "testset", ".", "imgs", ")", "\n", "\n", "# Launch the different runs", "\n", "for", "iteration_total", "in", "range", "(", "nb_runs", ")", ":", "\n", "\n", "        ", "top1_cnn_cumul_acc", "=", "[", "]", "\n", "top5_cnn_cumul_acc", "=", "[", "]", "\n", "top1_icarl_cumul_acc", "=", "[", "]", "\n", "top5_icarl_cumul_acc", "=", "[", "]", "\n", "top1_ncm_cumul_acc", "=", "[", "]", "\n", "top5_ncm_cumul_acc", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.input_fn": [[154, 180], ["tensorflow.data.Dataset.from_tensor_slices", "len", "resnet.process_record_dataset", "dataset.shuffle.shuffle"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.process_record_dataset"], ["\n", "#follow the same order than us", "\n", "order", "=", "np", ".", "arange", "(", "num_classes", ")", "\n", "order_list", "=", "list", "(", "order", ")", "\n", "\n", "# Initialization of the variables for this run", "\n", "X_valid_cumuls", "=", "[", "]", "\n", "X_protoset_cumuls", "=", "[", "]", "\n", "X_train_cumuls", "=", "[", "]", "\n", "Y_valid_cumuls", "=", "[", "]", "\n", "Y_protoset_cumuls", "=", "[", "]", "\n", "Y_train_cumuls", "=", "[", "]", "\n", "\n", "# The following contains all the training samples of the different classes", "\n", "# because we want to compare our method with the theoretical case where all the training samples are stored", "\n", "prototypes", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_classes", ")", "]", "\n", "for", "orde", "in", "range", "(", "num_classes", ")", ":", "\n", "            ", "prototypes", "[", "orde", "]", "=", "X_train_total", "[", "np", ".", "where", "(", "Y_train_total", "==", "order", "[", "orde", "]", ")", "]", "\n", "\n", "", "prototypes", "=", "np", ".", "array", "(", "prototypes", ")", "\n", "max_class_len", "=", "max", "(", "len", "(", "e", ")", "for", "e", "in", "prototypes", ")", "\n", "\n", "alpha_dr_herding", "=", "np", ".", "zeros", "(", "(", "int", "(", "num_classes", "/", "P", ")", ",", "max_class_len", ",", "P", ")", ",", "np", ".", "float32", ")", "\n", "\n", "\n", "first_batch_number", "=", "int", "(", "B", "/", "P", ")", "-", "1", "\n", "for", "b", "in", "range", "(", "first_batch_number", ",", "last_batch_number", ")", ":", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding._get_block_sizes": [[319, 340], ["ValueError", "choices.keys"], "function", ["None"], ["print", "(", "'Max and Min of valid labels: {}, {}'", ".", "format", "(", "min", "(", "map_Y_valid_cumul", ")", ",", "max", "(", "map_Y_valid_cumul", ")", ")", ")", "\n", "##############################################################", "\n", "ckp_name", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "ckp_prefix", "+", "'_model_{}.pth'", ".", "format", "(", "b", ")", ")", "\n", "print", "(", "'ckp_name'", ",", "ckp_name", ")", "\n", "if", "resume", "and", "os", ".", "path", ".", "exists", "(", "ckp_name", ")", ":", "\n", "                ", "print", "(", "\"###############################\"", ")", "\n", "print", "(", "\"Loading models from checkpoint\"", ")", "\n", "tg_model", "=", "torch", ".", "load", "(", "ckp_name", ")", "\n", "print", "(", "\"###############################\"", ")", "\n", "", "else", ":", "\n", "###############################", "\n", "                ", "if", "b", ">", "first_batch_number", "and", "less_forget", ":", "\n", "#fix the embedding of old classes", "\n", "                    ", "ignored_params", "=", "list", "(", "map", "(", "id", ",", "tg_model", ".", "fc", ".", "fc1", ".", "parameters", "(", ")", ")", ")", "\n", "base_params", "=", "filter", "(", "lambda", "p", ":", "id", "(", "p", ")", "not", "in", "ignored_params", ",", "tg_model", ".", "parameters", "(", ")", ")", "\n", "tg_params", "=", "[", "{", "'params'", ":", "base_params", ",", "'lr'", ":", "base_lr", ",", "'weight_decay'", ":", "custom_weight_decay", "}", ",", "{", "'params'", ":", "tg_model", ".", "fc", ".", "fc1", ".", "parameters", "(", ")", ",", "'lr'", ":", "0", ",", "'weight_decay'", ":", "0", "}", "]", "\n", "", "else", ":", "\n", "                    ", "tg_params", "=", "tg_model", ".", "parameters", "(", ")", "\n", "###############################", "\n", "", "tg_model", "=", "tg_model", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.imagenet_model_fn": [[342, 374], ["resnet.resnet_model_fn", "resnet.learning_rate_with_decay", "resnet.learning_rate_with_decay"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_model_fn", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.learning_rate_with_decay", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.learning_rate_with_decay"], ["                    ", "ref_model", "=", "ref_model", ".", "to", "(", "device", ")", "\n", "", "tg_optimizer", "=", "optim", ".", "SGD", "(", "tg_params", ",", "lr", "=", "base_lr", ",", "momentum", "=", "custom_momentum", ",", "weight_decay", "=", "custom_weight_decay", ")", "\n", "tg_lr_scheduler", "=", "lr_scheduler", ".", "MultiStepLR", "(", "tg_optimizer", ",", "milestones", "=", "lr_strat", ",", "gamma", "=", "lr_factor", ")", "\n", "###############################", "\n", "if", "less_forget", "and", "mr_loss", ":", "\n", "#apply the full LUCIR", "\n", "                    ", "print", "(", "\"train_eval_MR_LF\"", ")", "\n", "tg_model", "=", "train_eval_MR_LF", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "b", ",", "first_batch_number", ",", "cur_lamda", ",", "dist", ",", "K", ",", "lw_mr", ")", "\n", "", "else", ":", "#one of them is false or both are false", "\n", "                    ", "if", "less_forget", ":", "#apply only the less forget constraint, mr_loss is false", "\n", "                        ", "print", "(", "\"train_eval_LF\"", ")", "\n", "tg_model", "=", "train_eval_LF", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "b", ",", "first_batch_number", ",", "cur_lamda", ")", "\n", "", "else", ":", "#less forget is false, mr loss can be true or false, but doesn't matter", "\n", "                        ", "if", "mimic_score", ":", "\n", "                            ", "print", "(", "\"train_eval_MS\"", ")", "#apply cosine norm only", "\n", "tg_model", "=", "train_eval_MS", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "b", ",", "first_batch_number", ",", "\n", "lw_ms", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "\"train_eval\"", ")", "#don't apply anything:baseline", "\n", "tg_model", "=", "train_eval", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "b", ",", "first_batch_number", ",", "\n", "T", ",", "beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main_no_herding.main": [[376, 495], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "range", "print", "print", "print", "int", "print", "print", "print", "range", "range", "int", "range", "range", "range", "print", "print", "resnet.resnet_main", "print", "resnet.resnet_main", "math.ceil", "int", "resnet_features_.append", "numpy.asarray", "numpy.mean", "range", "numpy.ceil", "int", "len", "math.ceil", "numpy.where", "numpy.asarray", "numpy.random.randint", "selected_feat.append", "selected.append", "x_train_protoset[].append", "y_train_protoset[].append", "math.ceil", "len", "len", "len", "len", "len", "len", "len", "len", "str", "min", "min", "candidates.append", "candidates_feat.append", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_main", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_main"], ["", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "output_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "torch", ".", "save", "(", "tg_model", ",", "ckp_name", ")", "\n", "\n", "### Exemplars", "\n", "", "nb_protos_cl", "=", "int", "(", "math", ".", "ceil", "(", "memory_size", "/", "(", "B", "+", "P", "*", "b", ")", ")", ")", "\n", "\n", "print", "(", "'nb_protos_cl = '", "+", "str", "(", "nb_protos_cl", ")", ")", "\n", "\n", "tg_feature_model", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "tg_model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", "\n", "num_features", "=", "tg_model", ".", "fc", ".", "in_features", "\n", "# Herding", "\n", "print", "(", "'Updating exemplar set...'", ")", "\n", "for", "iter_dico", "in", "range", "(", "last_iter", "*", "P", ",", "(", "b", "+", "1", ")", "*", "P", ")", ":", "\n", "# Possible exemplars in the feature space and projected on the L2 sphere", "\n", "                ", "current_eval_set", "=", "merge_images_labels", "(", "prototypes", "[", "iter_dico", "]", ",", "np", ".", "zeros", "(", "len", "(", "prototypes", "[", "iter_dico", "]", ")", ")", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "num_samples", "=", "len", "(", "prototypes", "[", "iter_dico", "]", ")", "#number of images per class", "\n", "mapped_prototypes", "=", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ")", "\n", "D", "=", "mapped_prototypes", ".", "T", "\n", "D", "=", "D", "/", "np", ".", "linalg", ".", "norm", "(", "D", ",", "axis", "=", "0", ")", "\n", "\n", "# Herding procedure : ranking of the potential exemplars", "\n", "mu", "=", "np", ".", "mean", "(", "D", ",", "axis", "=", "1", ")", "\n", "index1", "=", "int", "(", "iter_dico", "/", "P", ")", "\n", "index2", "=", "iter_dico", "%", "P", "\n", "alpha_dr_herding", "[", "index1", ",", ":", ",", "index2", "]", "=", "alpha_dr_herding", "[", "index1", ",", ":", ",", "index2", "]", "*", "0", "\n", "w_t", "=", "mu", "\n", "iter_herding", "=", "0", "\n", "iter_herding_eff", "=", "0", "\n", "while", "not", "(", "np", ".", "sum", "(", "alpha_dr_herding", "[", "index1", ",", ":", ",", "index2", "]", "!=", "0", ")", "==", "min", "(", "nb_protos_cl", ",", "num_samples", ")", ")", "and", "iter_herding_eff", "<", "1000", ":", "\n", "                    ", "tmp_t", "=", "np", ".", "dot", "(", "w_t", ",", "D", ")", "\n", "ind_max", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "tmp_t", ")", ")", "#no herding", "\n", "iter_herding_eff", "+=", "1", "\n", "if", "alpha_dr_herding", "[", "index1", ",", "ind_max", ",", "index2", "]", "==", "0", ":", "\n", "                        ", "alpha_dr_herding", "[", "index1", ",", "ind_max", ",", "index2", "]", "=", "1", "+", "iter_herding", "\n", "iter_herding", "+=", "1", "\n", "", "w_t", "=", "w_t", "+", "mu", "-", "D", "[", ":", ",", "ind_max", "]", "\n", "\n", "# Prepare the protoset", "\n", "", "", "X_protoset_cumuls", "=", "[", "]", "\n", "Y_protoset_cumuls", "=", "[", "]", "\n", "\n", "# Class means for iCaRL and NCM + Storing the selected exemplars in the protoset", "\n", "print", "(", "'Computing mean-of_exemplars and theoretical mean...'", ")", "\n", "class_means", "=", "np", ".", "zeros", "(", "(", "num_features", ",", "num_classes", ",", "2", ")", ")", "\n", "for", "b2", "in", "range", "(", "b", "+", "1", ")", ":", "\n", "                ", "for", "iter_dico", "in", "range", "(", "P", ")", ":", "\n", "                    ", "current_cl", "=", "order", "[", "range", "(", "b2", "*", "P", ",", "(", "b2", "+", "1", ")", "*", "P", ")", "]", "\n", "current_eval_set", "=", "merge_images_labels", "(", "prototypes", "[", "b2", "*", "P", "+", "iter_dico", "]", ",", "np", ".", "zeros", "(", "len", "(", "prototypes", "[", "b2", "*", "P", "+", "iter_dico", "]", ")", ")", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "num_samples", "=", "len", "(", "prototypes", "[", "b2", "*", "P", "+", "iter_dico", "]", ")", "\n", "mapped_prototypes", "=", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ")", "\n", "#shape mapped prototypes = 512 (features) x number of images per class = 500 for cifar", "\n", "\n", "D", "=", "mapped_prototypes", ".", "T", "\n", "D", "=", "D", "/", "np", ".", "linalg", ".", "norm", "(", "D", ",", "axis", "=", "0", ")", "\n", "D2", "=", "D", "\n", "\n", "# iCaRL", "\n", "alph", "=", "alpha_dr_herding", "[", "b2", ",", ":", ",", "iter_dico", "]", "\n", "assert", "(", "(", "alph", "[", "num_samples", ":", "]", "==", "0", ")", ".", "all", "(", ")", ")", "\n", "alph", "=", "alph", "[", ":", "num_samples", "]", "\n", "alph", "=", "(", "alph", ">", "0", ")", "*", "(", "alph", "<", "nb_protos_cl", "+", "1", ")", "*", "1.", "\n", "X_protoset_cumuls", ".", "append", "(", "prototypes", "[", "b2", "*", "P", "+", "iter_dico", "]", "[", "np", ".", "where", "(", "alph", "==", "1", ")", "[", "0", "]", "]", ")", "\n", "Y_protoset_cumuls", ".", "append", "(", "order", "[", "b2", "*", "P", "+", "iter_dico", "]", "*", "np", ".", "ones", "(", "len", "(", "np", ".", "where", "(", "alph", "==", "1", ")", "[", "0", "]", ")", ")", ")", "\n", "alph", "=", "alph", "/", "np", ".", "sum", "(", "alph", ")", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", "=", "(", "np", ".", "dot", "(", "D", ",", "alph", ")", "+", "np", ".", "dot", "(", "D2", ",", "alph", ")", ")", "/", "2", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", "/=", "np", ".", "linalg", ".", "norm", "(", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "0", "]", ")", "\n", "\n", "# Normal NCM", "\n", "alph", "=", "np", ".", "ones", "(", "num_samples", ")", "/", "num_samples", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", "=", "(", "np", ".", "dot", "(", "D", ",", "alph", ")", "+", "np", ".", "dot", "(", "D2", ",", "alph", ")", ")", "/", "2", "\n", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", "/=", "np", ".", "linalg", ".", "norm", "(", "class_means", "[", ":", ",", "current_cl", "[", "iter_dico", "]", ",", "1", "]", ")", "\n", "\n", "", "", "class_means_name", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "ckp_prefix", "+", "'_class_means_{}.pth'", ".", "format", "(", "b", ")", ")", "\n", "\n", "torch", ".", "save", "(", "class_means", ",", "class_means_name", ")", "\n", "\n", "current_means", "=", "class_means", "[", ":", ",", "order", "[", "range", "(", "0", ",", "(", "b", "+", "1", ")", "*", "P", ")", "]", "]", "\n", "##############################################################", "\n", "# Calculate validation error of model on the cumul of classes:", "\n", "map_Y_valid_cumul", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "Y_valid_cumul", "]", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "X_valid_cumul", ",", "map_Y_valid_cumul", ")", "\n", "evalset", ".", "imgs", "=", "evalset", ".", "samples", "=", "current_eval_set", "\n", "evalloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "evalset", ",", "batch_size", "=", "eval_batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "cumul_acc", "=", "compute_accuracy", "(", "tg_model", ",", "tg_feature_model", ",", "current_means", ",", "evalloader", ")", "\n", "\n", "###############################", "\n", "print", "(", "'Saving protoset...'", ")", "\n", "map_Y_protoset_cumuls", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "np", ".", "concatenate", "(", "Y_protoset_cumuls", ")", "]", ")", "\n", "current_eval_set", "=", "merge_images_labels", "(", "np", ".", "concatenate", "(", "X_protoset_cumuls", ")", ",", "map_Y_protoset_cumuls", ")", "\n", "save_protosets", "(", "current_eval_set", ",", "ckp_prefix", ",", "b", ",", "output_dir", ")", "\n", "##############################################################", "\n", "if", "b", "==", "first_batch_number", "and", "cb_finetune", ":", "#for the convenience of evaluation", "\n", "                ", "torch", ".", "save", "(", "tg_model", ",", "ckp_name", ".", "replace", "(", "\"/checkpoint/\"", ",", "\"/checkpoint/AFTER_CBF_\"", ")", ")", "\n", "torch", ".", "save", "(", "class_means", ",", "class_means_name", ".", "replace", "(", "\"/checkpoint/\"", ",", "\"/checkpoint/AFTER_CBF_\"", ")", ")", "\n", "\n", "", "if", "b", ">", "first_batch_number", "and", "cb_finetune", ":", "\n", "# Class balance finetuning on the protoset", "\n", "                ", "print", "(", "\"###############################\"", ")", "\n", "print", "(", "\"Class balance finetuning on the protoset\"", ")", "\n", "print", "(", "\"###############################\"", ")", "\n", "map_Y_protoset_cumuls", "=", "np", ".", "array", "(", "[", "order_list", ".", "index", "(", "i", ")", "for", "i", "in", "np", ".", "concatenate", "(", "Y_protoset_cumuls", ")", "]", ")", "\n", "current_train_imgs", "=", "merge_images_labels", "(", "np", ".", "concatenate", "(", "X_protoset_cumuls", ")", ",", "map_Y_protoset_cumuls", ")", "\n", "trainset", ".", "imgs", "=", "trainset", ".", "samples", "=", "current_train_imgs", "\n", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "train_batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "print", "(", "'Min and Max of train labels: {}, {}'", ".", "format", "(", "min", "(", "map_Y_protoset_cumuls", ")", ",", "max", "(", "map_Y_protoset_cumuls", ")", ")", ")", "\n", "print", "(", "'Training-set size = '", "+", "str", "(", "len", "(", "trainset", ")", ")", ")", "\n", "\n", "#######################################", "\n", "if", "ft_flag", "==", "0", ":", "#everything is not updated", "\n", "                    ", "ignored_params", "=", "list", "(", "map", "(", "id", ",", "tg_model", ".", "fc", ".", "parameters", "(", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._get_h_w": [[52, 57], ["tensorflow.shape"], "function", ["None"], ["def", "_get_h_w", "(", "image", ")", ":", "\n", "  ", "\"\"\"Convenience for grabbing the height and width of an image.\n  \"\"\"", "\n", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "return", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._random_crop_and_flip": [[59, 87], ["vgg_preprocessing._get_h_w", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.slice", "tensorflow.image.random_flip_left_right"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._get_h_w"], ["", "def", "_random_crop_and_flip", "(", "image", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "  ", "\"\"\"Crops the given image to a random part of the image, and randomly flips.\n\n  Args:\n    image: a 3-D image tensor\n    crop_height: the new height.\n    crop_width: the new width.\n\n  Returns:\n    3-D tensor with cropped image.\n\n  \"\"\"", "\n", "height", ",", "width", "=", "_get_h_w", "(", "image", ")", "\n", "\n", "# Create a random bounding box.", "\n", "# Use tf.random_uniform and not numpy.random.rand as doing the former would", "\n", "# generate random numbers at graph eval time, unlike the latter which", "\n", "# generates random numbers at graph definition time.", "\n", "total_crop_height", "=", "(", "height", "-", "crop_height", ")", "\n", "crop_top", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "maxval", "=", "total_crop_height", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "total_crop_width", "=", "(", "width", "-", "crop_width", ")", "\n", "crop_left", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "maxval", "=", "total_crop_width", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "cropped", "=", "tf", ".", "slice", "(", "\n", "image", ",", "[", "crop_top", ",", "crop_left", ",", "0", "]", ",", "[", "crop_height", ",", "crop_width", ",", "-", "1", "]", ")", "\n", "\n", "cropped", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "cropped", ")", "\n", "return", "cropped", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._central_crop": [[89, 108], ["vgg_preprocessing._get_h_w", "tensorflow.slice"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._get_h_w"], ["", "def", "_central_crop", "(", "image", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "  ", "\"\"\"Performs central crops of the given image list.\n\n  Args:\n    image: a 3-D image tensor\n    crop_height: the height of the image following the crop.\n    crop_width: the width of the image following the crop.\n\n  Returns:\n    3-D tensor with cropped image.\n  \"\"\"", "\n", "height", ",", "width", "=", "_get_h_w", "(", "image", ")", "\n", "\n", "total_crop_height", "=", "(", "height", "-", "crop_height", ")", "\n", "crop_top", "=", "total_crop_height", "//", "2", "\n", "total_crop_width", "=", "(", "width", "-", "crop_width", ")", "\n", "crop_left", "=", "total_crop_width", "//", "2", "\n", "return", "tf", ".", "slice", "(", "\n", "image", ",", "[", "crop_top", ",", "crop_left", ",", "0", "]", ",", "[", "crop_height", ",", "crop_width", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._mean_image_subtraction": [[110, 141], ["tensorflow.expand_dims", "ValueError", "image.get_shape().as_list", "len", "ValueError", "tensorflow.expand_dims", "image.get_shape", "image.get_shape"], "function", ["None"], ["", "def", "_mean_image_subtraction", "(", "image", ",", "means", ")", ":", "\n", "  ", "\"\"\"Subtracts the given means from each image channel.\n\n  For example:\n    means = [123.68, 116.779, 103.939]\n    image = _mean_image_subtraction(image, means)\n\n  Note that the rank of `image` must be known.\n\n  Args:\n    image: a tensor of size [height, width, C].\n    means: a C-vector of values to subtract from each channel.\n\n  Returns:\n    the centered image.\n\n  Raises:\n    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n      than three or if the number of channels in `image` doesn't match the\n      number of values in `means`.\n  \"\"\"", "\n", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "!=", "3", ":", "\n", "    ", "raise", "ValueError", "(", "'Input must be of size [height, width, C>0]'", ")", "\n", "", "num_channels", "=", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "if", "len", "(", "means", ")", "!=", "num_channels", ":", "\n", "    ", "raise", "ValueError", "(", "'len(means) must match the number of channels'", ")", "\n", "\n", "# We have a 1-D tensor of means; convert to 3-D.", "\n", "", "means", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "means", ",", "0", ")", ",", "0", ")", "\n", "\n", "return", "image", "-", "means", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._smallest_size_at_least": [[143, 170], ["tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.minimum", "tensorflow.cast", "tensorflow.cast"], "function", ["None"], ["", "def", "_smallest_size_at_least", "(", "height", ",", "width", ",", "smallest_side", ")", ":", "\n", "  ", "\"\"\"Computes new shape with the smallest side equal to `smallest_side`.\n\n  Computes new shape with the smallest side equal to `smallest_side` while\n  preserving the original aspect ratio.\n\n  Args:\n    height: an int32 scalar tensor indicating the current height.\n    width: an int32 scalar tensor indicating the current width.\n    smallest_side: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    new_height: an int32 scalar tensor indicating the new height.\n    new_width: an int32 scalar tensor indicating the new width.\n  \"\"\"", "\n", "smallest_side", "=", "tf", ".", "cast", "(", "smallest_side", ",", "tf", ".", "float32", ")", "\n", "\n", "height", "=", "tf", ".", "cast", "(", "height", ",", "tf", ".", "float32", ")", "\n", "width", "=", "tf", ".", "cast", "(", "width", ",", "tf", ".", "float32", ")", "\n", "\n", "smaller_dim", "=", "tf", ".", "minimum", "(", "height", ",", "width", ")", "\n", "scale_ratio", "=", "smallest_side", "/", "smaller_dim", "\n", "new_height", "=", "tf", ".", "cast", "(", "height", "*", "scale_ratio", ",", "tf", ".", "int32", ")", "\n", "new_width", "=", "tf", ".", "cast", "(", "width", "*", "scale_ratio", ",", "tf", ".", "int32", ")", "\n", "\n", "return", "new_height", ",", "new_width", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._aspect_preserving_resize": [[172, 192], ["tensorflow.convert_to_tensor", "vgg_preprocessing._get_h_w", "vgg_preprocessing._smallest_size_at_least", "tensorflow.image.resize_images"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._get_h_w", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._smallest_size_at_least"], ["", "def", "_aspect_preserving_resize", "(", "image", ",", "smallest_side", ")", ":", "\n", "  ", "\"\"\"Resize images preserving the original aspect ratio.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    smallest_side: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image.\n  \"\"\"", "\n", "smallest_side", "=", "tf", ".", "convert_to_tensor", "(", "smallest_side", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "height", ",", "width", "=", "_get_h_w", "(", "image", ")", "\n", "new_height", ",", "new_width", "=", "_smallest_size_at_least", "(", "height", ",", "width", ",", "smallest_side", ")", "\n", "\n", "resized_image", "=", "tf", ".", "image", ".", "resize_images", "(", "\n", "image", ",", "[", "new_height", ",", "new_width", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "\n", "align_corners", "=", "False", ")", "\n", "return", "resized_image", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing.preprocess_image": [[194, 233], ["vgg_preprocessing._aspect_preserving_resize", "crop_fn", "tf.cast.set_shape", "tensorflow.cast", "vgg_preprocessing._mean_image_subtraction", "tensorflow.random_uniform", "tf.cast.get_shape().as_list", "tf.cast.get_shape"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._aspect_preserving_resize", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing._mean_image_subtraction"], ["", "def", "preprocess_image", "(", "image", ",", "output_height", ",", "output_width", ",", "images_mean", ",", "is_training", "=", "False", ",", "\n", "resize_side_min", "=", "_RESIZE_SIDE_MIN", ",", "\n", "resize_side_max", "=", "_RESIZE_SIDE_MAX", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n    resize_side_min: The lower bound for the smallest side of the image for\n      aspect-preserving resizing. If `is_training` is `False`, then this value\n      is used for rescaling.\n    resize_side_max: The upper bound for the smallest side of the image for\n      aspect-preserving resizing. If `is_training` is `False`, this value is\n      ignored. Otherwise, the resize side is sampled from\n        [resize_size_min, resize_size_max].\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "if", "is_training", ":", "\n", "# For training, we want to randomize some of the distortions.", "\n", "    ", "resize_side", "=", "tf", ".", "random_uniform", "(", "\n", "[", "]", ",", "minval", "=", "resize_side_min", ",", "maxval", "=", "resize_side_max", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "crop_fn", "=", "_random_crop_and_flip", "\n", "", "else", ":", "\n", "    ", "resize_side", "=", "resize_side_min", "\n", "crop_fn", "=", "_central_crop", "\n", "\n", "", "num_channels", "=", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "image", "=", "_aspect_preserving_resize", "(", "image", ",", "resize_side", ")", "\n", "image", "=", "crop_fn", "(", "image", ",", "output_height", ",", "output_width", ")", "\n", "\n", "image", ".", "set_shape", "(", "[", "output_height", ",", "output_width", ",", "num_channels", "]", ")", "\n", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "return", "_mean_image_subtraction", "(", "image", ",", "images_mean", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.ImagenetModel.__init__": [[186, 220], ["resnet.Model.__init__", "main._get_block_sizes"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main._get_block_sizes"], ["        ", "new_data_list", ".", "append", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", ")", "\n", "\n", "\n", "# Writing new data lists file:", "\n", "", "print", "(", "'New data S{}+ saved in {} '", ".", "format", "(", "batch_number", ",", "new_data_file_fpath", ")", ")", "\n", "if", "sess", "==", "0", ":", "\n", "        ", "new_data_file", "=", "open", "(", "new_data_file_fpath", ",", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "new_data_file", "=", "open", "(", "new_data_file_fpath", ",", "'a'", ")", "\n", "\n", "\n", "", "for", "line", "in", "new_data_list", ":", "\n", "        ", "new_data_file", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "new_data_file", ".", "close", "(", ")", "\n", "\n", "############################### SAVING  annotated features", "\n", "if", "balancing_AF", "==", "'poor'", ":", "\n", "        ", "new_data_features", "=", "None", "\n", "for", "feat", "in", "annotated_features", ":", "\n", "            ", "if", "new_data_features", "is", "None", ":", "\n", "                ", "new_data_features", "=", "feat", "\n", "", "else", ":", "\n", "                ", "new_data_features", "=", "np", ".", "vstack", "(", "(", "new_data_features", ",", "feat", ")", ")", "\n", "\n", "", "", "if", "sess", "==", "0", ":", "\n", "            ", "new_data_feat_file", "=", "open", "(", "new_data_feat_file_fpath", ",", "'w'", ")", "\n", "", "else", ":", "\n", "            ", "new_data_feat_file", "=", "open", "(", "new_data_feat_file_fpath", ",", "'a'", ")", "\n", "\n", "", "for", "feat", "in", "new_data_features", ":", "\n", "            ", "new_data_feat_file", ".", "write", "(", "str", "(", "' '", ".", "join", "(", "[", "str", "(", "e", ")", "for", "e", "in", "list", "(", "feat", ")", "]", ")", ")", "+", "'\\n'", ")", "\n", "", "new_data_feat_file", ".", "close", "(", ")", "\n", "##########################################", "\n", "\n", "", "oracle_annotated_paths", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.ImagenetModel.__call__": [[221, 315], ["tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.transpose", "tensorflow.variable_scope", "resnet.conv2d_fixed_padding", "tensorflow.identity", "enumerate", "resnet.batch_norm_relu", "tensorflow.layers.average_pooling2d", "tensorflow.identity", "tensorflow.reshape", "tensorflow.identity", "tensorflow.layers.dense", "tensorflow.identity", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope.reuse_variables", "tensorflow.variable_scope", "resnet.conv2d_fixed_padding", "tensorflow.identity", "enumerate", "resnet.batch_norm_relu", "tensorflow.layers.average_pooling2d", "tensorflow.identity", "tensorflow.reshape", "tensorflow.identity", "tensorflow.layers.dense", "tensorflow.identity", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope.reuse_variables", "tensorflow.layers.max_pooling2d", "tensorflow.identity", "resnet.block_layer", "tensorflow.layers.max_pooling2d", "tensorflow.identity", "resnet.block_layer"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer"], ["for", "(", "path", ",", "class_", ")", "in", "zip", "(", "annotated_paths", ",", "annotated_classes", ")", ":", "\n", "        ", "oracle_annotated_paths", ".", "append", "(", "path", "+", "' '", "+", "str", "(", "class_", ")", "+", "'\\n'", ")", "\n", "\n", "", "return", "oracle_annotated_paths", "\n", "\n", "\n", "", "def", "main", "(", "I", ")", ":", "\n", "    ", "if", "__name__", "==", "'__main__'", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "data_output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "data_output_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "models_save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "models_save_dir", ")", "\n", "\n", "# catching warnings", "\n", "", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "warn_list", ":", "\n", "            ", "herding", "=", "StaticHerding", "(", ")", "\n", "\n", "runs_top1_acc", "=", "[", "]", "\n", "runs_topx_acc", "=", "[", "]", "\n", "\n", "first_run_starting_time", "=", "time", ".", "time", "(", ")", "\n", "for", "r", "in", "range", "(", "1", ",", "num_runs", "+", "1", ")", ":", "\n", "                ", "run_data_output_dir", "=", "os", ".", "path", ".", "join", "(", "data_output_dir", ",", "'run_'", "+", "str", "(", "r", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "run_data_output_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "run_data_output_dir", ")", "\n", "\n", "", "run_models_save_dir", "=", "os", ".", "path", ".", "join", "(", "models_save_dir", ",", "'run_'", "+", "str", "(", "r", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "run_models_save_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "run_models_save_dir", ")", "\n", "\n", "", "run_features_destination_dir", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "'features'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "run_features_destination_dir", ")", ":", "\n", "                    ", "os", ".", "mkdir", "(", "run_features_destination_dir", ")", "\n", "\n", "", "top1_val_accuracies", "=", "[", "]", "\n", "topx_val_accuracies", "=", "[", "]", "\n", "previous_model", "=", "None", "\n", "\n", "run_starting_time", "=", "time", ".", "time", "(", ")", "\n", "batch_oracle_annotated_paths", "=", "{", "}", "\n", "undetected_classes", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "1", ",", "T", "+", "1", ")", ":", "\n", "                    ", "print", "(", "'*'", "*", "110", ")", "\n", "print", "(", "'*'", "*", "46", "+", "' Run {}/{} | BATCH {} '", ".", "format", "(", "r", ",", "num_runs", ",", "b", ")", "+", "'*'", "*", "45", ")", "\n", "print", "(", "'*'", "*", "110", "+", "'\\n'", ")", "\n", "\n", "if", "b", "==", "1", ":", "\n", "                        ", "model_load_path", "=", "first_model_load_path", "\n", "new_train_file_path", "=", "path_train_batch1", "\n", "val_file_path", "=", "path_val_batch1", "\n", "print", "(", "'Train data loaded from '", "+", "new_train_file_path", ")", "\n", "print", "(", "'Val data loaded from '", "+", "val_file_path", ")", "\n", "\n", "new_train_dataset", "=", "ImagesListFileFolder", "(", "\n", "new_train_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", "\n", ")", "\n", "\n", "model_dsets", "=", "[", "new_train_dataset", "]", "\n", "\n", "val_dataset", "=", "ImagesListFileFolder", "(", "\n", "val_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "val_dataset", ",", "batch_size", "=", "val_batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "old_classes_number", "=", "0", "\n", "new_classes_number", "=", "len", "(", "val_dataset", ".", "classes", ")", "\n", "print", "(", "\"Classes number = \"", "+", "str", "(", "new_classes_number", ")", ")", "\n", "print", "(", "\"Validation-set size = \"", "+", "str", "(", "len", "(", "val_dataset", ")", ")", ")", "\n", "\n", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "base", ")", "\n", "\n", "print", "(", "'\\nLoading model from '", "+", "model_load_path", ")", "\n", "state", "=", "torch", ".", "load", "(", "model_load_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model", ".", "load_state_dict", "(", "state", "[", "'state_dict'", "]", ")", "\n", "model", "=", "model", ".", "cuda", "(", "gpu", ")", "\n", "\n", "print", "(", "'\\n\\n********* VALIDATION ********* '", ")", "\n", "model", ".", "eval", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "topx", "=", "AverageMeter", "(", ")", "\n", "top", "=", "min", "(", "5", ",", "new_classes_number", ")", "\n", "N", ",", "n", "=", "get_dataset_N_n", "(", "model_dsets", ",", "model", ".", "fc", ".", "out_features", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.parse_record": [[117, 152], ["tensorflow.read_file", "tensorflow.image.decode_jpeg", "tensorflow.image.decode_jpeg", "vgg_preprocessing.preprocess_image", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.reduce_join", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.vgg_preprocessing.preprocess_image"], ["            ", "full_paths", "=", "np_paths", "\n", "full_features", "=", "np_features", "\n", "full_scores", "=", "np_scores", "\n", "", "else", ":", "\n", "            ", "full_paths", "=", "np", ".", "append", "(", "full_paths", ",", "np_paths", ")", "\n", "full_features", "=", "np", ".", "vstack", "(", "(", "full_features", ",", "np_features", ")", ")", "\n", "full_scores", "=", "np", ".", "vstack", "(", "(", "full_scores", ",", "np_scores", ")", ")", "\n", "\n", "", "", "probas_path", "=", "os", ".", "path", ".", "join", "(", "run_data_output_dir", ",", "str", "(", "batch_number", ")", "+", "'_proba.pkl'", ")", "\n", "with", "open", "(", "probas_path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "cPickle", ".", "dump", "(", "full_scores", ",", "f", ")", "\n", "\n", "", "print", "(", "\"\"", ")", "\n", "\n", "# Features normalization", "\n", "full_features", "=", "min_max", "(", "full_features", ")", "\n", "\n", "dist_matrix", "=", "None", "\n", "if", "(", "'kcenters'", "in", "classical_AF", "and", "sess", "==", "0", ")", "or", "'kcenters'", "in", "balancing_AF", ":", "dist_matrix", "=", "create_dist_matrix", "(", "full_features", ")", "\n", "\n", "# Available indexes for oracle", "\n", "# todo: modify entropy code to allow working on avail indexes", "\n", "avail_indexes", "=", "np", ".", "arange", "(", "full_features", ".", "shape", "[", "0", "]", ")", "\n", "\n", "print", "(", "'------> Manual annotation'", ")", "\n", "print", "(", "'images number -> '", "+", "str", "(", "len", "(", "full_paths", ")", ")", ")", "\n", "print", "(", "'budget of oracle -> '", "+", "str", "(", "budget", ")", ")", "\n", "print", "(", "''", ")", "\n", "\n", "oracle", "=", "oracle_annotation", "(", "budget", ",", "full_features", ",", "full_paths", ",", "dist_matrix", ",", "avail_indexes", ",", "full_classes", ",", "probas_path", ")", "\n", "\n", "if", "sess", "==", "0", ":", "\n", "# Annotation of budget by oracle + Balancing", "\n", "        ", "oracle", ".", "run", "(", "classical_AF", ")", "\n", "\n", "# Data annotated manually by the oracle", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.input_fn": [[154, 180], ["tensorflow.data.Dataset.from_tensor_slices", "len", "resnet.process_record_dataset", "dataset.shuffle.shuffle"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.process_record_dataset"], ["annotated_classes", "=", "oracle", ".", "annotated_classes", "\n", "annotated_paths", "=", "oracle", ".", "annotated_paths", "\n", "annotated_features", "=", "oracle", ".", "annotated_features", "\n", "\n", "", "else", ":", "\n", "\n", "        ", "if", "balancing_AF", "==", "'poor'", ":", "\n", "            ", "annotated_classes", ",", "annotated_paths", ",", "annotated_features", "=", "poor", "(", "\n", "full_features", ",", "full_classes", ",", "\n", "full_paths", ",", "budget", ",", "\n", "new_data_file_fpath", ",", "\n", "new_data_feat_file_fpath", ")", "\n", "\n", "\n", "", "elif", "balancing_AF", "==", "'bcore'", ":", "\n", "            ", "annotated_classes", ",", "annotated_paths", ",", "annotated_features", "=", "bcore", "(", "dist_matrix", ",", "full_features", ",", "full_classes", ",", "\n", "full_paths", ",", "budget", ",", "\n", "new_data_file_fpath", ",", "\n", "new_data_feat_file_fpath", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "'invalid balancing type'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "", "", "classes", "=", "list", "(", "set", "(", "annotated_classes", ")", ")", "\n", "print", "(", "'Classes detected by the oracle = '", "+", "str", "(", "sorted", "(", "classes", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main._get_block_sizes": [[319, 340], ["ValueError", "choices.keys"], "function", ["None"], ["inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", "gpu", ")", ",", "labels", ".", "cuda", "(", "gpu", ")", "\n", "scores", "=", "model", "(", "Variable", "(", "inputs", ")", ")", "\n", "\n", "if", "apply_th_train", "or", "apply_th_val_al", ":", "\n", "                                ", "scores", "=", "th_calibration", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "1", ")", ",", "N", ",", "n", ")", "\n", "\n", "", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "scores", ".", "data", ",", "labels", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "topx", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "# -------------------------------------------", "\n", "", "print", "(", "'BATCH 1 | Val : acc@1 = {:.2f}% ; acc@{} = {:.2f}%'", ".", "format", "(", "top1", ".", "avg", ",", "top", ",", "topx", ".", "avg", ")", ")", "\n", "top1_val_accuracies", ".", "append", "(", "top1", ".", "avg", ")", "\n", "topx_val_accuracies", ".", "append", "(", "topx", ".", "avg", ")", "\n", "\n", "oracle_annotated_paths", "=", "open", "(", "new_train_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "batch_oracle_annotated_paths", "[", "b", "]", "=", "oracle_annotated_paths", "\n", "\n", "", "else", ":", "\n", "\n", "                        ", "batch_algo_name", "=", "algo_name", "+", "'_b'", "+", "str", "(", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.main.imagenet_model_fn": [[342, 374], ["resnet.resnet_model_fn", "resnet.learning_rate_with_decay", "resnet.learning_rate_with_decay"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_model_fn", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.learning_rate_with_decay", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.learning_rate_with_decay"], ["new_val_file_path", "=", "os", ".", "path", ".", "join", "(", "dataset_files_dir", ",", "'separated/val/batch'", "+", "str", "(", "b", ")", ")", "\n", "if", "b", "==", "2", ":", "\n", "                            ", "old_val_file_path", "=", "path_val_batch1", "\n", "", "else", ":", "\n", "                            ", "old_val_file_path", "=", "os", ".", "path", ".", "join", "(", "dataset_files_dir", ",", "'accumulated/val/batch'", "+", "str", "(", "b", "-", "1", ")", ")", "\n", "\n", "", "if", "mode", "==", "\"il\"", ":", "# supervised :", "\n", "                            ", "I", "=", "1", "\n", "new_train_file_path", "=", "os", ".", "path", ".", "join", "(", "train_files_dir", ",", "'batch'", "+", "str", "(", "b", ")", ")", "\n", "oracle_annotated_paths", "=", "open", "(", "new_train_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "batch_oracle_annotated_paths", "[", "b", "]", "=", "oracle_annotated_paths", "\n", "\n", "", "print", "(", "'Old train data loaded from '", "+", "old_train_file_path", ")", "\n", "print", "(", "'New val data loaded from '", "+", "new_val_file_path", ")", "\n", "print", "(", "'Old val data loaded from '", "+", "old_val_file_path", ")", "\n", "\n", "# Data loaders for training", "\n", "old_train_dataset", "=", "ImagesListFileFolder", "(", "\n", "old_train_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", ")", "\n", "\n", "old_val_dataset", "=", "ImagesListFileFolder", "(", "\n", "old_val_file_path", ",", "\n", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", ",", "return_path", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_imagenet.load_data": [[30, 49], ["open", "enumerate", "line.strip().split", "data.append", "label.append", "line.strip", "int"], "function", ["None"], ["", "def", "load_data", "(", "fpath", ",", "order", ")", ":", "\n", "    ", "lines", "=", "open", "(", "fpath", ")", "\n", "data", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "\n", "\n", "for", "line", "in", "lines", ":", "\n", "      ", "arr", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "data", ".", "append", "(", "arr", "[", "0", "]", ")", "\n", "label", ".", "append", "(", "arr", "[", "1", "]", ")", "\n", "\n", "# labels = np.asarray(d[label_key], np.int8)", "\n", "## map to new labels", "\n", "", "mapping", "=", "{", "}", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "order", ")", ":", "\n", "      ", "mapping", "[", "j", "]", "=", "i", "\n", "", "labels", "=", "[", "mapping", "[", "int", "(", "label_", ")", "]", "for", "label_", "in", "label", "]", "\n", "\n", "return", "data", ",", "labels", "\n", "# return data, label", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_imagenet.prepare_validation": [[51, 92], ["range", "range", "numpy.asarray", "numpy.asarray", "range", "x_train_new.append", "y_train_new.append", "x_test_new.append", "y_test_new.append", "x_val_new.append", "y_val_new.append", "range", "numpy.random.shuffle", "x_train_new[].extend", "y_train_new[].extend", "x_val_new[].extend", "y_val_new[].extend", "x_test_new[].extend", "y_test_new[].extend", "numpy.where", "y_train[].tolist", "y_train[].tolist", "numpy.where", "y_test[].tolist", "len", "len", "len", "len"], "function", ["None"], ["", "def", "prepare_validation", "(", "x_train", ",", "y_train", ",", "x_test", ",", "y_test", ",", "nb_groups", ",", "nb_cl", ",", "nb_val", ")", ":", "\n", "    ", "x_train_new", "=", "[", "]", "\n", "y_train_new", "=", "[", "]", "\n", "x_val_new", "=", "[", "]", "\n", "y_val_new", "=", "[", "]", "\n", "x_test_new", "=", "[", "]", "\n", "y_test_new", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "nb_groups", ")", ":", "\n", "      ", "x_train_new", ".", "append", "(", "[", "]", ")", "\n", "y_train_new", ".", "append", "(", "[", "]", ")", "\n", "x_test_new", ".", "append", "(", "[", "]", ")", "\n", "y_test_new", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "nb_groups", "*", "nb_cl", ")", ":", "\n", "      ", "x_val_new", ".", "append", "(", "[", "]", ")", "\n", "y_val_new", ".", "append", "(", "[", "]", ")", "\n", "# get max val, the results for the first item", "\n", "", "y_train", "=", "np", ".", "asarray", "(", "y_train", ",", "np", ".", "int16", ")", "\n", "y_test", "=", "np", ".", "asarray", "(", "y_test", ",", "np", ".", "int16", ")", "\n", "for", "i", "in", "range", "(", "nb_groups", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "nb_cl", ")", ":", "\n", "        ", "tmp_ind", "=", "np", ".", "where", "(", "y_train", "==", "nb_cl", "*", "i", "+", "j", ")", "[", "0", "]", "\n", "# print (len(tmp_ind))", "\n", "np", ".", "random", ".", "shuffle", "(", "tmp_ind", ")", "\n", "# print (tmp_ind[0:len(tmp_ind)-nb_val])", "\n", "\n", "# print ([x_train[k] for k in tmp_ind[0:len(tmp_ind)-nb_val]] )", "\n", "x_train_new", "[", "i", "]", ".", "extend", "(", "[", "x_train", "[", "k", "]", "for", "k", "in", "tmp_ind", "[", "0", ":", "len", "(", "tmp_ind", ")", "-", "nb_val", "]", "]", ")", "\n", "y_train_new", "[", "i", "]", ".", "extend", "(", "y_train", "[", "tmp_ind", "[", "0", ":", "len", "(", "tmp_ind", ")", "-", "nb_val", "]", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "# x_val_new[i*nb_cl+j].extend(x_train[tmp_ind[len(tmp_ind)-nb_val:]])", "\n", "x_val_new", "[", "i", "*", "nb_cl", "+", "j", "]", ".", "extend", "(", "[", "x_train", "[", "k", "]", "for", "k", "in", "tmp_ind", "[", "len", "(", "tmp_ind", ")", "-", "nb_val", ":", "]", "]", ")", "\n", "y_val_new", "[", "i", "*", "nb_cl", "+", "j", "]", ".", "extend", "(", "y_train", "[", "tmp_ind", "[", "len", "(", "tmp_ind", ")", "-", "nb_val", ":", "]", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "tmp_ind", "=", "np", ".", "where", "(", "y_test", "==", "nb_cl", "*", "i", "+", "j", ")", "[", "0", "]", "\n", "# x_test_new[i].extend(x_test[tmp_ind])", "\n", "x_test_new", "[", "i", "]", ".", "extend", "(", "[", "x_test", "[", "k", "]", "for", "k", "in", "tmp_ind", "]", ")", "\n", "y_test_new", "[", "i", "]", ".", "extend", "(", "y_test", "[", "tmp_ind", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "return", "x_train_new", ",", "y_train_new", ",", "x_val_new", ",", "y_val_new", ",", "x_test_new", ",", "y_test_new", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.Model.__init__": [[292, 342], ["tensorflow.test.is_built_with_cuda"], "methods", ["None"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.Model.__call__": [[343, 393], ["resnet.conv2d_fixed_padding", "tensorflow.identity", "enumerate", "resnet.batch_norm_relu", "tensorflow.layers.average_pooling2d", "tensorflow.identity", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.identity", "tensorflow.transpose", "tensorflow.layers.max_pooling2d", "tensorflow.identity", "resnet.block_layer"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.ResnetArgParser.__init__": [[819, 857], ["argparse.ArgumentParser.__init__", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument", "resnet.ResnetArgParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.process_record_dataset": [[61, 107], ["dataset.shuffle.prefetch", "dataset.shuffle.repeat", "dataset.shuffle.map", "dataset.shuffle.batch", "dataset.shuffle.prefetch", "dataset.shuffle.shuffle", "parse_record_fn"], "function", ["None"], ["        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n", "", "", "class", "ResNet", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu": [[112, 122], ["tensorflow.layers.batch_normalization", "tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.relu"], ["for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.fixed_padding": [[124, 149], ["tensorflow.pad", "tensorflow.pad"], "function", ["None"], ["kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding": [[151, 163], ["tensorflow.layers.conv2d", "resnet.fixed_padding", "tensorflow.variance_scaling_initializer"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.fixed_padding"], ["return", "x", "\n", "\n", "", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.building_block": [[165, 202], ["resnet.batch_norm_relu", "resnet.conv2d_fixed_padding", "resnet.batch_norm_relu", "resnet.conv2d_fixed_padding", "resnet.block_layer.projection_shortcut"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n", "", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n", "\n", "", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n", "\n", "", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.bottleneck_block": [[204, 247], ["resnet.batch_norm_relu", "resnet.conv2d_fixed_padding", "resnet.batch_norm_relu", "resnet.conv2d_fixed_padding", "resnet.batch_norm_relu", "resnet.conv2d_fixed_padding", "resnet.block_layer.projection_shortcut"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.batch_norm_relu", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding"], ["\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.block_layer": [[249, 286], ["block_fn", "range", "tensorflow.identity", "resnet.conv2d_fixed_padding", "block_fn"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.conv2d_fixed_padding"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.learning_rate_with_decay": [[398, 431], ["int", "tensorflow.cast", "tensorflow.train.piecewise_constant"], "function", ["None"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_model_fn": [[433, 680], ["tensorflow.summary.image", "model_class", "model_class.", "print", "tensorflow.losses.softmax_cross_entropy", "tensorflow.identity", "tensorflow.summary.scalar", "tensorflow.metrics.accuracy", "tensorflow.identity", "tensorflow.summary.scalar", "tensorflow.estimator.EstimatorSpec", "tensorflow.estimator.EstimatorSpec", "print", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.argmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.losses.softmax_cross_entropy", "tensorflow.train.get_or_create_global_step", "resnet.learning_rate_with_decay.learning_rate_fn", "tensorflow.identity", "tensorflow.summary.scalar", "tensorflow.train.MomentumOptimizer", "tensorflow.get_collection", "tensorflow.argmax", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.metrics.mean", "tensorflow.losses.softmax_cross_entropy", "tensorflow.estimator.EstimatorSpec", "range", "range", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "print", "restore_model_dir.replace", "restore_model_dir.replace.replace", "print", "tensorflow.train.load_variable", "tensorflow.train.load_variable", "tensorflow.concat", "tensorflow.concat", "tensorflow.metrics.mean", "tensorflow.metrics.mean", "tensorflow.losses.softmax_cross_entropy", "tensorflow.estimator.EstimatorSpec", "print", "range", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "print", "range", "range", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.get_collection", "tensorflow.concat", "print", "tensorflow.nn.l2_loss", "tensorflow.train.init_from_checkpoint", "tensorflow.control_dependencies", "tensorflow.argmax", "tensorflow.nn.in_top_k", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.nn.in_top_k", "tensorflow.nn.in_top_k", "tensorflow.stack", "range", "range", "tensorflow.stack", "tensorflow.stack", "print", "restore_model_dir.replace", "print", "tensorflow.train.load_variable", "tensorflow.train.load_variable", "print", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable_scope", "tf.get_variable_scope.reuse_variables", "tensorflow.add_n", "tensorflow.train.init_from_checkpoint", "tensorflow.train.init_from_checkpoint", "tf.train.MomentumOptimizer.minimize", "tf.train.MomentumOptimizer.minimize", "str", "str", "tensorflow.add_n", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.nn.l2_loss", "resnet.resnet_model_fn.loss_filter_fn"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.utils_resnet.get_variable"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.resnet.resnet_main": [[682, 813], ["os.path.join", "len", "tensorflow.estimator.RunConfig().replace", "tensorflow.estimator.Estimator", "range", "str", "os.path.join", "os.path.join", "tensorflow.train.LoggingTensorHook", "print", "tf.estimator.Estimator.predict", "str", "str", "tensorflow.estimator.RunConfig", "input_function", "tf.estimator.Estimator.train", "print", "len", "print", "tensorflow.estimator.RunConfig().replace", "tensorflow.estimator.Estimator", "tf.estimator.Estimator.evaluate", "print", "tf.estimator.Estimator.evaluate", "print", "tf.estimator.Estimator.evaluate", "print", "tensorflow.train.load_variable", "tensorflow.train.load_variable", "print", "input_function", "list", "input_function", "tf.estimator.Estimator.train", "input_function", "input_function", "input_function", "tensorflow.estimator.RunConfig"], "function", ["None"], []], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.validation_no_memory.get_dataset_mean": [[17, 30], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "re.findall"], "function", ["None"], ["def", "get_dataset_mean", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "return", "dataset_mean", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.validation.get_dataset_mean": [[17, 30], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "re.findall"], "function", ["None"], ["def", "get_dataset_mean", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "return", "dataset_mean", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.no_mem_fr_train_val.accuracy": [[25, 39], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.no_mem_fr_train_val.get_dataset_mean_std": [[41, 55], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "float", "re.findall", "re.findall"], "function", ["None"], ["", "def", "get_dataset_mean_std", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "dataset_std", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "1", "]", ")", "]", "\n", "return", "dataset_mean", ",", "dataset_std", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.no_mem_fr_train_val.target_transform": [[56, 58], ["None"], "function", ["None"], ["", "def", "target_transform", "(", "target", ",", "P", ",", "b", ")", ":", "\n", "    ", "return", "target", "-", "(", "P", "*", "(", "b", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.ft_bal.accuracy": [[19, 33], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.ft_bal.get_dataset_mean_std": [[35, 49], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split", "open", "dataset_stat.split.split", "line.strip().split.strip", "float", "float", "re.findall", "re.findall"], "function", ["None"], ["", "def", "get_dataset_mean_std", "(", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "    ", "import", "re", "\n", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", "=", "line", "[", "0", "]", "\n", "dataset_stat", "=", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "            ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "dataset_std", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "1", "]", ")", "]", "\n", "return", "dataset_mean", ",", "dataset_std", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.ImagesListFileFolder.__init__": [[57, 83], ["open().readlines", "list", "e.strip.strip.strip", "int", "samples.append", "len", "RuntimeError", "set", "open", "e.strip.strip.split", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "print", "sys.exit", "e.strip.strip.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "images_list_file", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "return_path", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "return_path", "=", "return_path", "\n", "images_list_file", "=", "open", "(", "images_list_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "samples", "=", "[", "]", "\n", "for", "e", "in", "images_list_file", ":", "\n", "            ", "e", "=", "e", ".", "strip", "(", ")", "\n", "image_path", "=", "e", ".", "split", "(", ")", "[", "0", "]", "\n", "try", ":", "\n", "                ", "assert", "(", "os", ".", "path", ".", "exists", "(", "image_path", ")", ")", "\n", "", "except", "AssertionError", ":", "\n", "                ", "print", "(", "'Cant find '", "+", "image_path", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "", "image_class", "=", "int", "(", "e", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "samples", ".", "append", "(", "(", "image_path", ",", "image_class", ")", ")", "\n", "\n", "", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"No image found\"", ")", ")", "\n", "\n", "", "self", ".", "loader", "=", "default_loader", "\n", "self", ".", "extensions", "=", "IMG_EXTENSIONS", "\n", "self", ".", "classes", "=", "list", "(", "set", "(", "[", "e", "[", "1", "]", "for", "e", "in", "samples", "]", ")", ")", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "targets", "=", "[", "s", "[", "1", "]", "for", "s", "in", "samples", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.ImagesListFileFolder.__getitem__": [[85, 102], ["MyImageFolder.ImagesListFileFolder.loader", "MyImageFolder.ImagesListFileFolder.transform", "MyImageFolder.ImagesListFileFolder.target_transform"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.no_mem_fr_train_val.target_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "if", "self", ".", "return_path", ":", "\n", "            ", "return", "(", "sample", ",", "target", ")", ",", "self", ".", "samples", "[", "index", "]", "[", "0", "]", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.ImagesListFileFolder.__len__": [[103, 105], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.ImagesListFileFolder.__repr__": [[106, 115], ["MyImageFolder.ImagesListFileFolder.__len__", "MyImageFolder.ImagesListFileFolder.transform.__repr__().replace", "MyImageFolder.ImagesListFileFolder.target_transform.__repr__().replace", "MyImageFolder.ImagesListFileFolder.transform.__repr__", "MyImageFolder.ImagesListFileFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__len__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__repr__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__init__": [[162, 188], ["open().readlines", "list", "e.strip.strip.strip", "int", "samples.append", "len", "RuntimeError", "set", "open", "e.strip.strip.split", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "print", "sys.exit", "e.strip.strip.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "images_list_file", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "return_path", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "return_path", "=", "return_path", "\n", "images_list_file", "=", "open", "(", "images_list_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "samples", "=", "[", "]", "\n", "for", "e", "in", "images_list_file", ":", "\n", "            ", "e", "=", "e", ".", "strip", "(", ")", "\n", "image_path", "=", "e", ".", "split", "(", ")", "[", "0", "]", "\n", "try", ":", "\n", "                ", "assert", "(", "os", ".", "path", ".", "exists", "(", "image_path", ")", ")", "\n", "", "except", "AssertionError", ":", "\n", "                ", "print", "(", "'Cant find '", "+", "image_path", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "", "image_class", "=", "int", "(", "e", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "samples", ".", "append", "(", "(", "image_path", ",", "image_class", ")", ")", "\n", "\n", "", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"No image found\"", ")", ")", "\n", "\n", "", "self", ".", "loader", "=", "default_loader", "\n", "self", ".", "extensions", "=", "IMG_EXTENSIONS", "\n", "self", ".", "classes", "=", "list", "(", "set", "(", "[", "e", "[", "1", "]", "for", "e", "in", "samples", "]", ")", ")", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "targets", "=", "[", "s", "[", "1", "]", "for", "s", "in", "samples", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__getitem__": [[189, 206], ["MyImageFolder.IndexImagesListFileFolder.loader", "MyImageFolder.IndexImagesListFileFolder.transform", "MyImageFolder.IndexImagesListFileFolder.target_transform"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.codes.no_mem_fr_train_val.target_transform"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "if", "self", ".", "return_path", ":", "\n", "            ", "return", "index", ",", "self", ".", "samples", "[", "index", "]", "[", "0", "]", ",", "sample", ",", "target", "\n", "", "return", "index", ",", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__len__": [[207, 209], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__repr__": [[210, 219], ["MyImageFolder.IndexImagesListFileFolder.__len__", "MyImageFolder.IndexImagesListFileFolder.transform.__repr__().replace", "MyImageFolder.IndexImagesListFileFolder.target_transform.__repr__().replace", "MyImageFolder.IndexImagesListFileFolder.transform.__repr__", "MyImageFolder.IndexImagesListFileFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__len__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__repr__", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.IndexImagesListFileFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.has_file_allowed_extension": [[9, 19], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["def", "has_file_allowed_extension", "(", "filename", ",", "extensions", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an allowed extension.\n    Args:\n        filename (string): path to a file\n        extensions (iterable of strings): extensions to consider (lowercase)\n    Returns:\n        bool: True if the filename ends with one of given extensions\n    \"\"\"", "\n", "filename_lower", "=", "filename", ".", "lower", "(", ")", "\n", "return", "any", "(", "filename_lower", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "extensions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.is_image_file": [[21, 29], ["MyImageFolder.has_file_allowed_extension"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.has_file_allowed_extension"], ["", "def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an allowed image extension.\n    Args:\n        filename (string): path to a file\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"", "\n", "return", "has_file_allowed_extension", "(", "filename", ",", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.pil_loader": [[120, 125], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.default_loader": [[128, 134], ["get_image_backend", "accimage_loader", "MyImageFolder.pil_loader"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.MyImageFolder.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.Utils.DataUtils.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.Utils.DataUtils.accuracy": [[13, 27], ["max", "target.size", "output.topk", "pred.t.t.t", "pred.t.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "methods", ["None"], ["", "def", "accuracy", "(", "self", ",", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "        ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.Utils.DataUtils.get_dataset_mean_std": [[28, 40], ["open().readlines", "print", "sys.exit", "line.strip().split.strip().split.strip().split", "open", "dataset_stat.split.split.split", "line.strip().split.strip().split.strip", "float", "float", "re.findall", "re.findall"], "methods", ["None"], ["", "def", "get_dataset_mean_std", "(", "self", ",", "normalization_dataset_name", ",", "datasets_mean_std_file_path", ")", ":", "\n", "        ", "datasets_mean_std_file", "=", "open", "(", "datasets_mean_std_file_path", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "datasets_mean_std_file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ")", "\n", "dataset_name", ",", "dataset_stat", "=", "line", "[", "0", "]", ",", "line", "[", "1", "]", "\n", "if", "dataset_name", "==", "normalization_dataset_name", ":", "\n", "                ", "dataset_stat", "=", "dataset_stat", ".", "split", "(", "';'", ")", "\n", "dataset_mean", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "0", "]", ")", "]", "\n", "dataset_std", "=", "[", "float", "(", "e", ")", "for", "e", "in", "re", ".", "findall", "(", "r'\\d+\\.\\d+'", ",", "dataset_stat", "[", "1", "]", ")", "]", "\n", "return", "dataset_mean", ",", "dataset_std", "\n", "", "", "print", "(", "'Invalid normalization dataset name'", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.__init__": [[5, 7], ["AverageMeter.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.reset": [[8, 13], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update": [[14, 19], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.Utils.DataUtils.from_str_to_list": [[40, 51], ["string.split", "list.append", "int", "list.append", "p.strip", "float", "list.append", "p.strip", "str", "p.strip"], "methods", ["None"], ["\n", "", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.Utils.DataUtils.print_parameters": [[13, 16], ["cp.keys", "print", "str"], "methods", ["None"], ["", "def", "accuracy", "(", "self", ",", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "        ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval.train_eval": [[12, 66], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax"], ["def", "train_eval", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iteration", ",", "start_iteration", ",", "T", ",", "beta", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "#cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "#eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval.train_eval_lwf": [[69, 125], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "print", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax"], ["", "def", "train_eval_lwf", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iteration", ",", "start_iteration", ",", "T", ",", "beta", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "print", "(", "'old = '", "+", "str", "(", "num_old_classes", ")", ")", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "# print(outputs.shape)", "\n", "# print(targets.shape)", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "#cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "#eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval.train_eval_lwf2": [[128, 190], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "print", "tg_model.train", "enumerate", "tg_lr_scheduler.step", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "loss.cpu().data.numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_optimizer.step", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "loss.cpu", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax"], ["", "def", "train_eval_lwf2", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iter_size", ",", "iteration", ",", "start_iteration", ",", "T", ",", "beta", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "print", "(", "'old = '", "+", "str", "(", "num_old_classes", ")", ")", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "# tg_lr_scheduler.step()", "\n", "", "", "", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "# print(outputs.shape)", "\n", "# print(targets.shape)", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "#cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "\n", "", "loss", ".", "data", "/=", "iter_size", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "batch_idx", "+", "1", ")", "%", "iter_size", "==", "0", ":", "\n", "                ", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "tg_lr_scheduler", ".", "step", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "#eval", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval.train_eval_lwf3": [[194, 259], ["min", "range", "torch.device", "torch.device", "torch.device", "ref_model.eval", "print", "tg_model.train", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "tg_model.modules", "tg_lr_scheduler.step", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_lr_scheduler.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "str", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_optimizer.step", "loss.cpu().data.numpy", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "loss.cpu", "torch.KLDivLoss", "torch.log_softmax", "torch.softmax", "ref_model.detach"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax"], ["", "def", "train_eval_lwf3", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iter_size", ",", "iteration", ",", "start_iteration", ",", "T", ",", "beta", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "print", "(", "'old = '", "+", "str", "(", "num_old_classes", ")", ")", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "if", "iteration", "==", "start_iteration", ":", "\n", "            ", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "# print(outputs.shape)", "\n", "# print(targets.shape)", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "#cross entropy + distillation", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "F", ".", "log_softmax", "(", "outputs", "[", ":", ",", ":", "num_old_classes", "]", "/", "T", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "ref_outputs", ".", "detach", "(", ")", "/", "T", ",", "dim", "=", "1", ")", ")", "*", "T", "*", "T", "*", "beta", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "\n", "", "loss", ".", "data", "/=", "iter_size", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "(", "batch_idx", "+", "1", ")", "%", "iter_size", "==", "0", ":", "\n", "                ", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "", "", "if", "iteration", ">", "start_iteration", ":", "\n", "            ", "tg_lr_scheduler", ".", "step", "(", "loss", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "#eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "return", "tg_model", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MR_LF.get_ref_features": [[14, 17], ["None"], "function", ["None"], ["def", "get_ref_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "ref_features", "\n", "ref_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MR_LF.get_cur_features": [[18, 21], ["None"], "function", ["None"], ["", "def", "get_cur_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "cur_features", "\n", "cur_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MR_LF.get_old_scores_before_scale": [[22, 25], ["None"], "function", ["None"], ["", "def", "get_old_scores_before_scale", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "old_scores", "\n", "old_scores", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MR_LF.get_new_scores_before_scale": [[26, 29], ["None"], "function", ["None"], ["", "def", "get_new_scores_before_scale", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "new_scores", "\n", "new_scores", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MR_LF.train_eval_MR_LF": [[30, 118], ["min", "range", "torch.device", "torch.device", "ref_model.eval", "ref_model.fc.register_forward_hook", "tg_model.fc.register_forward_hook", "tg_model.fc.fc1.register_forward_hook", "tg_model.fc.fc2.register_forward_hook", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "print", "ref_model.fc.register_forward_hook.remove", "tg_model.fc.register_forward_hook.remove", "tg_model.fc.fc1.register_forward_hook.remove", "tg_model.fc.fc2.register_forward_hook.remove", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "torch.cat", "torch.cat", "torch.zeros().to", "torch.zeros().to", "gt_index.scatter().ge.scatter().ge", "torch.cat.masked_select", "targets.lt", "torch.nonzero().size", "torch.nonzero().size", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.cat.size", "tg_model.size", "outputs_bs[].topk", "gt_scores[].view().repeat", "torch.zeros().to", "torch.zeros().to", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.CosineEmbeddingLoss", "ref_features.detach", "torch.ones().to", "torch.ones().to", "torch.zeros", "torch.zeros", "gt_index.scatter().ge.scatter", "torch.nonzero", "torch.nonzero", "gt_scores[].view().repeat.size", "max_novel_scores.size", "gt_scores[].view().repeat.size", "torch.cat.size", "targets.view", "gt_scores[].view", "torch.MarginRankingLoss", "gt_scores[].view().repeat.view", "max_novel_scores.view", "torch.ones().to", "torch.ones().to", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update"], ["", "def", "train_eval_MR_LF", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iteration", ",", "start_iteration", ",", "lamda", ",", "dist", ",", "K", ",", "lw_mr", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "handle_ref_features", "=", "ref_model", ".", "fc", ".", "register_forward_hook", "(", "get_ref_features", ")", "\n", "handle_cur_features", "=", "tg_model", ".", "fc", ".", "register_forward_hook", "(", "get_cur_features", ")", "\n", "handle_old_scores_bs", "=", "tg_model", ".", "fc", ".", "fc1", ".", "register_forward_hook", "(", "get_old_scores_before_scale", ")", "\n", "handle_new_scores_bs", "=", "tg_model", ".", "fc", ".", "fc2", ".", "register_forward_hook", "(", "get_new_scores_before_scale", ")", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "CosineEmbeddingLoss", "(", ")", "(", "cur_features", ",", "ref_features", ".", "detach", "(", ")", ",", "torch", ".", "ones", "(", "inputs", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "device", ")", ")", "*", "lamda", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "#################################################", "\n", "#scores before scale, [-1, 1]", "\n", "outputs_bs", "=", "torch", ".", "cat", "(", "(", "old_scores", ",", "new_scores", ")", ",", "dim", "=", "1", ")", "\n", "assert", "(", "outputs_bs", ".", "size", "(", ")", "==", "outputs", ".", "size", "(", ")", ")", "\n", "#get groud truth scores", "\n", "gt_index", "=", "torch", ".", "zeros", "(", "outputs_bs", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "gt_index", "=", "gt_index", ".", "scatter", "(", "1", ",", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", ".", "ge", "(", "0.5", ")", "\n", "gt_scores", "=", "outputs_bs", ".", "masked_select", "(", "gt_index", ")", "\n", "#get top-K scores on novel classes", "\n", "max_novel_scores", "=", "outputs_bs", "[", ":", ",", "num_old_classes", ":", "]", ".", "topk", "(", "K", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "#the index of hard samples, i.e., samples of old classes", "\n", "hard_index", "=", "targets", ".", "lt", "(", "num_old_classes", ")", "\n", "hard_num", "=", "torch", ".", "nonzero", "(", "hard_index", ")", ".", "size", "(", "0", ")", "\n", "#print(\"hard examples size: \", hard_num)", "\n", "if", "hard_num", ">", "0", ":", "\n", "                    ", "gt_scores", "=", "gt_scores", "[", "hard_index", "]", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "K", ")", "\n", "max_novel_scores", "=", "max_novel_scores", "[", "hard_index", "]", "\n", "assert", "(", "gt_scores", ".", "size", "(", ")", "==", "max_novel_scores", ".", "size", "(", ")", ")", "\n", "assert", "(", "gt_scores", ".", "size", "(", "0", ")", "==", "hard_num", ")", "\n", "loss3", "=", "nn", ".", "MarginRankingLoss", "(", "margin", "=", "dist", ")", "(", "gt_scores", ".", "view", "(", "-", "1", ",", "1", ")", ",", "max_novel_scores", ".", "view", "(", "-", "1", ",", "1", ")", ",", "torch", ".", "ones", "(", "hard_num", "*", "K", ")", ".", "to", "(", "device", ")", ")", "*", "lw_mr", "\n", "", "else", ":", "\n", "                    ", "loss3", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "#################################################", "\n", "", "loss", "=", "loss1", "+", "loss2", "+", "loss3", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "print", "(", "\"Removing register_forward_hook\"", ")", "\n", "handle_ref_features", ".", "remove", "(", ")", "\n", "handle_cur_features", ".", "remove", "(", ")", "\n", "handle_old_scores_bs", ".", "remove", "(", ")", "\n", "handle_new_scores_bs", ".", "remove", "(", ")", "\n", "", "return", "tg_model", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_LF.get_ref_features": [[13, 16], ["None"], "function", ["None"], ["def", "get_ref_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "ref_features", "\n", "ref_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_LF.get_cur_features": [[17, 20], ["None"], "function", ["None"], ["", "def", "get_cur_features", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "cur_features", "\n", "cur_features", "=", "inputs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_LF.train_eval_LF": [[21, 80], ["min", "range", "torch.device", "torch.device", "ref_model.eval", "ref_model.fc.register_forward_hook", "tg_model.fc.register_forward_hook", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "print", "ref_model.fc.register_forward_hook.remove", "tg_model.fc.register_forward_hook.remove", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.CosineEmbeddingLoss", "ref_features.detach", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update"], ["", "def", "train_eval_LF", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iteration", ",", "start_iteration", ",", "lamda", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "\n", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "handle_ref_features", "=", "ref_model", ".", "fc", ".", "register_forward_hook", "(", "get_ref_features", ")", "\n", "handle_cur_features", "=", "tg_model", ".", "fc", ".", "register_forward_hook", "(", "get_cur_features", ")", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "loss1", "=", "nn", ".", "CosineEmbeddingLoss", "(", ")", "(", "cur_features", ",", "ref_features", ".", "detach", "(", ")", ",", "torch", ".", "ones", "(", "inputs", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "device", ")", ")", "*", "lamda", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "print", "(", "\"Removing register_forward_hook\"", ")", "\n", "handle_ref_features", ".", "remove", "(", ")", "\n", "handle_cur_features", ".", "remove", "(", ")", "\n", "", "return", "tg_model", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.compute_features.compute_features": [[7, 21], ["tg_feature_model.eval", "numpy.zeros", "torch.device", "torch.no_grad", "inputs.to.to", "numpy.squeeze", "torch.cuda.is_available", "tg_feature_model().cpu", "tg_feature_model"], "function", ["None"], ["def", "compute_features", "(", "tg_feature_model", ",", "evalloader", ",", "num_samples", ",", "num_features", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "tg_feature_model", ".", "eval", "(", ")", "\n", "\n", "features", "=", "np", ".", "zeros", "(", "[", "num_samples", ",", "num_features", "]", ")", "\n", "start_idx", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "inputs", ",", "targets", "in", "evalloader", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", ")", "\n", "features", "[", "start_idx", ":", "start_idx", "+", "inputs", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "np", ".", "squeeze", "(", "tg_feature_model", "(", "inputs", ")", ".", "cpu", "(", ")", ")", "\n", "start_idx", "=", "start_idx", "+", "inputs", ".", "shape", "[", "0", "]", "\n", "", "", "assert", "(", "start_idx", "==", "num_samples", ")", "\n", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MS.get_old_scores_before_scale": [[10, 13], ["None"], "function", ["None"], ["def", "get_old_scores_before_scale", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "old_scores", "\n", "old_scores", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MS.get_new_scores_before_scale": [[14, 17], ["None"], "function", ["None"], ["", "def", "get_new_scores_before_scale", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "    ", "global", "new_scores", "\n", "new_scores", "=", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.train_eval_MS.train_eval_MS": [[18, 80], ["min", "range", "torch.device", "torch.device", "ref_model.eval", "tg_model.fc.fc1.register_forward_hook", "tg_model.fc.fc2.register_forward_hook", "tg_model.train", "tg_lr_scheduler.step", "enumerate", "AverageMeter", "AverageMeter", "tg_model.eval", "print", "print", "tg_model.fc.fc1.register_forward_hook.remove", "tg_model.fc.fc2.register_forward_hook.remove", "tg_model.modules", "tg_optimizer.zero_grad", "tg_model", "loss.backward", "tg_optimizer.step", "torch.no_grad", "torch.no_grad", "enumerate", "torch.cuda.is_available", "torch.cuda.is_available", "isinstance", "inputs.to", "targets.to", "ref_model", "tg_model", "utils.accuracy", "AverageMeter.update", "AverageMeter.update", "len", "m.eval", "torch.CrossEntropyLoss", "ref_model.detach", "ref_model.fc.sigma.detach", "torch.CrossEntropyLoss", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "torch.MSELoss", "ref_scores.detach"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update"], ["", "def", "train_eval_MS", "(", "epochs", ",", "tg_model", ",", "ref_model", ",", "tg_optimizer", ",", "tg_lr_scheduler", ",", "trainloader", ",", "testloader", ",", "iteration", ",", "start_iteration", ",", "lw_ms", ",", "fix_bn", "=", "False", ",", "weight_per_class", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "", "top", "=", "min", "(", "5", ",", "tg_model", ".", "fc", ".", "out_features", ")", "\n", "\n", "\n", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "ref_model", ".", "eval", "(", ")", "\n", "num_old_classes", "=", "ref_model", ".", "fc", ".", "out_features", "\n", "handle_old_scores_bs", "=", "tg_model", ".", "fc", ".", "fc1", ".", "register_forward_hook", "(", "get_old_scores_before_scale", ")", "\n", "handle_new_scores_bs", "=", "tg_model", ".", "fc", ".", "fc2", ".", "register_forward_hook", "(", "get_new_scores_before_scale", ")", "\n", "", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "#train", "\n", "        ", "tg_model", ".", "train", "(", ")", "\n", "if", "fix_bn", ":", "\n", "            ", "for", "m", "in", "tg_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "", "tg_lr_scheduler", ".", "step", "(", ")", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "trainloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "tg_optimizer", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "if", "iteration", "==", "start_iteration", ":", "\n", "                ", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "", "else", ":", "\n", "                ", "ref_outputs", "=", "ref_model", "(", "inputs", ")", "\n", "ref_scores", "=", "ref_outputs", ".", "detach", "(", ")", "/", "ref_model", ".", "fc", ".", "sigma", ".", "detach", "(", ")", "\n", "loss1", "=", "nn", ".", "MSELoss", "(", ")", "(", "old_scores", ",", "ref_scores", ".", "detach", "(", ")", ")", "*", "lw_ms", "*", "num_old_classes", "\n", "loss2", "=", "nn", ".", "CrossEntropyLoss", "(", "weight_per_class", ")", "(", "outputs", ",", "targets", ")", "\n", "loss", "=", "loss1", "+", "loss2", "\n", "", "loss", ".", "backward", "(", ")", "\n", "tg_optimizer", ".", "step", "(", ")", "\n", "\n", "# eval", "\n", "", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "tg_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "testloader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "top", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "print", "(", "'{:03}/{:03} | Test ({}) |  acc@1 = {:.2f} | acc@{} = {:.2f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "epochs", ",", "len", "(", "testloader", ")", ",", "top1", ".", "avg", ",", "top", ",", "top5", ".", "avg", ")", ")", "\n", "\n", "\n", "", "if", "iteration", ">", "start_iteration", ":", "\n", "        ", "print", "(", "\"Removing register_forward_hook\"", ")", "\n", "handle_old_scores_bs", ".", "remove", "(", ")", "\n", "handle_new_scores_bs", ".", "remove", "(", ")", "\n", "", "return", "tg_model", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.compute_accuracy.compute_accuracy": [[14, 88], ["tg_model.eval", "tg_feature_model.eval", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "torch.device", "torch.device", "torch.no_grad", "torch.no_grad", "enumerate", "print", "print", "print", "targets.size", "tg_model", "torch.softmax", "F.softmax.max", "predicted.eq().sum().item", "utils.accuracy", "AverageMeter.AverageMeter.update", "AverageMeter.AverageMeter.update", "numpy.squeeze", "scipy.spatial.distance.cdist", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to.max", "predicted_icarl.eq().sum().item", "utils.accuracy", "AverageMeter.AverageMeter.update", "AverageMeter.AverageMeter.update", "scipy.spatial.distance.cdist", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to.max", "predicted_ncm.eq().sum().item", "utils.accuracy", "AverageMeter.AverageMeter.update", "AverageMeter.AverageMeter.update", "torch.cuda.is_available", "torch.cuda.is_available", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "tg_feature_model", "np.squeeze.cpu", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "np.squeeze.cpu", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "scale.repeat().type().to", "predicted.eq().sum", "torch.from_numpy", "torch.from_numpy", "predicted_icarl.eq().sum", "torch.from_numpy", "torch.from_numpy", "predicted_ncm.eq().sum", "min", "min", "min", "scale.repeat().type", "predicted.eq", "predicted_icarl.eq", "predicted_ncm.eq", "scale.repeat"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update"], ["def", "compute_accuracy", "(", "tg_model", ",", "tg_feature_model", ",", "class_means", ",", "evalloader", ",", "scale", "=", "None", ",", "print_info", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "tg_model", ".", "eval", "(", ")", "\n", "tg_feature_model", ".", "eval", "(", ")", "\n", "\n", "num_classes", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "\n", "correct", "=", "0", "\n", "correct_icarl", "=", "0", "\n", "correct_ncm", "=", "0", "\n", "\n", "top1_correct", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top5_correct", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top1_correct_icarl", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top5_correct_icarl", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top1_correct_ncm", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top5_correct_ncm", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "\n", "\n", "total", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "evalloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "                ", "assert", "(", "scale", ".", "shape", "[", "0", "]", "==", "1", ")", "\n", "assert", "(", "outputs", ".", "shape", "[", "1", "]", "==", "scale", ".", "shape", "[", "1", "]", ")", "\n", "outputs", "=", "outputs", "/", "scale", ".", "repeat", "(", "outputs", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "to", "(", "device", ")", "\n", "", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "\n", "outputs_feature", "=", "np", ".", "squeeze", "(", "tg_feature_model", "(", "inputs", ")", ")", "\n", "\n", "sqd_icarl", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "0", "]", ".", "T", ",", "outputs_feature", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "score_icarl", "=", "torch", ".", "from_numpy", "(", "(", "-", "sqd_icarl", ")", ".", "T", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "predicted_icarl", "=", "score_icarl", ".", "max", "(", "1", ")", "\n", "correct_icarl", "+=", "predicted_icarl", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "score_icarl", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct_icarl", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct_icarl", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "\n", "# Compute score for NCM", "\n", "sqd_ncm", "=", "cdist", "(", "class_means", "[", ":", ",", ":", ",", "1", "]", ".", "T", ",", "outputs_feature", ".", "cpu", "(", ")", ",", "'sqeuclidean'", ")", "\n", "score_ncm", "=", "torch", ".", "from_numpy", "(", "(", "-", "sqd_ncm", ")", ".", "T", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "predicted_ncm", "=", "score_ncm", ".", "max", "(", "1", ")", "\n", "correct_ncm", "+=", "predicted_ncm", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "score_ncm", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct_ncm", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct_ncm", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "\n", "", "", "if", "print_info", ":", "\n", "        ", "print", "(", "\"LUCIR-CNN  | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", ")", ")", "\n", "print", "(", "\"LUCIR-NCM  | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct_ncm", ".", "avg", ",", "top5_correct_ncm", ".", "avg", ")", ")", "\n", "print", "(", "\"iCaRL      | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct_icarl", ".", "avg", ",", "top5_correct_icarl", ".", "avg", ")", ")", "\n", "\n", "\n", "", "top1_cnn_acc", ",", "top5_cnn_acc", "=", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", "\n", "top1_icarl_acc", ",", "top5_icarl_acc", "=", "top1_correct_icarl", ".", "avg", ",", "top5_correct_icarl", ".", "avg", "\n", "top1_ncm_acc", ",", "top5_ncm_acc", "=", "top1_correct_ncm", ".", "avg", ",", "top5_correct_ncm", ".", "avg", "\n", "\n", "return", "[", "top1_cnn_acc", ",", "top5_cnn_acc", ",", "top1_icarl_acc", ",", "top5_icarl_acc", ",", "top1_ncm_acc", ",", "top5_ncm_acc", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils_incremental.compute_accuracy.compute_accuracy_lwf": [[91, 131], ["tg_model.eval", "tg_feature_model.eval", "AverageMeter.AverageMeter", "AverageMeter.AverageMeter", "torch.device", "torch.device", "torch.no_grad", "torch.no_grad", "enumerate", "print", "targets.size", "tg_model", "torch.softmax", "F.softmax.max", "predicted.eq().sum().item", "utils.accuracy", "AverageMeter.AverageMeter.update", "AverageMeter.AverageMeter.update", "torch.cuda.is_available", "torch.cuda.is_available", "inputs.to", "targets.to", "prec1.item", "inputs.size", "prec5.item", "inputs.size", "scale.repeat().type().to", "predicted.eq().sum", "min", "scale.repeat().type", "predicted.eq", "scale.repeat"], "function", ["home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update", "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.utils.AverageMeter.AverageMeter.update"], ["", "def", "compute_accuracy_lwf", "(", "tg_model", ",", "tg_feature_model", ",", "evalloader", ",", "scale", "=", "None", ",", "print_info", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "device", "is", "None", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "tg_model", ".", "eval", "(", ")", "\n", "tg_feature_model", ".", "eval", "(", ")", "\n", "\n", "num_classes", "=", "tg_model", ".", "fc", ".", "out_features", "\n", "\n", "correct", "=", "0", "\n", "\n", "top1_correct", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "top5_correct", "=", "AverageMeter", ".", "AverageMeter", "(", ")", "\n", "\n", "\n", "total", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "evalloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "outputs", "=", "tg_model", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "1", ")", "\n", "if", "scale", "is", "not", "None", ":", "\n", "                ", "assert", "(", "scale", ".", "shape", "[", "0", "]", "==", "1", ")", "\n", "assert", "(", "outputs", ".", "shape", "[", "1", "]", "==", "scale", ".", "shape", "[", "1", "]", ")", "\n", "outputs", "=", "outputs", "/", "scale", ".", "repeat", "(", "outputs", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "to", "(", "device", ")", "\n", "", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "utils", ".", "accuracy", "(", "outputs", ".", "data", ",", "targets", ",", "topk", "=", "(", "1", ",", "min", "(", "5", ",", "num_classes", ")", ")", ")", "\n", "top1_correct", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "top5_correct", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "inputs", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "", "if", "print_info", ":", "\n", "        ", "print", "(", "\"LUCIR-CNN  | acc@1 = {:.2f}%\\tacc@5 = {:.2f}%\"", ".", "format", "(", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", ")", ")", "\n", "\n", "\n", "", "top1_cnn_acc", ",", "top5_cnn_acc", "=", "top1_correct", ".", "avg", ",", "top5_correct", ".", "avg", "\n", "\n", "return", "[", "top1_cnn_acc", ",", "top5_cnn_acc", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem_herd.accuracy": [[29, 44], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "# batch_size = 1", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_nem.ift_nem.accuracy": [[31, 46], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "# batch_size = 1", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th_herd.softmax": [[36, 39], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.EdenBelouadah_class-incremental-learning.FT_th.ift_th.softmax": [[35, 38], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]]}