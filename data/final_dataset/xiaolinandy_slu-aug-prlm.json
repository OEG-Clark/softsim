{"home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.PretrainedBartModel._init_weights": [[100, 112], ["isinstance", "isinstance", "module.weight.data.normal_", "module.weight.data.normal_", "module.bias.data.zero_", "module.weight.data[].zero_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "std", "=", "self", ".", "config", ".", "init_std", "\n", "\n", "# called init_bert_params in fairseq", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.PretrainedBartModel.dummy_inputs": [[113, 132], ["torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "modeling_bart._prepare_bart_decoder_inputs", "torch.Tensor().long.ne", "torch.Tensor().long.ne", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs"], ["", "", "", "@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "pad_token", "=", "1", "\n", "input_ids", "=", "torch", ".", "Tensor", "(", "\n", "[", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "2", ",", "pad_token", "]", ",", "\n", "]", "\n", ")", ".", "long", "(", ")", "\n", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attn_mask", "=", "None", "\n", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"attention_mask\"", ":", "input_ids", ".", "ne", "(", "pad_token", ")", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "decoder_attn_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.EncoderLayer.__init__": [[183, 197], ["torch.nn.Module.__init__", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "self_attn", "=", "SelfAttention", "(", "\n", "self", ".", "embed_dim", ",", "config", ".", "encoder_attention_heads", ",", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "F", ".", "gelu", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "encoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "encoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.EncoderLayer.forward": [[198, 226], ["modeling_bart.EncoderLayer.self_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.self_attn_layer_norm", "modeling_bart.EncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.fc2", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.final_layer_norm", "modeling_bart.EncoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n            for t_tgt, t_src is excluded (or masked out), =0 means it is\n            included in attention\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", ",", "attn_weights", "=", "self", ".", "self_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "encoder_padding_mask", ",", "need_weights", "=", "self", ".", "output_attentions", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "return", "x", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartEncoder.__init__": [[237, 254], ["torch.nn.Module.__init__", "modeling_bart.LearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bart.LayerNorm", "modeling_bart.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "encoder_layerdrop", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_source_positions", "=", "config", ".", "max_position_embeddings", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "self", ".", "embed_positions", "=", "LearnedPositionalEmbedding", "(", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ",", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "EncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "encoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartEncoder.forward": [[255, 306], ["modeling_bart.BartEncoder.embed_tokens", "modeling_bart.BartEncoder.embed_positions", "modeling_bart.BartEncoder.layernorm_embedding", "torch.dropout", "torch.dropout", "x.transpose.transpose.transpose", "random.uniform", "encoder_states.append", "hidden_state.transpose", "encoder_states.append", "encoder_layer.forward", "all_attentions.append"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_ids (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            attention_mask (torch.LongTensor): indicating which indices are padding tokens.\n        Returns:\n            namedtuple:\n                - **x** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n\n                - **encoder_states** (List[Tensor]): all intermediate\n                  hidden states of shape `(src_len, batch, embed_dim)`.\n                  Only populated if *return_all_hiddens* is True.\n                - **all_attentions** (List[Tensor]): Attention weights for each layer.\n                During training might not be of length n_layers because of layer dropout.\n        \"\"\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_ids", ")", "\n", "x", "=", "inputs_embeds", "+", "embed_pos", "\n", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "encoder_states", ",", "all_attentions", "=", "[", "]", ",", "[", "]", "\n", "\n", "# encoder layers", "\n", "for", "encoder_layer", "in", "self", ".", "layers", ":", "\n", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "encoder_states", ".", "append", "(", "x", ")", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "# skip the layer", "\n", "                ", "attn", "=", "None", "\n", "", "else", ":", "\n", "                ", "x", ",", "attn", "=", "encoder_layer", ".", "forward", "(", "x", ",", "attention_mask", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "attn", ")", "\n", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "encoder_states", ".", "append", "(", "x", ")", "\n", "\n", "", "encoder_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "encoder_states", "]", "\n", "\n", "return", "x", ",", "encoder_states", ",", "all_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.DecoderLayer.__init__": [[309, 330], ["torch.nn.Module.__init__", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "self_attn", "=", "SelfAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "config", ".", "decoder_attention_heads", ",", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "F", ".", "gelu", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "encoder_attn", "=", "SelfAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "config", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "decoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "decoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.DecoderLayer.forward": [[331, 409], ["modeling_bart.DecoderLayer.self_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.self_attn_layer_norm", "modeling_bart.DecoderLayer.encoder_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.encoder_attn_layer_norm", "modeling_bart.DecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.fc2", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.final_layer_norm", "modeling_bart.DecoderLayer.fc1", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attn_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "need_attn_weights", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_attn_mask (ByteTensor, optional): binary\n                ByteTensor of shape `(batch, src_len)` where padding\n                elements are indicated by ``1``.\n            need_attn_weights (bool, optional): return attention weights\n                for each head (default: return average over heads).\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "if", "decoder_cached_states", "is", "None", ":", "\n", "            ", "prev_self_attn_state", ",", "prev_attn_state", "=", "(", "None", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "decoder_cached_states", ")", "==", "3", "\n", "prev_self_attn_state", ",", "prev_attn_state", "=", "(", "\n", "decoder_cached_states", "[", "\"self\"", "]", ",", "\n", "decoder_cached_states", "[", "\"encoder_decoder\"", "]", ",", "\n", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "prev_self_attn_state", "\n", "decoder_cached_states", "[", "\"self\"", "]", "=", "saved_state", "\n", "", "y", "=", "x", "# TODO(SS): figure out why fairseq did this, then hopefully delete it", "\n", "\n", "x", ",", "self_attn_weights", "=", "self", ".", "self_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "y", ",", "\n", "value", "=", "y", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "need_weights", "=", "need_attn_weights", ",", "\n", "attn_mask", "=", "attention_mask", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "residual", "=", "x", "\n", "assert", "self", ".", "encoder_attn", ".", "cache_key", "!=", "self", ".", "self_attn", ".", "cache_key", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "prev_attn_state", "\n", "decoder_cached_states", "[", "\"encoder_decoder\"", "]", "=", "saved_state", "\n", "", "x", ",", "encoder_attn_weights", "=", "self", ".", "encoder_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_hidden_states", ",", "# could be None", "\n", "value", "=", "encoder_hidden_states", ",", "\n", "key_padding_mask", "=", "encoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "need_attn_weights", ",", "# not returning it so why compute it", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "# change for enc-dec attention", "\n", "return", "(", "\n", "x", ",", "\n", "encoder_attn_weights", ",", "#self_attn_weights,", "\n", "decoder_cached_states", ",", "\n", ")", "# just self_attn weights for now, following t5, decoder_cached_states = cache for decoding", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.DecoderLayer._past_to_dict": [[411, 417], ["len"], "methods", ["None"], ["", "def", "_past_to_dict", "(", "self", ",", "prev_attn_state", ")", ":", "\n", "        ", "prev_key", ",", "prev_value", "=", "prev_attn_state", "[", ":", "2", "]", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "if", "len", "(", "prev_attn_state", ")", ">=", "3", ":", "\n", "            ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_attn_state", "[", "2", "]", "\n", "", "return", "saved_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartDecoder.__init__": [[428, 445], ["torch.nn.Module.__init__", "modeling_bart.LearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bart.LayerNorm", "modeling_bart.DecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ":", "nn", ".", "Embedding", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "decoder_layerdrop", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_positions", "=", "LearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "d_model", ",", "self", ".", "padding_idx", ",", "\n", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "DecoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "decoder_layers", ")", "]", "\n", ")", "# type: List[DecoderLayer]", "\n", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "config", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartDecoder.forward": [[446, 515], ["modeling_bart.BartDecoder.embed_positions", "modeling_bart.BartDecoder.embed_tokens", "modeling_bart.BartDecoder.layernorm_embedding", "torch.dropout", "torch.dropout", "x.transpose.transpose.transpose", "enumerate", "x.transpose.transpose.transpose", "random.uniform", "decoder_layer.forward", "hidden_state.transpose", "list", "next_decoder_cache.append"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_padding_mask", ",", "\n", "combined_mask", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Includes several features from \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            input_ids (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_hidden_states: output from the encoder, used for\n                encoder-side attention\n            encoder_padding_mask: for ignoring pad tokens\n            decoder_cached_states (dict or None): dictionary used for storing state during generation\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - hidden states\n                - attentions\n        \"\"\"", "\n", "# embed positions", "\n", "positions", "=", "self", ".", "embed_positions", "(", "input_ids", ")", "\n", "x", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "\n", "", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "# (seq_len, BS, model_dim)", "\n", "# decoder layers", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_self_attns", "=", "(", ")", "\n", "next_decoder_cache", "=", "[", "]", "\n", "\n", "for", "i", ",", "decoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "decoder_layer", "# type: DecoderLayer", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "\n", "                ", "continue", "\n", "", "layer_state", "=", "decoder_cached_states", "[", "i", "]", "if", "decoder_cached_states", "is", "not", "None", "else", "None", "\n", "x", ",", "layer_self_attn", ",", "layer_past", "=", "decoder_layer", ".", "forward", "(", "\n", "x", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_padding_mask", ",", "\n", "decoder_cached_states", "=", "layer_state", ",", "\n", "attention_mask", "=", "combined_mask", ",", "\n", "need_attn_weights", "=", "self", ".", "output_attentions", ",", "\n", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "next_decoder_cache", ".", "append", "(", "layer_past", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "+=", "(", "x", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_self_attns", "+=", "(", "layer_self_attn", ",", ")", "\n", "\n", "# Convert shapes from (seq_len, BS, model_dim) to (BS, seq_len, model_dim)", "\n", "", "", "all_hidden_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "all_hidden_states", "]", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", ",", "next_decoder_cache", ",", "all_hidden_states", ",", "list", "(", "all_self_attns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.SelfAttention.__init__": [[520, 552], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "# otherwise self_attention", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "# True for all BART", "\n", "\n", "assert", "self", ".", "encoder_decoder_attention", "or", "qkv_same_dim", ",", "(", "\n", "\"Self-attention requires query, key and \"", "\"value to be of the same size\"", "\n", ")", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "cache_key", "=", "\"encoder_decoder\"", "if", "self", ".", "encoder_decoder_attention", "else", "\"self\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.SelfAttention._shape": [[553, 555], ["tensor.contiguous().view().transpose", "tensor.contiguous().view", "tensor.contiguous"], "methods", ["None"], ["", "def", "_shape", "(", "self", ",", "tensor", ",", "dim_0", ",", "bsz", ")", ":", "\n", "        ", "return", "tensor", ".", "contiguous", "(", ")", ".", "view", "(", "dim_0", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.SelfAttention.forward": [[556, 654], ["query.size", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax.type_as", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_bart.SelfAttention.transpose().contiguous().view", "modeling_bart.SelfAttention.out_proj", "attn_weights.view.view.view", "list", "decoder_cached_states.get", "modeling_bart.SelfAttention.q_proj", "modeling_bart.SelfAttention.k_proj", "modeling_bart.SelfAttention.v_proj", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention._use_and_update_saved_state", "decoder_cached_states.get.update", "modeling_bart.SelfAttention.transpose", "attn_weights.view.view.size", "attn_weights.view.view.view", "attn_weights.view.view.view", "key_padding_mask.unsqueeze().unsqueeze().to", "attn_weights.view.view.masked_fill", "attn_weights.view.view.view", "modeling_bart.SelfAttention.size", "query.size", "modeling_bart.SelfAttention.k_proj", "modeling_bart.SelfAttention.v_proj", "attn_weights.view.view.view", "key_padding_mask.dim", "float", "modeling_bart.SelfAttention.transpose().contiguous", "modeling_bart.SelfAttention.view", "modeling_bart.SelfAttention.view", "key_padding_mask.size", "key_padding_mask.unsqueeze().unsqueeze", "modeling_bart.SelfAttention.transpose", "key_padding_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._use_and_update_saved_state"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "value", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "decoder_cached_states", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "False", ",", "\n", "static_kv", ":", "bool", "=", "False", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Time(SeqLen) x Batch x Channel\n\n        Args:\n\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n        \"\"\"", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "# get here for encoder decoder cause of static_kv", "\n", "if", "decoder_cached_states", "is", "not", "None", ":", "# get the last k,v and mask for reuse", "\n", "            ", "saved_state", "=", "decoder_cached_states", ".", "get", "(", "self", ".", "cache_key", ",", "{", "}", ")", "\n", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "q", "=", "self", ".", "q_proj", "(", "query", ")", "*", "self", ".", "scaling", "\n", "if", "self", ".", "encoder_decoder_attention", ":", "\n", "            ", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "\n", "", "q", "=", "self", ".", "_shape", "(", "q", ",", "tgt_len", ",", "bsz", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "self", ".", "_shape", "(", "k", ",", "-", "1", ",", "bsz", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "self", ".", "_shape", "(", "v", ",", "-", "1", ",", "bsz", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "            ", "k", ",", "v", ",", "key_padding_mask", ",", "new_state", "=", "self", ".", "_use_and_update_saved_state", "(", "\n", "k", ",", "v", ",", "saved_state", ",", "key_padding_mask", ",", "static_kv", ",", "bsz", "\n", ")", "\n", "saved_state", ".", "update", "(", "\n", "{", "\n", "\"prev_key\"", ":", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", ",", "\n", "\"prev_value\"", ":", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", ",", "\n", "\"prev_key_padding_mask\"", ":", "key_padding_mask", ",", "\n", "}", "\n", ")", "\n", "decoder_cached_states", "[", "self", ".", "cache_key", "]", "=", "saved_state", "# Update cache", "\n", "", "assert", "k", "is", "not", "None", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "assert", "attn_weights", ".", "size", "(", ")", "==", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "+", "attn_mask", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism not supporting Optional types.", "\n", "", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "", "assert", "key_padding_mask", "is", "None", "or", "key_padding_mask", ".", "size", "(", ")", "[", ":", "2", "]", "==", "(", "bsz", ",", "src_len", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "reshaped", "=", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "to", "(", "torch", ".", "bool", ")", "\n", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "reshaped", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "attn_weights_float", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights_float", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ",", ")", "\n", "assert", "v", "is", "not", "None", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "attn_output", ".", "size", "(", ")", "==", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn_output", "=", "self", ".", "out_proj", "(", "attn_output", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "return", "attn_output", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.SelfAttention._use_and_update_saved_state": [[655, 681], ["saved_state.get", "modeling_bart.SelfAttention._cat_prev_key_padding_mask", "_prev_key.view", "_prev_value.view", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._cat_prev_key_padding_mask"], ["", "def", "_use_and_update_saved_state", "(", "self", ",", "k", ",", "v", ",", "saved_state", ",", "key_padding_mask", ",", "static_kv", ",", "bsz", ")", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "        ", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "            ", "_prev_key", "=", "saved_state", "[", "\"prev_key\"", "]", "\n", "assert", "_prev_key", "is", "not", "None", "\n", "prev_key", "=", "_prev_key", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                ", "assert", "k", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "k", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "\"prev_value\"", "in", "saved_state", ":", "\n", "            ", "_prev_value", "=", "saved_state", "[", "\"prev_value\"", "]", "\n", "assert", "_prev_value", "is", "not", "None", "\n", "prev_value", "=", "_prev_value", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                ", "assert", "v", "is", "not", "None", "\n", "v", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "v", "]", ",", "dim", "=", "1", ")", "\n", "", "", "assert", "k", "is", "not", "None", "and", "v", "is", "not", "None", "\n", "prev_key_padding_mask", "=", "saved_state", ".", "get", "(", "\"prev_key_padding_mask\"", ",", "None", ")", "# type: Optional[Tensor]", "\n", "key_padding_mask", "=", "self", ".", "_cat_prev_key_padding_mask", "(", "\n", "key_padding_mask", ",", "prev_key_padding_mask", ",", "bsz", ",", "k", ".", "size", "(", "1", ")", ",", "static_kv", "\n", ")", "\n", "return", "k", ",", "v", ",", "key_padding_mask", ",", "saved_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.SelfAttention._cat_prev_key_padding_mask": [[682, 711], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "key_padding_mask.float", "filler.cuda.cuda.cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.size", "prev_key_padding_mask.float", "filler.cuda.cuda.float", "filler.cuda.cuda.cuda", "key_padding_mask.size", "filler.cuda.cuda.float", "key_padding_mask.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_cat_prev_key_padding_mask", "(", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "src_len", ":", "int", ",", "\n", "static_kv", ":", "bool", ",", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "# saved key padding masks have shape (bsz, seq_len)", "\n", "        ", "if", "prev_key_padding_mask", "is", "not", "None", "and", "static_kv", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", "and", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "# During incremental decoding, as the padding token enters and", "\n", "# leaves the frame, there will be a time when prev or current is None", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", ":", "\n", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "prev_key_padding_mask", ".", "size", "(", "1", ")", ")", "\n", "if", "prev_key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "filler", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "key_padding_mask", ".", "size", "(", "1", ")", ")", "\n", "if", "key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "filler", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "return", "new_key_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartClassificationHead.__init__": [[718, 725], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "input_dim", ",", "inner_dim", ",", "num_classes", ",", "pooler_dropout", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "input_dim", ",", "inner_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "pooler_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "inner_dim", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartClassificationHead.forward": [[726, 733], ["modeling_bart.BartClassificationHead.dropout", "modeling_bart.BartClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_bart.BartClassificationHead.dropout", "modeling_bart.BartClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.LearnedPositionalEmbedding.__init__": [[743, 751], ["torch.nn.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "int", ",", "\n", ")", ":", "\n", "# if padding_idx is specified then offset the embedding ids by", "\n", "# this index and adjust num_embeddings appropriately", "\n", "        ", "assert", "padding_idx", "is", "not", "None", "\n", "num_embeddings", "+=", "padding_idx", "+", "1", "# WHY?", "\n", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.LearnedPositionalEmbedding.forward": [[752, 756], ["modeling_utils.create_position_ids_from_input_ids", "super().forward"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "positions", "=", "create_position_ids_from_input_ids", "(", "input", ",", "self", ".", "padding_idx", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartModel.__init__": [[801, 813], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_bart.BartEncoder", "modeling_bart.BartDecoder", "modeling_bart.BartModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "padding_idx", ",", "vocab_size", "=", "config", ".", "pad_token_id", ",", "config", ".", "vocab_size", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "config", ".", "d_model", ",", "padding_idx", ")", "\n", "\n", "self", ".", "encoder", "=", "BartEncoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "self", ".", "decoder", "=", "BartDecoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartModel.forward": [[814, 855], ["file_utils.add_start_docstrings_to_callable", "modeling_bart._prepare_bart_decoder_inputs", "isinstance", "modeling_bart.BartModel.decoder.forward", "modeling_bart._filter_out_falsey_values", "isinstance", "modeling_bart._filter_out_falsey_values", "modeling_bart.BartModel.encoder.forward", "attention_mask.dim", "attention_mask.max", "attention_mask.long"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "# type: Tuple", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "assert", "attention_mask", ".", "dim", "(", ")", "==", "2", "\n", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ".", "long", "(", ")", ")", "*", "-", "10000.0", "\n", "assert", "attention_mask", ".", "max", "(", ")", "<=", "0", "\n", "\n", "# make masks if user doesn't supply", "\n", "", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "decoder_attn_mask", "=", "decoder_attention_mask", ",", "\n", ")", "\n", "\n", "\n", "assert", "decoder_input_ids", "is", "not", "None", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "# TODO(SS): make this caching more usable when overwrite generate", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "", "assert", "isinstance", "(", "encoder_outputs", ",", "tuple", ")", "\n", "# dec_features, decoder_cached_states, dec_hidden, dec_attn", "\n", "# test", "\n", "decoder_outputs", "=", "self", ".", "decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "# Attention and hidden_states will be [] or None if they aren't needed", "\n", "decoder_outputs", "=", "_filter_out_falsey_values", "(", "decoder_outputs", ")", "# type: tuple", "\n", "assert", "isinstance", "(", "decoder_outputs", "[", "0", "]", ",", "torch", ".", "Tensor", ")", "\n", "encoder_outputs", "=", "_filter_out_falsey_values", "(", "encoder_outputs", ")", "# type: tuple", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartModel.get_input_embeddings": [[856, 858], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartModel.set_input_embeddings": [[859, 861], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "shared", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartModel.get_output_embeddings": [[862, 864], ["modeling_bart._make_linear_from_emb"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._make_linear_from_emb"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "_make_linear_from_emb", "(", "self", ".", "shared", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM.__init__": [[872, 877], ["modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartModel", "modeling_bart._make_linear_from_emb", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._make_linear_from_emb"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model", "=", "BartModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "_make_linear_from_emb", "(", "self", ".", "model", ".", "shared", ")", "\n", "self", ".", "cls_layer", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "shared", ".", "weight", ".", "shape", "[", "1", "]", ",", "config", ".", "slot_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM.forward": [[879, 953], ["file_utils.add_start_docstrings_to_callable", "modeling_bart.BartForMaskedLM.model.forward", "modeling_bart.BartForMaskedLM.lm_head.forward", "modeling_bart.BartForMaskedLM.cls_layer.forward", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "torch.nn.CrossEntropyLoss.", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape", "slot_logits.contiguous.contiguous.contiguous", "torch.nn.CrossEntropyLoss.", "slot_logits.contiguous.contiguous.reshape", "slot_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "slot_labels", "=", "None", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        masked_lm_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the masked language modeling loss.\n            Indices should either be in ``[0, ..., config.vocab_size]`` or -100 (see ``input_ids`` docstring).\n            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens\n            with labels\n            in ``[0, ..., config.vocab_size]``.\n\n    Returns:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n        masked_lm_loss (`optional`, returned when ``masked_lm_labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n            Masked language modeling loss.\n        prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`)\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n            tokenizer = BartTokenizer.from_pretrained('bart-large')\n            model = BartForMaskedLM.from_pretrained('bart-large')\n            input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n            outputs = model(input_ids=input_ids, lm_labels=input_ids)\n            loss, prediction_scores = outputs[:2]\n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "slot_logits", "=", "self", ".", "cls_layer", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "outputs", "=", "(", "lm_logits", ",", "slot_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "#outputs = (lm_logits,) + outputs[1:]", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "#masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), lm_labels.view(-1))", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "#outputs = (masked_lm_loss,) + outputs", "\n", "\n", "if", "slot_labels", "is", "not", "None", ":", "\n", "                ", "slot_logits", "=", "slot_logits", ".", "contiguous", "(", ")", "\n", "slot_loss", "=", "loss_fct", "(", "slot_logits", ".", "reshape", "(", "-", "1", ",", "slot_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "slot_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", "slot_loss", ",", ")", "+", "outputs", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM.generate": [[954, 1168], ["isinstance", "isinstance", "modeling_bart.BartForMaskedLM.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "logger.warning", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_bart.BartForMaskedLM._generate_beam_search", "modeling_bart.BartForMaskedLM._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "isinstance", "next", "modeling_bart.BartForMaskedLM.parameters"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_beam_search", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_no_beam_search"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `True`.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictely positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            bos_token_id: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n\n            eos_token_ids: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n        Return:\n\n            output: `torch.LongTensor` of shape `(batch_size * num_return_sequences, sequence_length)`\n                sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id, do_sample=False)  # do greedy decoding\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, bos_token_id=tokenizer.bos_token_id, pad_token_id=tokenizer.pad_token_id, eos_token_ids=tokenizer.eos_token_id, num_return_sequences=3)  # 3 generate sequences using by sampling\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_ids", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "(", "isinstance", "(", "e", ",", "int", ")", "and", "e", ">=", "0", ")", "for", "e", "in", "eos_token_ids", ")", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "", "if", "pad_token_id", "is", "None", "and", "eos_token_ids", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_ids", "[", "0", "]", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM._generate_no_beam_search": [[1169, 1270], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "enumerate", "modeling_bart.BartForMaskedLM.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "modeling_bart.BartForMaskedLM._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max"], "methods", ["None"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#value, next_token_id = torch.topk(F.softmax(next_token_logits), 5, dim=-1)", "\n", "#print(value[0], next_token_id[0], value[1], next_token_id[1])", "\n", "#return input_ids[0], next_token_id[0], input_ids[1], next_token_id[1]", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "", "return", "decoded", ",", "decoded_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM._generate_beam_search": [[1271, 1484], ["input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "input_ids.contiguous().view.contiguous().view.new().fill_", "torch.cat.view", "torch.cat.view", "input_ids.contiguous().view.contiguous().view.new().fill_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.new.new.view", "range", "torch.cat.new", "torch.cat.new", "enumerate", "modeling_utils.BeamHypotheses", "modeling_bart.BartForMaskedLM.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "modeling_bart.BartForMaskedLM._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "len", "best.append", "torch.cat.new.min().item", "torch.cat.new.max().item", "min", "torch.cat.new().fill_", "torch.cat.new().fill_", "enumerate", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "input_ids.contiguous().view.contiguous().view.new", "input_ids.contiguous().view.contiguous().view.new", "range", "range", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.log_softmax", "torch.log_softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "next_words.view.view.view", "next_scores.view.view.view", "torch.log_softmax", "torch.log_softmax", "_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "tuple", "zip", "max", "set", "torch.softmax", "torch.softmax", "beam_scores[].expand_as", "torch.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reordered_past.append", "generated_hyps[].add", "torch.cat.new.min", "torch.cat.new.max", "torch.cat.new.max().item", "torch.cat.new", "torch.cat.new", "len", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "next", "decoder_input_ids[].tolist", "next_scores[].max().item", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "layer_past[].unsqueeze().clone().detach", "decoder_input_ids[].clone", "score.item", "modeling_bart.BartForMaskedLM.parameters", "word_id.item", "decoder_input_ids[].clone", "score.item", "torch.cat.new.max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "next_scores[].max", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["None"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "num_beams", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoder_input_ids", "=", "decoder_input_ids", ".", "view", "(", "batch_size", "*", "num_beams", ",", "1", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", "*", "num_beams", ",", "max_length", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "# outputs = self(**model_inputs)  # (batch_size * num_beams, cur_len, vocab_size)", "\n", "scores", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "scores", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample 2 next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", ")", "# (batch_size * num_beams, 2)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, 2)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, 2)", "\n", "# Match shape of greedy beam search", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_ids", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# add to generated hypotheses if end of sentence or last iteration", "\n", "if", "eos_token_ids", "is", "not", "None", "and", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", ":", "\n", "                        ", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted word if it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_idx", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "decoder_input_ids", "=", "decoder_input_ids", "[", "beam_idx", ",", ":", "]", "\n", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "=", "decoded_label", "[", "beam_idx", ",", ":", "]", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 2nd position", "\n", "                    ", "reordered_layer_past", "=", "[", "layer_past", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "1", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "# Add all open beam hypothesis to generated_hyps", "\n", "            ", "if", "not", "done", "[", "batch_idx", "]", ":", "\n", "                ", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "", "sent_lengths", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "best_hyp", "=", "max", "(", "hypotheses", ".", "beams", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "1", "]", "\n", "sent_lengths", "[", "i", "]", "=", "len", "(", "best_hyp", ")", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# shorter batches are filled with pad_token", "\n", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined\"", "\n", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ",", "sent_max_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypothesis and eos_token_id if necessary", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "                ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                    ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "", "", "", "else", ":", "\n", "# none of the hypotheses have an eos_token", "\n", "            ", "assert", "(", "len", "(", "hypo", ")", "==", "max_length", "for", "hypo", "in", "best", ")", "\n", "decoded", "=", "torch", ".", "stack", "(", "best", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "\n", "", "return", "decoded", ",", "decoded_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM.prepare_inputs_for_generation": [[1485, 1488], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"decoder_cached_states\"", ":", "past", ",", "\"decoder_input_ids\"", ":", "input_ids", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForMaskedLM.get_output_embeddings": [[1489, 1491], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForSequenceClassification.__init__": [[1500, 1508], ["modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartModel", "modeling_bart.BartClassificationHead", "modeling_bart.BartForSequenceClassification.model._init_weights", "modeling_bart.BartForSequenceClassification.model._init_weights"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel._init_weights", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel._init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "BartModel", "(", "config", ")", "\n", "self", ".", "classification_head", "=", "BartClassificationHead", "(", "\n", "config", ".", "d_model", ",", "config", ".", "d_model", ",", "config", ".", "num_labels", ",", "config", ".", "classif_dropout", ",", "\n", ")", "\n", "self", ".", "model", ".", "_init_weights", "(", "self", ".", "classification_head", ".", "dense", ")", "\n", "self", ".", "model", ".", "_init_weights", "(", "self", ".", "classification_head", ".", "out_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.BartForSequenceClassification.forward": [[1509, 1575], ["file_utils.add_start_docstrings_to_callable", "modeling_bart.BartForSequenceClassification.model.forward", "input_ids.eq", "modeling_bart.BartForSequenceClassification.classification_head", "len", "ValueError", "x[].view", "torch.cross_entropy", "torch.cross_entropy", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "x.size", "x.size", "modeling_bart.BartForSequenceClassification.view", "labels.view", "input_ids.eq.sum"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n\n    Returns:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BartConfig`) and inputs:\n            loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n                Classification  loss (cross entropy)\n            logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n                Classification (or regression if config.num_labels==1) scores (before SoftMax).\n            hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n                of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n                Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n            attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n                Attentions weights after the attention softmax, used to compute the weighted average in the\n                self-attention\n                heads.\n\n    Examples::\n\n        from transformers import BartTokenizer, BartForSequenceClassification\n        import torch\n\n        tokenizer = BartTokenizer.from_pretrained('bart-large')\n        model = BartForSequenceClassification.from_pretrained('bart-large')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\",\n        add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=labels)\n        loss, logits = outputs[:2]\n\n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", ")", "\n", "x", "=", "outputs", "[", "0", "]", "# last hidden state", "\n", "eos_mask", "=", "input_ids", ".", "eq", "(", "self", ".", "config", ".", "eos_token_id", ")", "\n", "if", "len", "(", "torch", ".", "unique", "(", "eos_mask", ".", "sum", "(", "1", ")", ")", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"All examples must have the same number of <eos> tokens.\"", ")", "\n", "", "sentence_representation", "=", "x", "[", "eos_mask", ",", ":", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "self", ".", "classification_head", "(", "sentence_representation", ")", "\n", "# Prepend logits", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "# prepend loss to output,", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart._prepare_bart_decoder_inputs": [[70, 93], ["_combine_masks.to", "modeling_bart.shift_tokens_right", "shift_tokens_right.size", "modeling_bart.make_padding_mask", "modeling_bart._combine_masks", "torch.triu", "torch.triu", "modeling_bart.fill_with_neg_inf", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.shift_tokens_right", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.make_padding_mask", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._combine_masks", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.fill_with_neg_inf"], ["def", "_prepare_bart_decoder_inputs", "(", "\n", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "None", ",", "decoder_attn_mask", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Prepare masks that ignore padding tokens  decoder and a causal lm mask for the decoder if\n    none are provided. This mimics the default behavior in fairseq. To override it pass in masks.\n    \"\"\"", "\n", "pad_token_id", "=", "config", ".", "pad_token_id", "\n", "need_causal_mask", "=", "not", "config", ".", "output_past", "\n", "if", "decoder_input_ids", "is", "None", ":", "\n", "        ", "decoder_input_ids", "=", "shift_tokens_right", "(", "input_ids", ",", "pad_token_id", ")", "\n", "", "bsz", ",", "tgt_len", "=", "decoder_input_ids", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "if", "decoder_attn_mask", "is", "None", ":", "\n", "        ", "decoder_padding_mask", "=", "make_padding_mask", "(", "decoder_input_ids", ",", "pad_token_id", ")", "\n", "if", "need_causal_mask", ":", "\n", "            ", "causal_lm_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "torch", ".", "zeros", "(", "tgt_len", ",", "tgt_len", ")", ")", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "causal_lm_mask", "=", "None", "\n", "", "new_shape", "=", "(", "bsz", ",", "tgt_len", ",", "tgt_len", ")", "\n", "# make it broadcastable so can just be added to the attention coefficients", "\n", "decoder_attn_mask", "=", "_combine_masks", "(", "decoder_padding_mask", ",", "causal_lm_mask", ",", "new_shape", ")", "\n", "", "decoder_attn_mask", "=", "decoder_attn_mask", ".", "to", "(", "device", "=", "input_ids", ".", "device", ")", "\n", "assert", "decoder_attn_mask", "is", "None", "or", "decoder_attn_mask", ".", "shape", "==", "(", "bsz", ",", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "return", "decoder_input_ids", ",", "decoder_attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart._make_linear_from_emb": [[134, 139], ["torch.nn.Linear"], "function", ["None"], ["", "", "def", "_make_linear_from_emb", "(", "emb", ")", ":", "\n", "    ", "vocab_size", ",", "emb_size", "=", "emb", ".", "weight", ".", "shape", "\n", "lin_layer", "=", "nn", ".", "Linear", "(", "vocab_size", ",", "emb_size", ",", "bias", "=", "False", ")", "\n", "lin_layer", ".", "weight", ".", "data", "=", "emb", ".", "weight", ".", "data", "# .T", "\n", "return", "lin_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart._check_shapes": [[142, 145], ["AssertionError"], "function", ["None"], ["", "def", "_check_shapes", "(", "shape_1", ",", "shape2", ")", ":", "\n", "    ", "if", "shape_1", "!=", "shape2", ":", "\n", "        ", "raise", "AssertionError", "(", "\"shape mismatch: {} != {}\"", ".", "format", "(", "shape_1", ",", "shape2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart._combine_masks": [[147, 160], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "modeling_bart._check_shapes", "key_padding_mask.unsqueeze().expand", "modeling_bart._check_shapes", "attn_mask.unsqueeze().expand", "key_padding_mask.unsqueeze", "attn_mask.unsqueeze"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._check_shapes", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._check_shapes"], ["", "", "def", "_combine_masks", "(", "key_padding_mask", ",", "attn_mask", ",", "targ_size", ")", ":", "\n", "# targ_size = (bsz, tgt_len, src_len)", "\n", "    ", "a", "=", "torch", ".", "zeros", "(", "targ_size", ")", "\n", "b", "=", "torch", ".", "zeros", "(", "targ_size", ")", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "# (bsz, tgt_len) -> targ_size", "\n", "        ", "_check_shapes", "(", "key_padding_mask", ".", "shape", ",", "targ_size", "[", ":", "2", "]", ")", "\n", "reshaped", "=", "key_padding_mask", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "*", "targ_size", ")", "\n", "a", "[", "reshaped", "]", "=", "1e-8", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "# (tgt_len, src_len) -> targ_size", "\n", "        ", "_check_shapes", "(", "attn_mask", ".", "shape", ",", "targ_size", "[", "-", "2", ":", "]", ")", "\n", "b", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "*", "targ_size", ")", "\n", "", "return", "(", "a", "+", "b", ")", ".", "unsqueeze", "(", "1", ")", ".", "clamp", "(", "LARGE_NEGATIVE", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.shift_tokens_right": [[162, 169], ["input_ids.clone", "input_ids.gather().squeeze", "input_ids.gather", "input_ids.ne().sum", "input_ids.ne"], "function", ["None"], ["", "def", "shift_tokens_right", "(", "input_ids", ",", "pad_token_id", ")", ":", "\n", "    ", "\"\"\"Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\"\"\"", "\n", "prev_output_tokens", "=", "input_ids", ".", "clone", "(", ")", "\n", "index_of_eos", "=", "(", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "prev_output_tokens", "[", ":", ",", "0", "]", "=", "input_ids", ".", "gather", "(", "1", ",", "index_of_eos", ")", ".", "squeeze", "(", ")", "\n", "prev_output_tokens", "[", ":", ",", "1", ":", "]", "=", "input_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "return", "prev_output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.make_padding_mask": [[171, 177], ["input_ids.eq", "input_ids.eq.any"], "function", ["None"], ["", "def", "make_padding_mask", "(", "input_ids", ",", "padding_idx", "=", "1", ")", ":", "\n", "    ", "\"\"\"True for pad tokens\"\"\"", "\n", "padding_mask", "=", "input_ids", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "padding_mask", ".", "any", "(", ")", ":", "\n", "        ", "padding_mask", "=", "None", "\n", "", "return", "padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.LayerNorm": [[758, 767], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "FusedLayerNorm"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["", "", "def", "LayerNorm", "(", "normalized_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "normalization", "import", "FusedLayerNorm", "\n", "\n", "return", "FusedLayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "torch", ".", "nn", ".", "LayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart.fill_with_neg_inf": [[769, 772], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a input_ids with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.modeling_bart._filter_out_falsey_values": [[774, 777], ["tuple", "isinstance"], "function", ["None"], ["", "def", "_filter_out_falsey_values", "(", "tup", ")", "->", "Tuple", ":", "\n", "    ", "\"\"\"Remove entries that are None or [] from an iterable.\"\"\"", "\n", "return", "tuple", "(", "x", "for", "x", "in", "tup", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "or", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.__init__": [[32, 46], ["torch.Module.__init__", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tagset_size", ")", ":", "\n", "        ", "super", "(", "CRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "print", "(", "\"build CRF...\"", ")", "\n", "# Matrix of transition parameters.  Entry i,j is the score of transitioning *from* i *to* j.", "\n", "self", ".", "tagset_size", "=", "tagset_size", "\n", "# # We add 2 here, because of START_TAG and STOP_TAG", "\n", "# # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag", "\n", "init_transitions", "=", "torch", ".", "zeros", "(", "self", ".", "tagset_size", "+", "2", ",", "self", ".", "tagset_size", "+", "2", ")", "\n", "init_transitions", "[", ":", ",", "START_TAG", "]", "=", "-", "10000.0", "\n", "init_transitions", "[", "STOP_TAG", ",", ":", "]", "=", "-", "10000.0", "\n", "#init_transitions[:,0] = -10000.0  ### 0 is <pad>", "\n", "#init_transitions[0,:] = -10000.0  ### 0 is <pad>", "\n", "#init_transitions = init_transitions.to(self.device)", "\n", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "init_transitions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device": [[47, 49], ["None"], "methods", ["None"], ["", "def", "set_device", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._calculate_alg": [[50, 96], ["feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view().expand", "scores.view.view.view", "enumerate", "enumerate.__next__", "inivalues[].clone().view", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "crf.CRF.transitions.view().expand", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "mask[].view().expand", "torch.logsumexp.masked_select", "torch.logsumexp.masked_select", "torch.logsumexp.masked_select", "mask_idx.contiguous().view.contiguous().view.contiguous().view", "inivalues[].clone().view.masked_scatter_", "crf.CRF.transitions.view().expand", "inivalues[].clone().view.contiguous().view().expand", "final_partition.sum", "mask.transpose().contiguous.transpose().contiguous.transpose", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view", "inivalues[].clone", "inivalues[].clone().view.contiguous().view().expand", "crf.CRF.transitions.view", "mask[].view", "mask_idx.contiguous().view.contiguous().view.contiguous", "crf.CRF.transitions.view", "inivalues[].clone().view.contiguous().view", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous", "inivalues[].clone().view.contiguous().view", "inivalues[].clone().view.contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose", "inivalues[].clone().view.contiguous"], "methods", ["None"], ["", "def", "_calculate_alg", "(", "self", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size+2)\n                masks: (batch, seq_len)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "assert", "(", "tag_size", "==", "self", ".", "tagset_size", "+", "2", ")", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "\n", "ins_num", "=", "seq_len", "*", "batch_size", "\n", "## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)", "\n", "feats", "=", "feats", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ins_num", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "## scores: x -> y_t  plus y_{t-1} -> y_t", "\n", "scores", "=", "feats", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "scores", "=", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "# build iter", "\n", "seq_iter", "=", "enumerate", "(", "scores", ")", "\n", "_", ",", "inivalues", "=", "seq_iter", ".", "__next__", "(", ")", "# bat_size * from_target_size * to_target_size", "\n", "# only need start from start_tag", "\n", "partition", "=", "inivalues", "[", ":", ",", "START_TAG", ",", ":", "]", ".", "clone", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "# bat_size * to_target_size", "\n", "\n", "## add start score (from start to all tag, duplicate to batch_size)", "\n", "for", "idx", ",", "cur_values", "in", "seq_iter", ":", "\n", "# cur_values: bat_size * from_target * to_target", "\n", "# (bat_size * from_target * to_target) -> (bat_size * to_target)", "\n", "            ", "cur_values", "=", "cur_values", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "cur_partition", "=", "torch", ".", "logsumexp", "(", "cur_values", ",", "1", ")", "# bat_size * to_target", "\n", "\n", "# partition = utils.switch(partition, cur_partition, mask[idx].view(bat_size, 1).expand(bat_size, self.tagset_size)).view(bat_size, -1)", "\n", "mask_idx", "=", "mask", "[", "idx", ",", ":", "]", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", "\n", "\n", "## effective updated partition part, only keep the partition value of mask value = 1", "\n", "masked_cur_partition", "=", "cur_partition", ".", "masked_select", "(", "mask_idx", ")", "\n", "## let mask_idx broadcastable, to disable warning", "\n", "mask_idx", "=", "mask_idx", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "\n", "\n", "## replace the partition where the maskvalue=1, other partition value keeps the same", "\n", "partition", ".", "masked_scatter_", "(", "mask_idx", ",", "masked_cur_partition", ")", "\n", "# until the last state, add transition score for all partition (and do log_sum_exp) then select the value in STOP_TAG", "\n", "", "cur_values", "=", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "cur_partition", "=", "torch", ".", "logsumexp", "(", "cur_values", ",", "1", ")", "\n", "final_partition", "=", "cur_partition", "[", ":", ",", "STOP_TAG", "]", "\n", "return", "final_partition", ".", "sum", "(", ")", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._viterbi_decode": [[98, 176], ["feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view().expand", "scores.view.view.view", "enumerate", "list", "list", "enumerate.__next__", "inivalues[].clone().view", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.gather().squeeze.contiguous().view().expand", "torch.gather().squeeze.contiguous().view().expand", "torch.gather().squeeze.contiguous().view().expand", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "back_points.transpose().contiguous.transpose().contiguous.scatter_", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "decode_idx.transpose.transpose.transpose", "crf.CRF.transitions.view().expand", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "cur_bp.masked_fill_", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.gather().view.expand", "torch.gather().view.expand", "torch.gather().view.expand", "crf.CRF.transitions.view().expand", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze.detach().view", "torch.gather().squeeze.detach().view", "torch.gather().squeeze.detach().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "mask.transpose().contiguous.transpose().contiguous.transpose", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view", "inivalues[].clone", "inivalues[].clone().view.contiguous().view().expand", "mask[].view().expand", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "back_points.transpose().contiguous.transpose().contiguous.transpose", "back_points.transpose().contiguous.transpose().contiguous.transpose", "len", "crf.CRF.transitions.view", "mask.transpose().contiguous.transpose().contiguous.long", "torch.sum().view().long.view", "torch.sum().view().long.view", "torch.sum().view().long.view", "crf.CRF.transitions.view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().squeeze.detach", "torch.gather().squeeze.detach", "torch.gather().squeeze.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous", "inivalues[].clone().view.contiguous().view", "mask[].view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose", "inivalues[].clone().view.contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous"], "methods", ["None"], ["", "def", "_viterbi_decode", "(", "self", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size+2)\n                mask: (batch, seq_len)\n            output:\n                decode_idx: (batch, seq_len) decoded sequence\n                path_score: (batch, 1) corresponding score for each sequence (to be implementated)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "assert", "(", "tag_size", "==", "self", ".", "tagset_size", "+", "2", ")", "\n", "## calculate sentence length for each sentence", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "## mask to (seq_len, batch_size)", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "ins_num", "=", "seq_len", "*", "batch_size", "\n", "## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)", "\n", "feats", "=", "feats", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ins_num", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "## need to consider start", "\n", "scores", "=", "feats", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "scores", "=", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "\n", "# build iter", "\n", "seq_iter", "=", "enumerate", "(", "scores", ")", "\n", "## record the position of best score", "\n", "back_points", "=", "list", "(", ")", "\n", "partition_history", "=", "list", "(", ")", "\n", "##  reverse mask (bug for mask = 1- mask, use this as alternative choice)", "\n", "# mask = 1 + (-1)*mask", "\n", "mask", "=", "(", "1", "-", "mask", ".", "long", "(", ")", ")", ".", "byte", "(", ")", "\n", "_", ",", "inivalues", "=", "seq_iter", ".", "__next__", "(", ")", "# bat_size * from_target_size * to_target_size", "\n", "# only need start from start_tag", "\n", "partition", "=", "inivalues", "[", ":", ",", "START_TAG", ",", ":", "]", ".", "clone", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ")", "# bat_size * to_target_size", "\n", "# print \"init part:\",partition.size()", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "# iter over last scores", "\n", "for", "idx", ",", "cur_values", "in", "seq_iter", ":", "\n", "# previous to_target is current from_target", "\n", "# partition: previous results log(exp(from_target)), #(batch_size * from_target)", "\n", "# cur_values: batch_size * from_target * to_target", "\n", "            ", "cur_values", "=", "cur_values", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "## forscores, cur_bp = torch.max(cur_values[:,:-2,:], 1) # do not consider START_TAG/STOP_TAG", "\n", "partition", ",", "cur_bp", "=", "torch", ".", "max", "(", "cur_values", ",", "1", ")", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "## cur_bp: (batch_size, tag_size) max source score position in current tag", "\n", "## set padded label as 0, which will be filtered in post processing", "\n", "cur_bp", ".", "masked_fill_", "(", "mask", "[", "idx", "]", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", ",", "0", ")", "\n", "back_points", ".", "append", "(", "cur_bp", ")", "\n", "### add score to final STOP_TAG", "\n", "", "partition_history", "=", "torch", ".", "cat", "(", "partition_history", ",", "0", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "## (batch_size, seq_len. tag_size)", "\n", "### get the last position for each setences, and select the last partitions using gather()", "\n", "last_position", "=", "length_mask", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "-", "1", "\n", "last_partition", "=", "torch", ".", "gather", "(", "partition_history", ",", "1", ",", "last_position", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "\n", "### calculate the score from last partition to end state (and then select the STOP_TAG from it)", "\n", "last_values", "=", "last_partition", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "_", ",", "last_bp", "=", "torch", ".", "max", "(", "last_values", ",", "1", ")", "\n", "pad_zero", "=", "torch", ".", "zeros", "(", "batch_size", ",", "tag_size", ")", ".", "to", "(", "self", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "back_points", ".", "append", "(", "pad_zero", ")", "\n", "back_points", "=", "torch", ".", "cat", "(", "back_points", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ")", "\n", "\n", "## select end ids in STOP_TAG", "\n", "pointer", "=", "last_bp", "[", ":", ",", "STOP_TAG", "]", "\n", "insert_last", "=", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values", "\n", "back_points", ".", "scatter_", "(", "1", ",", "last_position", ",", "insert_last", ")", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "## decode from the end, padded position ids are 0, which will be filtered if following evaluation", "\n", "decode_idx", "=", "torch", ".", "zeros", "(", "seq_len", ",", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "decode_idx", "[", "-", "1", "]", "=", "pointer", ".", "data", "\n", "for", "idx", "in", "range", "(", "len", "(", "back_points", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "pointer", "=", "torch", ".", "gather", "(", "back_points", "[", "idx", "]", ",", "1", ",", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "decode_idx", "[", "idx", "]", "=", "pointer", ".", "detach", "(", ")", ".", "view", "(", "batch_size", ")", "\n", "", "path_score", "=", "None", "\n", "decode_idx", "=", "decode_idx", ".", "transpose", "(", "1", ",", "0", ")", "\n", "return", "path_score", ",", "decode_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.forward": [[177, 180], ["crf.CRF._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._viterbi_decode"], ["", "def", "forward", "(", "self", ",", "feats", ")", ":", "\n", "        ", "path_score", ",", "best_path", "=", "self", ".", "_viterbi_decode", "(", "feats", ")", "\n", "return", "path_score", ",", "best_path", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._score_sentence": [[181, 230], ["scores.size", "scores.size", "scores.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "new_tags.transpose().contiguous().view.transpose().contiguous().view.to", "crf.CRF.transitions[].contiguous().view().expand", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "tg_energy.masked_select.masked_select.masked_select", "mask.transpose", "tg_energy.masked_select.masked_select.sum", "torch.gather.sum", "torch.gather.sum", "torch.gather.sum", "crf.CRF.transitions[].contiguous().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scores.view", "crf.CRF.transitions[].contiguous", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "new_tags.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["None"], ["", "def", "_score_sentence", "(", "self", ",", "scores", ",", "mask", ",", "tags", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                scores: variable (seq_len, batch, tag_size, tag_size)\n                mask: (batch, seq_len)\n                tags: tensor  (batch, seq_len)\n            output:\n                score: sum of score for gold sequences within whole batch\n        \"\"\"", "\n", "# Gives the score of a provided tag sequence", "\n", "batch_size", "=", "scores", ".", "size", "(", "1", ")", "\n", "seq_len", "=", "scores", ".", "size", "(", "0", ")", "\n", "tag_size", "=", "scores", ".", "size", "(", "2", ")", "\n", "## convert tag value into a new format, recorded label bigram information to index", "\n", "new_tags", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "idx", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "## from START_TAG to first label, use (tag_size - 2) since START_TAG = -2", "\n", "                ", "new_tags", "[", ":", ",", "0", "]", "=", "(", "tag_size", "-", "2", ")", "*", "tag_size", "+", "tags", "[", ":", ",", "0", "]", "\n", "\n", "", "else", ":", "\n", "                ", "new_tags", "[", ":", ",", "idx", "]", "=", "tags", "[", ":", ",", "idx", "-", "1", "]", "*", "tag_size", "+", "tags", "[", ":", ",", "idx", "]", "\n", "", "", "new_tags", "=", "new_tags", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "## transition for label to STOP_TAG", "\n", "end_transition", "=", "self", ".", "transitions", "[", ":", ",", "STOP_TAG", "]", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ")", "\n", "## length for batch,  last word position = length - 1", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "## index the label id of last word", "\n", "end_ids", "=", "torch", ".", "gather", "(", "tags", ",", "1", ",", "length_mask", "-", "1", ")", "\n", "\n", "## index the transition score for end_id to STOP_TAG", "\n", "end_energy", "=", "torch", ".", "gather", "(", "end_transition", ",", "1", ",", "end_ids", ")", "\n", "\n", "## convert tag as (seq_len, batch_size, 1)", "\n", "new_tags", "=", "new_tags", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "1", ")", "\n", "### need convert tags id to search from 400 positions of scores", "\n", "tg_energy", "=", "torch", ".", "gather", "(", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "-", "1", ")", ",", "2", ",", "new_tags", ")", ".", "view", "(", "seq_len", ",", "batch_size", ")", "# seq_len * bat_size", "\n", "## mask transpose to (seq_len, batch_size)", "\n", "tg_energy", "=", "tg_energy", ".", "masked_select", "(", "mask", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n", "## calculate the score from START_TAG to first label", "\n", "# #start_transition = self.transitions[START_TAG,:].view(1, tag_size).expand(batch_size, tag_size)", "\n", "# #start_energy = torch.gather(start_transition, 1, tags[0,:])", "\n", "\n", "## add all score together", "\n", "# #gold_score = start_energy.sum() + tg_energy.sum() + end_energy.sum()", "\n", "gold_score", "=", "tg_energy", ".", "sum", "(", ")", "+", "end_energy", ".", "sum", "(", ")", "\n", "return", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.neg_log_likelihood_loss": [[231, 237], ["crf.CRF._calculate_alg", "crf.CRF._score_sentence"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._calculate_alg", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._score_sentence"], ["", "def", "neg_log_likelihood_loss", "(", "self", ",", "feats", ",", "mask", ",", "tags", ")", ":", "\n", "# nonegative log likelihood", "\n", "# batch_size = feats.size(0)", "\n", "        ", "forward_score", ",", "scores", "=", "self", ".", "_calculate_alg", "(", "feats", ",", "mask", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "scores", ",", "mask", ",", "tags", ")", "\n", "return", "forward_score", "-", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._viterbi_decode_nbest": [[238, 385], ["feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.size", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view().expand", "scores.view.view.view", "enumerate", "list", "list", "enumerate.__next__", "inivalues[].clone", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.cat().view().transpose().contiguous", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "last_values.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "end_bp.transpose.transpose.transpose", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "pointer.contiguous().view().expand", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "back_points.transpose().contiguous.transpose().contiguous.scatter_", "back_points.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "decode_idx.transpose.transpose.transpose", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.softmax", "torch.softmax", "torch.softmax", "crf.CRF.transitions.view().expand", "partition.transpose.transpose.view().expand", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "partition.transpose.transpose.transpose", "cur_bp.transpose.transpose.transpose", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "torch.cat().view().transpose().contiguous.append", "cur_bp.transpose.transpose.masked_fill_", "back_points.transpose().contiguous.transpose().contiguous.append", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.gather().view.expand", "torch.gather().view.expand", "torch.gather().view.expand", "crf.CRF.transitions.view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "max_scores.view().expand", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "mask.transpose().contiguous.transpose().contiguous.transpose", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous().view", "cur_values.view.view.view", "mask[].view().expand", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.cat().view().transpose", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pointer.contiguous().view", "back_points.transpose().contiguous.transpose().contiguous.transpose", "back_points.transpose().contiguous.transpose().contiguous.transpose", "len", "back_points[].view", "pointer.contiguous().view", "crf.CRF.transitions.view", "mask.transpose().contiguous.transpose().contiguous.long", "partition.transpose.transpose.view", "cur_values.view.view.view", "partition.transpose.transpose.contiguous().view().expand", "cur_values.view.view.view().expand", "partition.transpose.transpose.contiguous().view().expand", "torch.sum().view().long.view", "torch.sum().view().long.view", "torch.sum().view().long.view", "crf.CRF.transitions.view", "pointer.contiguous().view", "mask[].view().expand().long", "max_scores.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose().contiguous", "mask[].view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "pointer.contiguous", "pointer.contiguous", "partition.transpose.transpose.contiguous().view", "cur_values.view.view.view", "partition.transpose.transpose.contiguous().view", "pointer.contiguous", "mask[].view().expand", "feats.transpose().contiguous().view().expand.transpose().contiguous().view().expand.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "partition.transpose.transpose.contiguous", "partition.transpose.transpose.contiguous", "mask[].view"], "methods", ["None"], ["", "def", "_viterbi_decode_nbest", "(", "self", ",", "feats", ",", "mask", ",", "nbest", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size+2)\n                mask: (batch, seq_len)\n            output:\n                decode_idx: (batch, nbest, seq_len) decoded sequence\n                path_score: (batch, nbest) corresponding score for each sequence (to be implementated)\n                nbest decode for sentence with one token is not well supported, to be optimized\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "assert", "(", "tag_size", "==", "self", ".", "tagset_size", "+", "2", ")", "\n", "## calculate sentence length for each sentence", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "## mask to (seq_len, batch_size)", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "ins_num", "=", "seq_len", "*", "batch_size", "\n", "## be careful the view shape, it is .view(ins_num, 1, tag_size) but not .view(ins_num, tag_size, 1)", "\n", "feats", "=", "feats", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "ins_num", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "## need to consider start", "\n", "scores", "=", "feats", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", ".", "expand", "(", "ins_num", ",", "tag_size", ",", "tag_size", ")", "\n", "scores", "=", "scores", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "\n", "# build iter", "\n", "seq_iter", "=", "enumerate", "(", "scores", ")", "\n", "## record the position of best score", "\n", "back_points", "=", "list", "(", ")", "\n", "partition_history", "=", "list", "(", ")", "\n", "##  reverse mask (bug for mask = 1- mask, use this as alternative choice)", "\n", "# mask = 1 + (-1)*mask", "\n", "mask", "=", "(", "1", "-", "mask", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "_", ",", "inivalues", "=", "seq_iter", ".", "__next__", "(", ")", "# bat_size * from_target_size * to_target_size", "\n", "# only need start from start_tag", "\n", "partition", "=", "inivalues", "[", ":", ",", "START_TAG", ",", ":", "]", ".", "clone", "(", ")", "# bat_size * to_target_size", "\n", "## initial partition [batch_size, tag_size]", "\n", "partition_history", ".", "append", "(", "partition", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ")", ")", "\n", "# iter over last scores", "\n", "for", "idx", ",", "cur_values", "in", "seq_iter", ":", "\n", "            ", "if", "idx", "==", "1", ":", "\n", "                ", "cur_values", "=", "cur_values", ".", "view", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "tag_size", ")", "\n", "", "else", ":", "\n", "# previous to_target is current from_target", "\n", "# partition: previous results log(exp(from_target)), #(batch_size * nbest * from_target)", "\n", "# cur_values: batch_size * from_target * to_target", "\n", "                ", "cur_values", "=", "cur_values", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "tag_size", ")", "+", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "tag_size", ")", "\n", "## compare all nbest and all from target", "\n", "cur_values", "=", "cur_values", ".", "view", "(", "batch_size", ",", "tag_size", "*", "nbest", ",", "tag_size", ")", "\n", "# print \"cur size:\",cur_values.size()", "\n", "", "partition", ",", "cur_bp", "=", "torch", ".", "topk", "(", "cur_values", ",", "nbest", ",", "1", ")", "\n", "## cur_bp/partition: [batch_size, nbest, tag_size], id should be normize through nbest in following backtrace step", "\n", "# print partition[:,0,:]", "\n", "# print cur_bp[:,0,:]", "\n", "# print \"nbest, \",idx", "\n", "if", "idx", "==", "1", ":", "\n", "                ", "cur_bp", "=", "cur_bp", "*", "nbest", "\n", "", "partition", "=", "partition", ".", "transpose", "(", "2", ",", "1", ")", "\n", "cur_bp", "=", "cur_bp", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# print partition", "\n", "# exit(0)", "\n", "#partition: (batch_size * to_target * nbest)", "\n", "#cur_bp: (batch_size * to_target * nbest) Notice the cur_bp number is the whole position of tag_size*nbest, need to convert when decode", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "## cur_bp: (batch_size,nbest, tag_size) topn source score position in current tag", "\n", "## set padded label as 0, which will be filtered in post processing", "\n", "## mask[idx] ? mask[idx-1]", "\n", "cur_bp", ".", "masked_fill_", "(", "mask", "[", "idx", "]", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ")", ",", "0", ")", "\n", "# print cur_bp[0]", "\n", "back_points", ".", "append", "(", "cur_bp", ")", "\n", "### add score to final STOP_TAG", "\n", "", "partition_history", "=", "torch", ".", "cat", "(", "partition_history", ",", "0", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "nbest", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "## (batch_size, seq_len, nbest, tag_size)", "\n", "### get the last position for each setences, and select the last partitions using gather()", "\n", "last_position", "=", "length_mask", ".", "view", "(", "batch_size", ",", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ",", "nbest", ")", "-", "1", "\n", "last_partition", "=", "torch", ".", "gather", "(", "partition_history", ",", "1", ",", "last_position", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "1", ")", "\n", "### calculate the score from last partition to end state (and then select the STOP_TAG from it)", "\n", "last_values", "=", "last_partition", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "tag_size", ")", "+", "self", ".", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "1", ",", "tag_size", ")", ".", "expand", "(", "batch_size", ",", "tag_size", ",", "nbest", ",", "tag_size", ")", "\n", "last_values", "=", "last_values", ".", "view", "(", "batch_size", ",", "tag_size", "*", "nbest", ",", "tag_size", ")", "\n", "end_partition", ",", "end_bp", "=", "torch", ".", "topk", "(", "last_values", ",", "nbest", ",", "1", ")", "\n", "## end_partition: (batch, nbest, tag_size)", "\n", "end_bp", "=", "end_bp", ".", "transpose", "(", "2", ",", "1", ")", "\n", "# end_bp: (batch, tag_size, nbest)", "\n", "pad_zero", "=", "torch", ".", "zeros", "(", "batch_size", ",", "tag_size", ",", "nbest", ")", ".", "to", "(", "self", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "back_points", ".", "append", "(", "pad_zero", ")", "\n", "back_points", "=", "torch", ".", "cat", "(", "back_points", ")", ".", "view", "(", "seq_len", ",", "batch_size", ",", "tag_size", ",", "nbest", ")", "\n", "\n", "## select end ids in STOP_TAG", "\n", "pointer", "=", "end_bp", "[", ":", ",", "STOP_TAG", ",", ":", "]", "## (batch_size, nbest)", "\n", "insert_last", "=", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ",", "nbest", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ",", "nbest", ")", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values", "\n", "# print \"lp:\",last_position", "\n", "# print \"il:\",insert_last[0]", "\n", "# exit(0)", "\n", "## copy the ids of last position:insert_last to back_points, though the last_position index", "\n", "## last_position includes the length of batch sentences", "\n", "# print \"old:\", back_points[9,0,:,:]", "\n", "back_points", ".", "scatter_", "(", "1", ",", "last_position", ",", "insert_last", ")", "\n", "## back_points: [batch_size, seq_length, tag_size, nbest]", "\n", "# print \"new:\", back_points[9,0,:,:]", "\n", "# exit(0)", "\n", "# print pointer[2]", "\n", "'''\n        back_points: in simple demonstratration\n        x,x,x,x,x,x,x,x,x,7\n        x,x,x,x,x,4,0,0,0,0\n        x,x,6,0,0,0,0,0,0,0\n        '''", "\n", "\n", "back_points", "=", "back_points", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "# print back_points[0]", "\n", "## back_points: (seq_len, batch, tag_size, nbest)", "\n", "## decode from the end, padded position ids are 0, which will be filtered in following evaluation", "\n", "decode_idx", "=", "torch", ".", "zeros", "(", "seq_len", ",", "batch_size", ",", "nbest", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "decode_idx", "[", "-", "1", "]", "=", "pointer", ".", "data", "/", "nbest", "\n", "# print \"pointer-1:\",pointer[2]", "\n", "# exit(0)", "\n", "# use old mask, let 0 means has token", "\n", "for", "idx", "in", "range", "(", "len", "(", "back_points", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "# print \"pointer: \",idx,  pointer[3]", "\n", "# print \"back:\",back_points[idx][3]", "\n", "# print \"mask:\",mask[idx+1,3]", "\n", "            ", "new_pointer", "=", "torch", ".", "gather", "(", "back_points", "[", "idx", "]", ".", "view", "(", "batch_size", ",", "tag_size", "*", "nbest", ")", ",", "1", ",", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "nbest", ")", ")", "\n", "decode_idx", "[", "idx", "]", "=", "new_pointer", ".", "data", "/", "nbest", "\n", "# # use new pointer to remember the last end nbest ids for non longest", "\n", "pointer", "=", "new_pointer", "+", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "nbest", ")", "*", "mask", "[", "idx", "]", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "nbest", ")", ".", "long", "(", ")", "\n", "\n", "# exit(0)", "\n", "", "path_score", "=", "None", "\n", "decode_idx", "=", "decode_idx", ".", "transpose", "(", "1", ",", "0", ")", "\n", "## decode_idx: [batch, seq_len, nbest]", "\n", "# print decode_idx[:,:,0]", "\n", "# print \"nbest:\",nbest", "\n", "# print \"diff:\", decode_idx[:,:,0]- decode_idx[:,:,4]", "\n", "# print decode_idx[:,0,:]", "\n", "# exit(0)", "\n", "\n", "### calculate probability for each sequence", "\n", "scores", "=", "end_partition", "[", ":", ",", ":", ",", "STOP_TAG", "]", "\n", "## scores: [batch_size, nbest]", "\n", "max_scores", ",", "_", "=", "torch", ".", "max", "(", "scores", ",", "1", ")", "\n", "minus_scores", "=", "scores", "-", "max_scores", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "nbest", ")", "\n", "path_score", "=", "F", ".", "softmax", "(", "minus_scores", ",", "1", ")", "\n", "## path_score: [batch_size, nbest]", "\n", "# exit(0)", "\n", "return", "path_score", ",", "decode_idx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.log_sum_exp": [[17, 29], ["torch.max", "torch.max", "torch.max", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view.view", "torch.log().view", "torch.log().view", "torch.log().view", "torch.gather", "torch.gather", "torch.gather", "idx.view", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "torch.gather().view.expand_as"], "function", ["None"], ["def", "log_sum_exp", "(", "vec", ",", "m_size", ")", ":", "\n", "    ", "\"\"\"\n    calculate log of exp sum\n    args:\n        vec (batch_size, vanishing_dim, hidden_dim) : input tensor\n        m_size : hidden_dim\n    return:\n        batch_size, hidden_dim\n    \"\"\"", "\n", "_", ",", "idx", "=", "torch", ".", "max", "(", "vec", ",", "1", ")", "# B * 1 * M", "\n", "max_score", "=", "torch", ".", "gather", "(", "vec", ",", "1", ",", "idx", ".", "view", "(", "-", "1", ",", "1", ",", "m_size", ")", ")", ".", "view", "(", "-", "1", ",", "1", ",", "m_size", ")", "# B * M", "\n", "return", "max_score", ".", "view", "(", "-", "1", ",", "m_size", ")", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "vec", "-", "max_score", ".", "expand_as", "(", "vec", ")", ")", ",", "1", ")", ")", ".", "view", "(", "-", "1", ",", "m_size", ")", "# B * M", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.transfer_separate_data": [[12, 23], ["zip", "open", "open", "open", "data.append", "line.strip", "line.strip", "line.strip", "f.readlines", "f.readlines", "f.readlines"], "function", ["None"], ["def", "transfer_separate_data", "(", "raw_txt", ",", "label_txt", ",", "intent_txt", ")", ":", "\n", "    ", "with", "open", "(", "raw_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "label_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intent_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "data", "=", "[", "]", "\n", "for", "t", ",", "l", ",", "i", "in", "zip", "(", "raw_data", ",", "label_data", ",", "intent_data", ")", ":", "\n", "        ", "data", ".", "append", "(", "[", "t", ",", "l", ",", "i", "]", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.transfer_gen_data": [[25, 33], ["open", "f.readlines", "line.strip().split.strip().split", "data.append", "line.strip().split.strip"], "function", ["None"], ["", "def", "transfer_gen_data", "(", "txt", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "#assert len(line) == 2", "\n", "data", ".", "append", "(", "line", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.gen_conll_data": [[35, 48], ["open", "enumerate", "data[].split", "data[].split", "range", "f.write", "len", "len", "print", "print", "print", "len", "len", "len", "f.write", "len", "len"], "function", ["None"], ["", "def", "gen_conll_data", "(", "org_data", ",", "new_data", ",", "output_file", ")", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "count", ",", "data", "in", "enumerate", "(", "org_data", "+", "new_data", ")", ":", "\n", "            ", "utter", "=", "data", "[", "0", "]", ".", "split", "(", ")", "\n", "label", "=", "data", "[", "1", "]", ".", "split", "(", ")", "\n", "if", "len", "(", "utter", ")", "!=", "len", "(", "label", ")", ":", "\n", "                ", "print", "(", "utter", ",", "label", ")", "\n", "print", "(", "len", "(", "utter", ")", ",", "len", "(", "label", ")", ")", "\n", "print", "(", "count", ")", "\n", "", "assert", "len", "(", "utter", ")", "==", "len", "(", "label", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "utter", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "utter", "[", "i", "]", "+", "'\\t'", "+", "label", "[", "i", "]", "+", "'\\n'", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.clean_txt": [[50, 59], ["new_txt.append", "len", "re.sub", "word.lower.lower", "word.lower.lower"], "function", ["None"], ["", "", "", "def", "clean_txt", "(", "txt_list", ")", ":", "\n", "    ", "new_txt", "=", "[", "]", "\n", "for", "word", "in", "txt_list", ":", "\n", "        ", "if", "len", "(", "word", ")", ">", "1", ":", "\n", "            ", "word", "=", "re", ".", "sub", "(", "\"'\"", ",", "\"\"", ",", "word", ".", "lower", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "new_txt", ".", "append", "(", "word", ")", "\n", "", "return", "new_txt", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.snips2conll": [[61, 83], ["open", "f.readlines", "open", "f.readlines", "open", "range", "data[].append", "data[].append", "len", "get_evaluate_data.clean_txt", "range", "f.write", "line.strip().split", "line.strip().split", "len", "len", "print", "exit", "len", "f.write", "line.strip", "line.strip"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.clean_txt"], ["", "def", "snips2conll", "(", "utter", "=", "'seq.in'", ",", "label", "=", "'seq.out'", ",", "out", "=", "'snips.conll'", ")", ":", "\n", "    ", "data", "=", "{", "'utter'", ":", "[", "]", ",", "'label'", ":", "[", "]", "}", "\n", "with", "open", "(", "utter", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "data", "[", "'utter'", "]", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "", "with", "open", "(", "label", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "data", "[", "'label'", "]", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "", "with", "open", "(", "out", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "data", "[", "'utter'", "]", ")", ")", ":", "\n", "            ", "utter", "=", "clean_txt", "(", "data", "[", "'utter'", "]", "[", "i", "]", ")", "\n", "label", "=", "data", "[", "'label'", "]", "[", "i", "]", "\n", "if", "len", "(", "utter", ")", "!=", "len", "(", "label", ")", ":", "\n", "                ", "print", "(", "utter", ",", "label", ")", "\n", "exit", "(", ")", "\n", "", "for", "j", "in", "range", "(", "len", "(", "utter", ")", ")", ":", "\n", "                ", "if", "label", "[", "j", "]", "==", "'B-timeRange'", ":", "\n", "                    ", "label", "[", "j", "]", "=", "'B-timerange'", "\n", "", "if", "label", "[", "j", "]", "==", "'I-timeRange'", ":", "\n", "                    ", "label", "[", "j", "]", "=", "'I-timerange'", "\n", "", "f", ".", "write", "(", "utter", "[", "j", "]", "+", "'\\t'", "+", "label", "[", "j", "]", "+", "'\\n'", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.get_lstm_data": [[84, 97], ["open", "enumerate", "data[].split", "data[].split", "range", "f.write", "len", "len", "print", "print", "print", "len", "len", "len", "f.write", "len", "len"], "function", ["None"], ["", "", "", "def", "get_lstm_data", "(", "gen_data", ",", "output_file", ")", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "count", ",", "data", "in", "enumerate", "(", "gen_data", ")", ":", "\n", "            ", "utter", "=", "data", "[", "0", "]", ".", "split", "(", ")", "\n", "label", "=", "data", "[", "1", "]", ".", "split", "(", ")", "\n", "if", "len", "(", "utter", ")", "!=", "len", "(", "label", ")", ":", "\n", "                ", "print", "(", "utter", ",", "label", ")", "\n", "print", "(", "len", "(", "utter", ")", ",", "len", "(", "label", ")", ")", "\n", "print", "(", "count", ")", "\n", "", "assert", "len", "(", "utter", ")", "==", "len", "(", "label", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "utter", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "utter", "[", "i", "]", "+", "'\\t'", "+", "label", "[", "i", "]", "+", "'\\n'", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.get_bert_data": [[98, 117], ["open", "enumerate", "data[].split", "data[].split", "range", "len", "len", "print", "print", "print", "len", "len", "len", "f.write", "len", "f.write", "len", "len", "f.write", "f.write", "str"], "function", ["None"], ["", "", "", "def", "get_bert_data", "(", "gen_data", ",", "output_file", ")", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "count", ",", "data", "in", "enumerate", "(", "gen_data", ")", ":", "\n", "            ", "utter", "=", "data", "[", "0", "]", ".", "split", "(", ")", "\n", "label", "=", "data", "[", "1", "]", ".", "split", "(", ")", "\n", "if", "len", "(", "utter", ")", "!=", "len", "(", "label", ")", ":", "\n", "                ", "print", "(", "utter", ",", "label", ")", "\n", "print", "(", "len", "(", "utter", ")", ",", "len", "(", "label", ")", ")", "\n", "print", "(", "count", ")", "\n", "", "assert", "len", "(", "utter", ")", "==", "len", "(", "label", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "utter", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "utter", "[", "i", "]", "+", "':'", "+", "label", "[", "i", "]", "+", "' '", ")", "\n", "", "if", "len", "(", "data", ")", "==", "3", ":", "\n", "                ", "f", ".", "write", "(", "'<=> '", "+", "str", "(", "data", "[", "2", "]", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                ", "if", "'snips'", "in", "output_file", ":", "\n", "                    ", "f", ".", "write", "(", "'<=> AddToPlaylist\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "f", ".", "write", "(", "'<=> atis_flight\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_evaluate_data.convert_conll_to_bert": [[118, 142], ["open", "f.readlines", "open", "enumerate", "range", "f.write", "data.append", "line.strip().split.strip().split", "text.append", "label.append", "len", "len", "print", "print", "print", "len", "len", "len", "f.write", "len", "len", "line.strip().split.strip"], "function", ["None"], ["", "", "", "", "", "def", "convert_conll_to_bert", "(", "conll_data", ",", "bert_data", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "conll_data", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "text", ",", "label", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "if", "line", "==", "'\\n'", ":", "\n", "                ", "data", ".", "append", "(", "[", "text", ",", "label", "]", ")", "\n", "text", ",", "label", "=", "[", "]", ",", "[", "]", "\n", "", "else", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "text", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "label", ".", "append", "(", "line", "[", "1", "]", ")", "\n", "", "", "", "with", "open", "(", "bert_data", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "count", ",", "data", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "utter", "=", "data", "[", "0", "]", "\n", "label", "=", "data", "[", "1", "]", "\n", "if", "len", "(", "utter", ")", "!=", "len", "(", "label", ")", ":", "\n", "                ", "print", "(", "utter", ",", "label", ")", "\n", "print", "(", "len", "(", "utter", ")", ",", "len", "(", "label", ")", ")", "\n", "print", "(", "count", ")", "\n", "", "assert", "len", "(", "utter", ")", "==", "len", "(", "label", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "utter", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "utter", "[", "i", "]", "+", "':'", "+", "label", "[", "i", "]", "+", "' '", ")", "\n", "", "f", ".", "write", "(", "'<=> AddToPlaylist\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slice": [[18, 23], ["new_data.append"], "function", ["None"], ["def", "get_slice", "(", "data", ",", "index", ")", ":", "\n", "    ", "new_data", "=", "[", "]", "\n", "for", "i", "in", "index", ":", "\n", "        ", "new_data", ".", "append", "(", "data", "[", "i", "]", ")", "\n", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_train_data": [[24, 74], ["zip", "len", "list", "random.shuffle", "open", "open", "open", "len", "len", "len", "len", "text.split.split", "label.split.split", "enumerate", "delex_text.append", "range", "int", "line.strip", "line.strip", "line.strip", "len", "len", "open", "get_source_data.get_slice", "open", "get_source_data.get_slice", "open", "get_source_data.get_slice", "open", "get_source_data.get_slice", "f.readlines", "f.readlines", "f.readlines", "delex.append", "str", "f.write", "f.write", "f.write", "f.write", "delex.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slice", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slice", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slice", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slice"], ["", "def", "get_train_data", "(", "data_folder", ",", "output_folder", ",", "proportion", ")", ":", "\n", "# train_data", "\n", "    ", "with", "open", "(", "data_folder", "+", "'train/seq.in'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw_text", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'train/seq.out'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "slot_label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'train/label'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "assert", "len", "(", "raw_text", ")", "==", "len", "(", "slot_label", ")", "\n", "assert", "len", "(", "raw_text", ")", "==", "len", "(", "intents", ")", "\n", "\n", "delex_text", "=", "[", "]", "\n", "for", "text", ",", "label", ",", "intent", "in", "zip", "(", "raw_text", ",", "slot_label", ",", "intents", ")", ":", "\n", "        ", "text", "=", "text", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "delex", "=", "[", "]", "\n", "assert", "len", "(", "text", ")", "==", "len", "(", "label", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "if", "w", "==", "'O'", ":", "\n", "                ", "delex", ".", "append", "(", "text", "[", "i", "]", ")", "\n", "", "elif", "w", "[", "0", "]", "==", "'B'", ":", "\n", "                ", "delex", ".", "append", "(", "'_'", "+", "w", "[", "2", ":", "]", "+", "'_'", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "", "delex_text", ".", "append", "(", "' '", ".", "join", "(", "delex", ")", ")", "\n", "\n", "# split data", "\n", "", "dataset_size", "=", "len", "(", "raw_text", ")", "\n", "index_seq", "=", "list", "(", "range", "(", "dataset_size", ")", ")", "\n", "random", ".", "shuffle", "(", "index_seq", ")", "\n", "for", "p", "in", "proportion", ":", "\n", "        ", "new_size", "=", "int", "(", "dataset_size", "*", "p", ")", "\n", "new_index", "=", "index_seq", "[", ":", "new_size", "]", "\n", "name_pre", "=", "output_folder", "+", "'train_'", "+", "str", "(", "new_size", ")", "+", "'_'", "\n", "# raw_text", "\n", "with", "open", "(", "name_pre", "+", "'raw.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "data", "in", "get_slice", "(", "raw_text", ",", "new_index", ")", ":", "\n", "                ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# delex_text", "\n", "", "", "with", "open", "(", "name_pre", "+", "'delex.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "data", "in", "get_slice", "(", "delex_text", ",", "new_index", ")", ":", "\n", "                ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# label_text", "\n", "", "", "with", "open", "(", "name_pre", "+", "'label.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "data", "in", "get_slice", "(", "slot_label", ",", "new_index", ")", ":", "\n", "                ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# intent", "\n", "", "", "with", "open", "(", "name_pre", "+", "'intent.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "data", "in", "get_slice", "(", "intents", ",", "new_index", ")", ":", "\n", "                ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_val_data": [[75, 122], ["zip", "open", "open", "open", "len", "len", "len", "len", "text.split.split", "label.split.split", "enumerate", "delex_text.append", "open", "open", "open", "open", "line.strip", "line.strip", "line.strip", "len", "len", "f.write", "f.write", "f.write", "f.write", "f.readlines", "f.readlines", "f.readlines", "delex.append", "delex.append"], "function", ["None"], ["", "", "", "", "def", "get_val_data", "(", "data_folder", ",", "output_folder", ",", "type", ")", ":", "\n", "# val_data", "\n", "    ", "if", "type", "==", "'val'", ":", "\n", "        ", "prefix", "=", "'valid'", "\n", "", "elif", "type", "==", "'test'", ":", "\n", "        ", "prefix", "=", "'test'", "\n", "", "with", "open", "(", "data_folder", "+", "prefix", "+", "'/seq.in'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw_text", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "prefix", "+", "'/seq.out'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "slot_label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "prefix", "+", "'/label'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intent", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "assert", "len", "(", "raw_text", ")", "==", "len", "(", "slot_label", ")", "\n", "assert", "len", "(", "raw_text", ")", "==", "len", "(", "intent", ")", "\n", "\n", "delex_text", "=", "[", "]", "\n", "for", "text", ",", "label", ",", "int", "in", "zip", "(", "raw_text", ",", "slot_label", ",", "intent", ")", ":", "\n", "        ", "text", "=", "text", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "delex", "=", "[", "]", "\n", "assert", "len", "(", "text", ")", "==", "len", "(", "label", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "if", "w", "==", "'O'", ":", "\n", "                ", "delex", ".", "append", "(", "text", "[", "i", "]", ")", "\n", "", "elif", "w", "[", "0", "]", "==", "'B'", ":", "\n", "                ", "delex", ".", "append", "(", "'_'", "+", "w", "[", "2", ":", "]", "+", "'_'", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "", "", "delex_text", ".", "append", "(", "' '", ".", "join", "(", "delex", ")", ")", "\n", "\n", "", "name_pre", "=", "output_folder", "+", "type", "+", "'_'", "\n", "# raw_text", "\n", "with", "open", "(", "name_pre", "+", "'raw.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "data", "in", "raw_text", ":", "\n", "            ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# delex_text", "\n", "", "", "with", "open", "(", "name_pre", "+", "'delex.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "data", "in", "delex_text", ":", "\n", "            ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# label_text", "\n", "", "", "with", "open", "(", "name_pre", "+", "'label.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "data", "in", "slot_label", ":", "\n", "            ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "# intent", "\n", "", "", "with", "open", "(", "name_pre", "+", "'intent.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "data", "in", "intent", ":", "\n", "            ", "f", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slot_intent": [[123, 153], ["set", "set", "open", "open", "open", "open", "open", "open", "label.split.split", "open", "open", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "line.strip", "f.write", "f.write", "f.readlines", "f.readlines", "f.readlines", "f.readlines", "f.readlines", "f.readlines", "set.add"], "function", ["None"], ["", "", "", "def", "get_slot_intent", "(", "data_folder", ",", "output_folder", ")", ":", "\n", "    ", "with", "open", "(", "data_folder", "+", "'train/seq.out'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "slot_label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'train/label'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'valid'", "+", "'/seq.out'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "slot_label", "+=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'valid'", "+", "'/label'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intents", "+=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'test'", "+", "'/seq.out'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "slot_label", "+=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "data_folder", "+", "'test'", "+", "'/label'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intents", "+=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "# get slot labels:", "\n", "", "slots", "=", "set", "(", ")", "\n", "for", "label", "in", "slot_label", ":", "\n", "        ", "label", "=", "label", ".", "split", "(", ")", "\n", "for", "l", "in", "label", ":", "\n", "            ", "if", "l", "!=", "'O'", ":", "\n", "                ", "slots", ".", "add", "(", "l", "[", "2", ":", "]", ")", "\n", "", "", "", "with", "open", "(", "output_folder", "+", "'slot_vocab.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "s", "in", "slots", ":", "\n", "            ", "f", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n", "# get intent labels:", "\n", "", "", "ints", "=", "set", "(", "intents", ")", "\n", "with", "open", "(", "output_folder", "+", "'intent_vocab.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "s", "in", "ints", ":", "\n", "            ", "f", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_parallel_data": [[155, 185], ["slot_delex_dict.items", "print", "open", "slots.sort", "list", "open", "len", "line.strip().split", "slot_delex_dict[].append", "set", "len", "len", "range", "f.write", "f.readlines", "slots.append", "len", "range", "line.strip", "len", "para_data.append"], "function", ["None"], ["", "", "", "def", "get_parallel_data", "(", "delex_file", ",", "para_file", ")", ":", "\n", "    ", "with", "open", "(", "delex_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "delex_text", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "slot_delex_dict", "=", "{", "}", "\n", "for", "delex", "in", "delex_text", ":", "\n", "        ", "slots", "=", "[", "]", "\n", "for", "w", "in", "delex", ":", "\n", "            ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                ", "slots", ".", "append", "(", "w", ")", "\n", "", "", "slots", ".", "sort", "(", ")", "\n", "slots", "=", "'#'", ".", "join", "(", "slots", ")", "\n", "if", "slots", "not", "in", "slot_delex_dict", ":", "\n", "            ", "slot_delex_dict", "[", "slots", "]", "=", "[", "' '", ".", "join", "(", "delex", ")", "]", "\n", "", "else", ":", "\n", "            ", "slot_delex_dict", "[", "slots", "]", ".", "append", "(", "' '", ".", "join", "(", "delex", ")", ")", "\n", "\n", "", "", "para_data", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "slot", ",", "texts", "in", "slot_delex_dict", ".", "items", "(", ")", ":", "\n", "        ", "texts", "=", "list", "(", "set", "(", "texts", ")", ")", "\n", "if", "len", "(", "texts", ")", ">", "1", ":", "\n", "            ", "count", "+=", "len", "(", "texts", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "len", "(", "texts", ")", ")", ":", "\n", "                    ", "if", "i", "!=", "j", ":", "\n", "                        ", "para_data", ".", "append", "(", "[", "texts", "[", "i", "]", ",", "texts", "[", "j", "]", "]", ")", "\n", "", "", "", "", "", "with", "open", "(", "para_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "data", "in", "para_data", ":", "\n", "            ", "f", ".", "write", "(", "data", "[", "0", "]", "+", "'\\t'", "+", "data", "[", "1", "]", "+", "'\\n'", ")", "\n", "", "", "print", "(", "count", ",", "len", "(", "delex_text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_source_data.get_slot_dict": [[186, 228], ["zip", "slot_dict.items", "open", "open", "open", "open", "data.append", "raw.split.split", "label.split.split", "enumerate", "list", "open", "json.dump", "str", "line.strip", "line.strip", "line.strip", "line.strip", "slot_dict[].add", "f.readlines", "f.readlines", "f.readlines", "f.readlines", "slot_dict[].add", "slot_dict.keys", "set", "slot_dict[].add"], "function", ["None"], ["", "def", "get_slot_dict", "(", "output_folder", ",", "sizes", ")", ":", "\n", "    ", "for", "size", "in", "sizes", ":", "\n", "        ", "name_pre", "=", "output_folder", "+", "'train_'", "+", "str", "(", "size", ")", "+", "'_'", "\n", "with", "open", "(", "name_pre", "+", "'raw.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "raw_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "name_pre", "+", "'label.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "label_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "name_pre", "+", "'intent.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "intent_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "name_pre", "+", "'delex.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "delex_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "data", "=", "[", "]", "\n", "for", "t", ",", "l", ",", "i", ",", "d", "in", "zip", "(", "raw_data", ",", "label_data", ",", "intent_data", ",", "delex_data", ")", ":", "\n", "            ", "data", ".", "append", "(", "[", "t", ",", "l", ",", "i", ",", "d", "]", ")", "\n", "\n", "", "slot_dict", "=", "{", "}", "\n", "for", "raw", ",", "label", ",", "_", ",", "_", "in", "data", ":", "\n", "            ", "raw", "=", "raw", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "raw", ")", ":", "\n", "                ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                    ", "if", "tmp_str", ":", "\n", "                        ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "word", "\n", "tmp_label", "=", "label", "[", "i", "]", "[", "2", ":", "]", "\n", "if", "tmp_label", "not", "in", "slot_dict", ".", "keys", "(", ")", ":", "\n", "                        ", "slot_dict", "[", "tmp_label", "]", "=", "set", "(", ")", "\n", "", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'I'", ":", "\n", "                    ", "tmp_str", "=", "tmp_str", "+", "' '", "+", "word", "\n", "", "else", ":", "\n", "                    ", "if", "tmp_str", ":", "\n", "                        ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "", "", "if", "tmp_str", ":", "\n", "                ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", ":", "\n", "            ", "slot_dict", "[", "k", "]", "=", "list", "(", "v", ")", "\n", "", "with", "open", "(", "name_pre", "+", "'slot_dict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "slot_dict", ",", "f", ",", "ensure_ascii", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_csv_data.write_csv": [[3, 9], ["open", "csv.writer", "csv.writer.writerow"], "function", ["None"], ["def", "write_csv", "(", "data", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "_file", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "_file", ",", "delimiter", "=", "','", ",", "quotechar", "=", "'\"'", ",", "\n", "quoting", "=", "csv", ".", "QUOTE_MINIMAL", ")", "\n", "for", "row", "in", "data", ":", "\n", "            ", "writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_csv_data.get_csv_data": [[10, 27], ["zip", "get_csv_data.write_csv", "open", "open", "open", "open", "data.append", "line.strip", "line.strip", "line.strip", "line.strip", "f.readlines", "f.readlines", "f.readlines", "f.readlines"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.preprocess.get_csv_data.write_csv"], ["", "", "", "def", "get_csv_data", "(", "data_pth", ")", ":", "\n", "    ", "raw_pth", "=", "data_pth", "+", "'_raw.txt'", "\n", "label_pth", "=", "data_pth", "+", "'_label.txt'", "\n", "delex_pth", "=", "data_pth", "+", "'_delex.txt'", "\n", "intent_pth", "=", "data_pth", "+", "'_intent.txt'", "\n", "data", "=", "[", "[", "'utterance'", ",", "'labels'", ",", "'delexicalised'", ",", "'intent'", "]", "]", "\n", "with", "open", "(", "raw_pth", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "label_pth", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "delex_pth", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "delex", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_pth", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intent", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "for", "r", ",", "l", ",", "d", ",", "i", "in", "zip", "(", "raw", ",", "label", ",", "delex", ",", "intent", ")", ":", "\n", "        ", "data", ".", "append", "(", "[", "r", ",", "l", ",", "d", ",", "i", "]", ")", "\n", "", "write_csv", "(", "data", ",", "data_pth", "+", "'.csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.LabelSmoothingLoss.__init__": [[21, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "classes", ",", "smoothing", "=", "0.0", ",", "dim", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "cls", "=", "classes", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.LabelSmoothingLoss.forward": [[28, 42], ["target.ne", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "nll_loss.squeeze.squeeze.squeeze", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "loss.mean", "torch.nn.functional.log_softmax.gather", "torch.nn.functional.log_softmax.gather", "torch.nn.functional.log_softmax.gather", "smooth_prob.mean", "value_mask[].unsqueeze", "torch.nn.functional.log_softmax.mean", "torch.nn.functional.log_softmax.mean", "torch.nn.functional.log_softmax.mean", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred", ",", "target", ",", "value_mask", "=", "None", ")", ":", "\n", "        ", "mask", "=", "target", ".", "ne", "(", "-", "100", ")", "\n", "x", "=", "pred", "[", "mask", "]", "\n", "target", "=", "target", "[", "mask", "]", "\n", "logprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "x", ",", "dim", "=", "-", "1", ")", "# bs*classes", "\n", "nll_loss", "=", "-", "logprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "1", ")", ")", "\n", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "1", ")", "# bs", "\n", "if", "torch", ".", "is_tensor", "(", "value_mask", ")", ":", "\n", "            ", "smooth_prob", "=", "-", "logprobs", "*", "value_mask", "[", "mask", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_prob", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "smooth_loss", "=", "-", "logprobs", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "", "loss", "=", "self", ".", "confidence", "*", "nll_loss", "+", "self", ".", "smoothing", "*", "smooth_loss", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGeneration.__init__": [[44, 47], ["transformers.BartForMaskedLM.__init__", "BartExt.LabelSmoothingLoss"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "label_smoothing_layer", "=", "LabelSmoothingLoss", "(", "self", ".", "config", ".", "vocab_size", ",", "smoothing", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGeneration.forward": [[48, 81], ["BartExt.BartForGeneration.model.forward", "BartExt.BartForGeneration.lm_head.forward", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "BartExt.BartForGeneration.label_smoothing_layer", "BartExt.BartForGeneration.label_smoothing_layer", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape", "value_mask.reshape", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "value_mask", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "#masked_lm_loss = loss_fct(lm_logits.reshape(-1, lm_logits.shape[-1]), lm_labels.reshape(-1))", "\n", "if", "torch", ".", "is_tensor", "(", "value_mask", ")", ":", "\n", "                ", "masked_lm_loss", "=", "self", ".", "label_smoothing_layer", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ",", "value_mask", ".", "reshape", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "masked_lm_loss", "=", "self", ".", "label_smoothing_layer", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "\n", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "# lm_loss, lm_logits, decoder_cached_states, dec_hidden, dec_attn", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGeneration.generate": [[82, 200], ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "BartExt.BartForGeneration._generate_beam_search", "BartExt.BartForGeneration._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "isinstance", "next", "BartExt.BartForGeneration.parameters"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_beam_search", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_no_beam_search"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_ids", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "(", "isinstance", "(", "e", ",", "int", ")", "and", "e", ">=", "0", ")", "for", "e", "in", "eos_token_ids", ")", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "bos_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGeneration._generate_no_beam_search": [[201, 300], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_().float", "input_ids.ne", "input_ids.new().fill_", "enumerate", "input_ids.ne", "BartExt.BartForGeneration.", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "attn.masked_fill.masked_fill.masked_fill", "BartExt.BartForGeneration._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new().fill_", "input_ids.ne", "float", "range", "transformers.modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "input_ids.new", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max().item", "torch.softmax", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max", "input_ids.new().fill_.max"], "methods", ["None"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "bos_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "attn_values", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ",", "input_ids", ".", "shape", "[", "1", "]", ")", ".", "fill_", "(", "0", ")", ".", "float", "(", ")", "\n", "attn_enc_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", "\n", "att_src_mask", "=", "attn_enc_mask", "&", "input_ids", ".", "ne", "(", "bos_token_id", ")", "&", "input_ids", ".", "ne", "(", "eos_token_ids", "[", "0", "]", ")", "# bs*src_len", "\n", "cur_len", "=", "1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#outputs = self(input_ids=input_ids, decoder_input_ids=decoder_input_ids, attention_mask=attn_enc_mask)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#src, tgt = torch.topk(next_token_logits[1], 5)", "\n", "#print(src, tgt)", "\n", "attn", "=", "torch", ".", "mean", "(", "outputs", "[", "1", "]", "[", "11", "]", "[", ":", ",", ":", ",", "-", "1", ",", ":", "]", ",", "dim", "=", "1", ")", "# bs*src_len", "\n", "attn", "=", "attn", ".", "masked_fill", "(", "~", "att_src_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "#src_index = torch.argmax(attn, dim=-1) # bs", "\n", "attn_values", "[", ":", ",", "cur_len", "]", "=", "attn", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "", "return", "decoded", ",", "attn_values", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGenerationTest.__init__": [[303, 306], ["transformers.BartForMaskedLM.__init__", "BartExt.LabelSmoothingLoss"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "label_smoothing_layer", "=", "LabelSmoothingLoss", "(", "self", ".", "config", ".", "vocab_size", ",", "smoothing", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGenerationTest.forward": [[307, 335], ["BartExt.BartForGenerationTest.model.forward", "BartExt.BartForGenerationTest.lm_head.forward", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "torch.CrossEntropyLoss.", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "lm_labels", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "#masked_lm_loss = self.label_smoothing_layer(lm_logits.reshape(-1, self.config.vocab_size), lm_labels.reshape(-1))", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "# lm_loss, lm_logits, decoder_cached_states, dec_hidden, dec_attn", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGenerationTest.generate": [[336, 454], ["isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "BartExt.BartForGenerationTest._generate_beam_search", "BartExt.BartForGenerationTest._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "isinstance", "next", "BartExt.BartForGenerationTest.parameters"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_beam_search", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_no_beam_search"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_ids", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "(", "isinstance", "(", "e", ",", "int", ")", "and", "e", ">=", "0", ")", "for", "e", "in", "eos_token_ids", ")", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "bos_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGenerationTest._generate_no_beam_search": [[455, 554], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_().float", "input_ids.ne", "BartExt.BartForGenerationTest.model.encoder.forward", "input_ids.new().fill_", "enumerate", "input_ids.ne", "BartExt.BartForGenerationTest.", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_probs.append", "BartExt.BartForGenerationTest._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new().fill_", "input_ids.ne", "torch.softmax", "torch.softmax", "torch.softmax", "range", "transformers.modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "input_ids.new", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max().item", "torch.softmax", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max", "input_ids.new().fill_.max"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "bos_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "attn_values", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ",", "input_ids", ".", "shape", "[", "1", "]", ")", ".", "fill_", "(", "0", ")", ".", "float", "(", ")", "\n", "attn_enc_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", "\n", "att_src_mask", "=", "attn_enc_mask", "&", "input_ids", ".", "ne", "(", "bos_token_id", ")", "&", "input_ids", ".", "ne", "(", "eos_token_ids", "[", "0", "]", ")", "# bs*src_len", "\n", "cur_len", "=", "1", "\n", "\n", "# encoder cache:", "\n", "encoder_outputs", "=", "self", ".", "model", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ")", "#, attention_mask=attn_enc_mask)", "\n", "# toy test", "\n", "output_probs", "=", "[", "]", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "encoder_outputs", "=", "encoder_outputs", ")", "\n", "#outputs = self(input_ids=input_ids, decoder_input_ids=decoder_input_ids)", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "src", ",", "tgt", "=", "torch", ".", "topk", "(", "F", ".", "softmax", "(", "next_token_logits", "[", "0", "]", ",", "dim", "=", "-", "1", ")", ",", "20", ")", "\n", "output_probs", ".", "append", "(", "[", "src", ",", "tgt", "]", ")", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "", "return", "decoded", ",", "output_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForGenerationTest._generate_beam_search": [[555, 773], ["input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "input_ids.contiguous().view.contiguous().view.new().fill_", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.new.new.view", "BartExt.BartForGenerationTest.model.encoder.forward", "range", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "transformers.modeling_utils.BeamHypotheses", "BartExt.BartForGenerationTest.", "BartExt.BartForGenerationTest._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "torch.cat.new.min().item", "torch.cat.new.max().item", "min", "torch.cat.new().fill_", "torch.cat.new().fill_", "torch.cat.new().fill_", "enumerate", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "input_ids.contiguous().view.contiguous().view.new", "range", "range", "range", "transformers.modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "next_words.view.view.view", "next_scores.view.view.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "tuple", "zip", "all_beams.append", "torch.cat.new.append", "set", "torch.softmax", "torch.softmax", "torch.softmax", "beam_scores[].expand_as", "torch.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reordered_past.append", "generated_hyps[].add", "len", "torch.cat.new.min", "torch.cat.new.max", "torch.cat.new.max().item", "torch.cat.new", "torch.cat.new", "torch.cat.new", "len", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "next", "decoder_input_ids[].tolist", "next_scores[].max().item", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "layer_past[].unsqueeze().clone().detach", "decoder_input_ids[].clone", "score.item", "BartExt.BartForGenerationTest.parameters", "word_id.item", "decoder_input_ids[].clone", "score.item", "torch.cat.new.max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "next_scores[].max", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "num_beams", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoder_input_ids", "=", "decoder_input_ids", ".", "view", "(", "batch_size", "*", "num_beams", ",", "1", ")", "\n", "cur_len", "=", "1", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# encoder cache:", "\n", "encoder_outputs", "=", "self", ".", "model", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ")", "# , attention_mask=attn_enc_mask)", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "encoder_outputs", "=", "encoder_outputs", ")", "\n", "scores", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "scores", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample 2 next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", ")", "# (batch_size * num_beams, 2)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, 2)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, 2)", "\n", "# Match shape of greedy beam search", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_ids", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# add to generated hypotheses if end of sentence or last iteration", "\n", "if", "eos_token_ids", "is", "not", "None", "and", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", ":", "\n", "                        ", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted word if it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_idx", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "decoder_input_ids", "=", "decoder_input_ids", "[", "beam_idx", ",", ":", "]", "\n", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 2nd position", "\n", "                    ", "reordered_layer_past", "=", "[", "layer_past", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "1", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "# Add all open beam hypothesis to generated_hyps", "\n", "            ", "if", "not", "done", "[", "batch_idx", "]", ":", "\n", "                ", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "", "sent_lengths", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ")", "\n", "best", "=", "[", "]", "\n", "all_beams", "=", "[", "]", "\n", "sent_lengths", "=", "[", "]", "\n", "for", "hypotheses", "in", "generated_hyps", ":", "\n", "            ", "for", "seq", "in", "hypotheses", ".", "beams", ":", "\n", "                ", "all_beams", ".", "append", "(", "seq", "[", "1", "]", ")", "\n", "sent_lengths", ".", "append", "(", "len", "(", "seq", "[", "1", "]", ")", ")", "\n", "", "", "sent_lengths", "=", "decoder_input_ids", ".", "new", "(", "sent_lengths", ")", "\n", "batch_size", "=", "batch_size", "*", "num_beams", "\n", "\n", "'''for i, hypotheses in enumerate(generated_hyps):\n            best_hyp = max(hypotheses.beams, key=lambda x: x[0])[1]\n            sent_lengths[i] = len(best_hyp)\n            best.append(best_hyp)'''", "\n", "\n", "# shorter batches are filled with pad_token", "\n", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined\"", "\n", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ",", "sent_max_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypothesis and eos_token_id if necessary", "\n", "# change best with all_beams for test", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "all_beams", ")", ":", "\n", "                ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                    ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "", "", "", "else", ":", "\n", "# none of the hypotheses have an eos_token", "\n", "            ", "assert", "(", "len", "(", "hypo", ")", "==", "max_length", "for", "hypo", "in", "best", ")", "\n", "decoded", "=", "torch", ".", "stack", "(", "best", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "\n", "", "return", "decoded", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFiling.__init__": [[775, 780], ["transformers.BartForMaskedLM.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "copy.deepcopy", "BartExt.LabelSmoothingLoss"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "sf_layer", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "shared", ".", "weight", ".", "shape", "[", "1", "]", ",", "config", ".", "slot_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "sf_decoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "decoder", ")", "\n", "self", ".", "label_smoothing_layer", "=", "LabelSmoothingLoss", "(", "self", ".", "config", ".", "vocab_size", ",", "smoothing", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFiling.forward": [[781, 829], ["transformers.modeling_bart._prepare_bart_decoder_inputs", "BartExt.BartForSlotFiling.model.encoder.forward", "BartExt.BartForSlotFiling.model.decoder.forward", "BartExt.BartForSlotFiling.sf_decoder.forward", "BartExt._filter_out_falsey_values", "BartExt._filter_out_falsey_values", "BartExt.BartForSlotFiling.lm_head.forward", "BartExt.BartForSlotFiling.sf_layer.forward", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "BartExt.BartForSlotFiling.label_smoothing_layer", "slot_logits.contiguous.contiguous.contiguous", "torch.CrossEntropyLoss.", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape", "slot_logits.contiguous.contiguous.reshape", "slot_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "decoder_input_ids", ",", "\n", "lm_labels", "=", "None", ",", "\n", "slot_labels", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", "\n", ")", ":", "\n", "# make masks if user doesn't supply", "\n", "        ", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "decoder_attn_mask", "=", "decoder_attention_mask", ",", "\n", ")", "\n", "\n", "encoder_outputs", "=", "self", ".", "model", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "lm_decoder_outputs", "=", "self", ".", "model", ".", "decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "sf_decoder_outputs", "=", "self", ".", "sf_decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_decoder_outputs", "=", "_filter_out_falsey_values", "(", "lm_decoder_outputs", ")", "\n", "sf_decoder_outputs", "=", "_filter_out_falsey_values", "(", "sf_decoder_outputs", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "lm_decoder_outputs", "[", "0", "]", ")", "\n", "slot_logits", "=", "self", ".", "sf_layer", ".", "forward", "(", "sf_decoder_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "slot_logits", ",", ")", "+", "lm_decoder_outputs", "[", "1", ":", "]", "\n", "\n", "if", "torch", ".", "is_tensor", "(", "lm_labels", ")", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "#masked_lm_loss = loss_fct(lm_logits.reshape(-1, self.config.vocab_size), lm_labels.reshape(-1))", "\n", "masked_lm_loss", "=", "self", ".", "label_smoothing_layer", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "\n", "slot_logits", "=", "slot_logits", ".", "contiguous", "(", ")", "\n", "slot_loss", "=", "loss_fct", "(", "slot_logits", ".", "reshape", "(", "-", "1", ",", "slot_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "slot_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", "slot_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFiling._generate_no_beam_search": [[830, 937], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "enumerate", "BartExt.BartForSlotFiling.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "BartExt.BartForSlotFiling.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "BartExt.BartForSlotFiling._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new", "range", "transformers.modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max", "torch.softmax", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max"], "methods", ["None"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#value, next_token_id = torch.topk(F.softmax(next_token_logits), 5, dim=-1)", "\n", "#print(value[0], next_token_id[0], value[1], next_token_id[1])", "\n", "#return input_ids[0], next_token_id[0], input_ids[1], next_token_id[1]", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "# slot prediction", "\n", "", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoded", ")", "\n", "slot_logits", "=", "outputs", "[", "1", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "=", "next_token_slot_label", "\n", "\n", "return", "decoded", ",", "decoded_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFilingCRF.__init__": [[939, 944], ["transformers.BartForMaskedLM.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "copy.deepcopy", "utils.crf.CRF"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "sf_layer", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "shared", ".", "weight", ".", "shape", "[", "1", "]", ",", "config", ".", "slot_size", "+", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "sf_decoder", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ".", "decoder", ")", "\n", "self", ".", "crf_layer", "=", "crf", ".", "CRF", "(", "config", ".", "slot_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFilingCRF.forward": [[949, 999], ["transformers.modeling_bart._prepare_bart_decoder_inputs", "BartExt.BartForSlotFilingCRF.model.encoder.forward", "BartExt.BartForSlotFilingCRF.model.decoder.forward", "BartExt.BartForSlotFilingCRF.sf_decoder.forward", "BartExt._filter_out_falsey_values", "BartExt._filter_out_falsey_values", "BartExt.BartForSlotFilingCRF.lm_head.forward", "BartExt.BartForSlotFilingCRF.sf_layer.forward", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "torch.CrossEntropyLoss.", "slot_logits.contiguous.contiguous.contiguous", "BartExt.BartForSlotFilingCRF.crf_layer.neg_log_likelihood_loss", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.neg_log_likelihood_loss"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "decoder_input_ids", ",", "\n", "lm_labels", "=", "None", ",", "\n", "slot_labels", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", "\n", ")", ":", "\n", "# make masks if user doesn't supply", "\n", "        ", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "decoder_attn_mask", "=", "decoder_attention_mask", ",", "\n", ")", "\n", "\n", "encoder_outputs", "=", "self", ".", "model", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "lm_decoder_outputs", "=", "self", ".", "model", ".", "decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "sf_decoder_outputs", "=", "self", ".", "sf_decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_decoder_outputs", "=", "_filter_out_falsey_values", "(", "lm_decoder_outputs", ")", "\n", "sf_decoder_outputs", "=", "_filter_out_falsey_values", "(", "sf_decoder_outputs", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "lm_decoder_outputs", "[", "0", "]", ")", "\n", "slot_logits", "=", "self", ".", "sf_layer", ".", "forward", "(", "sf_decoder_outputs", "[", "0", "]", ")", "\n", "slot_mask", "=", "torch", ".", "ne", "(", "decoder_input_ids", ",", "1", ")", ".", "bool", "(", ")", "\n", "total_len", "=", "torch", ".", "sum", "(", "slot_mask", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "slot_logits", ",", ")", "+", "lm_decoder_outputs", "[", "1", ":", "]", "\n", "\n", "if", "torch", ".", "is_tensor", "(", "lm_labels", ")", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "\n", "slot_logits", "=", "slot_logits", ".", "contiguous", "(", ")", "\n", "slot_loss", "=", "self", ".", "crf_layer", ".", "neg_log_likelihood_loss", "(", "slot_logits", ",", "slot_mask", ",", "slot_labels", ")", "\n", "slot_loss", "/=", "total_len", "\n", "outputs", "=", "(", "masked_lm_loss", ",", "slot_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt.BartForSlotFilingCRF._generate_no_beam_search": [[1000, 1109], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "enumerate", "BartExt.BartForSlotFilingCRF.", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "torch.ne().bool", "BartExt.BartForSlotFilingCRF.crf_layer._viterbi_decode", "BartExt.BartForSlotFilingCRF.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "BartExt.BartForSlotFilingCRF._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new", "range", "transformers.modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "input_ids.new().fill_.max().item", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max", "torch.softmax", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF._viterbi_decode"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#value, next_token_id = torch.topk(F.softmax(next_token_logits), 5, dim=-1)", "\n", "#print(value[0], next_token_id[0], value[1], next_token_id[1])", "\n", "#return input_ids[0], next_token_id[0], input_ids[1], next_token_id[1]", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "# crf prediction", "\n", "", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoded", ")", "\n", "slot_logits", "=", "outputs", "[", "1", "]", "\n", "slot_mask", "=", "torch", ".", "ne", "(", "decoded", ",", "1", ")", ".", "bool", "(", ")", "\n", "path_score", ",", "best_path", "=", "self", ".", "crf_layer", ".", "_viterbi_decode", "(", "slot_logits", ",", "slot_mask", ")", "\n", "#print(best_path.shape, decoded_label.shape)", "\n", "decoded_label", "=", "best_path", "\n", "\n", "return", "decoded", ",", "decoded_label", "", "", "", ""]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.BartExt._filter_out_falsey_values": [[16, 19], ["tuple", "isinstance"], "function", ["None"], ["def", "_filter_out_falsey_values", "(", "tup", ")", ":", "\n", "    ", "\"\"\"Remove entries that are None or [] from an iterable.\"\"\"", "\n", "return", "tuple", "(", "x", "for", "x", "in", "tup", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "or", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.__init__": [[106, 127], ["os.path.isfile", "logger.info", "run_delex_to_raw_single.LineByLineTextDataset.get_train_data", "run_delex_to_raw_single.LineByLineTextDataset.get_value_mask", "print", "open", "open", "open", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "len", "line.strip", "line.strip", "line.strip", "f.read().splitlines", "f.readlines", "f.readlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.get_train_data", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.get_value_mask"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "label_path", ":", "str", ",", "delex_path", ":", "str", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "delex_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "delexs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_delexs", ",", "new_examples", ",", "new_values", "=", "self", ".", "get_train_data", "(", "labels", ",", "delexs", ",", "examples", ",", "args", ")", "\n", "#new_delexs = [' '.join(re.sub('\\.', ' ', label).split()) for label in new_delexs]", "\n", "#new_delexs = [' '.join(re.sub('_', ' ', label).split()) for label in new_delexs]", "\n", "self", ".", "examples", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_examples", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "delexs", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_delexs", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "values", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_values", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "masks", "=", "self", ".", "get_value_mask", "(", "self", ".", "examples", ",", "self", ".", "values", ")", "\n", "print", "(", "len", "(", "new_delexs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.get_train_data": [[128, 157], ["zip", "label.split.split.split", "example.split.split.split", "delex.split.split.split", "len", "len", "enumerate", "new_delexs.append", "new_examples.append", "new_values.append", "new_value.append", "new_delex.append", "new_delex.append", "new_delex.append", "new_delex.append", "new_value.append", "new_delex.append", "re.sub"], "methods", ["None"], ["", "def", "get_train_data", "(", "self", ",", "labels", ",", "delexs", ",", "examples", ",", "args", ")", ":", "\n", "        ", "new_delexs", ",", "new_examples", ",", "new_values", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "label", ",", "delex", ",", "example", "in", "zip", "(", "labels", ",", "delexs", ",", "examples", ")", ":", "\n", "            ", "label", "=", "label", ".", "split", "(", ")", "\n", "example", "=", "example", ".", "split", "(", ")", "\n", "delex", "=", "delex", ".", "split", "(", ")", "\n", "assert", "len", "(", "label", ")", "==", "len", "(", "example", ")", "\n", "for", "d", "in", "delex", ":", "\n", "                ", "if", "d", "[", "0", "]", "==", "'_'", ":", "\n", "                    ", "d", "=", "d", "[", "1", ":", "-", "1", "]", "\n", "new_delex", ",", "new_value", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", ":", "\n", "                        ", "if", "l", "[", "0", "]", "==", "'B'", "and", "l", "[", "2", ":", "]", "==", "d", ":", "\n", "                            ", "if", "args", ".", "use_mask", ":", "\n", "                                ", "new_delex", ".", "append", "(", "'<mask>'", ")", "\n", "", "else", ":", "\n", "                                ", "new_delex", ".", "append", "(", "'_'", ")", "\n", "new_delex", ".", "append", "(", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "d", ")", ")", "\n", "new_delex", ".", "append", "(", "'_'", ")", "\n", "", "new_value", ".", "append", "(", "example", "[", "i", "]", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'I'", "and", "l", "[", "2", ":", "]", "==", "d", ":", "\n", "                            ", "new_value", ".", "append", "(", "example", "[", "i", "]", ")", "\n", "continue", "\n", "", "else", ":", "\n", "                            ", "new_delex", ".", "append", "(", "example", "[", "i", "]", ")", "\n", "", "", "new_delexs", ".", "append", "(", "' '", ".", "join", "(", "new_delex", ")", ")", "\n", "new_examples", ".", "append", "(", "' '", ".", "join", "(", "example", ")", ")", "\n", "new_values", ".", "append", "(", "' '", ".", "join", "(", "new_value", ")", ")", "\n", "", "", "", "return", "new_delexs", ",", "new_examples", ",", "new_values", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.get_value_mask": [[158, 168], ["zip", "value_mask.append", "len", "example.index"], "methods", ["None"], ["", "def", "get_value_mask", "(", "self", ",", "examples", ",", "values", ")", ":", "\n", "        ", "value_mask", "=", "[", "]", "\n", "for", "example", ",", "value", "in", "zip", "(", "examples", ",", "values", ")", ":", "\n", "            ", "value", "=", "value", "[", "1", ":", "-", "1", "]", "\n", "mask", "=", "[", "False", "]", "*", "len", "(", "example", ")", "\n", "for", "v", "in", "value", ":", "\n", "                ", "pos", "=", "example", ".", "index", "(", "v", ")", "\n", "mask", "[", "pos", "]", "=", "True", "\n", "", "value_mask", ".", "append", "(", "mask", ")", "\n", "", "return", "value_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.__len__": [[172, 174], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.LineByLineTextDataset.__getitem__": [[175, 179], ["torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "delexs", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "self", ".", "masks", "[", "i", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.get_token_label": [[67, 87], ["zip", "line.split.split", "label.split.split", "zip", "tok_label.append", "cont_word_mask.append", "tok_labels.append", "cont_word_masks.append", "tokenizer.tokenize", "len", "len", "len", "len"], "function", ["None"], ["def", "get_token_label", "(", "tokenizer", ",", "lines", ",", "labels", ")", ":", "\n", "    ", "tok_labels", "=", "[", "]", "\n", "cont_word_masks", "=", "[", "]", "\n", "for", "line", ",", "label", "in", "zip", "(", "lines", ",", "labels", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tok_label", "=", "[", "'<pad>'", "]", "\n", "cont_word_mask", "=", "[", "0", "]", "\n", "for", "word", ",", "l", "in", "zip", "(", "line", ",", "label", ")", ":", "\n", "            ", "tok", "=", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "if", "len", "(", "l", ")", "==", "1", ":", "\n", "                ", "tok_label", "+=", "[", "l", "]", "*", "len", "(", "tok", ")", "\n", "", "else", ":", "\n", "                ", "tok_label", "+=", "(", "[", "l", "]", "+", "[", "'I'", "+", "l", "[", "1", ":", "]", "]", "*", "(", "len", "(", "tok", ")", "-", "1", ")", ")", "\n", "", "cont_word_mask", "+=", "(", "[", "0", "]", "+", "[", "1", "]", "*", "(", "len", "(", "tok", ")", "-", "1", ")", ")", "\n", "", "tok_label", ".", "append", "(", "'<pad>'", ")", "\n", "cont_word_mask", ".", "append", "(", "0", ")", "\n", "tok_labels", ".", "append", "(", "tok_label", ")", "\n", "cont_word_masks", ".", "append", "(", "cont_word_mask", ")", "\n", "", "return", "tok_labels", ",", "cont_word_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.convert_label_to_id": [[88, 95], ["token_type_ids.append"], "function", ["None"], ["", "def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "slot_dict", "[", "'<pad>'", "]", "=", "-", "100", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.convert_id_to_label": [[96, 104], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "new_dict", "[", "-", "100", "]", "=", "'<pad>'", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.load_and_cache_examples": [[182, 188], ["run_delex_to_raw_single.LineByLineTextDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", "\n", "delex_path", "=", "args", ".", "eval_delex_file", "if", "evaluate", "else", "args", ".", "train_delex_file", "\n", "label_path", "=", "args", ".", "eval_label_file", "if", "evaluate", "else", "args", ".", "train_label_file", "\n", "return", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "label_path", "=", "label_path", ",", "\n", "delex_path", "=", "delex_path", ",", "block_size", "=", "args", ".", "block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.set_seed": [[190, 196], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single._sorted_checkpoints": [[198, 214], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single._rotate_checkpoints": [[216, 232], ["run_delex_to_raw_single._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.mask_tokens": [[234, 265], ["inputs.clone", "slot_ids.clone", "torch.full", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "inputs.clone.eq", "torch.full.masked_fill_", "range", "torch.bernoulli", "range", "[].item"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "\n", "    ", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "seq_len", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "if", "args", ".", "wwm", ":", "\n", "        ", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "last_mask_flag", "=", "False", "\n", "for", "j", "in", "range", "(", "seq_len", ")", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "j", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                    ", "if", "masked_indices", "[", "i", "]", "[", "j", "]", ":", "\n", "                        ", "last_mask_flag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "last_mask_flag", "=", "False", "\n", "", "", "else", ":", "\n", "                    ", "if", "last_mask_flag", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "True", "\n", "", "else", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "False", "\n", "", "", "", "", "", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "indices_replaced", "=", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.mask_tokens_cont": [[266, 305], ["inputs.clone", "slot_ids.clone", "inputs.clone", "inputs.clone.ne", "torch.sum", "start_seq.clone", "range", "torch.randint", "start_index[].item", "torch.tensor", "torch.cat", "torch.cat", "start_seq[].item", "mask_lens[].item", "seq_lens[].item", "tokenizer.convert_tokens_to_ids", "[].item", "seq_lens[].item", "[].item", "torch.ones().long", "torch.ones"], "function", ["None"], ["", "def", "mask_tokens_cont", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "    ", "\"\"\" mask continued n tokens \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "mask_inputs", "=", "inputs", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "no_padding_mask", "=", "labels", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "seq_lens", "=", "torch", ".", "sum", "(", "no_padding_mask", ",", "dim", "=", "-", "1", ")", "\n", "mask_lens", "=", "(", "seq_lens", "*", "args", ".", "mlm_probability", ")", ".", "int", "(", ")", "+", "1", "\n", "start_seq", "=", "seq_lens", "\n", "start_index", "=", "start_seq", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "        ", "start_index", "[", "i", "]", "=", "torch", ".", "randint", "(", "start_seq", "[", "i", "]", ".", "item", "(", ")", ",", "(", "1", ",", ")", ")", "\n", "start_tmp", "=", "start_index", "[", "i", "]", ".", "item", "(", ")", "\n", "end_tmp", "=", "start_tmp", "+", "mask_lens", "[", "i", "]", ".", "item", "(", ")", "\n", "# avoid mask part of a word", "\n", "if", "args", ".", "wwm", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "start_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "start_tmp", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "while", "True", ":", "\n", "                ", "if", "end_tmp", ">=", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "\n", "                    ", "break", "\n", "", "if", "cont_ids", "[", "i", "]", "[", "end_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "end_tmp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "", "labels", "[", "i", "]", "[", ":", "start_tmp", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "end_tmp", ":", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "]", "=", "-", "100", "\n", "seq_1", "=", "inputs", "[", "i", "]", "[", ":", "start_tmp", "]", "\n", "seq_2", "=", "torch", ".", "tensor", "(", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seq_3", "=", "inputs", "[", "i", "]", "[", "end_tmp", ":", "]", "\n", "tmp_mask", "=", "torch", ".", "cat", "(", "[", "seq_1", ",", "seq_2", ",", "seq_3", "]", ")", "\n", "pad_length", "=", "inputs", "[", "i", "]", ".", "shape", "[", "0", "]", "-", "tmp_mask", ".", "shape", "[", "0", "]", "\n", "mask_inputs", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "tmp_mask", ",", "torch", ".", "ones", "(", "pad_length", ")", ".", "long", "(", ")", "*", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "", "return", "mask_inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.train": [[307, 543], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_delex_to_raw_single.set_seed", "SummaryWriter", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "os.path.exists", "hasattr", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "outputs.to.eq", "inputs.to.ne", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "values.to.to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.item", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_delex_to_raw_single._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "total_loss.mean.mean", "total_loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "logger.info", "logger.info", "logger.info", "print", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_delex_to_raw_single._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_delex_to_raw_single.evaluate", "evaluate.items", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "value_ids", "=", "[", "s", "[", "2", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "value_ids", "=", "pad_sequence", "(", "value_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "False", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", ",", "value_ids", "]", "\n", "return", "data", "\n", "\n", "", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_epoch", "=", "0", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "lm_loss", ",", "logging_lm_loss", "=", "0.0", ",", "0.0", "\n", "sl_loss", ",", "logging_sl_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "outputs", ",", "values", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "attn_enc_mask", "=", "inputs", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "# print(inputs[0], outputs[0], values[0])", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]), tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "values", "=", "values", ".", "to", "(", "args", ".", "device", ")", "\n", "#attn_enc_mask = attn_enc_mask.to(args.device)", "\n", "model", ".", "train", "(", ")", "\n", "#preds = model(inputs, decoder_input_ids=outputs[:, :-1], lm_labels=labels[:, 1:], attention_mask=attn_enc_mask)", "\n", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ",", "value_mask", "=", "values", "[", ":", ",", "1", ":", "]", ")", "\n", "#preds = model(inputs, decoder_input_ids=outputs[:, :-1], lm_labels=labels[:, 1:])", "\n", "loss", "=", "preds", "[", "0", "]", "\n", "total_loss", "=", "loss", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "total_loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "total_loss", ".", "backward", "(", ")", "\n", "\n", "", "lm_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"lm_loss\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"slot_loss\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"training lm_loss: %.2f\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training sl_loss: %.2f\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training lr: %f\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ")", "\n", "logging_lm_loss", "=", "lm_loss", "\n", "logging_sl_loss", "=", "sl_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "print", "(", "global_step", ")", "\n", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "global_epoch", "+=", "1", "\n", "if", "args", ".", "save_steps", "==", "0", ":", "\n", "            ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_epoch", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "lm_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.evaluate": [[545, 612], ["run_delex_to_raw_single.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.DataParallel", "len", "outputs.to.eq", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "prefix", "=", "\"\"", ")", "->", "Dict", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", "]", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", ",", "eval_slot_loss", "=", "0.0", ",", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "outputs", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "preds", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "lm_loss", "=", "loss", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.get_slot_dict": [[614, 623], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.add_vocab": [[624, 633], ["enumerate", "open", "args.slot_dict.keys", "open", "word.strip", "f.write", "f.readlines"], "function", ["None"], ["", "def", "add_vocab", "(", "org_file", ",", "new_file", ",", "args", ")", ":", "\n", "    ", "with", "open", "(", "org_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "org_vocab", "=", "[", "word", ".", "strip", "(", ")", "for", "word", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_vocab", "=", "org_vocab", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "new_vocab", "[", "i", "+", "1", "]", "=", "'_'", "+", "w", "+", "'_'", "\n", "", "with", "open", "(", "new_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "w", "in", "new_vocab", ":", "\n", "            ", "f", ".", "write", "(", "w", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_delex_to_raw_single.main": [[634, 961], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_delex_to_raw_single.set_seed", "run_delex_to_raw_single.get_slot_dict", "len", "model_class.from_pretrained.to", "logger.info", "ValueError", "run_delex_to_raw_single._sorted_checkpoints", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "parser.parse_args.slot_dict.keys", "min", "model_class.from_pretrained", "logger.info", "model_class", "model_class.from_pretrained.crf_layer.set_device", "torch.distributed.barrier", "run_delex_to_raw_single.load_and_cache_examples", "run_delex_to_raw_single.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "len", "ValueError", "config_class.from_pretrained", "config_class", "tokenizer_class.from_pretrained", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "model_class.from_pretrained.crf_layer.set_device", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_delex_to_raw_single.evaluate", "dict", "results.update", "bool", "torch.distributed.get_rank", "model_class.from_pretrained.crf_layer.set_device", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "default", "=", "'bart'", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "'bart-large'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "# new added", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lambda_slot\"", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "\"multitask slot predict weight\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crf\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use crf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wwm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask the whole word\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_cont\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask continued k words\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--share_dec\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"share same decoder for lm and slot tagging\"", ")", "\n", "# slot_type_embedding related:", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_delex_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_delex.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_delex_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/val_delex.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/val_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_mask\"", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Used --should_continue but no checkpoint was found in --output_dir.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "1", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", ".", "format", "(", "tokenizer_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "# add vocab", "\n", "", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "#special_tokens_dict = {'additional_special_tokens': ['_' + k + '_' for k in args.slot_dict.keys()]}", "\n", "#tokenizer.add_special_tokens(special_tokens_dict)", "\n", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "\n", "# new class", "\n", "#emd_layer = model.resize_token_embeddings(len(tokenizer))", "\n", "#model.model.encoder.embed_tokens = emd_layer", "\n", "#model.model.decoder.embed_tokens = emd_layer", "\n", "", "if", "args", ".", "crf", ":", "\n", "        ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "if", "args", ".", "crf", ":", "\n", "            ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "if", "args", ".", "crf", ":", "\n", "                ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.LineByLineTextDataset.__init__": [[104, 120], ["os.path.isfile", "logger.info", "run_act_to_raw.LineByLineTextDataset.get_act_data", "open", "open", "open", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "line.strip", "line.strip", "line.strip", "f.read().splitlines", "f.readlines", "f.readlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.get_act_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "label_path", ":", "str", ",", "intent_path", ":", "str", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_acts", "=", "self", ".", "get_act_data", "(", "labels", ",", "examples", ",", "intents", ")", "\n", "self", ".", "examples", "=", "tokenizer", ".", "batch_encode_plus", "(", "examples", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "acts", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_acts", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.LineByLineTextDataset.get_act_data": [[121, 156], ["zip", "label.split.split.split", "example.split.split.split", "run_act_to_raw.split_intent_snips", "enumerate", "enumerate", "new_acts.append", "len", "len", "act.append", "re.sub", "re.sub", "act.append", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.split_intent_snips"], ["", "def", "get_act_data", "(", "self", ",", "labels", ",", "examples", ",", "intents", ")", ":", "\n", "        ", "new_acts", "=", "[", "]", "\n", "for", "label", ",", "example", ",", "intent", "in", "zip", "(", "labels", ",", "examples", ",", "intents", ")", ":", "\n", "            ", "label", "=", "label", ".", "split", "(", ")", "\n", "example", "=", "example", ".", "split", "(", ")", "\n", "# atis or snips", "\n", "#intent_str = split_intent_atis(intent)", "\n", "intent_str", "=", "split_intent_snips", "(", "intent", ")", "\n", "assert", "len", "(", "label", ")", "==", "len", "(", "example", ")", "\n", "act", "=", "[", "]", "\n", "tmp_str", ",", "tmp_label", "=", "''", ",", "''", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "example", ")", ":", "\n", "                ", "if", "tmp_str", "and", "tmp_label", "and", "label", "[", "i", "]", "[", "0", "]", "!=", "'I'", ":", "\n", "                    ", "act", ".", "append", "(", "[", "tmp_label", ",", "tmp_str", "]", ")", "\n", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                    ", "tmp_label", "=", "label", "[", "i", "]", "[", "2", ":", "]", "\n", "tmp_str", "=", "w", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'I'", ":", "\n", "                    ", "tmp_str", "+=", "' '", "+", "w", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "if", "tmp_str", "and", "tmp_label", ":", "\n", "                ", "act", ".", "append", "(", "[", "tmp_label", ",", "tmp_str", "]", ")", "\n", "", "act_str", "=", "' '", "+", "intent_str", "+", "' ( '", "\n", "for", "i", ",", "(", "slot", ",", "value", ")", "in", "enumerate", "(", "act", ")", ":", "\n", "                ", "slot", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "slot", ")", "\n", "slot", "=", "re", ".", "sub", "(", "'\\.'", ",", "' '", ",", "slot", ")", "\n", "act_str", "+=", "slot", "+", "' = '", "+", "value", "\n", "if", "i", "<", "len", "(", "act", ")", "-", "1", ":", "\n", "                    ", "act_str", "+=", "' ; '", "\n", "", "", "act_str", "+=", "')'", "\n", "new_acts", ".", "append", "(", "act_str", ")", "\n", "", "return", "new_acts", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.LineByLineTextDataset.__len__": [[158, 160], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.LineByLineTextDataset.__getitem__": [[161, 164], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "acts", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.convert_label_to_id": [[69, 76], ["token_type_ids.append"], "function", ["None"], ["def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "slot_dict", "[", "'<pad>'", "]", "=", "-", "100", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.convert_id_to_label": [[77, 85], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "new_dict", "[", "-", "100", "]", "=", "'<pad>'", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.split_intent_snips": [[86, 93], ["list", "enumerate", "c.isupper", "c.lower"], "function", ["None"], ["", "def", "split_intent_snips", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "list", "(", "intent", ")", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "intent", ")", ":", "\n", "        ", "if", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "intent", "[", "i", "]", "=", "' '", "+", "c", ".", "lower", "(", ")", "\n", "", "", "intent", "=", "''", ".", "join", "(", "intent", ")", ".", "strip", "(", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.split_intent_atis": [[94, 102], ["re.split", "new_intent.append"], "function", ["None"], ["", "def", "split_intent_atis", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "re", ".", "split", "(", "r'_|#'", ",", "intent", ")", "\n", "new_intent", "=", "[", "]", "\n", "for", "w", "in", "intent", ":", "\n", "        ", "if", "w", "!=", "'atis'", ":", "\n", "            ", "new_intent", ".", "append", "(", "w", ")", "\n", "", "", "intent", "=", "' '", ".", "join", "(", "new_intent", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.load_and_cache_examples": [[167, 173], ["run_act_to_raw.LineByLineTextDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", "\n", "intent_path", "=", "args", ".", "eval_intent_file", "if", "evaluate", "else", "args", ".", "train_intent_file", "\n", "label_path", "=", "args", ".", "eval_label_file", "if", "evaluate", "else", "args", ".", "train_label_file", "\n", "return", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "label_path", "=", "label_path", ",", "\n", "intent_path", "=", "intent_path", ",", "block_size", "=", "args", ".", "block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.set_seed": [[175, 181], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw._sorted_checkpoints": [[183, 199], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw._rotate_checkpoints": [[201, 217], ["run_act_to_raw._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.mask_tokens": [[219, 250], ["inputs.clone", "slot_ids.clone", "torch.full", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "inputs.clone.eq", "torch.full.masked_fill_", "range", "torch.bernoulli", "range", "[].item"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "\n", "    ", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "seq_len", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "if", "args", ".", "wwm", ":", "\n", "        ", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "last_mask_flag", "=", "False", "\n", "for", "j", "in", "range", "(", "seq_len", ")", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "j", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                    ", "if", "masked_indices", "[", "i", "]", "[", "j", "]", ":", "\n", "                        ", "last_mask_flag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "last_mask_flag", "=", "False", "\n", "", "", "else", ":", "\n", "                    ", "if", "last_mask_flag", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "True", "\n", "", "else", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "False", "\n", "", "", "", "", "", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "indices_replaced", "=", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.mask_tokens_cont": [[251, 290], ["inputs.clone", "slot_ids.clone", "inputs.clone", "inputs.clone.ne", "torch.sum", "start_seq.clone", "range", "torch.randint", "start_index[].item", "torch.tensor", "torch.cat", "torch.cat", "start_seq[].item", "mask_lens[].item", "seq_lens[].item", "tokenizer.convert_tokens_to_ids", "[].item", "seq_lens[].item", "[].item", "torch.ones().long", "torch.ones"], "function", ["None"], ["", "def", "mask_tokens_cont", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "    ", "\"\"\" mask continued n tokens \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "mask_inputs", "=", "inputs", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "no_padding_mask", "=", "labels", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "seq_lens", "=", "torch", ".", "sum", "(", "no_padding_mask", ",", "dim", "=", "-", "1", ")", "\n", "mask_lens", "=", "(", "seq_lens", "*", "args", ".", "mlm_probability", ")", ".", "int", "(", ")", "+", "1", "\n", "start_seq", "=", "seq_lens", "\n", "start_index", "=", "start_seq", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "        ", "start_index", "[", "i", "]", "=", "torch", ".", "randint", "(", "start_seq", "[", "i", "]", ".", "item", "(", ")", ",", "(", "1", ",", ")", ")", "\n", "start_tmp", "=", "start_index", "[", "i", "]", ".", "item", "(", ")", "\n", "end_tmp", "=", "start_tmp", "+", "mask_lens", "[", "i", "]", ".", "item", "(", ")", "\n", "# avoid mask part of a word", "\n", "if", "args", ".", "wwm", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "start_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "start_tmp", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "while", "True", ":", "\n", "                ", "if", "end_tmp", ">=", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "\n", "                    ", "break", "\n", "", "if", "cont_ids", "[", "i", "]", "[", "end_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "end_tmp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "", "labels", "[", "i", "]", "[", ":", "start_tmp", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "end_tmp", ":", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "]", "=", "-", "100", "\n", "seq_1", "=", "inputs", "[", "i", "]", "[", ":", "start_tmp", "]", "\n", "seq_2", "=", "torch", ".", "tensor", "(", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seq_3", "=", "inputs", "[", "i", "]", "[", "end_tmp", ":", "]", "\n", "tmp_mask", "=", "torch", ".", "cat", "(", "[", "seq_1", ",", "seq_2", ",", "seq_3", "]", ")", "\n", "pad_length", "=", "inputs", "[", "i", "]", ".", "shape", "[", "0", "]", "-", "tmp_mask", ".", "shape", "[", "0", "]", "\n", "mask_inputs", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "tmp_mask", ",", "torch", ".", "ones", "(", "pad_length", ")", ".", "long", "(", ")", "*", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "", "return", "mask_inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.train": [[292, 523], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_act_to_raw.set_seed", "SummaryWriter", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "os.path.exists", "hasattr", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "outputs.to.eq", "inputs.to.ne", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "attn_enc_mask.to.to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.item", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_act_to_raw._rotate_checkpoints", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "total_loss.mean.mean", "total_loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "hasattr", "os.path.join", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "logger.info", "logger.info", "logger.info", "print", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_act_to_raw._rotate_checkpoints", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_act_to_raw.evaluate", "evaluate.items", "hasattr", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", "]", "\n", "return", "data", "\n", "\n", "", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_epoch", "=", "0", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "lm_loss", ",", "logging_lm_loss", "=", "0.0", ",", "0.0", "\n", "sl_loss", ",", "logging_sl_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "outputs", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "attn_enc_mask", "=", "inputs", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]), tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_enc_mask", "=", "attn_enc_mask", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "#preds = model(inputs, decoder_input_ids=outputs[:, :-1], lm_labels=labels[:, 1:], attention_mask=attn_enc_mask)", "\n", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "preds", "[", "0", "]", "\n", "total_loss", "=", "loss", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "total_loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "total_loss", ".", "backward", "(", ")", "\n", "\n", "", "lm_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"lm_loss\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"slot_loss\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"training lm_loss: %.2f\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training sl_loss: %.2f\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training lr: %f\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ")", "\n", "logging_lm_loss", "=", "lm_loss", "\n", "logging_sl_loss", "=", "sl_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "print", "(", "global_step", ")", "\n", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "# torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))", "\n", "# torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))", "\n", "# logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "global_epoch", "+=", "1", "\n", "if", "args", ".", "save_steps", "==", "0", ":", "\n", "            ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_epoch", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "# torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))", "\n", "# torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))", "\n", "# logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)", "\n", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "lm_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.evaluate": [[525, 592], ["run_act_to_raw.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.DataParallel", "len", "outputs.to.eq", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "prefix", "=", "\"\"", ")", "->", "Dict", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", "]", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", ",", "eval_slot_loss", "=", "0.0", ",", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "outputs", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "preds", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "lm_loss", "=", "loss", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.get_slot_dict": [[594, 603], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.add_vocab": [[604, 613], ["enumerate", "open", "args.slot_dict.keys", "open", "word.strip", "f.write", "f.readlines"], "function", ["None"], ["", "def", "add_vocab", "(", "org_file", ",", "new_file", ",", "args", ")", ":", "\n", "    ", "with", "open", "(", "org_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "org_vocab", "=", "[", "word", ".", "strip", "(", ")", "for", "word", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_vocab", "=", "org_vocab", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "new_vocab", "[", "i", "+", "1", "]", "=", "'_'", "+", "w", "+", "'_'", "\n", "", "with", "open", "(", "new_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "w", "in", "new_vocab", ":", "\n", "            ", "f", ".", "write", "(", "w", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_raw.main": [[614, 938], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_act_to_raw.set_seed", "run_act_to_raw.get_slot_dict", "len", "model_class.from_pretrained.to", "logger.info", "ValueError", "run_act_to_raw._sorted_checkpoints", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "parser.parse_args.slot_dict.keys", "min", "model_class.from_pretrained", "logger.info", "model_class", "model_class.from_pretrained.crf_layer.set_device", "torch.distributed.barrier", "run_act_to_raw.load_and_cache_examples", "run_act_to_raw.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "len", "ValueError", "config_class.from_pretrained", "config_class", "tokenizer_class.from_pretrained", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "model_class.from_pretrained.crf_layer.set_device", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_act_to_raw.evaluate", "dict", "results.update", "bool", "torch.distributed.get_rank", "model_class.from_pretrained.crf_layer.set_device", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "default", "=", "'bart'", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "'bart-large'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "# new added", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lambda_slot\"", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "\"multitask slot predict weight\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crf\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use crf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wwm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask the whole word\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_cont\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask continued k words\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--share_dec\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"share same decoder for lm and slot tagging\"", ")", "\n", "# slot_type_embedding related:", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_intent_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_intent.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_intent_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/atis/val_intent.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/atis/val_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Used --should_continue but no checkpoint was found in --output_dir.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "1", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", ".", "format", "(", "tokenizer_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "# add vocab", "\n", "", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "\n", "# new class", "\n", "#emd_layer = model.resize_token_embeddings(len(tokenizer))", "\n", "#model.model.encoder.embed_tokens = emd_layer", "\n", "#model.model.decoder.embed_tokens = emd_layer", "\n", "", "if", "args", ".", "crf", ":", "\n", "        ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "if", "args", ".", "crf", ":", "\n", "            ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "if", "args", ".", "crf", ":", "\n", "                ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.convert_label": [[9, 20], ["range", "len"], "function", ["None"], ["def", "convert_label", "(", "label", ")", ":", "\n", "    ", "last_label", "=", "'O'", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "        ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "label", "[", "i", "]", "==", "last_label", ":", "\n", "            ", "label", "[", "i", "]", "=", "'I-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", ":", "\n", "            ", "last_label", "=", "label", "[", "i", "]", "\n", "label", "[", "i", "]", "=", "'B-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "last_label", "=", "'O'", "\n", "", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.transfer_separate_data": [[21, 34], ["zip", "open", "open", "open", "open", "data.append", "line.strip", "line.strip", "line.strip", "line.strip", "f.readlines", "f.readlines", "f.readlines", "f.readlines"], "function", ["None"], ["", "def", "transfer_separate_data", "(", "raw_txt", ",", "label_txt", ",", "intent_txt", ",", "delex_txt", ")", ":", "\n", "    ", "with", "open", "(", "raw_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "label_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "intent_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "delex_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "delex_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "data", "=", "[", "]", "\n", "for", "t", ",", "l", ",", "i", ",", "d", "in", "zip", "(", "raw_data", ",", "label_data", ",", "intent_data", ",", "delex_data", ")", ":", "\n", "        ", "data", ".", "append", "(", "[", "t", ",", "l", ",", "i", ",", "d", "]", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.get_slot_dict": [[35, 63], ["slot_dict.items", "raw.split.split", "label.split.split", "enumerate", "list", "slot_dict[].add", "slot_dict[].add", "slot_dict.keys", "set", "slot_dict[].add"], "function", ["None"], ["", "def", "get_slot_dict", "(", "data", ")", ":", "\n", "# data = [raw, label, intent]", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "for", "raw", ",", "label", ",", "_", ",", "_", "in", "data", ":", "\n", "        ", "raw", "=", "raw", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "raw", ")", ":", "\n", "            ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                ", "if", "tmp_str", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "word", "\n", "tmp_label", "=", "label", "[", "i", "]", "[", "2", ":", "]", "\n", "if", "tmp_label", "not", "in", "slot_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", "=", "set", "(", ")", "\n", "", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'I'", ":", "\n", "                ", "tmp_str", "=", "tmp_str", "+", "' '", "+", "word", "\n", "", "else", ":", "\n", "                ", "if", "tmp_str", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "", "", "if", "tmp_str", ":", "\n", "            ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", ":", "\n", "        ", "slot_dict", "[", "k", "]", "=", "list", "(", "v", ")", "\n", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.filter_data": [[65, 124], ["print", "zip", "print", "len", "enumerate", "len", "len", "len", "new_label.append", "convert_label.append", "filter_single_data.convert_label", "gen_data.append", "delex.append", "delex.append", "len", "convert_label.append", "value.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.convert_label"], ["", "def", "filter_data", "(", "src", ",", "tgt", ",", "lbl", ",", "intents", ")", ":", "\n", "    ", "gen_data", "=", "[", "]", "\n", "count", "=", "1", "\n", "print", "(", "len", "(", "src", ")", ")", "\n", "for", "org", ",", "gen", ",", "lb", ",", "it", "in", "zip", "(", "src", ",", "tgt", ",", "lbl", ",", "intents", ")", ":", "\n", "        ", "delex", "=", "[", "]", "\n", "new_label", "=", "[", "]", "\n", "str", "=", "''", "\n", "for", "w", "in", "org", ":", "\n", "            ", "if", "w", "==", "'_'", "and", "str", "==", "''", ":", "\n", "                ", "str", "=", "'_'", "\n", "", "elif", "w", "==", "'_'", "and", "str", "!=", "''", ":", "\n", "                ", "delex", ".", "append", "(", "str", ")", "\n", "str", "=", "''", "\n", "", "elif", "str", "!=", "''", ":", "\n", "                ", "str", "+=", "w", "+", "'_'", "\n", "", "else", ":", "\n", "                ", "delex", ".", "append", "(", "w", ")", "\n", "", "", "for", "l", "in", "lb", ":", "\n", "            ", "if", "l", "[", "0", "]", "==", "'I'", "and", "'_'", "+", "l", "[", "2", ":", "]", "+", "'_'", "in", "delex", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "new_label", ".", "append", "(", "l", ")", "\n", "", "", "org", "=", "delex", "\n", "org", "=", "[", "'<s>'", "]", "+", "org", "+", "[", "'</s>'", "]", "\n", "gen", "=", "[", "'<s>'", "]", "+", "gen", "+", "[", "'</s>'", "]", "\n", "lb", "=", "[", "'O'", "]", "+", "new_label", "+", "[", "'O'", "]", "\n", "assert", "len", "(", "org", ")", "==", "len", "(", "lb", ")", "\n", "gen_index", "=", "0", "\n", "label", "=", "[", "]", "\n", "value", ",", "target_label", "=", "[", "]", ",", "''", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "org", ")", ":", "\n", "            ", "if", "w", "==", "gen", "[", "gen_index", "]", ":", "\n", "                ", "gen_index", "+=", "1", "\n", "label", ".", "append", "(", "lb", "[", "i", "]", ")", "\n", "continue", "\n", "", "elif", "org", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "org", "[", "i", "+", "1", "]", "[", "0", "]", "!=", "'_'", ":", "\n", "                ", "while", "gen_index", "<", "len", "(", "gen", ")", ":", "\n", "                    ", "if", "gen", "[", "gen_index", "]", "==", "org", "[", "i", "+", "1", "]", ":", "\n", "                        ", "break", "\n", "", "label", ".", "append", "(", "org", "[", "i", "]", ")", "\n", "value", ".", "append", "(", "gen", "[", "gen_index", "]", ")", "\n", "target_label", "=", "org", "[", "i", "]", "\n", "gen_index", "+=", "1", "\n", "# no matching slot, filter out", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "# continuous slot", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "#print(count)", "\n", "            ", "if", "target_label", ":", "\n", "                ", "label", "=", "convert_label", "(", "label", ")", "\n", "value", "=", "' '", ".", "join", "(", "value", ")", "\n", "gen_data", ".", "append", "(", "[", "gen", "[", "1", ":", "-", "1", "]", ",", "label", "[", "1", ":", "-", "1", "]", ",", "it", ",", "value", ",", "target_label", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "", "", "count", "+=", "1", "\n", "", "print", "(", "len", "(", "gen_data", ")", ")", "\n", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.get_slot_value_dict": [[125, 174], ["zip", "new_dict.items", "enumerate", "list", "delex.append", "new_dict.keys", "new_dict[].add", "set", "delex.append", "len", "slot_value.strip", "slot_value.strip"], "function", ["None"], ["", "def", "get_slot_value_dict", "(", "src", ",", "tgt", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "org", ",", "gen", "in", "zip", "(", "src", ",", "tgt", ")", ":", "\n", "        ", "delex", "=", "[", "]", "\n", "slot_type", "=", "''", "\n", "str", "=", "''", "\n", "for", "w", "in", "org", ":", "\n", "            ", "if", "w", "==", "'_'", "and", "str", "==", "''", ":", "\n", "                ", "str", "=", "'_'", "\n", "", "elif", "w", "==", "'_'", "and", "str", "!=", "''", ":", "\n", "                ", "delex", ".", "append", "(", "str", ")", "\n", "slot_type", "=", "str", "\n", "str", "=", "''", "\n", "", "elif", "str", "!=", "''", ":", "\n", "                ", "str", "+=", "w", "+", "'_'", "\n", "", "else", ":", "\n", "                ", "delex", ".", "append", "(", "w", ")", "\n", "", "", "org", "=", "delex", "\n", "org", "=", "[", "'<s>'", "]", "+", "org", "+", "[", "'</s>'", "]", "\n", "gen", "=", "[", "'<s>'", "]", "+", "gen", "+", "[", "'</s>'", "]", "\n", "gen_index", "=", "0", "\n", "slot_value", "=", "''", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "org", ")", ":", "\n", "            ", "if", "w", "==", "gen", "[", "gen_index", "]", ":", "\n", "                ", "gen_index", "+=", "1", "\n", "continue", "\n", "", "elif", "org", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "org", "[", "i", "+", "1", "]", "[", "0", "]", "!=", "'_'", ":", "\n", "                ", "while", "gen_index", "<", "len", "(", "gen", ")", ":", "\n", "                    ", "if", "gen", "[", "gen_index", "]", "==", "org", "[", "i", "+", "1", "]", ":", "\n", "                        ", "break", "\n", "", "slot_value", "+=", "gen", "[", "gen_index", "]", "+", "' '", "\n", "gen_index", "+=", "1", "\n", "# no matching slot, filter out", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "# continuous slot", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "            ", "if", "slot_type", "and", "slot_value", ":", "\n", "                ", "if", "slot_type", "in", "new_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "new_dict", "[", "slot_type", "]", ".", "add", "(", "slot_value", ".", "strip", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_dict", "[", "slot_type", "]", "=", "[", "slot_value", ".", "strip", "(", ")", "]", "\n", "new_dict", "[", "slot_type", "]", "=", "set", "(", "new_dict", "[", "slot_type", "]", ")", "\n", "", "", "", "", "for", "k", ",", "v", "in", "new_dict", ".", "items", "(", ")", ":", "\n", "        ", "new_dict", "[", "k", "]", "=", "list", "(", "v", ")", "\n", "#print(new_dict)", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.clean_repeat": [[175, 198], ["data_dict.items", "print", "print", "random.shuffle", "len", "len", "wanted_data.append", "data_dict.keys", "final_data.append", "len", "len"], "function", ["None"], ["", "def", "clean_repeat", "(", "raw_data", ",", "gen_data", ",", "slot_dict", ")", ":", "\n", "    ", "data_dict", "=", "{", "}", "\n", "final_data", "=", "[", "]", "\n", "wanted_data", "=", "[", "]", "\n", "count", "=", "0.", "\n", "for", "txt", "in", "raw_data", ":", "\n", "        ", "data_dict", "[", "txt", "]", "=", "[", "''", ",", "''", "]", "\n", "", "for", "txt", ",", "label", ",", "intent", ",", "value", ",", "target_label", "in", "gen_data", ":", "\n", "        ", "txt", "=", "' '", ".", "join", "(", "txt", ")", "\n", "label", "=", "' '", ".", "join", "(", "label", ")", "\n", "if", "value", "not", "in", "slot_dict", "[", "target_label", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "wanted_data", ".", "append", "(", "[", "txt", ",", "label", ",", "intent", "]", ")", "\n", "", "if", "txt", "not", "in", "data_dict", ".", "keys", "(", ")", ":", "\n", "            ", "data_dict", "[", "txt", "]", "=", "[", "label", ",", "intent", "]", "\n", "", "", "for", "k", ",", "v", "in", "data_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "v", "[", "0", "]", "!=", "''", ":", "\n", "            ", "final_data", ".", "append", "(", "[", "k", ",", "v", "[", "0", "]", ",", "v", "[", "1", "]", "]", ")", "\n", "", "", "print", "(", "len", "(", "final_data", ")", ")", "\n", "print", "(", "count", ",", "len", "(", "gen_data", ")", ",", "count", "/", "len", "(", "gen_data", ")", ")", "\n", "# extract 1308 samples", "\n", "random", ".", "shuffle", "(", "final_data", ")", "\n", "return", "final_data", "[", ":", "len", "(", "raw_data", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_single_data.slot_replace": [[199, 216], ["zip", "gen_data.append", "random.choice", "random.choice.split", "new_text.append", "new_label.append", "len", "len", "len", "random.choice.split"], "function", ["None"], ["", "def", "slot_replace", "(", "delex_data", ",", "label_data", ",", "slot_dict", ")", ":", "\n", "    ", "gen_data", "=", "[", "]", "\n", "for", "delex", ",", "label", "in", "zip", "(", "delex_data", ",", "label_data", ")", ":", "\n", "#delex = delex.split()", "\n", "        ", "new_text", ",", "new_label", "=", "[", "]", ",", "[", "]", "\n", "for", "w", "in", "delex", ":", "\n", "            ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                ", "value", "=", "random", ".", "choice", "(", "slot_dict", "[", "w", "]", ")", "\n", "new_text", "+=", "value", ".", "split", "(", ")", "\n", "new_label", "+=", "[", "'B-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "\n", "new_label", "+=", "[", "'I-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "*", "(", "len", "(", "value", ".", "split", "(", ")", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "new_text", ".", "append", "(", "w", ")", "\n", "new_label", ".", "append", "(", "'O'", ")", "\n", "", "assert", "len", "(", "new_label", ")", "==", "len", "(", "new_text", ")", "\n", "", "gen_data", ".", "append", "(", "[", "' '", ".", "join", "(", "new_text", ")", ",", "' '", ".", "join", "(", "new_label", ")", "]", ")", "\n", "", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.get_count": [[16, 22], ["None"], "function", ["None"], ["", "", "def", "get_count", "(", "slot", ",", "text", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "w", "in", "text", ":", "\n", "        ", "if", "w", "==", "slot", ":", "\n", "            ", "count", "+=", "1", "\n", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.convert_label": [[23, 34], ["range", "len"], "function", ["None"], ["", "def", "convert_label", "(", "label", ")", ":", "\n", "    ", "last_label", "=", "'O'", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "        ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "label", "[", "i", "]", "==", "last_label", ":", "\n", "            ", "label", "[", "i", "]", "=", "'I-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", ":", "\n", "            ", "last_label", "=", "label", "[", "i", "]", "\n", "label", "[", "i", "]", "=", "'B-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "last_label", "=", "'O'", "\n", "", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.match_value": [[35, 61], ["label.copy", "enumerate", "len", "label.copy", "label.copy"], "function", ["None"], ["", "def", "match_value", "(", "slot", ",", "value", ",", "raw", ",", "label", ")", ":", "\n", "    ", "flag", "=", "False", "\n", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "compare_count", "=", "0", "\n", "# atis", "\n", "#slot = slot_change['_'.join(slot)]", "\n", "# snips", "\n", "slot", "=", "'_'", ".", "join", "(", "slot", ")", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "raw", ")", ":", "\n", "        ", "if", "w", "==", "value", "[", "compare_count", "]", "and", "label", "[", "i", "]", "==", "'O'", ":", "\n", "            ", "if", "compare_count", "==", "0", ":", "\n", "                ", "new_label", "[", "i", "]", "=", "'B-'", "+", "slot", "\n", "", "else", ":", "\n", "                ", "new_label", "[", "i", "]", "=", "'I-'", "+", "slot", "\n", "", "compare_count", "+=", "1", "\n", "if", "compare_count", "==", "len", "(", "value", ")", ":", "\n", "                ", "flag", "=", "True", "\n", "break", "\n", "", "", "elif", "w", "==", "value", "[", "0", "]", "and", "label", "[", "i", "]", "==", "'O'", ":", "\n", "            ", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "new_label", "[", "i", "]", "=", "'B-'", "+", "slot", "\n", "compare_count", "=", "1", "\n", "", "else", ":", "\n", "            ", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "compare_count", "=", "0", "\n", "", "", "return", "new_label", ",", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.filter_data": [[62, 82], ["zip", "print", "re.sub", "raw.split.split", "act.split.split", "len", "filter_act_delex.get_count", "gen_data.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.get_count"], ["", "def", "filter_data", "(", "acts", ",", "raws", ")", ":", "\n", "    ", "gen_data", "=", "[", "]", "\n", "for", "act", ",", "raw", "in", "zip", "(", "acts", ",", "raws", ")", ":", "\n", "        ", "raw", "=", "re", ".", "sub", "(", "'<s>|</s>|<pad>'", ",", "''", ",", "raw", ")", "\n", "raw", "=", "raw", ".", "split", "(", ")", "\n", "act", "=", "act", ".", "split", "(", ")", "\n", "for", "w", "in", "raw", ":", "\n", "            ", "if", "w", "[", "0", "]", "==", "'_'", "and", "w", "not", "in", "act", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "            ", "for", "slot", "in", "act", ":", "\n", "                ", "if", "slot", "not", "in", "raw", ":", "\n", "                    ", "break", "\n", "", "count", "=", "get_count", "(", "slot", ",", "raw", ")", "\n", "if", "count", ">", "1", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "gen_data", ".", "append", "(", "' '", ".", "join", "(", "raw", ")", ")", "\n", "", "", "", "print", "(", "'matching data: '", ",", "len", "(", "gen_data", ")", ")", "\n", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.get_slot_value_dict": [[83, 132], ["zip", "new_dict.items", "enumerate", "list", "delex.append", "new_dict.keys", "new_dict[].add", "set", "delex.append", "len", "slot_value.strip", "slot_value.strip"], "function", ["None"], ["", "def", "get_slot_value_dict", "(", "src", ",", "tgt", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "org", ",", "gen", "in", "zip", "(", "src", ",", "tgt", ")", ":", "\n", "        ", "delex", "=", "[", "]", "\n", "slot_type", "=", "''", "\n", "str", "=", "''", "\n", "for", "w", "in", "org", ":", "\n", "            ", "if", "w", "==", "'_'", "and", "str", "==", "''", ":", "\n", "                ", "str", "=", "'_'", "\n", "", "elif", "w", "==", "'_'", "and", "str", "!=", "''", ":", "\n", "                ", "delex", ".", "append", "(", "str", ")", "\n", "slot_type", "=", "str", "\n", "str", "=", "''", "\n", "", "elif", "str", "!=", "''", ":", "\n", "                ", "str", "+=", "w", "+", "'_'", "\n", "", "else", ":", "\n", "                ", "delex", ".", "append", "(", "w", ")", "\n", "", "", "org", "=", "delex", "\n", "org", "=", "[", "'<s>'", "]", "+", "org", "+", "[", "'</s>'", "]", "\n", "gen", "=", "[", "'<s>'", "]", "+", "gen", "+", "[", "'</s>'", "]", "\n", "gen_index", "=", "0", "\n", "slot_value", "=", "''", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "org", ")", ":", "\n", "            ", "if", "w", "==", "gen", "[", "gen_index", "]", ":", "\n", "                ", "gen_index", "+=", "1", "\n", "continue", "\n", "", "elif", "org", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "org", "[", "i", "+", "1", "]", "[", "0", "]", "!=", "'_'", ":", "\n", "                ", "while", "gen_index", "<", "len", "(", "gen", ")", ":", "\n", "                    ", "if", "gen", "[", "gen_index", "]", "==", "org", "[", "i", "+", "1", "]", ":", "\n", "                        ", "break", "\n", "", "slot_value", "+=", "gen", "[", "gen_index", "]", "+", "' '", "\n", "gen_index", "+=", "1", "\n", "# no matching slot, filter out", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "# continuous slot", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "            ", "if", "slot_type", "and", "slot_value", ":", "\n", "                ", "if", "slot_type", "in", "new_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "new_dict", "[", "slot_type", "]", ".", "add", "(", "slot_value", ".", "strip", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "new_dict", "[", "slot_type", "]", "=", "[", "slot_value", ".", "strip", "(", ")", "]", "\n", "new_dict", "[", "slot_type", "]", "=", "set", "(", "new_dict", "[", "slot_type", "]", ")", "\n", "", "", "", "", "for", "k", ",", "v", "in", "new_dict", ".", "items", "(", ")", ":", "\n", "        ", "new_dict", "[", "k", "]", "=", "list", "(", "v", ")", "\n", "#print(new_dict)", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.delex_text": [[133, 146], ["txt.split.split", "label.split.split", "zip", "len", "len", "delex.append", "delex.append"], "function", ["None"], ["", "def", "delex_text", "(", "txt", ",", "label", ")", ":", "\n", "    ", "txt", "=", "txt", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "delex", "=", "[", "]", "\n", "assert", "len", "(", "txt", ")", "==", "len", "(", "label", ")", "\n", "for", "t", ",", "l", "in", "zip", "(", "txt", ",", "label", ")", ":", "\n", "        ", "if", "l", "[", "0", "]", "==", "'B'", ":", "\n", "            ", "delex", ".", "append", "(", "'_'", "+", "l", "[", "2", ":", "]", "+", "'_'", ")", "\n", "", "elif", "l", "==", "'O'", ":", "\n", "            ", "delex", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "", "return", "' '", ".", "join", "(", "delex", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.clean_repeat": [[148, 164], ["enumerate", "print", "random.shuffle", "len", "data_dict.keys", "final_data.append", "len"], "function", ["None"], ["", "def", "clean_repeat", "(", "raw_data", ",", "delex_data", ",", "gen_data", ")", ":", "\n", "    ", "data_dict", "=", "{", "}", "\n", "final_data", "=", "[", "]", "\n", "# for txt in raw_data:", "\n", "#     data_dict[txt] = ''", "\n", "# all same delex delete", "\n", "for", "i", ",", "txt", "in", "enumerate", "(", "delex_data", ")", ":", "\n", "        ", "data_dict", "[", "txt", "]", "=", "''", "\n", "", "for", "txt", "in", "gen_data", ":", "\n", "        ", "if", "txt", "not", "in", "data_dict", ".", "keys", "(", ")", ":", "\n", "            ", "data_dict", "[", "txt", "]", "=", "''", "\n", "final_data", ".", "append", "(", "txt", ")", "\n", "", "", "print", "(", "'different data: '", ",", "len", "(", "final_data", ")", ")", "\n", "# extract 1308 samples", "\n", "random", ".", "shuffle", "(", "final_data", ")", "\n", "return", "final_data", "[", ":", "len", "(", "raw_data", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_delex.slot_replace": [[165, 182], ["zip", "gen_data.append", "random.choice", "random.choice.split", "new_text.append", "new_label.append", "len", "len", "len", "random.choice.split"], "function", ["None"], ["", "def", "slot_replace", "(", "delex_data", ",", "label_data", ",", "slot_dict", ")", ":", "\n", "    ", "gen_data", "=", "[", "]", "\n", "for", "delex", ",", "label", "in", "zip", "(", "delex_data", ",", "label_data", ")", ":", "\n", "#delex = delex.split()", "\n", "        ", "new_text", ",", "new_label", "=", "[", "]", ",", "[", "]", "\n", "for", "w", "in", "delex", ":", "\n", "            ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                ", "value", "=", "random", ".", "choice", "(", "slot_dict", "[", "w", "]", ")", "\n", "new_text", "+=", "value", ".", "split", "(", ")", "\n", "new_label", "+=", "[", "'B-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "\n", "new_label", "+=", "[", "'I-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "*", "(", "len", "(", "value", ".", "split", "(", ")", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "new_text", ".", "append", "(", "w", ")", "\n", "new_label", ".", "append", "(", "'O'", ")", "\n", "", "assert", "len", "(", "new_label", ")", "==", "len", "(", "new_text", ")", "\n", "", "gen_data", ".", "append", "(", "[", "' '", ".", "join", "(", "new_text", ")", ",", "' '", ".", "join", "(", "new_label", ")", "]", ")", "\n", "", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.convert_label": [[16, 27], ["range", "len"], "function", ["None"], ["", "", "def", "convert_label", "(", "label", ")", ":", "\n", "    ", "last_label", "=", "'O'", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "        ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "label", "[", "i", "]", "==", "last_label", ":", "\n", "            ", "label", "[", "i", "]", "=", "'I-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", ":", "\n", "            ", "last_label", "=", "label", "[", "i", "]", "\n", "label", "[", "i", "]", "=", "'B-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "last_label", "=", "'O'", "\n", "", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.match_value": [[28, 55], ["label.copy", "enumerate", "len", "label.copy", "label.copy"], "function", ["None"], ["", "def", "match_value", "(", "slot", ",", "value", ",", "raw", ",", "label", ",", "args", ")", ":", "\n", "    ", "flag", "=", "False", "\n", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "compare_count", "=", "0", "\n", "# atis", "\n", "if", "'atis'", "in", "args", ".", "raw_file", ":", "\n", "        ", "slot", "=", "slot_change", "[", "'_'", ".", "join", "(", "slot", ")", "]", "\n", "", "else", ":", "\n", "        ", "slot", "=", "'_'", ".", "join", "(", "slot", ")", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "raw", ")", ":", "\n", "        ", "if", "w", "==", "value", "[", "compare_count", "]", "and", "label", "[", "i", "]", "==", "'O'", ":", "\n", "            ", "if", "compare_count", "==", "0", ":", "\n", "                ", "new_label", "[", "i", "]", "=", "'B-'", "+", "slot", "\n", "", "else", ":", "\n", "                ", "new_label", "[", "i", "]", "=", "'I-'", "+", "slot", "\n", "", "compare_count", "+=", "1", "\n", "if", "compare_count", "==", "len", "(", "value", ")", ":", "\n", "                ", "flag", "=", "True", "\n", "break", "\n", "", "", "elif", "w", "==", "value", "[", "0", "]", "and", "label", "[", "i", "]", "==", "'O'", ":", "\n", "            ", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "new_label", "[", "i", "]", "=", "'B-'", "+", "slot", "\n", "compare_count", "=", "1", "\n", "", "else", ":", "\n", "            ", "new_label", "=", "label", ".", "copy", "(", ")", "\n", "compare_count", "=", "0", "\n", "", "", "return", "new_label", ",", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.too_short": [[56, 62], ["len", "len"], "function", ["None"], ["", "def", "too_short", "(", "raw", ",", "tmp_values", ")", ":", "\n", "    ", "tmp_values", "=", "' '", ".", "join", "(", "tmp_values", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "raw", ")", "<=", "len", "(", "tmp_values", ")", "+", "1", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.filter_data": [[63, 99], ["slot_dict.items", "zip", "print", "raw.split.split", "act.split.split", "range", "filter_act_data.too_short", "len", "len", "int", "slot_values.append", "tmp_values.append", "filter_act_data.match_value", "gen_data.append", "len", "len", "act[].split", "act[].split"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.too_short", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.match_value"], ["", "", "def", "filter_data", "(", "acts", ",", "raws", ",", "slot_dict", ",", "args", ")", ":", "\n", "    ", "slot_values_dict", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", ":", "\n", "        ", "slot_values_dict", "+=", "v", "\n", "", "gen_data", "=", "[", "]", "\n", "for", "act", ",", "raw", "in", "zip", "(", "acts", ",", "raws", ")", ":", "\n", "        ", "raw", "=", "raw", ".", "split", "(", ")", "\n", "label", "=", "[", "'O'", "]", "*", "len", "(", "raw", ")", "\n", "act", "=", "act", ".", "split", "(", "'\\t'", ")", "\n", "assert", "len", "(", "act", ")", "%", "2", "==", "0", "\n", "slot_values", "=", "[", "]", "\n", "tmp_values", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "act", ")", "/", "2", ")", ")", ":", "\n", "            ", "slot_values", ".", "append", "(", "[", "act", "[", "2", "*", "i", "]", ".", "split", "(", ")", ",", "act", "[", "2", "*", "i", "+", "1", "]", ".", "split", "(", ")", "]", ")", "\n", "tmp_values", ".", "append", "(", "act", "[", "2", "*", "i", "+", "1", "]", ")", "\n", "", "flag", "=", "False", "\n", "for", "v", "in", "slot_values_dict", ":", "\n", "            ", "if", "v", "not", "in", "tmp_values", "and", "v", "in", "raw", ":", "\n", "                ", "for", "v_all", "in", "tmp_values", ":", "\n", "                    ", "if", "v", "in", "v_all", ":", "\n", "                        ", "break", "\n", "", "", "else", ":", "\n", "                    ", "flag", "=", "True", "\n", "break", "\n", "", "", "", "if", "too_short", "(", "raw", ",", "tmp_values", ")", ":", "\n", "            ", "flag", "=", "True", "\n", "", "if", "flag", ":", "\n", "            ", "continue", "\n", "", "for", "slot", ",", "value", "in", "slot_values", ":", "\n", "            ", "label", ",", "flag", "=", "match_value", "(", "slot", ",", "value", ",", "raw", ",", "label", ",", "args", ")", "\n", "if", "not", "flag", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "            ", "gen_data", ".", "append", "(", "[", "' '", ".", "join", "(", "raw", ")", ",", "' '", ".", "join", "(", "label", ")", "]", ")", "\n", "", "", "print", "(", "'matching data: '", ",", "len", "(", "gen_data", ")", ")", "\n", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.get_slot_dict": [[100, 128], ["slot_dict.items", "raw.split.split", "label.split.split", "enumerate", "list", "slot_dict[].add", "slot_dict[].add", "slot_dict.keys", "set", "slot_dict[].add"], "function", ["None"], ["", "def", "get_slot_dict", "(", "data", ")", ":", "\n", "# data = [raw, label, intent]", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "for", "raw", ",", "label", "in", "data", ":", "\n", "        ", "raw", "=", "raw", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "raw", ")", ":", "\n", "            ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                ", "if", "tmp_str", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "word", "\n", "tmp_label", "=", "label", "[", "i", "]", "[", "2", ":", "]", "\n", "if", "tmp_label", "not", "in", "slot_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", "=", "set", "(", ")", "\n", "", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'I'", ":", "\n", "                ", "tmp_str", "=", "tmp_str", "+", "' '", "+", "word", "\n", "", "else", ":", "\n", "                ", "if", "tmp_str", ":", "\n", "                    ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "", "", "if", "tmp_str", ":", "\n", "            ", "slot_dict", "[", "tmp_label", "]", ".", "add", "(", "tmp_str", ")", "\n", "", "", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", ":", "\n", "        ", "slot_dict", "[", "k", "]", "=", "list", "(", "v", ")", "\n", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.delex_text": [[129, 142], ["txt.split.split", "label.split.split", "zip", "len", "len", "delex.append", "delex.append"], "function", ["None"], ["", "def", "delex_text", "(", "txt", ",", "label", ")", ":", "\n", "    ", "txt", "=", "txt", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "delex", "=", "[", "]", "\n", "assert", "len", "(", "txt", ")", "==", "len", "(", "label", ")", "\n", "for", "t", ",", "l", "in", "zip", "(", "txt", ",", "label", ")", ":", "\n", "        ", "if", "l", "[", "0", "]", "==", "'B'", ":", "\n", "            ", "delex", ".", "append", "(", "'_'", "+", "l", "[", "2", ":", "]", "+", "'_'", ")", "\n", "", "elif", "l", "==", "'O'", ":", "\n", "            ", "delex", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "", "return", "' '", ".", "join", "(", "delex", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.clean_repeat": [[144, 160], ["enumerate", "print", "random.shuffle", "len", "data_dict.keys", "final_data.append", "len"], "function", ["None"], ["", "def", "clean_repeat", "(", "raw_data", ",", "delex_data", ",", "gen_data", ")", ":", "\n", "    ", "data_dict", "=", "{", "}", "\n", "final_data", "=", "[", "]", "\n", "# for txt in raw_data:", "\n", "#     data_dict[txt] = ''", "\n", "# all same delex delete", "\n", "for", "i", ",", "txt", "in", "enumerate", "(", "raw_data", ")", ":", "\n", "        ", "data_dict", "[", "txt", "]", "=", "''", "\n", "", "for", "txt", ",", "label", "in", "gen_data", ":", "\n", "        ", "if", "txt", "not", "in", "data_dict", ".", "keys", "(", ")", ":", "\n", "            ", "data_dict", "[", "txt", "]", "=", "label", "\n", "final_data", ".", "append", "(", "[", "txt", ",", "label", "]", ")", "\n", "", "", "print", "(", "'different data: '", ",", "len", "(", "final_data", ")", ")", "\n", "# extract 1308 samples", "\n", "random", ".", "shuffle", "(", "final_data", ")", "\n", "return", "final_data", "[", ":", "len", "(", "raw_data", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.slot_replace": [[161, 178], ["zip", "gen_data.append", "random.choice", "random.choice.split", "new_text.append", "new_label.append", "len", "len", "len", "random.choice.split"], "function", ["None"], ["", "def", "slot_replace", "(", "delex_data", ",", "label_data", ",", "slot_dict", ")", ":", "\n", "    ", "gen_data", "=", "[", "]", "\n", "for", "delex", ",", "label", "in", "zip", "(", "delex_data", ",", "label_data", ")", ":", "\n", "#delex = delex.split()", "\n", "        ", "new_text", ",", "new_label", "=", "[", "]", ",", "[", "]", "\n", "for", "w", "in", "delex", ":", "\n", "            ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                ", "value", "=", "random", ".", "choice", "(", "slot_dict", "[", "w", "]", ")", "\n", "new_text", "+=", "value", ".", "split", "(", ")", "\n", "new_label", "+=", "[", "'B-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "\n", "new_label", "+=", "[", "'I-'", "+", "w", "[", "1", ":", "-", "1", "]", "]", "*", "(", "len", "(", "value", ".", "split", "(", ")", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "new_text", ".", "append", "(", "w", ")", "\n", "new_label", ".", "append", "(", "'O'", ")", "\n", "", "assert", "len", "(", "new_label", ")", "==", "len", "(", "new_text", ")", "\n", "", "gen_data", ".", "append", "(", "[", "' '", ".", "join", "(", "new_text", ")", ",", "' '", ".", "join", "(", "new_label", ")", "]", ")", "\n", "", "return", "gen_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.filter_act_data.transfer_separate_data": [[179, 188], ["zip", "open", "open", "data.append", "line.strip", "line.strip", "f.readlines", "f.readlines"], "function", ["None"], ["", "def", "transfer_separate_data", "(", "raw_txt", ",", "label_txt", ")", ":", "\n", "    ", "with", "open", "(", "raw_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "raw_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "label_txt", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "label_data", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "data", "=", "[", "]", "\n", "for", "t", ",", "l", "in", "zip", "(", "raw_data", ",", "label_data", ")", ":", "\n", "        ", "data", ".", "append", "(", "[", "t", ",", "l", "]", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.LineByLineTextDataset.__init__": [[95, 111], ["os.path.isfile", "logger.info", "run_act_to_delex.LineByLineTextDataset.get_act_data", "open", "open", "open", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "line.strip", "line.strip", "line.strip", "f.read().splitlines", "f.readlines", "f.readlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.get_act_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "label_path", ":", "str", ",", "intent_path", ":", "str", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_acts", "=", "self", ".", "get_act_data", "(", "examples", ",", "intents", ")", "\n", "self", ".", "examples", "=", "tokenizer", ".", "batch_encode_plus", "(", "examples", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "acts", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_acts", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.LineByLineTextDataset.get_act_data": [[112, 133], ["zip", "example.split.split.split", "run_act_to_delex.split_intent", "enumerate", "new_acts.append", "re.sub", "re.sub", "act.append", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.split_intent"], ["", "def", "get_act_data", "(", "self", ",", "examples", ",", "intents", ")", ":", "\n", "        ", "new_acts", "=", "[", "]", "\n", "for", "example", ",", "intent", "in", "zip", "(", "examples", ",", "intents", ")", ":", "\n", "            ", "example", "=", "example", ".", "split", "(", ")", "\n", "intent_str", "=", "split_intent", "(", "intent", ")", "\n", "act", "=", "[", "]", "\n", "for", "w", "in", "example", ":", "\n", "                ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                    ", "act", ".", "append", "(", "w", ")", "\n", "", "", "act_str", "=", "' '", "+", "intent_str", "+", "' ( '", "\n", "for", "i", ",", "slot", "in", "enumerate", "(", "act", ")", ":", "\n", "                ", "slot_str", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "slot", "[", "1", ":", "-", "1", "]", ")", "\n", "slot_str", "=", "re", ".", "sub", "(", "'\\.'", ",", "' '", ",", "slot_str", ")", "\n", "act_str", "+=", "slot", "+", "' = '", "+", "slot_str", "\n", "if", "i", "<", "len", "(", "act", ")", "-", "1", ":", "\n", "                    ", "act_str", "+=", "' ; '", "\n", "", "", "act_str", "+=", "')'", "\n", "new_acts", ".", "append", "(", "act_str", ")", "\n", "if", "not", "act_str", ":", "\n", "                ", "assert", "False", "\n", "", "", "return", "new_acts", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.LineByLineTextDataset.__len__": [[137, 139], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.LineByLineTextDataset.__getitem__": [[140, 143], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "acts", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.convert_label_to_id": [[69, 76], ["token_type_ids.append"], "function", ["None"], ["def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "slot_dict", "[", "'<pad>'", "]", "=", "-", "100", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.convert_id_to_label": [[77, 85], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "new_dict", "[", "-", "100", "]", "=", "'<pad>'", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.split_intent": [[86, 93], ["list", "enumerate", "c.isupper", "c.lower"], "function", ["None"], ["", "def", "split_intent", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "list", "(", "intent", ")", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "intent", ")", ":", "\n", "        ", "if", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "intent", "[", "i", "]", "=", "' '", "+", "c", ".", "lower", "(", ")", "\n", "", "", "intent", "=", "''", ".", "join", "(", "intent", ")", ".", "strip", "(", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples": [[146, 152], ["run_act_to_delex.LineByLineTextDataset"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", "\n", "intent_path", "=", "args", ".", "eval_intent_file", "if", "evaluate", "else", "args", ".", "train_intent_file", "\n", "label_path", "=", "args", ".", "eval_label_file", "if", "evaluate", "else", "args", ".", "train_label_file", "\n", "return", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "label_path", "=", "label_path", ",", "\n", "intent_path", "=", "intent_path", ",", "block_size", "=", "args", ".", "block_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.set_seed": [[154, 160], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints": [[162, 178], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints": [[180, 196], ["run_act_to_delex._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.mask_tokens": [[198, 229], ["inputs.clone", "slot_ids.clone", "torch.full", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "inputs.clone.eq", "torch.full.masked_fill_", "range", "torch.bernoulli", "range", "[].item"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "\n", "    ", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "seq_len", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "if", "args", ".", "wwm", ":", "\n", "        ", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "            ", "last_mask_flag", "=", "False", "\n", "for", "j", "in", "range", "(", "seq_len", ")", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "j", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                    ", "if", "masked_indices", "[", "i", "]", "[", "j", "]", ":", "\n", "                        ", "last_mask_flag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "last_mask_flag", "=", "False", "\n", "", "", "else", ":", "\n", "                    ", "if", "last_mask_flag", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "True", "\n", "", "else", ":", "\n", "                        ", "masked_indices", "[", "i", "]", "[", "j", "]", "=", "False", "\n", "", "", "", "", "", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "indices_replaced", "=", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "return", "inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.mask_tokens_cont": [[230, 269], ["inputs.clone", "slot_ids.clone", "inputs.clone", "inputs.clone.ne", "torch.sum", "start_seq.clone", "range", "torch.randint", "start_index[].item", "torch.tensor", "torch.cat", "torch.cat", "start_seq[].item", "mask_lens[].item", "seq_lens[].item", "tokenizer.convert_tokens_to_ids", "[].item", "seq_lens[].item", "[].item", "torch.ones().long", "torch.ones"], "function", ["None"], ["", "def", "mask_tokens_cont", "(", "inputs", ",", "tokenizer", ",", "args", ",", "slot_ids", ",", "cont_ids", ")", ":", "\n", "    ", "\"\"\" mask continued n tokens \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "slot_labels", "=", "slot_ids", ".", "clone", "(", ")", "\n", "mask_inputs", "=", "inputs", ".", "clone", "(", ")", "\n", "bs", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "no_padding_mask", "=", "labels", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "seq_lens", "=", "torch", ".", "sum", "(", "no_padding_mask", ",", "dim", "=", "-", "1", ")", "\n", "mask_lens", "=", "(", "seq_lens", "*", "args", ".", "mlm_probability", ")", ".", "int", "(", ")", "+", "1", "\n", "start_seq", "=", "seq_lens", "\n", "start_index", "=", "start_seq", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "        ", "start_index", "[", "i", "]", "=", "torch", ".", "randint", "(", "start_seq", "[", "i", "]", ".", "item", "(", ")", ",", "(", "1", ",", ")", ")", "\n", "start_tmp", "=", "start_index", "[", "i", "]", ".", "item", "(", ")", "\n", "end_tmp", "=", "start_tmp", "+", "mask_lens", "[", "i", "]", ".", "item", "(", ")", "\n", "# avoid mask part of a word", "\n", "if", "args", ".", "wwm", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "if", "cont_ids", "[", "i", "]", "[", "start_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "start_tmp", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "while", "True", ":", "\n", "                ", "if", "end_tmp", ">=", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "\n", "                    ", "break", "\n", "", "if", "cont_ids", "[", "i", "]", "[", "end_tmp", "]", ".", "item", "(", ")", "==", "1", ":", "\n", "                    ", "end_tmp", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "", "labels", "[", "i", "]", "[", ":", "start_tmp", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "end_tmp", ":", "]", "=", "-", "100", "\n", "labels", "[", "i", "]", "[", "seq_lens", "[", "i", "]", ".", "item", "(", ")", ":", "]", "=", "-", "100", "\n", "seq_1", "=", "inputs", "[", "i", "]", "[", ":", "start_tmp", "]", "\n", "seq_2", "=", "torch", ".", "tensor", "(", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seq_3", "=", "inputs", "[", "i", "]", "[", "end_tmp", ":", "]", "\n", "tmp_mask", "=", "torch", ".", "cat", "(", "[", "seq_1", ",", "seq_2", ",", "seq_3", "]", ")", "\n", "pad_length", "=", "inputs", "[", "i", "]", ".", "shape", "[", "0", "]", "-", "tmp_mask", ".", "shape", "[", "0", "]", "\n", "mask_inputs", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "tmp_mask", ",", "torch", ".", "ones", "(", "pad_length", ")", ".", "long", "(", ")", "*", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "", "return", "mask_inputs", ",", "labels", ",", "slot_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train": [[271, 512], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_act_to_delex.set_seed", "SummaryWriter", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "os.path.exists", "hasattr", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "outputs.to.eq", "inputs.to.ne", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "attn_enc_mask.unsqueeze().expand.to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "torch.mean", "inputs.to.ne", "inputs.to.ne", "attn_enc_mask.unsqueeze().expand.unsqueeze().expand", "attn.masked_fill.masked_fill", "torch.argmax", "loss.item", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_act_to_delex._rotate_checkpoints", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "attn.masked_fill.size", "float", "total_loss.mean.mean", "total_loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "hasattr", "os.path.join", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "attn_enc_mask.unsqueeze().expand.unsqueeze", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "logger.info", "logger.info", "logger.info", "print", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_act_to_delex._rotate_checkpoints", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_act_to_delex.evaluate", "evaluate.items", "hasattr", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._rotate_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", "]", "\n", "return", "data", "\n", "\n", "", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_epoch", "=", "0", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "lm_loss", ",", "logging_lm_loss", "=", "0.0", ",", "0.0", "\n", "sl_loss", ",", "logging_sl_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "outputs", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "attn_enc_mask", "=", "inputs", ".", "ne", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]), tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_enc_mask", "=", "attn_enc_mask", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "#preds = model(inputs, decoder_input_ids=outputs[:, :-1], lm_labels=labels[:, 1:], attention_mask=attn_enc_mask)", "\n", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "preds", "[", "0", "]", "\n", "# attn shape: (bs, self.num_heads, tgt_len, src_len)", "\n", "attn", "=", "torch", ".", "mean", "(", "preds", "[", "2", "]", "[", "11", "]", ",", "dim", "=", "1", ")", "\n", "# attn shape: (bs, tgt_len, src_len)", "\n", "attn_enc_mask", "&=", "inputs", ".", "ne", "(", "tokenizer", ".", "bos_token_id", ")", "\n", "attn_enc_mask", "&=", "inputs", ".", "ne", "(", "tokenizer", ".", "eos_token_id", ")", "# bs * src_len", "\n", "attn_enc_mask", "=", "attn_enc_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "attn", ".", "size", "(", ")", ")", "\n", "attn", "=", "attn", ".", "masked_fill", "(", "~", "attn_enc_mask", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "src_index", "=", "torch", ".", "argmax", "(", "attn", ",", "dim", "=", "-", "1", ")", "\n", "#print(src_index[0])", "\n", "#exit()", "\n", "total_loss", "=", "loss", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "total_loss", "=", "total_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "total_loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "total_loss", ".", "backward", "(", ")", "\n", "\n", "", "lm_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"lm_loss\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"slot_loss\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"training lm_loss: %.2f\"", ",", "(", "lm_loss", "-", "logging_lm_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training sl_loss: %.2f\"", ",", "(", "sl_loss", "-", "logging_sl_loss", ")", "/", "args", ".", "logging_steps", ")", "\n", "logger", ".", "info", "(", "\"training lr: %f\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ")", "\n", "logging_lm_loss", "=", "lm_loss", "\n", "logging_sl_loss", "=", "sl_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "print", "(", "global_step", ")", "\n", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "# torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))", "\n", "# torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))", "\n", "# logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "global_epoch", "+=", "1", "\n", "if", "args", ".", "save_steps", "==", "0", ":", "\n", "            ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_epoch", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "# torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))", "\n", "# torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))", "\n", "# logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)", "\n", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "lm_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate": [[514, 581], ["run_act_to_delex.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.DataParallel", "len", "outputs.to.eq", "outputs.to.clone", "inputs.to.to", "outputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "prefix", "=", "\"\"", ")", "->", "Dict", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "[", "s", "[", "0", "]", "for", "s", "in", "examples", "]", "\n", "output_ids", "=", "[", "s", "[", "1", "]", "for", "s", "in", "examples", "]", "\n", "input_ids", "=", "pad_sequence", "(", "input_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "output_ids", "=", "pad_sequence", "(", "output_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "[", "input_ids", ",", "output_ids", "]", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", ",", "eval_slot_loss", "=", "0.0", ",", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "outputs", "=", "batch", "\n", "padding_mask", "=", "outputs", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "labels", "=", "outputs", ".", "clone", "(", ")", "\n", "labels", "[", "padding_mask", "]", "=", "-", "100", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "outputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "preds", "=", "model", "(", "inputs", ",", "decoder_input_ids", "=", "outputs", "[", ":", ",", ":", "-", "1", "]", ",", "lm_labels", "=", "labels", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "preds", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "lm_loss", "=", "loss", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.get_slot_dict": [[583, 592], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.add_vocab": [[593, 602], ["enumerate", "open", "args.slot_dict.keys", "open", "word.strip", "f.write", "f.readlines"], "function", ["None"], ["", "def", "add_vocab", "(", "org_file", ",", "new_file", ",", "args", ")", ":", "\n", "    ", "with", "open", "(", "org_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "org_vocab", "=", "[", "word", ".", "strip", "(", ")", "for", "word", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_vocab", "=", "org_vocab", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "new_vocab", "[", "i", "+", "1", "]", "=", "'_'", "+", "w", "+", "'_'", "\n", "", "with", "open", "(", "new_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "w", "in", "new_vocab", ":", "\n", "            ", "f", ".", "write", "(", "w", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.main": [[603, 929], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_act_to_delex.set_seed", "run_act_to_delex.get_slot_dict", "len", "tokenizer_class.from_pretrained.add_special_tokens", "model_class.from_pretrained.resize_token_embeddings", "model_class.from_pretrained.to", "logger.info", "ValueError", "run_act_to_delex._sorted_checkpoints", "os.path.exists", "os.listdir", "ValueError", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "parser.parse_args.slot_dict.keys", "min", "model_class.from_pretrained", "logger.info", "model_class", "len", "model_class.from_pretrained.crf_layer.set_device", "torch.distributed.barrier", "run_act_to_delex.load_and_cache_examples", "run_act_to_delex.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "len", "ValueError", "config_class.from_pretrained", "config_class", "tokenizer_class.from_pretrained", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "model_class.from_pretrained.crf_layer.set_device", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_act_to_delex.evaluate", "dict", "results.update", "parser.parse_args.slot_dict.keys", "bool", "torch.distributed.get_rank", "model_class.from_pretrained.crf_layer.set_device", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex._sorted_checkpoints", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.load_and_cache_examples", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.train", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.run_act_to_delex.evaluate", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "default", "=", "'bart'", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "'bart-large'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "\n", "# new added", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lambda_slot\"", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "\"multitask slot predict weight\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crf\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use crf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wwm\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask the whole word\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mask_cont\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"mask continued k words\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--share_dec\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"share same decoder for lm and slot tagging\"", ")", "\n", "# slot_type_embedding related:", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_intent_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_intent.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_intent_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/atis/val_intent.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/train_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_label_file\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/atis/val_label.txt\"", ",", "help", "=", "\"\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Used --should_continue but no checkpoint was found in --output_dir.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "1", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", "(", ")", "\n", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", ".", "format", "(", "tokenizer_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "# add vocab", "\n", "", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "special_tokens_dict", "=", "{", "'additional_special_tokens'", ":", "[", "'_'", "+", "k", "+", "'_'", "for", "k", "in", "args", ".", "slot_dict", ".", "keys", "(", ")", "]", "}", "\n", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "\n", "# new class", "\n", "", "emd_layer", "=", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "model", ".", "model", ".", "encoder", ".", "embed_tokens", "=", "emd_layer", "\n", "model", ".", "model", ".", "decoder", ".", "embed_tokens", "=", "emd_layer", "\n", "if", "args", ".", "crf", ":", "\n", "        ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "if", "args", ".", "crf", ":", "\n", "            ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "if", "args", ".", "crf", ":", "\n", "                ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.LineByLineTextDataset.__init__": [[85, 106], ["os.path.isfile", "logger.info", "get_act_to_delex.LineByLineTextDataset.get_act_data", "open", "open", "open", "open", "json.load", "tokenizer.batch_encode_plus", "open", "line.strip", "line.strip", "line.strip", "range", "f.read().splitlines", "f.readlines", "f.readlines", "f.write", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.get_act_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ",", "label_path", ",", "intent_path", ",", "slot_dict_path", ",", "output_act_path", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "slot_dict_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "slot_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "new_acts", ",", "act_values", "=", "self", ".", "get_act_data", "(", "examples", ",", "intents", ")", "\n", "self", ".", "acts", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_acts", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "with", "open", "(", "output_act_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "act", "in", "act_values", ":", "\n", "                ", "for", "i", "in", "range", "(", "SEQ_NUM", ")", ":", "\n", "                    ", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "act", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.LineByLineTextDataset.get_act_data": [[107, 132], ["zip", "example.split.split.split", "get_act_to_delex.split_intent", "enumerate", "new_acts.append", "act_values.append", "re.sub", "re.sub", "act_value.extend", "act.append", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.split_intent"], ["", "", "", "", "def", "get_act_data", "(", "self", ",", "examples", ",", "intents", ")", ":", "\n", "        ", "new_acts", "=", "[", "]", "\n", "act_values", "=", "[", "]", "\n", "for", "example", ",", "intent", "in", "zip", "(", "examples", ",", "intents", ")", ":", "\n", "            ", "example", "=", "example", ".", "split", "(", ")", "\n", "intent_str", "=", "split_intent", "(", "intent", ")", "\n", "act", "=", "[", "]", "\n", "for", "w", "in", "example", ":", "\n", "                ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                    ", "act", ".", "append", "(", "w", ")", "\n", "", "", "act_str", "=", "' '", "+", "intent_str", "+", "' ( '", "\n", "act_value", "=", "[", "]", "\n", "for", "i", ",", "slot", "in", "enumerate", "(", "act", ")", ":", "\n", "                ", "slot_str", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "slot", "[", "1", ":", "-", "1", "]", ")", "\n", "slot_str", "=", "re", ".", "sub", "(", "'\\.'", ",", "' '", ",", "slot_str", ")", "\n", "act_str", "+=", "slot", "+", "' = '", "+", "slot_str", "\n", "if", "i", "<", "len", "(", "act", ")", "-", "1", ":", "\n", "                    ", "act_str", "+=", "' ; '", "\n", "", "act_value", ".", "extend", "(", "[", "slot", "]", ")", "\n", "", "act_str", "+=", "')'", "\n", "new_acts", ".", "append", "(", "act_str", ")", "\n", "act_values", ".", "append", "(", "act_value", ")", "\n", "if", "not", "act_str", ":", "\n", "                ", "assert", "False", "\n", "", "", "return", "new_acts", ",", "act_values", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.LineByLineTextDataset.__len__": [[133, 135], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "acts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.LineByLineTextDataset.__getitem__": [[136, 138], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "acts", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.get_token_label": [[34, 46], ["zip", "line.split.split", "label.split.split", "zip", "tok_label.append", "tok_labels.append", "tokenizer.tokenize", "len"], "function", ["None"], ["def", "get_token_label", "(", "tokenizer", ",", "lines", ",", "labels", ")", ":", "\n", "    ", "tok_labels", "=", "[", "]", "\n", "for", "line", ",", "label", "in", "zip", "(", "lines", ",", "labels", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tok_label", "=", "[", "'O'", "]", "\n", "for", "word", ",", "l", "in", "zip", "(", "line", ",", "label", ")", ":", "\n", "            ", "tok", "=", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "tok_label", "+=", "[", "l", "]", "*", "len", "(", "tok", ")", "\n", "", "tok_label", ".", "append", "(", "'O'", ")", "\n", "tok_labels", ".", "append", "(", "tok_label", ")", "\n", "", "return", "tok_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.convert_id_to_label": [[47, 54], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.convert_label_to_id": [[55, 61], ["token_type_ids.append"], "function", ["None"], ["", "def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.split_intent": [[62, 69], ["list", "enumerate", "c.isupper", "c.lower"], "function", ["None"], ["", "def", "split_intent", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "list", "(", "intent", ")", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "intent", ")", ":", "\n", "        ", "if", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "intent", "[", "i", "]", "=", "' '", "+", "c", ".", "lower", "(", ")", "\n", "", "", "intent", "=", "''", ".", "join", "(", "intent", ")", ".", "strip", "(", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.change_act": [[70, 82], ["random.random", "new_act.append", "slot_dict.keys", "print", "random.choice"], "function", ["None"], ["", "def", "change_act", "(", "act", ",", "slot_dict", ")", ":", "\n", "# act:[(s1, v1), ...]", "\n", "    ", "new_act", "=", "[", "]", "\n", "for", "slot", ",", "value", "in", "act", ":", "\n", "        ", "if", "slot", "not", "in", "slot_dict", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "slot", ")", "\n", "assert", "False", "\n", "", "prob", "=", "random", ".", "random", "(", ")", "\n", "if", "prob", ">=", "ACT_REPLACE_RATIO", ":", "\n", "            ", "value", "=", "random", ".", "choice", "(", "slot_dict", "[", "slot", "]", ")", "\n", "", "new_act", ".", "append", "(", "[", "slot", ",", "value", "]", ")", "\n", "", "return", "new_act", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.set_seed": [[139, 143], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.gen_data": [[146, 194], ["get_act_to_delex.LineByLineTextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "tqdm.tqdm", "torch.nn.utils.rnn.pad_sequence", "len", "inputs.to.to", "open", "torch.no_grad", "model.generate", "range", "writer.write", "range", "tokenizer.decode", "gen_strs.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.generate"], ["", "def", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "eval_dataset", "=", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "gen_data_file", ",", "label_path", "=", "args", ".", "gen_label_file", ",", "\n", "intent_path", "=", "args", ".", "gen_intent_file", ",", "slot_dict_path", "=", "args", ".", "slot_dict_file", ",", "output_act_path", "=", "args", ".", "output_act_file", ")", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "input_ids", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "gen_seqs", "=", "[", "]", "\n", "gen_strs", "=", "[", "]", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running generation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", "=", "batch", "\n", "batch_size", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", ",", "outputs_att_id", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", ",", "max_length", "=", "40", ",", "temperature", "=", "0.8", ",", "top_p", "=", "0.9", ",", "\n", "bos_token_id", "=", "tokenizer", ".", "bos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "\n", "eos_token_ids", "=", "tokenizer", ".", "eos_token_id", ",", "num_return_sequences", "=", "SEQ_NUM", ",", "repetition_penalty", "=", "1.4", ",", "\n", "num_beams", "=", "1", ")", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]))", "\n", "# print(tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# the original sentence", "\n", "#input_token = tokenizer.convert_ids_to_tokens(inputs[i])", "\n", "#input_str = tokenizer.decode(inputs[i], skip_special_tokens=True)", "\n", "                ", "for", "j", "in", "range", "(", "SEQ_NUM", ")", ":", "\n", "#output_token = tokenizer.convert_ids_to_tokens(outputs[seq_num*i+j])", "\n", "                    ", "output_str", "=", "tokenizer", ".", "decode", "(", "outputs", "[", "SEQ_NUM", "*", "i", "+", "j", "]", ")", "\n", "gen_strs", ".", "append", "(", "output_str", ")", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "data", "in", "gen_strs", ":", "\n", "            ", "writer", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.get_slot_dict": [[196, 205], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "", "", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_delex.main": [[206, 266], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "get_act_to_delex.get_slot_dict", "len", "get_act_to_delex.set_seed", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "get_act_to_delex.gen_data", "parser.parse_args.slot_dict.keys", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.gen_data"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gen_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"data source for generating.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_file\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The generated result file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for prediction\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "2020", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_label_file\"", ",", "default", "=", "'../data/snips/train_1308_label.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_intent_file\"", ",", "default", "=", "'../data/snips/train_1308_intent.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_act_file\"", ",", "default", "=", "'../data/snips/train_1308_act.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--slot_dict_file\"", ",", "default", "=", "'../data/snips/train_1308_slot_dict.json'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--change_input\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'whether to change the input of dialogue acts'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "device", "=", "device", "\n", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "set_seed", "(", "args", ")", "\n", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.__init__": [[60, 88], ["os.path.isfile", "logger.info", "get_delex_to_raw_single.LineByLineTextDataset.get_train_data", "print", "open", "open", "open", "open", "open", "open", "open", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "len", "line.strip", "line.strip", "line.strip", "line.strip", "f.write", "f.write", "f.write", "f.read().splitlines", "f.readlines", "f.readlines", "f.readlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.get_train_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ",", "label_path", ",", "delex_path", ",", "intent_path", ",", "output_delex_path", ",", "output_label_path", ",", "output_intent_path", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "delex_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "delexs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "new_delexs", ",", "new_examples", ",", "new_labels", ",", "new_intents", "=", "self", ".", "get_train_data", "(", "labels", ",", "delexs", ",", "examples", ",", "intents", ",", "args", ")", "\n", "with", "open", "(", "output_delex_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "new_delexs", ":", "\n", "                ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "output_label_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "new_labels", ":", "\n", "                ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "", "with", "open", "(", "output_intent_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "new_intents", ":", "\n", "                ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "", "self", ".", "examples", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_examples", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "self", ".", "delexs", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_delexs", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "print", "(", "len", "(", "new_delexs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.get_train_data": [[89, 117], ["zip", "label.split.split.split", "example.split.split.split", "delex.split.split.split", "len", "len", "enumerate", "new_delexs.append", "new_examples.append", "new_labels.append", "new_intents.append", "new_delex.append", "new_delex.append", "new_delex.append", "new_delex.append", "new_delex.append", "re.sub"], "methods", ["None"], ["", "def", "get_train_data", "(", "self", ",", "labels", ",", "delexs", ",", "examples", ",", "intents", ",", "args", ")", ":", "\n", "        ", "new_delexs", ",", "new_examples", ",", "new_labels", ",", "new_intents", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "label", ",", "delex", ",", "example", ",", "intent", "in", "zip", "(", "labels", ",", "delexs", ",", "examples", ",", "intents", ")", ":", "\n", "            ", "label", "=", "label", ".", "split", "(", ")", "\n", "example", "=", "example", ".", "split", "(", ")", "\n", "delex", "=", "delex", ".", "split", "(", ")", "\n", "assert", "len", "(", "label", ")", "==", "len", "(", "example", ")", "\n", "for", "d", "in", "delex", ":", "\n", "                ", "if", "d", "[", "0", "]", "==", "'_'", ":", "\n", "                    ", "d", "=", "d", "[", "1", ":", "-", "1", "]", "\n", "new_delex", "=", "[", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", ":", "\n", "                        ", "if", "l", "[", "0", "]", "==", "'B'", "and", "l", "[", "2", ":", "]", "==", "d", ":", "\n", "                            ", "if", "args", ".", "use_mask", ":", "\n", "                                ", "new_delex", ".", "append", "(", "'<mask>'", ")", "\n", "", "else", ":", "\n", "                                ", "new_delex", ".", "append", "(", "'_'", ")", "\n", "new_delex", ".", "append", "(", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "d", ")", ")", "\n", "new_delex", ".", "append", "(", "'_'", ")", "\n", "", "", "elif", "l", "[", "0", "]", "==", "'I'", "and", "l", "[", "2", ":", "]", "==", "d", ":", "\n", "                            ", "continue", "\n", "", "else", ":", "\n", "                            ", "new_delex", ".", "append", "(", "example", "[", "i", "]", ")", "\n", "", "", "new_delexs", ".", "append", "(", "' '", ".", "join", "(", "new_delex", ")", ")", "\n", "new_examples", ".", "append", "(", "' '", ".", "join", "(", "example", ")", ")", "\n", "new_labels", ".", "append", "(", "' '", ".", "join", "(", "label", ")", ")", "\n", "new_intents", ".", "append", "(", "intent", ")", "\n", "", "", "", "return", "new_delexs", ",", "new_examples", ",", "new_labels", ",", "new_intents", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.__len__": [[118, 120], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "delexs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.LineByLineTextDataset.__getitem__": [[121, 123], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "delexs", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_token_label": [[30, 42], ["zip", "line.split.split", "label.split.split", "zip", "tok_label.append", "tok_labels.append", "tokenizer.tokenize", "len"], "function", ["None"], ["def", "get_token_label", "(", "tokenizer", ",", "lines", ",", "labels", ")", ":", "\n", "    ", "tok_labels", "=", "[", "]", "\n", "for", "line", ",", "label", "in", "zip", "(", "lines", ",", "labels", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tok_label", "=", "[", "'O'", "]", "\n", "for", "word", ",", "l", "in", "zip", "(", "line", ",", "label", ")", ":", "\n", "            ", "tok", "=", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "tok_label", "+=", "[", "l", "]", "*", "len", "(", "tok", ")", "\n", "", "tok_label", ".", "append", "(", "'O'", ")", "\n", "tok_labels", ".", "append", "(", "tok_label", ")", "\n", "", "return", "tok_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.convert_id_to_label": [[43, 50], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.convert_label_to_id": [[51, 57], ["token_type_ids.append"], "function", ["None"], ["", "def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.set_seed": [[124, 128], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_delex_index": [[130, 154], ["re.sub", "tokenizer.tokenize", "index[].append"], "function", ["None"], ["", "def", "get_delex_index", "(", "delex", ",", "input_token", ",", "tokenizer", ")", ":", "\n", "# return index:{'_name_': [index_1, index_2, ...]}", "\n", "    ", "count", "=", "0", "\n", "index", "=", "{", "}", "\n", "for", "w", "in", "delex", ":", "\n", "        ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "            ", "index", "[", "w", "]", "=", "[", "]", "\n", "", "w_d", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "w", ")", "\n", "if", "w_d", "[", "0", "]", "!=", "' '", ":", "\n", "            ", "w_d", "=", "' '", "+", "w_d", "\n", "", "tokens", "=", "tokenizer", ".", "tokenize", "(", "w_d", ")", "\n", "#print(tokens)", "\n", "for", "t", "in", "tokens", ":", "\n", "            ", "if", "t", "!=", "'_'", ":", "\n", "                ", "if", "w", "[", "0", "]", "==", "'_'", ":", "\n", "                    ", "index", "[", "w", "]", ".", "append", "(", "count", ")", "\n", "", "count", "+=", "1", "\n", "", "", "", "token_count", "=", "0", "\n", "for", "w", "in", "input_token", ":", "\n", "        ", "if", "w", "!=", "'<pad>'", ":", "\n", "            ", "token_count", "+=", "1", "\n", "#print(count, token_count)", "\n", "", "", "assert", "count", "==", "token_count", "\n", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_output_att": [[155, 183], ["enumerate", "len", "len", "output_text.append", "output_att.append", "output_text.append", "output_att.append", "output_text.append", "output_att.append", "output_text.append", "output_att.append"], "function", ["None"], ["", "def", "get_output_att", "(", "output_token", ",", "attn_value", ")", ":", "\n", "# attn_value: tgt_len * src_len", "\n", "    ", "output_text", "=", "[", "]", "\n", "output_att", "=", "[", "]", "\n", "tmp_str", "=", "''", "\n", "tmp_att_value", "=", "0", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "output_token", ")", ":", "\n", "        ", "if", "w", "==", "'<pad>'", ":", "\n", "            ", "pass", "\n", "", "elif", "w", "==", "'<s>'", ":", "\n", "            ", "output_text", ".", "append", "(", "w", ")", "\n", "output_att", ".", "append", "(", "attn_value", "[", "i", "]", ")", "\n", "", "elif", "w", "==", "'</s>'", ":", "\n", "            ", "output_text", ".", "append", "(", "tmp_str", ")", "\n", "output_att", ".", "append", "(", "tmp_att_value", ")", "\n", "output_text", ".", "append", "(", "w", ")", "\n", "output_att", ".", "append", "(", "attn_value", "[", "i", "]", ")", "\n", "", "elif", "w", "[", "0", "]", "==", "'\u0120'", ":", "\n", "            ", "if", "tmp_str", "!=", "''", ":", "\n", "                ", "output_text", ".", "append", "(", "tmp_str", ")", "\n", "output_att", ".", "append", "(", "tmp_att_value", ")", "\n", "", "tmp_str", "=", "w", "[", "1", ":", "]", "\n", "tmp_att_value", "=", "attn_value", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "tmp_str", "+=", "w", "\n", "", "", "assert", "len", "(", "output_att", ")", "==", "len", "(", "output_text", ")", "\n", "\n", "return", "output_text", ",", "output_att", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_slot_pred": [[184, 206], ["torch.argmax().item", "delex_index_map.items", "delex_rev_map.keys", "torch.argmax"], "function", ["None"], ["", "def", "get_slot_pred", "(", "att_value", ",", "delex_index_map", ")", ":", "\n", "    ", "max_ind", "=", "torch", ".", "argmax", "(", "att_value", ")", ".", "item", "(", ")", "\n", "delex_rev_map", "=", "{", "}", "\n", "for", "k", ",", "vs", "in", "delex_index_map", ".", "items", "(", ")", ":", "\n", "        ", "for", "v", "in", "vs", ":", "\n", "            ", "delex_rev_map", "[", "v", "]", "=", "k", "\n", "", "", "if", "max_ind", "in", "delex_rev_map", ".", "keys", "(", ")", ":", "\n", "        ", "return", "delex_rev_map", "[", "max_ind", "]", "\n", "", "else", ":", "\n", "        ", "return", "'O'", "\n", "\n", "", "'''max_value = 0\n    tmp_slot = ''\n    for k, vs in delex_index_map.items():\n        tmp_value = 0.\n        for v in vs:\n            tmp_value += att_value[v].item()\n        tmp_value /= len(vs)\n        if max_value < tmp_value:\n            max_value = tmp_value\n            tmp_slot = k\n    return tmp_slot'''", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.convert_label": [[207, 227], ["range", "len", "len", "len", "delex_index_map.keys", "slot_stat.keys"], "function", ["None"], ["", "def", "convert_label", "(", "label", ",", "delex_index_map", ")", ":", "\n", "    ", "last_label", "=", "'O'", "\n", "slot_stat", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "        ", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "label", "[", "i", "]", "==", "last_label", ":", "\n", "            ", "label", "[", "i", "]", "=", "'I-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'_'", ":", "\n", "            ", "last_label", "=", "label", "[", "i", "]", "\n", "label", "[", "i", "]", "=", "'B-'", "+", "last_label", "[", "1", ":", "-", "1", "]", "\n", "if", "last_label", "[", "1", ":", "-", "1", "]", "in", "slot_stat", ":", "\n", "#print(label)", "\n", "                ", "return", "'error'", "\n", "", "else", ":", "\n", "                ", "slot_stat", "[", "last_label", "[", "1", ":", "-", "1", "]", "]", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "last_label", "=", "'O'", "\n", "", "", "if", "len", "(", "delex_index_map", ".", "keys", "(", ")", ")", "!=", "len", "(", "slot_stat", ".", "keys", "(", ")", ")", ":", "\n", "        ", "return", "'error'", "\n", "\n", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_output_label": [[228, 311], ["zip", "print", "open", "get_delex_to_raw_single.get_delex_index", "get_delex_to_raw_single.get_output_att", "enumerate", "len", "line.strip().split", "get_delex_to_raw_single.convert_label", "f.readlines", "none_slot_word.append", "convert_label.append", "output_data.append", "line.strip", "len", "convert_label.append", "len", "get_delex_to_raw_single.get_slot_pred", "convert_label.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_delex_index", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_output_att", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.convert_label", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_slot_pred"], ["", "def", "get_output_label", "(", "input_pth", ",", "gen_data", ",", "tokenizer", ")", ":", "\n", "    ", "output_data", "=", "[", "]", "\n", "with", "open", "(", "input_pth", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "delex_data", "=", "[", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "for", "delex", ",", "otpt", "in", "zip", "(", "delex_data", ",", "gen_data", ")", ":", "\n", "        ", "\"\"\" delex: [i want to watch _movie_number_ _movie_type_ movie]\n            input_token: [<s> i want to watch movie number movie type movie </s> <pad> <pad>]\n            output_token: [<s> i want to watch 1 horror movie </s> <pad> <pad>]\n            attn_id: [1 2 3 .... 0 2 0]\n            \n            return: [[i want to watch 1 horror movie], \n                     [O O O O B-movie_number B-movie_type O]]\n        \"\"\"", "\n", "input_token", ",", "output_token", ",", "attn_id", "=", "otpt", "\n", "delex", "=", "[", "'<s>'", "]", "+", "delex", "+", "[", "'</s>'", "]", "\n", "delex_index_map", "=", "get_delex_index", "(", "delex", ",", "input_token", ",", "tokenizer", ")", "\n", "output_txt", ",", "output_att", "=", "get_output_att", "(", "output_token", ",", "attn_id", ")", "\n", "#print(delex_index_map, output_txt, output_att)", "\n", "none_slot_index", "=", "0", "\n", "label", "=", "[", "]", "\n", "none_slot_word", "=", "[", "]", "\n", "for", "s", "in", "delex", ":", "\n", "            ", "if", "s", "[", "0", "]", "!=", "'_'", ":", "\n", "                ", "none_slot_word", ".", "append", "(", "s", ")", "\n", "\n", "# att + matching", "\n", "", "", "gen_index", "=", "0", "\n", "gen", "=", "output_txt", "\n", "flag", "=", "False", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "delex", ")", ":", "\n", "            ", "if", "w", "==", "gen", "[", "gen_index", "]", ":", "\n", "                ", "gen_index", "+=", "1", "\n", "label", ".", "append", "(", "'O'", ")", "\n", "continue", "\n", "", "elif", "delex", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "delex", "[", "i", "+", "1", "]", "[", "0", "]", "!=", "'_'", ":", "\n", "                ", "while", "gen_index", "<", "len", "(", "gen", ")", ":", "\n", "                    ", "if", "gen", "[", "gen_index", "]", "==", "delex", "[", "i", "+", "1", "]", ":", "\n", "                        ", "break", "\n", "", "label", ".", "append", "(", "delex", "[", "i", "]", ")", "\n", "gen_index", "+=", "1", "\n", "# no matching slot, filter out", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "# continuous slot", "\n", "", "", "elif", "delex", "[", "i", "]", "[", "0", "]", "==", "'_'", "and", "delex", "[", "i", "+", "1", "]", "[", "0", "]", "==", "'_'", ":", "\n", "                ", "while", "gen_index", "<", "len", "(", "gen", ")", ":", "\n", "                    ", "slot", "=", "get_slot_pred", "(", "output_att", "[", "gen_index", "]", ",", "delex_index_map", ")", "\n", "if", "slot", "==", "delex", "[", "i", "]", ":", "\n", "                        ", "gen_index", "+=", "1", "\n", "label", ".", "append", "(", "delex", "[", "i", "]", ")", "\n", "", "elif", "slot", "==", "delex", "[", "i", "+", "1", "]", ":", "\n", "                        ", "break", "\n", "", "else", ":", "\n", "                        ", "flag", "=", "True", "\n", "break", "\n", "", "", "else", ":", "\n", "                    ", "break", "\n", "", "if", "flag", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "break", "\n", "", "", "else", ":", "\n", "#print(count)", "\n", "            ", "label", "=", "convert_label", "(", "label", ",", "delex_index_map", ")", "\n", "if", "label", "!=", "'error'", ":", "\n", "                ", "output_data", ".", "append", "(", "[", "gen", "[", "1", ":", "-", "1", "]", ",", "label", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "\n", "# pure att", "\n", "", "", "'''for i, w in enumerate(output_txt):\n            if w == none_slot_word[none_slot_index]:\n                none_slot_index += 1\n                label.append('O')\n            else:\n                slot = get_slot_pred(output_att[i], delex_index_map)\n                label.append(slot)\n        if none_slot_index == len(none_slot_word):\n            label = convert_label(label, delex_index_map)\n            if label != 'error':\n                output_data.append([output_txt[1:-1], label[1:-1]])'''", "\n", "\n", "#exit()", "\n", "", "print", "(", "len", "(", "output_data", ")", ")", "\n", "return", "output_data", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.gen_data": [[314, 370], ["get_delex_to_raw_single.LineByLineTextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "tqdm.tqdm", "torch.nn.utils.rnn.pad_sequence", "len", "inputs.to.to", "open", "torch.no_grad", "model.generate", "range", "writer.write", "range", "tokenizer.decode", "gen_strs.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.generate"], ["", "def", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "eval_dataset", "=", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "gen_data_file", ",", "label_path", "=", "args", ".", "gen_label_file", ",", "\n", "delex_path", "=", "args", ".", "gen_delex_file", ",", "intent_path", "=", "args", ".", "gen_intent_file", ",", "output_delex_path", "=", "args", ".", "output_delex_file", ",", "\n", "output_label_path", "=", "args", ".", "output_label_file", ",", "output_intent_path", "=", "args", ".", "output_intent_file", ")", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "input_ids", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "gen_seqs", "=", "[", "]", "\n", "gen_strs", "=", "[", "]", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running generation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", "=", "batch", "\n", "batch_size", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "seq_num", "=", "1", "\n", "#print(inputs[0])", "\n", "#print(tokenizer.convert_ids_to_tokens(inputs[0]))", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", ",", "outputs_probs", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", ",", "max_length", "=", "40", ",", "temperature", "=", "1", ",", "top_p", "=", "0.9", ",", "\n", "bos_token_id", "=", "tokenizer", ".", "bos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "\n", "eos_token_ids", "=", "tokenizer", ".", "eos_token_id", ",", "num_return_sequences", "=", "seq_num", ",", "repetition_penalty", "=", "1.4", ",", "\n", "num_beams", "=", "1", ")", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]))", "\n", "# print(tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "# for prob, index in outputs_probs:", "\n", "#     print(prob)", "\n", "#     print(tokenizer.convert_ids_to_tokens(index))", "\n", "#exit()", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# the original sentence", "\n", "#input_token = tokenizer.convert_ids_to_tokens(inputs[i])", "\n", "#input_str = tokenizer.decode(inputs[i], skip_special_tokens=True)", "\n", "                ", "for", "j", "in", "range", "(", "seq_num", ")", ":", "\n", "#output_token = tokenizer.convert_ids_to_tokens(outputs[seq_num*i+j])", "\n", "                    ", "output_str", "=", "tokenizer", ".", "decode", "(", "outputs", "[", "seq_num", "*", "i", "+", "j", "]", ",", "skip_special_tokens", "=", "True", ")", "\n", "gen_strs", ".", "append", "(", "output_str", ")", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "data", "in", "gen_strs", ":", "\n", "            ", "writer", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.get_slot_dict": [[372, 381], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "", "", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_delex_to_raw_single.main": [[382, 449], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "get_delex_to_raw_single.get_slot_dict", "len", "get_delex_to_raw_single.set_seed", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "get_delex_to_raw_single.gen_data", "parser.parse_args.slot_dict.keys", "model_class.from_pretrained.crf_layer.set_device", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.gen_data", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.utils.crf.CRF.set_device"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gen_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"data source for generating.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_file\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The generated result file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for prediction\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "2020", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--crf\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"use crf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--share_dec\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"share same decoder for lm and slot tagging\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--filt_att\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"filter the generated data by attention\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_delex_file\"", ",", "default", "=", "'../data/snips/train_1308_delex.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_label_file\"", ",", "default", "=", "'../data/snips/train_1308_label.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_intent_file\"", ",", "default", "=", "'../data/snips/train_1308_intent.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_delex_file\"", ",", "default", "=", "'../data/snips/train_1308_single_delex.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_label_file\"", ",", "default", "=", "'../data/snips/train_1308_single_label.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_intent_file\"", ",", "default", "=", "'../data/snips/train_1308_single_intent.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_mask\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "device", "=", "device", "\n", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "set_seed", "(", "args", ")", "\n", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "config", "=", "config", ")", "\n", "if", "args", ".", "crf", ":", "\n", "        ", "model", ".", "crf_layer", ".", "set_device", "(", "args", ".", "device", ")", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.__init__": [[93, 114], ["os.path.isfile", "logger.info", "get_act_to_raw.LineByLineTextDataset.get_act_data", "open", "open", "open", "open", "json.load", "tokenizer.batch_encode_plus", "open", "line.strip", "line.strip", "line.strip", "range", "f.read().splitlines", "f.readlines", "f.readlines", "f.write", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.get_act_data"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ",", "label_path", ",", "intent_path", ",", "slot_dict_path", ",", "output_act_path", ",", "block_size", "=", "512", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "with", "open", "(", "label_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "intent_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "intents", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "with", "open", "(", "slot_dict_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "slot_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "new_acts", ",", "act_values", "=", "self", ".", "get_act_data", "(", "labels", ",", "examples", ",", "intents", ",", "slot_dict", ",", "args", ")", "\n", "self", ".", "acts", "=", "tokenizer", ".", "batch_encode_plus", "(", "new_acts", ",", "max_length", "=", "block_size", ")", "[", "\"input_ids\"", "]", "\n", "with", "open", "(", "output_act_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "act", "in", "act_values", ":", "\n", "                ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                    ", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "act", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.get_act_data": [[115, 158], ["zip", "label.split.split.split", "example.split.split.split", "get_act_to_raw.split_intent_snips", "enumerate", "enumerate", "new_acts.append", "act_values.append", "len", "len", "change_act.append", "get_act_to_raw.change_act", "re.sub", "re.sub", "act_value.extend", "change_act.append", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.split_intent_snips", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.change_act"], ["", "", "", "", "def", "get_act_data", "(", "self", ",", "labels", ",", "examples", ",", "intents", ",", "slot_dict", ",", "args", ")", ":", "\n", "        ", "new_acts", ",", "act_values", "=", "[", "]", ",", "[", "]", "\n", "for", "label", ",", "example", ",", "intent", "in", "zip", "(", "labels", ",", "examples", ",", "intents", ")", ":", "\n", "            ", "label", "=", "label", ".", "split", "(", ")", "\n", "example", "=", "example", ".", "split", "(", ")", "\n", "# ATIS OR SNIPS", "\n", "intent_str", "=", "split_intent_snips", "(", "intent", ")", "\n", "assert", "len", "(", "label", ")", "==", "len", "(", "example", ")", "\n", "act", "=", "[", "]", "\n", "tmp_str", ",", "tmp_label", "=", "''", ",", "''", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "example", ")", ":", "\n", "                ", "if", "tmp_str", "and", "tmp_label", "and", "label", "[", "i", "]", "[", "0", "]", "!=", "'I'", ":", "\n", "                    ", "act", ".", "append", "(", "[", "tmp_label", ",", "tmp_str", "]", ")", "\n", "tmp_str", "=", "''", "\n", "tmp_label", "=", "''", "\n", "", "if", "label", "[", "i", "]", "[", "0", "]", "==", "'B'", ":", "\n", "                    ", "tmp_label", "=", "label", "[", "i", "]", "[", "2", ":", "]", "\n", "tmp_str", "=", "w", "\n", "", "elif", "label", "[", "i", "]", "[", "0", "]", "==", "'I'", ":", "\n", "                    ", "tmp_str", "+=", "' '", "+", "w", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "if", "tmp_str", "and", "tmp_label", ":", "\n", "                ", "act", ".", "append", "(", "[", "tmp_label", ",", "tmp_str", "]", ")", "\n", "", "act_str", "=", "' '", "+", "intent_str", "+", "' ( '", "\n", "act_value", "=", "[", "]", "\n", "if", "args", ".", "change_input", ":", "\n", "                ", "act", "=", "change_act", "(", "act", ",", "slot_dict", ")", "\n", "", "if", "not", "act", ":", "\n", "                ", "continue", "\n", "", "for", "i", ",", "(", "slot", ",", "value", ")", "in", "enumerate", "(", "act", ")", ":", "\n", "                ", "slot", "=", "re", ".", "sub", "(", "'_'", ",", "' '", ",", "slot", ")", "\n", "slot", "=", "re", ".", "sub", "(", "'\\.'", ",", "' '", ",", "slot", ")", "\n", "act_str", "+=", "slot", "+", "' = '", "+", "value", "\n", "if", "i", "<", "len", "(", "act", ")", "-", "1", ":", "\n", "                    ", "act_str", "+=", "' ; '", "\n", "", "act_value", ".", "extend", "(", "[", "slot", ",", "value", "]", ")", "\n", "", "act_str", "+=", "')'", "\n", "if", "not", "act_str", ":", "\n", "                ", "continue", "\n", "", "new_acts", ".", "append", "(", "act_str", ")", "\n", "act_values", ".", "append", "(", "act_value", ")", "\n", "", "return", "new_acts", ",", "act_values", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.__len__": [[159, 161], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "acts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.LineByLineTextDataset.__getitem__": [[162, 164], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "acts", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_token_label": [[33, 45], ["zip", "line.split.split", "label.split.split", "zip", "tok_label.append", "tok_labels.append", "tokenizer.tokenize", "len"], "function", ["None"], ["def", "get_token_label", "(", "tokenizer", ",", "lines", ",", "labels", ")", ":", "\n", "    ", "tok_labels", "=", "[", "]", "\n", "for", "line", ",", "label", "in", "zip", "(", "lines", ",", "labels", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "tok_label", "=", "[", "'O'", "]", "\n", "for", "word", ",", "l", "in", "zip", "(", "line", ",", "label", ")", ":", "\n", "            ", "tok", "=", "tokenizer", ".", "tokenize", "(", "' '", "+", "word", ")", "\n", "tok_label", "+=", "[", "l", "]", "*", "len", "(", "tok", ")", "\n", "", "tok_label", ".", "append", "(", "'O'", ")", "\n", "tok_labels", ".", "append", "(", "tok_label", ")", "\n", "", "return", "tok_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.convert_id_to_label": [[46, 53], ["token_type_ids.append", "slot_dict.items", "sample.item"], "function", ["None"], ["", "def", "convert_id_to_label", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "new_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "slot_dict", ".", "items", "(", ")", "}", "\n", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "new_dict", "[", "sample", ".", "item", "(", ")", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.convert_label_to_id": [[54, 60], ["token_type_ids.append"], "function", ["None"], ["", "def", "convert_label_to_id", "(", "labels", ",", "slot_dict", ")", ":", "\n", "    ", "token_type_ids", "=", "[", "]", "\n", "for", "sample", "in", "labels", ":", "\n", "        ", "type_id", "=", "[", "slot_dict", "[", "s", "]", "for", "s", "in", "sample", "]", "\n", "token_type_ids", ".", "append", "(", "type_id", ")", "\n", "", "return", "token_type_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.split_intent_snips": [[61, 68], ["list", "enumerate", "c.isupper", "c.lower"], "function", ["None"], ["", "def", "split_intent_snips", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "list", "(", "intent", ")", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "intent", ")", ":", "\n", "        ", "if", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "intent", "[", "i", "]", "=", "' '", "+", "c", ".", "lower", "(", ")", "\n", "", "", "intent", "=", "''", ".", "join", "(", "intent", ")", ".", "strip", "(", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.split_intent_atis": [[69, 77], ["re.split", "new_intent.append"], "function", ["None"], ["", "def", "split_intent_atis", "(", "intent", ")", ":", "\n", "    ", "intent", "=", "re", ".", "split", "(", "r'_|#'", ",", "intent", ")", "\n", "new_intent", "=", "[", "]", "\n", "for", "w", "in", "intent", ":", "\n", "        ", "if", "w", "!=", "'atis'", ":", "\n", "            ", "new_intent", ".", "append", "(", "w", ")", "\n", "", "", "intent", "=", "' '", ".", "join", "(", "new_intent", ")", "\n", "return", "intent", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.change_act": [[78, 90], ["random.random", "random.choice", "new_act.append", "slot_dict.keys", "print"], "function", ["None"], ["", "def", "change_act", "(", "act", ",", "slot_dict", ")", ":", "\n", "# act:[(s1, v1), ...]", "\n", "    ", "new_act", "=", "[", "]", "\n", "for", "slot", ",", "value", "in", "act", ":", "\n", "        ", "if", "slot", "not", "in", "slot_dict", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "slot", ")", "\n", "assert", "False", "\n", "", "prob", "=", "random", ".", "random", "(", ")", "\n", "#if prob >= ACT_REPLACE_RATIO:", "\n", "value", "=", "random", ".", "choice", "(", "slot_dict", "[", "slot", "]", ")", "\n", "new_act", ".", "append", "(", "[", "slot", ",", "value", "]", ")", "\n", "", "return", "new_act", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed": [[165, 169], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.gen_data": [[172, 221], ["get_act_to_raw.LineByLineTextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "tqdm.tqdm", "torch.nn.utils.rnn.pad_sequence", "len", "inputs.to.to", "open", "torch.no_grad", "model.generate", "range", "writer.write", "range", "tokenizer.decode", "gen_strs.append"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.generate"], ["", "def", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "eval_dataset", "=", "LineByLineTextDataset", "(", "tokenizer", ",", "args", ",", "file_path", "=", "args", ".", "gen_data_file", ",", "label_path", "=", "args", ".", "gen_label_file", ",", "\n", "intent_path", "=", "args", ".", "gen_intent_file", ",", "slot_dict_path", "=", "args", ".", "slot_dict_file", ",", "output_act_path", "=", "args", ".", "output_act_file", ")", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "input_ids", "=", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "data", "=", "input_ids", "\n", "return", "data", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "collate_fn", "=", "collate", "\n", ")", "\n", "gen_seqs", "=", "[", "]", "\n", "gen_strs", "=", "[", "]", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running generation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", "=", "batch", "\n", "batch_size", "=", "inputs", ".", "shape", "[", "0", "]", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "seq_num", "=", "3", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", ",", "outputs_att_id", "=", "model", ".", "generate", "(", "input_ids", "=", "inputs", ",", "max_length", "=", "40", ",", "temperature", "=", "0.9", ",", "top_p", "=", "0.9", ",", "\n", "bos_token_id", "=", "tokenizer", ".", "bos_token_id", ",", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", ",", "\n", "eos_token_ids", "=", "tokenizer", ".", "eos_token_id", ",", "num_return_sequences", "=", "seq_num", ",", "repetition_penalty", "=", "1.4", ",", "\n", "num_beams", "=", "1", ")", "\n", "# print(tokenizer.convert_ids_to_tokens(inputs[0]))", "\n", "# print(tokenizer.convert_ids_to_tokens(outputs[0]))", "\n", "# exit()", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# the original sentence", "\n", "#input_token = tokenizer.convert_ids_to_tokens(inputs[i])", "\n", "#input_str = tokenizer.decode(inputs[i], skip_special_tokens=True)", "\n", "                ", "for", "j", "in", "range", "(", "seq_num", ")", ":", "\n", "#output_token = tokenizer.convert_ids_to_tokens(outputs[seq_num*i+j])", "\n", "                    ", "output_str", "=", "tokenizer", ".", "decode", "(", "outputs", "[", "seq_num", "*", "i", "+", "j", "]", ",", "skip_special_tokens", "=", "True", ")", "\n", "gen_strs", ".", "append", "(", "output_str", ")", "\n", "", "", "", "", "with", "open", "(", "args", ".", "output_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "data", "in", "gen_strs", ":", "\n", "            ", "writer", ".", "write", "(", "data", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict": [[223, 232], ["open", "f.readlines", "line.strip.strip"], "function", ["None"], ["", "", "", "def", "get_slot_dict", "(", "slot_file", ")", ":", "\n", "    ", "slot_dict", "=", "{", "}", "\n", "count", "=", "0", "\n", "with", "open", "(", "slot_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "slot_dict", "[", "line", "]", "=", "count", "\n", "count", "+=", "1", "\n", "", "", "return", "slot_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.main": [[233, 293], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "get_act_to_raw.get_slot_dict", "len", "get_act_to_raw.set_seed", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "get_act_to_raw.gen_data", "parser.parse_args.slot_dict.keys", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.get_slot_dict", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.set_seed", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.bart.get_act_to_raw.gen_data"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gen_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"data source for generating.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_file\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The generated result file\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ",", "\n", ")", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Ratio of tokens to mask for prediction\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "2020", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cuda_id\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"gpu id\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slot_type_list\"", ",", "type", "=", "str", ",", "default", "=", "\"../data/snips/slot_type_list.txt\"", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_label_file\"", ",", "default", "=", "'../data/snips/train_1308_label.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--gen_intent_file\"", ",", "default", "=", "'../data/snips/train_1308_intent.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_act_file\"", ",", "default", "=", "'../data/snips/train_1308_act.txt'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--slot_dict_file\"", ",", "default", "=", "'../data/snips/train_1308_slot_dict.json'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--change_input\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'whether to change the input of dialogue acts'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "args", ".", "cuda_id", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "device", "=", "device", "\n", "args", ".", "slot_dict", "=", "get_slot_dict", "(", "args", ".", "slot_type_list", ")", "\n", "num_class", "=", "len", "(", "args", ".", "slot_dict", ".", "keys", "(", ")", ")", "\n", "set_seed", "(", "args", ")", "\n", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "config", ".", "slot_size", "=", "num_class", "\n", "config", ".", "output_attentions", "=", "True", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "gen_data", "(", "model", ",", "tokenizer", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel._init_weights": [[100, 112], ["isinstance", "isinstance", "module.weight.data.normal_", "module.weight.data.normal_", "module.bias.data.zero_", "module.weight.data[].zero_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "std", "=", "self", ".", "config", ".", "init_std", "\n", "\n", "# called init_bert_params in fairseq", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "std", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel.dummy_inputs": [[113, 132], ["torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "modeling_bart._prepare_bart_decoder_inputs", "torch.Tensor().long.ne", "torch.Tensor().long.ne", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs"], ["", "", "", "@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "pad_token", "=", "1", "\n", "input_ids", "=", "torch", ".", "Tensor", "(", "\n", "[", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "2", ",", "pad_token", "]", ",", "\n", "]", "\n", ")", ".", "long", "(", ")", "\n", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attn_mask", "=", "None", "\n", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"attention_mask\"", ":", "input_ids", ".", "ne", "(", "pad_token", ")", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "decoder_attn_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.EncoderLayer.__init__": [[183, 197], ["torch.nn.Module.__init__", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "self_attn", "=", "SelfAttention", "(", "\n", "self", ".", "embed_dim", ",", "config", ".", "encoder_attention_heads", ",", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", ")", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "F", ".", "gelu", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "encoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "encoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.EncoderLayer.forward": [[198, 226], ["modeling_bart.EncoderLayer.self_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.self_attn_layer_norm", "modeling_bart.EncoderLayer.activation_fn", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.fc2", "torch.dropout", "torch.dropout", "modeling_bart.EncoderLayer.final_layer_norm", "modeling_bart.EncoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n            for t_tgt, t_src is excluded (or masked out), =0 means it is\n            included in attention\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", ",", "attn_weights", "=", "self", ".", "self_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "encoder_padding_mask", ",", "need_weights", "=", "self", ".", "output_attentions", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "return", "x", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartEncoder.__init__": [[237, 254], ["torch.nn.Module.__init__", "modeling_bart.LearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bart.LayerNorm", "modeling_bart.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "encoder_layerdrop", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_source_positions", "=", "config", ".", "max_position_embeddings", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "self", ".", "embed_positions", "=", "LearnedPositionalEmbedding", "(", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ",", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "EncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "encoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartEncoder.forward": [[255, 306], ["modeling_bart.BartEncoder.embed_tokens", "modeling_bart.BartEncoder.embed_positions", "modeling_bart.BartEncoder.layernorm_embedding", "torch.dropout", "torch.dropout", "x.transpose.transpose.transpose", "random.uniform", "encoder_states.append", "hidden_state.transpose", "encoder_states.append", "encoder_layer.forward", "all_attentions.append"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_ids (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            attention_mask (torch.LongTensor): indicating which indices are padding tokens.\n        Returns:\n            namedtuple:\n                - **x** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n\n                - **encoder_states** (List[Tensor]): all intermediate\n                  hidden states of shape `(src_len, batch, embed_dim)`.\n                  Only populated if *return_all_hiddens* is True.\n                - **all_attentions** (List[Tensor]): Attention weights for each layer.\n                During training might not be of length n_layers because of layer dropout.\n        \"\"\"", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_ids", ")", "\n", "x", "=", "inputs_embeds", "+", "embed_pos", "\n", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "encoder_states", ",", "all_attentions", "=", "[", "]", ",", "[", "]", "\n", "\n", "# encoder layers", "\n", "for", "encoder_layer", "in", "self", ".", "layers", ":", "\n", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "encoder_states", ".", "append", "(", "x", ")", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "# skip the layer", "\n", "                ", "attn", "=", "None", "\n", "", "else", ":", "\n", "                ", "x", ",", "attn", "=", "encoder_layer", ".", "forward", "(", "x", ",", "attention_mask", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "attn", ")", "\n", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "encoder_states", ".", "append", "(", "x", ")", "\n", "\n", "", "encoder_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "encoder_states", "]", "\n", "\n", "return", "x", ",", "encoder_states", ",", "all_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.DecoderLayer.__init__": [[309, 330], ["torch.nn.Module.__init__", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "modeling_bart.SelfAttention", "modeling_bart.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bart.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "self_attn", "=", "SelfAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "config", ".", "decoder_attention_heads", ",", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "activation_fn", "=", "F", ".", "gelu", "\n", "self", ".", "activation_dropout", "=", "config", ".", "activation_dropout", "\n", "\n", "self", ".", "self_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "encoder_attn", "=", "SelfAttention", "(", "\n", "self", ".", "embed_dim", ",", "\n", "config", ".", "decoder_attention_heads", ",", "\n", "dropout", "=", "config", ".", "attention_dropout", ",", "\n", "encoder_decoder_attention", "=", "True", ",", "\n", ")", "\n", "self", ".", "encoder_attn_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "config", ".", "decoder_ffn_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "config", ".", "decoder_ffn_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "final_layer_norm", "=", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.DecoderLayer.forward": [[331, 409], ["modeling_bart.DecoderLayer.self_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.self_attn_layer_norm", "modeling_bart.DecoderLayer.encoder_attn.forward", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.encoder_attn_layer_norm", "modeling_bart.DecoderLayer.activation_fn", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.fc2", "torch.dropout", "torch.dropout", "modeling_bart.DecoderLayer.final_layer_norm", "modeling_bart.DecoderLayer.fc1", "len"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attn_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "need_attn_weights", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_attn_mask (ByteTensor, optional): binary\n                ByteTensor of shape `(batch, src_len)` where padding\n                elements are indicated by ``1``.\n            need_attn_weights (bool, optional): return attention weights\n                for each head (default: return average over heads).\n\n        Returns:\n            encoded output of shape `(seq_len, batch, embed_dim)`\n        \"\"\"", "\n", "if", "decoder_cached_states", "is", "None", ":", "\n", "            ", "prev_self_attn_state", ",", "prev_attn_state", "=", "(", "None", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "decoder_cached_states", ")", "==", "3", "\n", "prev_self_attn_state", ",", "prev_attn_state", "=", "(", "\n", "decoder_cached_states", "[", "\"self\"", "]", ",", "\n", "decoder_cached_states", "[", "\"encoder_decoder\"", "]", ",", "\n", ")", "\n", "\n", "", "residual", "=", "x", "\n", "if", "prev_self_attn_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "prev_self_attn_state", "\n", "decoder_cached_states", "[", "\"self\"", "]", "=", "saved_state", "\n", "", "y", "=", "x", "# TODO(SS): figure out why fairseq did this, then hopefully delete it", "\n", "\n", "x", ",", "self_attn_weights", "=", "self", ".", "self_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "y", ",", "\n", "value", "=", "y", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "need_weights", "=", "need_attn_weights", ",", "\n", "attn_mask", "=", "attention_mask", ",", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "self_attn_layer_norm", "(", "x", ")", "\n", "residual", "=", "x", "\n", "assert", "self", ".", "encoder_attn", ".", "cache_key", "!=", "self", ".", "self_attn", ".", "cache_key", "\n", "if", "prev_attn_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "prev_attn_state", "\n", "decoder_cached_states", "[", "\"encoder_decoder\"", "]", "=", "saved_state", "\n", "", "x", ",", "encoder_attn_weights", "=", "self", ".", "encoder_attn", ".", "forward", "(", "\n", "query", "=", "x", ",", "\n", "key", "=", "encoder_hidden_states", ",", "# could be None", "\n", "value", "=", "encoder_hidden_states", ",", "\n", "key_padding_mask", "=", "encoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "need_attn_weights", ",", "# not returning it so why compute it", "\n", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "x", "=", "self", ".", "encoder_attn_layer_norm", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "x", "=", "self", ".", "activation_fn", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "activation_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "x", "=", "self", ".", "final_layer_norm", "(", "x", ")", "\n", "# change for enc-dec attention", "\n", "return", "(", "\n", "x", ",", "\n", "encoder_attn_weights", ",", "#self_attn_weights,", "\n", "decoder_cached_states", ",", "\n", ")", "# just self_attn weights for now, following t5, decoder_cached_states = cache for decoding", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.DecoderLayer._past_to_dict": [[411, 417], ["len"], "methods", ["None"], ["", "def", "_past_to_dict", "(", "self", ",", "prev_attn_state", ")", ":", "\n", "        ", "prev_key", ",", "prev_value", "=", "prev_attn_state", "[", ":", "2", "]", "\n", "saved_state", "=", "{", "\"prev_key\"", ":", "prev_key", ",", "\"prev_value\"", ":", "prev_value", "}", "\n", "if", "len", "(", "prev_attn_state", ")", ">=", "3", ":", "\n", "            ", "saved_state", "[", "\"prev_key_padding_mask\"", "]", "=", "prev_attn_state", "[", "2", "]", "\n", "", "return", "saved_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartDecoder.__init__": [[428, 445], ["torch.nn.Module.__init__", "modeling_bart.LearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bart.LayerNorm", "modeling_bart.DecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "embed_tokens", ":", "nn", ".", "Embedding", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "decoder_layerdrop", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "self", ".", "embed_positions", "=", "LearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "d_model", ",", "self", ".", "padding_idx", ",", "\n", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "DecoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "decoder_layers", ")", "]", "\n", ")", "# type: List[DecoderLayer]", "\n", "self", ".", "layernorm_embedding", "=", "LayerNorm", "(", "config", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartDecoder.forward": [[446, 515], ["modeling_bart.BartDecoder.embed_positions", "modeling_bart.BartDecoder.embed_tokens", "modeling_bart.BartDecoder.layernorm_embedding", "torch.dropout", "torch.dropout", "x.transpose.transpose.transpose", "enumerate", "x.transpose.transpose.transpose", "random.uniform", "decoder_layer.forward", "hidden_state.transpose", "list", "next_decoder_cache.append"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_padding_mask", ",", "\n", "combined_mask", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Includes several features from \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            input_ids (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_hidden_states: output from the encoder, used for\n                encoder-side attention\n            encoder_padding_mask: for ignoring pad tokens\n            decoder_cached_states (dict or None): dictionary used for storing state during generation\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - hidden states\n                - attentions\n        \"\"\"", "\n", "# embed positions", "\n", "positions", "=", "self", ".", "embed_positions", "(", "input_ids", ")", "\n", "x", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "\n", "\n", "if", "positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "positions", "\n", "\n", "", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "# (seq_len, BS, model_dim)", "\n", "# decoder layers", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_self_attns", "=", "(", ")", "\n", "next_decoder_cache", "=", "[", "]", "\n", "\n", "for", "i", ",", "decoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "decoder_layer", "# type: DecoderLayer", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "\n", "                ", "continue", "\n", "", "layer_state", "=", "decoder_cached_states", "[", "i", "]", "if", "decoder_cached_states", "is", "not", "None", "else", "None", "\n", "x", ",", "layer_self_attn", ",", "layer_past", "=", "decoder_layer", ".", "forward", "(", "\n", "x", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_padding_mask", ",", "\n", "decoder_cached_states", "=", "layer_state", ",", "\n", "attention_mask", "=", "combined_mask", ",", "\n", "need_attn_weights", "=", "self", ".", "output_attentions", ",", "\n", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "next_decoder_cache", ".", "append", "(", "layer_past", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "+=", "(", "x", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_self_attns", "+=", "(", "layer_self_attn", ",", ")", "\n", "\n", "# Convert shapes from (seq_len, BS, model_dim) to (BS, seq_len, model_dim)", "\n", "", "", "all_hidden_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "all_hidden_states", "]", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", ",", "next_decoder_cache", ",", "all_hidden_states", ",", "list", "(", "all_self_attns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention.__init__": [[520, 552], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "num_heads", ",", "\n", "kdim", "=", "None", ",", "\n", "vdim", "=", "None", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "# otherwise self_attention", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "# True for all BART", "\n", "\n", "assert", "self", ".", "encoder_decoder_attention", "or", "qkv_same_dim", ",", "(", "\n", "\"Self-attention requires query, key and \"", "\"value to be of the same size\"", "\n", ")", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "self", ".", "kdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "self", ".", "vdim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "cache_key", "=", "\"encoder_decoder\"", "if", "self", ".", "encoder_decoder_attention", "else", "\"self\"", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape": [[553, 555], ["tensor.contiguous().view().transpose", "tensor.contiguous().view", "tensor.contiguous"], "methods", ["None"], ["", "def", "_shape", "(", "self", ",", "tensor", ",", "dim_0", ",", "bsz", ")", ":", "\n", "        ", "return", "tensor", ".", "contiguous", "(", ")", ".", "view", "(", "dim_0", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention.forward": [[556, 654], ["query.size", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax.type_as", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_bart.SelfAttention.transpose().contiguous().view", "modeling_bart.SelfAttention.out_proj", "attn_weights.view.view.view", "list", "decoder_cached_states.get", "modeling_bart.SelfAttention.q_proj", "modeling_bart.SelfAttention.k_proj", "modeling_bart.SelfAttention.v_proj", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention._shape", "modeling_bart.SelfAttention._use_and_update_saved_state", "decoder_cached_states.get.update", "modeling_bart.SelfAttention.transpose", "attn_weights.view.view.size", "attn_weights.view.view.view", "attn_weights.view.view.view", "key_padding_mask.unsqueeze().unsqueeze().to", "attn_weights.view.view.masked_fill", "attn_weights.view.view.view", "modeling_bart.SelfAttention.size", "query.size", "modeling_bart.SelfAttention.k_proj", "modeling_bart.SelfAttention.v_proj", "attn_weights.view.view.view", "key_padding_mask.dim", "float", "modeling_bart.SelfAttention.transpose().contiguous", "modeling_bart.SelfAttention.view", "modeling_bart.SelfAttention.view", "key_padding_mask.size", "key_padding_mask.unsqueeze().unsqueeze", "modeling_bart.SelfAttention.transpose", "key_padding_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._shape", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._use_and_update_saved_state"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "query", ",", "\n", "key", ":", "Optional", "[", "Tensor", "]", ",", "\n", "value", ":", "Optional", "[", "Tensor", "]", ",", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", "decoder_cached_states", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Optional", "[", "Tensor", "]", "]", "]", "]", "=", "None", ",", "\n", "need_weights", ":", "bool", "=", "False", ",", "\n", "static_kv", ":", "bool", "=", "False", ",", "\n", "attn_mask", ":", "Optional", "[", "Tensor", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Tensor", ",", "Optional", "[", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"Input shape: Time(SeqLen) x Batch x Channel\n\n        Args:\n\n            key_padding_mask (ByteTensor, optional): mask to exclude\n                keys that are pads, of shape `(batch, src_len)`, where\n                padding elements are indicated by 1s.\n            need_weights (bool, optional): return the attention weights,\n                averaged over heads (default: False).\n            attn_mask (ByteTensor, optional): typically used to\n                implement causal attention, where the mask prevents the\n                attention from looking forward in time (default: None).\n        \"\"\"", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "# get here for encoder decoder cause of static_kv", "\n", "if", "decoder_cached_states", "is", "not", "None", ":", "# get the last k,v and mask for reuse", "\n", "            ", "saved_state", "=", "decoder_cached_states", ".", "get", "(", "self", ".", "cache_key", ",", "{", "}", ")", "\n", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "q", "=", "self", ".", "q_proj", "(", "query", ")", "*", "self", ".", "scaling", "\n", "if", "self", ".", "encoder_decoder_attention", ":", "\n", "            ", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "k_proj", "(", "key", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "k", "=", "self", ".", "k_proj", "(", "query", ")", "\n", "v", "=", "self", ".", "v_proj", "(", "query", ")", "\n", "\n", "", "q", "=", "self", ".", "_shape", "(", "q", ",", "tgt_len", ",", "bsz", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "self", ".", "_shape", "(", "k", ",", "-", "1", ",", "bsz", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "self", ".", "_shape", "(", "v", ",", "-", "1", ",", "bsz", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "            ", "k", ",", "v", ",", "key_padding_mask", ",", "new_state", "=", "self", ".", "_use_and_update_saved_state", "(", "\n", "k", ",", "v", ",", "saved_state", ",", "key_padding_mask", ",", "static_kv", ",", "bsz", "\n", ")", "\n", "saved_state", ".", "update", "(", "\n", "{", "\n", "\"prev_key\"", ":", "k", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", ",", "\n", "\"prev_value\"", ":", "v", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", ",", "\n", "\"prev_key_padding_mask\"", ":", "key_padding_mask", ",", "\n", "}", "\n", ")", "\n", "decoder_cached_states", "[", "self", ".", "cache_key", "]", "=", "saved_state", "# Update cache", "\n", "", "assert", "k", "is", "not", "None", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "assert", "attn_weights", ".", "size", "(", ")", "==", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "+", "attn_mask", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism not supporting Optional types.", "\n", "", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "dim", "(", ")", "==", "0", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "", "assert", "key_padding_mask", "is", "None", "or", "key_padding_mask", ".", "size", "(", ")", "[", ":", "2", "]", "==", "(", "bsz", ",", "src_len", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "reshaped", "=", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ".", "to", "(", "torch", ".", "bool", ")", "\n", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "reshaped", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "attn_weights_float", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "attn_weights", "=", "attn_weights_float", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_probs", "=", "F", ".", "dropout", "(", "attn_weights_float", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ",", ")", "\n", "assert", "v", "is", "not", "None", "\n", "attn_output", "=", "torch", ".", "bmm", "(", "attn_probs", ",", "v", ")", "\n", "assert", "attn_output", ".", "size", "(", ")", "==", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", ")", "\n", "attn_output", "=", "attn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn_output", "=", "self", ".", "out_proj", "(", "attn_output", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "return", "attn_output", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._use_and_update_saved_state": [[655, 681], ["saved_state.get", "modeling_bart.SelfAttention._cat_prev_key_padding_mask", "_prev_key.view", "_prev_value.view", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._cat_prev_key_padding_mask"], ["", "def", "_use_and_update_saved_state", "(", "self", ",", "k", ",", "v", ",", "saved_state", ",", "key_padding_mask", ",", "static_kv", ",", "bsz", ")", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "        ", "if", "\"prev_key\"", "in", "saved_state", ":", "\n", "            ", "_prev_key", "=", "saved_state", "[", "\"prev_key\"", "]", "\n", "assert", "_prev_key", "is", "not", "None", "\n", "prev_key", "=", "_prev_key", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                ", "assert", "k", "is", "not", "None", "\n", "k", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "k", "]", ",", "dim", "=", "1", ")", "\n", "", "", "if", "\"prev_value\"", "in", "saved_state", ":", "\n", "            ", "_prev_value", "=", "saved_state", "[", "\"prev_value\"", "]", "\n", "assert", "_prev_value", "is", "not", "None", "\n", "prev_value", "=", "_prev_value", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                ", "assert", "v", "is", "not", "None", "\n", "v", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "v", "]", ",", "dim", "=", "1", ")", "\n", "", "", "assert", "k", "is", "not", "None", "and", "v", "is", "not", "None", "\n", "prev_key_padding_mask", "=", "saved_state", ".", "get", "(", "\"prev_key_padding_mask\"", ",", "None", ")", "# type: Optional[Tensor]", "\n", "key_padding_mask", "=", "self", ".", "_cat_prev_key_padding_mask", "(", "\n", "key_padding_mask", ",", "prev_key_padding_mask", ",", "bsz", ",", "k", ".", "size", "(", "1", ")", ",", "static_kv", "\n", ")", "\n", "return", "k", ",", "v", ",", "key_padding_mask", ",", "saved_state", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.SelfAttention._cat_prev_key_padding_mask": [[682, 711], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.float", "key_padding_mask.float", "filler.cuda.cuda.cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "prev_key_padding_mask.size", "prev_key_padding_mask.float", "filler.cuda.cuda.float", "filler.cuda.cuda.cuda", "key_padding_mask.size", "filler.cuda.cuda.float", "key_padding_mask.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_cat_prev_key_padding_mask", "(", "\n", "key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "prev_key_padding_mask", ":", "Optional", "[", "Tensor", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "src_len", ":", "int", ",", "\n", "static_kv", ":", "bool", ",", "\n", ")", "->", "Optional", "[", "Tensor", "]", ":", "\n", "# saved key padding masks have shape (bsz, seq_len)", "\n", "        ", "if", "prev_key_padding_mask", "is", "not", "None", "and", "static_kv", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", "and", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "# During incremental decoding, as the padding token enters and", "\n", "# leaves the frame, there will be a time when prev or current is None", "\n", "", "elif", "prev_key_padding_mask", "is", "not", "None", ":", "\n", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "prev_key_padding_mask", ".", "size", "(", "1", ")", ")", "\n", "if", "prev_key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "prev_key_padding_mask", ".", "float", "(", ")", ",", "filler", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "filler", "=", "torch", ".", "zeros", "(", "batch_size", ",", "src_len", "-", "key_padding_mask", ".", "size", "(", "1", ")", ")", "\n", "if", "key_padding_mask", ".", "is_cuda", ":", "\n", "                ", "filler", "=", "filler", ".", "cuda", "(", ")", "\n", "", "new_key_padding_mask", "=", "torch", ".", "cat", "(", "[", "filler", ".", "float", "(", ")", ",", "key_padding_mask", ".", "float", "(", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "new_key_padding_mask", "=", "prev_key_padding_mask", "\n", "", "return", "new_key_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartClassificationHead.__init__": [[718, 725], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "input_dim", ",", "inner_dim", ",", "num_classes", ",", "pooler_dropout", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "input_dim", ",", "inner_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "pooler_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "inner_dim", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartClassificationHead.forward": [[726, 733], ["modeling_bart.BartClassificationHead.dropout", "modeling_bart.BartClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_bart.BartClassificationHead.dropout", "modeling_bart.BartClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LearnedPositionalEmbedding.__init__": [[743, 751], ["torch.nn.Embedding.__init__"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["def", "__init__", "(", "\n", "self", ",", "num_embeddings", ":", "int", ",", "embedding_dim", ":", "int", ",", "padding_idx", ":", "int", ",", "\n", ")", ":", "\n", "# if padding_idx is specified then offset the embedding ids by", "\n", "# this index and adjust num_embeddings appropriately", "\n", "        ", "assert", "padding_idx", "is", "not", "None", "\n", "num_embeddings", "+=", "padding_idx", "+", "1", "# WHY?", "\n", "super", "(", ")", ".", "__init__", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LearnedPositionalEmbedding.forward": [[752, 756], ["modeling_utils.create_position_ids_from_input_ids", "super().forward"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "positions", "=", "create_position_ids_from_input_ids", "(", "input", ",", "self", ".", "padding_idx", ")", "\n", "return", "super", "(", ")", ".", "forward", "(", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartModel.__init__": [[801, 813], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "modeling_bart.BartEncoder", "modeling_bart.BartDecoder", "modeling_bart.BartModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "padding_idx", ",", "vocab_size", "=", "config", ".", "pad_token_id", ",", "config", ".", "vocab_size", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "config", ".", "d_model", ",", "padding_idx", ")", "\n", "\n", "self", ".", "encoder", "=", "BartEncoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "self", ".", "decoder", "=", "BartDecoder", "(", "config", ",", "self", ".", "shared", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartModel.forward": [[814, 855], ["file_utils.add_start_docstrings_to_callable", "modeling_bart._prepare_bart_decoder_inputs", "isinstance", "modeling_bart.BartModel.decoder.forward", "modeling_bart._filter_out_falsey_values", "isinstance", "modeling_bart._filter_out_falsey_values", "modeling_bart.BartModel.encoder.forward", "attention_mask.dim", "attention_mask.max", "attention_mask.long"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "# type: Tuple", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "assert", "attention_mask", ".", "dim", "(", ")", "==", "2", "\n", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ".", "long", "(", ")", ")", "*", "-", "10000.0", "\n", "assert", "attention_mask", ".", "max", "(", ")", "<=", "0", "\n", "\n", "# make masks if user doesn't supply", "\n", "", "decoder_input_ids", ",", "decoder_attn_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "decoder_attn_mask", "=", "decoder_attention_mask", ",", "\n", ")", "\n", "\n", "\n", "assert", "decoder_input_ids", "is", "not", "None", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "# TODO(SS): make this caching more usable when overwrite generate", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "", "assert", "isinstance", "(", "encoder_outputs", ",", "tuple", ")", "\n", "# dec_features, decoder_cached_states, dec_hidden, dec_attn", "\n", "# test", "\n", "decoder_outputs", "=", "self", ".", "decoder", ".", "forward", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_attn_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "# Attention and hidden_states will be [] or None if they aren't needed", "\n", "decoder_outputs", "=", "_filter_out_falsey_values", "(", "decoder_outputs", ")", "# type: tuple", "\n", "assert", "isinstance", "(", "decoder_outputs", "[", "0", "]", ",", "torch", ".", "Tensor", ")", "\n", "encoder_outputs", "=", "_filter_out_falsey_values", "(", "encoder_outputs", ")", "# type: tuple", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartModel.get_input_embeddings": [[856, 858], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartModel.set_input_embeddings": [[859, 861], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "shared", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartModel.get_output_embeddings": [[862, 864], ["modeling_bart._make_linear_from_emb"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._make_linear_from_emb"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "_make_linear_from_emb", "(", "self", ".", "shared", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.__init__": [[872, 877], ["modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartModel", "modeling_bart._make_linear_from_emb", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._make_linear_from_emb"], ["def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model", "=", "BartModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "_make_linear_from_emb", "(", "self", ".", "model", ".", "shared", ")", "\n", "self", ".", "cls_layer", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "shared", ".", "weight", ".", "shape", "[", "1", "]", ",", "config", ".", "slot_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.forward": [[879, 953], ["file_utils.add_start_docstrings_to_callable", "modeling_bart.BartForMaskedLM.model.forward", "modeling_bart.BartForMaskedLM.lm_head.forward", "modeling_bart.BartForMaskedLM.cls_layer.forward", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "lm_logits.contiguous.contiguous.contiguous", "torch.nn.CrossEntropyLoss.", "lm_logits.contiguous.contiguous.reshape", "lm_labels.reshape", "slot_logits.contiguous.contiguous.contiguous", "torch.nn.CrossEntropyLoss.", "slot_logits.contiguous.contiguous.reshape", "slot_labels.reshape"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "slot_labels", "=", "None", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        masked_lm_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the masked language modeling loss.\n            Indices should either be in ``[0, ..., config.vocab_size]`` or -100 (see ``input_ids`` docstring).\n            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens\n            with labels\n            in ``[0, ..., config.vocab_size]``.\n\n    Returns:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n        masked_lm_loss (`optional`, returned when ``masked_lm_labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n            Masked language modeling loss.\n        prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`)\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n            tokenizer = BartTokenizer.from_pretrained('bart-large')\n            model = BartForMaskedLM.from_pretrained('bart-large')\n            input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\")).unsqueeze(0)  # Batch size 1\n            outputs = model(input_ids=input_ids, lm_labels=input_ids)\n            loss, prediction_scores = outputs[:2]\n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "slot_logits", "=", "self", ".", "cls_layer", ".", "forward", "(", "outputs", "[", "0", "]", ")", "\n", "outputs", "=", "(", "lm_logits", ",", "slot_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "#outputs = (lm_logits,) + outputs[1:]", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "#masked_lm_loss = loss_fct(lm_logits.view(-1, self.config.vocab_size), lm_labels.view(-1))", "\n", "lm_logits", "=", "lm_logits", ".", "contiguous", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "reshape", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "lm_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "#outputs = (masked_lm_loss,) + outputs", "\n", "\n", "if", "slot_labels", "is", "not", "None", ":", "\n", "                ", "slot_logits", "=", "slot_logits", ".", "contiguous", "(", ")", "\n", "slot_loss", "=", "loss_fct", "(", "slot_logits", ".", "reshape", "(", "-", "1", ",", "slot_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "slot_labels", ".", "reshape", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", "slot_loss", ",", ")", "+", "outputs", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.generate": [[954, 1168], ["isinstance", "isinstance", "modeling_bart.BartForMaskedLM.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full", "torch.full", "torch.full", "logger.warning", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_bart.BartForMaskedLM._generate_beam_search", "modeling_bart.BartForMaskedLM._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "isinstance", "next", "modeling_bart.BartForMaskedLM.parameters"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_beam_search", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_no_beam_search"], ["", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `True`.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictely positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            bos_token_id: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n\n            eos_token_ids: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n        Return:\n\n            output: `torch.LongTensor` of shape `(batch_size * num_return_sequences, sequence_length)`\n                sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id, do_sample=False)  # do greedy decoding\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, bos_token_id=tokenizer.bos_token_id, pad_token_id=tokenizer.pad_token_id, eos_token_ids=tokenizer.eos_token_id, num_return_sequences=3)  # 3 generate sequences using by sampling\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_ids", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "(", "isinstance", "(", "e", ",", "int", ")", "and", "e", ">=", "0", ")", "for", "e", "in", "eos_token_ids", ")", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "", "if", "pad_token_id", "is", "None", "and", "eos_token_ids", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_ids", "[", "0", "]", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_no_beam_search": [[1169, 1270], ["input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "input_ids.new().fill_", "enumerate", "modeling_bart.BartForMaskedLM.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "modeling_bart.BartForMaskedLM._do_output_past", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input_ids.new().fill_.min().item", "input_ids.new().fill_.max().item", "input_ids.new().fill_", "input_ids.new", "input_ids.new", "input_ids.new", "input_ids.new", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.multinomial().squeeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "set", "tokens_to_add.unsqueeze", "input_ids.new().fill_.mul().bool", "input_ids.new().fill_.masked_fill_", "input_ids.new().fill_.mul_", "input_ids.new().fill_.min", "input_ids.new().fill_.max", "input_ids.new", "input_ids.new().fill_.max().item", "decoder_input_ids[].tolist", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "input_ids.new().fill_.max().item", "input_ids.new().fill_.max", "torch.softmax", "torch.softmax", "input_ids.new().fill_.mul", "input_ids.new().fill_.max", "eos_in_sents.long", "input_ids.new().fill_.max"], "methods", ["None"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#value, next_token_id = torch.topk(F.softmax(next_token_logits), 5, dim=-1)", "\n", "#print(value[0], next_token_id[0], value[1], next_token_id[1])", "\n", "#return input_ids[0], next_token_id[0], input_ids[1], next_token_id[1]", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "\n", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "decoder_input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "", "return", "decoded", ",", "decoded_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM._generate_beam_search": [[1271, 1484], ["input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "input_ids.contiguous().view.contiguous().view.new().fill_", "torch.cat.view", "torch.cat.view", "input_ids.contiguous().view.contiguous().view.new().fill_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beam_scores.new.new.view", "range", "torch.cat.new", "torch.cat.new", "enumerate", "modeling_utils.BeamHypotheses", "modeling_bart.BartForMaskedLM.", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "modeling_bart.BartForMaskedLM._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all", "len", "best.append", "torch.cat.new.min().item", "torch.cat.new.max().item", "min", "torch.cat.new().fill_", "torch.cat.new().fill_", "enumerate", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "torch.stack().type().to", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "input_ids.contiguous().view.contiguous().view.new", "input_ids.contiguous().view.contiguous().view.new", "range", "range", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.log_softmax", "torch.log_softmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "next_words.view.view.view", "next_scores.view.view.view", "torch.log_softmax", "torch.log_softmax", "_scores.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "tuple", "zip", "max", "set", "torch.softmax", "torch.softmax", "beam_scores[].expand_as", "torch.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reordered_past.append", "generated_hyps[].add", "torch.cat.new.min", "torch.cat.new.max", "torch.cat.new.max().item", "torch.cat.new", "torch.cat.new", "len", "torch.stack().type", "torch.stack().type", "torch.stack().type", "torch.stack().type", "next", "decoder_input_ids[].tolist", "next_scores[].max().item", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "layer_past[].unsqueeze().clone().detach", "decoder_input_ids[].clone", "score.item", "modeling_bart.BartForMaskedLM.parameters", "word_id.item", "decoder_input_ids[].clone", "score.item", "torch.cat.new.max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "next_scores[].max", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["None"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "decoder_input_ids", "=", "input_ids", ".", "new", "(", "batch_size", ",", "num_beams", ",", "1", ")", ".", "fill_", "(", "0", ")", "\n", "decoder_input_ids", "=", "decoder_input_ids", ".", "view", "(", "batch_size", "*", "num_beams", ",", "1", ")", "\n", "decoded_label", "=", "input_ids", ".", "new", "(", "batch_size", "*", "num_beams", ",", "max_length", ")", ".", "fill_", "(", "0", ")", "\n", "cur_len", "=", "1", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "#model_inputs = self.prepare_inputs_for_generation(input_ids, past=past)", "\n", "            ", "outputs", "=", "self", "(", "input_ids", "=", "input_ids", ",", "decoder_input_ids", "=", "decoder_input_ids", ")", "\n", "# outputs = self(**model_inputs)  # (batch_size * num_beams, cur_len, vocab_size)", "\n", "scores", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "next_token_slot_logits", "=", "outputs", "[", "1", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "next_token_slot_label", "=", "torch", ".", "argmax", "(", "next_token_slot_logits", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "[", ":", ",", "cur_len", "]", "=", "next_token_slot_label", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "decoder_input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "scores", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample 2 next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", ")", "# (batch_size * num_beams, 2)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, 2)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, 2)", "\n", "# Match shape of greedy beam search", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_ids", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# add to generated hypotheses if end of sentence or last iteration", "\n", "if", "eos_token_ids", "is", "not", "None", "and", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", ":", "\n", "                        ", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted word if it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_idx", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "decoder_input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "decoder_input_ids", "=", "decoder_input_ids", "[", "beam_idx", ",", ":", "]", "\n", "decoder_input_ids", "=", "torch", ".", "cat", "(", "[", "decoder_input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "decoded_label", "=", "decoded_label", "[", "beam_idx", ",", ":", "]", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 2nd position", "\n", "                    ", "reordered_layer_past", "=", "[", "layer_past", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "1", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "# Add all open beam hypothesis to generated_hyps", "\n", "            ", "if", "not", "done", "[", "batch_idx", "]", ":", "\n", "                ", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "decoder_input_ids", "[", "batch_idx", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "", "sent_lengths", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "best_hyp", "=", "max", "(", "hypotheses", ".", "beams", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "1", "]", "\n", "sent_lengths", "[", "i", "]", "=", "len", "(", "best_hyp", ")", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# shorter batches are filled with pad_token", "\n", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined\"", "\n", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "decoder_input_ids", ".", "new", "(", "batch_size", ",", "sent_max_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypothesis and eos_token_id if necessary", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "                ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                    ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "", "", "", "else", ":", "\n", "# none of the hypotheses have an eos_token", "\n", "            ", "assert", "(", "len", "(", "hypo", ")", "==", "max_length", "for", "hypo", "in", "best", ")", "\n", "decoded", "=", "torch", ".", "stack", "(", "best", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "\n", "", "return", "decoded", ",", "decoded_label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.prepare_inputs_for_generation": [[1485, 1488], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"decoder_cached_states\"", ":", "past", ",", "\"decoder_input_ids\"", ":", "input_ids", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForMaskedLM.get_output_embeddings": [[1489, 1491], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__": [[1500, 1508], ["modeling_utils.PreTrainedModel.__init__", "modeling_bart.BartModel", "modeling_bart.BartClassificationHead", "modeling_bart.BartForSequenceClassification.model._init_weights", "modeling_bart.BartForSequenceClassification.model._init_weights"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.__init__", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel._init_weights", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.PretrainedBartModel._init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "BartConfig", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "BartModel", "(", "config", ")", "\n", "self", ".", "classification_head", "=", "BartClassificationHead", "(", "\n", "config", ".", "d_model", ",", "config", ".", "d_model", ",", "config", ".", "num_labels", ",", "config", ".", "classif_dropout", ",", "\n", ")", "\n", "self", ".", "model", ".", "_init_weights", "(", "self", ".", "classification_head", ".", "dense", ")", "\n", "self", ".", "model", ".", "_init_weights", "(", "self", ".", "classification_head", ".", "out_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward": [[1509, 1575], ["file_utils.add_start_docstrings_to_callable", "modeling_bart.BartForSequenceClassification.model.forward", "input_ids.eq", "modeling_bart.BartForSequenceClassification.classification_head", "len", "ValueError", "x[].view", "torch.cross_entropy", "torch.cross_entropy", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "x.size", "x.size", "modeling_bart.BartForSequenceClassification.view", "labels.view", "input_ids.eq.sum"], "methods", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.BartForSequenceClassification.forward"], ["", "@", "add_start_docstrings_to_callable", "(", "BART_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the sequence classification/regression loss.\n            Indices should be in :obj:`[0, ..., config.num_labels - 1]`.\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n\n    Returns:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.BartConfig`) and inputs:\n            loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`label` is provided):\n                Classification  loss (cross entropy)\n            logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n                Classification (or regression if config.num_labels==1) scores (before SoftMax).\n            hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n                of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n                Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n            attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n                Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n                Attentions weights after the attention softmax, used to compute the weighted average in the\n                self-attention\n                heads.\n\n    Examples::\n\n        from transformers import BartTokenizer, BartForSequenceClassification\n        import torch\n\n        tokenizer = BartTokenizer.from_pretrained('bart-large')\n        model = BartForSequenceClassification.from_pretrained('bart-large')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\",\n        add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=labels)\n        loss, logits = outputs[:2]\n\n        \"\"\"", "\n", "outputs", "=", "self", ".", "model", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", ")", "\n", "x", "=", "outputs", "[", "0", "]", "# last hidden state", "\n", "eos_mask", "=", "input_ids", ".", "eq", "(", "self", ".", "config", ".", "eos_token_id", ")", "\n", "if", "len", "(", "torch", ".", "unique", "(", "eos_mask", ".", "sum", "(", "1", ")", ")", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"All examples must have the same number of <eos> tokens.\"", ")", "\n", "", "sentence_representation", "=", "x", "[", "eos_mask", ",", ":", "]", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "logits", "=", "self", ".", "classification_head", "(", "sentence_representation", ")", "\n", "# Prepend logits", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "# prepend loss to output,", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._prepare_bart_decoder_inputs": [[70, 93], ["_combine_masks.to", "modeling_bart.shift_tokens_right", "shift_tokens_right.size", "modeling_bart.make_padding_mask", "modeling_bart._combine_masks", "torch.triu", "torch.triu", "modeling_bart.fill_with_neg_inf", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.shift_tokens_right", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.make_padding_mask", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._combine_masks", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.fill_with_neg_inf"], ["def", "_prepare_bart_decoder_inputs", "(", "\n", "config", ",", "input_ids", ",", "decoder_input_ids", "=", "None", ",", "decoder_attn_mask", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Prepare masks that ignore padding tokens  decoder and a causal lm mask for the decoder if\n    none are provided. This mimics the default behavior in fairseq. To override it pass in masks.\n    \"\"\"", "\n", "pad_token_id", "=", "config", ".", "pad_token_id", "\n", "need_causal_mask", "=", "not", "config", ".", "output_past", "\n", "if", "decoder_input_ids", "is", "None", ":", "\n", "        ", "decoder_input_ids", "=", "shift_tokens_right", "(", "input_ids", ",", "pad_token_id", ")", "\n", "", "bsz", ",", "tgt_len", "=", "decoder_input_ids", ".", "size", "(", ")", "[", ":", "2", "]", "\n", "if", "decoder_attn_mask", "is", "None", ":", "\n", "        ", "decoder_padding_mask", "=", "make_padding_mask", "(", "decoder_input_ids", ",", "pad_token_id", ")", "\n", "if", "need_causal_mask", ":", "\n", "            ", "causal_lm_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "torch", ".", "zeros", "(", "tgt_len", ",", "tgt_len", ")", ")", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "causal_lm_mask", "=", "None", "\n", "", "new_shape", "=", "(", "bsz", ",", "tgt_len", ",", "tgt_len", ")", "\n", "# make it broadcastable so can just be added to the attention coefficients", "\n", "decoder_attn_mask", "=", "_combine_masks", "(", "decoder_padding_mask", ",", "causal_lm_mask", ",", "new_shape", ")", "\n", "", "decoder_attn_mask", "=", "decoder_attn_mask", ".", "to", "(", "device", "=", "input_ids", ".", "device", ")", "\n", "assert", "decoder_attn_mask", "is", "None", "or", "decoder_attn_mask", ".", "shape", "==", "(", "bsz", ",", "1", ",", "tgt_len", ",", "tgt_len", ")", "\n", "return", "decoder_input_ids", ",", "decoder_attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._make_linear_from_emb": [[134, 139], ["torch.nn.Linear"], "function", ["None"], ["", "", "def", "_make_linear_from_emb", "(", "emb", ")", ":", "\n", "    ", "vocab_size", ",", "emb_size", "=", "emb", ".", "weight", ".", "shape", "\n", "lin_layer", "=", "nn", ".", "Linear", "(", "vocab_size", ",", "emb_size", ",", "bias", "=", "False", ")", "\n", "lin_layer", ".", "weight", ".", "data", "=", "emb", ".", "weight", ".", "data", "# .T", "\n", "return", "lin_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._check_shapes": [[142, 145], ["AssertionError"], "function", ["None"], ["", "def", "_check_shapes", "(", "shape_1", ",", "shape2", ")", ":", "\n", "    ", "if", "shape_1", "!=", "shape2", ":", "\n", "        ", "raise", "AssertionError", "(", "\"shape mismatch: {} != {}\"", ".", "format", "(", "shape_1", ",", "shape2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._combine_masks": [[147, 160], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "modeling_bart._check_shapes", "key_padding_mask.unsqueeze().expand", "modeling_bart._check_shapes", "attn_mask.unsqueeze().expand", "key_padding_mask.unsqueeze", "attn_mask.unsqueeze"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._check_shapes", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._check_shapes"], ["", "", "def", "_combine_masks", "(", "key_padding_mask", ",", "attn_mask", ",", "targ_size", ")", ":", "\n", "# targ_size = (bsz, tgt_len, src_len)", "\n", "    ", "a", "=", "torch", ".", "zeros", "(", "targ_size", ")", "\n", "b", "=", "torch", ".", "zeros", "(", "targ_size", ")", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "# (bsz, tgt_len) -> targ_size", "\n", "        ", "_check_shapes", "(", "key_padding_mask", ".", "shape", ",", "targ_size", "[", ":", "2", "]", ")", "\n", "reshaped", "=", "key_padding_mask", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "*", "targ_size", ")", "\n", "a", "[", "reshaped", "]", "=", "1e-8", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "# (tgt_len, src_len) -> targ_size", "\n", "        ", "_check_shapes", "(", "attn_mask", ".", "shape", ",", "targ_size", "[", "-", "2", ":", "]", ")", "\n", "b", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "*", "targ_size", ")", "\n", "", "return", "(", "a", "+", "b", ")", ".", "unsqueeze", "(", "1", ")", ".", "clamp", "(", "LARGE_NEGATIVE", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.shift_tokens_right": [[162, 169], ["input_ids.clone", "input_ids.gather().squeeze", "input_ids.gather", "input_ids.ne().sum", "input_ids.ne"], "function", ["None"], ["", "def", "shift_tokens_right", "(", "input_ids", ",", "pad_token_id", ")", ":", "\n", "    ", "\"\"\"Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\"\"\"", "\n", "prev_output_tokens", "=", "input_ids", ".", "clone", "(", ")", "\n", "index_of_eos", "=", "(", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "sum", "(", "dim", "=", "1", ")", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "prev_output_tokens", "[", ":", ",", "0", "]", "=", "input_ids", ".", "gather", "(", "1", ",", "index_of_eos", ")", ".", "squeeze", "(", ")", "\n", "prev_output_tokens", "[", ":", ",", "1", ":", "]", "=", "input_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "return", "prev_output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.make_padding_mask": [[171, 177], ["input_ids.eq", "input_ids.eq.any"], "function", ["None"], ["", "def", "make_padding_mask", "(", "input_ids", ",", "padding_idx", "=", "1", ")", ":", "\n", "    ", "\"\"\"True for pad tokens\"\"\"", "\n", "padding_mask", "=", "input_ids", ".", "eq", "(", "padding_idx", ")", "\n", "if", "not", "padding_mask", ".", "any", "(", ")", ":", "\n", "        ", "padding_mask", "=", "None", "\n", "", "return", "padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm": [[758, 767], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "FusedLayerNorm"], "function", ["home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm", "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.LayerNorm"], ["", "", "def", "LayerNorm", "(", "normalized_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "normalization", "import", "FusedLayerNorm", "\n", "\n", "return", "FusedLayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "torch", ".", "nn", ".", "LayerNorm", "(", "normalized_shape", ",", "eps", ",", "elementwise_affine", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart.fill_with_neg_inf": [[769, 772], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a input_ids with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaolinandy_slu-aug-prlm.modify.modeling_bart._filter_out_falsey_values": [[774, 777], ["tuple", "isinstance"], "function", ["None"], ["", "def", "_filter_out_falsey_values", "(", "tup", ")", "->", "Tuple", ":", "\n", "    ", "\"\"\"Remove entries that are None or [] from an iterable.\"\"\"", "\n", "return", "tuple", "(", "x", "for", "x", "in", "tup", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "or", "x", ")", "\n", "\n"]]}